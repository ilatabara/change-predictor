id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fcinder~master~I4e9fb3c6b3e098998f41e266b2cfc51a4af1fc65,openstack/cinder,master,I4e9fb3c6b3e098998f41e266b2cfc51a4af1fc65,Fix bad indentation in netapp and san.hp volume drivers,MERGED,2014-08-13 07:53:59.000000000,2014-08-16 05:26:18.000000000,2014-08-13 18:38:24.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 7872}, {'_account_id': 8871}, {'_account_id': 9064}, {'_account_id': 9366}, {'_account_id': 10068}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-08-13 07:53:59.000000000', 'files': ['cinder/volume/drivers/netapp/utils.py', 'cinder/volume/drivers/netapp/ssc_utils.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/58908e6d6c6bbad1c7bc4144a7b42f0fde3485cd', 'message': 'Fix bad indentation in netapp and san.hp volume drivers\n\nCloses-Bug: #1356223\n\nChange-Id: I4e9fb3c6b3e098998f41e266b2cfc51a4af1fc65\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>\n'}]",0,113803,58908e6d6c6bbad1c7bc4144a7b42f0fde3485cd,21,13,1,9064,,,0,"Fix bad indentation in netapp and san.hp volume drivers

Closes-Bug: #1356223

Change-Id: I4e9fb3c6b3e098998f41e266b2cfc51a4af1fc65
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/03/113803/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/netapp/utils.py', 'cinder/volume/drivers/netapp/ssc_utils.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py']",7,58908e6d6c6bbad1c7bc4144a7b42f0fde3485cd,bug/1356223," # Error code 150 means 'invalid operation: Cannot grow # this type of volume'. # Suppress raising this exception because we can # resolve it by converting it into a base volume. # Afterwards, extending the volume should succeed, or # fail with a different exception/error code. ex_ctxt.reraise = False self._extend_volume(volume, volume_name, growth_size_mib, _convert_to_base=True)"," # Error code 150 means 'invalid operation: Cannot grow # this type of volume'. # Suppress raising this exception because we can # resolve it by converting it into a base volume. # Afterwards, extending the volume should succeed, or # fail with a different exception/error code. ex_ctxt.reraise = False self._extend_volume(volume, volume_name, growth_size_mib, _convert_to_base=True)",97,97
openstack%2Fopenstack-doc-tools~master~I345e6a8557ad91c8a5941139873cd2c23a27f199,openstack/openstack-doc-tools,master,I345e6a8557ad91c8a5941139873cd2c23a27f199,Fix doc-tools-check-language,MERGED,2014-08-15 20:46:29.000000000,2014-08-16 05:13:44.000000000,2014-08-16 05:13:44.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-15 20:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/17bacb14d71f799149c1ea1a5c82d29439d9cc8c', 'message': 'Fix doc-tools-check-language\n\nFix quoting so strings are split.\n\nChange-Id: I345e6a8557ad91c8a5941139873cd2c23a27f199\n'}, {'number': 2, 'created': '2014-08-16 04:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/3a49f43686c36b102ba0ce4209ad230add071cb0', 'message': 'Fix doc-tools-check-language\n\nFix quoting so strings are split.\nAdd config variables so that api-site repository can be used.\n\nChange-Id: I345e6a8557ad91c8a5941139873cd2c23a27f199\n'}, {'number': 3, 'created': '2014-08-16 04:56:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/1916f634f12fbdaba1789b66967814b4891196e6', 'message': 'Fix doc-tools-check-language\n\nFix quoting so strings are split.\nAdd config variables so that api-site repository can be used.\n\nChange-Id: I345e6a8557ad91c8a5941139873cd2c23a27f199\n'}, {'number': 4, 'created': '2014-08-16 05:09:12.000000000', 'files': ['bin/doc-tools-check-languages.conf', 'RELEASE_NOTES.rst', 'bin/doc-tools-check-languages'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/edb4ff499811f1c23de136025f96cc032037474f', 'message': 'Fix doc-tools-check-language\n\nFix quoting so strings are split.\nAdd config variables so that api-site repository can be used.\n\nChange-Id: I345e6a8557ad91c8a5941139873cd2c23a27f199\n'}]",0,114655,edb4ff499811f1c23de136025f96cc032037474f,16,3,4,6547,,,0,"Fix doc-tools-check-language

Fix quoting so strings are split.
Add config variables so that api-site repository can be used.

Change-Id: I345e6a8557ad91c8a5941139873cd2c23a27f199
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/55/114655/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/doc-tools-check-languages'],1,17bacb14d71f799149c1ea1a5c82d29439d9cc8c,fix-check-languages," for book in ${BOOKS[""$language""]}; do"," for book in ""${BOOKS[""$language""]}""; do",1,1
openstack%2Fcinder~master~Ia12c91b356f0ccebf874933ff459aa2faa190655,openstack/cinder,master,Ia12c91b356f0ccebf874933ff459aa2faa190655,Ignore HTTP_PROXY during test requests,MERGED,2014-08-13 02:16:48.000000000,2014-08-16 04:48:36.000000000,2014-08-16 04:48:35.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12492}]","[{'number': 1, 'created': '2014-08-13 02:16:48.000000000', 'files': ['cinder/tests/test_wsgi.py', 'cinder/tests/integrated/integrated_helpers.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b0ebfb90958afac39be24b5157763d479256ab8c', 'message': 'Ignore HTTP_PROXY during test requests\n\nurllib2 follows http_proxy/HTTP_PROXY by default.  If a (non-local)\nproxy is set and a test tries to connect to localhost:$port, it will\ninstead attempt to connect to $port on the proxy and (presumably) fail.\n\nThis change forces the two tests that failed in the presence of\nHTTP_PROXY to connect directly.\n\nChange-Id: Ia12c91b356f0ccebf874933ff459aa2faa190655\n'}]",0,113752,b0ebfb90958afac39be24b5157763d479256ab8c,19,11,1,11279,,,0,"Ignore HTTP_PROXY during test requests

urllib2 follows http_proxy/HTTP_PROXY by default.  If a (non-local)
proxy is set and a test tries to connect to localhost:$port, it will
instead attempt to connect to $port on the proxy and (presumably) fail.

This change forces the two tests that failed in the presence of
HTTP_PROXY to connect directly.

Change-Id: Ia12c91b356f0ccebf874933ff459aa2faa190655
",git fetch https://review.opendev.org/openstack/cinder refs/changes/52/113752/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_wsgi.py', 'cinder/tests/integrated/integrated_helpers.py']",2,b0ebfb90958afac39be24b5157763d479256ab8c,http-proxy,"import fixtures for var in ('http_proxy', 'HTTP_PROXY'): self.useFixture(fixtures.EnvironmentVariable(var)) ",,13,3
openstack%2Fcinder~master~I1b37c49e0a624de42d89890b44458ec6bd4239ee,openstack/cinder,master,I1b37c49e0a624de42d89890b44458ec6bd4239ee,Fixes wrong usage of mock.assert_not_called(),MERGED,2014-08-06 07:07:37.000000000,2014-08-16 04:47:43.000000000,2014-08-16 04:47:41.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 8247}, {'_account_id': 8415}, {'_account_id': 9533}, {'_account_id': 9796}, {'_account_id': 11811}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-08-06 07:07:37.000000000', 'files': ['cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/324b981b78ae1d1dfef31b910b272e11ee166cbf', 'message': 'Fixes wrong usage of mock.assert_not_called()\n\nThere is no method assert_not_called in mock, use\nassertFalse(mock.called) instead of that.\n\nChange-Id: I1b37c49e0a624de42d89890b44458ec6bd4239ee\n'}]",0,112222,324b981b78ae1d1dfef31b910b272e11ee166cbf,22,10,1,9796,,,0,"Fixes wrong usage of mock.assert_not_called()

There is no method assert_not_called in mock, use
assertFalse(mock.called) instead of that.

Change-Id: I1b37c49e0a624de42d89890b44458ec6bd4239ee
",git fetch https://review.opendev.org/openstack/cinder refs/changes/22/112222/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_glusterfs.py'],1,324b981b78ae1d1dfef31b910b272e11ee166cbf,mock_no_method, self.assertFalse(mock_logger.debug.called) self.assertFalse(mock_logger.info.called) self.assertFalse(mock_delete_if_exists.called) self.assertFalse(mock_write_info_file.called), mock_logger.debug.assert_not_called() mock_logger.info.assert_not_called() mock_delete_if_exists.assert_not_called() mock_write_info_file.assert_not_called(),4,4
openstack%2Fcinder~master~I527780765371dcc9645a721d60ed9ac67ddde29f,openstack/cinder,master,I527780765371dcc9645a721d60ed9ac67ddde29f,Issue one SQL statement per execute() call,MERGED,2014-08-13 02:01:05.000000000,2014-08-16 02:47:50.000000000,2014-08-13 17:34:00.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2759}, {'_account_id': 9533}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12492}]","[{'number': 1, 'created': '2014-08-13 02:01:05.000000000', 'files': ['cinder/db/sqlalchemy/migrate_repo/versions/001_cinder_init.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fec9efbdf8eca107a23a32109e37b4039c8beebc', 'message': ""Issue one SQL statement per execute() call\n\nSome sqlalchemy drivers don't support multiple SQL statements in a\nsingle execute() call.  The sqlalchemy author has confirmed that one\nstatement per execute() is the intended API.\n\nChange-Id: I527780765371dcc9645a721d60ed9ac67ddde29f\n""}]",0,113747,fec9efbdf8eca107a23a32109e37b4039c8beebc,16,10,1,11279,,,0,"Issue one SQL statement per execute() call

Some sqlalchemy drivers don't support multiple SQL statements in a
single execute() call.  The sqlalchemy author has confirmed that one
statement per execute() is the intended API.

Change-Id: I527780765371dcc9645a721d60ed9ac67ddde29f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/47/113747/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/db/sqlalchemy/migrate_repo/versions/001_cinder_init.py'],1,fec9efbdf8eca107a23a32109e37b4039c8beebc,separate-sql," migrate_engine.execute(""SET foreign_key_checks = 0"") for table in tables: migrate_engine.execute( ""ALTER TABLE %s CONVERT TO CHARACTER SET utf8"" % table) migrate_engine.execute(""SET foreign_key_checks = 1"") migrate_engine.execute( ""ALTER DATABASE %s DEFAULT CHARACTER SET utf8"" % migrate_engine.url.database) migrate_engine.execute(""ALTER TABLE %s Engine=InnoDB"" % table)"," sql = ""SET foreign_key_checks = 0;"" for table in tables: sql += ""ALTER TABLE %s CONVERT TO CHARACTER SET utf8;"" % table sql += ""SET foreign_key_checks = 1;"" sql += ""ALTER DATABASE %s DEFAULT CHARACTER SET utf8;"" \ % migrate_engine.url.database sql += ""ALTER TABLE %s Engine=InnoDB;"" % table migrate_engine.execute(sql)",8,7
openstack%2Fnova~master~I21afa9b0b3465ef24246a5c20bc7ebfcd2f6b780,openstack/nova,master,I21afa9b0b3465ef24246a5c20bc7ebfcd2f6b780,Updated from global requirements,MERGED,2014-08-13 23:22:30.000000000,2014-08-16 02:26:10.000000000,2014-08-16 01:14:23.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1247}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-08-13 23:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32d5db2c58d12fdecb3a79d550272728afdeb767', 'message': 'Updated from global requirements\n\nChange-Id: I21afa9b0b3465ef24246a5c20bc7ebfcd2f6b780\n'}, {'number': 2, 'created': '2014-08-14 12:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7cf60a5ef0562d63ac2dfb6716c5b47dfaf06e1b', 'message': 'Updated from global requirements\n\nChange-Id: I21afa9b0b3465ef24246a5c20bc7ebfcd2f6b780\n'}, {'number': 3, 'created': '2014-08-14 19:20:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/85511ad9a5b101455feffdbd889a6211eb388cc1', 'message': 'Updated from global requirements\n\nChange-Id: I21afa9b0b3465ef24246a5c20bc7ebfcd2f6b780\n'}]",0,114062,85511ad9a5b101455feffdbd889a6211eb388cc1,29,7,3,11131,,,0,"Updated from global requirements

Change-Id: I21afa9b0b3465ef24246a5c20bc7ebfcd2f6b780
",git fetch https://review.opendev.org/openstack/nova refs/changes/62/114062/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,32d5db2c58d12fdecb3a79d550272728afdeb767,openstack/requirements,"websockify>=0.5.1,<0.7","websockify>=0.5.1,<0.6",1,1
openstack%2Fnova~master~Ibd516b41cc40afafe2dc37cdc5657d494c33c2cf,openstack/nova,master,Ibd516b41cc40afafe2dc37cdc5657d494c33c2cf,Log cleanups for nova.network.neutron.api,MERGED,2014-06-16 13:59:58.000000000,2014-08-16 02:23:40.000000000,2014-08-14 10:28:14.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 7641}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-16 13:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e4d9b22af1659dd74eceffc99407e6f11156eae', 'message': 'Log cleanups for nova.network.neutron.api\n\nThis patch adds hints for error and warning levels.\n\nChange-Id: Ibd516b41cc40afafe2dc37cdc5657d494c33c2cf\n'}, {'number': 2, 'created': '2014-07-20 05:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1891103b01e74e81eab262fd77b00a1e63b26344', 'message': 'Log cleanups for nova.network.neutron.api\n\nThis patch adds hints for error and warning levels.\n\nTrivialFix\n\nChange-Id: Ibd516b41cc40afafe2dc37cdc5657d494c33c2cf\n'}, {'number': 3, 'created': '2014-07-20 07:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/36ee979c94e7e8cf979d496f8fc594a20fe8c4c0', 'message': 'Log cleanups for nova.network.neutron.api\n\nThis patch adds hints for error and warning levels.\n\nTrivialFix\n\nChange-Id: Ibd516b41cc40afafe2dc37cdc5657d494c33c2cf\n'}, {'number': 4, 'created': '2014-07-22 17:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e53abf49b9a4dfa98e296f9defcf00c349c21a1', 'message': 'Log cleanups for nova.network.neutron.api\n\nThis patch adds hints for error and warning levels.\n\nTrivialFix\n\nChange-Id: Ibd516b41cc40afafe2dc37cdc5657d494c33c2cf\n'}, {'number': 5, 'created': '2014-07-27 20:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/534a44a81f5488865ac807a26b4a3eead18a50e7', 'message': 'Log cleanups for nova.network.neutron.api\n\nThis patch adds hints for error and warning levels.\n\nTrivialFix\n\nChange-Id: Ibd516b41cc40afafe2dc37cdc5657d494c33c2cf\n'}, {'number': 6, 'created': '2014-08-03 11:42:16.000000000', 'files': ['nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2a5e4645a900e4a688ff21234af8d6c34839de2e', 'message': 'Log cleanups for nova.network.neutron.api\n\nThis patch adds hints for log error and warning levels.\n\nTrivialFix\n\nChange-Id: Ibd516b41cc40afafe2dc37cdc5657d494c33c2cf\n'}]",5,100258,2a5e4645a900e4a688ff21234af8d6c34839de2e,108,18,6,1653,,,0,"Log cleanups for nova.network.neutron.api

This patch adds hints for log error and warning levels.

TrivialFix

Change-Id: Ibd516b41cc40afafe2dc37cdc5657d494c33c2cf
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/100258/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/neutronv2/api.py'],1,0e4d9b22af1659dd74eceffc99407e6f11156eae,network-log-messages,"from nova.openstack.common.gettextutils import _LE from nova.openstack.common.gettextutils import _LW LOG.warning(_LW('Neutron error: quota exceeded')) LOG.exception(_LE('Neutron error creating port on network %s'), LOG.warn(_LW(""No network configured!""), instance=instance) msg = _LE(""Failed to update port %s"") msg = _LE(""Failed to delete port %s"") LOG.exception(_LE(""Failed to delete neutron port %s""), LOG.exception(_LE(""Failed to delete neutron port %s""), LOG.exception(_LE(""Failed to access port %s""), LOG.exception(_LE('Unable to access floating IP %s'), id) LOG.exception(_LE('Unable to access floating IP %(fixed_ip)s ' 'for port %(port_id)s'), msg = _LE(""Unable to update host of port %s"") LOG.warning(_LW(""Network %(id)s not matched with the tenants "" ""network! The ports tenant %(tenant_id)s will be "" ""used.""),"," LOG.warning(_('Neutron error: quota exceeded')) LOG.exception(_('Neutron error creating port on network %s'), LOG.warn(_(""No network configured!""), instance=instance) msg = _(""Failed to update port %s"") msg = _(""Failed to delete port %s"") LOG.exception(_(""Failed to delete neutron port %s""), LOG.exception(_(""Failed to delete neutron port %s"") % LOG.exception(_(""Failed to access port %s""), LOG.exception(_('Unable to access floating IP %s'), id) LOG.exception(_('Unable to access floating IP %(fixed_ip)s ' 'for port %(port_id)s'), msg = _(""Unable to update host of port %s"") LOG.warning(_(""Network %(id)s not matched with the tenants "" ""network! The ports tenant %(tenant_id)s will be "" ""used.""),",17,15
openstack%2Fpython-heatclient~master~Ic63518d9cb36632b737fbb5700b4b41e77bdcb3e,openstack/python-heatclient,master,Ic63518d9cb36632b737fbb5700b4b41e77bdcb3e,Support to listing nested resources,ABANDONED,2014-07-29 08:57:32.000000000,2014-08-16 02:19:35.000000000,,"[{'_account_id': 3}, {'_account_id': 7256}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 9126}, {'_account_id': 9189}, {'_account_id': 11034}]","[{'number': 1, 'created': '2014-07-29 08:57:32.000000000', 'files': ['heatclient/tests/test_shell.py', 'heatclient/tests/test_resources.py', 'heatclient/v1/resources.py', 'heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/c941a69c161cffa9f8831bef39a09f0c42723ad3', 'message': ""Support to listing nested resources\n\nThis patch adds support to listing nested resources in a stack.  A user\ncan add '--depth <n>' to the command 'heat resource-list' to list the\nnested resources.  In the list of resources returned, an additional\ncolumn 'parent_resource' is appended so that user can easily find out\nthe containing relationship among resources.\n\nImplements: blueprint explode-nested-resources\nChange-Id: Ic63518d9cb36632b737fbb5700b4b41e77bdcb3e\n""}]",7,110237,c941a69c161cffa9f8831bef39a09f0c42723ad3,16,7,1,8246,,,0,"Support to listing nested resources

This patch adds support to listing nested resources in a stack.  A user
can add '--depth <n>' to the command 'heat resource-list' to list the
nested resources.  In the list of resources returned, an additional
column 'parent_resource' is appended so that user can easily find out
the containing relationship among resources.

Implements: blueprint explode-nested-resources
Change-Id: Ic63518d9cb36632b737fbb5700b4b41e77bdcb3e
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/37/110237/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/test_shell.py', 'heatclient/tests/test_resources.py', 'heatclient/v1/resources.py', 'heatclient/v1/shell.py']",4,c941a69c161cffa9f8831bef39a09f0c42723ad3,bp/explode-nested-resources,"@utils.arg('-D', '--depth', metavar='<DEPTH>', default=0, help='Depth for listing nested resources.') fields = {'stack_id': args.id, 'nested_depth': args.depth} if (args.depth > 0): fields.append('parent_resource') ", fields = {'stack_id': args.id},22,7
openstack%2Fopenstacksdk~master~I9c9e310a47750eb7848f290f9e35a6020c726ddb,openstack/openstacksdk,master,I9c9e310a47750eb7848f290f9e35a6020c726ddb,Add Meter resource to telemetry,MERGED,2014-08-11 21:37:43.000000000,2014-08-16 00:05:13.000000000,2014-08-16 00:05:12.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 12807}]","[{'number': 1, 'created': '2014-08-11 21:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7870970725ecc4ef7d77e52f543f09c6b88d01b5', 'message': 'Add Meter resource to telemetry\n\nCan perform list operations on meters only.\n\nChange-Id: I9c9e310a47750eb7848f290f9e35a6020c726ddb\n'}, {'number': 2, 'created': '2014-08-12 02:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/34777130b143588ca27d46a9531694c1b524f080', 'message': 'Add Meter resource to telemetry\n\nCan perform list operations on meters only.\n\nChange-Id: I9c9e310a47750eb7848f290f9e35a6020c726ddb\n'}, {'number': 3, 'created': '2014-08-14 00:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8417d9e0693e348a32a76446479cea3cc7be5909', 'message': 'Add Meter resource to telemetry\n\nCan perform list operations on meters only.\n\nChange-Id: I9c9e310a47750eb7848f290f9e35a6020c726ddb\n'}, {'number': 4, 'created': '2014-08-14 04:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d2695829fec426d2debaf3d3c35251848a54cfbd', 'message': 'Add Meter resource to telemetry\n\nCan perform list operations on meters only.\n\nChange-Id: I9c9e310a47750eb7848f290f9e35a6020c726ddb\n'}, {'number': 5, 'created': '2014-08-14 22:56:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/169ab00c949002e9605fd75ad1e0999d7d67a35f', 'message': 'Add Meter resource to telemetry\n\nCan perform list operations on meters only.\n\nChange-Id: I9c9e310a47750eb7848f290f9e35a6020c726ddb\n'}, {'number': 6, 'created': '2014-08-15 20:42:24.000000000', 'files': ['openstack/tests/telemetry/v2/test_meter.py', 'openstack/telemetry/v2/meter.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/84d01d307aacfcaca922f3babfef3d94926ad75b', 'message': 'Add Meter resource to telemetry\n\nCan perform list operations on meters only.\n\nChange-Id: I9c9e310a47750eb7848f290f9e35a6020c726ddb\n'}]",5,113376,84d01d307aacfcaca922f3babfef3d94926ad75b,30,4,6,12807,,,0,"Add Meter resource to telemetry

Can perform list operations on meters only.

Change-Id: I9c9e310a47750eb7848f290f9e35a6020c726ddb
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/76/113376/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/telemetry/v2/test_meter.py', 'openstack/telemetry/v2/meter.py']",2,7870970725ecc4ef7d77e52f543f09c6b88d01b5,add-telemetry-meter,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack import resource from openstack.telemetry import telemetry_service class Meter(resource.Resource): resource_key = 'meter' resources_key = 'meters' base_path = '/v2.0/meters' service = telemetry_service.TelemetryService() # Supported Operations allow_list = True # Properties name = resource.prop('name') project_id = resource.prop('project_id') resource_id = resource.prop('resource_id') source = resource.prop('source') type = resource.prop('type') unit = resource.prop('unit') user_id = resource.prop('user_id') ",,86,0
openstack%2Fopenstacksdk~master~I12fa97f1d1870ea6e0d89b24725ec5834de785a4,openstack/openstacksdk,master,I12fa97f1d1870ea6e0d89b24725ec5834de785a4,Publicize resource_id property,MERGED,2014-08-15 20:40:03.000000000,2014-08-16 00:04:10.000000000,2014-08-16 00:04:09.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-15 20:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/83e8486804f24d81d5fb508ed06d923201f935ae', 'message': 'Publicize resouce_id property\n\nThe resource_id property was marked for internal use, this change is to publish it.\nBased on review of meter resource: https://review.openstack.org/#/c/113376/\n\nChange-Id: I12fa97f1d1870ea6e0d89b24725ec5834de785a4\n'}, {'number': 2, 'created': '2014-08-15 20:44:09.000000000', 'files': ['openstack/telemetry/v2/resource.py', 'openstack/tests/telemetry/v2/test_resource.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b47a340e6b9a78f5a95153b930ea1bb39ab11ae1', 'message': 'Publicize resource_id property\n\nThe resource_id property was marked for internal use, this change is to publish it.\nBased on review of meter resource: https://review.openstack.org/#/c/113376/\n\nChange-Id: I12fa97f1d1870ea6e0d89b24725ec5834de785a4\n'}]",0,114653,b47a340e6b9a78f5a95153b930ea1bb39ab11ae1,10,3,2,12807,,,0,"Publicize resource_id property

The resource_id property was marked for internal use, this change is to publish it.
Based on review of meter resource: https://review.openstack.org/#/c/113376/

Change-Id: I12fa97f1d1870ea6e0d89b24725ec5834de785a4
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/53/114653/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/telemetry/v2/resource.py', 'openstack/tests/telemetry/v2/test_resource.py']",2,83e8486804f24d81d5fb508ed06d923201f935ae,public-resource-id," self.assertEqual(EXAMPLE['resource_id'], sot.resource_id)",,3,2
openstack%2Fneutron~master~I501bf669b2a999a171f9a3ee3e9893d4ead50e3b,openstack/neutron,master,I501bf669b2a999a171f9a3ee3e9893d4ead50e3b,Opencontrail plug-in implementation for core resources,MERGED,2014-05-29 23:20:55.000000000,2014-08-15 23:50:49.000000000,2014-08-15 16:38:44.000000000,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1923}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6316}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8306}, {'_account_id': 8645}, {'_account_id': 8887}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10186}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-05-29 23:20:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb729d007630a6440b90a7de70025fe30a590f72', 'message': 'Opencontrail plug-in implementation for core resources.\n\nAdds Opencontrail plug-in implementation with unit tests.\nThis patch has no dependency on any other blueprints.\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned and the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 2, 'created': '2014-05-31 22:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d890bc3c8052039c7eb0a3f05b4da74a29633c52', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned and the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 3, 'created': '2014-06-03 02:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc69cc7cd434fe16450b7936a26603a4fc07e80c', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned and the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 4, 'created': '2014-06-04 22:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc67db73b709e646ed7ed4d0b7d4c65ebe1cd8f1', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fix for unit test\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned and the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 5, 'created': '2014-06-04 23:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f284c428142706b03585266321afd8db71fe8a28', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fix for unit test\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned and the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 6, 'created': '2014-06-06 18:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4cc79cc3298d5177094ec5c849fbe29a71fbc239', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit test\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned and the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 7, 'created': '2014-06-07 01:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d63179ebd1fda788c1603c3027a6d2bcbdf31091', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit test\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned and the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 8, 'created': '2014-06-07 02:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a27b9d2ddee0dcd06c1627981fd91afa4419f2af', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit test\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned and the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 9, 'created': '2014-06-09 03:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/662f8861298b9d9df7eb7df7ee7655b1dcab28d5', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit test\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned and the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 10, 'created': '2014-06-10 01:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d34eb6a1af8108de393fe987839ba163aad3ea7', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit test\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned and the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 11, 'created': '2014-06-10 01:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/750d54f478261e7c06382b54c24047ea15369b8a', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit test\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 12, 'created': '2014-06-10 01:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3604790c0c023ba5514fdecbf01b1e6c0002d719', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit testing\n- Adding logs in browser readable form\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 13, 'created': '2014-06-10 01:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/af6aa4c2f1ac04f1cd92359c2c105b3f61e52406', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit testing\n- Adding logs in web browser in readable format\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 14, 'created': '2014-06-11 05:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cb8c47bfc95d4a4dacc95953f154081da56efff0', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit testing\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 15, 'created': '2014-06-13 03:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4370df71eb1ea14ffde1c792758ee877f6170c24', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit testing\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 16, 'created': '2014-06-13 21:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/61befa308c7381fb2b1ddd4c26e72eee8d51ea97', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit testing\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 17, 'created': '2014-06-13 22:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/97c87ab87e510200ff05835dfbfc77cac6744588', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit testing\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 18, 'created': '2014-06-15 21:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e02d4dcab46e0a2cf7e9b0164c228e132bbf72f', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit testing\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 19, 'created': '2014-06-16 21:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/61a0e2b31f46f6fd8143d60709d4af8fa69b9128', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit testing\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 20, 'created': '2014-06-16 23:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/31e6a6f0fe8260d4222c2b3603df65cafdd90190', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit testing\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 21, 'created': '2014-06-18 22:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc71a70dd7e654515693b00e8f42e92105484381', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes minor fixes for unit testing\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 22, 'created': '2014-06-18 23:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/38b1b3a47aeebeec89d449e19b396468de06f992', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes a minor fix for unit testing\n  in test_db_plugin.py line 2420 where there was a missing return.\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 23, 'created': '2014-06-30 09:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99ceb396414af928533fab57f0e0b8986bb824f3', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes a minor fix for unit testing\n  in test_db_plugin.py line 2420 where there was a missing return.\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 24, 'created': '2014-07-14 21:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20ce62b39e76876fa48b914737f2cca11e189ff5', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n- This commit also includes a minor fix for unit testing\n  in test_db_plugin.py line 2420 where there was a missing return.\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 25, 'created': '2014-07-25 23:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2527eed628f06b28adb5607a5d3b0eaf434bf0aa', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\nThe link below describes how to install VIF driver for opencontrail\nhttps://github.com/Juniper/contrail-controller/wiki/\nOpenContrail-bring-up-and-provisioning\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 26, 'created': '2014-07-28 18:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c397ee6e94d93c065fec8a9105b59f5b1e550d35', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\nThe link below describes how to install VIF driver for opencontrail\nhttps://github.com/Juniper/contrail-controller/wiki/\nOpenContrail-bring-up-and-provisioning\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nNote: The previous review https://review.openstack.org/#/c/43793/\n      has been abandoned as the owner is on a long leave\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 27, 'created': '2014-07-30 23:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ddbccad6f56df6e6214fbaef156f022e7204053', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\nThe link below describes how to install VIF driver for opencontrail\nhttps://github.com/Juniper/contrail-controller/wiki/\nOpenContrail-bring-up-and-provisioning\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 28, 'created': '2014-08-04 07:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f495e7d4bd0d2e3c68b57adc2b5daae2ee2c2b0c', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\nThe link below describes how to install VIF driver for opencontrail\nhttps://github.com/Juniper/contrail-controller/wiki/\nOpenContrail-bring-up-and-provisioning\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 29, 'created': '2014-08-04 22:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cfb51fb89b87cfb1890f2d7b3c12efb9512d93e1', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\nThe link below describes how to install VIF driver for opencontrail\nhttps://github.com/Juniper/contrail-controller/wiki/\nOpenContrail-bring-up-and-provisioning\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 30, 'created': '2014-08-12 05:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8530e9afc3bc029fff37c335f2e2a984c30daf8c', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\nThe link below describes how to install VIF driver for opencontrail\nhttps://github.com/Juniper/contrail-controller/wiki/\nOpenContrail-bring-up-and-provisioning\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 31, 'created': '2014-08-12 07:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/907c807d4ee2c8cdfab95c5364ba13c7b4447520', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\nThe link below describes how to install VIF driver for opencontrail\nhttps://github.com/Juniper/contrail-controller/wiki/\nOpenContrail-bring-up-and-provisioning\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 32, 'created': '2014-08-12 18:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b04df955890145998604ab7e1d7759e7bb57449b', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\nThe link below describes how to install VIF driver for opencontrail\nhttps://github.com/Juniper/contrail-controller/wiki/\nOpenContrail-bring-up-and-provisioning\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 33, 'created': '2014-08-14 23:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eab8ad2c88473c5c35de82ea28d53bff54e4f6c8', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\nThe link below describes how to install VIF driver for opencontrail\nhttps://github.com/Juniper/contrail-controller/wiki/\nOpenContrail-bring-up-and-provisioning\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nDocImpact\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}, {'number': 34, 'created': '2014-08-15 01:34:48.000000000', 'files': ['etc/neutron/plugins/opencontrail/contrailplugin.ini', 'neutron/plugins/opencontrail/common/__init__.py', 'neutron/extensions/portbindings.py', 'neutron/tests/unit/opencontrail/__init__.py', 'neutron/plugins/opencontrail/common/exceptions.py', 'neutron/plugins/opencontrail/contrail_plugin.py', 'setup.cfg', 'neutron/tests/unit/opencontrail/test_contrail_plugin.py', 'neutron/plugins/opencontrail/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a1561f8eb883e9200248c9c41d3bcc992edac8c', 'message': 'Opencontrail plug-in implementation for core resources\n\nAdds Opencontrail plug-in implementation with unit tests\nThis patch has no dependency on any other blueprints\nThe link below describes how to install VIF driver for opencontrail\nhttps://github.com/Juniper/contrail-controller/wiki/\nOpenContrail-bring-up-and-provisioning\n\n- The contrail_plugin_core.py is the main interface for neutron common\n  infrastructure. It relays API requests to the opencontrail controller\n\nDocImpact\nChange-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b\nImplements: blueprint juniper-plugin-with-extensions\n'}]",347,96630,1a1561f8eb883e9200248c9c41d3bcc992edac8c,667,40,34,8887,,,0,"Opencontrail plug-in implementation for core resources

Adds Opencontrail plug-in implementation with unit tests
This patch has no dependency on any other blueprints
The link below describes how to install VIF driver for opencontrail
https://github.com/Juniper/contrail-controller/wiki/
OpenContrail-bring-up-and-provisioning

- The contrail_plugin_core.py is the main interface for neutron common
  infrastructure. It relays API requests to the opencontrail controller

DocImpact
Change-Id: I501bf669b2a999a171f9a3ee3e9893d4ead50e3b
Implements: blueprint juniper-plugin-with-extensions
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/96630/34 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron/plugins/opencontrail/contrailplugin.ini', 'neutron/extensions/portbindings.py', 'neutron/plugins/opencontrail/contrail_plugin_core.py', 'neutron/tests/unit/opencontrail/__init__.py', 'setup.cfg', 'neutron/tests/unit/opencontrail/test_contrail_plugin.py', 'neutron/plugins/opencontrail/__init__.py']",7,fb729d007630a6440b90a7de70025fe30a590f72,bp/s,,,2160,1
openstack%2Fnova~master~I1c114df8e4ab2fccd966ed4af22181881590c443,openstack/nova,master,I1c114df8e4ab2fccd966ed4af22181881590c443,Removes GlanceClient stubs,MERGED,2014-08-09 22:47:07.000000000,2014-08-15 23:48:45.000000000,2014-08-15 23:48:43.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-09 22:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a552b933f1c06b105328638e3795fcee89fdc563', 'message': 'Removes GlanceClient stubs\n\nRefactors the tests in nova.tests.image.test_glance that were checking\nthe bahviour of both the GlanceClientWrapper retry logic and the\nglanceclient.Client creation to use mock instead of the FakeGlanceClient\nin nova.tests.glance.stubs. The fake stub client was actually masking\nissues in the existing test cases, including not properly checking the\nidentity headers that are actually supplied to the real\nglaceclient.Client constructor.\n\nChange-Id: I1c114df8e4ab2fccd966ed4af22181881590c443\nPartial-bug: #1293938\n'}, {'number': 2, 'created': '2014-08-12 18:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f713ec8d53c2658a0c9d633c2a2c2a2fd9f26a6', 'message': 'Removes GlanceClient stubs\n\nRefactors the tests in nova.tests.image.test_glance that were checking\nthe behaviour of both the GlanceClientWrapper retry logic and the\nglanceclient.Client creation to use mock instead of the FakeGlanceClient\nin nova.tests.glance.stubs. The fake stub client was actually masking\nissues in the existing test cases, including not properly checking the\nidentity headers that are actually supplied to the real\nglanceclient.Client constructor.\n\nChange-Id: I1c114df8e4ab2fccd966ed4af22181881590c443\nPartial-bug: #1293938\n'}, {'number': 3, 'created': '2014-08-13 02:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cf1f563574f8d394ec8de51b28dbbf17e0d5304', 'message': 'Removes GlanceClient stubs\n\nRefactors the tests in nova.tests.image.test_glance that were checking\nthe behaviour of both the GlanceClientWrapper retry logic and the\nglanceclient.Client creation to use mock instead of the FakeGlanceClient\nin nova.tests.glance.stubs. The fake stub client was actually masking\nissues in the existing test cases, including not properly checking the\nidentity headers that are actually supplied to the real\nglanceclient.Client constructor.\n\nChange-Id: I1c114df8e4ab2fccd966ed4af22181881590c443\nPartial-bug: #1293938\n'}, {'number': 4, 'created': '2014-08-15 16:20:43.000000000', 'files': ['nova/tests/glance/stubs.py', 'nova/tests/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/486623c0ca6d71ace5e6b0cd234be05f10f13dc4', 'message': 'Removes GlanceClient stubs\n\nRefactors the tests in nova.tests.image.test_glance that were checking\nthe behaviour of both the GlanceClientWrapper retry logic and the\nglanceclient.Client creation to use mock instead of the FakeGlanceClient\nin nova.tests.glance.stubs. The fake stub client was actually masking\nissues in the existing test cases, including not properly checking the\nidentity headers that are actually supplied to the real\nglanceclient.Client constructor.\n\nChange-Id: I1c114df8e4ab2fccd966ed4af22181881590c443\nPartial-bug: #1293938\n'}]",2,113098,486623c0ca6d71ace5e6b0cd234be05f10f13dc4,45,10,4,7,,,0,"Removes GlanceClient stubs

Refactors the tests in nova.tests.image.test_glance that were checking
the behaviour of both the GlanceClientWrapper retry logic and the
glanceclient.Client creation to use mock instead of the FakeGlanceClient
in nova.tests.glance.stubs. The fake stub client was actually masking
issues in the existing test cases, including not properly checking the
identity headers that are actually supplied to the real
glanceclient.Client constructor.

Change-Id: I1c114df8e4ab2fccd966ed4af22181881590c443
Partial-bug: #1293938
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/113098/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/glance/stubs.py', 'nova/tests/image/test_glance.py']",2,a552b933f1c06b105328638e3795fcee89fdc563,bug/1293938,"class TestCreateGlanceClient(test.NoDBTestCase): @mock.patch('nova.utils.is_valid_ipv6') @mock.patch('glanceclient.Client') def test_headers_passed_glanceclient(self, init_mock, ipv6_mock): self.flags(auth_strategy='keystone') ipv6_mock.return_value = False auth_token = 'token' ctx = context.RequestContext('fake', 'fake', auth_token=auth_token) host = 'host4' port = 9295 use_ssl = False expected_endpoint = 'http://host4:9295' expected_params = { 'identity_headers': { 'X-Auth-Token': 'token', 'X-User-Id': 'fake', 'X-Roles': '', 'X-Tenant-Id': 'fake', 'X-Service-Catalog': '[]', 'X-Identity-Status': 'Confirmed' }, 'token': 'token' } glance._create_glance_client(ctx, host, port, use_ssl) init_mock.assert_called_once_with('1', expected_endpoint, **expected_params) # Test the version is properly passed to glanceclient. ipv6_mock.reset_mock() init_mock.reset_mock() expected_endpoint = 'http://host4:9295' expected_params = { 'identity_headers': { 'X-Auth-Token': 'token', 'X-User-Id': 'fake', 'X-Roles': '', 'X-Tenant-Id': 'fake', 'X-Service-Catalog': '[]', 'X-Identity-Status': 'Confirmed' }, 'token': 'token' } glance._create_glance_client(ctx, host, port, use_ssl, version=2) init_mock.assert_called_once_with('2', expected_endpoint, **expected_params) # Test that non-keystone auth strategy doesn't bother to pass # glanceclient all the Keystone-related headers. ipv6_mock.reset_mock() init_mock.reset_mock() self.flags(auth_strategy='non-keystone') expected_endpoint = 'http://host4:9295' expected_params = { } glance._create_glance_client(ctx, host, port, use_ssl) init_mock.assert_called_once_with('1', expected_endpoint, **expected_params) # Test that the IPv6 bracketization adapts the endpoint properly. ipv6_mock.reset_mock() init_mock.reset_mock() ipv6_mock.return_value = True expected_endpoint = 'http://[host4]:9295' expected_params = { } glance._create_glance_client(ctx, host, port, use_ssl) init_mock.assert_called_once_with('1', expected_endpoint, **expected_params) class TestGlanceClientWrapper(test.NoDBTestCase): @mock.patch('time.sleep') @mock.patch('nova.image.glance._create_glance_client') def test_static_client_without_retries(self, create_client_mock, sleep_mock): client_mock = mock.MagicMock() images_mock = mock.MagicMock() images_mock.get.side_effect = glanceclient.exc.ServiceUnavailable type(client_mock).images = mock.PropertyMock(return_value=images_mock) create_client_mock.return_value = client_mock self.flags(num_retries=0, group='glance') ctx = context.RequestContext('fake', 'fake') host = 'host4' port = 9295 use_ssl = False client = glance.GlanceClientWrapper(context=ctx, host=host, port=port, use_ssl=use_ssl) create_client_mock.assert_called_once_with(ctx, host, port, use_ssl, 1) self.assertRaises(exception.GlanceConnectionFailed, client.call, ctx, 1, 'get', 'meow') self.assertFalse(sleep_mock.called) @mock.patch('time.sleep') @mock.patch('nova.image.glance._create_glance_client') def test_static_client_with_retries(self, create_client_mock, sleep_mock): self.flags(num_retries=1, group='glance') client_mock = mock.MagicMock() images_mock = mock.MagicMock() images_mock.get.side_effect = [ glanceclient.exc.ServiceUnavailable, None ] type(client_mock).images = mock.PropertyMock(return_value=images_mock) create_client_mock.return_value = client_mock ctx = context.RequestContext('fake', 'fake') host = 'host4' port = 9295 use_ssl = False client = glance.GlanceClientWrapper(context=ctx, host=host, port=port, use_ssl=use_ssl) client.call(ctx, 1, 'get', 'meow') sleep_mock.assert_called_once_with(1) @mock.patch('random.shuffle') @mock.patch('time.sleep') @mock.patch('nova.image.glance._create_glance_client') def test_default_client_without_retries(self, create_client_mock, sleep_mock, shuffle_mock): api_servers = [ 'host1:9292', 'https://host2:9293', 'http://host3:9294' ] client_mock = mock.MagicMock() images_mock = mock.MagicMock() images_mock.get.side_effect = glanceclient.exc.ServiceUnavailable type(client_mock).images = mock.PropertyMock(return_value=images_mock) create_client_mock.return_value = client_mock shuffle_mock.return_value = api_servers self.flags(num_retries=0, group='glance') self.flags(api_servers=api_servers, group='glance') # Here we are testing the behaviour that calling client.call() twice # when there are no retries will cycle through the api_servers and not # sleep (which would be an indication of a retry) ctx = context.RequestContext('fake', 'fake') client = glance.GlanceClientWrapper() self.assertRaises(exception.GlanceConnectionFailed, client.call, ctx, 1, 'get', 'meow') self.assertFalse(sleep_mock.called) self.assertRaises(exception.GlanceConnectionFailed, client.call, ctx, 1, 'get', 'meow') self.assertFalse(sleep_mock.called) create_client_mock.assert_has_calls( [ mock.call(ctx, 'host1', 9292, False, 1), mock.call(ctx, 'host2', 9293, True, 1), ] ) @mock.patch('random.shuffle') @mock.patch('time.sleep') @mock.patch('nova.image.glance._create_glance_client') def test_default_client_with_retries(self, create_client_mock, sleep_mock, shuffle_mock): api_servers = [ 'host1:9292', 'https://host2:9293', 'http://host3:9294' ] client_mock = mock.MagicMock() images_mock = mock.MagicMock() images_mock.get.side_effect = [ glanceclient.exc.ServiceUnavailable, None ] type(client_mock).images = mock.PropertyMock(return_value=images_mock) create_client_mock.return_value = client_mock self.flags(num_retries=1, group='glance') self.flags(api_servers=api_servers, group='glance') ctx = context.RequestContext('fake', 'fake') # And here we're testing that if num_retries is not 0, then we attempt # to retry the same connection action against the next client. client = glance.GlanceClientWrapper() client.call(ctx, 1, 'get', 'meow') create_client_mock.assert_has_calls( [ mock.call(ctx, 'host1', 9292, False, 1), mock.call(ctx, 'host2', 9293, True, 1), ] ) sleep_mock.assert_called_once_with(1) ","import randomimport timedef _create_failing_glance_client(info): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that fails the first time, then succeeds."""""" def get(self, image_id): info['num_calls'] += 1 if info['num_calls'] == 1: raise glanceclient.exc.ServiceUnavailable('') return {} return MyGlanceStubClient() class TestGlanceClientWrapper(test.NoDBTestCase): def setUp(self): super(TestGlanceClientWrapper, self).setUp() # host1 has no scheme, which is http by default self.flags(api_servers=['host1:9292', 'https://host2:9293', 'http://host3:9294'], group='glance') # Make the test run fast def _fake_sleep(secs): pass self.stubs.Set(time, 'sleep', _fake_sleep) def test_headers_passed_glanceclient(self): auth_token = 'auth_token' ctxt = context.RequestContext('fake', 'fake', auth_token=auth_token) fake_host = 'host4' fake_port = 9295 fake_use_ssl = False def _get_fake_glanceclient(version, endpoint, **params): fake_client = glance_stubs.StubGlanceClient(version, endpoint, **params) self.assertIsNotNone(fake_client.auth_token) self.assertIsNotNone(fake_client.identity_headers) self.assertEqual(fake_client.identity_header['X-Auth_Token'], auth_token) self.assertEqual(fake_client.identity_header['X-User-Id'], 'fake') self.assertIsNone(fake_client.identity_header['X-Roles']) self.assertIsNone(fake_client.identity_header['X-Tenant-Id']) self.assertIsNone(fake_client.identity_header['X-Service-Catalog']) self.assertEqual(fake_client. identity_header['X-Identity-Status'], 'Confirmed') self.stubs.Set(glanceclient.Client, '__init__', _get_fake_glanceclient) glance._create_glance_client(ctxt, fake_host, fake_port, fake_use_ssl) def test_static_client_without_retries(self): self.flags(num_retries=0, group='glance') ctxt = context.RequestContext('fake', 'fake') fake_host = 'host4' fake_port = 9295 fake_use_ssl = False info = {'num_calls': 0} def _fake_create_glance_client(context, host, port, use_ssl, version): self.assertEqual(host, fake_host) self.assertEqual(port, fake_port) self.assertEqual(use_ssl, fake_use_ssl) return _create_failing_glance_client(info) self.stubs.Set(glance, '_create_glance_client', _fake_create_glance_client) client = glance.GlanceClientWrapper(context=ctxt, host=fake_host, port=fake_port, use_ssl=fake_use_ssl) self.assertRaises(exception.GlanceConnectionFailed, client.call, ctxt, 1, 'get', 'meow') self.assertEqual(info['num_calls'], 1) def test_default_client_without_retries(self): self.flags(num_retries=0, group='glance') ctxt = context.RequestContext('fake', 'fake') info = {'num_calls': 0, 'host': 'host1', 'port': 9292, 'use_ssl': False} # Leave the list in a known-order def _fake_shuffle(servers): pass def _fake_create_glance_client(context, host, port, use_ssl, version): self.assertEqual(host, info['host']) self.assertEqual(port, info['port']) self.assertEqual(use_ssl, info['use_ssl']) return _create_failing_glance_client(info) self.stubs.Set(random, 'shuffle', _fake_shuffle) self.stubs.Set(glance, '_create_glance_client', _fake_create_glance_client) client = glance.GlanceClientWrapper() client2 = glance.GlanceClientWrapper() self.assertRaises(exception.GlanceConnectionFailed, client.call, ctxt, 1, 'get', 'meow') self.assertEqual(info['num_calls'], 1) info = {'num_calls': 0, 'host': 'host2', 'port': 9293, 'use_ssl': True} def _fake_shuffle2(servers): # fake shuffle in a known manner servers.append(servers.pop(0)) self.stubs.Set(random, 'shuffle', _fake_shuffle2) self.assertRaises(exception.GlanceConnectionFailed, client2.call, ctxt, 1, 'get', 'meow') self.assertEqual(info['num_calls'], 1) def test_static_client_with_retries(self): self.flags(num_retries=1, group='glance') ctxt = context.RequestContext('fake', 'fake') fake_host = 'host4' fake_port = 9295 fake_use_ssl = False info = {'num_calls': 0} def _fake_create_glance_client(context, host, port, use_ssl, version): self.assertEqual(host, fake_host) self.assertEqual(port, fake_port) self.assertEqual(use_ssl, fake_use_ssl) return _create_failing_glance_client(info) self.stubs.Set(glance, '_create_glance_client', _fake_create_glance_client) client = glance.GlanceClientWrapper(context=ctxt, host=fake_host, port=fake_port, use_ssl=fake_use_ssl) client.call(ctxt, 1, 'get', 'meow') self.assertEqual(info['num_calls'], 2) def test_default_client_with_retries(self): self.flags(num_retries=1, group='glance') ctxt = context.RequestContext('fake', 'fake') info = {'num_calls': 0, 'host0': 'host1', 'port0': 9292, 'use_ssl0': False, 'host1': 'host2', 'port1': 9293, 'use_ssl1': True} # Leave the list in a known-order def _fake_shuffle(servers): pass def _fake_create_glance_client(context, host, port, use_ssl, version): attempt = info['num_calls'] self.assertEqual(host, info['host%s' % attempt]) self.assertEqual(port, info['port%s' % attempt]) self.assertEqual(use_ssl, info['use_ssl%s' % attempt]) return _create_failing_glance_client(info) self.stubs.Set(random, 'shuffle', _fake_shuffle) self.stubs.Set(glance, '_create_glance_client', _fake_create_glance_client) client = glance.GlanceClientWrapper() client2 = glance.GlanceClientWrapper() client.call(ctxt, 1, 'get', 'meow') self.assertEqual(info['num_calls'], 2) def _fake_shuffle2(servers): # fake shuffle in a known manner servers.append(servers.pop(0)) self.stubs.Set(random, 'shuffle', _fake_shuffle2) info = {'num_calls': 0, 'host0': 'host2', 'port0': 9293, 'use_ssl0': True, 'host1': 'host3', 'port1': 9294, 'use_ssl1': False} client2.call(ctxt, 1, 'get', 'meow') self.assertEqual(info['num_calls'], 2) ",204,290
openstack%2Fcongress~master~Ib06843d9d17be83bc7cde88e57453a4e8dd78b70,openstack/congress,master,Ib06843d9d17be83bc7cde88e57453a4e8dd78b70,Path bug fixes for harness,MERGED,2014-08-15 23:29:32.000000000,2014-08-15 23:46:32.000000000,2014-08-15 23:46:31.000000000,"[{'_account_id': 3}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-08-15 23:29:32.000000000', 'files': ['congress/common/config.py', 'congress/tests/test_congress.py', 'etc/datasources.conf.sample', 'congress/service.py', 'congress/harness.py', 'congress/tests/helper.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/e701b9d3820531061896e0c1c8d3aea6facd2eda', 'message': ""Path bug fixes for harness\n\nThere was some inconsistency between different components'\nsemantics for one of the path config variables.  One thought\nit was pointing to congress/congress and the other thought\nit was pointing to congress.\n\nThis change eliminates that inconsistency.\n\nChange-Id: Ib06843d9d17be83bc7cde88e57453a4e8dd78b70\n""}]",0,114696,e701b9d3820531061896e0c1c8d3aea6facd2eda,7,2,1,8215,,,0,"Path bug fixes for harness

There was some inconsistency between different components'
semantics for one of the path config variables.  One thought
it was pointing to congress/congress and the other thought
it was pointing to congress.

This change eliminates that inconsistency.

Change-Id: Ib06843d9d17be83bc7cde88e57453a4e8dd78b70
",git fetch https://review.opendev.org/openstack/congress refs/changes/96/114696/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/common/config.py', 'congress/tests/test_congress.py', 'etc/datasources.conf.sample', 'congress/harness.py', 'congress/service.py', 'congress/tests/helper.py']",6,e701b9d3820531061896e0c1c8d3aea6facd2eda,,"def root_path(): """"""Return path to root of source code."""""" x = os.path.realpath(__file__) x, y = os.path.split(x) # drop ""helper.py"" x, y = os.path.split(x) # drop ""tests"" x, y = os.path.split(x) # drop ""congress"" return x ",,38,16
openstack%2Ffuel-docs~stable%2F5.0~I0408c27f75c76df10480c210c92921e014f1de75,openstack/fuel-docs,stable/5.0,I0408c27f75c76df10480c210c92921e014f1de75,remove cross-document refs from relnotes,MERGED,2014-08-15 22:45:48.000000000,2014-08-15 23:32:33.000000000,2014-08-15 23:32:33.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-15 22:45:48.000000000', 'files': ['pages/release-notes/v5-0/040-resolved-issues.rst', 'pages/release-notes/v5-0/039-resolved-issues-501.rst', 'pages/release-notes/v5-0/020-new-features.rst', 'pages/release-notes/v5-0/030-other-enhancements.rst', 'pages/release-notes/v5-0/050-known-issues.rst', 'pages/release-notes/v5-0/019-new-features-501.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/82dd726dae5db1b7d1799c6eba84b280cb9b4ce5', 'message': 'remove cross-document refs from relnotes\n\nChange-Id: I0408c27f75c76df10480c210c92921e014f1de75\n'}]",0,114685,82dd726dae5db1b7d1799c6eba84b280cb9b4ce5,9,3,1,10014,,,0,"remove cross-document refs from relnotes

Change-Id: I0408c27f75c76df10480c210c92921e014f1de75
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/85/114685/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v5-0/039-resolved-issues-501.rst', 'pages/release-notes/v5-0/040-resolved-issues.rst', 'pages/release-notes/v5-0/020-new-features.rst', 'pages/release-notes/v5-0/030-other-enhancements.rst', 'pages/release-notes/v5-0/050-known-issues.rst', 'pages/release-notes/v5-0/019-new-features-501.rst']",6,82dd726dae5db1b7d1799c6eba84b280cb9b4ce5,relnotesrefs,"See `Upgrade from an Earlier Version <http://docs.mirantis.com/openstack/fuel/fuel-5.0/user-guide.html#upgrade-from-an-earlier-version>`_ for details and instructions.on the ""Create a new OpenStack environment"" screen.",See :ref:`upgrade-ug` for details and instructions.on the :ref:`name-distro-ug` screen.,27,20
openstack%2Fcongress~master~I4ee2a7db33ae1ae002c4bc5931c94bb2ab19698b,openstack/congress,master,I4ee2a7db33ae1ae002c4bc5931c94bb2ab19698b,Fix parameter ordering to add_item,MERGED,2014-08-15 23:24:11.000000000,2014-08-15 23:31:21.000000000,2014-08-15 23:31:21.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2014-08-15 23:24:11.000000000', 'files': ['congress/api/webservice.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/b422e734de079823202411ced40c9175cd03008d', 'message': 'Fix parameter ordering to add_item\n\nThis bug was introduced by a recent commit.  End-to-end API testing\nshould be in place to catch these problems, but this commit does not\ncontain them in interest of unbreaking HEAD.\n\nChange-Id: I4ee2a7db33ae1ae002c4bc5931c94bb2ab19698b\n'}]",0,114694,b422e734de079823202411ced40c9175cd03008d,7,2,1,9253,,,0,"Fix parameter ordering to add_item

This bug was introduced by a recent commit.  End-to-end API testing
should be in place to catch these problems, but this commit does not
contain them in interest of unbreaking HEAD.

Change-Id: I4ee2a7db33ae1ae002c4bc5931c94bb2ab19698b
",git fetch https://review.opendev.org/openstack/congress refs/changes/94/114694/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/api/webservice.py'],1,b422e734de079823202411ced40c9175cd03008d,," item, request.params, id_, context=self._get_context(request))"," item, id_, request.params, context=self._get_context(request))",1,1
openstack%2Fpython-swiftclient~master~Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f,openstack/python-swiftclient,master,Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f,Add keystone v3 auth support,MERGED,2014-05-02 14:03:02.000000000,2014-08-15 23:24:00.000000000,2014-08-15 23:23:59.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 866}, {'_account_id': 1179}, {'_account_id': 1916}, {'_account_id': 6198}, {'_account_id': 6968}, {'_account_id': 7191}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}, {'_account_id': 9276}, {'_account_id': 9910}]","[{'number': 1, 'created': '2014-05-02 14:03:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/eeef8770709eb0c6a5b08786c1029bba4e17c4b3', 'message': ""Add keystone v3 auth support\n\nEnables swiftclient to authenticate using\nthe keystone v3 API, allowing user id's, user\ndomains and tenant/project domains to be\nspecified.\n\nSince swiftclient imports keystoneclient, the\nmain changes in swiftclient/client.py are to\nselectively import the correct keystoneclient\nlibrary version and pass a number of new\noptions to it via the get_auth() function. In\naddition the get_keystoneclient_2_0 method\nhas been renamed get_auth_keystone to better\nreflect its purpose since it now deals with\nboth v2 and v3 use cases.\n\nIn swiftclient/shell.py the new options are\nadded to the parser. A new set of unit tests\nare added to test_shell.py to verify the\nparser.\n\nNote that to use keystone v3 and a UUID token\nprovider with swift you will need to set\nauth_version = v3.0 in the auth_token\nmiddleware config section of\nproxy-server.conf. With PKI token this\ndoes not appear to be necessary.\n\nChange-Id: Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f\n""}, {'number': 2, 'created': '2014-05-09 16:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/e14bf0bd9abb097f187a2005162fdb6cd17e830d', 'message': ""Add keystone v3 auth support\n\nEnables swiftclient to authenticate using\nthe keystone v3 API, allowing user id's, user\ndomains and tenant/project domains to be\nspecified.\n\nSince swiftclient imports keystoneclient, the\nmain changes in swiftclient/client.py are to\nselectively import the correct keystoneclient\nlibrary version and pass a number of new\noptions to it via the get_auth() function.\n\nIn swiftclient/shell.py the new options are\nadded to the parser. A new set of unit tests\nare added to test_shell.py to verify the\nparser.\n\nNote that to use keystone v3 and a UUID token\nprovider with swift you will need to set\nauth_version = v3.0 in the auth_token\nmiddleware config section of\nproxy-server.conf.\n\nblueprint keystone-v3-support\n\nChange-Id: Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f\n""}, {'number': 3, 'created': '2014-05-20 10:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/7cc62001805ec71787799e5ef16fc6e6e515574a', 'message': ""Add keystone v3 auth support\n\nEnables swiftclient to authenticate using\nthe keystone v3 API, allowing user id's, user\ndomains and tenant/project domains to be\nspecified.\n\nSince swiftclient imports keystoneclient, the\nmain changes in swiftclient/client.py are to\nselectively import the correct keystoneclient\nlibrary version and pass a number of new\noptions to it via the get_auth() function. In\naddition the get_keystoneclient_2_0 method\nhas been renamed get_auth_keystone to better\nreflect its purpose since it now deals with\nboth v2 and v3 use cases.\n\nIn swiftclient/shell.py the new options are\nadded to the parser. To make the default help\nmessage shorter, help for all the --os-*\noptions (including the existing v2 options)\nis only displayed when explicitly requested\nusng a new --os-help option.\n\nA new set of unit tests is added to\ntest_shell.py to verify the parser. A comment\nin tests/sample.conf explains how to\nconfigure the existing functional tests to\nrun using keystone v3 API.\n\nNote that to use keystone v3\nwith swift you will need to set\nauth_version = v3.0 in the auth_token\nmiddleware config section of\nproxy-server.conf.\n\nChange-Id: Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f\n""}, {'number': 4, 'created': '2014-05-21 14:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/b484e67d840e3056a0bff99f1a1c80dec0f73a71', 'message': ""Add keystone v3 auth support\n\nEnables swiftclient to authenticate using\nthe keystone v3 API, allowing user id's, user\ndomains and tenant/project domains to be\nspecified.\n\nSince swiftclient imports keystoneclient, the\nmain changes in swiftclient/client.py are to\nselectively import the correct keystoneclient\nlibrary version and pass a number of new\noptions to it via the get_auth() function. In\naddition the get_keystoneclient_2_0 method\nhas been renamed get_auth_keystone to better\nreflect its purpose since it now deals with\nboth v2 and v3 use cases.\n\nIn swiftclient/shell.py the new options are\nadded to the parser. To make the default help\nmessage shorter, help for all the --os-*\noptions (including the existing v2 options)\nis only displayed when explicitly requested\nusng a new --os-help option.\n\nA new set of unit tests is added to\ntest_shell.py to verify the parser. A comment\nin tests/sample.conf explains how to\nconfigure the existing functional tests to\nrun using keystone v3 API.\n\nNote that to use keystone v3\nwith swift you will need to set\nauth_version = v3.0 in the auth_token\nmiddleware config section of\nproxy-server.conf.\n\nChange-Id: Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f\n""}, {'number': 5, 'created': '2014-06-27 11:09:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/be44eef803d84524704f96bdb84ca6ef8d262b7e', 'message': ""Add keystone v3 auth support\n\nEnables swiftclient to authenticate using\nthe keystone v3 API, allowing user id's, user\ndomains and tenant/project domains to be\nspecified.\n\nSince swiftclient imports keystoneclient, the\nmain changes in swiftclient/client.py are to\nselectively import the correct keystoneclient\nlibrary version and pass a number of new\noptions to it via the get_auth() function. In\naddition the get_keystoneclient_2_0 method\nhas been renamed get_auth_keystone to better\nreflect its purpose since it now deals with\nboth v2 and v3 use cases.\n\nIn swiftclient/shell.py the new options are\nadded to the parser. To make the default help\nmessage shorter, help for all the --os-*\noptions (including the existing v2 options)\nis only displayed when explicitly requested\nusng a new --os-help option.\n\nA new set of unit tests is added to\ntest_shell.py to verify the parser. A comment\nin tests/sample.conf explains how to\nconfigure the existing functional tests to\nrun using keystone v3 API.\n\nNote that to use keystone v3\nwith swift you will need to set\nauth_version = v3.0 in the auth_token\nmiddleware config section of\nproxy-server.conf.\n\nChange-Id: Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f\n""}, {'number': 6, 'created': '2014-06-30 15:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/91b29a0207282a098b80e5802a031298f718543a', 'message': ""Add keystone v3 auth support\n\nEnables swiftclient to authenticate using\nthe keystone v3 API, allowing user id's, user\ndomains and tenant/project domains to be\nspecified.\n\nSince swiftclient imports keystoneclient, the\nmain changes in swiftclient/client.py are to\nselectively import the correct keystoneclient\nlibrary version and pass a number of new\noptions to it via the get_auth() function. In\naddition the get_keystoneclient_2_0 method\nhas been renamed get_auth_keystone to better\nreflect its purpose since it now deals with\nboth v2 and v3 use cases.\n\nIn swiftclient/shell.py the new options are\nadded to the parser. To make the default help\nmessage shorter, help for all the --os-*\noptions (including the existing v2 options)\nis only displayed when explicitly requested\nusng a new --os-help option.\n\nA new set of unit tests is added to\ntest_shell.py to verify the parser. A comment\nin tests/sample.conf explains how to\nconfigure the existing functional tests to\nrun using keystone v3 API.\n\nNote that to use keystone v3\nwith swift you will need to set\nauth_version = v3.0 in the auth_token\nmiddleware config section of\nproxy-server.conf.\n\nChange-Id: Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f\n""}, {'number': 7, 'created': '2014-07-18 14:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/3934b60441ebbdd08db3c9bc31c45b3bf831759f', 'message': ""Add keystone v3 auth support\n\nEnables swiftclient to authenticate using\nthe keystone v3 API, allowing user id's, user\ndomains and tenant/project domains to be\nspecified.\n\nSince swiftclient imports keystoneclient, the\nmain changes in swiftclient/client.py are to\nselectively import the correct keystoneclient\nlibrary version and pass a number of new\noptions to it via the get_auth() function. In\naddition the get_keystoneclient_2_0 method\nhas been renamed get_auth_keystone to better\nreflect its purpose since it now deals with\nboth v2 and v3 use cases.\n\nIn swiftclient/shell.py the new options are\nadded to the parser. To make the default help\nmessage shorter, help for all the --os-*\noptions (including the existing v2 options)\nis only displayed when explicitly requested\nusng a new --os-help option.\n\nA new set of unit tests is added to\ntest_shell.py to verify the parser. A comment\nin tests/sample.conf explains how to\nconfigure the existing functional tests to\nrun using keystone v3 API.\n\nNote that to use keystone v3\nwith swift you will need to set\nauth_version = v3.0 in the auth_token\nmiddleware config section of\nproxy-server.conf.\n\nChange-Id: Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f\n""}, {'number': 8, 'created': '2014-07-23 15:56:36.000000000', 'files': ['swiftclient/shell.py', 'tests/unit/test_swiftclient.py', 'tests/unit/test_shell.py', 'swiftclient/client.py', 'tests/sample.conf', 'tests/unit/utils.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/cae12940b1bff230381289b732b464d88423fec1', 'message': ""Add keystone v3 auth support\n\nEnables swiftclient to authenticate using\nthe keystone v3 API, allowing user id's, user\ndomains and tenant/project domains to be\nspecified.\n\nSince swiftclient imports keystoneclient, the\nmain changes in swiftclient/client.py are to\nselectively import the correct keystoneclient\nlibrary version and pass a number of new\noptions to it via the get_auth() function. In\naddition the get_keystoneclient_2_0 method\nhas been renamed get_auth_keystone to better\nreflect its purpose since it now deals with\nboth v2 and v3 use cases.\n\nIn swiftclient/shell.py the new options are\nadded to the parser. To make the default help\nmessage shorter, help for all the --os-*\noptions (including the existing v2 options)\nis only displayed when explicitly requested\nusng a new --os-help option.\n\nA new set of unit tests is added to\ntest_shell.py to verify the parser. A comment\nin tests/sample.conf explains how to\nconfigure the existing functional tests to\nrun using keystone v3 API.\n\nNote that to use keystone v3\nwith swift you will need to set\nauth_version = v3.0 in the auth_token\nmiddleware config section of\nproxy-server.conf.\n\nChange-Id: Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f\n""}]",39,91788,cae12940b1bff230381289b732b464d88423fec1,117,14,8,7847,,,0,"Add keystone v3 auth support

Enables swiftclient to authenticate using
the keystone v3 API, allowing user id's, user
domains and tenant/project domains to be
specified.

Since swiftclient imports keystoneclient, the
main changes in swiftclient/client.py are to
selectively import the correct keystoneclient
library version and pass a number of new
options to it via the get_auth() function. In
addition the get_keystoneclient_2_0 method
has been renamed get_auth_keystone to better
reflect its purpose since it now deals with
both v2 and v3 use cases.

In swiftclient/shell.py the new options are
added to the parser. To make the default help
message shorter, help for all the --os-*
options (including the existing v2 options)
is only displayed when explicitly requested
usng a new --os-help option.

A new set of unit tests is added to
test_shell.py to verify the parser. A comment
in tests/sample.conf explains how to
configure the existing functional tests to
run using keystone v3 API.

Note that to use keystone v3
with swift you will need to set
auth_version = v3.0 in the auth_token
middleware config section of
proxy-server.conf.

Change-Id: Ifda0b3263eb919a8c6a1b204ba0a1215ed6f642f
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/88/91788/5 && git format-patch -1 --stdout FETCH_HEAD,"['swiftclient/shell.py', 'tests/test_swiftclient.py', 'tests/utils.py', 'swiftclient/client.py', 'tests/test_shell.py']",5,eeef8770709eb0c6a5b08786c1029bba4e17c4b3,p-keystone-v3-3," class TestParsing(unittest.TestCase): def _make_fake_command(self, result): def fake_command(parser, args, thread_manager): result[0], result[1] = swiftclient.shell.parse_args(parser, args) return fake_command def _make_args(self, cmd, opts, os_opts, separator='-'): """""" Construct command line arguments for given options. """""" args = ["""", cmd] for k, v in opts.items(): arg = ""--"" + k.replace(""_"", ""-"") args = args + [arg, v] for k, v in os_opts.items(): arg = ""--os"" + separator + k.replace(""_"", separator) args = args + [arg, v] return args def _make_env(self, opts, os_opts): """""" Construct a dict of environment variables for given options. """""" env = {} for k, v in opts.items(): key = 'ST_' + k.upper() env[key] = v for k, v in os_opts.items(): key = 'OS_' + k.upper() env[key] = v return env def _verify_opts(self, actual_opts, opts, os_opts={}, os_opts_dict={}): """""" Check parsed options are correct. :param opts: v1 style options. :param os_opts: openstack style options. :param os_opts_dict: openstack options that should be found in the os_options dict. """""" # check the expected opts are set for key, v in opts.items(): actual = getattr(actual_opts, key) self.assertEqual(v, actual, 'Expected %s for key %s, found %s' % (v, key, actual)) for key, v in os_opts.items(): actual = getattr(actual_opts, ""os_"" + key) self.assertEqual(v, actual, 'Expected %s for key %s, found %s' % (v, key, actual)) # check the os_options dict values are set self.assertTrue(hasattr(actual_opts, 'os_options')) actual_os_opts_dict = getattr(actual_opts, 'os_options') expected_os_opts_keys = ['project_name', 'region_name', 'tenant_name', 'user_domain_name', 'endpoint_type', 'object_storage_url', 'project_domain_id', 'user_id', 'user_domain_id', 'tenant_id', 'service_type', 'project_id', 'auth_token', 'project_domain_name'] for key in expected_os_opts_keys: self.assertTrue(key in actual_os_opts_dict) cli_key = key if key == 'object_storage_url': # exceptions to the pattern... cli_key = 'storage_url' if cli_key in os_opts_dict: expect = os_opts_dict[cli_key] else: expect = None actual = actual_os_opts_dict[key] self.assertEqual(expect, actual, 'Expected %s for %s, got %s' % (expect, key, actual)) for key in actual_os_opts_dict: self.assertTrue(key in expected_os_opts_keys) # check that equivalent keys have equal values equivalents = [('os_username', 'user'), ('os_auth_url', 'auth'), ('os_password', 'key')] for pair in equivalents: self.assertEqual(getattr(actual_opts, pair[0]), getattr(actual_opts, pair[1])) def test_minimum_required_args_v3(self): opts = {""auth_version"": ""3""} os_opts = {""password"": ""secret"", ""username"": ""user"", ""auth_url"": ""http://example.com:5000/v3""} args = self._make_args(""stat"", opts, os_opts, '-') result = [None, None] fake_command = self._make_fake_command(result) with mock.patch('swiftclient.shell.st_stat', fake_command): swiftclient.shell.main(args) self._verify_opts(result[0], opts, os_opts, {}) # check its ok to have user_id instead of username os_opts = {""password"": ""secret"", ""auth_url"": ""http://example.com:5000/v3""} os_opts_dict = {""user_id"": ""user_ID""} all_os_opts = os_opts.copy() all_os_opts.update(os_opts_dict) args = self._make_args(""stat"", opts, all_os_opts, '-') result = [None, None] fake_command = self._make_fake_command(result) with mock.patch('swiftclient.shell.st_stat', fake_command): swiftclient.shell.main(args) self._verify_opts(result[0], opts, os_opts, os_opts_dict) # check no user credentials required if token and url supplied os_opts = {} os_opts_dict = {""storage_url"": ""http://example.com:8080/v1"", ""auth_token"": ""0123abcd""} args = self._make_args(""stat"", opts, os_opts_dict, '-') result = [None, None] fake_command = self._make_fake_command(result) with mock.patch('swiftclient.shell.st_stat', fake_command): swiftclient.shell.main(args) self._verify_opts(result[0], opts, os_opts, os_opts_dict) def test_args_v3(self): opts = {""auth_version"": ""3""} os_opts = {""password"": ""secret"", ""username"": ""user"", ""auth_url"": ""http://example.com:5000/v3""} os_opts_dict = {""user_id"": ""user_ID"", ""project_id"": ""project_ID"", ""tenant_id"": ""tenant_ID"", ""project_domain_id"": ""project_domain_ID"", ""user_domain_id"": ""user_domain_ID"", ""tenant_name"": ""tenant"", ""project_name"": ""project"", ""project_domain_name"": ""project_domain"", ""user_domain_name"": ""user_domain"", ""auth_token"": ""token"", ""storage_url"": ""http://example.com:8080/v1"", ""region_name"": ""region"", ""service_type"": ""service""} all_os_opts = os_opts.copy() all_os_opts.update(os_opts_dict) # check using hyphen separator args = self._make_args(""stat"", opts, all_os_opts, '-') result = [None, None] fake_command = self._make_fake_command(result) with mock.patch('swiftclient.shell.st_stat', fake_command): swiftclient.shell.main(args) self._verify_opts(result[0], opts, os_opts, os_opts_dict) # check using underscore separator args = self._make_args(""stat"", opts, all_os_opts, '_') result = [None, None] fake_command = self._make_fake_command(result) with mock.patch('swiftclient.shell.st_stat', fake_command): swiftclient.shell.main(args) self._verify_opts(result[0], opts, os_opts, os_opts_dict) # check using environment variables args = self._make_args(""stat"", {}, {}) env = self._make_env(opts, all_os_opts) result = [None, None] fake_command = self._make_fake_command(result) with mock.patch.dict(os.environ, env): with mock.patch('swiftclient.shell.st_stat', fake_command): swiftclient.shell.main(args) self._verify_opts(result[0], opts, os_opts, os_opts_dict) def test_command_args_v3(self): result = [None, None] fake_command = self._make_fake_command(result) opts = {""auth_version"": ""3""} os_opts = {""password"": ""secret"", ""username"": ""user"", ""auth_url"": ""http://example.com:5000/v3""} args = self._make_args(""stat"", opts, os_opts) with mock.patch('swiftclient.shell.st_stat', fake_command): swiftclient.shell.main(args) self.assertEqual(['stat'], result[1]) with mock.patch('swiftclient.shell.st_stat', fake_command): args = args + [""container_name""] swiftclient.shell.main(args) self.assertEqual([""stat"", ""container_name""], result[1]) def test_insufficient_args_v3(self): opts = {""auth_version"": ""3""} os_opts = {""password"": ""secret"", ""auth_url"": ""http://example.com:5000/v3""} args = self._make_args(""stat"", opts, os_opts) self.assertRaises(SystemExit, swiftclient.shell.main, args) os_opts = {""username"": ""user"", ""auth_url"": ""http://example.com:5000/v3""} args = self._make_args(""stat"", opts, os_opts) self.assertRaises(SystemExit, swiftclient.shell.main, args) os_opts = {""username"": ""user"", ""password"": ""secret""} args = self._make_args(""stat"", opts, os_opts) self.assertRaises(SystemExit, swiftclient.shell.main, args)",,369,38
openstack%2Fhorizon~master~I8121bb658f9799f6cfa7738cdbb5cfa9bbf39cfe,openstack/horizon,master,I8121bb658f9799f6cfa7738cdbb5cfa9bbf39cfe,Remove redundant template from data_processing/data_plugins,MERGED,2014-08-14 11:09:20.000000000,2014-08-15 23:22:51.000000000,2014-08-15 23:22:50.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-08-14 11:09:20.000000000', 'files': ['openstack_dashboard/dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/_versions_list.html', 'openstack_dashboard/dashboards/project/data_processing/data_plugins/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/604fd47f97c1a5ed2fc0a72a0d3be346a6b96695', 'message': ""Remove redundant template from data_processing/data_plugins\n\nRemove 'project/data_processing.data_plugins/_versions_list.html' template\nand make a list of versions at the plugins table using standard Column\nclass attributes.\n\nCloses-Bug: #1356821\n\nChange-Id: I8121bb658f9799f6cfa7738cdbb5cfa9bbf39cfe\n""}]",0,114199,604fd47f97c1a5ed2fc0a72a0d3be346a6b96695,11,4,1,6914,,,0,"Remove redundant template from data_processing/data_plugins

Remove 'project/data_processing.data_plugins/_versions_list.html' template
and make a list of versions at the plugins table using standard Column
class attributes.

Closes-Bug: #1356821

Change-Id: I8121bb658f9799f6cfa7738cdbb5cfa9bbf39cfe
",git fetch https://review.opendev.org/openstack/horizon refs/changes/99/114199/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/_versions_list.html', 'openstack_dashboard/dashboards/project/data_processing/data_plugins/tables.py']",2,604fd47f97c1a5ed2fc0a72a0d3be346a6b96695,bug/1356821,"from django.template import defaultfilters as filters versions = tables.Column(""versions"", verbose_name=_(""Supported Versions""), wrap_list=True, filters=(filters.unordered_list,))","from django import templatedef render_versions(plugin): template_name = 'project/data_processing.data_plugins/_versions_list.html' context = {""plugin"": plugin} return template.loader.render_to_string(template_name, context) versions = tables.Column(render_versions, verbose_name=_(""Supported Versions""))",5,14
openstack%2Foslo.utils~master~I7d3cda719908413cea074935eb6c4e94cb6071d3,openstack/oslo.utils,master,I7d3cda719908413cea074935eb6c4e94cb6071d3,New public API for mask_password ported from incubator,MERGED,2014-08-15 17:44:41.000000000,2014-08-15 23:20:22.000000000,2014-08-15 23:20:21.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-08-15 17:44:41.000000000', 'files': ['oslo/utils/strutils.py', 'tests/test_strutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/424638f95565d106f11b0831b0432a918f0c22e9', 'message': ""New public API for mask_password ported from incubator\n\nmask_password is used in processutils and log modules. processutils\nis going into oslo.concurrency and log into oslo.log. Since we don't\nwant any oslo library to depend on oslo.log, we need this facility\nin oslo.utils for use by both oslo.log and oslo.concurrency.\n\nChange-Id: I7d3cda719908413cea074935eb6c4e94cb6071d3\n""}]",0,114611,424638f95565d106f11b0831b0432a918f0c22e9,13,6,1,5638,,,0,"New public API for mask_password ported from incubator

mask_password is used in processutils and log modules. processutils
is going into oslo.concurrency and log into oslo.log. Since we don't
want any oslo library to depend on oslo.log, we need this facility
in oslo.utils for use by both oslo.log and oslo.concurrency.

Change-Id: I7d3cda719908413cea074935eb6c4e94cb6071d3
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/11/114611/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/utils/strutils.py', 'tests/test_strutils.py']",2,424638f95565d106f11b0831b0432a918f0c22e9,mask-password," class MaskPasswordTestCase(test_base.BaseTestCase): def test_json(self): # Test 'adminPass' w/o spaces payload = """"""{'adminPass':'mypassword'}"""""" expected = """"""{'adminPass':'***'}"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'adminPass' with spaces payload = """"""{ 'adminPass' : 'mypassword' }"""""" expected = """"""{ 'adminPass' : '***' }"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_pass' w/o spaces payload = """"""{'admin_pass':'mypassword'}"""""" expected = """"""{'admin_pass':'***'}"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_pass' with spaces payload = """"""{ 'admin_pass' : 'mypassword' }"""""" expected = """"""{ 'admin_pass' : '***' }"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_password' w/o spaces payload = """"""{'admin_password':'mypassword'}"""""" expected = """"""{'admin_password':'***'}"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_password' with spaces payload = """"""{ 'admin_password' : 'mypassword' }"""""" expected = """"""{ 'admin_password' : '***' }"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'password' w/o spaces payload = """"""{'password':'mypassword'}"""""" expected = """"""{'password':'***'}"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'password' with spaces payload = """"""{ 'password' : 'mypassword' }"""""" expected = """"""{ 'password' : '***' }"""""" self.assertEqual(expected, strutils.mask_password(payload)) def test_xml(self): # Test 'adminPass' w/o spaces payload = """"""<adminPass>mypassword</adminPass>"""""" expected = """"""<adminPass>***</adminPass>"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'adminPass' with spaces payload = """"""<adminPass> mypassword </adminPass>"""""" expected = """"""<adminPass>***</adminPass>"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_pass' w/o spaces payload = """"""<admin_pass>mypassword</admin_pass>"""""" expected = """"""<admin_pass>***</admin_pass>"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_pass' with spaces payload = """"""<admin_pass> mypassword </admin_pass>"""""" expected = """"""<admin_pass>***</admin_pass>"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_password' w/o spaces payload = """"""<admin_password>mypassword</admin_password>"""""" expected = """"""<admin_password>***</admin_password>"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_password' with spaces payload = """"""<admin_password> mypassword </admin_password>"""""" expected = """"""<admin_password>***</admin_password>"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'password' w/o spaces payload = """"""<password>mypassword</password>"""""" expected = """"""<password>***</password>"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'password' with spaces payload = """"""<password> mypassword </password>"""""" expected = """"""<password>***</password>"""""" self.assertEqual(expected, strutils.mask_password(payload)) def test_xml_attribute(self): # Test 'adminPass' w/o spaces payload = """"""adminPass='mypassword'"""""" expected = """"""adminPass='***'"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'adminPass' with spaces payload = """"""adminPass = 'mypassword'"""""" expected = """"""adminPass = '***'"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'adminPass' with double quotes payload = """"""adminPass = ""mypassword\"""""""" expected = """"""adminPass = ""***\"""""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_pass' w/o spaces payload = """"""admin_pass='mypassword'"""""" expected = """"""admin_pass='***'"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_pass' with spaces payload = """"""admin_pass = 'mypassword'"""""" expected = """"""admin_pass = '***'"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_pass' with double quotes payload = """"""admin_pass = ""mypassword\"""""""" expected = """"""admin_pass = ""***\"""""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_password' w/o spaces payload = """"""admin_password='mypassword'"""""" expected = """"""admin_password='***'"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_password' with spaces payload = """"""admin_password = 'mypassword'"""""" expected = """"""admin_password = '***'"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'admin_password' with double quotes payload = """"""admin_password = ""mypassword\"""""""" expected = """"""admin_password = ""***\"""""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'password' w/o spaces payload = """"""password='mypassword'"""""" expected = """"""password='***'"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'password' with spaces payload = """"""password = 'mypassword'"""""" expected = """"""password = '***'"""""" self.assertEqual(expected, strutils.mask_password(payload)) # Test 'password' with double quotes payload = """"""password = ""mypassword\"""""""" expected = """"""password = ""***\"""""""" self.assertEqual(expected, strutils.mask_password(payload)) def test_json_message(self): payload = """"""body: {""changePassword"": {""adminPass"": ""1234567""}}"""""" expected = """"""body: {""changePassword"": {""adminPass"": ""***""}}"""""" self.assertEqual(expected, strutils.mask_password(payload)) payload = """"""body: {""rescue"": {""admin_pass"": ""1234567""}}"""""" expected = """"""body: {""rescue"": {""admin_pass"": ""***""}}"""""" self.assertEqual(expected, strutils.mask_password(payload)) payload = """"""body: {""rescue"": {""admin_password"": ""1234567""}}"""""" expected = """"""body: {""rescue"": {""admin_password"": ""***""}}"""""" self.assertEqual(expected, strutils.mask_password(payload)) payload = """"""body: {""rescue"": {""password"": ""1234567""}}"""""" expected = """"""body: {""rescue"": {""password"": ""***""}}"""""" self.assertEqual(expected, strutils.mask_password(payload)) def test_xml_message(self): payload = """"""<?xml version=""1.0"" encoding=""UTF-8""?> <rebuild xmlns=""http://docs.openstack.org/compute/api/v1.1"" name=""foobar"" imageRef=""http://openstack.example.com/v1.1/32278/images/70a599e0-31e7"" accessIPv4=""1.2.3.4"" accessIPv6=""fe80::100"" adminPass=""seekr3t""> <metadata> <meta key=""My Server Name"">Apache1</meta> </metadata> </rebuild>"""""" expected = """"""<?xml version=""1.0"" encoding=""UTF-8""?> <rebuild xmlns=""http://docs.openstack.org/compute/api/v1.1"" name=""foobar"" imageRef=""http://openstack.example.com/v1.1/32278/images/70a599e0-31e7"" accessIPv4=""1.2.3.4"" accessIPv6=""fe80::100"" adminPass=""***""> <metadata> <meta key=""My Server Name"">Apache1</meta> </metadata> </rebuild>"""""" self.assertEqual(expected, strutils.mask_password(payload)) payload = """"""<?xml version=""1.0"" encoding=""UTF-8""?> <rescue xmlns=""http://docs.openstack.org/compute/api/v1.1"" admin_pass=""MySecretPass""/>"""""" expected = """"""<?xml version=""1.0"" encoding=""UTF-8""?> <rescue xmlns=""http://docs.openstack.org/compute/api/v1.1"" admin_pass=""***""/>"""""" self.assertEqual(expected, strutils.mask_password(payload)) payload = """"""<?xml version=""1.0"" encoding=""UTF-8""?> <rescue xmlns=""http://docs.openstack.org/compute/api/v1.1"" admin_password=""MySecretPass""/>"""""" expected = """"""<?xml version=""1.0"" encoding=""UTF-8""?> <rescue xmlns=""http://docs.openstack.org/compute/api/v1.1"" admin_password=""***""/>"""""" self.assertEqual(expected, strutils.mask_password(payload)) payload = """"""<?xml version=""1.0"" encoding=""UTF-8""?> <rescue xmlns=""http://docs.openstack.org/compute/api/v1.1"" password=""MySecretPass""/>"""""" expected = """"""<?xml version=""1.0"" encoding=""UTF-8""?> <rescue xmlns=""http://docs.openstack.org/compute/api/v1.1"" password=""***""/>"""""" self.assertEqual(expected, strutils.mask_password(payload)) def test_mask_password(self): payload = ""test = 'password' : 'aaaaaa'"" expected = ""test = 'password' : '111'"" self.assertEqual(expected, strutils.mask_password(payload, secret='111')) payload = 'test = ""original_password"" : ""aaaaaaaaa""' expected = 'test = ""original_password"" : ""***""' self.assertEqual(expected, strutils.mask_password(payload)) payload = 'test = ""param1"" : ""value""' expected = 'test = ""param1"" : ""value""' self.assertEqual(expected, strutils.mask_password(payload)) payload = """"""{'adminPass':'mypassword'}"""""" payload = six.text_type(payload) expected = """"""{'adminPass':'***'}"""""" self.assertEqual(expected, strutils.mask_password(payload)) payload = (""test = 'node.session.auth.password','-v','mypassword',"" ""'nomask'"") expected = (""test = 'node.session.auth.password','-v','***',"" ""'nomask'"") self.assertEqual(expected, strutils.mask_password(payload)) payload = (""test = 'node.session.auth.password', '--password', "" ""'mypassword', 'nomask'"") expected = (""test = 'node.session.auth.password', '--password', "" ""'***', 'nomask'"") self.assertEqual(expected, strutils.mask_password(payload)) payload = (""test = 'node.session.auth.password', '--password', "" ""'mypassword'"") expected = (""test = 'node.session.auth.password', '--password', "" ""'***'"") self.assertEqual(expected, strutils.mask_password(payload)) payload = ""test = node.session.auth.password -v mypassword nomask"" expected = ""test = node.session.auth.password -v *** nomask"" self.assertEqual(expected, strutils.mask_password(payload)) payload = (""test = node.session.auth.password --password mypassword "" ""nomask"") expected = (""test = node.session.auth.password --password *** "" ""nomask"") self.assertEqual(expected, strutils.mask_password(payload)) payload = (""test = node.session.auth.password --password mypassword"") expected = (""test = node.session.auth.password --password ***"") self.assertEqual(expected, strutils.mask_password(payload))",,298,0
openstack%2Fpycadf~master~Idcfefd923e5ddb574087265c998dd50ebfe70a79,openstack/pycadf,master,Idcfefd923e5ddb574087265c998dd50ebfe70a79,clean up license headers,MERGED,2014-07-29 23:09:10.000000000,2014-08-15 23:20:19.000000000,2014-08-15 23:20:18.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5638}, {'_account_id': 6460}, {'_account_id': 6537}, {'_account_id': 7514}]","[{'number': 1, 'created': '2014-07-29 23:09:10.000000000', 'files': ['pycadf/middleware/notifier.py', 'pycadf/reason.py', 'pycadf/tests/base.py', 'pycadf/middleware/base.py', 'pycadf/event.py', 'pycadf/cadftype.py', 'pycadf/tests/test_cadf_spec.py', 'pycadf/utils.py', 'pycadf/tests/test_utils.py', 'pycadf/metric.py', 'pycadf/tests/middleware/test_audit.py', 'pycadf/timestamp.py', 'pycadf/geolocation.py', 'pycadf/path.py', 'pycadf/attachment.py', 'pycadf/measurement.py', 'pycadf/tests/audit/test_api.py', 'pycadf/audit/api.py', 'pycadf/credential.py', 'pycadf/host.py', 'pycadf/resource.py', 'pycadf/middleware/audit.py', 'pycadf/endpoint.py', 'pycadf/eventfactory.py', 'pycadf/cadftaxonomy.py', 'pycadf/identifier.py', 'pycadf/tag.py', 'pycadf/reporterstep.py'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/870b4efb44ab3869739fa1cdec9e1b4fdd6be37f', 'message': 'clean up license headers\n\nThis removes extraneous whitespace, applies a consistent licensing\nheader to all files, removes ""all rights reserved"" lines attributed to\nthe OpenStack Foundation, removes authorship lines for Matt Rutkowski\n(which the git commit history much more accurately conveys) and follows\nall licenses with a blank line before the code/docstr begins.\n\nChange-Id: Idcfefd923e5ddb574087265c998dd50ebfe70a79\n'}]",15,110498,870b4efb44ab3869739fa1cdec9e1b4fdd6be37f,33,6,1,4,,,0,"clean up license headers

This removes extraneous whitespace, applies a consistent licensing
header to all files, removes ""all rights reserved"" lines attributed to
the OpenStack Foundation, removes authorship lines for Matt Rutkowski
(which the git commit history much more accurately conveys) and follows
all licenses with a blank line before the code/docstr begins.

Change-Id: Idcfefd923e5ddb574087265c998dd50ebfe70a79
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/98/110498/1 && git format-patch -1 --stdout FETCH_HEAD,"['pycadf/middleware/notifier.py', 'pycadf/reason.py', 'pycadf/tests/base.py', 'pycadf/middleware/base.py', 'pycadf/event.py', 'pycadf/cadftype.py', 'pycadf/tests/test_cadf_spec.py', 'pycadf/utils.py', 'pycadf/tests/test_utils.py', 'pycadf/metric.py', 'pycadf/tests/middleware/test_audit.py', 'pycadf/timestamp.py', 'pycadf/geolocation.py', 'pycadf/path.py', 'pycadf/attachment.py', 'pycadf/measurement.py', 'pycadf/tests/audit/test_api.py', 'pycadf/audit/api.py', 'pycadf/credential.py', 'pycadf/host.py', 'pycadf/resource.py', 'pycadf/middleware/audit.py', 'pycadf/endpoint.py', 'pycadf/eventfactory.py', 'pycadf/cadftaxonomy.py', 'pycadf/identifier.py', 'pycadf/tag.py', 'pycadf/reporterstep.py']",28,870b4efb44ab3869739fa1cdec9e1b4fdd6be37f,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may not # use this file except in compliance with the License. You may obtain a copy of # the License at# http://www.apache.org/licenses/LICENSE-2.0# License for the specific language governing permissions and limitations under # the License.","## Author: Matt Rutkowski <mrutkows@us.ibm.com># Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0# License for the specific language governing permissions and limitations # under the License.",189,247
openstack%2Fnova~master~Ieb9c6ebe0dc1ca65d0541187fcbba4e73fe0f8d1,openstack/nova,master,Ieb9c6ebe0dc1ca65d0541187fcbba4e73fe0f8d1,Include child_versions in object hashes,MERGED,2014-08-14 14:20:12.000000000,2014-08-15 23:09:01.000000000,2014-08-15 23:08:59.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1812}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-14 14:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/baad4fd0b4eaab23e9f714388543bdfa67eb2777', 'message': 'Include child_versions in object hashes\n\nThis adds the child_versions array to the object hash test. This helps\nremind contributors and reviewers that changing that mapping also requires\na bump to the list object version.\n\nChange-Id: Ieb9c6ebe0dc1ca65d0541187fcbba4e73fe0f8d1\n'}, {'number': 2, 'created': '2014-08-15 14:48:10.000000000', 'files': ['nova/tests/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bf8f7c90fcb0f1db60e778dc85fedfcf9d7a9338', 'message': 'Include child_versions in object hashes\n\nThis adds the child_versions array to the object hash test. This helps\nremind contributors and reviewers that changing that mapping also requires\na bump to the list object version.\n\nChange-Id: Ieb9c6ebe0dc1ca65d0541187fcbba4e73fe0f8d1\n'}]",0,114257,bf8f7c90fcb0f1db60e778dc85fedfcf9d7a9338,25,7,2,4393,,,0,"Include child_versions in object hashes

This adds the child_versions array to the object hash test. This helps
remind contributors and reviewers that changing that mapping also requires
a bump to the list object version.

Change-Id: Ieb9c6ebe0dc1ca65d0541187fcbba4e73fe0f8d1
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/114257/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/objects/test_objects.py'],1,baad4fd0b4eaab23e9f714388543bdfa67eb2777,object-hash-children," 'AgentList': '1.0-31f07426a729311a42ff7f6246e76e25', 'AggregateList': '1.2-4b02a285b8612bfb86a96ff80052fb0a', 'BlockDeviceMappingList': '1.2-a6df0a8ef84d6bbaba51143499e9bed2', 'ComputeNodeList': '1.3-1c9c281e02182eabffa6b63ee349996a', 'DNSDomainList': '1.0-cfb3e7e82be661501c31099523154db4', 'FixedIPList': '1.1-c12d1165c88fa721ab8abcf502fa1b29', 'FlavorList': '1.1-a3d5551267cb8f62ff38ded125900721', 'FloatingIPList': '1.2-6c5b0b4d4a4c17575f4d91bae14e5237', 'InstanceActionEventList': '1.0-1d5cc958171d6ce07383c2ad6208318e', 'InstanceActionList': '1.0-368410fdb8d69ae20c495308535d6266', 'InstanceFaultList': '1.1-aeb598ffd0cd6aa61fca7adf0f5e900d', 'InstanceGroupList': '1.2-a474822eebc3e090012e581adcc1fa09', 'InstanceList': '1.6-6891f6f61f8eb0b55c0cefac3f734c24', 'KeyPairList': '1.0-71132a568cc5d078ba1748a9c02c87b8', 'MigrationList': '1.1-8c5f678edc72a592d591a13b35e54353', 'NetworkList': '1.2-aa4ad23f035b97a41732ea8b3445fc5e', 'PciDeviceList': '1.0-43d6c4ea0dd77955e97b23d937a3f925', 'SecurityGroupList': '1.0-528e6448adfeeb78921ebeda499ab72f', 'SecurityGroupRuleList': '1.0-1052b37dc59a1957ee5b0b9268d03af3', 'ServiceList': '1.0-2c960ac9bc56a12c65b9118bb3a58b44', 'VirtualInterfaceList': '1.0-accbf02628a8063c1d885077a2bf49b6', if hasattr(obj_class, 'child_versions'): relevant_data = (fields, methods, obj_class.child_versions) else: relevant_data = (fields, methods)"," 'AgentList': '1.0-f8b860e1f2ce80e676ba1a37ddf86e4f', 'AggregateList': '1.2-504137b7ec3855b00d01f165dcebc23e', 'BlockDeviceMappingList': '1.2-d6d7df540ca149dda78b22b4b10bdef3', 'ComputeNodeList': '1.3-ff59187056eaa96f6fd3fb70693d818c', 'DNSDomainList': '1.0-6e3cc498d89dd7e90f9beb021644221c', 'FixedIPList': '1.1-8ea5cfca611598f1242fd4095e49e58b', 'FlavorList': '1.1-d559595f55936a6d602721c3bdff6fff', 'FloatingIPList': '1.2-1b77acb3523d16e3282624f51fee60d8', 'InstanceActionEventList': '1.0-937f4ed414ff2354de416834b948fbd6', 'InstanceActionList': '1.0-d46ade45deeba63c55821e22c164bd1b', 'InstanceFaultList': '1.1-bd578be60d045629ca7b3ce1a2493ae4', 'InstanceGroupList': '1.2-bebd07052779ae3b47311efe85428a8b', 'InstanceList': '1.6-78800140a5f9818ab00f8c052437655f', 'KeyPairList': '1.0-854cfff138dac9d5925c89cf805d1a70', 'MigrationList': '1.1-6ca2ebb822ebfe1a660bace824b378c6', 'NetworkList': '1.2-16510568c6e64cb8b358cb2b11333196', 'PciDeviceList': '1.0-5da7b4748a5a2594bae2cd0bd211cca2', 'SecurityGroupList': '1.0-9513387aabf08c2a7961ac4da4315ed4', 'SecurityGroupRuleList': '1.0-af4deeea8699ee90fb217f77d711d781', 'ServiceList': '1.0-ae64b4922df28d7cd11c59cddddf926c', 'VirtualInterfaceList': '1.0-dc9e9d5bce522d28f96092c49119b3e0', relevant_data = (fields, methods)",25,22
openstack%2Fnova~master~I874ade4456b92a63959a765c7851bcd001befa32,openstack/nova,master,I874ade4456b92a63959a765c7851bcd001befa32,Fixes Hyper-V agent force_hyperv_utils_v1 flag issue,MERGED,2014-07-18 13:55:09.000000000,2014-08-15 22:34:21.000000000,2014-08-15 22:34:18.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 3185}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7934}, {'_account_id': 8213}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10814}]","[{'number': 1, 'created': '2014-07-18 13:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33bc2a486974b33c97c132073ef69d9d2d496146', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}, {'number': 2, 'created': '2014-07-22 12:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/40bed88a623320477620521bb42270596283f07f', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}, {'number': 3, 'created': '2014-07-22 15:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d1cbc81bd7f2cc9049c9976288365a6cdc6e173', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}, {'number': 4, 'created': '2014-07-22 15:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4f0973f1ca68d298d691e9070c1a7e5b477c569', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}, {'number': 5, 'created': '2014-07-22 17:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/838df49dee7294349545db7eb497e55ac9758974', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}, {'number': 6, 'created': '2014-07-22 17:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6732f95801a60f057cb0be683a683a833d37106e', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}, {'number': 7, 'created': '2014-07-22 19:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ac9ce8155a2e0c053fda1776c4ad261e3607b71', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}, {'number': 8, 'created': '2014-07-23 14:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c1102bdc193c50a8f7781f7d28db5ca2fd5d8c9', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}, {'number': 9, 'created': '2014-07-23 15:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc013f141bff8f8b17ee7994e69598c2eddbe253', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}, {'number': 10, 'created': '2014-07-24 14:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e883d2e7cdbff5dc8f9d038e83f49870b167de01', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}, {'number': 11, 'created': '2014-08-14 17:22:30.000000000', 'files': ['nova/tests/virt/hyperv/test_migrationops.py', 'nova/tests/virt/hyperv/test_vmops.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/tests/virt/hyperv/test_utilsfactory.py', 'nova/virt/hyperv/utilsfactory.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/52de9395e5fe4f328f6dab0b35d660a700787c76', 'message': ""Fixes Hyper-V agent force_hyperv_utils_v1 flag issue\n\nWMI root\\virtualization namespace v1 (in Hyper-V) has been removed\nfrom Windows Server / Hyper-V Server 2012 R2.\n\nHyper-V compute agent now creates instances which uses\nroot\\virtualization\\v2 namespace if the agent's OS is\nWindows Server / Hyper-V Server 2012 R2 or newer.\n\nCloses-Bug: #1344036\n\nChange-Id: I874ade4456b92a63959a765c7851bcd001befa32\n""}]",9,108013,52de9395e5fe4f328f6dab0b35d660a700787c76,96,16,11,10814,,,0,"Fixes Hyper-V agent force_hyperv_utils_v1 flag issue

WMI root\virtualization namespace v1 (in Hyper-V) has been removed
from Windows Server / Hyper-V Server 2012 R2.

Hyper-V compute agent now creates instances which uses
root\virtualization\v2 namespace if the agent's OS is
Windows Server / Hyper-V Server 2012 R2 or newer.

Closes-Bug: #1344036

Change-Id: I874ade4456b92a63959a765c7851bcd001befa32
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/108013/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/hyperv/test_hypervapi.py', 'nova/tests/virt/hyperv/test_utilsfactory.py', 'nova/virt/hyperv/utilsfactory.py']",3,33bc2a486974b33c97c132073ef69d9d2d496146,bug/1344036,"def _get_virt_class(v1_class, v2_class, force_v1_flag): # V1 virtualization namespace features are no longer supported on # Windows Server / Hyper-V Server 2012 R2 (kernel version 6.3) or above. if get_hostutils().check_min_windows_version(6, 3): if force_v1_flag: LOG.warning('V1 virtualization namespace no longer supported on ' 'Windows Server / Hyper-V Server 2012 R2 or above.') return _get_class(v1_class, v2_class, False) return _get_class(v1_class, v2_class, force_v1_flag) def get_vmutils(host='.'): return _get_virt_class(vmutils.VMUtils, vmutilsv2.VMUtilsV2, CONF.hyperv.force_hyperv_utils_v1)(host) return _get_virt_class(vhdutils.VHDUtils, vhdutilsv2.VHDUtilsV2, CONF.hyperv.force_hyperv_utils_v1)() return _get_virt_class(networkutils.NetworkUtils, networkutilsv2.NetworkUtilsV2, CONF.hyperv.force_hyperv_utils_v1)()","def get_vmutils(host='.'): return _get_class(vmutils.VMUtils, vmutilsv2.VMUtilsV2, CONF.hyperv.force_hyperv_utils_v1)(host) return _get_class(vhdutils.VHDUtils, vhdutilsv2.VHDUtilsV2, CONF.hyperv.force_hyperv_utils_v1)() return _get_class(networkutils.NetworkUtils, networkutilsv2.NetworkUtilsV2, CONF.hyperv.force_hyperv_utils_v1)()",77,7
openstack%2Ftempest~master~I6a00f1835c359bfd639bf19ba2c4616638695359,openstack/tempest,master,I6a00f1835c359bfd639bf19ba2c4616638695359,Add ironic instance rebuild test,MERGED,2014-05-20 18:11:57.000000000,2014-08-15 22:33:25.000000000,2014-08-15 22:33:24.000000000,"[{'_account_id': 3}, {'_account_id': 97}, {'_account_id': 1192}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 5196}, {'_account_id': 7139}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10342}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-20 18:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fef455a65bee3ac02a03524b42f228e80028b127', 'message': 'Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 2, 'created': '2014-05-23 17:35:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/11fc6de4e1b9dea608a7af54bc2623d4666aa614', 'message': 'Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 3, 'created': '2014-06-06 19:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9f47546d671464cbfdd4f62bd055a3d5ed4334f6', 'message': 'Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists. We also verify the\nexpected ephemeral partition mount point and size.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 4, 'created': '2014-06-11 13:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bd71f4dafd18048028baad9bf2ce7ebd1b756680', 'message': 'Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists. We also verify the\nexpected ephemeral partition mount point and size.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 5, 'created': '2014-06-12 12:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e16efa8effc46ac6c5f5762c641e2ffd9f8be4db', 'message': 'Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists. We also verify the\nexpected ephemeral partition mount point and size.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 6, 'created': '2014-06-12 15:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4b7c73e6e6a134dc6c99d1309ca57327601f810d', 'message': 'Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists. We also verify the\nexpected ephemeral partition mount point and size.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 7, 'created': '2014-06-16 17:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c725f8fc11abf10b5c55e56ae1a060d03f86bb69', 'message': 'Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists. We also verify the\nexpected ephemeral partition mount point and size.\n\nBecause gate tempest runs use only a single VM for the ironic\nbaremetal node, we need to wait for this node to become available\nbetween tests (or add additional VMs, which would require more\nresources in our test nodes). This adds a check before instance\nboot time for available VCPUs and RAM. Two configuration variables\nare added to control the timeout for this check, and how often\nthe check is performed. This also requires an admin credentialed\ncompute client.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 8, 'created': '2014-06-16 20:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/51cfefac83b66953a3a7dc99dba172ee7de1859f', 'message': 'Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists. We also verify the\nexpected ephemeral partition mount point and size.\n\nBecause gate tempest runs use only a single VM for the ironic\nbaremetal node, we need to wait for this node to become available\nbetween tests (or add additional VMs, which would require more\nresources in our test nodes). This adds a check before instance\nboot time for available VCPUs and RAM. Two configuration variables\nare added to control the timeout for this check, and how often\nthe check is performed. This also requires an admin credentialed\ncompute client.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 9, 'created': '2014-06-17 21:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/118bfe53e1be5fd33d1ff5c39663f7bb2550f956', 'message': 'Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists. We also verify the\nexpected ephemeral partition mount point and size.\n\nBecause gate tempest runs use only a single VM for the ironic\nbaremetal node, we need to wait for this node to become available\nbetween tests (or add additional VMs, which would require more\nresources in our test nodes). This adds a check before instance\nboot time for available VCPUs and RAM. Two configuration variables\nare added to control the timeout for this check, and how often\nthe check is performed. This also requires an admin credentialed\ncompute client.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 10, 'created': '2014-06-19 15:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/58fc6744491892f1553aec79f7573fc7df6ed0b2', 'message': ""Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists. We also verify the\nexpected ephemeral partition mount point and size.\n\nBecause gate tempest runs use only a single VM for the ironic\nbaremetal node, we need to wait for this node to become available\nbetween tests (or add additional VMs, which would require more\nresources in our test nodes). This adds a check before instance\nboot time for available VCPUs and RAM. Two configuration variables\nare added to control the timeout for this check, and how often\nthe check is performed. This also requires an admin credentialed\ncompute client.\n\nA new baremetal features configuration group is added, along with\na 'rebuild' option, so we can control whether this test is run.\nIt defaults to True (enabled).\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n""}, {'number': 11, 'created': '2014-06-20 14:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e95cc76f6ee433889fd4be982b27d582a723bacd', 'message': ""Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists. We also verify the\nexpected ephemeral partition mount point and size.\n\nBecause gate tempest runs use only a single VM for the ironic\nbaremetal node, we need to wait for this node to become available\nbetween tests (or add additional VMs, which would require more\nresources in our test nodes). This adds a check before instance\nboot time for available VCPUs and RAM. Two configuration variables\nare added to control the timeout for this check, and how often\nthe check is performed. This also requires an admin credentialed\ncompute client.\n\nA new compute feature configuration option is added, 'rebuild',\nso we can control whether this test is run. Currently, only\nIronic does rebuild testing, but it is anticipated that this\nwill be needed by compute tests someday (and it is a function of\ncompute, after all). The default value is True (enabled).\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n""}, {'number': 12, 'created': '2014-06-24 19:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b4a7c55de774efe115dfd6dfbd0e7833cb45e800', 'message': ""Add ironic instance rebuild advanced test\n\nPart 2 of a change to the ironic scenario tests. This adds verification\nof rebuilding an instance and preservation of the ephemeral partition.\nA file is created on the ephemeral partition before the rebuild, then\nafter the rebuild, we verify that it still exists. We also verify the\nexpected ephemeral partition mount point and size.\n\nBecause gate tempest runs use only a single VM for the ironic\nbaremetal node, we need to wait for this node to become available\nbetween tests (or add additional VMs, which would require more\nresources in our test nodes). This adds a check before instance\nboot time for available VCPUs and RAM. Two configuration variables\nare added to control the timeout for this check, and how often\nthe check is performed. This also requires an admin credentialed\ncompute client.\n\nA new compute feature configuration option is added, 'rebuild',\nso we can control whether this test is run. Currently, only\nIronic does rebuild testing, but it is anticipated that this\nwill be needed by compute tests someday (and it is a function of\ncompute, after all). The default value is True (enabled).\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n""}, {'number': 13, 'created': '2014-07-14 18:15:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c16c2114097e6035ae3e793348733108bd689c34', 'message': 'Add ironic instance rebuild test\n\nThis adds verification of rebuilding an instance and preservation\nof the ephemeral partition. A file is created on the ephemeral\npartition before the rebuild, then after the rebuild, we verify\nthat it still exists. We also verify the expected ephemeral\npartition mount point and size, which is an ironic-specific\ntest point.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 14, 'created': '2014-07-14 18:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f696f226dd28db16ef19d177eb13db47282bf162', 'message': 'Add ironic instance rebuild test\n\nThis adds verification of rebuilding an instance and preservation\nof the ephemeral partition. A file is created on the ephemeral\npartition before the rebuild, then after the rebuild, we verify\nthat it still exists. We also verify the expected ephemeral\npartition mount point and size, which is an ironic-specific\ntest point.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 15, 'created': '2014-07-14 19:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4db426e1b2b364e7f845cf395ec5a02fae711c6a', 'message': 'Add ironic instance rebuild test\n\nThis adds verification of rebuilding an instance and preservation\nof the ephemeral partition. A file is created on the ephemeral\npartition before the rebuild, then after the rebuild, we verify\nthat it still exists. We also verify the expected ephemeral\npartition mount point and size, which is an ironic-specific\ntest criteria.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 16, 'created': '2014-07-28 16:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7f921b453b26c0616fe7f38a625da8ccc456c175', 'message': 'Add ironic instance rebuild test\n\nThis adds verification of rebuilding an instance and preservation\nof the ephemeral partition. A file is created on the ephemeral\npartition before the rebuild, then after the rebuild, we verify\nthat it still exists. We also verify the expected ephemeral\npartition mount point and size, which is an ironic-specific\ntest criteria.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 17, 'created': '2014-08-12 15:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8598db373c129b8d75dc804d45a2cbb4ad2ebaf6', 'message': 'Add ironic instance rebuild test\n\nThis adds verification of rebuilding an instance and preservation\nof the ephemeral partition. A file is created on the ephemeral\npartition before the rebuild, then after the rebuild, we verify\nthat it still exists. We also verify the expected ephemeral\npartition mount point and size, which is an ironic-specific\ntest criteria.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}, {'number': 18, 'created': '2014-08-15 15:41:35.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/scenario/test_baremetal_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0271936ebb77d8139a8807f497898189d60515d1', 'message': 'Add ironic instance rebuild test\n\nThis adds verification of rebuilding an instance and preservation\nof the ephemeral partition. A file is created on the ephemeral\npartition before the rebuild, then after the rebuild, we verify\nthat it still exists. We also verify the expected ephemeral\npartition mount point and size, which is an ironic-specific\ntest criteria.\n\nChange-Id: I6a00f1835c359bfd639bf19ba2c4616638695359\n'}]",29,94439,0271936ebb77d8139a8807f497898189d60515d1,239,14,18,3099,,,0,"Add ironic instance rebuild test

This adds verification of rebuilding an instance and preservation
of the ephemeral partition. A file is created on the ephemeral
partition before the rebuild, then after the rebuild, we verify
that it still exists. We also verify the expected ephemeral
partition mount point and size, which is an ironic-specific
test criteria.

Change-Id: I6a00f1835c359bfd639bf19ba2c4616638695359
",git fetch https://review.opendev.org/openstack/tempest refs/changes/39/94439/16 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/test_baremetal_advanced_ops.py', 'tempest/scenario/manager.py']",2,fef455a65bee3ac02a03524b42f228e80028b127,bm_part2," def rebuild_server(self, server, client=None, image=None, preserve_ephemeral=False, wait=True, rebuild_kwargs={}): if client is None: client = self.compute_client if image is None: image = CONF.compute.image_ref LOG.debug(""Rebuilding server (name: %s, image: %s, preserve eph: %s)"", server.name, image, preserve_ephemeral) server.rebuild(image, preserve_ephemeral=preserve_ephemeral, **rebuild_kwargs) if wait: self.status_timeout(client.servers, server.id, 'ACTIVE') ",,67,0
openstack%2Fswift~master~Ibed6bdb49bddcdb868742c41f86d2482a7edfd29,openstack/swift,master,Ibed6bdb49bddcdb868742c41f86d2482a7edfd29,Sleep for longer at a time in lock_path.,MERGED,2014-08-11 16:51:35.000000000,2014-08-15 22:33:01.000000000,2014-08-15 22:33:00.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 1009}, {'_account_id': 2828}, {'_account_id': 7233}]","[{'number': 1, 'created': '2014-08-11 16:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d439df3c90557ea66d26b41966ce227a4e11394d', 'message': 'Sleep for longer at a time in lock_path.\n\nWhen lock_path is called and the lock goes for the whole 10 seconds,\nthe flock is called 1000 times. With this patch, the short 0.01 sleep\nis used for the first 1% of the total lock time and then 1% of the\ntotal lock time is used.\n\nChange-Id: Ibed6bdb49bddcdb868742c41f86d2482a7edfd29\n'}, {'number': 2, 'created': '2014-08-14 19:16:26.000000000', 'files': ['swift/common/utils.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/a0e0014159c0e12a10cc452b92e86f99196e77bb', 'message': 'Sleep for longer at a time in lock_path.\n\nWhen lock_path is called and the lock goes for the whole 10 seconds,\nthe flock is called 1000 times. With this patch, the short 0.01 sleep\nis used for the first 1% of the total lock time and then 1% of the\ntotal lock time is used.\n\nChange-Id: Ibed6bdb49bddcdb868742c41f86d2482a7edfd29\n'}]",2,113317,a0e0014159c0e12a10cc452b92e86f99196e77bb,17,5,2,995,,,0,"Sleep for longer at a time in lock_path.

When lock_path is called and the lock goes for the whole 10 seconds,
the flock is called 1000 times. With this patch, the short 0.01 sleep
is used for the first 1% of the total lock time and then 1% of the
total lock time is used.

Change-Id: Ibed6bdb49bddcdb868742c41f86d2482a7edfd29
",git fetch https://review.opendev.org/openstack/swift refs/changes/17/113317/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'test/unit/common/test_utils.py']",2,d439df3c90557ea66d26b41966ce227a4e11394d,timeout_spin," def test_lock_path_num_sleeps(self): tmpdir = mkdtemp() num_short_calls = [0] exception_raised = [False] def my_sleep(to_sleep): if to_sleep == 0.01: num_short_calls[0] += 1 else: raise Exception('sleep time changed: %s' % to_sleep) try: with mock.patch('swift.common.utils.sleep', my_sleep): with utils.lock_path(tmpdir): with utils.lock_path(tmpdir): pass except Exception as e: exception_raised[0] = True self.assertTrue('sleep time changed' in str(e)) finally: shutil.rmtree(tmpdir) self.assertEqual(num_short_calls[0], 11) self.assertTrue(exception_raised[0]) ",,30,1
openstack%2Fcongress~master~Ifc3df18bd3e3b978a6de312b45e868b6b2540871,openstack/congress,master,Ifc3df18bd3e3b978a6de312b45e868b6b2540871,Added tracing to API,MERGED,2014-08-15 20:30:07.000000000,2014-08-15 22:27:13.000000000,2014-08-15 22:27:12.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 12875}]","[{'number': 1, 'created': '2014-08-15 20:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/1da7b1798116de342c691ad4e840b81c6f209fa9', 'message': 'Added tracing to API\n\nPreviously the tracing functionality for tables was not exposed\nat the API layer.\n\nThis change surfaces tracing via an optional parameter to the rows\ndata model.\n\nChange-Id: Ifc3df18bd3e3b978a6de312b45e868b6b2540871\n'}, {'number': 2, 'created': '2014-08-15 21:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/e7bbdef2418c5250505123313970913e1477e435', 'message': 'Added tracing to API\n\nPreviously the tracing functionality for tables was not exposed\nat the API layer.\n\nThis change surfaces tracing via an optional parameter to the rows\ndata model.\n\nChange-Id: Ifc3df18bd3e3b978a6de312b45e868b6b2540871\n'}, {'number': 3, 'created': '2014-08-15 21:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/e4bfee79581031f72da5a00dd1545d9632ce77aa', 'message': 'Added tracing to API\n\nPreviously the tracing functionality for tables was not exposed\nat the API layer.\n\nThis change surfaces tracing via an optional parameter to the rows\ndata model.\n\nChange-Id: Ifc3df18bd3e3b978a6de312b45e868b6b2540871\n'}, {'number': 4, 'created': '2014-08-15 21:22:34.000000000', 'files': ['congress/tests/test_congress.py', 'congress/api/row_model.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/a084ec39962ee3d29b11172ac315d1d55d6d5dca', 'message': 'Added tracing to API\n\nPreviously the tracing functionality for tables was not exposed\nat the API layer.\n\nThis change surfaces tracing via an optional parameter to the rows\ndata model.\n\nChange-Id: Ifc3df18bd3e3b978a6de312b45e868b6b2540871\n'}]",10,114652,a084ec39962ee3d29b11172ac315d1d55d6d5dca,22,4,4,8215,,,0,"Added tracing to API

Previously the tracing functionality for tables was not exposed
at the API layer.

This change surfaces tracing via an optional parameter to the rows
data model.

Change-Id: Ifc3df18bd3e3b978a6de312b45e868b6b2540871
",git fetch https://review.opendev.org/openstack/congress refs/changes/52/114652/3 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/test_congress.py', 'congress/api/row_model.py']",2,1da7b1798116de342c691ad4e840b81c6f209fa9,trace," gen_trace = False trace = ""Not available"" if 'trace' in params and params['trace'].lower() == 'true': print ""gen_trace is True"" gen_trace = True LOG.info(""gen_trace: "" + str(gen_trace)) result = self.engine.select(query, target=policy_name, trace=gen_trace) if gen_trace: literals = result[0] trace = result[1] else: literals = result literals = frozenset(literals) if gen_trace: return {""results"": results, ""trace"": trace}"," literals = frozenset(self.engine.theory[policy_name].select(query)) # None is the standin for the ID (could hash row, I suppose)",62,15
openstack%2Fcongress~master~I5a67ddbdf4cb4d000fdc78b0d6192eb284f9abb1,openstack/congress,master,I5a67ddbdf4cb4d000fdc78b0d6192eb284f9abb1,Added tracing option to Select queries,MERGED,2014-08-12 17:19:06.000000000,2014-08-15 22:26:04.000000000,2014-08-15 22:26:04.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 6923}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 12875}]","[{'number': 1, 'created': '2014-08-12 17:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/3dcde4c2a9142dbd1706be4075a51eb73f93dbb1', 'message': 'Added tracing option to Select queries\n\nPreviously the only way to see a trace explaining why a particular\nquery was true was to set debug_mode() on Runtime and inspect the\nlog.\n\nThis change makes it possible to ask for the trace when running\na select query.  The Runtime.select() now either returns a singleton\nif tracing is False (like always) or (answer, trace) if tracing is\ntrue.  This ensures the change is backwards compatible.\n\nChange-Id: I5a67ddbdf4cb4d000fdc78b0d6192eb284f9abb1\n'}, {'number': 2, 'created': '2014-08-15 20:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/01ecefc74f55d307598400e64b15b1bf8ef8a0d7', 'message': 'Added tracing option to Select queries\n\nPreviously the only way to see a trace explaining why a particular\nquery was true was to set debug_mode() on Runtime and inspect the\nlog.\n\nThis change makes it possible to ask for the trace when running\na select query.  The Runtime.select() now either returns a singleton\nif tracing is False (like always) or (answer, trace) if tracing is\ntrue.  This ensures the change is backwards compatible.\n\nCloses-bug: 1356626\nChange-Id: I5a67ddbdf4cb4d000fdc78b0d6192eb284f9abb1\n'}, {'number': 3, 'created': '2014-08-15 21:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/cbac9220b039fae31d761e2ad3f3808e5d1557af', 'message': 'Added tracing option to Select queries\n\nPreviously the only way to see a trace explaining why a particular\nquery was true was to set debug_mode() on Runtime and inspect the\nlog.\n\nThis change makes it possible to ask for the trace when running\na select query.  The Runtime.select() now either returns a singleton\nif tracing is False (like always) or (answer, trace) if tracing is\ntrue.  This ensures the change is backwards compatible.\n\nCloses-bug: 1356626\nChange-Id: I5a67ddbdf4cb4d000fdc78b0d6192eb284f9abb1\n'}, {'number': 4, 'created': '2014-08-15 21:22:34.000000000', 'files': ['congress/policy/tests/test_nonrecur.py', 'congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/7a727a8ac4c4b2da9d373458dd2cabee10f28413', 'message': 'Added tracing option to Select queries\n\nPreviously the only way to see a trace explaining why a particular\nquery was true was to set debug_mode() on Runtime and inspect the\nlog.\n\nThis change makes it possible to ask for the trace when running\na select query.  The Runtime.select() now either returns a singleton\nif tracing is False (like always) or (answer, trace) if tracing is\ntrue.  This ensures the change is backwards compatible.\n\nCloses-bug: 1356626\nChange-Id: I5a67ddbdf4cb4d000fdc78b0d6192eb284f9abb1\n'}]",0,113590,7a727a8ac4c4b2da9d373458dd2cabee10f28413,18,6,4,8215,,,0,"Added tracing option to Select queries

Previously the only way to see a trace explaining why a particular
query was true was to set debug_mode() on Runtime and inspect the
log.

This change makes it possible to ask for the trace when running
a select query.  The Runtime.select() now either returns a singleton
if tracing is False (like always) or (answer, trace) if tracing is
true.  This ensures the change is backwards compatible.

Closes-bug: 1356626
Change-Id: I5a67ddbdf4cb4d000fdc78b0d6192eb284f9abb1
",git fetch https://review.opendev.org/openstack/congress refs/changes/90/113590/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/policy/tests/test_nonrecur.py', 'congress/policy/runtime.py']",2,3dcde4c2a9142dbd1706be4075a51eb73f93dbb1,trace,"import cStringIO self.funcs = [LOG.debug] # functions to call to trace for func in self.funcs: func(""{}{}"".format((""| "" * depth), msg)) class StringTracer(Tracer): def __init__(self): super(StringTracer, self).__init__() self.stream = cStringIO.StringIO() self.funcs.append(lambda x: self.stream.write(x + '\n')) def get_value(self): return self.stream.getvalue() def get_tracer(self): return self.tracer changes.extend(self.modify(event)) if isinstance(tracer, Tracer): self.tracer = tracer self.database.tracer = tracer self.delta_rules.tracer = tracer else: self.tracer = tracer['self'] self.database.tracer = tracer['database'] self.delta_rules.tracer = tracer['delta_rules'] def get_tracer(self): return {'self': self.tracer, 'database': self.database.tracer, 'delta_rules': self.delta_rules.tracer} if isinstance(tracer, Tracer): self.tracer = tracer for th in self.theory: self.theory[th].set_tracer(tracer) else: self.tracer = tracer[0] for th, tracr in tracer[1].items(): if th in self.theory: self.theory[th].set_tracer(tracr) def get_tracer(self): """"""Return (Runtime's tracer, dict of tracers for each theory). Useful so we can temporarily change tracing. """""" d = {} for th in self.theory: d[th] = self.theory[th].get_tracer() return (self.tracer, d) def select(self, query, target=None, trace=False): return self.select_string(query, self.get_target(target), trace) elif isinstance(query, tuple): return self.select_tuple(query, self.get_target(target), trace) else: return self.select_obj(query, self.get_target(target), trace) def select_string(self, policy_string, theory, trace): results = self.select_obj(policy[0], theory, trace) if trace: return (compile.formulas_to_string(results[0]), results[1]) else: return compile.formulas_to_string(results) def select_tuple(self, tuple, theory, trace): return self.select_obj(compile.Literal.create_from_iter(tuple), theory, trace) def select_obj(self, query, theory, trace): if trace: old_tracer = self.get_tracer() tracer = StringTracer() # still LOG.debugs trace tracer.trace('*') # trace everything self.set_tracer(tracer) value = theory.select(query) self.set_tracer(old_tracer) return (value, tracer.get_value())"," LOG.debug(""{}{}"".format((""| "" * depth), msg)) changes.extend(self.modify( event.formula, event.insert, event.proofs)) self.tracer = tracer self.database.tracer = tracer self.delta_rules.tracer = tracer self.tracer = tracer for th in self.theory: self.theory[th].set_tracer(tracer) def select(self, query, target=None): return self.select_string(query, self.get_target(target)) elif isinstance(query, tuple): return self.select_tuple(query, self.get_target(target)) else: return self.select_obj(query, self.get_target(target)) def select_string(self, policy_string, theory): results = self.select_obj(policy[0], theory) return compile.formulas_to_string(results) def select_tuple(self, tuple, theory): return self.select_obj(compile.Literal.create_from_iter(tuple), theory) def select_obj(self, query, theory):",96,22
openstack%2Fpuppet-glance~stable%2Fhavana~Ibe503b24ae3bfa10944537d5deaa068a01eaa5f3,openstack/puppet-glance,stable/havana,Ibe503b24ae3bfa10944537d5deaa068a01eaa5f3,Fixes wrong values in get_glance_image_attrs,MERGED,2014-05-16 17:54:32.000000000,2014-08-15 22:24:49.000000000,2014-08-15 22:24:49.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 7462}, {'_account_id': 7822}, {'_account_id': 8482}]","[{'number': 1, 'created': '2014-05-16 17:54:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/19a420f6abe43526f7f3c06993aa507f0c38d178', 'message': 'Fixes wrong values in get_glance_image_attrs (BACKPORT)\n\nThe output of the glance show command in get_glance_image_attrs\ndoes not get properly converted while being added to the\nattrs array.\n\nChange-Id: Ibe503b24ae3bfa10944537d5deaa068a01eaa5f3\nCloses-Bug: #1199513\n'}, {'number': 2, 'created': '2014-08-06 19:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/8f40b176f3574750c9b003c221ddc14e39c84f83', 'message': 'Fixes wrong values in get_glance_image_attrs\n\nThe output of the glance show command in get_glance_image_attrs\ndoes not get properly converted while being added to the\nattrs array.\n\nChange-Id: Ibe503b24ae3bfa10944537d5deaa068a01eaa5f3\nCloses-Bug: #1199513\n(cherry picked from commit 0adbbcf9f44367cb840c8786b05c35c63d7d2f41)\n'}, {'number': 3, 'created': '2014-08-07 11:45:21.000000000', 'files': ['lib/puppet/provider/glance.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/15780880b0476e5a80eff0b85268ccd139ac5d46', 'message': 'Fixes wrong values in get_glance_image_attrs\n\nThe output of the glance show command in get_glance_image_attrs\ndoes not get properly converted while being added to the\nattrs array.\n\nChange-Id: Ibe503b24ae3bfa10944537d5deaa068a01eaa5f3\nCloses-Bug: #1199513\n(cherry picked from commit 0adbbcf9f44367cb840c8786b05c35c63d7d2f41)\n'}]",0,93977,15780880b0476e5a80eff0b85268ccd139ac5d46,23,6,3,7462,,,0,"Fixes wrong values in get_glance_image_attrs

The output of the glance show command in get_glance_image_attrs
does not get properly converted while being added to the
attrs array.

Change-Id: Ibe503b24ae3bfa10944537d5deaa068a01eaa5f3
Closes-Bug: #1199513
(cherry picked from commit 0adbbcf9f44367cb840c8786b05c35c63d7d2f41)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/77/93977/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/glance.rb'],1,19a420f6abe43526f7f3c06993aa507f0c38d178,bug/1199513, attrs[line.split(': ').first.downcase] = line.split(': ')[1..-1].pop, attrs[line.split(': ').first.downcase] = line.split(': ')[1..-1].to_s,1,1
openstack%2Fcongress~master~Icb60d6067b6aa092720592a2632accc5a7e6e6bd,openstack/congress,master,Icb60d6067b6aa092720592a2632accc5a7e6e6bd,Spin up all configured services at startup,MERGED,2014-08-14 23:01:19.000000000,2014-08-15 22:23:59.000000000,2014-08-15 22:23:59.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 12875}]","[{'number': 1, 'created': '2014-08-14 23:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/393e3bfe7508738f2498ec2e57c7107229508736', 'message': ""Spin up all configured services at startup\n\nPreviously, a service wasn't spun up until there was a policy statement\nthat utilized a table from that service.  This made it hard to for users\nto understand which services were available to them.\n\nThis change spins up all configured services at startup.\n\nChange-Id: Icb60d6067b6aa092720592a2632accc5a7e6e6bd\n""}, {'number': 2, 'created': '2014-08-14 23:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/22dbe150ddd4c9701293966eb8ac3fa9be87cd61', 'message': ""Spin up all configured services at startup\n\nPreviously, a service wasn't spun up until there was a policy statement\nthat utilized a table from that service.  This made it hard to for users\nto understand which services were available to them.\n\nThis change spins up all configured services at startup.\n\nCloses-bug: 1357121\nChange-Id: Icb60d6067b6aa092720592a2632accc5a7e6e6bd\n""}, {'number': 3, 'created': '2014-08-15 19:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/ee7bc236bcba7386083c2b87851a45143803fb5f', 'message': ""Spin up all configured services at startup\n\nPreviously, a service wasn't spun up until there was a policy statement\nthat utilized a table from that service.  This made it hard to for users\nto understand which services were available to them.\n\nThis change spins up all configured services at startup.\n\nCloses-bug: 1357121\nChange-Id: Icb60d6067b6aa092720592a2632accc5a7e6e6bd\n""}, {'number': 4, 'created': '2014-08-15 21:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/e75a89ef6cfc77c2cf8a1711018c20d454deda38', 'message': ""Spin up all configured services at startup\n\nPreviously, a service wasn't spun up until there was a policy statement\nthat utilized a table from that service.  This made it hard to for users\nto understand which services were available to them.\n\nThis change spins up all configured services at startup.\n\nCloses-bug: 1357121\nChange-Id: Icb60d6067b6aa092720592a2632accc5a7e6e6bd\n""}, {'number': 5, 'created': '2014-08-15 21:22:34.000000000', 'files': ['congress/tests/test_congress.py', 'congress/harness.py', 'congress/tests/helper.py', 'congress/policy/dsepolicy.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/c5efd0f6cf2ad07f8192168845abc4fc9ef95259', 'message': ""Spin up all configured services at startup\n\nPreviously, a service wasn't spun up until there was a policy statement\nthat utilized a table from that service.  This made it hard to for users\nto understand which services were available to them.\n\nThis change spins up all configured services at startup.\n\nCloses-bug: 1357121\nChange-Id: Icb60d6067b6aa092720592a2632accc5a7e6e6bd\n""}]",4,114386,c5efd0f6cf2ad07f8192168845abc4fc9ef95259,25,5,5,8215,,,0,"Spin up all configured services at startup

Previously, a service wasn't spun up until there was a policy statement
that utilized a table from that service.  This made it hard to for users
to understand which services were available to them.

This change spins up all configured services at startup.

Closes-bug: 1357121
Change-Id: Icb60d6067b6aa092720592a2632accc5a7e6e6bd
",git fetch https://review.opendev.org/openstack/congress refs/changes/86/114386/3 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/test_congress.py', 'congress/harness.py', 'congress/service.py', 'congress/tests/helper.py', 'congress/policy/dsepolicy.py']",5,393e3bfe7508738f2498ec2e57c7107229508736,trace,,"import os import re import sys from congress.datasources.datasource_driver import DataSourceConfigException self.load_data_service(service) def load_data_service(self, service_name): """"""Load the service called SERVICE_NAME, if it has not already been loaded. Also loads module if that has not already been loaded. """""" # TODO(thinrichs): Move all this functionality to a different # component whose responsibility is spinning these up, # checking they are still alive, restarting, reporting status, etc. # Probably d6cage (or a subclass of it). if self.d6cage is None: # policy engine is running without ability to create services return if service_name in self.d6cage.services: return if service_name not in self.d6cage.config: raise DataSourceConfigException( ""Service %s used in rule but not configured; "" ""tables will be empty"" % service_name) service_config = self.d6cage.config[service_name] if 'module' not in service_config: raise DataSourceConfigException( ""Service %s config missing 'module' entry"" % service_name) module_path = service_config['module'] module_name = re.sub('[^a-zA-Z0-9_]', '_', module_path) if not os.path.isabs(module_path) and self.rootdir is not None: module_path = os.path.join(self.rootdir, module_path) if module_name not in sys.modules: self.log(""Trying to create module {} from {}"".format( module_name, module_path)) self.d6cage.loadModule(module_name, module_path) self.log(""Trying to create service {} with module {}"".format( service_name, module_name)) self.d6cage.createservice(name=service_name, moduleName=module_name, args=service_config) ",143,145
openstack%2Fsahara~master~I099425fc58e33d47a0a4424a9e16753f7cde064a,openstack/sahara,master,I099425fc58e33d47a0a4424a9e16753f7cde064a,Fix parsing dfsreport for CDH in integration tests,MERGED,2014-08-07 09:35:29.000000000,2014-08-15 21:24:23.000000000,2014-08-15 21:24:23.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-08-07 09:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d02592df3a223d0c90430a50eca50300ab844c79', 'message': 'Fix parsing dfsreport for CDH in integration tests\n\nChange-Id: I099425fc58e33d47a0a4424a9e16753f7cde064a\nCloses-bug: #1352325\n'}, {'number': 2, 'created': '2014-08-08 12:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0e65fc2a26cce5827a5278a4c4c2125c761d47d1', 'message': 'Fix parsing dfsreport for CDH in integration tests\n\nChange-Id: I099425fc58e33d47a0a4424a9e16753f7cde064a\nCloses-bug: #1352325\n'}, {'number': 3, 'created': '2014-08-08 14:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/35fc2df1b0a3b247039c7a89fd029a7ba29f72c6', 'message': 'Fix parsing dfsreport for CDH in integration tests\n\nChange-Id: I099425fc58e33d47a0a4424a9e16753f7cde064a\nCloses-bug: #1352325\n'}, {'number': 4, 'created': '2014-08-14 12:08:02.000000000', 'files': ['sahara/tests/integration/tests/base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/3d5b2d0088423eeb1dbe482e99f6bdb293cfb3fc', 'message': 'Fix parsing dfsreport for CDH in integration tests\n\nChange-Id: I099425fc58e33d47a0a4424a9e16753f7cde064a\nCloses-bug: #1352325\n'}]",2,112534,3d5b2d0088423eeb1dbe482e99f6bdb293cfb3fc,74,9,4,7710,,,0,"Fix parsing dfsreport for CDH in integration tests

Change-Id: I099425fc58e33d47a0a4424a9e16753f7cde064a
Closes-bug: #1352325
",git fetch https://review.opendev.org/openstack/sahara refs/changes/34/112534/3 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/integration/tests/base.py'],1,d02592df3a223d0c90430a50eca50300ab844c79,fix-cdh-dfsreport," try: active_tasktracker_count = int( active_tasktracker_count) except ValueError: active_tasktracker_count = -1 'grep -e ""Datanodes available:.*"" ' '-e ""Live datanodes.*"" | grep -o ""[0-9]*"" | head -1' try: active_datanode_count = int(active_datanode_count) except ValueError: active_tasktracker_count = -1"," active_tasktracker_count = int(active_tasktracker_count) 'grep ""Datanodes available:.*"" | awk \'{print $3}\'' active_datanode_count = int(active_datanode_count)",12,3
openstack%2Fnova~master~I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29,openstack/nova,master,I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29,Pull transfer module unit tests from glance tests,MERGED,2014-07-28 02:07:40.000000000,2014-08-15 21:09:24.000000000,2014-08-15 20:00:05.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-28 02:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc8c6b893044ca13fc479b4b3ece761b1cdab9a5', 'message': ""Pull transfer module unit tests from glance tests\n\nSeparates the unit tests of the file transfer download module (the only\none that is implemented in nova.image.download) out into its own unit\ntest file test_transfer_modules.py out of test_glance.py. In the\nprocess, properly limited the unit test boundaries of the transfer module\nunit tests to just the tranfer module class' download() method, instead\nof testing all the way through the GlanceImageService class\nunnecessarily (since that is already tested thoroughly in\ntest_glance.py). As an added benefit, the unit tests of the download and\ntransfer module stuff went from around 4 seconds to less than a\nquarter-second for all the tests.\n\nChange-Id: I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29\n""}, {'number': 2, 'created': '2014-08-07 15:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd390b6c57228b7a6d28fa4b270c6fb5e4a9cc88', 'message': ""Pull transfer module unit tests from glance tests\n\nSeparates the unit tests of the file transfer download module (the only\none that is implemented in nova.image.download) out into its own unit\ntest file test_transfer_modules.py out of test_glance.py. In the\nprocess, properly limited the unit test boundaries of the transfer module\nunit tests to just the tranfer module class' download() method, instead\nof testing all the way through the GlanceImageService class\nunnecessarily (since that is already tested thoroughly in\ntest_glance.py). As an added benefit, the unit tests of the download and\ntransfer module stuff went from around 4 seconds to less than a\nquarter-second for all the tests.\n\nChange-Id: I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29\n""}, {'number': 3, 'created': '2014-08-07 17:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/377b9b8f227d91d67b83ca867a9e1c2952c13d01', 'message': ""Pull transfer module unit tests from glance tests\n\nSeparates the unit tests of the file transfer download module (the only\none that is implemented in nova.image.download) out into its own unit\ntest file test_transfer_modules.py out of test_glance.py. In the\nprocess, properly limited the unit test boundaries of the transfer module\nunit tests to just the tranfer module class' download() method, instead\nof testing all the way through the GlanceImageService class\nunnecessarily (since that is already tested thoroughly in\ntest_glance.py). As an added benefit, the unit tests of the download and\ntransfer module stuff went from around 4 seconds to less than a\nquarter-second for all the tests.\n\nChange-Id: I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29\n""}, {'number': 4, 'created': '2014-08-08 14:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6fc81630ac03f14346390fe91d290b08c6e4fa8a', 'message': ""Pull transfer module unit tests from glance tests\n\nSeparates the unit tests of the file transfer download module (the only\none that is implemented in nova.image.download) out into its own unit\ntest file test_transfer_modules.py out of test_glance.py. In the\nprocess, properly limited the unit test boundaries of the transfer module\nunit tests to just the tranfer module class' download() method, instead\nof testing all the way through the GlanceImageService class\nunnecessarily (since that is already tested thoroughly in\ntest_glance.py). As an added benefit, the unit tests of the download and\ntransfer module stuff went from around 4 seconds to less than a\nquarter-second for all the tests.\n\nChange-Id: I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29\n""}, {'number': 5, 'created': '2014-08-08 21:04:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae14af82c6e4f3696bd3015803b4a2bfdcb28d06', 'message': ""Pull transfer module unit tests from glance tests\n\nSeparates the unit tests of the file transfer download module (the only\none that is implemented in nova.image.download) out into its own unit\ntest file test_transfer_modules.py out of test_glance.py. In the\nprocess, properly limited the unit test boundaries of the transfer module\nunit tests to just the tranfer module class' download() method, instead\nof testing all the way through the GlanceImageService class\nunnecessarily (since that is already tested thoroughly in\ntest_glance.py). As an added benefit, the unit tests of the download and\ntransfer module stuff went from around 4 seconds to less than a\nquarter-second for all the tests.\n\nChange-Id: I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29\n""}, {'number': 6, 'created': '2014-08-09 16:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b8730f9c93cae8f0c713768280844abc6bb6af4', 'message': ""Pull transfer module unit tests from glance tests\n\nSeparates the unit tests of the file transfer download module (the only\none that is implemented in nova.image.download) out into its own unit\ntest file test_transfer_modules.py out of test_glance.py. In the\nprocess, properly limited the unit test boundaries of the transfer module\nunit tests to just the tranfer module class' download() method, instead\nof testing all the way through the GlanceImageService class\nunnecessarily (since that is already tested thoroughly in\ntest_glance.py). As an added benefit, the unit tests of the download and\ntransfer module stuff went from around 4 seconds to less than a\nquarter-second for all the tests.\n\nChange-Id: I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29\n""}, {'number': 7, 'created': '2014-08-12 18:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/511b675865f65a3d8fdf64df1abcb44e87ad1c92', 'message': ""Pull transfer module unit tests from glance tests\n\nSeparates the unit tests of the file transfer download module (the only\none that is implemented in nova.image.download) out into its own unit\ntest file test_transfer_modules.py out of test_glance.py. In the\nprocess, properly limited the unit test boundaries of the transfer module\nunit tests to just the transfer module class' download() method, instead\nof testing all the way through the GlanceImageService class\nunnecessarily (since that is already tested thoroughly in\ntest_glance.py). As an added benefit, the unit tests of the download and\ntransfer module stuff went from around 4 seconds to less than a\nquarter-second for all the tests.\n\nChange-Id: I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29\n""}, {'number': 8, 'created': '2014-08-13 02:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b24f95343259a3843908aa209dce1f766b52f19', 'message': ""Pull transfer module unit tests from glance tests\n\nSeparates the unit tests of the file transfer download module (the only\none that is implemented in nova.image.download) out into its own unit\ntest file test_transfer_modules.py out of test_glance.py. In the\nprocess, properly limited the unit test boundaries of the transfer module\nunit tests to just the transfer module class' download() method, instead\nof testing all the way through the GlanceImageService class\nunnecessarily (since that is already tested thoroughly in\ntest_glance.py). As an added benefit, the unit tests of the download and\ntransfer module stuff went from around 4 seconds to less than a\nquarter-second for all the tests.\n\nChange-Id: I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29\n""}, {'number': 9, 'created': '2014-08-15 16:20:29.000000000', 'files': ['nova/tests/image/test_transfer_modules.py', 'nova/tests/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cc5254bf483e1efea969ad0948a226a3ec270495', 'message': ""Pull transfer module unit tests from glance tests\n\nSeparates the unit tests of the file transfer download module (the only\none that is implemented in nova.image.download) out into its own unit\ntest file test_transfer_modules.py out of test_glance.py. In the\nprocess, properly limited the unit test boundaries of the transfer module\nunit tests to just the transfer module class' download() method, instead\nof testing all the way through the GlanceImageService class\nunnecessarily (since that is already tested thoroughly in\ntest_glance.py). As an added benefit, the unit tests of the download and\ntransfer module stuff went from around 4 seconds to less than a\nquarter-second for all the tests.\n\nChange-Id: I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29\n""}]",2,109894,cc5254bf483e1efea969ad0948a226a3ec270495,73,10,9,7,,,0,"Pull transfer module unit tests from glance tests

Separates the unit tests of the file transfer download module (the only
one that is implemented in nova.image.download) out into its own unit
test file test_transfer_modules.py out of test_glance.py. In the
process, properly limited the unit test boundaries of the transfer module
unit tests to just the transfer module class' download() method, instead
of testing all the way through the GlanceImageService class
unnecessarily (since that is already tested thoroughly in
test_glance.py). As an added benefit, the unit tests of the download and
transfer module stuff went from around 4 seconds to less than a
quarter-second for all the tests.

Change-Id: I2ff6e31359d343b78dc4d03cf2beafd8a99b0a29
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/109894/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/image/test_transfer_modules.py', 'nova/tests/image/test_glance.py']",2,fc8c6b893044ca13fc479b4b3ece761b1cdab9a5,bye-bye-image-service-stubs,"class TestDownloadNoDirectUri(test.NoDBTestCase): """"""Tests the download method of the GlanceImageService when the default of not allowing direct URI transfers is set. @mock.patch('__builtin__.open') @mock.patch('nova.image.glance._get_locations') def test_download_no_data_no_dest_path(self, get_loc_mock, open_mock): client = mock.MagicMock() client.call.return_value = mock.sentinel.image_chunks ctx = mock.sentinel.ctx service = glance.GlanceImageService(client) res = service.download(ctx, mock.sentinel.image_id) self.assertFalse(get_loc_mock.called) self.assertFalse(open_mock.called) client.call.assert_called_once_with(ctx, 1, 'data', mock.sentinel.image_id) self.assertEqual(mock.sentinel.image_chunks, res) @mock.patch('__builtin__.open') @mock.patch('nova.image.glance._get_locations') def test_download_data_no_dest_path(self, get_loc_mock, open_mock): client = mock.MagicMock() client.call.return_value = [1, 2, 3] ctx = mock.sentinel.ctx data = mock.MagicMock() service = glance.GlanceImageService(client) res = service.download(ctx, mock.sentinel.image_id, data=data) self.assertFalse(get_loc_mock.called) self.assertFalse(open_mock.called) client.call.assert_called_once_with(ctx, 1, 'data', mock.sentinel.image_id) self.assertIsNone(res) data.write.assert_has_calls( [ mock.call(1), mock.call(2), mock.call(3) ] ) self.assertFalse(data.close.called) @mock.patch('__builtin__.open') @mock.patch('nova.image.glance._get_locations') def test_download_no_data_dest_path(self, get_loc_mock, open_mock): client = mock.MagicMock() client.call.return_value = [1, 2, 3] ctx = mock.sentinel.ctx writer = mock.MagicMock() open_mock.return_value = writer service = glance.GlanceImageService(client) res = service.download(ctx, mock.sentinel.image_id, dst_path=mock.sentinel.dst_path) self.assertFalse(get_loc_mock.called) client.call.assert_called_once_with(ctx, 1, 'data', mock.sentinel.image_id) open_mock.assert_called_once_with(mock.sentinel.dst_path, 'wb') self.assertIsNone(res) writer.write.assert_has_calls( [ mock.call(1), mock.call(2), mock.call(3) ] ) writer.close.assert_called_once_with() @mock.patch('__builtin__.open') @mock.patch('nova.image.glance._get_locations') def test_download_data_dest_path(self, get_loc_mock, open_mock): # NOTE(jaypipes): This really shouldn't be allowed, but because of the # horrible design of the download() method in GlanceImageService, no # error is raised, and the dst_path is ignored... # #TODO(jaypipes): Fix the aforementioned horrible design of # the download() method. client = mock.MagicMock() client.call.return_value = [1, 2, 3] ctx = mock.sentinel.ctx data = mock.MagicMock() service = glance.GlanceImageService(client) res = service.download(ctx, mock.sentinel.image_id, data=data) self.assertFalse(get_loc_mock.called) self.assertFalse(open_mock.called) client.call.assert_called_once_with(ctx, 1, 'data', mock.sentinel.image_id) self.assertIsNone(res) data.write.assert_has_calls( [ mock.call(1), mock.call(2), mock.call(3) ] ) self.assertFalse(data.close.called) class TestDownloadDirectUri(test.NoDBTestCase): """"""Tests the download method of the GlanceImageService when direct URI transfers are allowed. """""" @mock.patch('nova.image.glance.GlanceImageService._get_transfer_module') @mock.patch('nova.image.glance._get_locations') def test_download_direct_file_uri(self, get_loc_mock, get_tran_mock): get_loc_mock.return_value = [ { 'url': 'file:///files/image', 'metadata': mock.sentinel.loc_meta } ] tran_mod = mock.MagicMock() get_tran_mock.return_value = tran_mod client = mock.MagicMock() ctx = mock.sentinel.ctx service = glance.GlanceImageService(client) res = service.download(ctx, mock.sentinel.image_id, dst_path=mock.sentinel.dst_path) self.assertIsNone(res) self.assertFalse(client.call.called) get_loc_mock.assert_called_once_with(client, ctx, mock.sentinel.image_id) get_tran_mock.assert_called_once_with('file') tran_mod.download.assert_called_once_with(ctx, mock.ANY, mock.sentinel.dst_path, mock.sentinel.loc_meta) @mock.patch('__builtin__.open') @mock.patch('nova.image.glance.GlanceImageService._get_transfer_module') @mock.patch('nova.image.glance._get_locations') def test_download_direct_exception_fallback(self, get_loc_mock, get_tran_mock, open_mock): # Test that we fall back to downloading to the dst_path # if the download method of the transfer module raised # an exception. get_loc_mock.return_value = [ { 'url': 'file:///files/image', 'metadata': mock.sentinel.loc_meta } ] tran_mod = mock.MagicMock() tran_mod.download.side_effect = Exception get_tran_mock.return_value = tran_mod client = mock.MagicMock() client.call.return_value = [1, 2, 3] ctx = mock.sentinel.ctx writer = mock.MagicMock() open_mock.return_value = writer service = glance.GlanceImageService(client) res = service.download(ctx, mock.sentinel.image_id, dst_path=mock.sentinel.dst_path) self.assertIsNone(res) get_loc_mock.assert_called_once_with(client, ctx, mock.sentinel.image_id) get_tran_mock.assert_called_once_with('file') tran_mod.download.assert_called_once_with(ctx, mock.ANY, mock.sentinel.dst_path, mock.sentinel.loc_meta) client.call.assert_called_once_with(ctx, 1, 'data', mock.sentinel.image_id) # NOTE(jaypipes): log messages call open() in part of the # download path, so here, we just check that the last open() # call was done for the dst_path file descriptor. open_mock.assert_called_with(mock.sentinel.dst_path, 'wb') self.assertIsNone(res) writer.write.assert_has_calls( [ mock.call(1), mock.call(2), mock.call(3) ] ) writer.close.assert_called_once_with() @mock.patch('__builtin__.open') @mock.patch('nova.image.glance.GlanceImageService._get_transfer_module') @mock.patch('nova.image.glance._get_locations') def test_download_direct_no_mode_fallback(self, get_loc_mock, get_tran_mock, open_mock): # Test that we fall back to downloading to the dst_path # if no appropriate transfer module is found... # an exception. self.flags(allowed_direct_url_schemes=['funky'], group='glance') get_loc_mock.return_value = [ { 'url': 'file:///files/image', 'metadata': mock.sentinel.loc_meta } ] get_tran_mock.return_value = None client = mock.MagicMock() client.call.return_value = [1, 2, 3] ctx = mock.sentinel.ctx writer = mock.MagicMock() open_mock.return_value = writer service = glance.GlanceImageService(client) res = service.download(ctx, mock.sentinel.image_id, dst_path=mock.sentinel.dst_path) self.assertIsNone(res) get_loc_mock.assert_called_once_with(client, ctx, mock.sentinel.image_id) get_tran_mock.assert_called_once_with('file') client.call.assert_called_once_with(ctx, 1, 'data', mock.sentinel.image_id) # NOTE(jaypipes): log messages call open() in part of the # download path, so here, we just check that the last open() # call was done for the dst_path file descriptor. open_mock.assert_called_with(mock.sentinel.dst_path, 'wb') self.assertIsNone(res) writer.write.assert_has_calls( [ mock.call(1), mock.call(2), mock.call(3) ] ) writer.close.assert_called_once_with()","import filecmp import osimport tempfileimport moxfrom nova.tests.api.openstack import fakesimport nova.virt.libvirt.utils as lv_utilsclass NullWriter(object): """"""Used to test ImageService.get which takes a writer object."""""" def write(self, *arg, **kwargs): pass class TestGlanceImageService(test.NoDBTestCase): """"""Tests the Glance image service. At a high level, the translations involved are: 1. Glance -> ImageService - This is needed so we can support multple ImageServices (Glance, Local, etc) 2. ImageService -> API - This is needed so we can support multple APIs (OpenStack, EC2) def setUp(self): super(TestGlanceImageService, self).setUp() fakes.stub_out_compute_api_snapshot(self.stubs) self.client = glance_stubs.StubGlanceClient() self.service = self._create_image_service(self.client) self.context = context.RequestContext('fake', 'fake', auth_token=True) self.mox = mox.Mox() self.files_to_clean = [] def tearDown(self): super(TestGlanceImageService, self).tearDown() self.mox.UnsetStubs() for f in self.files_to_clean: try: os.unlink(f) except os.error: pass def _get_tempfile(self): (outfd, config_filename) = tempfile.mkstemp(prefix='nova_glance_tests') self.files_to_clean.append(config_filename) return (outfd, config_filename) def _create_image_service(self, client): def _fake_create_glance_client(context, host, port, use_ssl, version): return client self.stubs.Set(glance, '_create_glance_client', _fake_create_glance_client) client_wrapper = glance.GlanceClientWrapper( 'fake', 'fake_host', 9292) return glance.GlanceImageService(client=client_wrapper) def test_download_with_retries(self): tries = [0] class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that fails the first time, then succeeds."""""" def get(self, image_id): if tries[0] == 0: tries[0] = 1 raise glanceclient.exc.ServiceUnavailable('') else: return {} client = MyGlanceStubClient() service = self._create_image_service(client) image_id = 1 # doesn't matter writer = NullWriter() # When retries are disabled, we should get an exception self.flags(num_retries=0, group='glance') self.assertRaises(exception.GlanceConnectionFailed, service.download, self.context, image_id, data=writer) # Now lets enable retries. No exception should happen now. tries = [0] self.flags(num_retries=1, group='glance') service.download(self.context, image_id, data=writer) def test_download_file_url(self): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that returns a file url."""""" (outfd, s_tmpfname) = tempfile.mkstemp(prefix='directURLsrc') outf = os.fdopen(outfd, 'w') inf = open('/dev/urandom', 'r') for i in range(10): _data = inf.read(1024) outf.write(_data) outf.close() def get(self, image_id): return type('GlanceTestDirectUrlMeta', (object,), {'direct_url': 'file://%s' + self.s_tmpfname}) client = MyGlanceStubClient() (outfd, tmpfname) = tempfile.mkstemp(prefix='directURLdst') os.close(outfd) service = self._create_image_service(client) image_id = 1 # doesn't matter service.download(self.context, image_id, dst_path=tmpfname) # compare the two files rc = filecmp.cmp(tmpfname, client.s_tmpfname) self.assertTrue(rc, ""The file %s and %s should be the same"" % (tmpfname, client.s_tmpfname)) os.remove(client.s_tmpfname) os.remove(tmpfname) def test_download_module_filesystem_match(self): mountpoint = '/' fs_id = 'someid' desc = {'id': fs_id, 'mountpoint': mountpoint} class MyGlanceStubClient(glance_stubs.StubGlanceClient): outer_test = self def get(self, image_id): return type('GlanceLocations', (object,), {'locations': [ {'url': 'file:///' + os.devnull, 'metadata': desc}]}) def data(self, image_id): self.outer_test.fail('This should not be called because the ' 'transfer module should have intercepted ' 'it.') self.mox.StubOutWithMock(lv_utils, 'copy_image') image_id = 1 # doesn't matter client = MyGlanceStubClient() self.flags(group='image_file_url', filesystems=['gluster']) service = self._create_image_service(client) # NOTE(Jbresnah) The following options must be added after the module # has added the specific groups. self.flags(group='image_file_url:gluster', id=fs_id) self.flags(group='image_file_url:gluster', mountpoint=mountpoint) dest_file = os.devnull lv_utils.copy_image(mox.IgnoreArg(), dest_file) self.mox.ReplayAll() service.download(self.context, image_id, dst_path=dest_file) self.mox.VerifyAll() def test_download_module_no_filesystem_match(self): mountpoint = '/' fs_id = 'someid' desc = {'id': fs_id, 'mountpoint': mountpoint} some_data = ""sfxvdwjer"" class MyGlanceStubClient(glance_stubs.StubGlanceClient): outer_test = self def get(self, image_id): return type('GlanceLocations', (object,), {'locations': [ {'url': 'file:///' + os.devnull, 'metadata': desc}]}) def data(self, image_id): return some_data def _fake_copyfile(source, dest): self.fail('This should not be called because a match should not ' 'have been found.') self.stubs.Set(lv_utils, 'copy_image', _fake_copyfile) image_id = 1 # doesn't matter client = MyGlanceStubClient() self.flags(allowed_direct_url_schemes=['file'], group='glance') self.flags(group='image_file_url', filesystems=['gluster']) service = self._create_image_service(client) # NOTE(Jbresnah) The following options must be added after the module # has added the specific groups. self.flags(group='image_file_url:gluster', id='someotherid') self.flags(group='image_file_url:gluster', mountpoint=mountpoint) service.download(self.context, image_id, dst_path=os.devnull, data=None) def test_download_module_mountpoints(self): glance_mount = '/glance/mount/point' _, data_filename = self._get_tempfile() nova_mount = os.path.dirname(data_filename) source_path = os.path.basename(data_filename) file_url = 'file://%s' % os.path.join(glance_mount, source_path) file_system_id = 'test_FS_ID' file_system_desc = {'id': file_system_id, 'mountpoint': glance_mount} class MyGlanceStubClient(glance_stubs.StubGlanceClient): outer_test = self def get(self, image_id): return type('GlanceLocations', (object,), {'locations': [{'url': file_url, 'metadata': file_system_desc}]}) def data(self, image_id): self.outer_test.fail('This should not be called because the ' 'transfer module should have intercepted ' 'it.') self.copy_called = False def _fake_copyfile(source, dest): self.assertEqual(source, data_filename) self.copy_called = True self.stubs.Set(lv_utils, 'copy_image', _fake_copyfile) self.flags(allowed_direct_url_schemes=['file'], group='glance') self.flags(group='image_file_url', filesystems=['gluster']) image_id = 1 # doesn't matter client = MyGlanceStubClient() service = self._create_image_service(client) self.flags(group='image_file_url:gluster', id=file_system_id) self.flags(group='image_file_url:gluster', mountpoint=nova_mount) service.download(self.context, image_id, dst_path=os.devnull) self.assertTrue(self.copy_called) def test_download_module_file_bad_module(self): _, data_filename = self._get_tempfile() file_url = 'applesauce://%s' % data_filename class MyGlanceStubClient(glance_stubs.StubGlanceClient): data_called = False def get(self, image_id): return type('GlanceLocations', (object,), {'locations': [{'url': file_url, 'metadata': {}}]}) def data(self, image_id): self.data_called = True return ""someData"" self.flags(allowed_direct_url_schemes=['applesauce'], group='glance') self.mox.StubOutWithMock(lv_utils, 'copy_image') self.flags(allowed_direct_url_schemes=['file'], group='glance') image_id = 1 # doesn't matter client = MyGlanceStubClient() service = self._create_image_service(client) # by not calling copyfileobj in the file download module we verify # that the requirements were not met for its use self.mox.ReplayAll() service.download(self.context, image_id, dst_path=os.devnull) self.mox.VerifyAll() self.assertTrue(client.data_called)",310,248
openstack%2Fcongress~master~If756a7a805eaff5666fe7498fceb89d1603b37e9,openstack/congress,master,If756a7a805eaff5666fe7498fceb89d1603b37e9,API: Pass query parameters to DataModels,MERGED,2014-08-14 20:52:16.000000000,2014-08-15 20:38:48.000000000,2014-08-15 19:56:46.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 12875}]","[{'number': 1, 'created': '2014-08-14 20:52:16.000000000', 'files': ['congress/tests/api/test_webservice.py', 'congress/tests/test_congress.py', 'congress/api/webservice.py', 'congress/api/datasource_model.py', 'congress/api/table_model.py', 'congress/api/policy_model.py', 'congress/api/row_model.py', 'congress/api/rule_model.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/ff763493672ae5572b4e7be7f2048c83c0318041', 'message': 'API: Pass query parameters to DataModels\n\nQuery parameters in the API request are now exposed to the underlying\ndata model for consideration.\n\nCloses-Bug: #1357074\nChange-Id: If756a7a805eaff5666fe7498fceb89d1603b37e9\n'}]",2,114350,ff763493672ae5572b4e7be7f2048c83c0318041,10,4,1,9253,,,0,"API: Pass query parameters to DataModels

Query parameters in the API request are now exposed to the underlying
data model for consideration.

Closes-Bug: #1357074
Change-Id: If756a7a805eaff5666fe7498fceb89d1603b37e9
",git fetch https://review.opendev.org/openstack/congress refs/changes/50/114350/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/api/test_webservice.py', 'congress/tests/test_congress.py', 'congress/api/datasource_model.py', 'congress/api/webservice.py', 'congress/api/table_model.py', 'congress/api/policy_model.py', 'congress/api/row_model.py', 'congress/api/rule_model.py']",8,ff763493672ae5572b4e7be7f2048c83c0318041,," def get_item(self, id_, params, context=None): params: A dict-like object containing parameters from the request query string and body. def get_items(self, params, context=None): params: A dict-like object containing parameters from the request query string and body. def add_item(self, item, params, id_=None, context=None): params: A dict-like object containing parameters from the request query string and body. def delete_item(self, id_, params, context=None): params: A dict-like object containing parameters from the request query string and body. item = self.get_item(id_, params, context)"," def get_item(self, id_, context=None): def get_items(self, context=None): def add_item(self, item, id_=None, context=None): def delete_item(self, id_, context=None): item = self.get_item(id_, context)",96,61
openstack%2Ftripleo-specs~master~I144e627465d4a28ad692c14c03c1ec6387ef1f86,openstack/tripleo-specs,master,I144e627465d4a28ad692c14c03c1ec6387ef1f86,Tweak HAProxy spec to deal with mixed services.,MERGED,2014-07-18 10:18:48.000000000,2014-08-15 20:33:01.000000000,2014-08-15 20:33:01.000000000,"[{'_account_id': 3}, {'_account_id': 1605}, {'_account_id': 4190}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7582}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-07-18 10:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/4e8ebd0a4cef0a25c102d6cf586e886f614171fd', 'message': ""Tweak HAProxy spec to deal with mixed services.\n\nTurns out we didn't dig deep enough when designing it.\n\nChange-Id: I144e627465d4a28ad692c14c03c1ec6387ef1f86\n""}, {'number': 2, 'created': '2014-07-20 05:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/50d0e8d232f6adc0731aec72b578a14d5625f334', 'message': ""Tweak HAProxy spec to deal with mixed services.\n\nTurns out we didn't dig deep enough when designing it.\n\nChange-Id: I144e627465d4a28ad692c14c03c1ec6387ef1f86\n""}, {'number': 3, 'created': '2014-07-25 07:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/5a032ec4bd1e0bfb02d7c3fd15be52e55fb49823', 'message': ""Tweak HAProxy spec to deal with mixed services.\n\nTurns out we didn't dig deep enough when designing it.\n\nChange-Id: I144e627465d4a28ad692c14c03c1ec6387ef1f86\n""}, {'number': 4, 'created': '2014-08-02 01:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/2a5d5bba44cc53a1616321598ea3f21e2537fa6d', 'message': ""Tweak HAProxy spec to deal with mixed services.\n\nTurns out we didn't dig deep enough when designing it.\n\nChange-Id: I144e627465d4a28ad692c14c03c1ec6387ef1f86\n""}, {'number': 5, 'created': '2014-08-10 23:42:58.000000000', 'files': ['specs/juno/haproxy_configuration.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/2cc5b31b545f3d7e52264e2e203a110c755645b0', 'message': ""Tweak HAProxy spec to deal with mixed services.\n\nTurns out we didn't dig deep enough when designing it.\n\nChange-Id: I144e627465d4a28ad692c14c03c1ec6387ef1f86\n""}]",14,107956,2cc5b31b545f3d7e52264e2e203a110c755645b0,42,8,5,4190,,,0,"Tweak HAProxy spec to deal with mixed services.

Turns out we didn't dig deep enough when designing it.

Change-Id: I144e627465d4a28ad692c14c03c1ec6387ef1f86
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/56/107956/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/haproxy_configuration.rst'],1,4e8ebd0a4cef0a25c102d6cf586e886f614171fd,tweak-haproxy," in the case where we want to run that service on SSL only.We will bind haproxy, stunnel (ssl), openstack services on same ports with different ipaddress settings. HAProxy will be bound to VIP addresses only. STunnel where it is use will be bound to the controller ctlplane address. OpenStack services will bind to localhost for SSL only configurations, and to the ctlplane address for non-SSL or mixed-mode configurations. We'll strive to make SSL-only the default. An example, using horizon in mixed mode (HTTPS and HTTP): An example, using horizon in mixed mode (HTTPS and HTTP) listen horizon_http bind vip_address:80 listen horizon_https bind vip_address:443 server node_1 node_address:443 accept node_address:443 connect node_address:80 3. horizon bind node_address:80 A second example, using horizon in HTTPS only mode: vip_address = 192.0.2.21 node_address = 192.0.2.24 1. haproxy bind vip_address:80 An example, using horizon in mixed mode (HTTPS and HTTP) listen horizon_https bind vip_address:443 server node_1 node_address:443 2. stunnel accept node_address:443* Only ssl protected endpoints are publicly available if running SSL only.We need to make the service configs - nova etc - know on a per service basis where to bind. The current approach uses logic in the template to choose between localhost and my_ip. If we move the selection into Heat this can become a lot simpler (read a bind address, if set use it, if not don't). Alternatively we could extend the connect_ip concept to be on a per service basis. Right now all services are exposed to both SSL and plain, so this is workable until we get a situation where only some services are plain. ","The most convenient setup in my opinion, and also fits nicely in current code (requires minor refactoring), is to bind haproxy, stunnel (ssl), openstack services on same ports with different ipaddress settings. In case of using stunnel: bind vip_address:443 listen horizon accept node_address:80* Only ssl protected endpoints are publicly available",50,9
openstack%2Fheat~master~I2bd857492d2fca7f3683f7b7a6b062e3dddcbeed,openstack/heat,master,I2bd857492d2fca7f3683f7b7a6b062e3dddcbeed,Fix DBError output in test logs,MERGED,2014-08-11 15:23:25.000000000,2014-08-15 20:30:29.000000000,2014-08-15 20:30:28.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-08-11 15:23:25.000000000', 'files': ['heat/tests/test_engine_service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2fa305a3d3292a88e0729dddcb92a59026118780', 'message': 'Fix DBError output in test logs\n\nAfter patch If48ba9d3deb54f8e9ea1ed1987f832ddbaed33fc a (non-fatal) DBError\nis displayed during unit tests run.\nThis patch fixes that by proper mocking (and stops mixing mock and mox\nin single unit test).\n\nChange-Id: I2bd857492d2fca7f3683f7b7a6b062e3dddcbeed\n'}]",1,113288,2fa305a3d3292a88e0729dddcb92a59026118780,13,4,1,9542,,,0,"Fix DBError output in test logs

After patch If48ba9d3deb54f8e9ea1ed1987f832ddbaed33fc a (non-fatal) DBError
is displayed during unit tests run.
This patch fixes that by proper mocking (and stops mixing mock and mox
in single unit test).

Change-Id: I2bd857492d2fca7f3683f7b7a6b062e3dddcbeed
",git fetch https://review.opendev.org/openstack/heat refs/changes/88/113288/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_engine_service.py'],1,2fa305a3d3292a88e0729dddcb92a59026118780,fix/test-delete-same-engine," self.m.StubOutWithMock(self.man.thread_group_mgr, 'stop') self.man.thread_group_mgr.stop(stack.id).AndReturn(None) self.assertIsNone(self.man.delete_stack(self.ctx, stack.identifier()))"," with mock.patch.object(self.man.thread_group_mgr, 'stop', side_effect=self.man.thread_group_mgr.stop ) as stop_mock: self.assertIsNone(self.man.delete_stack(self.ctx, stack.identifier())) self.assertEqual(1, stop_mock.call_count) self.assertEqual((stack.id,), stop_mock.call_args[0]) ",3,10
openstack%2Ftripleo-heat-templates~master~I9b91e5dbf18810a11389b96232461ae44849f6ec,openstack/tripleo-heat-templates,master,I9b91e5dbf18810a11389b96232461ae44849f6ec,Revert migration to HOT,ABANDONED,2014-08-11 00:35:54.000000000,2014-08-15 20:19:18.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 4257}, {'_account_id': 4571}]","[{'number': 1, 'created': '2014-08-11 00:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/61a5a6bba8ef9ba34c77f27a9f76e52225c0dc20', 'message': ""Revert migration to HOT\n\nThe migration doesn't work when updating deployed clouds that were non-HOT, and\nHeat doesn't yet test this case (nor do we have tests of this case). As such,\nthis is an API break and we can't release like this.\n\nThis reverts commits beca15dec5265783047d5df210b270ed3d77dd4b and\n02772ba2877b9f6d427c6fd760bf19d6334c68a8 and fixes up changes landed since\nthen.\n\nChange-Id: I9b91e5dbf18810a11389b96232461ae44849f6ec\n""}, {'number': 2, 'created': '2014-08-12 23:17:01.000000000', 'files': ['examples/source_hot.yaml', 'undercloud-vm-nova-config.yaml', 'examples/scale_map_hot.yaml', 'examples/scale_map_result_hot.yaml', 'undercloud-bm-nova-deploy.yaml', 'controller.yaml', 'Makefile', 'undercloud-vm-ironic-config.yaml', 'examples/source_lib_result_hot.yaml', 'nagios3.yaml', 'undercloud-source.yaml', 'undercloud-bm-nova-config.yaml', 'nova-compute-config.yaml', 'nova-compute-instance.yaml', 'swift-storage-source.yaml', 'undercloud-vm-nova-deploy.yaml', 'debian-mirror.yaml', 'examples/launchconfig1_hot.yaml', 'block-storage.yaml', 'examples/source_include_subkey_hot.yaml', 'examples/scale1_hot.yaml', 'examples/launchconfig2_hot.yaml', 'examples/scale_result_hot.yaml', 'block-storage-nfs.yaml', 'nfs-server-source.yaml', 'tripleo_heat_merge/merge.py', 'ssl-source.yaml', 'base.yaml', 'overcloud-source.yaml', 'undercloud-vm-ironic-deploy.yaml', 'swift-deploy.yaml', 'examples/source2_lib_result_hot.yaml', 'swift-source.yaml', 'examples/launchconfig_result_hot.yaml', 'examples/source_include_subkey_result_hot.yaml', 'examples/scale2_hot.yaml', 'examples/scale_map2_hot.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/389c31d12752f03d802eb6d1c1b923fb310b2509', 'message': ""Revert migration to HOT\n\nThe migration doesn't work when updating deployed clouds that were non-HOT, and\nHeat doesn't yet test this case (nor do we have tests of this case). As such,\nthis is an API break and we can't release like this.\n\nThis reverts commits beca15dec5265783047d5df210b270ed3d77dd4b and\n02772ba2877b9f6d427c6fd760bf19d6334c68a8 and fixes up changes landed since\nthen.\n\nChange-Id: I9b91e5dbf18810a11389b96232461ae44849f6ec\nRelated-Bug: 1356097\n""}]",0,113154,389c31d12752f03d802eb6d1c1b923fb310b2509,12,4,2,4190,,,0,"Revert migration to HOT

The migration doesn't work when updating deployed clouds that were non-HOT, and
Heat doesn't yet test this case (nor do we have tests of this case). As such,
this is an API break and we can't release like this.

This reverts commits beca15dec5265783047d5df210b270ed3d77dd4b and
02772ba2877b9f6d427c6fd760bf19d6334c68a8 and fixes up changes landed since
then.

Change-Id: I9b91e5dbf18810a11389b96232461ae44849f6ec
Related-Bug: 1356097
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/54/113154/1 && git format-patch -1 --stdout FETCH_HEAD,"['examples/source_hot.yaml', 'undercloud-vm-nova-config.yaml', 'examples/scale_map_hot.yaml', 'examples/scale_map_result_hot.yaml', 'undercloud-bm-nova-deploy.yaml', 'controller.yaml', 'Makefile', 'undercloud-vm-ironic-config.yaml', 'examples/source_lib_result_hot.yaml', 'nagios3.yaml', 'undercloud-source.yaml', 'undercloud-bm-nova-config.yaml', 'nova-compute-config.yaml', 'nova-compute-instance.yaml', 'swift-storage-source.yaml', 'undercloud-vm-nova-deploy.yaml', 'debian-mirror.yaml', 'examples/launchconfig1_hot.yaml', 'block-storage.yaml', 'examples/source_include_subkey_hot.yaml', 'examples/scale1_hot.yaml', 'examples/launchconfig2_hot.yaml', 'examples/scale_result_hot.yaml', 'block-storage-nfs.yaml', 'nfs-server-source.yaml', 'tripleo_heat_merge/merge.py', 'ssl-source.yaml', 'base.yaml', 'overcloud-source.yaml', 'undercloud-vm-ironic-deploy.yaml', 'swift-deploy.yaml', 'examples/source2_lib_result_hot.yaml', 'swift-source.yaml', 'examples/launchconfig_result_hot.yaml', 'examples/source_include_subkey_result_hot.yaml', 'examples/scale2_hot.yaml', 'examples/scale_map2_hot.yaml']",37,61a5a6bba8ef9ba34c77f27a9f76e52225c0dc20,bug-1356097,heat_template_version: 2013-05-23,heat_template_version: 2014-10-16,1390,1257
openstack%2Fcongress~master~Ie8614fc984f14b1f8a1a3b8280581bf4d54a48f7,openstack/congress,master,Ie8614fc984f14b1f8a1a3b8280581bf4d54a48f7,Made policy_path optional,MERGED,2014-07-31 21:08:19.000000000,2014-08-15 20:15:42.000000000,2014-08-15 20:15:42.000000000,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-07-31 21:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/1de05fa86418b2b8be09bbe7a021ae8e9597f6b6', 'message': 'Made policy_path optional\n\nPreviously, when launching Congress we needed to give an absolute\npathname to the chunk of policies we wanted initially loaded.\nOne of those policies includes configuration data about the datasource\ndrivers, without which Congress does not run.\n\nThis change ensures that if a policy_path is not provided,\nthe default is congress/etc/snapshot.\n\nChange-Id: Ie8614fc984f14b1f8a1a3b8280581bf4d54a48f7\n'}, {'number': 2, 'created': '2014-08-05 21:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/8646f06a051a87fd8264e9ad73031a2fa4a0def7', 'message': 'Made policy_path optional\n\nPreviously, when launching Congress we needed to give an absolute\npathname to the chunk of policies we wanted initially loaded.\nOne of those policies includes configuration data about the datasource\ndrivers, without which Congress does not run.\n\nThis change ensures that if a policy_path is not provided,\nthe default is congress/etc/snapshot.\n\nChange-Id: Ie8614fc984f14b1f8a1a3b8280581bf4d54a48f7\n'}, {'number': 3, 'created': '2014-08-14 23:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/db7cfba5d3b170baa03df819c6314ae429b2aff7', 'message': 'Made policy_path optional\n\nPreviously, when launching Congress we needed to give an absolute\npathname to the chunk of policies we wanted initially loaded.\nOne of those policies includes configuration data about the datasource\ndrivers, without which Congress does not run.\n\nThis change ensures that if a policy_path is not provided,\nthe default is congress/etc/snapshot.\n\nChange-Id: Ie8614fc984f14b1f8a1a3b8280581bf4d54a48f7\n'}, {'number': 4, 'created': '2014-08-15 19:32:59.000000000', 'files': ['congress/server/dseserver.py', 'congress/service.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/96aacc0181e005be0fa493122b488f417c8440bd', 'message': 'Made policy_path optional\n\nPreviously, when launching Congress we needed to give an absolute\npathname to the chunk of policies we wanted initially loaded.\nOne of those policies includes configuration data about the datasource\ndrivers, without which Congress does not run.\n\nThis change ensures that if a policy_path is not provided,\nthe default is congress/etc/snapshot.\n\nChange-Id: Ie8614fc984f14b1f8a1a3b8280581bf4d54a48f7\n'}]",9,111086,96aacc0181e005be0fa493122b488f417c8440bd,29,5,4,8215,,,0,"Made policy_path optional

Previously, when launching Congress we needed to give an absolute
pathname to the chunk of policies we wanted initially loaded.
One of those policies includes configuration data about the datasource
drivers, without which Congress does not run.

This change ensures that if a policy_path is not provided,
the default is congress/etc/snapshot.

Change-Id: Ie8614fc984f14b1f8a1a3b8280581bf4d54a48f7
",git fetch https://review.opendev.org/openstack/congress refs/changes/86/111086/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/server/congress_server.py', 'etc/congress.conf.sample']",2,1de05fa86418b2b8be09bbe7a021ae8e9597f6b6,bug/1357121,# policy_path = '/Users/thinrichs/congress/congress/tests/snapshot',policy_path = '/Users/thinrichs/congress/congress/tests/snapshot',4,2
openstack%2Fcongress~master~I0fc4274c452ff91663eded7828dc8d8679935b4e,openstack/congress,master,I0fc4274c452ff91663eded7828dc8d8679935b4e,Added per-datasource configuration,MERGED,2014-08-13 22:41:43.000000000,2014-08-15 20:15:25.000000000,2014-08-15 20:15:24.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 12669}]","[{'number': 1, 'created': '2014-08-13 22:41:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/fd64ac75ea1c821db0230491cb16f75aa12d6b7b', 'message': 'Added per-datasource configuration\n\nPreviously, all datasources had the same username/password/tenant\nconfiguration information.  Additionally, the name to module mapping\nwas stored in a different place (but each data source could have\na different module).\n\nThis change puts all of the configuration information for datasources\ninto a single file, and enables the configuration information to\nbe different for each datasource.\n\nChange-Id: I0fc4274c452ff91663eded7828dc8d8679935b4e\n'}, {'number': 2, 'created': '2014-08-13 22:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/c6b90bcb8899e3b2348da71dcefc0443fb78dd39', 'message': 'Added per-datasource configuration\n\nPreviously, all datasources had the same username/password/tenant\nconfiguration information.  Additionally, the name to module mapping\nwas stored in a different place (but each data source could have\na different module).\n\nThis change puts all of the configuration information for datasources\ninto a single file, and enables the configuration information to\nbe different for each datasource.\n\nCloses-bug: #1356615\nChange-Id: I0fc4274c452ff91663eded7828dc8d8679935b4e\n'}, {'number': 3, 'created': '2014-08-14 17:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/2e9ee8f3201d5bfab3deddb099525460a3bae69c', 'message': 'Added per-datasource configuration\n\nPreviously, all datasources had the same username/password/tenant\nconfiguration information.  Additionally, the name to module mapping\nwas stored in a different place (but each data source could have\na different module).\n\nThis change puts all of the configuration information for datasources\ninto a single file, and enables the configuration information to\nbe different for each datasource.\n\nCloses-bug: #1356615\nChange-Id: I0fc4274c452ff91663eded7828dc8d8679935b4e\n'}, {'number': 4, 'created': '2014-08-14 23:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/4b20f50b26c7367e7a3915df1f5d083838f8816d', 'message': 'Added per-datasource configuration\n\nPreviously, all datasources had the same username/password/tenant\nconfiguration information.  Additionally, the name to module mapping\nwas stored in a different place (but each data source could have\na different module).\n\nThis change puts all of the configuration information for datasources\ninto a single file, and enables the configuration information to\nbe different for each datasource.\n\nCloses-bug: #1356615\nChange-Id: I0fc4274c452ff91663eded7828dc8d8679935b4e\n'}, {'number': 5, 'created': '2014-08-15 19:32:59.000000000', 'files': ['congress/common/config.py', 'congress/dse/tests/test_dse.py', 'congress/service.py', 'congress/tests/helper.py', 'congress/datasources/neutron_driver.py', 'congress/datasources/datasource_driver.py', 'congress/policy/dsepolicy.py', 'congress/tests/test_congress.py', 'congress/datasources/tests/unit/test_neutron_driver.py', 'congress/tests/datasources.conf', 'etc/datasources.conf.sample', 'congress/harness.py', 'congress/dse/d6cage.py', 'congress/datasources/tests/unit/test_nova_driver.py', 'congress/datasources/test_driver.py', 'congress/datasources/nova_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/f5b3209e39fb238ab73edfaa40fbdefa1ebaa8bf', 'message': 'Added per-datasource configuration\n\nPreviously, all datasources had the same username/password/tenant\nconfiguration information.  Additionally, the name to module mapping\nwas stored in a different place (but each data source could have\na different module).\n\nThis change puts all of the configuration information for datasources\ninto a single file, and enables the configuration information to\nbe different for each datasource.\n\nCloses-bug: #1356615\nChange-Id: I0fc4274c452ff91663eded7828dc8d8679935b4e\n'}]",22,114049,f5b3209e39fb238ab73edfaa40fbdefa1ebaa8bf,24,5,5,8215,,,0,"Added per-datasource configuration

Previously, all datasources had the same username/password/tenant
configuration information.  Additionally, the name to module mapping
was stored in a different place (but each data source could have
a different module).

This change puts all of the configuration information for datasources
into a single file, and enables the configuration information to
be different for each datasource.

Closes-bug: #1356615
Change-Id: I0fc4274c452ff91663eded7828dc8d8679935b4e
",git fetch https://review.opendev.org/openstack/congress refs/changes/49/114049/5 && git format-patch -1 --stdout FETCH_HEAD,"['congress/dse/tests/test_dse.py', 'congress/tests/helper.py', 'congress/datasources/neutron_driver.py', 'congress/datasources/datasource_driver.py', 'congress/policy/dsepolicy.py', 'congress/tests/test_congress.py', 'congress/datasources/tests/unit/test_neutron_driver.py', 'congress/tests/datasources.conf', 'etc/datasources.conf.sample', 'congress/harness.py', 'congress/dse/d6cage.py', 'congress/datasources/tests/unit/test_nova_driver.py', 'congress/datasources/test_driver.py', 'congress/datasources/nova_driver.py']",14,fd64ac75ea1c821db0230491cb16f75aa12d6b7b,bug/1357121," return NovaDriver(name, keys, inbox, datapath, args) def __init__(self, name='', keys='', inbox=None, datapath=None, args=None): if args is None: args = self._empty_openstack_credentials() super(NovaDriver, self).__init__(name, keys, inbox, datapath, args) if 'client' in args: self.neutron = args['client'] else: self.creds = self.get_nova_credentials_v2(name, args) self.nova_client = novaclient.client.Client(**self.creds) def get_nova_credentials_v2(self, name, args): creds = self._get_openstack_credentials(name, args) d['username'] = creds['username'] d['api_key'] = creds['password'] d['auth_url'] = creds['auth_url'] d['project_id'] = creds['tenant_name']","from congress.datasources.settings import OS_USERNAME, \ OS_PASSWORD, OS_AUTH_URL, OS_TENANT_NAME if 'client' in args: client = args['client'] del args['client'] else: client = None if 'poll_time' in args: poll_time = args['poll_time'] del args['poll_time'] else: poll_time = None return NovaDriver(name, keys, inbox=inbox, datapath=datapath, client=client, poll_time=poll_time, **args) USERNAME = OS_USERNAME PASSWORD = OS_PASSWORD AUTH_URL = OS_AUTH_URL TENANT_NAME = OS_TENANT_NAME def __init__(self, name='', keys='', inbox=None, datapath=None, client=None, poll_time=None, **creds): super(NovaDriver, self).__init__(name, keys, inbox=inbox, datapath=datapath, poll_time=poll_time, **creds) credentials = self.get_nova_credentials_v2() if client is None: self.nova_client = novaclient.client.Client(**credentials) else: self.nova_client = client self.state = {} def get_nova_credentials_v2(self): d['username'] = self.USERNAME d['api_key'] = self.PASSWORD d['auth_url'] = self.AUTH_URL d['project_id'] = self.TENANT_NAME",232,160
openstack%2Ftraining-guides~master~I5306b855f0736d3e6a00761c514b4a031f167ead,openstack/training-guides,master,I5306b855f0736d3e6a00761c514b4a031f167ead,labs: fix multiattach disks,MERGED,2014-08-15 12:38:50.000000000,2014-08-15 20:08:17.000000000,2014-08-15 20:08:16.000000000,"[{'_account_id': 3}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-08-15 12:38:50.000000000', 'files': ['labs/lib/osbash/virtualbox.functions'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/da34a77939cf75e15cd9217b823932aaebeae6b8', 'message': 'labs: fix multiattach disks\n\nWhen using VBoxMange storageattach with the ""--mtype multiattach""\noption, the command fails if another VM is already attached (via\nmultiattach) and running at the time of the call. If the option\nis left out, the new VM has its disk multiattached as desired.\n\nRather than trying to find out when to use the option, this patch uses\nmodifyhd to register a disk as type multiattach. This call does not fail\nif made several times for the same disk, and all subsequent\nstorageattach calls for that disk have the multiattach option\nautomatically set.\n\nChange-Id: I5306b855f0736d3e6a00761c514b4a031f167ead\nImplements: blueprint openstack-training-labs\n'}]",0,114524,da34a77939cf75e15cd9217b823932aaebeae6b8,7,2,1,11109,,,0,"labs: fix multiattach disks

When using VBoxMange storageattach with the ""--mtype multiattach""
option, the command fails if another VM is already attached (via
multiattach) and running at the time of the call. If the option
is left out, the new VM has its disk multiattached as desired.

Rather than trying to find out when to use the option, this patch uses
modifyhd to register a disk as type multiattach. This call does not fail
if made several times for the same disk, and all subsequent
storageattach calls for that disk have the multiattach option
automatically set.

Change-Id: I5306b855f0736d3e6a00761c514b4a031f167ead
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/24/114524/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/lib/osbash/virtualbox.functions'],1,da34a77939cf75e15cd9217b823932aaebeae6b8,bp/openstack-training-labs," $VBM modifyhd --type multiattach ""$DISK"" --medium ""$DISK"""," --medium ""$DISK"" \ --mtype multiattach",4,2
openstack%2Ftraining-guides~master~I9c260cb600d7bfcba8f18252d8116c7473a10839,openstack/training-guides,master,I9c260cb600d7bfcba8f18252d8116c7473a10839,labs: allow building individual nodes,MERGED,2014-08-14 20:11:58.000000000,2014-08-15 20:06:16.000000000,2014-08-15 20:06:15.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-14 20:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/27d40f5d2c55c07e18f8a468f4c2cacdd0587f6c', 'message': 'labs: allow building individual nodes\n\nSo far, osbash can build either a basedisk or a cluster consisting of\nthree nodes (controller, compute, network).\n\nWith this patch, the user can choose to (re-)build only a single node.\nFor instance, ""osbash.sh compute"" will build only the compute node\nwhile leaving controller and network nodes intact (if they exist).\n\nNote that this patch is currently for testing purposes only, because\nfor it to work, we would have to to work around a VirtualBox bug in\nthe multiattach disks osbash uses right now.\n\nChange-Id: I9c260cb600d7bfcba8f18252d8116c7473a10839\nImplements: blueprint openstack-training-labs\n'}, {'number': 2, 'created': '2014-08-15 12:40:20.000000000', 'files': ['labs/osbash.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/92ca8c180d27a2b2008d2b33366769acf2af1937', 'message': 'labs: allow building individual nodes\n\nSo far, osbash can build either a basedisk or a cluster consisting of\nthree nodes (controller, compute, network).\n\nWith this patch, the user can choose to (re-)build only a single node.\nFor instance, ""osbash.sh compute"" will build only the compute node\nwhile leaving controller and network nodes intact (if they exist).\n\nChange-Id: I9c260cb600d7bfcba8f18252d8116c7473a10839\nImplements: blueprint openstack-training-labs\n'}]",0,114330,92ca8c180d27a2b2008d2b33366769acf2af1937,11,3,2,11109,,,0,"labs: allow building individual nodes

So far, osbash can build either a basedisk or a cluster consisting of
three nodes (controller, compute, network).

With this patch, the user can choose to (re-)build only a single node.
For instance, ""osbash.sh compute"" will build only the compute node
while leaving controller and network nodes intact (if they exist).

Change-Id: I9c260cb600d7bfcba8f18252d8116c7473a10839
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/30/114330/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/osbash.sh'],1,27d40f5d2c55c07e18f8a468f4c2cacdd0587f6c,bp/openstack-training-labs," if [ ""$CMD"" = cluster ]; then nodes=""controller compute network"" else nodes=""$CMD""for node in $nodes; do vm_build_node ""$node"" done"," if ! [[ $CMD =~ (basedisk|cluster) ]]; then usagevm_build_node ""controller"" vm_build_node ""network"" vm_build_node ""compute""",7,5
openstack%2Ftripleo-heat-templates~master~I23f87511e59d4d3527403b1a81c1b3df65c6a904,openstack/tripleo-heat-templates,master,I23f87511e59d4d3527403b1a81c1b3df65c6a904,Use VIP for rabbit/keystone and mysql in block-storage.yaml,MERGED,2014-08-05 16:34:53.000000000,2014-08-15 20:02:04.000000000,2014-08-15 20:02:03.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}]","[{'number': 1, 'created': '2014-08-05 16:34:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b377820de1dc9ffb469afa60776b31b738b7b346', 'message': 'Use VIP for rabbit/keystone and mysql in block-storage.yaml\n\nPreviously BlockStorage nodes where using the controller ip instead\nof the virtual ip to reach rabbit, keystone and mysql.\n\nChange-Id: I23f87511e59d4d3527403b1a81c1b3df65c6a904\n'}, {'number': 2, 'created': '2014-08-06 16:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b1849e6254f5e4abf74ac51799ed7652d725f76', 'message': 'Use VIP for rabbit/keystone and mysql in block-storage.yaml\n\nPreviously BlockStorage nodes were using the controller ip instead\nof the virtual ip to reach rabbit, keystone and mysql.\n\nChange-Id: I23f87511e59d4d3527403b1a81c1b3df65c6a904\n'}, {'number': 3, 'created': '2014-08-14 16:20:06.000000000', 'files': ['block-storage.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c755d5548f23b25660517896de5264f1adb9ef28', 'message': 'Use VIP for rabbit/keystone and mysql in block-storage.yaml\n\nPreviously BlockStorage nodes were using the controller ip instead of the virtual ip to reach rabbit, keystone and mysql.\n\nChange-Id: I23f87511e59d4d3527403b1a81c1b3df65c6a904\n'}]",1,112069,c755d5548f23b25660517896de5264f1adb9ef28,35,5,3,6796,,,0,"Use VIP for rabbit/keystone and mysql in block-storage.yaml

Previously BlockStorage nodes were using the controller ip instead of the virtual ip to reach rabbit, keystone and mysql.

Change-Id: I23f87511e59d4d3527403b1a81c1b3df65c6a904
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/69/112069/1 && git format-patch -1 --stdout FETCH_HEAD,['block-storage.yaml'],1,b377820de1dc9ffb469afa60776b31b738b7b346,blockstoragescale_p5," controller_virtual_ip: {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]} cinder_dsn: {list_join: ['', ['mysql://cinder:unset@', {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]}, '/cinder']]} host: {get_input: controller_virtual_ip} host: {get_input: controller_virtual_ip}"," controller_host: {get_attr: [controller0, networks, ctlplane, 0]} cinder_dsn: {list_join: ['', ['mysql://cinder:unset@', {get_attr: [controller0, networks, ctlplane, 0]} , '/cinder']]} host: {get_input: controller_host} host: {get_input: controller_host}",4,4
openstack%2Ftripleo-heat-templates~master~Icc7d5ea0d91370ccdf7cb4742d052fea004bae44,openstack/tripleo-heat-templates,master,Icc7d5ea0d91370ccdf7cb4742d052fea004bae44,Remove unneeded neutron config parts from block-storage.yaml,MERGED,2014-08-05 16:30:25.000000000,2014-08-15 19:58:35.000000000,2014-08-15 19:58:34.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}]","[{'number': 1, 'created': '2014-08-05 16:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cdf7dfd00e978a18009b06f2afce23d56031ac9a', 'message': 'Remove unneeded neutron config parts from block-storage.yaml\n\nSome of the keys defined in block-storage.yaml for neutron and\npassed to the BlockStorage nodes were related to neutron, but\nBlockStorage nodes do not route instances traffic so do not need\nto be deployed with the OVS agent.\n\nChange-Id: Icc7d5ea0d91370ccdf7cb4742d052fea004bae44\n'}, {'number': 2, 'created': '2014-08-14 15:54:40.000000000', 'files': ['block-storage.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3af648f9df28eeb5ff83827860d90ae0735c00e9', 'message': 'Remove unneeded neutron config parts from block-storage.yaml\n\nSome of the keys defined in block-storage.yaml for neutron and\npassed to the BlockStorage nodes were related to neutron, but\nBlockStorage nodes do not route instances traffic so do not need\nto be deployed with the OVS agent.\n\nChange-Id: Icc7d5ea0d91370ccdf7cb4742d052fea004bae44\n'}]",0,112067,3af648f9df28eeb5ff83827860d90ae0735c00e9,35,5,2,6796,,,0,"Remove unneeded neutron config parts from block-storage.yaml

Some of the keys defined in block-storage.yaml for neutron and
passed to the BlockStorage nodes were related to neutron, but
BlockStorage nodes do not route instances traffic so do not need
to be deployed with the OVS agent.

Change-Id: Icc7d5ea0d91370ccdf7cb4742d052fea004bae44
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/67/112067/2 && git format-patch -1 --stdout FETCH_HEAD,['block-storage.yaml'],1,cdf7dfd00e978a18009b06f2afce23d56031ac9a,blockstoragescale_p4,," NeutronNetworkType: type: string default: 'gre' NeutronEnableTunnelling: type: string default: True neutron_local_ip: {get_attr: [BlockStorage0 , networks, ctlplane, 0]} interfaces: control: {get_param: NeutronPublicInterface} neutron: ovs: local_ip: {get_input: neutron_local_ip} tenant_network_type: {get_param: NeutronNetworkType} enable_tunneling: {get_param: NeutronEnableTunnelling} service-password: get_param: NeutronPassword",0,16
openstack%2Fneutron~master~I92f177af0e2a2fbc460e0d668989ce590b7d1cb2,openstack/neutron,master,I92f177af0e2a2fbc460e0d668989ce590b7d1cb2,Raise exception for network delete with subnets presents,MERGED,2014-08-01 17:48:29.000000000,2014-08-15 19:47:29.000000000,2014-08-13 01:36:44.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6785}, {'_account_id': 7018}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10068}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11269}]","[{'number': 1, 'created': '2014-08-01 17:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b41ba16ebd12127f06271debc26b2d7cb441dd79', 'message': 'Raise exception for network delete with subnets presents\n\nN1kv plugin should raise an exception during network delete\nif there is a subnet that is tied to that network.\n\nChange-Id: I92f177af0e2a2fbc460e0d668989ce590b7d1cb2\nCloses-Bug: 1336107\n'}, {'number': 2, 'created': '2014-08-09 19:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f4303858028fb54f3efd33ca65ba52f9ed8d80b', 'message': 'Raise exception for network delete with subnets presents\n\nN1kv plugin should raise an exception during network delete\nif there is a subnet that is tied to that network.\n\nChange-Id: I92f177af0e2a2fbc460e0d668989ce590b7d1cb2\nCloses-Bug: 1336107\n'}, {'number': 3, 'created': '2014-08-12 19:03:47.000000000', 'files': ['neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/89fb8b633b1ae34d0b56d73ee115462f4acc9540', 'message': ""Raise exception for network delete with subnets presents\n\nN1kv plugin should raise an exception during network delete\nif there is a subnet that is tied to that network.\n\nChanged the order of the Assert arguments since now it's encoraged to have <expected_value, actual_value> now.\n\nChange-Id: I92f177af0e2a2fbc460e0d668989ce590b7d1cb2\nCloses-Bug: 1336107\n""}]",17,111349,89fb8b633b1ae34d0b56d73ee115462f4acc9540,67,23,3,11269,,,0,"Raise exception for network delete with subnets presents

N1kv plugin should raise an exception during network delete
if there is a subnet that is tied to that network.

Changed the order of the Assert arguments since now it's encoraged to have <expected_value, actual_value> now.

Change-Id: I92f177af0e2a2fbc460e0d668989ce590b7d1cb2
Closes-Bug: 1336107
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/111349/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py']",2,b41ba16ebd12127f06271debc26b2d7cb441dd79,bug/1336107," if network['subnets']: msg = _(""Cannot delete network '%s', "" ""delete the associated subnet first"") % network['name'] raise n_exc.InvalidInput(error_message=msg)",,174,0
openstack%2Fneutron~master~I4a8f9d49c1ebfce9004217b5b422981f042fa38c,openstack/neutron,master,I4a8f9d49c1ebfce9004217b5b422981f042fa38c,Adds gateway to static routes when available,ABANDONED,2014-06-03 11:53:40.000000000,2014-08-15 19:47:29.000000000,,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5170}, {'_account_id': 7020}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-06-03 11:53:40.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/50563c63c17bbf8b33e3dbb355479d23fbda0e6d', 'message': 'Adds gateway to static routes when available\n\nAccording to the RFC 3442:\n""DHCP server administrators should therefore configure their DHCP\n servers to send both a Router option and a Classless Static Routes\n option, and should specify the default router(s) both in the Router\n option and in the Classless Static Routes option.""\n\nThis change will modify the dhcp agent accordingly.\n\nChange-Id: I4a8f9d49c1ebfce9004217b5b422981f042fa38c\n'}]",0,97476,50563c63c17bbf8b33e3dbb355479d23fbda0e6d,19,14,1,7020,,,0,"Adds gateway to static routes when available

According to the RFC 3442:
""DHCP server administrators should therefore configure their DHCP
 servers to send both a Router option and a Classless Static Routes
 option, and should specify the default router(s) both in the Router
 option and in the Classless Static Routes option.""

This change will modify the dhcp agent accordingly.

Change-Id: I4a8f9d49c1ebfce9004217b5b422981f042fa38c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/97476/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py']",2,50563c63c17bbf8b33e3dbb355479d23fbda0e6d,,"tag:tag0,option:classless-static-route,20.0.0.1/24,20.0.0.1,0.0.0.0/0,192.168.0.1 tag:tag0,249,20.0.0.1/24,20.0.0.1,0.0.0.0/0,192.168.0.1tag:tag1,option:classless-static-route,%s,%s,0.0.0.0/0,fdca:3ba5:a17a:4ba3::1 tag:tag1,249,%s,%s,0.0.0.0/0,fdca:3ba5:a17a:4ba3::1"""""".lstrip() % (fake_v6,tag:tag1,option:classless-static-route,%s,%s,%s,%s,,0.0.0.0/0,fdca:3ba5:a17a:4ba3::1 tag:tag1,249,%s,%s,,0.0.0.0/0,fdca:3ba5:a17a:4ba3::1"""""".lstrip() % (fake_v6, ""0.0.0.0/0"", ""10.0.0.1"",","tag:tag0,option:classless-static-route,20.0.0.1/24,20.0.0.1 tag:tag0,249,20.0.0.1/24,20.0.0.1tag:tag1,option:classless-static-route,%s,%s tag:tag1,249,%s,%s"""""".lstrip() % (fake_v6,tag:tag1,option:classless-static-route,%s,%s tag:tag1,249,%s,%s"""""".lstrip() % (fake_v6,",9,6
openstack%2Fkeystone~master~Ic33011fa4c91c6afa392818b1d3011268710c824,openstack/keystone,master,Ic33011fa4c91c6afa392818b1d3011268710c824,Remote Debugging for HTTPD,ABANDONED,2014-07-23 19:11:13.000000000,2014-08-15 19:28:28.000000000,,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 12215}]","[{'number': 1, 'created': '2014-07-23 19:11:13.000000000', 'files': ['doc/source/developing.rst', 'keystone/common/config.py', 'httpd/keystone.py', 'keystone/common/utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3df37c912b9158f1b20375b407fc928e7e7b6eb4', 'message': 'Remote Debugging for HTTPD\n\nAdds file configuration options to enable remote debugging\nwhen running in apache.\n\nChange-Id: Ic33011fa4c91c6afa392818b1d3011268710c824\n'}]",16,109081,3df37c912b9158f1b20375b407fc928e7e7b6eb4,9,6,1,2218,,,0,"Remote Debugging for HTTPD

Adds file configuration options to enable remote debugging
when running in apache.

Change-Id: Ic33011fa4c91c6afa392818b1d3011268710c824
",git fetch https://review.opendev.org/openstack/keystone refs/changes/81/109081/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/developing.rst', 'keystone/common/config.py', 'httpd/keystone.py', 'keystone/common/utils.py']",4,3df37c912b9158f1b20375b407fc928e7e7b6eb4,," if (CONF.pydev_debug_host and CONF.pydev_debug_port) or \ (CONF.remote_debug_host and CONF.remote_debug_port): host = CONF.pydev_debug_host or CONF.remote_debug_host port = CONF.pydev_debug_port or CONF.remote_debug_port LOG.debug('Debugging host %s port %s' % (host, port)) pydevd.settrace(host, port=port, 'either the CLI option --debug-host and --debug-port or ' 'the file config remote_debug_host and remote_debug port ' 'values are set, and that these values match a remote machine ' 'with a debugger processes is listening on that port.'))"," if CONF.pydev_debug_host and CONF.pydev_debug_port: pydevd.settrace(CONF.pydev_debug_host, port=CONF.pydev_debug_port, 'option --debug-url has the format <host>:<port> and that a ' 'debugger processes is listening on that port.'))",65,6
openstack%2Fopenstacksdk~master~Iad5f485dd14e98d0371b8cea15ddaf339b84c338,openstack/openstacksdk,master,Iad5f485dd14e98d0371b8cea15ddaf339b84c338,Pass command line data into list example,ABANDONED,2014-08-14 19:42:12.000000000,2014-08-15 19:10:46.000000000,,"[{'_account_id': 3}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-14 19:42:12.000000000', 'files': ['examples/list.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2e61d370adfad7588aad72f0ac22dde3c41b8d76', 'message': 'Pass command line data into list example\n\nThis is necessary for listing the contents of specific containers in the\nObject Store API.\n\nChange-Id: Iad5f485dd14e98d0371b8cea15ddaf339b84c338\n'}]",1,114322,2e61d370adfad7588aad72f0ac22dde3c41b8d76,5,2,1,8257,,,0,"Pass command line data into list example

This is necessary for listing the contents of specific containers in the
Object Store API.

Change-Id: Iad5f485dd14e98d0371b8cea15ddaf339b84c338
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/22/114322/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/list.py'],1,2e61d370adfad7588aad72f0ac22dde3c41b8d76,list_example_data, data = common.get_data_option(opts) obj = cls.new(**data) for ob in obj.list(sess): print(str(ob)), for obj in cls.list(sess): print(str(obj)),4,2
openstack%2Fheat~master~I6e75a78b4d496e235f11ec3d94ee58a069ab5336,openstack/heat,master,I6e75a78b4d496e235f11ec3d94ee58a069ab5336,Template get_version breaks with Template object,MERGED,2014-08-01 17:46:57.000000000,2014-08-15 19:02:34.000000000,2014-08-15 19:02:33.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7404}, {'_account_id': 8435}, {'_account_id': 9165}, {'_account_id': 9542}, {'_account_id': 10487}, {'_account_id': 10856}, {'_account_id': 11599}]","[{'number': 1, 'created': '2014-08-01 17:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d80ba9831b5a90cd39c5f4bece89b9324b5b2eef', 'message': 'Template get_version expects dict\n\nThe get_version method on template expects a dict, breaking\nstack preview. This patch allows get_vesion to be passed\neither a dict or a Template\n\nChange-Id: I6e75a78b4d496e235f11ec3d94ee58a069ab5336\nCloses-bug: #1351005\n'}, {'number': 2, 'created': '2014-08-04 21:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f7cc6fcc677b98d623e29124320e546cb6a0a414', 'message': 'Template get_version breaks with Template object\n\nThe get_version method on template expects a dict, breaking\nstack preview. This patch allows get_version to be passed\neither a dict or a Template\n\nChange-Id: I6e75a78b4d496e235f11ec3d94ee58a069ab5336\nCloses-bug: #1351005\n'}, {'number': 3, 'created': '2014-08-05 17:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0e6cccc7eacf420a8801253143fc43799a28447d', 'message': 'Template get_version breaks with Template object\n\nThe get_version method on template expects a dict, breaking\nstack preview. This patch allows get_version to be passed\neither a dict or a Template\n\nChange-Id: I6e75a78b4d496e235f11ec3d94ee58a069ab5336\nCloses-bug: #1351005\n'}, {'number': 4, 'created': '2014-08-07 17:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ba3259ceaa36d39063b47a52ce9debb517bc163a', 'message': 'Template get_version breaks with Template object\n\nThe get_version method on template expects a dict, breaking\nstack preview. This patch allows get_version to be passed\neither a dict or a Template\n\nChange-Id: I6e75a78b4d496e235f11ec3d94ee58a069ab5336\nCloses-bug: #1351005\n'}, {'number': 5, 'created': '2014-08-09 01:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d72036b5ed9cd77e5de3014e6df80dc6dc52751c', 'message': 'Template get_version breaks with Template object\n\nThe get_version method on template expects a dict, breaking\nstack preview. This patch allows get_version to be passed\neither a dict or a Template\n\nChange-Id: I6e75a78b4d496e235f11ec3d94ee58a069ab5336\nCloses-bug: #1351005\n'}, {'number': 6, 'created': '2014-08-12 13:47:28.000000000', 'files': ['heat/engine/stack_resource.py', 'heat/tests/test_stack_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0fc185a962cbde1f5cb0de0fda8c4b15c2ba5eac', 'message': 'Template get_version breaks with Template object\n\nThe get_version method on template expects a dict, breaking\nstack preview. This patch modifies StackResource preview\nto always call the Template constructor with a dict\n\nChange-Id: I6e75a78b4d496e235f11ec3d94ee58a069ab5336\nCloses-bug: #1351005\n'}]",10,111348,0fc185a962cbde1f5cb0de0fda8c4b15c2ba5eac,60,16,6,8435,,,0,"Template get_version breaks with Template object

The get_version method on template expects a dict, breaking
stack preview. This patch modifies StackResource preview
to always call the Template constructor with a dict

Change-Id: I6e75a78b4d496e235f11ec3d94ee58a069ab5336
Closes-bug: #1351005
",git fetch https://review.opendev.org/openstack/heat refs/changes/48/111348/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/template.py', 'heat/tests/test_template.py']",2,d80ba9831b5a90cd39c5f4bece89b9324b5b2eef,bug/1351005," def test_with_template_instance(self): tmpl = { 'heat_template_version': '2013-05-23', 'foo': 'bar', 'parameters': {} } tmpl_i = template.Template(tmpl) self.assertEqual(('heat_template_version', '2013-05-23'), template.get_version(tmpl_i, self.versions)) ",,12,0
openstack%2Fcinder~master~I4e7d5fc7c66d8037f01efc47a4cf5e93d9dba662,openstack/cinder,master,I4e7d5fc7c66d8037f01efc47a4cf5e93d9dba662,Implement import/export for SolidFire Driver,MERGED,2014-07-17 00:12:49.000000000,2014-08-15 18:59:40.000000000,2014-08-15 18:59:39.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 7420}, {'_account_id': 8871}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12018}]","[{'number': 1, 'created': '2014-07-17 00:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d8ce06de90578332d22e4453b3bb6b375e16929', 'message': 'Implement import/export for SolidFire Driver\n\nThis adds the import/export (or manage) functioniality\nto the SolidFire driver.\n\nPartially Implements: blueprint add-export-import-volumes\n\nChange-Id: I4e7d5fc7c66d8037f01efc47a4cf5e93d9dba662\n'}, {'number': 2, 'created': '2014-07-17 01:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a271e4481234d496c6961ac6249f9d4cc2314048', 'message': 'Implement import/export for SolidFire Driver\n\nThis adds the import/export (or manage) functioniality\nto the SolidFire driver.\n\nPartially Implements: blueprint add-export-import-volumes\n\nChange-Id: I4e7d5fc7c66d8037f01efc47a4cf5e93d9dba662\n'}, {'number': 3, 'created': '2014-07-17 02:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0fa55df4dcc2875f6fe28929b3bc444147fd2e10', 'message': 'Implement import/export for SolidFire Driver\n\nThis adds the import/export (or manage) functioniality\nto the SolidFire driver.\n\nPartially Implements: blueprint add-export-import-volumes\n\nChange-Id: I4e7d5fc7c66d8037f01efc47a4cf5e93d9dba662\n'}, {'number': 4, 'created': '2014-07-17 18:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/17b2f6af0b91ba9b3bb5e44848b804e79a8db6a9', 'message': 'Implement import/export for SolidFire Driver\n\nThis adds the import/export (or manage) functioniality\nto the SolidFire driver.\n\nPartially Implements: blueprint add-export-import-volumes\n\nChange-Id: I4e7d5fc7c66d8037f01efc47a4cf5e93d9dba662\n'}, {'number': 5, 'created': '2014-07-24 05:38:53.000000000', 'files': ['cinder/volume/drivers/solidfire.py', 'cinder/tests/test_solidfire.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/59f0a4b91675f537af36c34930d00bba6f6eaa68', 'message': 'Implement import/export for SolidFire Driver\n\nThis adds the import/export (or manage) functioniality\nto the SolidFire driver.\n\nPartially Implements: blueprint add-export-import-volumes\n\nChange-Id: I4e7d5fc7c66d8037f01efc47a4cf5e93d9dba662\n'}]",16,107535,59f0a4b91675f537af36c34930d00bba6f6eaa68,55,14,5,2243,,,0,"Implement import/export for SolidFire Driver

This adds the import/export (or manage) functioniality
to the SolidFire driver.

Partially Implements: blueprint add-export-import-volumes

Change-Id: I4e7d5fc7c66d8037f01efc47a4cf5e93d9dba662
",git fetch https://review.opendev.org/openstack/cinder refs/changes/35/107535/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/solidfire.py', 'cinder/tests/test_solidfire.py']",2,6d8ce06de90578332d22e4453b3bb6b375e16929,bp/add-export-import-volumes," elif method is 'ListActiveVolumes': test_name = ""existing_volume"" result = {'result': { 'volumes': [{'volumeID': 5, 'name': test_name, 'accountID': 8, 'sliceCount': 1, 'totalSize': 1 * units.Gi, 'enable512e': True, 'access': ""readWrite"", 'status': ""active"", 'attributes': {}, 'qos': None, 'iqn': test_name}]}} return result def test_manage_existing_volume(self): external_ref = {'name': 'existing volume', 'id': 5} testvol = {'project_id': 'testprjid', 'name': 'testvol', 'size': 1, 'id': 'a720b3c0-d1f0-11e1-9b23-0800200c9a66', 'created_at': timeutils.utcnow()} self.stubs.Set(SolidFireDriver, '_issue_api_request', self.fake_issue_api_request) sfv = SolidFireDriver(configuration=self.configuration) sfv.manage_existing(external_ref, testvol)",,103,2
openstack%2Fnova~master~I6062f32ae906d958e808c8f1574e0c16b687d856,openstack/nova,master,I6062f32ae906d958e808c8f1574e0c16b687d856,Add a missing instance=instance in compute/mgr,MERGED,2014-07-17 23:49:41.000000000,2014-08-15 18:56:07.000000000,2014-08-13 01:53:23.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4190}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-17 23:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/871d238b75445d26aebd655142c2baeda893db5a', 'message': 'Add a missing instance=instance in compute/mgr\n\nThis can be logged without context at the moment, so we should really\ninclude the instance parameter as normal.\n\nChange-Id: I6062f32ae906d958e808c8f1574e0c16b687d856\n'}, {'number': 2, 'created': '2014-08-08 13:44:33.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cee35213783bcc25b6f1bc1dd48da7f40f547d94', 'message': 'Add a missing instance=instance in compute/mgr\n\nThis can be logged without context at the moment, so we should really\ninclude the instance parameter as normal.\n\nChange-Id: I6062f32ae906d958e808c8f1574e0c16b687d856\n'}]",2,107859,cee35213783bcc25b6f1bc1dd48da7f40f547d94,42,14,2,4190,,,0,"Add a missing instance=instance in compute/mgr

This can be logged without context at the moment, so we should really
include the instance parameter as normal.

Change-Id: I6062f32ae906d958e808c8f1574e0c16b687d856
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/107859/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,871d238b75445d26aebd655142c2baeda893db5a,lifeless," LOG.debug(""Retry info not present, will not reschedule"", instance=instance))"," LOG.debug(""Retry info not present, will not reschedule"")",2,1
openstack%2Fopenstack-manuals~master~I32bbfc1efc0ae2c719ef30e26442a9630876200a,openstack/openstack-manuals,master,I32bbfc1efc0ae2c719ef30e26442a9630876200a,fix the path to nova-compute.py for Hyper-V,MERGED,2014-08-12 10:47:00.000000000,2014-08-15 18:54:55.000000000,2014-08-15 18:54:54.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}]","[{'number': 1, 'created': '2014-08-12 10:47:00.000000000', 'files': ['doc/config-reference/compute/section_hypervisor_hyper-v.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2444626afffc323a9ae36ba5d8fc603d7c8e0e8a', 'message': 'fix the path to nova-compute.py for Hyper-V\n\nChange-Id: I32bbfc1efc0ae2c719ef30e26442a9630876200a\nCloses-Bug: 1288635\n'}]",0,113488,2444626afffc323a9ae36ba5d8fc603d7c8e0e8a,10,3,1,10497,,,0,"fix the path to nova-compute.py for Hyper-V

Change-Id: I32bbfc1efc0ae2c719ef30e26442a9630876200a
Closes-Bug: 1288635
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/88/113488/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_hypervisor_hyper-v.xml'],1,2444626afffc323a9ae36ba5d8fc603d7c8e0e8a,bug/1288635, <screen><prompt>C:\></prompt><userinput>C:\python27\python.exe c:\nova\bin\nova-compute.py</userinput></screen>, <screen><prompt>C:\></prompt><userinput>C:\python27\python.exe c:\openstack\nova\bin\nova-compute.py</userinput></screen>,1,1
openstack%2Foslo.vmware~master~I568372fef6bb4e3e3d0d6da2c32c2e971b319ad7,openstack/oslo.vmware,master,I568372fef6bb4e3e3d0d6da2c32c2e971b319ad7,Add methods to the Datastore objects,MERGED,2014-07-24 00:56:44.000000000,2014-08-15 18:45:16.000000000,2014-08-15 18:45:15.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 8027}, {'_account_id': 8759}, {'_account_id': 9171}]","[{'number': 1, 'created': '2014-07-24 00:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/33727bde784dcdf1ade6033f4de2bb1b5db2bf55', 'message': 'Add methods to the Datastore objects\n\nThis patch ports three methods:\n- get_connected_hosts\n- get_summary\n- is_ds_mount_usable\n\nThese methods are used in Cinder (see http://goo.gl/yR5psg) and\nGlance (see http://goo.gl/aDeyfa).\n\nChange-Id: I568372fef6bb4e3e3d0d6da2c32c2e971b319ad7\n'}, {'number': 2, 'created': '2014-07-24 01:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/57214d26910c8826b52227368462f10d45477dde', 'message': 'Add methods to the Datastore objects\n\nThis patch ports three methods:\n- get_connected_hosts\n- get_summary\n- is_ds_mount_usable\n\nThese methods are used in Cinder (see http://goo.gl/yR5psg) and\nGlance (see http://goo.gl/aDeyfa).\n\nChange-Id: I568372fef6bb4e3e3d0d6da2c32c2e971b319ad7\n'}, {'number': 3, 'created': '2014-07-30 21:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/3cd5790855ce49501f9f4c821d3c1a1084cbe4ce', 'message': 'Add methods to the Datastore objects\n\nThis patch ports three methods:\n- get_connected_hosts\n- get_summary\n- is_ds_mount_usable\n\nThese methods are used in Cinder (see http://goo.gl/yR5psg) and\nGlance (see http://goo.gl/aDeyfa).\n\nChange-Id: I568372fef6bb4e3e3d0d6da2c32c2e971b319ad7\n'}, {'number': 4, 'created': '2014-08-14 19:32:58.000000000', 'files': ['oslo/vmware/objects/datastore.py', 'tests/objects/test_datastore.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/e5c22fa8571c447ad9753980340ce2c6efa18a1d', 'message': 'Add methods to the Datastore objects\n\nThis patch ports three methods:\n- get_connected_hosts\n- get_summary\n- is_ds_mount_usable\n\nThese methods are used in Cinder (see http://goo.gl/yR5psg) and\nGlance (see http://goo.gl/aDeyfa).\n\nChange-Id: I568372fef6bb4e3e3d0d6da2c32c2e971b319ad7\n'}]",3,109160,e5c22fa8571c447ad9753980340ce2c6efa18a1d,22,5,4,8759,,,0,"Add methods to the Datastore objects

This patch ports three methods:
- get_connected_hosts
- get_summary
- is_ds_mount_usable

These methods are used in Cinder (see http://goo.gl/yR5psg) and
Glance (see http://goo.gl/aDeyfa).

Change-Id: I568372fef6bb4e3e3d0d6da2c32c2e971b319ad7
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/60/109160/4 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/vmware/objects/datastore.py', 'tests/objects/test_datastore.py']",2,33727bde784dcdf1ade6033f4de2bb1b5db2bf55,methods_ds,"import mock from oslo.vmware import vim_utilclass HostMount(object): def __init__(self, key, mountInfo): self.key = key self.mountInfo = mountInfo class MountInfo(object): def __init__(self, accessMode, mounted, accessible): self.accessMode = accessMode self.mounted = mounted self.accessible = accessible def test_get_summary(self): ds_ref = vim_util.get_moref('ds-0', 'Datastore') ds = datastore.Datastore(ds_ref, 'ds-name') summary = mock.sentinel.summary vim_util.get_object_property = mock.Mock() vim_util.get_object_property.return_value = summary session = mock.Mock() ret = ds.get_summary(session) self.assertEqual(summary, ret) vim_util.get_object_property.assert_called_once_with(session.vim, ds.ref, 'summary') def test_get_connected_hosts(self): session = mock.Mock() ds_ref = vim_util.get_moref('ds-0', 'Datastore') ds = datastore.Datastore(ds_ref, 'ds-name') ds.get_summary = mock.Mock() ds.get_summary.return_value.accessible = False self.assertEqual([], ds.get_connected_hosts(session)) ds.get_summary.return_value.accessible = True m1 = HostMount(""m1"", MountInfo('readWrite', True, True)) m2 = HostMount(""m2"", MountInfo('read', True, True)) m3 = HostMount(""m3"", MountInfo('readWrite', False, True)) m4 = HostMount(""m4"", MountInfo('readWrite', True, False)) class Prop(object): DatastoreHostMount = [m1, m2, m3, m4] vim_util.get_object_property = mock.Mock() vim_util.get_object_property.return_value = Prop() hosts = ds.get_connected_hosts(session) self.assertEqual(1, len(hosts)) self.assertEqual(""m1"", hosts.pop()) def test_is_datastore_mount_usable(self): m = MountInfo('readWrite', True, True) self.assertTrue(datastore.Datastore.is_datastore_mount_usable(m)) m = MountInfo('read', True, True) self.assertFalse(datastore.Datastore.is_datastore_mount_usable(m)) m = MountInfo('readWrite', False, True) self.assertFalse(datastore.Datastore.is_datastore_mount_usable(m)) m = MountInfo('readWrite', True, False) self.assertFalse(datastore.Datastore.is_datastore_mount_usable(m)) m = MountInfo('readWrite', False, False) self.assertFalse(datastore.Datastore.is_datastore_mount_usable(m)) m = MountInfo('readWrite', None, None) self.assertFalse(datastore.Datastore.is_datastore_mount_usable(m)) m = MountInfo('readWrite', None, True) self.assertFalse(datastore.Datastore.is_datastore_mount_usable(m)) ",,112,0
openstack%2Fopenstack-manuals~master~Ibc3661e132a0ea4010a5a61f71ef5209ae6655b6,openstack/openstack-manuals,master,Ibc3661e132a0ea4010a5a61f71ef5209ae6655b6,"Typos and spellings errors fix in config-ref, HA/image guides",MERGED,2014-08-14 16:16:33.000000000,2014-08-15 18:43:06.000000000,2014-08-15 18:43:05.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-14 16:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/915790f697caf186c71db8eb0a01c5ad4d4f9835', 'message': 'Typos and spellings errors fix in config-ref, HA/image guides\n\nAnother round of typos/spelling errors fixing, in particular for\nconfig-reference, HA guide and image guide.\n\nChange-Id: Ibc3661e132a0ea4010a5a61f71ef5209ae6655b6\nCloses-Bug: #1356970\n'}, {'number': 2, 'created': '2014-08-15 08:00:43.000000000', 'files': ['doc/config-reference/block-storage/drivers/sheepdog-driver.xml', 'doc/config-reference/compute/section_compute-configure-xen.xml', 'doc/config-reference/networking/section_networking-options-reference.xml', 'doc/image-guide/section_windows-example.xml', 'doc/config-reference/block-storage/drivers/hds-hus-driver.xml', 'doc/config-reference/networking/section_networking-plugins-ml2.xml', 'doc/glossary/glossary-terms.xml', 'doc/image-guide/ch_creating_images_manually.xml', 'doc/config-reference/compute/section_xapi-install-plugins.xml', 'doc/config-reference/block-storage/drivers/lvm-volume-driver.xml', 'doc/image-guide/section_ubuntu-example.xml', 'doc/config-reference/compute/section_compute-scheduler.xml', 'doc/image-guide/ch_creating_images_automatically.xml', 'doc/config-reference/object-storage/section_object-storage-features.xml', 'doc/config-reference/compute/section_xen-install.xml', 'doc/config-reference/block-storage/drivers/hds-hnas-driver.xml', 'doc/image-guide/ch_openstack_images.xml', 'doc/high-availability-guide/ha_aa_controllers/section_run_openstack_api_and_schedulers.xml', 'doc/high-availability-guide/ha_aa_rabbitmq/section_configure_rabbitmq.xml', 'doc/high-availability-guide/ch_ha_aa_haproxy.xml', 'doc/image-guide/section_centos-example.xml', 'doc/config-reference/compute/section_hypervisor_vmware.xml', 'doc/config-reference/object-storage/section_object-storage-general-service-conf.xml', 'doc/config-reference/block-storage/drivers/emc-volume-driver.xml', 'doc/image-guide/ch_obtaining_images.xml', 'doc/config-reference/block-storage/drivers/ceph-rbd-volume-driver.xml', 'doc/config-reference/block-storage/drivers/emc-vnx-direct-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bcec02416ee0ea8acc5e1197a11ad626bfc0d918', 'message': 'Typos and spellings errors fix in config-ref, HA/image guides\n\nAnother round of typos/spelling errors fixing, in particular for\nconfig-reference, HA guide and image guide.\n\nChange-Id: Ibc3661e132a0ea4010a5a61f71ef5209ae6655b6\nCloses-Bug: #1356970\n'}]",1,114285,bcec02416ee0ea8acc5e1197a11ad626bfc0d918,12,3,2,12840,,,0,"Typos and spellings errors fix in config-ref, HA/image guides

Another round of typos/spelling errors fixing, in particular for
config-reference, HA guide and image guide.

Change-Id: Ibc3661e132a0ea4010a5a61f71ef5209ae6655b6
Closes-Bug: #1356970
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/85/114285/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/block-storage/drivers/sheepdog-driver.xml', 'doc/config-reference/compute/section_compute-configure-xen.xml', 'doc/config-reference/networking/section_networking-options-reference.xml', 'doc/image-guide/section_windows-example.xml', 'doc/config-reference/block-storage/drivers/hds-hus-driver.xml', 'doc/config-reference/networking/section_networking-plugins-ml2.xml', 'doc/glossary/glossary-terms.xml', 'doc/image-guide/ch_creating_images_manually.xml', 'doc/config-reference/compute/section_xapi-install-plugins.xml', 'doc/config-reference/block-storage/drivers/lvm-volume-driver.xml', 'doc/image-guide/section_ubuntu-example.xml', 'doc/config-reference/compute/section_compute-scheduler.xml', 'doc/image-guide/ch_creating_images_automatically.xml', 'doc/config-reference/object-storage/section_object-storage-features.xml', 'doc/config-reference/compute/section_xen-install.xml', 'doc/config-reference/block-storage/drivers/hds-hnas-driver.xml', 'doc/image-guide/ch_openstack_images.xml', 'doc/high-availability-guide/ha_aa_controllers/section_run_openstack_api_and_schedulers.xml', 'doc/high-availability-guide/ha_aa_rabbitmq/section_configure_rabbitmq.xml', 'doc/high-availability-guide/ch_ha_aa_haproxy.xml', 'doc/image-guide/section_centos-example.xml', 'doc/config-reference/compute/section_hypervisor_vmware.xml', 'doc/config-reference/object-storage/section_object-storage-general-service-conf.xml', 'doc/config-reference/block-storage/drivers/emc-volume-driver.xml', 'doc/image-guide/ch_obtaining_images.xml', 'doc/config-reference/block-storage/drivers/ceph-rbd-volume-driver.xml', 'doc/config-reference/block-storage/drivers/emc-vnx-direct-driver.xml']",27,915790f697caf186c71db8eb0a01c5ad4d4f9835,bug/1356970," <para>On Ubuntu x64, download the NaviSecCLI deb package from <link xlink:href=""https://github.com/emc-openstack/naviseccli"">EMC's OpenStack GitHub</link> web site."," <para>On Ubuntu x64, download the NaviSecCLI deb package from <link xlink:href=""https://github.com/emc-openstack/naviseccli"">EMC's OpenStack Github</link> web site.",42,42
openstack%2Ftrove-integration~master~I5f8c3172ae0e83dd5393eaf70afdb5d2ba7075d0,openstack/trove-integration,master,I5f8c3172ae0e83dd5393eaf70afdb5d2ba7075d0,Delete old images before uploading a new one to glance,MERGED,2014-08-15 17:11:24.000000000,2014-08-15 18:38:01.000000000,2014-08-15 18:37:59.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 10215}]","[{'number': 1, 'created': '2014-08-15 17:11:24.000000000', 'files': ['scripts/redstack'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/770f7e957551c7eb313eed7207a1597a9c29184f', 'message': 'Delete old images before uploading a new one to glance\n\nThe openstack client that the image upload in devstack now uses\n(I96cef118daf931b648c0483525ac7d2287fec2e0) fails when trying to\nupload another image having the same name into the glance catalog.\n\nThis change cleans up any older images that may exist in the catalog\nbefore uploading the new image as part of kick-start.\n\nChange-Id: I5f8c3172ae0e83dd5393eaf70afdb5d2ba7075d0\nCloses-bug: 1357472\n'}]",0,114604,770f7e957551c7eb313eed7207a1597a9c29184f,11,5,1,5293,,,0,"Delete old images before uploading a new one to glance

The openstack client that the image upload in devstack now uses
(I96cef118daf931b648c0483525ac7d2287fec2e0) fails when trying to
upload another image having the same name into the glance catalog.

This change cleans up any older images that may exist in the catalog
before uploading the new image as part of kick-start.

Change-Id: I5f8c3172ae0e83dd5393eaf70afdb5d2ba7075d0
Closes-bug: 1357472
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/04/114604/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/redstack'],1,770f7e957551c7eb313eed7207a1597a9c29184f,bug/1357472, GLANCE_IMAGEIDS=$(glance image-list | grep $(basename $IMAGE_URL .qcow2) | get_field 1) if [[ -n $GLANCE_IMAGEIDS ]]; then glance image-delete $GLANCE_IMAGEIDS fi,,4,0
openstack%2Fcongress~master~I451a3c78fbc2108d6937a1faf40542291d3f8107,openstack/congress,master,I451a3c78fbc2108d6937a1faf40542291d3f8107,Fix requirements.txt,MERGED,2014-08-11 23:43:58.000000000,2014-08-15 18:28:33.000000000,2014-08-15 18:28:33.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-08-11 23:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/0988bd36497f0229252345b7ee99cc106ed6dae5', 'message': 'Fix requirements.txt\n\nAdd mock and upgrade neutronclient.\n\nChange-Id: I451a3c78fbc2108d6937a1faf40542291d3f8107\n'}, {'number': 2, 'created': '2014-08-11 23:45:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/f12f6d8be7ee64bb77b1fa0dc152792028c7e182', 'message': 'Fix requirements.txt\n\nAdd mock and upgrade neutronclient.\n\nChange-Id: I451a3c78fbc2108d6937a1faf40542291d3f8107\n'}, {'number': 3, 'created': '2014-08-13 17:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/42151b89174be6b0f886c509788bb56840ad9bf0', 'message': 'Fix requirements.txt\n\nUpgrade neutronclient.\n\nChange-Id: I451a3c78fbc2108d6937a1faf40542291d3f8107\n'}, {'number': 4, 'created': '2014-08-13 17:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/e1da2a512d64c46fe6bc692703ccb349207bd12e', 'message': 'Fix requirements.txt\n\nUpgrade neutronclient.\n\nChange-Id: I451a3c78fbc2108d6937a1faf40542291d3f8107\n'}, {'number': 5, 'created': '2014-08-13 20:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/a090ba200f97b2d2962e54cc5bd4dc78575a269c', 'message': 'Fix requirements.txt\n\nUpgrade neutronclient.\n\nChange-Id: I451a3c78fbc2108d6937a1faf40542291d3f8107\n'}, {'number': 6, 'created': '2014-08-14 18:24:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/74336ef2b72ad759012cd7b5874839670a2be5b3', 'message': 'Fix requirements.txt\n\nUpgrade neutronclient.\n\nChange-Id: I451a3c78fbc2108d6937a1faf40542291d3f8107\n'}]",1,113406,74336ef2b72ad759012cd7b5874839670a2be5b3,23,4,6,12875,,,0,"Fix requirements.txt

Upgrade neutronclient.

Change-Id: I451a3c78fbc2108d6937a1faf40542291d3f8107
",git fetch https://review.opendev.org/openstack/congress refs/changes/06/113406/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0988bd36497f0229252345b7ee99cc106ed6dae5,x,"mock>=1.0python-neutronclient>=2.3.6,<3","python-neutronclient>=2.3.5,<3",2,1
openstack%2Fopenstack-manuals~master~I1349e126786d7a6ebfd73bf7ffd2aff3d7692790,openstack/openstack-manuals,master,I1349e126786d7a6ebfd73bf7ffd2aff3d7692790,Adding the beginnings of content in the Architecture chapter,MERGED,2014-08-09 06:06:16.000000000,2014-08-15 18:26:50.000000000,2014-08-15 18:26:49.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 8369}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-08-09 06:06:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a79649092f239db0cb560d3784a61d0e7cab356d', 'message': 'Adding the beginnings of content in the Architecture chapter\n\nThis is mostly copy-pasted from the OS Cloud Admin Guide, with\nsome extra info from the Red Hat Cloud Admin Guide. Still needs\nmore editing and shifting around.\n\nChange-Id: I1349e126786d7a6ebfd73bf7ffd2aff3d7692790\n'}, {'number': 2, 'created': '2014-08-09 08:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4b23c58d27def6efc924a5e800eef2c58c14b6d8', 'message': 'Adding the beginnings of content in the Architecture chapter\n\nThis is mostly copy-pasted from the OS Cloud Admin Guide, with\nsome extra info from the Red Hat Cloud Admin Guide. Still needs\nmore editing and shifting around.\n\nChange-Id: I1349e126786d7a6ebfd73bf7ffd2aff3d7692790\n'}, {'number': 3, 'created': '2014-08-09 08:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e87e631d94adf510973a76263f5596226b0a0af4', 'message': 'Adding the beginnings of content in the Architecture chapter\n\nThis is mostly copy-pasted from the OS Cloud Admin Guide, with\nsome extra info from the Red Hat Cloud Admin Guide. Still needs\nmore editing and shifting around.\n\nChange-Id: I1349e126786d7a6ebfd73bf7ffd2aff3d7692790\n'}, {'number': 4, 'created': '2014-08-09 09:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ca30e98de9831be0d6286b80d607186315cc7117', 'message': 'Adding the beginnings of content in the Architecture chapter\n\nThis is mostly copy-pasted from the OS Cloud Admin Guide, with\nsome extra info from the Red Hat Cloud Admin Guide. Still needs\nmore editing and shifting around.\n\nChange-Id: I1349e126786d7a6ebfd73bf7ffd2aff3d7692790\n'}, {'number': 5, 'created': '2014-08-09 10:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/100180fb3b9b8226982a67da25b878e364a309c8', 'message': 'Adding the beginnings of content in the Architecture chapter\n\nThis is mostly copy-pasted from the OS Cloud Admin Guide, with\nsome extra info from the Red Hat Cloud Admin Guide. Still needs\nmore editing and shifting around.\n\nChange-Id: I1349e126786d7a6ebfd73bf7ffd2aff3d7692790\n'}, {'number': 6, 'created': '2014-08-15 13:34:52.000000000', 'files': ['doc/networking-guide/ch_advanced.xml', 'doc/networking-guide/section_architecture-agents.xml', 'doc/networking-guide/section_architecture-plug-in.xml', 'doc/networking-guide/ch_networking-architecture.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/22016f2f4e530a83b4efd9d422a3e209540db691', 'message': 'Adding the beginnings of content in the Architecture chapter\n\nThis is mostly copy-pasted from the OS Cloud Admin Guide, with\nsome extra info from the Red Hat Cloud Admin Guide. Still needs\nmore editing and shifting around.\n\nChange-Id: I1349e126786d7a6ebfd73bf7ffd2aff3d7692790\n'}]",17,113071,22016f2f4e530a83b4efd9d422a3e209540db691,31,6,6,9162,,,0,"Adding the beginnings of content in the Architecture chapter

This is mostly copy-pasted from the OS Cloud Admin Guide, with
some extra info from the Red Hat Cloud Admin Guide. Still needs
more editing and shifting around.

Change-Id: I1349e126786d7a6ebfd73bf7ffd2aff3d7692790
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/71/113071/6 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/section_architecture-agents.xml', 'doc/networking-guide/section_architecture-plug-in.xml', 'doc/networking-guide/ch_networking-architecture.xml']",3,a79649092f239db0cb560d3784a61d0e7cab356d,113071," <para> A standard network architecture design includes a cloud controller host, a network gateway host, and a number of hypervisors for hosting virtual machines. The cloud controller and network gateway can be on the same host. However, if you expect VMs to send significant traffic to or from the Internet, a dedicated network gateway host helps avoid CPU contention between the <systemitem class=""service"">neutron-l3-agent</systemitem> and other OpenStack services that forward packets. </para> <para> OpenStack Networking can be run across multiple physical devices. It is also possible to run all service daemons on a single physical host for evaluation purposes, however this is not generally robust enough for production purposes. For greater redundancy, you can run each service on a dedicated physical host and replicate any essential services across multiple hosts. </para> <para> For more information about networking architecture options, see the <citetitle>OpenStack Configuration Reference</citetitle>. <!-- Bring this content directly in rather than referring to it. LKB --> </para> <!-- <mediaobject> <imageobject> <imagedata scale=""50"" fileref=""../../common/figures/Neutron-PhysNet-Diagram.png""/> </imageobject> </mediaobject> <para> A standard OpenStack Networking deployment would usually include one or more of the following physical networks: </para> <table rules=""all""> <caption>General distinct physical data center networks</caption> <col width=""20%""/> <col width=""80%""/> <thead> <tr> <th>Network</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><emphasis role=""bold"">Management network</emphasis></td> <td>Provides internal communication between OpenStack components. IP addresses on this network should be reachable only within the data center.</td> </tr> <tr> <td><emphasis role=""bold"">Data network</emphasis></td> <td>Provides VM data communication within the cloud deployment. The IP addressing requirements of this network depend on the Networking plug-in that is used.</td> </tr> <tr> <td><emphasis role=""bold"">External network</emphasis></td> <td>Provides VMs with Internet access in some deployment scenarios. Anyone on the Internet can reach IP addresses on this network.</td> </tr> <tr> <td><emphasis role=""bold"">API network</emphasis></td> <td>Exposes all OpenStack APIs, including the Networking API, to tenants. IP addresses on this network should be reachable by anyone on the Internet. The API network might be the same as the external network, because it is possible to create an external-network subnet that has allocated IP ranges that use less than the full range of IP addresses in an IP block.</td> </tr> </tbody> </table> </section> <section xml:id=""tenant-provider-networks""> <title>Tenant and provider networks</title> <para> The following diagram presents an overview of the tenant and provider network types, and illustrates how they interact within the overall Networking topology: </para> <figure> <title>Tenant and provider networks</title> <mediaobject> <imageobject> <imagedata scale=""90"" fileref=""../../common/figures/NetworkTypes.png""/> </imageobject> </mediaobject> </figure> <formalpara> <title>Tenant networks</title> <para>Users create tenant networks for connectivity within projects; they are fully isolated by default and are not shared with other projects. Networking supports a range of tenant network types: </para> </formalpara> <variablelist> <varlistentry> <term>Flat</term> <listitem> <para>All instances reside on the same network, which can also be shared with the hosts. No VLAN tagging or other network segregation takes place. </para> </listitem> </varlistentry> <varlistentry> <term>Local</term> <listitem> <para>Instances reside on the local compute host and are effectively isolated from any external networks. </para> </listitem> </varlistentry> <varlistentry> <term>VLAN</term> <listitem> <para>Networking allows users to create multiple provider or tenant networks using VLAN IDs (802.1Q tagged) that correspond to VLANs present in the physical network. This allows instances to communicate with each other across the environment. They can also communicate with dedicated servers, firewalls, load balancers and other networking infrastructure on the same layer 2 VLAN.</para> </listitem> </varlistentry> <varlistentry> <term>VXLAN and GRE</term> <listitem> <para>VXLAN and GRE use network overlays to support private communication between instances. A Networking router is required to enable traffic to traverse outside of the GRE or VXLAN tenant network. A router is also required to connect directly-connected tenant networks with external networks, including the Internet; the router provides the ability to connect to instances directly from an external network using floating IP addresses.</para> </listitem> </varlistentry> </variablelist> <formalpara> <title>Provider networks</title> <para>Provider networks are created by the OpenStack administrator and map directly to an existing physical network in the data center. Useful network types in this category are flat (untagged) and VLAN (802.1Q tagged). It is possible to allow provider networks to be shared among tenants as part of the network creation process.</para> </formalpara> </section> <section xml:id=""NSX_overview""> <title>VMware NSX integration</title> <para>OpenStack Networking uses the NSX plugin for Networking to integrate with an existing VMware vCenter deployment. When installed on the network nodes, the NSX plugin enables a NSX controller to centrally manage configuration settings and push them to managed network nodes. Network nodes are considered managed when they're added as hypervisors to the NSX controller.</para> <para>The diagram below depicts an example NSX deployment and illustrates the route inter-VM traffic takes between separate Compute nodes. Note the placement of the VMware NSX plugin and the <systemitem class=""service"">neutron-server</systemitem> service on the network node. The NSX controller features centrally with a green line to the network node to indicate the management relationship:</para> <figure> <title>VMware NSX overview</title> <mediaobject> <imageobject> <imagedata fileref=""../../common/figures/vmware_nsx.png"" format=""PNG"" contentwidth=""6in""/> </imageobject> </mediaobject> </figure> </section> --> "," <para> Bacon ipsum dolor sit amet biltong meatloaf andouille, turducken bresaola pork belly beef ribs ham hock capicola tail prosciutto landjaeger meatball pork loin. Swine turkey jowl, porchetta doner boudin meatloaf. Shoulder capicola prosciutto, shank landjaeger short ribs sirloin turducken pork belly boudin frankfurter chuck. Salami shankle bresaola cow filet mignon ham hock shank. </para>",270,22
openstack%2Fhorizon~master~I47f06f43e60012f502e70817feccf458fca7eef2,openstack/horizon,master,I47f06f43e60012f502e70817feccf458fca7eef2,rename pagination 'More' link to 'Next',MERGED,2014-08-14 21:02:21.000000000,2014-08-15 17:47:40.000000000,2014-08-15 05:09:10.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 6825}, {'_account_id': 9576}, {'_account_id': 9622}]","[{'number': 1, 'created': '2014-08-14 21:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ca26581020884ab475bc932fa41e7aa890f5e00e', 'message': ""rename pagination 'More' link to 'Next'\n\nThe term 'More' is not standard and suggests appending more items\nto the existing table rather than going to the next set of data.\n\nChange-Id: I47f06f43e60012f502e70817feccf458fca7eef2\nCloses-Bug: #1323880\n""}, {'number': 2, 'created': '2014-08-14 21:08:31.000000000', 'files': ['horizon/templates/horizon/common/_data_table.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ef076e1b834ec53f24a286d1825c52467f99f7c8', 'message': ""rename pagination 'More' link to 'Next'\n\nThe term 'More' is not standard and suggests appending more items\nto the existing table rather than going to the next set of data.\n\nChange-Id: I47f06f43e60012f502e70817feccf458fca7eef2\nCloses-Bug: #1323880\n""}]",0,114358,ef076e1b834ec53f24a286d1825c52467f99f7c8,13,6,2,9622,,,0,"rename pagination 'More' link to 'Next'

The term 'More' is not standard and suggests appending more items
to the existing table rather than going to the next set of data.

Change-Id: I47f06f43e60012f502e70817feccf458fca7eef2
Closes-Bug: #1323880
",git fetch https://review.opendev.org/openstack/horizon refs/changes/58/114358/2 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/common/_data_table.html'],1,ca26581020884ab475bc932fa41e7aa890f5e00e,bug/1323880," <a href=""?{{ table.get_pagination_string }}"">{% trans ""Next&nbsp;&raquo;"" %}</a>"," <a href=""?{{ table.get_pagination_string }}"">{% trans ""More&nbsp;&raquo;"" %}</a>",1,1
openstack%2Fpython-heatclient~master~I401f68d8c2e14179972928920003c75c851ad9cc,openstack/python-heatclient,master,I401f68d8c2e14179972928920003c75c851ad9cc,Add nested-depth option to resource-list,MERGED,2014-08-12 18:13:26.000000000,2014-08-15 17:33:28.000000000,2014-08-15 17:33:27.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 8246}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-08-12 18:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/456bae551747d27ad65a2036eeb8c81451bc37e2', 'message': 'Add nested-depth option to resource-list\n\nAdd `--nested-depth` option to allow listing of nested resources up to\n`<DEPTH>` levels deep.\n\nImplements: blueprint explode-nested-resources\nChange-Id: I401f68d8c2e14179972928920003c75c851ad9cc\n'}, {'number': 2, 'created': '2014-08-15 14:16:00.000000000', 'files': ['heatclient/tests/test_shell.py', 'heatclient/tests/test_resources.py', 'heatclient/v1/resources.py', 'heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/ec3fa70a81228f63b7ff8995d0e8ec03fbcaf1f2', 'message': 'Add nested-depth option to resource-list\n\nAdd `--nested-depth` option to allow listing of nested resources up to\n`<DEPTH>` levels deep.\n\nImplements: blueprint explode-nested-resources\nChange-Id: I401f68d8c2e14179972928920003c75c851ad9cc\n'}]",0,113606,ec3fa70a81228f63b7ff8995d0e8ec03fbcaf1f2,15,7,2,9189,,,0,"Add nested-depth option to resource-list

Add `--nested-depth` option to allow listing of nested resources up to
`<DEPTH>` levels deep.

Implements: blueprint explode-nested-resources
Change-Id: I401f68d8c2e14179972928920003c75c851ad9cc
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/06/113606/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/test_shell.py', 'heatclient/tests/test_resources.py', 'heatclient/v1/resources.py', 'heatclient/v1/shell.py']",4,456bae551747d27ad65a2036eeb8c81451bc37e2,bp/explode-nested-resources,"@utils.arg('-n', '--nested-depth', metavar='<DEPTH>', help='Depth of nested stacks from which to display resources.') fields = { 'stack_id': args.id, 'nested_depth': args.nested_depth, }", fields = {'stack_id': args.id},51,2
openstack%2Fnova~master~I06dbd32a9bc6d99068e06576e4ea7a8594764db5,openstack/nova,master,I06dbd32a9bc6d99068e06576e4ea7a8594764db5,Security groups: add missing translation,MERGED,2014-07-14 10:08:10.000000000,2014-08-15 17:33:12.000000000,2014-08-15 17:33:09.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9533}, {'_account_id': 9545}, {'_account_id': 9578}, {'_account_id': 9796}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-14 10:08:10.000000000', 'files': ['nova/network/security_group/security_group_base.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/556ccfce1fc807b4c3e85151e0fa8a8dccd5414a', 'message': 'Security groups: add missing translation\n\nCommit d562012f34eadfe6b68dd5ebe06a2fa565de3b2e added exceptions\nthat were not translated.\n\nChange-Id: I06dbd32a9bc6d99068e06576e4ea7a8594764db5\n'}]",2,106723,556ccfce1fc807b4c3e85151e0fa8a8dccd5414a,25,11,1,1653,,,0,"Security groups: add missing translation

Commit d562012f34eadfe6b68dd5ebe06a2fa565de3b2e added exceptions
that were not translated.

Change-Id: I06dbd32a9bc6d99068e06576e4ea7a8594764db5
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/106723/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/security_group/security_group_base.py'],1,556ccfce1fc807b4c3e85151e0fa8a8dccd5414a,missing-translation," raise exception.InvalidInput(reason=_(""Type and"" "" Code must be integers for ICMP protocol type"")) else: raise exception.InvalidInput(reason=_(""To and From ports "" ""must be integers""))"," raise exception.InvalidInput(reason=""Type and"" "" Code must be integers for ICMP protocol type"") else: raise exception.InvalidInput(reason=""To and From ports "" ""must be integers"")",4,4
openstack%2Fswift~master~I75e3f15ad217a71b4fd39552cf6db2957597efca,openstack/swift,master,I75e3f15ad217a71b4fd39552cf6db2957597efca,Add timestamp checking in AccountBroker.is_status_deleted,MERGED,2014-04-09 07:50:34.000000000,2014-08-15 17:31:41.000000000,2014-08-15 17:31:41.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 2649}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 9816}]","[{'number': 1, 'created': '2014-04-09 07:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/037b2a0cd35b0440e043d3353459e6c6190dde80', 'message': 'Add timestamp checking in AccountBroker.is_status_deleted\n\nAccount-reaper works only at account-server with the first replica, and reaps account with ""deleted"" status.\n\nOn the other hand, account-replicator doesn\'t replicate the status, only replicates *_timestamp. When swift fails to delete the first account replica, account-reaper never reaps the account, because the first replica never gets marked as ""deleted"".\n\nThis patch adds a timestamp checking into is_status_deleted method, and account-reaper will start to reap the account after account-replicator replicates *_timestamp.\n\nChange-Id: I75e3f15ad217a71b4fd39552cf6db2957597efca\nCloses-Bug: #1304755\n'}, {'number': 2, 'created': '2014-04-09 08:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b7c36d1b2a5da8629eccfd84315fdeca2ccc56f8', 'message': 'Add timestamp checking in AccountBroker.is_status_deleted\n\nAccount-reaper works only at account-server with the first replica, and reaps\naccount with ""deleted"" status.\n\nOn the other hand, account-replicator doesn\'t replicate the status, only\nreplicates *_timestamp.\nWhen swift fails to delete the first account replica, account-reaper never\nreaps the account, because the first replica never gets marked as ""deleted"".\n\nThis patch adds a timestamp checking into is_status_deleted method, and\naccount-reaper will start to reap the account after account-replicator\nreplicates *_timestamp.\n\nChange-Id: I75e3f15ad217a71b4fd39552cf6db2957597efca\nCloses-Bug: #1304755\n'}, {'number': 3, 'created': '2014-04-11 09:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f33b18b279d68d3cc9cbc3873053bfaa9246ce05', 'message': 'Add timestamp checking in AccountBroker.is_status_deleted\n\nAccount-reaper works only at account-server with the first replica, and reaps\naccount with ""deleted"" status.\n\nOn the other hand, account-replicator doesn\'t replicate the status, only\nreplicates *_timestamp.\nWhen swift fails to delete the first account replica, account-reaper never\nreaps the account, because the first replica never gets marked as ""deleted"".\n\nThis patch adds a timestamp checking into is_status_deleted method, and\naccount-reaper will start to reap the account after account-replicator\nreplicates *_timestamp.\n\nChange-Id: I75e3f15ad217a71b4fd39552cf6db2957597efca\nCloses-Bug: #1304755\n'}, {'number': 4, 'created': '2014-04-11 09:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e5486d0ae8683167d976f03260b7c4726ffec42e', 'message': 'Add timestamp checking in AccountBroker.is_status_deleted\n\nAccount-reaper works only at account-server with the first replica, and reaps\naccount with ""deleted"" status.\n\nOn the other hand, account-replicator doesn\'t replicate the status, only\nreplicates *_timestamp.\nWhen swift fails to delete the first account replica, account-reaper never\nreaps the account, because the first replica never gets marked as ""deleted"".\n\nThis patch adds a timestamp checking into is_status_deleted method, and\naccount-reaper will start to reap the account after account-replicator\nreplicates *_timestamp.\n\nChange-Id: I75e3f15ad217a71b4fd39552cf6db2957597efca\nCloses-Bug: #1304755\n'}, {'number': 5, 'created': '2014-04-14 00:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1534ea1ff478beb39b01ed74b4cd79a369d6d0ff', 'message': 'Add timestamp checking in AccountBroker.is_status_deleted\n\nAccount-reaper works only at account-server with the first replica, and reaps\naccount with ""deleted"" status.\n\nOn the other hand, account-replicator doesn\'t replicate the status, only\nreplicates *_timestamp.\nWhen swift fails to delete the first account replica, account-reaper never\nreaps the account, because the first replica never gets marked as ""deleted"".\n\nThis patch adds a timestamp checking into is_status_deleted method, and\naccount-reaper will start to reap the account after account-replicator\nreplicates *_timestamp.\n\nChange-Id: I75e3f15ad217a71b4fd39552cf6db2957597efca\nCloses-Bug: #1304755\n'}, {'number': 6, 'created': '2014-04-14 01:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/eda8e81203e3bb646ca355e8b4aa376f98801a96', 'message': 'Add timestamp checking in AccountBroker.is_status_deleted\n\nAccount-reaper works only at account-server with the first replica, and reaps\naccount with ""deleted"" status.\n\nOn the other hand, account-replicator doesn\'t replicate the status, only\nreplicates *_timestamp.\nWhen swift fails to delete the first account replica, account-reaper never\nreaps the account, because the first replica never gets marked as ""deleted"".\n\nThis patch adds a timestamp checking into is_status_deleted method, and\naccount-reaper will start to reap the account after account-replicator\nreplicates *_timestamp.\n\nChange-Id: I75e3f15ad217a71b4fd39552cf6db2957597efca\nCloses-Bug: #1304755\n'}, {'number': 7, 'created': '2014-08-12 01:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c4869b66624c243283f8fec6dcf0896c1f529127', 'message': 'Add timestamp checking in AccountBroker.is_status_deleted\n\nAccount-reaper works only at account-server with the first replica, and reaps\naccount with ""deleted"" status.\n\nOn the other hand, account-replicator doesn\'t replicate the status, only\nreplicates *_timestamp.\nWhen swift fails to delete the first account replica, account-reaper never\nreaps the account, because the first replica never gets marked as ""deleted"".\n\nThis patch adds a timestamp checking into is_status_deleted method, and\naccount-reaper will start to reap the account after account-replicator\nreplicates *_timestamp.\n\nChange-Id: I75e3f15ad217a71b4fd39552cf6db2957597efca\nCloses-Bug: #1304755\n'}, {'number': 8, 'created': '2014-08-12 03:31:44.000000000', 'files': ['swift/account/backend.py', 'test/unit/account/test_backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/41d851387cec122f4795d447458fd81e48e256b0', 'message': 'Add timestamp checking in AccountBroker.is_status_deleted\n\nAccount-reaper works only at account-server with the first replica, and reaps\naccount with ""deleted"" status.\n\nOn the other hand, account-replicator doesn\'t replicate the status, only\nreplicates *_timestamp.\nWhen swift fails to delete the first account replica, account-reaper never\nreaps the account, because the first replica never gets marked as ""deleted"".\n\nThis patch adds a timestamp checking into is_status_deleted method, and\naccount-reaper will start to reap the account after account-replicator\nreplicates *_timestamp.\n\nChange-Id: I75e3f15ad217a71b4fd39552cf6db2957597efca\nCloses-Bug: #1304755\n'}]",0,86248,41d851387cec122f4795d447458fd81e48e256b0,51,6,8,9816,,,0,"Add timestamp checking in AccountBroker.is_status_deleted

Account-reaper works only at account-server with the first replica, and reaps
account with ""deleted"" status.

On the other hand, account-replicator doesn't replicate the status, only
replicates *_timestamp.
When swift fails to delete the first account replica, account-reaper never
reaps the account, because the first replica never gets marked as ""deleted"".

This patch adds a timestamp checking into is_status_deleted method, and
account-reaper will start to reap the account after account-replicator
replicates *_timestamp.

Change-Id: I75e3f15ad217a71b4fd39552cf6db2957597efca
Closes-Bug: #1304755
",git fetch https://review.opendev.org/openstack/swift refs/changes/48/86248/3 && git format-patch -1 --stdout FETCH_HEAD,['swift/account/backend.py'],1,037b2a0cd35b0440e043d3353459e6c6190dde80,bug/1304755," SELECT put_timestamp, delete_timestamp, status return row['status'] == ""DELETED"" or ( row['delete_timestamp'] > row['put_timestamp'])"," SELECT status return (row['status'] == ""DELETED"")",3,2
openstack%2Fnova~stable%2Ficehouse~Ia31b33c9a1d347f15d3e0a67fa31ef6b25a7407a,openstack/nova,stable/icehouse,Ia31b33c9a1d347f15d3e0a67fa31ef6b25a7407a,shelve doesn't work on nova-cells environment,MERGED,2014-07-17 09:30:37.000000000,2014-08-15 17:23:58.000000000,2014-08-15 16:47:28.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 642}, {'_account_id': 1011}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8300}, {'_account_id': 8871}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-07-17 09:30:37.000000000', 'files': ['nova/tests/cells/test_cells_messaging.py', 'nova/cells/messaging.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e7d20879b2d4ef5261d0f85c520a63451b628eeb', 'message': ""shelve doesn't work on nova-cells environment\n\nThe compute_api shelve/unshelve methods expect an Instance object,\nbut cell is still passing the sqlalchemy form.\nSo adding shelve/unshelve to the list of methods that will receive an\nInstance object when using nova-cell.\n\nWhen shelving instance with nova-cell environment,\ninstance object needs to contain 'metadata' and 'info_cache'.\nSo fetching the same from databse and adding it to\ninstance object before calling shelve/unshelve methods.\n\nConflicts:\n    nova/cells/messaging.py\n\nCloses-Bug: #1338451\nChange-Id: Ia31b33c9a1d347f15d3e0a67fa31ef6b25a7407a\n(cherry picked from commit 9d4b49c542e2076c8a572d1e8c6d50e255efe087)\n""}]",0,107612,e7d20879b2d4ef5261d0f85c520a63451b628eeb,28,13,1,8300,,,0,"shelve doesn't work on nova-cells environment

The compute_api shelve/unshelve methods expect an Instance object,
but cell is still passing the sqlalchemy form.
So adding shelve/unshelve to the list of methods that will receive an
Instance object when using nova-cell.

When shelving instance with nova-cell environment,
instance object needs to contain 'metadata' and 'info_cache'.
So fetching the same from databse and adding it to
instance object before calling shelve/unshelve methods.

Conflicts:
    nova/cells/messaging.py

Closes-Bug: #1338451
Change-Id: Ia31b33c9a1d347f15d3e0a67fa31ef6b25a7407a
(cherry picked from commit 9d4b49c542e2076c8a572d1e8c6d50e255efe087)
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/107612/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/cells/test_cells_messaging.py', 'nova/cells/messaging.py']",2,e7d20879b2d4ef5261d0f85c520a63451b628eeb,lp/1338451," 'update_instance_metadata', 'shelve', 'unshelve'] expected_attrs = None # shelve and unshelve requires 'info_cache' and 'metadata', # because of this fetching same from database. if method in ['shelve', 'unshelve']: expected_attrs = ['metadata', 'info_cache'] inst_obj._from_db_object(message.ctxt, inst_obj, instance, expected_attrs=expected_attrs)"," 'update_instance_metadata'] inst_obj._from_db_object(message.ctxt, inst_obj, instance)",35,9
openstack%2Fopenstacksdk~master~I49f5a4e8de6bd8ad4982be8c25ea794e39bd42c8,openstack/openstacksdk,master,I49f5a4e8de6bd8ad4982be8c25ea794e39bd42c8,Add the Resource resource to telemetry,MERGED,2014-08-11 21:46:07.000000000,2014-08-15 16:58:55.000000000,2014-08-15 16:58:55.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 12807}]","[{'number': 1, 'created': '2014-08-11 21:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f1d7686b709dbbd6f24c16440b168d75df232784', 'message': 'Add the Resource resource to telemetry\n\nResource represents something within OpenStack which emits metrics.\nCan perform full list and retrieve operations, including query parameters on list.\n\nChange-Id: I49f5a4e8de6bd8ad4982be8c25ea794e39bd42c8\n'}, {'number': 2, 'created': '2014-08-11 21:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6f9546b4e3692e546d6cd1d27a265a3695a820d9', 'message': 'Add the Resource resource to telemetry\n\nResource represents something within OpenStack which emits metrics.\nCan perform full list and retrieve operations, including query parameters on list.\n\nChange-Id: I49f5a4e8de6bd8ad4982be8c25ea794e39bd42c8\n'}, {'number': 3, 'created': '2014-08-12 02:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/30468f164e667dfa88f4304afc4d10c097dddbf5', 'message': 'Add the Resource resource to telemetry\n\nResource represents something within OpenStack which emits metrics.\nCan perform full list and retrieve operations, including query parameters on list.\n\nChange-Id: I49f5a4e8de6bd8ad4982be8c25ea794e39bd42c8\n'}, {'number': 4, 'created': '2014-08-14 00:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/09ad170632e1cc3e971462d20f1da544bb5e39f4', 'message': 'Add the Resource resource to telemetry\n\nResource represents something within OpenStack which emits metrics.\nCan perform full list and retrieve operations, including query parameters on list.\n\nChange-Id: I49f5a4e8de6bd8ad4982be8c25ea794e39bd42c8\n'}, {'number': 5, 'created': '2014-08-14 00:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/48e90defd940635d1576dc63d8726cb189477d59', 'message': 'Add the Resource resource to telemetry\n\nResource represents something within OpenStack which emits metrics.\nCan perform full list and retrieve operations, including query parameters on list.\n\nChange-Id: I49f5a4e8de6bd8ad4982be8c25ea794e39bd42c8\n'}, {'number': 6, 'created': '2014-08-14 23:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4c352fdee6d4ebb987c15f19d32ebc8677efdcd8', 'message': 'Add the Resource resource to telemetry\n\nResource represents something within OpenStack which emits metrics.\nCan perform full list and retrieve operations, including query parameters on list.\n\nChange-Id: I49f5a4e8de6bd8ad4982be8c25ea794e39bd42c8\n'}, {'number': 7, 'created': '2014-08-14 23:28:57.000000000', 'files': ['openstack/telemetry/v2/resource.py', 'openstack/tests/telemetry/v2/test_resource.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d5b73b6931e8a3e289f222b8d8a500ecec60f645', 'message': 'Add the Resource resource to telemetry\n\nResource represents something within OpenStack which emits metrics.\nCan perform full list and retrieve operations, including query parameters on list.\n\nChange-Id: I49f5a4e8de6bd8ad4982be8c25ea794e39bd42c8\n'}]",4,113381,d5b73b6931e8a3e289f222b8d8a500ecec60f645,30,4,7,12807,,,0,"Add the Resource resource to telemetry

Resource represents something within OpenStack which emits metrics.
Can perform full list and retrieve operations, including query parameters on list.

Change-Id: I49f5a4e8de6bd8ad4982be8c25ea794e39bd42c8
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/81/113381/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/telemetry/v2/resource.py', 'openstack/tests/telemetry/v2/test_resource.py']",2,f1d7686b709dbbd6f24c16440b168d75df232784,add-telemetry-resource,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testtools from openstack.telemetry.v2 import meter IDENTIFIER = 'IDENTIFIER' EXAMPLE = { 'id': IDENTIFIER, 'name': 'instance', 'project_id': '123', 'resource_id': '456', 'source': 'abc', 'type': 'def', 'unit': 'ghi', 'user_id': '789' } class TestMeter(testtools.TestCase): def test_basic(self): sot = meter.Meter() self.assertEqual('meter', sot.resource_key) self.assertEqual('meters', sot.resources_key) self.assertEqual('/v2.0/meters', sot.base_path) self.assertEqual('telemetry', sot.service.service_type) self.assertTrue(sot.allow_create) self.assertTrue(sot.allow_retrieve) self.assertTrue(sot.allow_update) self.assertTrue(sot.allow_delete) self.assertTrue(sot.allow_list) def test_make_it(self): sot = meter.Meter(EXAMPLE) self.assertEqual(EXAMPLE['id'], sot.id) self.assertEqual(EXAMPLE['name'], sot.name) self.assertEqual(EXAMPLE['project_id'], sot.project_id) self.assertEqual(EXAMPLE['resource_id'], sot.resource_id) self.assertEqual(EXAMPLE['source'], sot.source) self.assertEqual(EXAMPLE['type'], sot.type) self.assertEqual(EXAMPLE['unit'], sot.unit) self.assertEqual(EXAMPLE['user_id'], sot.user_id) ",,88,0
openstack%2Ffuel-docs~master~Ife0d774c54c603a9eb8881649bf7cbdd8345e67d,openstack/fuel-docs,master,Ife0d774c54c603a9eb8881649bf7cbdd8345e67d,update Mirantis OpenStack version to 5.1,MERGED,2014-08-07 01:46:44.000000000,2014-08-15 16:57:30.000000000,2014-08-15 16:57:30.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-08-07 01:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3bb3c065ef8ece46c106dfddabc11facd2a2ec3f', 'message': 'update Mirantis OpenStack version to 5.1\n\nAdditional cleanups:\n\n * Removed duplicated explanation of Ceilometer\n   performance considerations for MongoDB database backend from the\n   terminology page and left it in the user guide where it belongs.\n\n * pt_archiver code fragment width reduced to fit inside page margins in\n   PDF.\n\n * toctree and preface removed from pdf_relnotes.rst.\n\nRelease notes are left referring 5.0.1, that will have to be addressed\nin a separate commit.\n\nChange-Id: Ife0d774c54c603a9eb8881649bf7cbdd8345e67d\n'}, {'number': 2, 'created': '2014-08-09 00:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e243bd5fc27b531bd9c828bd01416a3f0f4b426d', 'message': 'update Mirantis OpenStack version to 5.1\n\nAdditional cleanups:\n\n * Removed duplicated explanation of Ceilometer\n   performance considerations for MongoDB database backend from the\n   terminology page and left it in the user guide where it belongs.\n\n * pt_archiver code fragment width reduced to fit inside page margins in\n   PDF.\n\n * toctree and preface removed from pdf_relnotes.rst.\n\nRelease notes are left referring 5.0.1, that will have to be addressed\nin a separate commit.\n\nChange-Id: Ife0d774c54c603a9eb8881649bf7cbdd8345e67d\n'}, {'number': 3, 'created': '2014-08-15 16:55:48.000000000', 'files': ['pages/operations/perform/8200-keystone-tokens.rst', 'pdf/pdf_virtualbox.rst', 'common_conf.py', 'pdf/pdf_reference.rst', 'pdf/pdf_user.rst', 'pages/terminology/c/ceilometer.rst', 'pages/preface/preface.rst', 'pdf/pdf_relnotes.rst', 'pdf/pdf_operations.rst', 'index.rst', 'pages/operations/8500-ceilometer.rst', 'pdf/pdf_terminology.rst', 'pages/terminology/i/icehouse.rst', 'pdf/conf.py', 'pdf/pdf_planning-guide.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5bfe5ad403850d51c5e8e75a29c7aa2568d4e8b1', 'message': 'update Mirantis OpenStack version to 5.1\n\nAdditional cleanups:\n\n * Removed duplicated explanation of Ceilometer\n   performance considerations for MongoDB database backend from the\n   terminology page and left it in the user guide where it belongs.\n\n * pt_archiver code fragment width reduced to fit inside page margins in\n   PDF.\n\n * toctree and preface removed from pdf_relnotes.rst.\n\nRelease notes are left referring 5.0.1, that will have to be addressed\nin a separate commit.\n\nChange-Id: Ife0d774c54c603a9eb8881649bf7cbdd8345e67d\n'}]",6,112451,5bfe5ad403850d51c5e8e75a29c7aa2568d4e8b1,25,4,3,8787,,,0,"update Mirantis OpenStack version to 5.1

Additional cleanups:

 * Removed duplicated explanation of Ceilometer
   performance considerations for MongoDB database backend from the
   terminology page and left it in the user guide where it belongs.

 * pt_archiver code fragment width reduced to fit inside page margins in
   PDF.

 * toctree and preface removed from pdf_relnotes.rst.

Release notes are left referring 5.0.1, that will have to be addressed
in a separate commit.

Change-Id: Ife0d774c54c603a9eb8881649bf7cbdd8345e67d
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/51/112451/2 && git format-patch -1 --stdout FETCH_HEAD,"['pages/operations/perform/8200-keystone-tokens.rst', 'pdf/pdf_virtualbox.rst', 'common_conf.py', 'pdf/pdf_reference.rst', 'pdf/pdf_user.rst', 'pages/terminology/c/ceilometer.rst', 'pages/preface/preface.rst', 'pdf/pdf_relnotes.rst', 'pdf/pdf_operations.rst', 'index.rst', 'pages/operations/8500-ceilometer.rst', 'pdf/pdf_terminology.rst', 'pages/terminology/i/icehouse.rst', 'pdf/conf.py', 'pdf/pdf_planning-guide.rst']",15,3bb3c065ef8ece46c106dfddabc11facd2a2ec3f,up-version-to-5.1, | Mirantis OpenStack v5.1 | .. cssclass:: right|, | Mirantis OpenStack v5.0 | .. cssclass:: right|,35,48
openstack%2Fkeystone~master~I658a4dd479dbdcd07345c97d810c85aada3fa35b,openstack/keystone,master,I658a4dd479dbdcd07345c97d810c85aada3fa35b,Issue multiple SQL statements in separate engine.execute() calls,MERGED,2014-07-30 00:53:07.000000000,2014-08-15 16:56:23.000000000,2014-08-15 16:56:22.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 8871}, {'_account_id': 11279}, {'_account_id': 11816}]","[{'number': 1, 'created': '2014-07-30 00:53:07.000000000', 'files': ['keystone/common/sql/migrate_repo/versions/036_havana.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0c120a48406eb515e25c31cde21fe872ffa32417', 'message': 'Issue multiple SQL statements in separate engine.execute() calls\n\nSome sqlalchemy drivers (eg: mysqlconnector) don\'t support\nengine.execute(""sql stmt 1; sql stmt 2;"") and require a separate\nexecute() call for each SQL statement.  After discussions with\nsqlalchemy author, he confirmed it would be better to fix callers rather\nthan attempt to patch in support for multiple statements.\n\nWith this fix, keystone-manage db_sync succeeds using mysqlconnector.\n\nChange-Id: I658a4dd479dbdcd07345c97d810c85aada3fa35b\n'}]",0,110512,0c120a48406eb515e25c31cde21fe872ffa32417,20,7,1,11279,,,0,"Issue multiple SQL statements in separate engine.execute() calls

Some sqlalchemy drivers (eg: mysqlconnector) don't support
engine.execute(""sql stmt 1; sql stmt 2;"") and require a separate
execute() call for each SQL statement.  After discussions with
sqlalchemy author, he confirmed it would be better to fix callers rather
than attempt to patch in support for multiple statements.

With this fix, keystone-manage db_sync succeeds using mysqlconnector.

Change-Id: I658a4dd479dbdcd07345c97d810c85aada3fa35b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/12/110512/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/sql/migrate_repo/versions/036_havana.py'],1,0c120a48406eb515e25c31cde21fe872ffa32417,split-sql, migrate_engine.execute( 'ALTER TABLE migrate_version CONVERT TO CHARACTER SET utf8') migrate_engine.execute( 'ALTER DATABASE %s DEFAULT CHARACTER SET utf8' % migrate_engine.url.database), sql_stmt = 'ALTER TABLE migrate_version CONVERT TO CHARACTER SET utf8;' sql_stmt += ('ALTER DATABASE %s DEFAULT CHARACTER SET utf8;' % migrate_engine.url.database) migrate_engine.execute(sql_stmt),5,4
openstack%2Fsolum~master~I050d8ed0d49ca3679ea62b8d6ee4165f227193ba,openstack/solum,master,I050d8ed0d49ca3679ea62b8d6ee4165f227193ba,Configurable build-app and unittest logs,MERGED,2014-07-16 18:20:22.000000000,2014-08-15 16:54:12.000000000,2014-08-15 16:54:12.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 11324}]","[{'number': 1, 'created': '2014-07-16 18:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/338c8a1ac4b7762d5ea25580b342d3237f1381c1', 'message': 'WIP: Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 2, 'created': '2014-07-16 20:04:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/3e07ac24c9ba83d89b2ec85a8d054a9017abaa87', 'message': 'WIP: Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 3, 'created': '2014-07-16 20:13:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/99c118c802f888138f7990cd1358f0c34ee31e29', 'message': 'WIP: Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 4, 'created': '2014-07-16 20:24:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/0e67b3604102514598f416eef50338c6f9f4d67c', 'message': 'WIP: Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 5, 'created': '2014-07-17 15:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1673b50a0ca645f3380e2fa3a2b4a29c3d4ee1a4', 'message': 'WIP: Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 6, 'created': '2014-07-17 17:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/121df7904f42dd4330adc3d304fb36c673dd3b20', 'message': 'WIP: Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 7, 'created': '2014-07-21 20:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/9624587038672b60f7822dfd9abef8ac8f536914', 'message': 'WIP: Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 8, 'created': '2014-07-22 18:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/f4c6aae22c6e0b8d2f0cebe5422571b97bd7ca44', 'message': 'WIP: Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 9, 'created': '2014-07-22 20:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1a4979bd4d94a6dd92de3c29fddd089d902cccb9', 'message': 'WIP: Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 10, 'created': '2014-08-04 15:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6bf7f923612b3a2fc6bf15e45c433d85330cbb40', 'message': 'Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 11, 'created': '2014-08-04 17:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/fb01977b20e650e79733a5b32b2e6d1816ac81a7', 'message': 'Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 12, 'created': '2014-08-05 15:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/692b5f1cde0053fead58e72eecbb61acc9c7f21c', 'message': 'Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 13, 'created': '2014-08-13 16:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/536beb93de5a86eb37b64b4c9165e249dd136787', 'message': 'Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}, {'number': 14, 'created': '2014-08-14 15:26:00.000000000', 'files': ['solum/api/controllers/v1/datamodel/plan.py', 'solum/api/handlers/assembly_handler.py', 'contrib/lp-cedarish/docker/app-common', 'examples/plans/solum-pep8.yaml', 'solum/worker/config.py', 'etc/solum/solum.conf.sample', 'solum/worker/handlers/shell.py', 'contrib/lp-cedarish/docker/unittest-app', 'solum/tests/worker/handlers/test_shell.py', 'solum/conductor/handlers/default.py', 'solum/tests/worker/handlers/test_shell_nobuild.py', 'contrib/lp-cedarish/docker/build-app'], 'web_link': 'https://opendev.org/openstack/solum/commit/4e1922737c2fec5d64aea2f6b831f01799623f0f', 'message': 'Configurable build-app and unittest logs\n\nOutput from those stages is in a JSON format\nas set forth in the stage-logs spec.\n\nChange-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba\n'}]",23,107464,4e1922737c2fec5d64aea2f6b831f01799623f0f,59,5,14,1375,,,0,"Configurable build-app and unittest logs

Output from those stages is in a JSON format
as set forth in the stage-logs spec.

Change-Id: I050d8ed0d49ca3679ea62b8d6ee4165f227193ba
",git fetch https://review.opendev.org/openstack/solum refs/changes/64/107464/7 && git format-patch -1 --stdout FETCH_HEAD,"['solum/worker/handlers/shell.py', 'contrib/lp-cedarish/docker/unittest-app', 'solum/conductor/handlers/default.py', 'contrib/lp-cedarish/docker/app-common', 'examples/plans/solum-pep8.yaml', 'solum/worker/config.py', 'contrib/lp-cedarish/docker/build-app', 'etc/solum/solum.conf.sample']",8,338c8a1ac4b7762d5ea25580b342d3237f1381c1,logging-plus,# The directory containing task log output. #task_log_dir=/var/log/solum,,139,30
openstack%2Fpython-solumclient~master~I12360870fd4d91cbdc957bff7a316bd48f9bf12e,openstack/python-solumclient,master,I12360870fd4d91cbdc957bff7a316bd48f9bf12e,Updated from global requirements,MERGED,2014-08-13 23:25:25.000000000,2014-08-15 16:42:07.000000000,2014-08-15 16:42:07.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 8334}]","[{'number': 1, 'created': '2014-08-13 23:25:25.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/a7c0ba416c1cf07fab8757971b996f71a39da043', 'message': 'Updated from global requirements\n\nChange-Id: I12360870fd4d91cbdc957bff7a316bd48f9bf12e\n'}]",0,114077,a7c0ba416c1cf07fab8757971b996f71a39da043,10,3,1,11131,,,0,"Updated from global requirements

Change-Id: I12360870fd4d91cbdc957bff7a316bd48f9bf12e
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/77/114077/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a7c0ba416c1cf07fab8757971b996f71a39da043,openstack/requirements,requests>=1.2.1,requests>=1.1,1,1
openstack%2Fkeystone~master~Ibcf59aa45a8fc7e5cc66fd4edb91ae8fdc641d93,openstack/keystone,master,Ibcf59aa45a8fc7e5cc66fd4edb91ae8fdc641d93,Support the hints mechanism in list_credentials(),MERGED,2014-08-09 14:59:03.000000000,2014-08-15 16:38:39.000000000,2014-08-15 16:38:38.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 5707}, {'_account_id': 7725}, {'_account_id': 12215}]","[{'number': 1, 'created': '2014-08-09 14:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2e86c8940665c93d7079322a6cae294eb78571ea', 'message': 'Support the hints mechanism in list_credentials()\n\nThis fix implements the hints mechanism, considering filters as hints,\nso the particular backend implementation has an option to process or\nignore it. Since the EC2 credentials code calls list_credentials() with\nuser_id as a param, a separate method list_credentials_for_user has been\nintroduced to provide the compatibility while support the standard hints\nmechanism in list_credentials().\n\nCloses-Bug: #1353511\n\nChange-Id: Ibcf59aa45a8fc7e5cc66fd4edb91ae8fdc641d93\n'}, {'number': 2, 'created': '2014-08-10 14:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8fe0465d7fe0e868bd8b422db50825709289004b', 'message': 'Support the hints mechanism in list_credentials()\n\nThis fix implements the hints mechanism, considering filters as hints,\nso the particular backend implementation has an option to process or\nignore it. Since the EC2 credentials code calls list_credentials() with\nuser_id as a param, a separate method list_credentials_for_user has been\nintroduced to provide the compatibility while support the standard hints\nmechanism in list_credentials().\n\nCloses-Bug: #1353511\n\nChange-Id: Ibcf59aa45a8fc7e5cc66fd4edb91ae8fdc641d93\n'}, {'number': 3, 'created': '2014-08-10 19:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/557200c327d1600b141cf36c045c920c997d3c52', 'message': 'Support the hints mechanism in list_credentials()\n\nThis fix implements the hints mechanism, considering filters as hints,\nso the particular backend implementation has an option to process or\nignore it. Since the EC2 credentials code calls list_credentials() with\nuser_id as a param, a separate method list_credentials_for_user has been\nintroduced to provide the compatibility while support the standard hints\nmechanism in list_credentials().\n\nCloses-Bug: #1353511\n\nChange-Id: Ibcf59aa45a8fc7e5cc66fd4edb91ae8fdc641d93\n'}, {'number': 4, 'created': '2014-08-11 11:36:47.000000000', 'files': ['keystone/contrib/ec2/controllers.py', 'keystone/credential/backends/sql.py', 'keystone/tests/test_backend_sql.py', 'keystone/tests/test_v3_credential.py', 'keystone/credential/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/8aa322236ac406dc82a8965da0ed0006d0c4a3e0', 'message': ""Support the hints mechanism in list_credentials()\n\nThis fix implements the hints mechanism, considering filters as hints,\nso the particular backend implementation has an option to process or\nignore it. Since the EC2 credentials code calls list_credentials() with\nuser_id as a param, a separate method list_credentials_for_user has been\nintroduced to provide the compatibility while support the standard hints\nmechanism in list_credentials().\n\nThis fix doesn't plug hints into the controller, it prepares the way for\nimplementation of the bp filter-credentials-by-user to support filtering\ncredentials by user in a follow on patch.\n\nCloses-Bug: #1353511\n\nChange-Id: Ibcf59aa45a8fc7e5cc66fd4edb91ae8fdc641d93\n""}]",14,113091,8aa322236ac406dc82a8965da0ed0006d0c4a3e0,44,7,4,12215,,,0,"Support the hints mechanism in list_credentials()

This fix implements the hints mechanism, considering filters as hints,
so the particular backend implementation has an option to process or
ignore it. Since the EC2 credentials code calls list_credentials() with
user_id as a param, a separate method list_credentials_for_user has been
introduced to provide the compatibility while support the standard hints
mechanism in list_credentials().

This fix doesn't plug hints into the controller, it prepares the way for
implementation of the bp filter-credentials-by-user to support filtering
credentials by user in a follow on patch.

Closes-Bug: #1353511

Change-Id: Ibcf59aa45a8fc7e5cc66fd4edb91ae8fdc641d93
",git fetch https://review.opendev.org/openstack/keystone refs/changes/91/113091/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/contrib/ec2/controllers.py', 'keystone/credential/backends/sql.py', 'keystone/tests/test_backend_sql.py', 'keystone/tests/test_v3_credential.py', 'keystone/credential/core.py']",5,2e86c8940665c93d7079322a6cae294eb78571ea,bug/1353511,"from keystone.common import driver_hints @manager.response_truncated def list_credentials(self, hints=None): return self.driver.list_credentials(hints or driver_hints.Hints()) def list_credentials(self, hints): """"""List all credentials. :param hints: contains the list of filters yet to be satisfied. Any filters satisfied here will be removed so that the caller will know if any filters remain. :returns: a list of credential_refs or an empty list. """""" raise exception.NotImplemented() # pragma: no cover @abc.abstractmethod def list_credentials_for_user(self, user_id): """"""List credentials for a user. :param user_id: ID of a user to filter credentials by."," def list_credentials(self, **filters): """"""List all credentials in the system applying filters.",79,10
openstack%2Fnova~stable%2Ficehouse~I819ddf8ff68edc407d7932bf43771c440f514f26,openstack/nova,stable/icehouse,I819ddf8ff68edc407d7932bf43771c440f514f26,Read deleted instances during lifecycle events,MERGED,2014-08-07 08:58:17.000000000,2014-08-15 16:38:21.000000000,2014-08-15 16:38:19.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5196}, {'_account_id': 6873}, {'_account_id': 8213}, {'_account_id': 9008}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-08-07 08:58:17.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4e1e217000f5cc2ad5c199793f3ed2aefc89ec46', 'message': 'Read deleted instances during lifecycle events\n\nThis prevents us from failing to find the associated instance if\nthe lifecycle event happens after the instance has been deleted,\nas in the case of a ... delete.\n\nChange-Id: I819ddf8ff68edc407d7932bf43771c440f514f26\nCloses-bug: #1304968\n(cherry picked from commit 53ad788af6ced83bd9d6e58a25196a325d60fc4e)\n'}]",0,112520,4e1e217000f5cc2ad5c199793f3ed2aefc89ec46,17,8,1,6983,,,0,"Read deleted instances during lifecycle events

This prevents us from failing to find the associated instance if
the lifecycle event happens after the instance has been deleted,
as in the case of a ... delete.

Change-Id: I819ddf8ff68edc407d7932bf43771c440f514f26
Closes-bug: #1304968
(cherry picked from commit 53ad788af6ced83bd9d6e58a25196a325d60fc4e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/112520/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,4e1e217000f5cc2ad5c199793f3ed2aefc89ec46,bug/1304968, context = nova.context.get_admin_context(read_deleted='yes'), context = nova.context.get_admin_context(),1,1
openstack%2Ffuel-docs~stable%2F5.0~Icc29422aae2ec2a9380e2076bc0d639364966f02,openstack/fuel-docs,stable/5.0,Icc29422aae2ec2a9380e2076bc0d639364966f02,Release Notes and Supported Software for 5.0.1,MERGED,2014-08-15 00:11:43.000000000,2014-08-15 16:37:15.000000000,2014-08-15 16:37:06.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-08-15 00:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/72c2c9381a613f7012a7f65302a44d56b36751e3', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 2, 'created': '2014-08-15 16:35:43.000000000', 'files': ['pages/release-notes/v5-0/040-resolved-issues.rst', 'pages/release-notes/v5-0/039-resolved-issues-501.rst', 'pages/release-notes/v5-0/020-new-features.rst', 'pages/release-notes/v5-0/010-what-is-mirantis-openstack.rst', 'pages/release-notes/v5-0-icehouse-full.rst', 'pages/pre-install-guide/0025-supported-software-list.rst', 'pages/release-notes/v5-0/030-other-enhancements.rst', 'pages/release-notes/v5-0/050-known-issues.rst', 'pages/release-notes/v5-0/019-new-features-501.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/94714c196a5fa77ebe7a117dddafa35432cb8647', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}]",0,114398,94714c196a5fa77ebe7a117dddafa35432cb8647,15,4,2,8787,,,0,"Release Notes and Supported Software for 5.0.1

Release Notes
- Add 5.0.1 to preface.rst
- Updated title in 040-resolved-issues.rst and 050-known-issues.rst
- Add 019-new-features-501.rst with contents
- 030-other-enhancements -- moved note about Ubuntu version so it follows
  note about CentOS version, before note about Heartbleed
- Add 039-resolved-issues-501.rst with contents

Release/date control files -- updated for 5.0.1

Planning Guide -- updated ""Supported Software"" list for:
- Icehouse 2014.1.1
- Ceph 0.67.9 ""Dumpling""

Change-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/98/114398/2 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v5-0/039-resolved-issues-501.rst', 'pages/release-notes/v5-0/040-resolved-issues.rst', 'pages/release-notes/v5-0/020-new-features.rst', 'pages/release-notes/v5-0/010-what-is-mirantis-openstack.rst', 'pages/pre-install-guide/0025-supported-software-list.rst', 'pages/release-notes/v5-0-icehouse-full.rst', 'pages/release-notes/v5-0/030-other-enhancements.rst', 'pages/release-notes/v5-0/050-known-issues.rst', 'pages/release-notes/v5-0/019-new-features-501.rst']",9,72c2c9381a613f7012a7f65302a44d56b36751e3,501releasenotes," New Features in Mirantis OpenStack 5.0.1 ======================================== Support for the latest stable OpenStack IceHouse release -------------------------------------------------------- Mirantis OpenStack 5.0.1 provides hardened packages of the core OpenStack components that are included in the `OpenStack Icehouse 2014.1.1 <https://wiki.openstack.org/wiki/ReleaseNotes/2014.1.1>`_ release. Fuel 5.0.1 can deploy this version of OpenStack on either CentOS or Ubuntu. The Fuel Master Node is upgradable ---------------------------------- If you are running a Mirantis OpenStack 5.0 environment, you can upgrade to Fuel 5.0.1 but leave your OpenStack 5.0 environment in place. After the upgrade, the Fuel Master Node will be able to deploy either a Mirantis OpenStack 5.0 or 5.0.1 environment. It can add and delete nodes and perform other operational functions such as log management and Health Checks on either a 5.0.1 environment or a 5.0 environment. See :ref:`upgrade-ug` for details and instructions. .. Note:: This only upgrades the Fuel Master Node. It does not patch or update the OpenStack environment. The ability to patch and update OpenStack environments is planned for a future release. After the upgrade, you can deploy a Mirantis OpenStack 5.0 environment from the Fuel 5.0.1 dashboard by choosing one of the 2014.1 distros for the environment on the :ref:`name-distro-ug` screen. ",,615,188
openstack%2Ffuel-docs~master~Icc29422aae2ec2a9380e2076bc0d639364966f02,openstack/fuel-docs,master,Icc29422aae2ec2a9380e2076bc0d639364966f02,Release Notes and Supported Software for 5.0.1,MERGED,2014-07-02 22:49:05.000000000,2014-08-15 16:37:04.000000000,2014-08-15 16:37:04.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 3012}, {'_account_id': 6926}, {'_account_id': 7109}, {'_account_id': 7195}, {'_account_id': 7600}, {'_account_id': 8392}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 10014}, {'_account_id': 10136}, {'_account_id': 10391}, {'_account_id': 11090}, {'_account_id': 11427}]","[{'number': 1, 'created': '2014-07-02 22:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c99549e5b4e6fce35fbea2507174c10c6c8d2c40', 'message': 'Set up Release Notes, etc for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Add 019-new-features-501.rst with contents\n- Add 039-resolved-issues-501.rst without contents\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nUser Guide\n- Add note about upgrade to 0070-introduction.rst with link to 8000-upgrade.rst\n- Created 8000-upgrade.rst without contents\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 2, 'created': '2014-07-02 22:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4b8fc00a12bdf680e5092446a4495ac52cc301dd', 'message': 'Set up Release Notes, etc for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Add 019-new-features-501.rst with contents\n- Add 039-resolved-issues-501.rst without contents\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nUser Guide\n- Add note about upgrade to 0070-introduction.rst with link to 8000-upgrade.rst\n- Created 8000-upgrade.rst without contents\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 3, 'created': '2014-07-07 17:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/63a52f1472428215b999758b09f79f1fb8478780', 'message': 'Set up Release Notes, etc for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Add 019-new-features-501.rst with contents\n- Add 039-resolved-issues-501.rst with contents\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nUser Guide\n- Add note about upgrade to 0070-introduction.rst with link to 8000-upgrade.rst\n- Created 8000-upgrade.rst without contents\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 4, 'created': '2014-07-08 01:14:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5f67ab49d9527573c9af2fc273305bed8ea7a78b', 'message': 'Set up Release Notes, etc for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Add 019-new-features-501.rst with contents\n- Add 039-resolved-issues-501.rst with contents\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nUser Guide\n- Add note about upgrade to 0070-introduction.rst with link to 8000-upgrade.rst\n- Created 8000-upgrade.rst without contents\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 5, 'created': '2014-07-08 01:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0c1833429a45ad7b3c233eddb87cd2d4104d6bd5', 'message': 'Set up Release Notes, etc for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Add 019-new-features-501.rst with contents\n- Add 039-resolved-issues-501.rst with contents\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nUser Guide\n- Add note about upgrade to 0070-introduction.rst with link to 8000-upgrade.rst\n- Created 8000-upgrade.rst without contents\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 6, 'created': '2014-07-11 17:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e593249ff06493f322a93759f717e01892b0c9bb', 'message': 'Set up Release Notes, etc for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Add 019-new-features-501.rst with contents\n- Add 039-resolved-issues-501.rst with contents\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 7, 'created': '2014-07-11 17:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/bdc9d6ed7c55ebb860bcb69b1b5f8af9e0dcab8b', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 8, 'created': '2014-07-11 21:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f9c0e615d5ac994a87e9a6d6542ac1db30b674b9', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 9, 'created': '2014-07-11 23:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3fb19a6f6bcc9e88138988438bca15794ecb817f', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 10, 'created': '2014-07-14 09:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/611015d731d43b2aeaf75be340f00fb226b8e504', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 11, 'created': '2014-07-14 18:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/b94438cbe3c511a6c1d99d6aff46af64550caa6a', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 12, 'created': '2014-07-14 23:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/04e2065ed5d86c1e2a04cf46d214bef58161ffc8', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 13, 'created': '2014-07-14 23:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/9e1b440a2f3ebb57cd51dfcc257e81fec0c0ad02', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 14, 'created': '2014-07-15 12:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4e4caffd36e33cb0f3ba795aa8264b1a7bb976a8', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 15, 'created': '2014-07-16 08:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/face08ecac159415b95bfaf7fc99abb716084d61', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 16, 'created': '2014-07-16 10:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0f3cb9f8837859e78720b7fa68460d722da56bfd', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for Icehouse 2014.1.1\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 17, 'created': '2014-07-28 17:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4b97514264b98fe28b08fd3a3f59fbeb5832e486', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 67.9 (""Dumpling)""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 18, 'created': '2014-07-29 03:02:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/21878c9c90ef7899a2584a8f10327e249d03d705', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 67.9 (""Dumpling)""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 19, 'created': '2014-07-31 00:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a0e6b8fc6b8bf2883d03366edce91b7e783a0b8c', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 67.9 (""Dumpling)""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 20, 'created': '2014-07-31 01:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/07c4add65f1bf21059a32f9a1d49109bda626ad8', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 67.9 (""Dumpling)""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 21, 'created': '2014-07-31 01:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ea77be8afae60ba41b3350317625539750875f61', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 67.9 (""Dumpling)""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 22, 'created': '2014-07-31 03:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/b11af8f2debd0659e9ba10191d0807868de03038', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 23, 'created': '2014-07-31 03:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5e3fc6d0c7905b802615065996b99e4536bd1a0c', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 24, 'created': '2014-07-31 09:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/162eab810aef940df94c9e699111e708ca638347', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 25, 'created': '2014-07-31 20:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3941510d125ebf7017acfc0c28c2c816d6bcd2fb', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 26, 'created': '2014-08-05 03:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c51eb649d179c8211d49f9569a3a8f0b0adc50db', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 27, 'created': '2014-08-05 03:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/bc9dd8fad198913533286368e5be998292bc3f13', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 28, 'created': '2014-08-05 08:57:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0c181dd766dc22e2591cf1c3720e2d2ad2e9a550', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 29, 'created': '2014-08-05 19:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ffb9a5cfe4e4278dddeb07efb2d698ad32f976e4', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 30, 'created': '2014-08-05 23:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a7bdd9d47e78c7907430eef51ec96ca792958c67', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 31, 'created': '2014-08-06 00:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/de81e6d83424039d06b28a663e97c4d11c943ada', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 32, 'created': '2014-08-06 18:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/496717c91d6e4054ef5e6e17a21dc6086087f1a5', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 33, 'created': '2014-08-06 22:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d7b40e3c3f23dc20077f846888f3d45466cd05ec', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 34, 'created': '2014-08-07 09:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/11606ce7b7331bdca7cf1fcccc569167179a2886', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 35, 'created': '2014-08-07 10:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/82f15b4596afe793419c2129a415b4bf4ddb4b36', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 36, 'created': '2014-08-07 20:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/51f1f0d8cb0924bbc47eaceceaa5a8d343030030', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 37, 'created': '2014-08-09 00:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/82ddb963ce72a96c6e693b2f86b5be70606a1134', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 38, 'created': '2014-08-12 09:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0031e1de8e6208c1b9939171e874ea0122208cc8', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 39, 'created': '2014-08-12 21:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/33a894ead141d376cba0bfb4259a61b094953174', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 40, 'created': '2014-08-13 17:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4364b6cf6771e1b6eeeeb52d9882afae3ca11c09', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 41, 'created': '2014-08-13 18:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5e735fd41eb61b0be288c7cb6d33d2a4bf1a9d3d', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 42, 'created': '2014-08-13 20:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ab5545246982037b83b884e71f88be501efb7d41', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 43, 'created': '2014-08-13 22:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/b10dc8c20fbaf218ddf1d45c519a9961115a5055', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 44, 'created': '2014-08-13 23:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/93dcf6201ea7f88172e8f2c64f0add75ebf4b5a1', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 45, 'created': '2014-08-14 00:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3b306113ca49a679506754ac92bd9f7df25d0c9f', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 46, 'created': '2014-08-14 00:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/31130bcd5ce801ff3eeb4442dda88d0b0ff9b59e', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 47, 'created': '2014-08-14 08:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0ff841cf31fde13e5d9e2d890a5325913590d13a', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 48, 'created': '2014-08-14 11:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4edb81830c4236689bf9647946aa8b0d732d304f', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 49, 'created': '2014-08-14 15:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/91b0d267bdadb404bc9f868fdd020e34755ad432', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 50, 'created': '2014-08-14 21:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3a15a97a42d526e334360e8f7196452c571060b4', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 51, 'created': '2014-08-14 21:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1e981532a332834e2328b5d5aa9978c251f85710', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 52, 'created': '2014-08-15 00:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1c4d44a38810a9e5354323800fe067415b09b65c', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 53, 'created': '2014-08-15 06:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/531f757f95480bbcec03f12301af6fc0e8e93fe3', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 54, 'created': '2014-08-15 09:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/b901894084b573f7526025d28d5aadb3e8e498fd', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 55, 'created': '2014-08-15 14:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f9688242c12096c060cae37a7abe43a533f95627', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}, {'number': 56, 'created': '2014-08-15 16:35:16.000000000', 'files': ['pages/release-notes/v5-0/040-resolved-issues.rst', 'pages/release-notes/v5-0/039-resolved-issues-501.rst', 'pages/planning-guide/0025-supported-software-list.rst', 'pages/release-notes/v5-0/020-new-features.rst', 'pages/release-notes/v5-0/010-what-is-mirantis-openstack.rst', 'common_conf.py', 'pages/release-notes/v5-0-icehouse-full.rst', 'pages/release-notes/v5-0/030-other-enhancements.rst', 'pages/release-notes/v5-0/050-known-issues.rst', 'pages/preface/preface.rst', 'pages/release-notes/v5-0/019-new-features-501.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3a64ff0d832a88e0beab0600da6283f6a11463b1', 'message': 'Release Notes and Supported Software for 5.0.1\n\nRelease Notes\n- Add 5.0.1 to preface.rst\n- Updated title in 040-resolved-issues.rst and 050-known-issues.rst\n- Add 019-new-features-501.rst with contents\n- 030-other-enhancements -- moved note about Ubuntu version so it follows\n  note about CentOS version, before note about Heartbleed\n- Add 039-resolved-issues-501.rst with contents\n\nRelease/date control files -- updated for 5.0.1\n\nPlanning Guide -- updated ""Supported Software"" list for:\n- Icehouse 2014.1.1\n- Ceph 0.67.9 ""Dumpling""\n\nChange-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02\n'}]",156,104369,3a64ff0d832a88e0beab0600da6283f6a11463b1,382,19,56,10014,,,0,"Release Notes and Supported Software for 5.0.1

Release Notes
- Add 5.0.1 to preface.rst
- Updated title in 040-resolved-issues.rst and 050-known-issues.rst
- Add 019-new-features-501.rst with contents
- 030-other-enhancements -- moved note about Ubuntu version so it follows
  note about CentOS version, before note about Heartbleed
- Add 039-resolved-issues-501.rst with contents

Release/date control files -- updated for 5.0.1

Planning Guide -- updated ""Supported Software"" list for:
- Icehouse 2014.1.1
- Ceph 0.67.9 ""Dumpling""

Change-Id: Icc29422aae2ec2a9380e2076bc0d639364966f02
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/69/104369/54 && git format-patch -1 --stdout FETCH_HEAD,"['relnotes/index.rst', 'pages/release-notes/v5-0/040-resolved-issues.rst', 'pages/planning-guide/0025-supported-software-list.rst', 'pages/release-notes/v5-0/010-what-is-mirantis-openstack.rst', 'relnotes/conf.py', 'common_conf.py', 'pages/release-notes/v5-0-icehouse-full.rst', 'pages/preface/preface.rst', 'pages/release-notes/v5-0/039-resolved-issues-501.rst', 'pages/user-guide/0070-introduction.rst', 'index.rst', 'contents/contents-user.rst', 'pages/release-notes/v5-0/050-known-issues.rst', 'pages/release-notes/v5-0/019-new-features-501.rst', 'pages/user-guide/8000-upgrade.rst']",15,c99549e5b4e6fce35fbea2507174c10c6c8d2c40,501releasenotes, .. _upgrade-ug: Upgrade from an Earlier Version =============================== Content to come. ,,94,22
openstack%2Ffuel-docs~stable%2F5.0~I12338309b5388edb96e2911e054a50a347a63072,openstack/fuel-docs,stable/5.0,I12338309b5388edb96e2911e054a50a347a63072,update version to 5.0.1 across all docs,MERGED,2014-08-13 20:14:27.000000000,2014-08-15 16:36:38.000000000,2014-08-15 16:36:38.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-13 20:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3138790b57f285f8a17fdf6a7423196e79e9049a', 'message': 'update version to 5.0.1 across all docs\n\nChange-Id: I12338309b5388edb96e2911e054a50a347a63072\n'}, {'number': 2, 'created': '2014-08-14 22:29:53.000000000', 'files': ['pdf/pdf_preinstall.rst', 'pdf/pdf_virtualbox.rst', 'relnotes/index.rst', 'relnotes/conf.py', 'common_conf.py', 'pdf/pdf_reference.rst', 'pdf/pdf_user.rst', 'pages/preface/preface.rst', 'pdf/pdf_relnotes.rst', 'pdf/pdf_operations.rst', 'index.rst', 'pdf/pdf_terminology.rst', 'pdf/conf.py'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/cf36dffc15439a4fceeb7b0cff3d54af1a813987', 'message': 'update version to 5.0.1 across all docs\n\nChange-Id: I12338309b5388edb96e2911e054a50a347a63072\n'}]",0,114013,cf36dffc15439a4fceeb7b0cff3d54af1a813987,16,3,2,8787,,,0,"update version to 5.0.1 across all docs

Change-Id: I12338309b5388edb96e2911e054a50a347a63072
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/13/114013/2 && git format-patch -1 --stdout FETCH_HEAD,"['pdf/pdf_preinstall.rst', 'pdf/pdf_virtualbox.rst', 'relnotes/index.rst', 'relnotes/conf.py', 'common_conf.py', 'pdf/pdf_reference.rst', 'pdf/pdf_user.rst', 'pages/release-notes/v5-0-icehouse-full.rst', 'pages/preface/preface.rst', 'pdf/pdf_relnotes.rst', 'pdf/pdf_operations.rst', 'index.rst', 'pdf/pdf_terminology.rst', 'pdf/conf.py']",14,3138790b57f285f8a17fdf6a7423196e79e9049a,up-version-to-5.0.1," ('pdf/pdf_preinstall', u'Mirantis-OpenStack-5.0.1-PlanningGuide', u'Planning Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_user', u'Mirantis-OpenStack-5.0.1-UserGuide', u'User Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_operations', u'Mirantis-OpenStack-5.0.1-OperationsGuide', u'Operations Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_virtualbox', u'Mirantis-OpenStack-5.0.1-Running-Mirantis-OpenStack-on-VirtualBox', u'Running Mirantis OpenStack on VirtualBox', u'2014, Mirantis Inc.'), ('pdf/pdf_reference', u'Mirantis-OpenStack-5.0.1-ReferenceArchitecture', u'Reference Architecture', u'2014, Mirantis Inc.'), ('pdf/pdf_terminology', u'Mirantis-OpenStack-5.0.1-Terminology-Reference', u'Terminology Reference', u'2014, Mirantis Inc.'),"," ('pdf/pdf_preinstall', u'Mirantis-OpenStack-5.0-PlanningGuide', u'Planning Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_user', u'Mirantis-OpenStack-5.0-UserGuide', u'User Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_operations', u'Mirantis-OpenStack-5.0-OperationsGuide', u'Operations Guide', u'2014, Mirantis Inc.'), ('pdf/pdf_virtualbox', u'Mirantis-OpenStack-5.0-Running-Mirantis-OpenStack-on-VirtualBox', u'Running Mirantis OpenStack on VirtualBox', u'2014, Mirantis Inc.'), ('pdf/pdf_reference', u'Mirantis-OpenStack-5.0-ReferenceArchitecture', u'Reference Architecture', u'2014, Mirantis Inc.'), ('pdf/pdf_terminology', u'Mirantis-OpenStack-5.0-Terminology-Reference', u'Terminology Reference', u'2014, Mirantis Inc.'),",31,27
openstack%2Ffuel-docs~stable%2F5.0~Ie48d69461da1427d31b67f916d5e1a2abed95e91,openstack/fuel-docs,stable/5.0,Ie48d69461da1427d31b67f916d5e1a2abed95e91,Document Filter Scheduler and overcommit ratio,MERGED,2014-07-31 03:08:49.000000000,2014-08-15 16:36:17.000000000,2014-08-15 16:36:16.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-07-31 03:08:49.000000000', 'files': ['pages/terminology/s/scheduler.rst', 'pages/terminology/o/overcommit.rst', 'pages/terminology/allterms.rst', 'pages/user-guide/2000-deploy-new-environment.rst', '_images/user_screen_shots/settings-scheduler.png', 'pages/release-notes/v5-0/030-other-enhancements.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ed485904073b8baf1679c726bab266dc9f78d172', 'message': 'Document Filter Scheduler and overcommit ratio\n\nTerminology: add ""Scheduler"" and ""Overcommit ratio"" articles.\n\nUser guide: add section with graphic for Settings page where one\ncan select the older scheduler\n\nRelease Notes: add sections for ""Filter Scheduler"" and ""Overcommit ratio""\nto 030-other-enhancements\n\nChange-Id: Ie48d69461da1427d31b67f916d5e1a2abed95e91\nCloses-Bug: 1333436\n'}]",0,110840,ed485904073b8baf1679c726bab266dc9f78d172,12,4,1,8787,,,0,"Document Filter Scheduler and overcommit ratio

Terminology: add ""Scheduler"" and ""Overcommit ratio"" articles.

User guide: add section with graphic for Settings page where one
can select the older scheduler

Release Notes: add sections for ""Filter Scheduler"" and ""Overcommit ratio""
to 030-other-enhancements

Change-Id: Ie48d69461da1427d31b67f916d5e1a2abed95e91
Closes-Bug: 1333436
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/40/110840/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/terminology/s/scheduler.rst', 'pages/terminology/o/overcommit.rst', 'pages/terminology/allterms.rst', 'pages/user-guide/2000-deploy-new-environment.rst', '_images/user_screen_shots/settings-scheduler.png', 'pages/release-notes/v5-0/030-other-enhancements.rst']",6,ed485904073b8baf1679c726bab266dc9f78d172,bug/1333436,"Filter Scheduler improves how compute requests are dispatched ------------------------------------------------------------- The Filter Scheduler is enabled by default for the nova-compute service. The scheduler determines how to allocate new VM instances among the configured Compute Nodes. The Filter Scheduler uses filtering and weighting to make better decisions than the older scheduler. Users can, however, select the traditional (""naive"") scheduler from the Fuel ""Settings"" page. This is discussed more in the :ref:`scheduler-term` article. See `Some improvements in Nova Scheduler config <https://blueprints.launchpad.net/fuel/+spec/scheduler-config-improvements>`_. Overcommit ratio allows better resource allocation -------------------------------------------------- The overcommit ratio allows you to assign more CPU, memory, and disk resources to allocated instances than is physically available on the Compute nodes. This allows you to better utilize the available resources because most instances are not fully active at the same time. See :ref:`overcommit-term` for information about modifying the overcommit ratio for your environment by manually editing a configuration file. The overcommit ratio is not configurable from the Fuel UI; see `LP1333436 <https://bugs.launchpad.net/fuel/+bug/1333436>`_. ",,130,0
openstack%2Fneutron~master~I3b7f5b18ef5b2bd257eb11669ec35397653cbc8b,openstack/neutron,master,I3b7f5b18ef5b2bd257eb11669ec35397653cbc8b,Updated from global requirements,MERGED,2014-08-13 23:20:06.000000000,2014-08-15 16:25:39.000000000,2014-08-15 16:25:38.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-08-13 23:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6cb883a40672dbe3b1ef7c764884dd097e91e57', 'message': 'Updated from global requirements\n\nChange-Id: I3b7f5b18ef5b2bd257eb11669ec35397653cbc8b\n'}, {'number': 2, 'created': '2014-08-14 12:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f4ddaa0bc2271063d1418dfbdf6880b432f110a', 'message': 'Updated from global requirements\n\nChange-Id: I3b7f5b18ef5b2bd257eb11669ec35397653cbc8b\n'}, {'number': 3, 'created': '2014-08-14 19:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce63c8ef52fcd6d219e4be6508fdf14cc3ed8e30', 'message': 'Updated from global requirements\n\nChange-Id: I3b7f5b18ef5b2bd257eb11669ec35397653cbc8b\n'}, {'number': 4, 'created': '2014-08-14 20:25:04.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5b89bb273bc9c6391f7f68ec5aebbc050ad9c68', 'message': 'Updated from global requirements\n\nChange-Id: I3b7f5b18ef5b2bd257eb11669ec35397653cbc8b\n'}]",0,114061,b5b89bb273bc9c6391f7f68ec5aebbc050ad9c68,71,21,4,11131,,,0,"Updated from global requirements

Change-Id: I3b7f5b18ef5b2bd257eb11669ec35397653cbc8b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/114061/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c6cb883a40672dbe3b1ef7c764884dd097e91e57,openstack/requirements,requests>=1.2.1,requests>=1.1,1,1
openstack%2Ffuel-web~master~I5906cbfc094e0d0ca67158ba9fbec233eefb014e,openstack/fuel-web,master,I5906cbfc094e0d0ca67158ba9fbec233eefb014e,Delete task 'deploy' before raise exception on deployment start,MERGED,2014-08-15 15:18:02.000000000,2014-08-15 16:14:40.000000000,2014-08-15 16:14:40.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-08-15 15:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5daa572e856a683f1a1c80278fecbd6a28ce5f75', 'message': ""Delete task 'deploy' before raise exception on deployment start\n\nCloses-Bug: #1354401\n\nChange-Id: I5906cbfc094e0d0ca67158ba9fbec233eefb014e\n""}, {'number': 2, 'created': '2014-08-15 15:28:02.000000000', 'files': ['nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/task/manager.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bc9e377dbe010732bc2ba47161ed9d433998e07b', 'message': ""Delete task 'deploy' before raise exception on deployment start\n\nCloses-Bug: #1354401\n\nChange-Id: I5906cbfc094e0d0ca67158ba9fbec233eefb014e\n""}]",0,114568,bc9e377dbe010732bc2ba47161ed9d433998e07b,19,6,2,8392,,,0,"Delete task 'deploy' before raise exception on deployment start

Closes-Bug: #1354401

Change-Id: I5906cbfc094e0d0ca67158ba9fbec233eefb014e
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/68/114568/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/task/manager.py']",2,5daa572e856a683f1a1c80278fecbd6a28ce5f75,bug/1354401, db().delete(supertask) db().commit(),,4,0
openstack%2Fopenstack-manuals~master~Ia4862a7fd2c5784324897d6642b1ad205f82298c,openstack/openstack-manuals,master,Ia4862a7fd2c5784324897d6642b1ad205f82298c,Adding in content to the deployment overview file,MERGED,2014-08-09 04:42:01.000000000,2014-08-15 15:47:34.000000000,2014-08-15 15:47:33.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 8369}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-08-09 04:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/59a7f43e0dee96fec36817c3cf942bac77429e1c', 'message': 'Adding in content and images to the deployment overview file\n\nIncluding information from the Red Hat documentation and added\nan Images folder.\n\nChange-Id: Ia4862a7fd2c5784324897d6642b1ad205f82298c\n'}, {'number': 2, 'created': '2014-08-09 07:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c4d6c0851e30bb6871c6526fa4c304d8e36c7515', 'message': 'Adding in content and images to the deployment overview file\n\nIncluding information from the Red Hat documentation and added\nan Images folder.\n\nChange-Id: Ia4862a7fd2c5784324897d6642b1ad205f82298c\n'}, {'number': 3, 'created': '2014-08-09 07:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d0d2a935f96c15fd0530aab54a0e799090ab22c4', 'message': 'Adding in content and images to the deployment overview file\n\nIncluding information from the Red Hat documentation and added\nan Images folder.\n\nChange-Id: Ia4862a7fd2c5784324897d6642b1ad205f82298c\n'}, {'number': 4, 'created': '2014-08-14 20:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ed5d6f64309954f432596d1defa31899b64fa2dc', 'message': 'Adding in content and images to the deployment overview file\n\nIncluding information from the Red Hat documentation and added\nan Images folder.\n\nChange-Id: Ia4862a7fd2c5784324897d6642b1ad205f82298c\n'}, {'number': 5, 'created': '2014-08-15 14:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3388f9e86137feb5ea457c80d0287d405895a825', 'message': 'Adding in content and images to the deployment overview file\n\nIncluding information from the Red Hat documentation and added\nan Images folder.\n\nChange-Id: Ia4862a7fd2c5784324897d6642b1ad205f82298c\n'}, {'number': 6, 'created': '2014-08-15 14:57:03.000000000', 'files': ['doc/networking-guide/ch_deployment.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7bca9cd05bf6826fd4db4ea44c74e3f75335c1df', 'message': 'Adding in content to the deployment overview file\n\nIncluding information from the Red Hat documentation.\n\nChange-Id: Ia4862a7fd2c5784324897d6642b1ad205f82298c\n'}]",11,113063,7bca9cd05bf6826fd4db4ea44c74e3f75335c1df,32,5,6,10607,,,0,"Adding in content to the deployment overview file

Including information from the Red Hat documentation.

Change-Id: Ia4862a7fd2c5784324897d6642b1ad205f82298c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/63/113063/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/ch_deployment.xml'],1,59a7f43e0dee96fec36817c3cf942bac77429e1c,113063," OpenStack Networking provides an extreme amount of flexibility when deploying networking in support of a compute environment. As a result, the exact layout of a deployment will depend on a combination of expected workloads, expected scale, and available hardware. <mediaobject> <imageobject> <imagedata fileref=""Images/deployment_architecture.png"" align=""center"" width=""6in""/> </imageobject> </mediaobject> <para> For demonstration purposes, this chapter concentrates on a networking deployment that consists of these types of nodes:</para> <itemizedlist> <listitem> <para> <emphasis>Service Node:</emphasis> The service node exposes the networking API to clients and handles incoming requests before forwarding them to a message queue to be actioned by the other nodes. The service node hosts both the networking service itself and the active networking plug-in. In environments that use controller nodes to host the client-facing APIs and schedulers for all services, the controller node would also fulfil the role of service node as it is applied in this chapter. </para> <para> <emphasis>Network Node:</emphasis> The network node handles the majority of the networking workload. It hosts the DHCP agent, the Layer 3 (L3) agent, the Layer 2 (L2) Agent, and the metadata proxy. In addition to plug-ins that require an agent, it runs an instance of the plug-in agent (as do all other systems that handle data packets in an environment where such plug-ins are in use). Both the Open vSwitch and Linux Bridge plug-ins include an agent. </para> <para> <emphasis>Compute Node:</emphasis> The compute hosts the compute instances themselves. To connect compute instances to the networking services, compute nodes must also run the L2 agent. Like all other systems that handle data packets it must also run an instance of the plug-in agent. </para> </listitem> </itemizedlist> "," Bacon ipsum dolor sit amet biltong meatloaf andouille, turducken bresaola pork belly beef ribs ham hock capicola tail prosciutto landjaeger meatball pork loin. Swine turkey jowl, porchetta doner boudin meatloaf. Shoulder capicola prosciutto, shank landjaeger short ribs sirloin turducken pork belly boudin frankfurter chuck. Salami shankle bresaola cow filet mignon ham hock shank.",42,6
openstack%2Foslo-specs~master~Icad270434657b9f4d7065b9a8b0988efa9a6f337,openstack/oslo-specs,master,Icad270434657b9f4d7065b9a8b0988efa9a6f337,Update oslo.utils spec mention of mask_password,ABANDONED,2014-08-15 14:47:51.000000000,2014-08-15 15:40:03.000000000,,"[{'_account_id': 3}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-08-15 14:47:51.000000000', 'files': ['specs/juno/graduate-oslo-utils.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/adc5e1ef3dce4416c6e581755028084c354a6870', 'message': 'Update oslo.utils spec mention of mask_password\n\nWe decided to move mask_password() from strutils to to oslo.log, so\nupdate the spec to reflect that.\n\nChange-Id: Icad270434657b9f4d7065b9a8b0988efa9a6f337\n'}]",0,114558,adc5e1ef3dce4416c6e581755028084c354a6870,5,2,1,2472,,,0,"Update oslo.utils spec mention of mask_password

We decided to move mask_password() from strutils to to oslo.log, so
update the spec to reflect that.

Change-Id: Icad270434657b9f4d7065b9a8b0988efa9a6f337
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/58/114558/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/graduate-oslo-utils.rst'],1,adc5e1ef3dce4416c6e581755028084c354a6870,update-oslo-utils-mask-password,* Move :func:`mask_password` to oslo.log. See :doc:`graduate-oslo-log`., - mask_password,1,1
openstack%2Fceilometer~master~Ib6ab7838c718c30a84dd5e59dcc986515dc54731,openstack/ceilometer,master,Ib6ab7838c718c30a84dd5e59dcc986515dc54731,[HBase] Refactor hbase.utils,MERGED,2014-08-01 13:01:32.000000000,2014-08-15 15:35:44.000000000,2014-08-15 15:35:43.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 9562}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-08-01 13:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/724f258575fac14380c7461f79c2f23116814151', 'message': '[HBase] Refactor hbase.utils\n\nThis change implements a refactor for hbase.utils. Preparing of filters\nis shifted from make_events_query_from_filter to make_query\nmethod.\nImplicit using of comparison operators in filters now become explicit.\n\nChange-Id: Ib6ab7838c718c30a84dd5e59dcc986515dc54731\n'}, {'number': 2, 'created': '2014-08-05 08:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/96d77d1863006fd35ed0ad3bb47df0e0ae0fbbac', 'message': '[HBase] Refactor hbase.utils\n\nThis change implements a refactor for hbase.utils. Preparing of filters\nis shifted from make_events_query_from_filter to make_query\nmethod.\nImplicit using of comparison operators in filters now become explicit.\n\nChange-Id: Ib6ab7838c718c30a84dd5e59dcc986515dc54731\n'}, {'number': 3, 'created': '2014-08-06 11:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/59815b74baccfc03a59973c41cb0afaf9ace5937', 'message': '[HBase] Refactor hbase.utils\n\nThis change implements a refactor for hbase.utils. Preparing of filters\nis shifted from make_events_query_from_filter to make_query\nmethod.\nImplicit using of comparison operators in filters has become explicit.\n\nChange-Id: Ib6ab7838c718c30a84dd5e59dcc986515dc54731\n'}, {'number': 4, 'created': '2014-08-06 13:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6dd6fc937298ad9727015064adcf2204a10587dc', 'message': '[HBase] Refactor hbase.utils\n\nThis change implements a refactor for hbase.utils. Preparing of filters\nis shifted from make_events_query_from_filter to make_query\nmethod.\nImplicit using of comparison operators in filters has become explicit.\n\nChange-Id: Ib6ab7838c718c30a84dd5e59dcc986515dc54731'}, {'number': 5, 'created': '2014-08-07 08:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7a1e59248228725dbd463802dbd1df5eff3642f7', 'message': '[HBase] Refactor hbase.utils\n\nThis change implements a refactor for hbase.utils. Preparing of filters\nis shifted from make_events_query_from_filter to make_query\nmethod.\nImplicit using of comparison operators in filters has become explicit.\n\nChange-Id: Ib6ab7838c718c30a84dd5e59dcc986515dc54731'}, {'number': 6, 'created': '2014-08-12 12:59:26.000000000', 'files': ['ceilometer/storage/hbase/inmemory.py', 'ceilometer/storage/hbase/utils.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2339036d8a6029ef0d29077e0dbeeb3344d2158b', 'message': '[HBase] Refactor hbase.utils\n\nThis change implements a refactor for hbase.utils. Preparing of filters\nis shifted from make_events_query_from_filter to make_query\nmethod.\nImplicit using of comparison operators in filters has become explicit.\n\nChange-Id: Ib6ab7838c718c30a84dd5e59dcc986515dc54731'}]",10,111270,2339036d8a6029ef0d29077e0dbeeb3344d2158b,63,9,6,10987,,,0,"[HBase] Refactor hbase.utils

This change implements a refactor for hbase.utils. Preparing of filters
is shifted from make_events_query_from_filter to make_query
method.
Implicit using of comparison operators in filters has become explicit.

Change-Id: Ib6ab7838c718c30a84dd5e59dcc986515dc54731",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/70/111270/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/hbase/inmemory.py', 'ceilometer/storage/hbase/utils.py']",2,724f258575fac14380c7461f79c2f23116814151,Refactor,"OP_SIGN = {'eq': '=', 'lt': '<', 'le': '<=', 'ne': '!=', 'gt': '>', 'ge': '>='} # We need this additional dictionary because we have reverted timestamp in # row-keys for stored metrics OP_SIGN_REV = {'eq': '=', 'lt': '>', 'le': '>=', 'ne': '!=', 'gt': '<', 'ge': '<='} kwargs = {'event_type': event_filter.event_type, 'event_id': event_filter.message_id} res_q = make_query(**kwargs) rts_start, rts_end = get_start_end_rts(start, end) start_op = start_op or 'ge' end_op = end_op or 'lt' if rts_start: q.append(""SingleColumnValueFilter ('f', 'rts', %s, 'binary:%s')"" % (OP_SIGN_REV[start_op], rts_start)) if rts_end: q.append(""SingleColumnValueFilter ('f', 'rts', %s, 'binary:%s')"" % (OP_SIGN_REV[end_op], rts_end))def get_start_end_rts(start, end): rts_start = str(timestamp(start)) if start else """" rts_end = str(timestamp(end)) if end else """" # # By default, we are using ge for lower bound and lt for upper bound # if start_op == 'gt': # rts_start = str(long(rts_start) - 2) # if end_op == 'le': # rts_end = str(long(rts_end) - 1) elif key == 'event_id': q.append(""RowFilter ( = , 'regexstring:\d*_%s')"" % value) start_rts, end_rts = get_start_end_rts(start_timestamp, end_timestamp) start_op = start_timestamp_op or 'ge' end_op = end_timestamp_op or 'lt' mq.append(_QualifierFilter(OP_SIGN_REV[start_op], filter_value)) mq.append(_QualifierFilter(OP_SIGN_REV[end_op], filter_value))","OP_SIGN = {'eq': '=', 'lt': '<', 'le': '<=', 'ne': '!=', 'gt': '>', 'ge': '>='} q = [] res_q = None if event_filter.event_type: q.append(""SingleColumnValueFilter ('f', 'event_type', = , "" ""'binary:%s')"" % dump(event_filter.event_type)) if event_filter.message_id: q.append(""RowFilter ( = , 'regexstring:\d*_%s')"" % event_filter.message_id) if len(q): res_q = "" AND "".join(q) rts_start, rts_end = get_start_end_rts(start, start_op, end, end_op) if rts_start: q.append(""SingleColumnValueFilter ('f', 'rts', <=, 'binary:%s')"" % rts_start) if rts_end: q.append(""SingleColumnValueFilter ('f', 'rts', >=, 'binary:%s')"" % rts_end)def get_start_end_rts(start, start_op, end, end_op): rts_start = str(timestamp(start) + 1) if start else """" rts_end = str(timestamp(end) + 1) if end else """" # By default, we are using ge for lower bound and lt for upper bound if start_op == 'gt': rts_start = str(long(rts_start) - 2) if end_op == 'le': rts_end = str(long(rts_end) - 1) start_rts, end_rts = get_start_end_rts(start_timestamp, start_timestamp_op, end_timestamp, end_timestamp_op) mq.append(_QualifierFilter(""<="", filter_value)) mq.append(_QualifierFilter("">="", filter_value))",33,30
openstack%2Fnova~master~I223c70c729315b6ffc01eb293fe70553ef827162,openstack/nova,master,I223c70c729315b6ffc01eb293fe70553ef827162,libvirt: Allow specification of default machine type,MERGED,2014-06-17 19:54:27.000000000,2014-08-15 15:35:26.000000000,2014-08-15 15:35:23.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6763}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-17 19:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96b6b583b69237865e244e2cb45d3c1095fd2971', 'message': 'libvirt: Allow specification of default machine type\n\niThe libvirt driver currently does not set the machine type for a KVM\nguest by default. When not specified, libvirt will use the newest one\nit knows about. Unfortunately, that can result in live migrations\nfailing if your environment is using different versions of the host OS\non compute noes as the destination node may not be able to support the\nmachine type used when the VM was originally started.\n\nA simple solution to this is to provide a new option which allows you\nto specify the default machine type on a per compute node basis\n(nova.conf option). By using this option, you can ensure that VMs are\nstarted with a machine type that will allow it to be live migrated to\nother nodes in the deployment.\n\nThis patch implements that solution by adding the hw_machine_type\noption to the [libvirt] group of nova.conf.\n\nDocImpact\nCloses-bug: #1331170\n\nChange-Id: I223c70c729315b6ffc01eb293fe70553ef827162\n'}, {'number': 2, 'created': '2014-06-18 18:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49db1b076bd233948e18224c55e80066dc275f74', 'message': 'libvirt: Allow specification of default machine type\n\nThe libvirt driver currently does not set the machine type for a KVM\nguest by default. When not specified, libvirt will use the newest one\nit knows about. Unfortunately, that can result in live migrations\nfailing if your environment is using different versions of the host OS\non compute nodes as the destination node may not be able to support the\nmachine type used when the VM was originally started.\n\nA simple solution to this is to provide a new option which allows you\nto specify the default machine type on a per compute node basis\n(nova.conf option). By using this option, you can ensure that VMs are\nstarted with a machine type that will allow it to be live migrated to\nother nodes in the deployment.\n\nThis patch implements that solution by adding the hw_machine_type\noption to the [libvirt] group of nova.conf.\n\nDocImpact\nCloses-bug: #1331170\n\nChange-Id: I223c70c729315b6ffc01eb293fe70553ef827162\n'}, {'number': 3, 'created': '2014-08-07 15:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a01a2ec8026d35ac2c8774e9de67fcce42ea966', 'message': 'libvirt: Allow specification of default machine type\n\nThe libvirt driver currently does not set the machine type for a KVM\nguest by default. When not specified, libvirt will use the newest one\nit knows about. Unfortunately, that can result in live migrations\nfailing if your environment is using different versions of the host OS\non compute nodes as the destination node may not be able to support the\nmachine type used when the VM was originally started.\n\nA simple solution to this is to provide a new option which allows you\nto specify the default machine type on a per compute node basis\n(nova.conf option). By using this option, you can ensure that VMs are\nstarted with a machine type that will allow it to be live migrated to\nother nodes in the deployment.\n\nThis patch implements that solution by adding the hw_machine_type\noption to the [libvirt] group of nova.conf.\n\nDocImpact\nCloses-bug: #1331170\n\nChange-Id: I223c70c729315b6ffc01eb293fe70553ef827162\n'}, {'number': 4, 'created': '2014-08-12 14:43:10.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5b27fe7de22aef53b82402f15b076887bc52670a', 'message': 'libvirt: Allow specification of default machine type\n\nThe libvirt driver currently does not set the machine type for a KVM\nguest by default. When not specified, libvirt will use the newest one\nit knows about. Unfortunately, that can result in live migrations\nfailing if your environment is using different versions of the host OS\non compute nodes as the destination node may not be able to support the\nmachine type used when the VM was originally started.\n\nA simple solution to this is to provide a new option which allows you\nto specify the default machine type on a per compute node basis\n(nova.conf option). By using this option, you can ensure that VMs are\nstarted with a machine type that will allow it to be live migrated to\nother nodes in the deployment.\n\nThis patch implements that solution by adding the hw_machine_type\noption to the [libvirt] group of nova.conf.\n\nDocImpact\nCloses-bug: #1331170\n\nChange-Id: I223c70c729315b6ffc01eb293fe70553ef827162\n'}]",16,100664,5b27fe7de22aef53b82402f15b076887bc52670a,73,14,4,1561,,,0,"libvirt: Allow specification of default machine type

The libvirt driver currently does not set the machine type for a KVM
guest by default. When not specified, libvirt will use the newest one
it knows about. Unfortunately, that can result in live migrations
failing if your environment is using different versions of the host OS
on compute nodes as the destination node may not be able to support the
machine type used when the VM was originally started.

A simple solution to this is to provide a new option which allows you
to specify the default machine type on a per compute node basis
(nova.conf option). By using this option, you can ensure that VMs are
started with a machine type that will allow it to be live migrated to
other nodes in the deployment.

This patch implements that solution by adding the hw_machine_type
option to the [libvirt] group of nova.conf.

DocImpact
Closes-bug: #1331170

Change-Id: I223c70c729315b6ffc01eb293fe70553ef827162
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/100664/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py']",2,96b6b583b69237865e244e2cb45d3c1095fd2971,bug/1331170," def test_get_guest_config_machine_type_from_config(self): self.flags(virt_type='kvm', group='libvirt') self.flags(hw_machine_type='fake_machine_type', group='libvirt') conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) instance_ref = db.instance_create(self.context, self.test_instance) disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref) cfg = conn.get_guest_config(instance_ref, _fake_network_info(self.stubs, 1), {}, disk_info) self.assertEqual(cfg.os_mach_type, ""fake_machine_type"") ",,44,16
openstack%2Ftraining-guides~master~Ic5e5a2fee18a8c3f5b016fad75313558e9d28c08,openstack/training-guides,master,Ic5e5a2fee18a8c3f5b016fad75313558e9d28c08,Adds nova scripts for training labs compute node,MERGED,2014-08-14 15:36:43.000000000,2014-08-15 15:17:11.000000000,2014-08-15 15:17:10.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-14 15:36:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/80b46dd75b7e01623753cbe1861b2dfe63eb29e0', 'message': 'Adds nova scripts for training labs\n\nAdds nova scripts for training labs which will install and configure\nnova.\n\nChange-Id: Ic5e5a2fee18a8c3f5b016fad75313558e9d28c08\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 2, 'created': '2014-08-14 15:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/94eea15bdf007985ef5fa1db209506730d924c71', 'message': 'Adds nova scripts for training labs\n\nAdds nova scripts for training labs which will install and configure\nnova.\n\nChange-Id: Ic5e5a2fee18a8c3f5b016fad75313558e9d28c08\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 3, 'created': '2014-08-14 16:25:29.000000000', 'files': ['labs/scripts/setup_nova_compute.sh', 'labs/config/scripts.compute', 'labs/scripts/apt_pre-download.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/4649920e36281efbcdff9ec806c9b2dd801366f5', 'message': 'Adds nova scripts for training labs compute node\n\nAdds nova scripts for training labs which will install and configure\nnova on a compute node.\n\nChange-Id: Ic5e5a2fee18a8c3f5b016fad75313558e9d28c08\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}]",0,114274,4649920e36281efbcdff9ec806c9b2dd801366f5,14,3,3,7007,,,0,"Adds nova scripts for training labs compute node

Adds nova scripts for training labs which will install and configure
nova on a compute node.

Change-Id: Ic5e5a2fee18a8c3f5b016fad75313558e9d28c08
Co-Authored-By: Roger Luethi <rl@patchworkscience.org>
Partial-Bug: 1312764
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/74/114274/2 && git format-patch -1 --stdout FETCH_HEAD,"['labs/scripts/setup_nova_compute.sh', 'labs/config/scripts.compute', 'labs/scripts/apt_pre-download.sh']",3,80b46dd75b7e01623753cbe1861b2dfe63eb29e0,bug/1312764, nova-consoleauth nova-novncproxy nova-scheduler python-novaclient \ nova-compute-kvm python-guestfs, nova-consoleauth nova-novncproxy nova-scheduler python-novaclient,91,1
openstack%2Fnova~stable%2Fhavana~Ifafc6a4c172b1521d62988ccbb3a2f51a95e323f,openstack/nova,stable/havana,Ifafc6a4c172b1521d62988ccbb3a2f51a95e323f,domainEventRegisterAny called too often,MERGED,2014-08-06 21:40:48.000000000,2014-08-15 14:55:03.000000000,2014-08-15 14:55:00.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1706}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-08-06 21:40:48.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fd5b2bd67f9506fb83cc66c4dacf410901e41208', 'message': ""domainEventRegisterAny called too often\n\nChangeid I090765802bfe443440f16722bc7c43b6280fe56a fixes\nbug #1240905 but introduced a bug whereby domainEventRegisterAny\nis called on every call to _get_connection.\n\nConflicts:\n        nova/virt/libvirt/driver.py\n\nNOTE(mriedem): The conflict is due to the set_host_enabled\ncode not being in stable/havana and we don't want to backport\nthat for the threading fixes in this series.\n\nChange-Id: Ifafc6a4c172b1521d62988ccbb3a2f51a95e323f\nFixes: bug #1250135\n(cherry picked from commit 755f6194e29c8e3daf6fd64a59dc2be4c81b1f0d)\n""}]",0,112420,fd5b2bd67f9506fb83cc66c4dacf410901e41208,20,9,1,6873,,,0,"domainEventRegisterAny called too often

Changeid I090765802bfe443440f16722bc7c43b6280fe56a fixes
bug #1240905 but introduced a bug whereby domainEventRegisterAny
is called on every call to _get_connection.

Conflicts:
        nova/virt/libvirt/driver.py

NOTE(mriedem): The conflict is due to the set_host_enabled
code not being in stable/havana and we don't want to backport
that for the threading fixes in this series.

Change-Id: Ifafc6a4c172b1521d62988ccbb3a2f51a95e323f
Fixes: bug #1250135
(cherry picked from commit 755f6194e29c8e3daf6fd64a59dc2be4c81b1f0d)
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/112420/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py']",2,fd5b2bd67f9506fb83cc66c4dacf410901e41208,bug/1266711-havana," def _get_new_connection(self): # call with _wrapped_conn_lock held LOG.debug(_('Connecting to libvirt: %s'), self.uri()) if not CONF.libvirt_nonblocking: wrapped_conn = self._connect(self.uri(), self.read_only) else: wrapped_conn = tpool.proxy_call( (libvirt.virDomain, libvirt.virConnect), self._connect, self.uri(), self.read_only) self._wrapped_conn = wrapped_conn try: LOG.debug(_(""Registering for lifecycle events %s"") % str(self)) wrapped_conn.domainEventRegisterAny( None, libvirt.VIR_DOMAIN_EVENT_ID_LIFECYCLE, self._event_lifecycle_callback, self) except Exception as e: LOG.warn(_(""URI %(uri)s does not support events: %(error)s""), {'uri': self.uri(), 'error': e}) if self._has_min_version(wrapped_conn, MIN_LIBVIRT_CLOSE_CALLBACK_VERSION): try: LOG.debug(_(""Registering for connection events: %s"") % str(self)) wrapped_conn.registerCloseCallback( self._close_callback, None) except libvirt.libvirtError as e: LOG.warn(_(""URI %(uri)s does not support connection"" "" events: %(error)s""), {'uri': self.uri(), 'error': e}) return wrapped_conn if not wrapped_conn or not self._test_connection(wrapped_conn): wrapped_conn = self._get_new_connection()"," if not wrapped_conn or not self._test_connection(wrapped_conn): LOG.debug(_('Connecting to libvirt: %s'), self.uri()) if not CONF.libvirt_nonblocking: wrapped_conn = self._connect(self.uri(), self.read_only) else: wrapped_conn = tpool.proxy_call( (libvirt.virDomain, libvirt.virConnect), self._connect, self.uri(), self.read_only) self._wrapped_conn = wrapped_conn try: LOG.debug(_(""Registering for lifecycle events %s"") % str(self)) wrapped_conn.domainEventRegisterAny( None, libvirt.VIR_DOMAIN_EVENT_ID_LIFECYCLE, self._event_lifecycle_callback, self) except Exception as e: LOG.warn(_(""URI %(uri)s does not support events: %(error)s""), {'uri': self.uri(), 'error': e}) if self._has_min_version(wrapped_conn, MIN_LIBVIRT_CLOSE_CALLBACK_VERSION): try: LOG.debug(_(""Registering for connection events: %s"") % str(self)) wrapped_conn.registerCloseCallback( self._close_callback, None) except libvirt.libvirtError as e: LOG.warn(_(""URI %(uri)s does not support connection"" "" events: %(error)s""), {'uri': self.uri(), 'error': e})",59,39
openstack%2Ftempest~master~Idb094f2817e7ed007a0ea47cf8f8602b5aeb6268,openstack/tempest,master,Idb094f2817e7ed007a0ea47cf8f8602b5aeb6268,Allow dict's as schema definitions,MERGED,2014-08-07 11:55:24.000000000,2014-08-15 14:54:51.000000000,2014-08-15 14:54:51.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10723}]","[{'number': 1, 'created': '2014-08-07 11:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0168f923ee7afd0225b522b55e64ca10e4f32570', 'message': ""Allow dict's as schema definitions\n\nAll negative testing schema's will be moved to dict format. Therefore\nthe framework must support files and dict's. After all test are ported\nto dict's file support will be deprecated.\n\nChange-Id: Idb094f2817e7ed007a0ea47cf8f8602b5aeb6268\nPartially-implements: bp api-schema-unification\n""}, {'number': 2, 'created': '2014-08-07 12:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8e7ed57148471539a4883298b80db153c8f9da7b', 'message': ""Allow dict's as schema definitions\n\nAll negative testing schema's will be moved to dict format. Therefore\nthe framework must support files and dict's. After all test are ported\nto dict's file support will be deprecated.\n\nChange-Id: Idb094f2817e7ed007a0ea47cf8f8602b5aeb6268\nPartially-implements: bp api-schema-unification\n""}, {'number': 3, 'created': '2014-08-08 08:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7ca95d5a27c9066705013add20276dbf3fa86083', 'message': ""Allow dict's as schema definitions\n\nAll negative testing schema's will be moved to dict format. Therefore\nthe framework must support files and dict's. After all test are ported\nto dict's file support will be deprecated.\n\nChange-Id: Idb094f2817e7ed007a0ea47cf8f8602b5aeb6268\nPartially-implements: bp api-schema-unification\n""}, {'number': 4, 'created': '2014-08-15 06:43:11.000000000', 'files': ['tempest/tests/negative/test_negative_auto_test.py', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4f44d72d9c1006bb369f2530f0967dd3ac21d1c9', 'message': ""Allow dict's as schema definitions\n\nAll negative testing schema's will be moved to dict format. Therefore\nthe framework must support files and dict's. After all test are ported\nto dict's file support will be deprecated.\n\nChange-Id: Idb094f2817e7ed007a0ea47cf8f8602b5aeb6268\nPartially-implements: bp api-schema-unification\n""}]",0,112566,4f44d72d9c1006bb369f2530f0967dd3ac21d1c9,28,6,4,7872,,,0,"Allow dict's as schema definitions

All negative testing schema's will be moved to dict format. Therefore
the framework must support files and dict's. After all test are ported
to dict's file support will be deprecated.

Change-Id: Idb094f2817e7ed007a0ea47cf8f8602b5aeb6268
Partially-implements: bp api-schema-unification
",git fetch https://review.opendev.org/openstack/tempest refs/changes/66/112566/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/negative/test_negative_auto_test.py', 'tempest/test.py']",2,0168f923ee7afd0225b522b55e64ca10e4f32570,bp/api-schema-unification," def load_schema(file_or_dict): Loads a schema from a file_or_dict on a specified location. :param file_or_dict: just a dict or filename # NOTE(mkoderer): we will get rid of this function when all test are # ported to dicts if isinstance(file_or_dict, dict): return file_or_dict ""etc"", ""schemas"", file_or_dict) schema = getattr(test, '_schema', None) elif schema is not None: setattr(test, 'scenarios', NegativeAutoTest.generate_scenario(schema)) def generate_scenario(description): :param description: A file or dictionary with the following entries: description = NegativeAutoTest.load_schema(description) def execute(self, description): :param description: A json file or dictionary with the following entries: description = NegativeAutoTest.load_schema(description)"," def load_schema(file): Loads a schema from a file on a specified location. :param file: the file name ""etc"", ""schemas"", file) def generate_scenario(description_file): :param description: A dictionary with the following entries: description = NegativeAutoTest.load_schema(description_file) def execute(self, description_file): :param description: A dictionary with the following entries: description = NegativeAutoTest.load_schema(description_file)",31,10
openstack%2Fneutron~master~I099b90d39247bc9a7adfb87344d77ccd8acfad9e,openstack/neutron,master,I099b90d39247bc9a7adfb87344d77ccd8acfad9e,NSX: lift restriction on DVR update,MERGED,2014-08-14 19:47:45.000000000,2014-08-15 14:54:44.000000000,2014-08-15 00:11:40.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10387}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-08-14 19:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/31c1db3a0096de39fcb632dc8e5c0fd0f80874d3', 'message': 'NSX: lift restriction on DVR update\n\nThe restriction in place in the code is not justified considered\nthe capabilities of the DVR extension and the NSX backend.\n\nTransformations of centralized routers into distributed should be\nallowed.\n\nChange-Id: I099b90d39247bc9a7adfb87344d77ccd8acfad9e\nCloses-Bug: #1357048\n'}, {'number': 2, 'created': '2014-08-14 20:56:37.000000000', 'files': ['neutron/plugins/vmware/plugins/base.py', 'neutron/tests/unit/vmware/test_nsx_plugin.py', 'neutron/plugins/vmware/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9fc8b6c4b4d43df50b9bc15f4fdf274ad6dd711c', 'message': 'NSX: lift restriction on DVR update\n\nThe restriction in place in the code is not justified considered\nthe capabilities of the DVR extension and the NSX backend.\n\nTransformations of centralized routers into distributed should be\nallowed.\n\nChange-Id: I099b90d39247bc9a7adfb87344d77ccd8acfad9e\nCloses-Bug: #1357048\n'}]",0,114324,9fc8b6c4b4d43df50b9bc15f4fdf274ad6dd711c,44,19,2,261,,,0,"NSX: lift restriction on DVR update

The restriction in place in the code is not justified considered
the capabilities of the DVR extension and the NSX backend.

Transformations of centralized routers into distributed should be
allowed.

Change-Id: I099b90d39247bc9a7adfb87344d77ccd8acfad9e
Closes-Bug: #1357048
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/114324/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/vmware/plugins/base.py', 'neutron/tests/unit/vmware/test_nsx_plugin.py']",2,31c1db3a0096de39fcb632dc8e5c0fd0f80874d3,bug1357048,," def test_update_router_distributed_bad_request(self): res = self._create_router('json', 'tenant') router = self.deserialize('json', res) req = self.new_update_request( 'routers', {'router': {'distributed': True}}, router['router']['id']) res = req.get_response(self.ext_api) self.assertEqual(res.status_int, 400) ",0,13
openstack%2Fpuppet-neutron~master~I8ee2bca21cc3f32c017529b55c92a50094aa25d5,openstack/puppet-neutron,master,I8ee2bca21cc3f32c017529b55c92a50094aa25d5,Install neutron-plugin-ml2 package on Ubuntu,MERGED,2014-07-04 22:25:26.000000000,2014-08-15 14:47:55.000000000,2014-07-21 22:51:30.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6994}, {'_account_id': 7822}, {'_account_id': 8797}]","[{'number': 1, 'created': '2014-07-04 22:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/785e6e467a50569ed73151af5676268a087d3cb4', 'message': 'Install neutron-plugin-ml2 package on Ubuntu\n\nWhile there is no dedicated package for neutron-plugin-ml2 on Debian,\nthere is one on Ubuntu operating systems.\n\nWe should install it when ML2 core plugin is enabled.\n\nChange-Id: I8ee2bca21cc3f32c017529b55c92a50094aa25d5\n'}, {'number': 2, 'created': '2014-07-07 15:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/2ea23360523bea0ee46cfd77a7ff50234b934736', 'message': 'Install neutron-plugin-ml2 package on Ubuntu\n\nWhile there is no dedicated package for neutron-plugin-ml2 on Debian,\nthere is one on Ubuntu operating systems.\n\nWe should install it when ML2 core plugin is enabled.\n\nCloses-bug: #1337526\nChange-Id: I8ee2bca21cc3f32c017529b55c92a50094aa25d5\n'}, {'number': 3, 'created': '2014-07-07 15:31:35.000000000', 'files': ['spec/classes/neutron_plugins_ml2_spec.rb', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/c4e4818cad3227475c81bdd2f8dbc702b16cfa63', 'message': 'Install neutron-plugin-ml2 package on Ubuntu\n\nWhile there is no dedicated package for neutron-plugin-ml2 on Debian,\nthere is one on Ubuntu operating systems.\n\nWe should install it when ML2 core plugin is enabled.\n\nCloses-bug: #1337988\nChange-Id: I8ee2bca21cc3f32c017529b55c92a50094aa25d5\n'}]",0,104961,c4e4818cad3227475c81bdd2f8dbc702b16cfa63,17,5,3,7156,,,0,"Install neutron-plugin-ml2 package on Ubuntu

While there is no dedicated package for neutron-plugin-ml2 on Debian,
there is one on Ubuntu operating systems.

We should install it when ML2 core plugin is enabled.

Closes-bug: #1337988
Change-Id: I8ee2bca21cc3f32c017529b55c92a50094aa25d5
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/61/104961/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_plugins_ml2_spec.rb', 'manifests/params.pp']",2,785e6e467a50569ed73151af5676268a087d3cb4,bug/1337988, if $::operatingsystem == 'Ubuntu' { $ml2_server_package = 'neutron-plugin-ml2' } else { $ml2_server_package = false }, $ml2_server_package = false,21,2
openstack%2Fopenstack-manuals~master~Ib3056644d23cc28cb64cd437c70c55535482d252,openstack/openstack-manuals,master,Ib3056644d23cc28cb64cd437c70c55535482d252,Last part of typo/spelling errors fixing,MERGED,2014-08-15 10:17:08.000000000,2014-08-15 14:42:26.000000000,2014-08-15 12:48:01.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 12840}]","[{'number': 1, 'created': '2014-08-15 10:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/68237f7e2d2f877742dc9e43e13079072257faae', 'message': 'Last part of typo/spelling errors fixing\n\nThis patch complete the typo/spelling scanning on the openstack-manuals\nrepository.\n\nChange-Id: Ib3056644d23cc28cb64cd437c70c55535482d252\n'}, {'number': 2, 'created': '2014-08-15 10:27:37.000000000', 'files': ['doc/networking-guide/ch_advanced.xml', 'doc/user-guide/section_sdk_nova.xml', 'doc/user-guide-admin/section_cli_nova_manage_projects_security.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b739f858d7fd56f2e0bb4a9448344bef03c9d439', 'message': 'Last part of typo/spelling errors fixing\n\nThis patch complete the typo/spelling scanning on the openstack-manuals\nrepository.\n\nChange-Id: Ib3056644d23cc28cb64cd437c70c55535482d252\n'}]",2,114493,b739f858d7fd56f2e0bb4a9448344bef03c9d439,17,5,2,12840,,,0,"Last part of typo/spelling errors fixing

This patch complete the typo/spelling scanning on the openstack-manuals
repository.

Change-Id: Ib3056644d23cc28cb64cd437c70c55535482d252
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/93/114493/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/ch_advanced.xml', 'doc/user-guide/section_sdk_nova.xml', 'doc/user-guide-admin/section_cli_nova_manage_projects_security.xml', 'doc/user-guide/section_cli_trove.xml']",4,68237f7e2d2f877742dc9e43e13079072257faae,fixing-typos-4," trivial example. However, configuration groups can provide major efficiency when you"," trivial example. However, configuration groups can provide major efficiencies when you",7,7
openstack%2Fopenstack-manuals~master~Ied3295f45d9feb743ae4a077a4276175ceb9816c,openstack/openstack-manuals,master,Ied3295f45d9feb743ae4a077a4276175ceb9816c,Add link to the 'Ops/User Docs Review Inbox' to local-files.html,MERGED,2014-08-15 10:06:55.000000000,2014-08-15 14:41:26.000000000,2014-08-15 12:42:11.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-15 10:06:55.000000000', 'files': ['doc/local-files.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5311e5298568d760b3eb97da664575ecc37a4e90', 'message': ""Add link to the 'Ops/User Docs Review Inbox' to local-files.html\n\nThe corresponding dashboard file is available in the\ngerrit-dash-creator (https://github.com/stackforge/gerrit-dash-creator/)\nrepository.\n\nChange-Id: Ied3295f45d9feb743ae4a077a4276175ceb9816c\n""}]",0,114490,5311e5298568d760b3eb97da664575ecc37a4e90,9,4,1,167,,,0,"Add link to the 'Ops/User Docs Review Inbox' to local-files.html

The corresponding dashboard file is available in the
gerrit-dash-creator (https://github.com/stackforge/gerrit-dash-creator/)
repository.

Change-Id: Ied3295f45d9feb743ae4a077a4276175ceb9816c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/90/114490/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/local-files.html'],1,5311e5298568d760b3eb97da664575ecc37a4e90,update_url_review_dashboard," <dd> <a href=""https://review.openstack.org/#/dashboard/?foreach=%28project%3Aopenstack%2Fopenstack-manuals+OR+project%3Aopenstack%2Fapi-site+OR+project%3Aopenstack%2Fdocs-specs+OR+project%3Aopenstack%2Fobject-api+OR+project%3Aopenstack%2Fimage-api+OR+project%3Aopenstack%2Fidentity-api+OR+project%3Aopenstack%2Fcompute-api+OR+project%3Aopenstack%2Fvolume-api+OR+project%3Aopenstack%2Fnetconn-api+OR+project%3Aopenstack%2Foperations-guide+OR+project%3Aopenstack%2Fsecurity-doc+OR+project%3Aopenstack%2Ftraining-guides+OR+project%3Aopenstack%2Fopenstack-doc-tools+OR+project%3Astackforge%2Fclouddocs-maven-plugin%29+status%3Aopen+NOT+owner%3Aself+NOT+label%3AWorkflow%3C%3D-1+label%3AVerified%3E%3D1%252cjenkins+NOT+label%3ACode-Review%3C%3D-1%252cself+NOT+label%3ACode-Review%3E%3D1%252cself&title=Ops%2FUser+Docs+Review+Inbox&Needs+feedback+%28Changes+older+than+5+days+that+have+not+been+reviewed+by+anyone%29=NOT+label%3ACode-Review%3C%3D2+age%3A5d&Specs=project%3Aopenstack%2Fdocs-specs+status%3Aopen&API+Docs=%28project%3Aopenstack%2Fapi-site+OR+project%3Aopenstack%2Fobject-api+OR+project%3Aopenstack%2Fimage-api+OR+project%3Aopenstack%2Fidentity-api+OR+project%3Aopenstack%2Fcompute-api+OR+project%3Aopenstack%2Fvolume-api+OR+project%3Aopenstack%2Fnetconn-api%29+status%3Aopen&Ops%2FAdmin+Docs=%28project%3Aopenstack%2Fopenstack-manuals+OR+project%3Aopenstack%2Foperations-guide+OR+project%3Aopenstack%2Fsecurity-doc%29+status%3Aopen&Training=project%3Aopenstack%2Ftraining-guides&Doc+Tools=%28project%3Aopenstack%2Fopenstack-doc-tools+OR+project%3Astackforge%2Fclouddocs-maven-plugin%29+status%3Aopen&You+are+a+reviewer+%28but+haven%27t+voted+in+the+current+revision%29=reviewer%3Aself&Needs+final+%2B2=%28project%3Aopenstack%2Fopenstack-manuals+OR+project%3Aopenstack%2Fapi-site+OR+project%3Aopenstack%2Fobject-api+OR+project%3Aopenstack%2Fimage-api+OR+project%3Aopenstack%2Fidentity-api+OR+project%3Aopenstack%2Fcompute-api+OR+project%3Aopenstack%2Fvolume-api+OR+project%3Aopenstack%2Fnetconn-api+OR+project%3Aopenstack%2Foperations-guide+OR+project%3Aopenstack%2Fsecurity-doc+OR+project%3Aopenstack%2Ftraining-guides%29+label%3ACode-Review%3E%3D2+limit%3A50&Passed+Jenkins+%28with+no+negative+feedback%29=NOT+label%3ACode-Review%3E%3D2+NOT+label%3ACode-Review%3C%3D-1+limit%3A50&Wayward+Changes+%28Changes+with+no+code+review+in+the+last+two+days%29=NOT+label%3ACode-Review%3C%3D2+age%3A2d""> Ops/User Docs Review Inbox </a> </dd>",,5,0
openstack%2Fmagnetodb~master~I9305a7ec2e59cd98b3ac3e3569c53099a4ef5ad8,openstack/magnetodb,master,I9305a7ec2e59cd98b3ac3e3569c53099a4ef5ad8,Added hacking as test requirement,MERGED,2014-07-18 13:49:18.000000000,2014-08-15 14:26:43.000000000,2014-08-15 14:26:42.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8601}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-07-18 13:49:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/47fec1db08f624ab931a0311da9e5b0ac0c4dc01', 'message': 'Added hacking as test requirement\n\nRemoved flake8 and pep8 as test requirement, they are already required by\nhacking.\n\nIgnored all found issues for the moment to fix them with further patches.\n\nChange-Id: I9305a7ec2e59cd98b3ac3e3569c53099a4ef5ad8\n'}, {'number': 2, 'created': '2014-08-12 16:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/43d7cdecf5e5cbbef6b693b33ee06038b9b62ecc', 'message': 'Added hacking as test requirement\n\nRemoved flake8 and pep8 as test requirement, they are already required by\nhacking.\n\nIgnored all found issues for the moment to fix them with further patches.\n\nChange-Id: I9305a7ec2e59cd98b3ac3e3569c53099a4ef5ad8\n'}, {'number': 3, 'created': '2014-08-13 08:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/d2e01fb0087e3846a5b1af86dc11ae139eeb1466', 'message': 'Added hacking as test requirement\n\nRemoved flake8 and pep8 as test requirement, they are already required by\nhacking.\n\nIgnored all found issues for the moment to fix them with further patches.\n\nChange-Id: I9305a7ec2e59cd98b3ac3e3569c53099a4ef5ad8\n'}, {'number': 4, 'created': '2014-08-13 08:16:37.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/94deb1214edba018521413c3aa602df80d7a3321', 'message': 'Added hacking as test requirement\n\nRemoved flake8 and pep8 as test requirement, they are already\nrequired by hacking.\n\nIgnored all found issues for the moment to fix them with\nfurther patches.\n\nChange-Id: I9305a7ec2e59cd98b3ac3e3569c53099a4ef5ad8\n'}]",0,108009,94deb1214edba018521413c3aa602df80d7a3321,20,4,4,167,,,0,"Added hacking as test requirement

Removed flake8 and pep8 as test requirement, they are already
required by hacking.

Ignored all found issues for the moment to fix them with
further patches.

Change-Id: I9305a7ec2e59cd98b3ac3e3569c53099a4ef5ad8
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/09/108009/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,47fec1db08f624ab931a0311da9e5b0ac0c4dc01,add_hacking,"# H101 Use TODO(NAME) # H201 no 'except:' at least use 'except Exception:' # H233 Python 3.x incompatible use of print operator # H234 assertEquals is deprecated, use assertEqual # H301 one import per line # H302 import only modules. # H305 imports not grouped correctly # H306 imports not in alphabetical order # H307 like imports should be grouped together # H401 docstring should not start with a space # H402 one line docstring needs punctuation # H404 multi line docstring should start without a leading new line # H405 multi line docstring summary not separated with an empty line # H904 Wrap long lines in parentheses instead of a backslash # E226 missing whitespace around arithmetic operator # E241 multiple spaces after ':' ignore = H101,H201,H233,H234,H301,H302,H305,H306,H307,H401,H402,H404,H405,H904,E226,E241",,18,2
openstack%2Ffuel-astute~master~Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad,openstack/fuel-astute,master,Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad,Try to upload cirros after each deploy,MERGED,2014-08-13 08:14:32.000000000,2014-08-15 14:26:31.000000000,2014-08-15 14:26:30.000000000,"[{'_account_id': 3}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2014-08-13 08:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/0031557f23e03b255ba4902d9710be47ee852f1d', 'message': 'Try to upload cirros after each succesfull deploy\n\n- change target node which will perform upload to\n  last_controller fact, and not role with controller/primary-controller\n- credentials will be obtained from openrc on that node\n\nWe may want to add additonal fact to deployment_info:\n  last_controller_uid\nwhich will store uid without any additional prefixes\n\nCloses-Bug: 1354804\nChange-Id: Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad\n'}, {'number': 2, 'created': '2014-08-13 10:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/de2acd16827f68e3110b347386b7d8690e6d07fa', 'message': 'Try to upload cirros after each succesfull deploy\n\n- change target node which will perform upload to\n  last_controller fact, and not role with controller/primary-controller\n- credentials will be obtained from openrc on that node\n\nWe may want to add additonal fact to deployment_info:\n  last_controller_uid\nwhich will store uid without any additional prefixes\n\nCloses-Bug: 1354804\nChange-Id: Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad\n'}, {'number': 3, 'created': '2014-08-13 11:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/dcb6a91691850e7681d051171b4d6ac97dbf0076', 'message': 'Try to upload cirros after each succesfull deploy\n\n- change target node which will perform upload to\n  last_controller fact, and not role with controller/primary-controller\n- credentials will be obtained from openrc on that node\n\nWe may want to add additonal fact to deployment_info:\n  last_controller_uid\nwhich will store uid without any additional prefixes\n\nCloses-Bug: 1354804\nChange-Id: Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad\n'}, {'number': 4, 'created': '2014-08-13 12:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/6b0ba79a6bd155eeedaf62292b1568e2bfeff9c0', 'message': 'Try to upload cirros after each succesfull deploy\n\n- take controller uid from nodes attribute which is present for every\n  generated node\n- credentials will be obtained from openrc file on controller\n\nThis way we will try to upload TestVM image every time deployment task\npassed successfully, and if there is no TestVM image present in glance\nwe will add it\n\nCloses-Bug: 1354804\nChange-Id: Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad\n'}, {'number': 5, 'created': '2014-08-15 09:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/d4e6805dfa27a994e05b9176707fdfc2114d226b', 'message': 'Try to upload cirros image every deployment\n\n- Removed validation for deployment status\n- Added validation that glance index works on choosen controller\n\nIf glance works on controller we will try to upload image, if no\njust skip this action\n\nCloses-Bug: 1354804\nChange-Id: Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad\n'}, {'number': 6, 'created': '2014-08-15 10:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/f8ac4e26a1328bfe30384323e459e40b77e84b26', 'message': 'Try to upload cirros after each succesfull deploy\n\n- take controller uid from nodes attribute which is present for every\n  generated node\n- credentials will be obtained from openrc file on controller\n- remove check for cluster status after deployment\n\nThis way we will try to upload TestVM image every time after deployment,\nand if there is no TestVM image present in glance\nwe will add it\n\nCloses-Bug: 1354804\nChange-Id: Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad\n'}, {'number': 7, 'created': '2014-08-15 10:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/2e9d3893b974faf616a9d4adb838398c0aa09119', 'message': 'Try to upload cirros after each deploy\n\n- take controller uid from nodes attribute which is present for every\n  generated node\n- credentials will be obtained from openrc file on controller\n- remove check for cluster status after deployment\n\nThis way we will try to upload TestVM image every time after deployment,\nand if there is no TestVM image present in glance\nwe will add it\n\nCloses-Bug: 1354804\nChange-Id: Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad\n'}, {'number': 8, 'created': '2014-08-15 10:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/53bafcab045c4830898eb8e95be333f0c3807ef1', 'message': 'Try to upload cirros after each deploy\n\n- take controller uid from nodes attribute which is present for every\n  generated node\n- credentials will be obtained from openrc file on controller\n- remove check for cluster status after deployment\n\nThis way we will try to upload TestVM image every time after deployment,\nand if there is no TestVM image present in glance\nwe will add it\n\nCloses-Bug: 1354804\nChange-Id: Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad\n'}, {'number': 9, 'created': '2014-08-15 10:44:54.000000000', 'files': ['spec/unit/upload_cirros_image_hook_spec.rb', 'lib/astute/post_deploy_actions/upload_cirros_image.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/9c6a4810fa867c7acd6f3e22531f61ed15a33254', 'message': 'Try to upload cirros after each deploy\n\n- take controller uid from nodes attribute which is present for every\n  generated node\n- credentials will be obtained from openrc file on controller\n- remove check for cluster status after deployment\n\nThis way we will try to upload TestVM image every time after deployment,\nand if there is no TestVM image present in glance\nwe will add it\n\nCloses-Bug: 1354804\nChange-Id: Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad\n'}]",3,113810,9c6a4810fa867c7acd6f3e22531f61ed15a33254,54,7,9,8907,,,0,"Try to upload cirros after each deploy

- take controller uid from nodes attribute which is present for every
  generated node
- credentials will be obtained from openrc file on controller
- remove check for cluster status after deployment

This way we will try to upload TestVM image every time after deployment,
and if there is no TestVM image present in glance
we will add it

Closes-Bug: 1354804
Change-Id: Ifbe483cd63f5aa5094aaaf8097920fbef0e732ad
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/10/113810/9 && git format-patch -1 --stdout FETCH_HEAD,['lib/astute/post_deploy_actions/upload_cirros_image.rb'],1,0031557f23e03b255ba4902d9710be47ee852f1d,bug/1354804," node = deployment_info.last if node['last_controller'].nil? Astute.logger.debug(""Could not find last_controller in facts! Please check logs to be sure that it is correctly generated."") os = controller['test_vm_image'] controller_uid = node['last_controller'].split('-').last cmd = ""source openrc && /usr/bin/glance \ (/usr/bin/glance \ response = run_shell_command(context, Array(controller_uid), cmd) cmd = ""source openrc && /usr/bin/glance \ response = run_shell_command(context, Array(controller_uid), cmd) {'uid' => node['uid'], 'role' => node['role']"," controller = deployment_info.find { |n| n['role'] == 'primary-controller' } controller = deployment_info.find { |n| n['role'] == 'controller' } unless controller if controller.nil? Astute.logger.debug(""Could not find controller! Possible adding a new node to the existing cluster?"") os = { 'os_tenant_name' => Shellwords.escape(""#{controller['access']['tenant']}""), 'os_username' => Shellwords.escape(""#{controller['access']['user']}""), 'os_password' => Shellwords.escape(""#{controller['access']['password']}""), 'os_auth_url' => ""http://#{controller['management_vip'] || '127.0.0.1'}:5000/v2.0/"", } os.merge!(controller['test_vm_image']) auth_params = ""-N #{os['os_auth_url']} \ -T #{os['os_tenant_name']} \ -I #{os['os_username']} \ -K #{os['os_password']}"" cmd = ""/usr/bin/glance #{auth_params} \ (/usr/bin/glance #{auth_params} \ response = run_shell_command(context, Array(controller['uid']), cmd) cmd = ""/usr/bin/glance #{auth_params} \ response = run_shell_command(context, Array(controller['uid']), cmd) {'uid' => controller['uid'], 'role' => controller['role']",13,23
openstack%2Foslo.vmware~master~Ia7ca46bb3f263211ab1fe37585f183edf00461b1,openstack/oslo.vmware,master,Ia7ca46bb3f263211ab1fe37585f183edf00461b1,Log additional details of suds faults,MERGED,2014-07-03 12:24:41.000000000,2014-08-15 14:21:12.000000000,2014-08-15 14:21:12.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8027}, {'_account_id': 8871}, {'_account_id': 9171}, {'_account_id': 9172}]","[{'number': 1, 'created': '2014-07-03 12:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/49ae58ec3ba7de0f8f3d5bfe349cbe9ac12c4536', 'message': 'Log additional details of suds faults\n\nWhen a suds requests results in a fault response, the current\ncode loses details on that fault in the sequence of exceptions\npropagated through the call stack. A NoPermission fault will contain\nadditional metadata on the privilegeId and object type which\nneeds to be logged.  The fault string will be propagated with this\nfix, along with details of a NoPermission fault.\n\nThis functionality was added in Nova with commit\n62cb0dc6257daac5ec9fd1a90ee5721e6543dd76 and we need the same thing in\noslo.vmware\n\nChange-Id: Ia7ca46bb3f263211ab1fe37585f183edf00461b1\n'}, {'number': 2, 'created': '2014-07-11 11:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/20fcb489201254a79744fdf01270bb3c135523d2', 'message': ""Log additional details of suds faults\n\nWhen a suds requests results in a fault response, the current\ncode loses details on that fault in the sequence of exceptions\npropagated through the call stack. A NoPermission fault will contain\nadditional metadata on the privilegeId and object type which\nneeds to be logged.  The fault string will be propagated with this\nfix, along with details of a NoPermission fault.\n\nIt is possible 'details' to contain unicode values which is handled by\nimplementing __unicode__() for VimFaultException.\n\nThis functionality was added in Nova with commit\n62cb0dc6257daac5ec9fd1a90ee5721e6543dd76 and we need the same thing in\noslo.vmware\n\nChange-Id: Ia7ca46bb3f263211ab1fe37585f183edf00461b1\n""}, {'number': 3, 'created': '2014-07-11 11:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/28e07e3da1975b1e319511a696448dbd613ba79e', 'message': ""Log additional details of suds faults\n\nWhen a suds requests results in a fault response, the current\ncode loses details on that fault in the sequence of exceptions\npropagated through the call stack. A NoPermission fault will contain\nadditional metadata on the privilegeId and object type which\nneeds to be logged.  The fault string will be propagated with this\nfix, along with details of a NoPermission fault.\n\nIt is possible 'details' to contain unicode values which is handled by\nimplementing __unicode__() for VimFaultException.\n\nThis functionality was added in Nova with commit\n62cb0dc6257daac5ec9fd1a90ee5721e6543dd76 and we need the same thing in\noslo.vmware\n\nChange-Id: Ia7ca46bb3f263211ab1fe37585f183edf00461b1\n""}, {'number': 4, 'created': '2014-07-25 14:50:43.000000000', 'files': ['oslo/vmware/api.py', 'oslo/vmware/exceptions.py', 'oslo/vmware/service.py', 'tests/test_api.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/d76620bd1c59037d853ce23600d58b0c9353ed7e', 'message': ""Log additional details of suds faults\n\nWhen a suds requests results in a fault response, the current\ncode loses details on that fault in the sequence of exceptions\npropagated through the call stack. A NoPermission fault will contain\nadditional metadata on the privilegeId and object type which\nneeds to be logged.  The fault string will be propagated with this\nfix, along with details of a NoPermission fault.\n\nIt is possible 'details' to contain unicode values which is handled by\nimplementing __unicode__() for VimFaultException.\n\nThis functionality was added in Nova with commit\n62cb0dc6257daac5ec9fd1a90ee5721e6543dd76 and we need the same thing in\noslo.vmware\n\nChange-Id: Ia7ca46bb3f263211ab1fe37585f183edf00461b1\n""}]",9,104534,d76620bd1c59037d853ce23600d58b0c9353ed7e,44,8,4,9172,,,0,"Log additional details of suds faults

When a suds requests results in a fault response, the current
code loses details on that fault in the sequence of exceptions
propagated through the call stack. A NoPermission fault will contain
additional metadata on the privilegeId and object type which
needs to be logged.  The fault string will be propagated with this
fix, along with details of a NoPermission fault.

It is possible 'details' to contain unicode values which is handled by
implementing __unicode__() for VimFaultException.

This functionality was added in Nova with commit
62cb0dc6257daac5ec9fd1a90ee5721e6543dd76 and we need the same thing in
oslo.vmware

Change-Id: Ia7ca46bb3f263211ab1fe37585f183edf00461b1
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/34/104534/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/vmware/api.py', 'oslo/vmware/vim.py', 'tests/test_api.py']",3,49ae58ec3ba7de0f8f3d5bfe349cbe9ac12c4536,fault-details," def test_invoke_api_with_vim_fault_exception_details(self): api_session = self._create_api_session(True) fault_string = 'No permission to perform this operation.' fault_list = [exceptions.NO_PERMISSION] details = {'privilegeId': 'Resource.AssignVMToPool', 'object': 'domain-c7'} def api(*args, **kwargs): raise exceptions.VimFaultException(fault_list, fault_string, details=details) module = mock.Mock() module.api = api e = self.assertRaises(exceptions.NoPermissionException, lambda: api_session.invoke_api(module, 'api')) expected_str = ""%s\nFaults: %s\nDetails: %s"" % (fault_string, fault_list, details) self.assertEqual(expected_str, str(e)) ",,34,8
openstack%2Ffuel-library~stable%2F5.0~I6e35d65a3a8546d275084d929975548d856d8359,openstack/fuel-library,stable/5.0,I6e35d65a3a8546d275084d929975548d856d8359,Install glance-api before creating subdirs,ABANDONED,2014-08-15 08:03:08.000000000,2014-08-15 13:56:30.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}]","[{'number': 1, 'created': '2014-08-15 08:03:08.000000000', 'files': ['deployment/puppet/swift/manifests/storage/all.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5c5fa91c48770459762f3db65cd1949fdae14a35', 'message': 'Install glance-api before creating subdirs\n\nWe need to install glance-api before we start creating subdirs\ninside /var/lib/glance for swift device directories.\n\nChange-Id: I6e35d65a3a8546d275084d929975548d856d8359\nCloses-bug: #1346894\n'}]",0,114465,5c5fa91c48770459762f3db65cd1949fdae14a35,11,8,1,11090,,,0,"Install glance-api before creating subdirs

We need to install glance-api before we start creating subdirs
inside /var/lib/glance for swift device directories.

Change-Id: I6e35d65a3a8546d275084d929975548d856d8359
Closes-bug: #1346894
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/65/114465/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/swift/manifests/storage/all.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp']",2,5c5fa91c48770459762f3db65cd1949fdae14a35,bug/1346894-5.0, # At least debian glance-common package chowns whole /var/lib/glance recursively # which breaks swift ownership of dirs inside $storage_mnt_base_dir (default: /var/lib/glance/node/) # so we just need to make sure package glance-common (dependency for glance-api) is already installed # before creating swift device directories Package[$glance::params::api_package_name] -> Anchor <| title=='swift-device-directories-start' |> ,,8,0
openstack%2Ftraining-guides~master~I5cae44953d03306cb880334b41b89ac0f134f34a,openstack/training-guides,master,I5cae44953d03306cb880334b41b89ac0f134f34a,minor change to training-cluster-by-script,ABANDONED,2014-06-27 14:32:19.000000000,2014-08-15 13:37:58.000000000,,"[{'_account_id': 3}, {'_account_id': 6923}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-06-27 14:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/7bd95e9f413de724962248514ace1baa1776f02f', 'message': 'minor change to training-cluster-by-script\n\nadded transition “a” and “the”\n\nChange-Id: I5cae44953d03306cb880334b41b89ac0f134f34a\n'}, {'number': 2, 'created': '2014-07-02 20:04:05.000000000', 'files': ['doc/training-guides/training-cluster-by-script.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/b0d81e3b3751f12678cfaf6d4fc7ee7bd243c334', 'message': 'minor change to training-cluster-by-script\n\nadded transition “a” and “the”\nstubs out section which is incorrect due to changes in the labs section.\n\nChange-Id: I5cae44953d03306cb880334b41b89ac0f134f34a\n'}]",2,103150,b0d81e3b3751f12678cfaf6d4fc7ee7bd243c334,15,4,2,9382,,,0,"minor change to training-cluster-by-script

added transition “a” and “the”
stubs out section which is incorrect due to changes in the labs section.

Change-Id: I5cae44953d03306cb880334b41b89ac0f134f34a
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/50/103150/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/training-cluster-by-script.xml'],1,7bd95e9f413de724962248514ace1baa1776f02f,changes_training-cluster-by-script," <filename>~/Scripts/test_scripts.sh</filename> file to test all the <para>To use Virtual Box as a test environment, you must attach although it is recommended because your host machine may fail.</para>"," <filename>~/Scripts/test_scripts.sh</filename> file to test all <para>To use Virtual Box as test environment, you must attach although it is recommended because your host machine might fail.</para>",3,3
openstack%2Fnova~master~Iab8070c25a9dee505c0602efad85c41c21c2aa58,openstack/nova,master,Iab8070c25a9dee505c0602efad85c41c21c2aa58,Remove rescue/unrescue NotImplementedError handle,MERGED,2014-06-23 02:14:39.000000000,2014-08-15 13:33:50.000000000,2014-08-15 13:33:47.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 8574}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 02:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b11af44b4e48a8b6caa6ea6d0004098f1bd7a28', 'message': ""Remove rescue/unrescue NotImplementedError handle\n\nThere are 2 kinds of RPC call from API layer to compute layer,\none is cast and another is call. For cast, the RPC message will\nbe posted and the API service will not wait for the message to\nbe processed. So it won't be able to catch the exception raised\nin compute layer and catch and handle the exception is useless\nand error leading. This patch removes code in API layer for\nrescue and unrescue functions.\n\nChange-Id: Iab8070c25a9dee505c0602efad85c41c21c2aa58\n""}, {'number': 2, 'created': '2014-06-23 03:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d94d074817228a55208d968aa75b9bf62af2b60a', 'message': ""Remove rescue/unrescue NotImplementedError handle\n\nThere are 2 kinds of RPC call from API layer to compute layer,\none is cast and another is call. For cast, the RPC message will\nbe posted and the API service will not wait for the message to\nbe processed. So it won't be able to catch the exception raised\nin compute layer and catch and handle the exception is useless\nand error leading. This patch removes code in API layer for\nrescue and unrescue functions.\n\nChange-Id: Iab8070c25a9dee505c0602efad85c41c21c2aa58\n""}, {'number': 3, 'created': '2014-07-25 15:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/857cb80a72d6ea2d36791d3311ec52bbf55bb23f', 'message': ""Remove rescue/unrescue NotImplementedError handle\n\nThere are 2 kinds of RPC call from API layer to compute layer,\none is cast and another is call. For cast, the RPC message will\nbe posted and the API service will not wait for the message to\nbe processed. So it won't be able to catch the exception raised\nin compute layer and catch and handle the exception is useless\nand error leading. This patch removes code in API layer for\nrescue and unrescue functions.\n\nChange-Id: Iab8070c25a9dee505c0602efad85c41c21c2aa58\n""}, {'number': 4, 'created': '2014-07-25 17:14:30.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_rescue.py', 'nova/api/openstack/compute/plugins/v3/rescue.py', 'nova/api/openstack/compute/contrib/rescue.py', 'nova/tests/api/openstack/compute/contrib/test_rescue.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b4a32a9623a31ef215adb6b523fbed994ee5c6b6', 'message': ""Remove rescue/unrescue NotImplementedError handle\n\nThere are 2 kinds of RPC call from API layer to compute layer,\none is cast and another is call. For cast, the RPC message will\nbe posted and the API service will not wait for the message to\nbe processed. So it won't be able to catch the exception raised\nin compute layer and catch and handle the exception is useless\nand error leading. This patch removes code in API layer for\nrescue and unrescue functions.\n\nChange-Id: Iab8070c25a9dee505c0602efad85c41c21c2aa58\n""}]",0,101788,b4a32a9623a31ef215adb6b523fbed994ee5c6b6,73,15,4,6062,,,0,"Remove rescue/unrescue NotImplementedError handle

There are 2 kinds of RPC call from API layer to compute layer,
one is cast and another is call. For cast, the RPC message will
be posted and the API service will not wait for the message to
be processed. So it won't be able to catch the exception raised
in compute layer and catch and handle the exception is useless
and error leading. This patch removes code in API layer for
rescue and unrescue functions.

Change-Id: Iab8070c25a9dee505c0602efad85c41c21c2aa58
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/101788/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_rescue.py', 'nova/api/openstack/compute/plugins/v3/rescue.py', 'nova/api/openstack/compute/contrib/rescue.py', 'nova/tests/api/openstack/compute/contrib/test_rescue.py']",4,4b11af44b4e48a8b6caa6ea6d0004098f1bd7a28,revert_v2_rescue_function,," @mock.patch('nova.compute.api.API.rescue') def test_rescue_raises_not_implemented(self, rescue_mock): body = dict(rescue=None) def fake_rescue(*args, **kwargs): raise NotImplementedError('not implemented') rescue_mock.side_effect = fake_rescue req = webob.Request.blank('/v2/fake/servers/test_inst/action') req.method = ""POST"" req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" resp = req.get_response(self.app) self.assertEqual(resp.status_int, 501) @mock.patch('nova.compute.api.API.unrescue') def test_unrescue_raises_not_implemented(self, unrescue_mock): body = dict(unrescue=None) def fake_unrescue(*args, **kwargs): raise NotImplementedError('not implemented') unrescue_mock.side_effect = fake_unrescue req = webob.Request.blank('/v2/fake/servers/test_inst/action') req.method = ""POST"" req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" resp = req.get_response(self.app) self.assertEqual(resp.status_int, 501)",0,77
openstack%2Ftripleo-incubator~master~Ie115a042ea409380c27b2c4d770a223ce74d8fad,openstack/tripleo-incubator,master,Ie115a042ea409380c27b2c4d770a223ce74d8fad,Document NeutronControlPlaneID,MERGED,2014-07-14 19:05:30.000000000,2014-08-15 13:17:24.000000000,2014-08-15 13:17:23.000000000,"[{'_account_id': 3}, {'_account_id': 7471}, {'_account_id': 7585}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-07-14 19:05:30.000000000', 'files': ['scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/1b002cb7eb5382661020bcf8ac0680b2b6aa0ca8', 'message': 'Document NeutronControlPlaneID\n\nNeutronControlPlaneID must be passed as a parameter when creating the\novercloud. Otherwise the stack create will fail with: ERROR: Either\nnetwork or network_id should be specified, as the OS::Neutron::Port type\nrequires network to be set to a non-empty string.\n\nThis does not show up in the CI because the parameter is set when\ndevtest was run as a script, but it needs to be documented as well for\nthose following along from the docs.\n\nChange-Id: Ie115a042ea409380c27b2c4d770a223ce74d8fad\n'}]",0,106844,1b002cb7eb5382661020bcf8ac0680b2b6aa0ca8,14,4,1,7144,,,0,"Document NeutronControlPlaneID

NeutronControlPlaneID must be passed as a parameter when creating the
overcloud. Otherwise the stack create will fail with: ERROR: Either
network or network_id should be specified, as the OS::Neutron::Port type
requires network to be set to a non-empty string.

This does not show up in the CI because the parameter is set when
devtest was run as a script, but it needs to be documented as well for
those following along from the docs.

Change-Id: Ie115a042ea409380c27b2c4d770a223ce74d8fad
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/44/106844/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_overcloud.sh'],1,1b002cb7eb5382661020bcf8ac0680b2b6aa0ca8,,"NeutronControlPlaneID=$(neutron net-show ctlplane | grep ' id ' | awk '{print $4}') ""NeutronControlPlaneID"": ""'${NeutronControlPlaneID}'"",","NeutronControlPlaneID=$(neutron net-show ctlplane | grep ' id ' | awk '{print $4}') ""NeutronControlPlaneID"": ""'${NeutronControlPlaneID}'"",",2,2
openstack%2Fkeystone~master~I0b1002adf6181fe6824e31de477cec4028df6bc6,openstack/keystone,master,I0b1002adf6181fe6824e31de477cec4028df6bc6,Pagination for api request to users list,ABANDONED,2013-12-26 16:10:12.000000000,2014-08-15 13:17:13.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1531}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6738}, {'_account_id': 8871}, {'_account_id': 9101}, {'_account_id': 9180}, {'_account_id': 9751}, {'_account_id': 11717}]","[{'number': 1, 'created': '2013-12-26 16:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1e2f4c6178af497324d5d093575d1b8b6e4a01b9', 'message': 'Add limit processing for getting users list\n\nKeystone client has limit parameter for users.list,\nbut it is not handled on the server side.\nImplement limit processing for users like it done\nfor tenants.\n\nCloses-bug: 1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n'}, {'number': 2, 'created': '2013-12-30 17:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/80f9925fb3e9355a73abb9293da219f4d2a680d3', 'message': 'Add limit processing for getting users list\n\nKeystone client has limit parameter for users.list,\nbut it is not handled on the server side.\nImplement limit processing for users like it done\nfor tenants.\n\nCloses-bug: 1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n'}, {'number': 3, 'created': '2013-12-31 08:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f9333b94a7d2a12289fb508d01edee835b8c7c28', 'message': 'Add limit processing for getting users list\n\nKeystone client has limit parameter for users.list,\nbut it is not handled on the server side.\nImplement limit processing for users like it done\nfor tenants.\n\nCloses-bug: #1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n'}, {'number': 4, 'created': '2014-01-15 11:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/56bd6005994dea026f14b0cd717690454e39dc0c', 'message': 'Pagination for users list\n\nImplement limit and marker processing\nfor users like it done for tenants.\n\nCloses-bug: #1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n'}, {'number': 5, 'created': '2014-01-16 10:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bf4cc172e07412ad4f9369e4248a372b79d9d5d0', 'message': 'Pagination for users list\n\nImplement limit and marker processing\nfor users like it done for tenants.\n\nCloses-bug: #1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n'}, {'number': 6, 'created': '2014-01-21 09:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ec48d4b3f05fbd8a264ee29a785ee131967f4505', 'message': ""Pagination for api request to users list\n\nImplements processing limit and marker params,\nwhich specified in api request for users list.\nThis params can be passed to the keystone client,\nbut doesn't process by server.\nImplements like it done for tenants.\n\nCloses-bug: #1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n""}, {'number': 7, 'created': '2014-02-24 22:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d9cad94a5f062302c127872fd313f3695364aa0b', 'message': ""Pagination for api request to users list\n\nImplements processing limit and marker params,\nwhich specified in api request for users list.\nThis params can be passed to the keystone client,\nbut doesn't process by server.\nImplements like it done for tenants.\n\nCloses-bug: #1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n""}, {'number': 8, 'created': '2014-02-25 14:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fc27aae36f8762de243ab2329f8b2c808e8ee620', 'message': ""Pagination for api request to users list\n\nImplements processing limit and marker params,\nwhich specified in api request for users list.\nThis params can be passed to the keystone client,\nbut doesn't process by server.\nImplements like it done for tenants.\n\nCloses-bug: #1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n""}, {'number': 9, 'created': '2014-04-28 09:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/528fa54690d9bb2fb7698080a943caced32b81d0', 'message': ""Pagination for api request to users list\n\nImplements processing limit and marker params,\nwhich specified in api request for users list.\nThis params can be passed to the keystone client,\nbut doesn't process by server.\nImplements like it done for tenants.\n\nCloses-bug: #1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n""}, {'number': 10, 'created': '2014-05-07 09:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8831c4e95cb06f9a6d232e138f19a0dc17adcd40', 'message': ""Pagination for api request to users list\n\nImplements processing limit and marker params,\nwhich specified in api request for users list.\nThis params can be passed to the keystone client,\nbut doesn't process by server.\nImplements like it done for tenants.\n\nCloses-bug: #1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n""}, {'number': 11, 'created': '2014-05-15 11:37:58.000000000', 'files': ['keystone/assignment/controllers.py', 'keystone/tests/test_keystoneclient.py', 'keystone/common/controller.py', 'keystone/identity/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7a440893ce4330015af7119a31ecc78c1a4f5ef2', 'message': ""Pagination for api request to users list\n\nImplements processing limit and marker params,\nwhich specified in api request for users list.\nThis params can be passed to the keystone client,\nbut doesn't process by server.\nImplements like it done for tenants.\n\nCloses-bug: #1079154\n\nChange-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6\n""}]",15,64159,7a440893ce4330015af7119a31ecc78c1a4f5ef2,71,13,11,9180,,,0,"Pagination for api request to users list

Implements processing limit and marker params,
which specified in api request for users list.
This params can be passed to the keystone client,
but doesn't process by server.
Implements like it done for tenants.

Closes-bug: #1079154

Change-Id: I0b1002adf6181fe6824e31de477cec4028df6bc6
",git fetch https://review.opendev.org/openstack/keystone refs/changes/59/64159/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_keystoneclient.py', 'keystone/identity/controllers.py']",2,1e2f4c6178af497324d5d093575d1b8b6e4a01b9,bug/1079154," limit = context['query_string'].get('limit') if limit is not None: try: limit = int(limit) if limit < 0: raise AssertionError() except (ValueError, AssertionError): msg = _('Invalid limit value') raise exception.ValidationError(message=msg) if limit is not None: user_list = user_list[:limit]",,26,0
openstack%2Frally~master~I547f93d829036a5edb67b4e71b9f360de18a2fd3,openstack/rally,master,I547f93d829036a5edb67b4e71b9f360de18a2fd3,Add additional results to task result,ABANDONED,2014-07-11 08:38:20.000000000,2014-08-15 13:16:05.000000000,,"[{'_account_id': 3}, {'_account_id': 9180}]","[{'number': 1, 'created': '2014-07-11 08:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/39f7a5761a89f8cbc663d62c18ffec377d27cb1b', 'message': 'Add additional results to task result\n\nWe need some result from ScenarioRunner, that availiable only after\nall scenario runs, so it is better to get it as returned value from\nrunner.run and not to distend result_queue\n\n* Add class RunnerResult for runner specific results that should not\n  be sended to result_queue\n* Add field ""extras"" to ""data"" to store RunnerResult\n* Rename ScenarioRunnerResult to RunnerResult due to it\'s current\n  appointment\n\nChange-Id: I547f93d829036a5edb67b4e71b9f360de18a2fd3\n'}, {'number': 2, 'created': '2014-07-18 09:54:47.000000000', 'files': ['tests/benchmark/runners/test_base.py', 'rally/benchmark/runners/base.py', 'tests/orchestrator/test_api.py', 'tests/benchmark/runners/test_constant.py', 'tests/benchmark/runners/test_periodic.py', 'rally/cmd/commands/task.py', 'rally/benchmark/engine.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/d3e50fce7c46496666b07a796c79a924a4fedc07', 'message': 'Add additional results to task result\n\nWe need some result from ScenarioRunner, that availiable only after\nall scenario runs, so it is better to get it as returned value from\nrunner.run and not to distend result_queue\n\n* Add class RunnerResult for runner specific results that should not\n  be sended to result_queue\n* Add field ""extras"" to ""data"" to store RunnerResult\n* Rename ScenarioRunnerResult to RunnerResult due to it\'s current\n  appointment\n\nChange-Id: I547f93d829036a5edb67b4e71b9f360de18a2fd3\n'}]",0,106308,d3e50fce7c46496666b07a796c79a924a4fedc07,9,2,2,9180,,,0,"Add additional results to task result

We need some result from ScenarioRunner, that availiable only after
all scenario runs, so it is better to get it as returned value from
runner.run and not to distend result_queue

* Add class RunnerResult for runner specific results that should not
  be sended to result_queue
* Add field ""extras"" to ""data"" to store RunnerResult
* Rename ScenarioRunnerResult to RunnerResult due to it's current
  appointment

Change-Id: I547f93d829036a5edb67b4e71b9f360de18a2fd3
",git fetch https://review.opendev.org/openstack/rally refs/changes/08/106308/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/benchmark/runners/test_base.py', 'rally/benchmark/runners/base.py', 'tests/benchmark/runners/test_constant.py', 'tests/benchmark/runners/test_periodic.py', 'rally/cmd/commands/task.py', 'rally/benchmark/engine.py']",6,39f7a5761a89f8cbc663d62c18ffec377d27cb1b,extra_runner_results," runner_result = runner.run(name, kw.get(""context"", {}), kw.get(""args"", {})) is_done.extras = runner_result task.append_results(key, {""raw"": results, ""extras"": is_done.extras})"," runner.run(name, kw.get(""context"", {}), kw.get(""args"", {})) task.append_results(key, {""raw"": results})",62,26
openstack%2Ftripleo-image-elements~master~I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e,openstack/tripleo-image-elements,master,I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e,Add pkg_map support to openvswitch elements,MERGED,2014-07-15 08:26:45.000000000,2014-08-15 13:15:15.000000000,2014-08-15 13:15:14.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 360}, {'_account_id': 1726}, {'_account_id': 6796}, {'_account_id': 6969}, {'_account_id': 7144}, {'_account_id': 8532}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-07-15 08:26:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d7a7c7cd5193382507df4e3ec319fb58503dabf1', 'message': 'Add pkg_map support to neutron element\n\nNeutron element install openvswitch from packages. This is not needed\non RH family distros, and on SuSE they use a different name.\nAdding support for pkg_map we can address all this differences.\n\nChange-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e\n'}, {'number': 2, 'created': '2014-07-15 09:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/10424c0602e1f75a4a00fa8c3c4001abe20a3de3', 'message': 'Add pkg_map support to openvswitch elements\n\nOpenvswitch elements install openvswitch from packages. This is not needed\non RH family distros, and on SuSE they use a different name.\nAdding support for pkg_map so we can address all this differences.\n\nChange-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e\n'}, {'number': 3, 'created': '2014-07-15 10:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e8c423d4472cb8af510d7391ff62f9e430fff35b', 'message': 'Add pkg_map support to openvswitch elements\n\nOpenvswitch elements install openvswitch from packages. This is not needed\non RH family distros, and on SuSE they use a different name.\nAdding support for pkg_map so we can address all this differences.\n\nChange-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e\n'}, {'number': 4, 'created': '2014-07-15 17:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/dfe1cb0f2cf5d3378e7ccd19f98e89c4d1ebc316', 'message': 'Add pkg_map support to openvswitch elements\n\nOpenvswitch elements install openvswitch from packages. This is not needed\non RH family distros, and on SuSE they use a different name.\nAdding support for pkg_map so we can address all this differences.\n\nChange-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e\n'}, {'number': 5, 'created': '2014-07-17 20:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/7564e62c1077142cbd22d5ef5a5a0c23edeaa6d5', 'message': 'Add pkg_map support to openvswitch elements\n\nOpenvswitch elements install openvswitch from packages. This is not needed\non RH family distros, and on SuSE they use a different name.\nAdding support for pkg_map so we can address all this differences.\n\nChange-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e\n'}, {'number': 6, 'created': '2014-07-17 20:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2902bbcc00066fb01947e69450733f1f1551bffa', 'message': 'Add pkg_map support to openvswitch elements\n\nOpenvswitch elements install openvswitch from packages. This is not needed\non RH family distros, and on SuSE they use a different name.\nAdding support for pkg_map so we can address all this differences.\n\nChange-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e\n'}, {'number': 7, 'created': '2014-07-18 08:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f2a637c391d1db08815c65331605a62996a40532', 'message': 'Add pkg_map support to openvswitch elements\n\nOpenvswitch elements install openvswitch from packages. This is not needed\non RH family distros, and on SuSE they use a different name.\nAdding support for pkg_map so we can address all this differences.\n\nChange-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e\n'}, {'number': 8, 'created': '2014-07-18 08:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a3d78670214152bf45633add1fa806ba75d9bbbb', 'message': 'Add pkg_map support to openvswitch elements\n\nOpenvswitch elements install openvswitch from packages. This is not needed\non RH family distros, and on SuSE they use a different name.\nAdding support for pkg_map so we can address all this differences.\n\nChange-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e\n'}, {'number': 9, 'created': '2014-07-22 15:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3d5ecfd4783a7ecf1982e4832535ffc82836d17e', 'message': 'Add pkg_map support to openvswitch elements\n\nOpenvswitch elements install openvswitch from packages. This is not needed\non RH family distros, and on SuSE they use a different name.\nAdding support for pkg_map so we can address all this differences.\n\nChange-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e\n'}, {'number': 10, 'created': '2014-08-11 09:28:33.000000000', 'files': ['elements/openvswitch/install.d/74-openvswitch', 'elements/openvswitch-datapath/pkg-map', 'elements/openvswitch/pkg-map', 'elements/openvswitch-datapath/install.d/75-openvswitch-datapath'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9a69a2ed8f28b11704b02c23e5f1420b1a9404ed', 'message': 'Add pkg_map support to openvswitch elements\n\nOpenvswitch elements install openvswitch from packages. This is not needed\non RH family distros, and on SuSE they use a different name.\nAdding support for pkg_map so we can address all this differences.\n\nChange-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e\n'}]",4,106960,9a69a2ed8f28b11704b02c23e5f1420b1a9404ed,61,9,10,1726,,,0,"Add pkg_map support to openvswitch elements

Openvswitch elements install openvswitch from packages. This is not needed
on RH family distros, and on SuSE they use a different name.
Adding support for pkg_map so we can address all this differences.

Change-Id: I257ecede6f4fe0b7e6ee7b9ce660d5bfade06a1e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/60/106960/4 && git format-patch -1 --stdout FETCH_HEAD,"['elements/neutron/install.d/neutron-source-install/76-neutron', 'elements/neutron/pkg-map', 'elements/neutron/element-deps']",3,d7a7c7cd5193382507df4e3ec319fb58503dabf1,bug/1316985,pkg-map,,18,1
openstack%2Fopenstack-doc-tools~master~Ie68e88d4b8a310382795c727ff9824289cbcc3b9,openstack/openstack-doc-tools,master,Ie68e88d4b8a310382795c727ff9824289cbcc3b9,It's isfile,MERGED,2014-08-15 12:47:56.000000000,2014-08-15 13:04:33.000000000,2014-08-15 13:04:33.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6843}]","[{'number': 1, 'created': '2014-08-15 12:47:56.000000000', 'files': ['os_doc_tools/doctest.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/f8d8886cc08f485c06869f5fdf7788a510fc8f17', 'message': ""It's isfile\n\nIt's os.path.isfile instead of is_file.\n\nChange-Id: Ie68e88d4b8a310382795c727ff9824289cbcc3b9\n""}]",0,114525,f8d8886cc08f485c06869f5fdf7788a510fc8f17,8,3,1,6547,,,0,"It's isfile

It's os.path.isfile instead of is_file.

Change-Id: Ie68e88d4b8a310382795c727ff9824289cbcc3b9
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/25/114525/1 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/doctest.py'],1,f8d8886cc08f485c06869f5fdf7788a510fc8f17,fix-is-file," if os.path.isfile(os.path.join(get_publish_path(), 'www-index.html')):"," if os.path.is_file(os.path.join(get_publish_path(), 'www-index.html')):",1,1
openstack%2Ftripleo-heat-templates~master~I98499dd54bb907d29cf355fe83b5c285a7375e97,openstack/tripleo-heat-templates,master,I98499dd54bb907d29cf355fe83b5c285a7375e97,Add strict dependencies to the undercloud template,MERGED,2014-08-14 10:49:39.000000000,2014-08-15 12:44:51.000000000,2014-08-15 12:44:50.000000000,"[{'_account_id': 3}, {'_account_id': 1605}, {'_account_id': 6449}, {'_account_id': 7579}, {'_account_id': 8688}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-08-14 10:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/09f56168d8b3de1f2c0f725fb73a2189c06581e4', 'message': 'Add strict dependencies to the undercloud template\n\nCurrently there is very weak ordering of StructuredDeployments during\nheat stack creation on the undercloud. This can cause the deployment which\nsends the completion signal back to Heat to happen before all others have\ncompleted, which in turn leads Heat to state the stack is ready while ORC\nis still configuring services\n\nThe only workaround to this is to wait an unknown amount of time after the\nheat stack completes before the system is usable.\n\nThis patch prevents the completion signal from being returned early, by\nensuring these are strictly ordered:\n   undercloudIronicDeployment (if used)\n   undercloudNovaDeployment\n   undercloudPassthroughDeployment\n   undercloudDeployment\n\nChange-Id: I98499dd54bb907d29cf355fe83b5c285a7375e97\nNote: The refrencing for the undercloud has been removed.\n'}, {'number': 2, 'created': '2014-08-14 10:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8f350903fe6813b4f145a4238e1bd9b109469f51', 'message': 'Add strict dependencies to the undercloud template\n\nCurrently there is very weak ordering of StructuredDeployments during\nheat stack creation on the undercloud. This can cause the deployment which\nsends the completion signal back to Heat to happen before all others have\ncompleted, which in turn leads Heat to state the stack is ready while ORC\nis still configuring services\n\nThe only workaround to this is to wait an unknown amount of time after the\nheat stack completes before the system is usable.\n\nThis patch prevents the completion signal from being returned early, by\nensuring these are strictly ordered:\n   undercloudIronicDeployment (if used)\n   undercloudNovaDeployment\n   undercloudPassthroughDeployment\n   undercloudDeployment\n\nChange-Id: I98499dd54bb907d29cf355fe83b5c285a7375e97\nNote: The reference numbering for the undercloud has been removed.\n'}, {'number': 3, 'created': '2014-08-14 10:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/761f7cf96f4340ab4f28f44608ba93bafc05c4a5', 'message': 'Add strict dependencies to the undercloud template\n\nCurrently there is very weak ordering of StructuredDeployments during\nheat stack creation on the undercloud. This can cause the deployment which\nsends the completion signal back to Heat to happen before all others have\ncompleted, which in turn leads Heat to state the stack is ready while ORC\nis still configuring services\n\nThe only workaround to this is to wait an unknown amount of time after the\nheat stack completes before the system is usable.\n\nThis patch prevents the completion signal from being returned early, by\nensuring these are strictly ordered:\n   undercloudIronicDeployment (if used)\n   undercloudNovaDeployment\n   undercloudPassthroughDeployment\n   undercloudDeployment\n\nNote: The reference numbering for the undercloud has been removed.\nChange-Id: I98499dd54bb907d29cf355fe83b5c285a7375e97\n'}, {'number': 4, 'created': '2014-08-14 10:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bd8a546f178a52fd0ba07732f2bd2db8eab65853', 'message': 'Add strict dependencies to the undercloud template\n\nCurrently there is very weak ordering of StructuredDeployments during\nheat stack creation on the undercloud. This can cause the deployment which\nsends the completion signal back to Heat to happen before all others have\ncompleted, which in turn leads Heat to state the stack is ready while ORC\nis still configuring services\n\nThe only workaround to this is to wait an unknown amount of time after the\nheat stack completes before the system is usable.\n\nThis patch prevents the completion signal from being returned early, by\nensuring these are strictly ordered:\n   undercloudIronicDeployment (if used)\n   undercloudNovaDeployment\n   undercloudPassthroughDeployment\n   undercloudDeployment\n\nNote: The reference numbering for the undercloud has been removed.\nChange-Id: I98499dd54bb907d29cf355fe83b5c285a7375e97\n'}, {'number': 5, 'created': '2014-08-14 13:31:56.000000000', 'files': ['undercloud-vm-ironic-deploy.yaml', 'undercloud-bm-nova-deploy.yaml', 'undercloud-vm-nova-deploy.yaml', 'undercloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/de1ea55597b22bfbd8ba51b801a52c43cbd04555', 'message': 'Add strict dependencies to the undercloud template\n\nCurrently there is very weak ordering of StructuredDeployments during\nheat stack creation on the undercloud. This can cause the deployment which\nsends the completion signal back to Heat to happen before all others have\ncompleted, which in turn leads Heat to state the stack is ready while ORC\nis still configuring services\n\nThe only workaround to this is to wait an unknown amount of time after the\nheat stack completes before the system is usable.\n\nThis patch prevents the completion signal from being returned early, by\nensuring these are strictly ordered:\n   undercloudIronicDeployment (if used)\n   undercloudNovaDeployment\n   undercloudPassthroughDeployment\n   undercloudDeployment\n\nNote: The reference numbering for the undercloud has been removed.\nChange-Id: I98499dd54bb907d29cf355fe83b5c285a7375e97\n'}]",0,114197,de1ea55597b22bfbd8ba51b801a52c43cbd04555,26,6,5,10373,,,0,"Add strict dependencies to the undercloud template

Currently there is very weak ordering of StructuredDeployments during
heat stack creation on the undercloud. This can cause the deployment which
sends the completion signal back to Heat to happen before all others have
completed, which in turn leads Heat to state the stack is ready while ORC
is still configuring services

The only workaround to this is to wait an unknown amount of time after the
heat stack completes before the system is usable.

This patch prevents the completion signal from being returned early, by
ensuring these are strictly ordered:
   undercloudIronicDeployment (if used)
   undercloudNovaDeployment
   undercloudPassthroughDeployment
   undercloudDeployment

Note: The reference numbering for the undercloud has been removed.
Change-Id: I98499dd54bb907d29cf355fe83b5c285a7375e97
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/97/114197/4 && git format-patch -1 --stdout FETCH_HEAD,"['undercloud-vm-ironic-deploy.yaml', 'undercloud-bm-nova-deploy.yaml', 'undercloud-vm-nova-deploy.yaml', 'undercloud-source.yaml']",4,09f56168d8b3de1f2c0f725fb73a2189c06581e4,feature/heat_dependencies, undercloudDeployment: depends_on: [undercloudPassthroughDeployment] undercloudPassthroughDeployment: depend_on: [undercloudNovaDeployment], 99_undercloudDeployment: 00_undercloudPassthroughDeployment:,9,6
openstack%2Fheat~master~Iac09aaa60ef5c1de27c9eeca7c65eca41c06907e,openstack/heat,master,Iac09aaa60ef5c1de27c9eeca7c65eca41c06907e,Native WaitConditionHandle move to common curl_cli,MERGED,2014-08-12 14:42:08.000000000,2014-08-15 12:42:22.000000000,2014-08-15 12:42:21.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 8871}, {'_account_id': 12437}]","[{'number': 1, 'created': '2014-08-12 14:42:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/965332bb622ee91d4039d3e8156a4e4351bebb24', 'message': ""Native WaitConditionHandle move to common curl_cli\n\nMove to a common curl_cli attribute, which can be used for both\nsuccess (default) and failure (by passing appropriate status data,\nand optionally reason).  This should allow a slightly more flexible\ninterface than the current success/failure attributes, while still\nremaining simple, and enabling simpler portability between this and\nthe alternative Swift signal implementation.\n\nNote this breaks compatibility with the attributes we just recently\nmerged, but I'm assuming since it's so recent nobody is using it yet.\n\nThe example template at https://review.openstack.org/#/c/106424/ has\nbeen updated to reflect the new interface.\n\nChange-Id: Iac09aaa60ef5c1de27c9eeca7c65eca41c06907e\nblueprint: native-waitcondition\n""}, {'number': 2, 'created': '2014-08-14 13:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c2343992285b4fd4f1d03461e3fc9a260942c488', 'message': ""Native WaitConditionHandle move to common curl_cli\n\nMove to a common curl_cli attribute, which can be used for both\nsuccess (default) and failure (by passing appropriate status data,\nand optionally reason).  This should allow a slightly more flexible\ninterface than the current success/failure attributes, while still\nremaining simple, and enabling simpler portability between this and\nthe alternative Swift signal implementation.\n\nNote this breaks compatibility with the attributes we just recently\nmerged, but I'm assuming since it's so recent nobody is using it yet.\n\nThe example template at https://review.openstack.org/#/c/106424/ has\nbeen updated to reflect the new interface.\n\nChange-Id: Iac09aaa60ef5c1de27c9eeca7c65eca41c06907e\nblueprint: native-waitcondition\n""}, {'number': 3, 'created': '2014-08-14 16:26:11.000000000', 'files': ['heat/tests/test_waitcondition.py', 'heat/engine/resources/wait_condition.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7e742a4f9184c667dfc0999fb642ef28b4cbef91', 'message': ""Native WaitConditionHandle move to common curl_cli\n\nMove to a common curl_cli attribute, which can be used for both\nsuccess (default) and failure (by passing appropriate status data,\nand optionally reason).  This should allow a slightly more flexible\ninterface than the current success/failure attributes, while still\nremaining simple, and enabling simpler portability between this and\nthe alternative Swift signal implementation.\n\nNote this breaks compatibility with the attributes we just recently\nmerged, but I'm assuming since it's so recent nobody is using it yet.\n\nThe example template at https://review.openstack.org/#/c/106424/ has\nbeen updated to reflect the new interface.\n\nChange-Id: Iac09aaa60ef5c1de27c9eeca7c65eca41c06907e\nblueprint: native-waitcondition\n""}]",2,113541,7e742a4f9184c667dfc0999fb642ef28b4cbef91,23,8,3,4328,,,0,"Native WaitConditionHandle move to common curl_cli

Move to a common curl_cli attribute, which can be used for both
success (default) and failure (by passing appropriate status data,
and optionally reason).  This should allow a slightly more flexible
interface than the current success/failure attributes, while still
remaining simple, and enabling simpler portability between this and
the alternative Swift signal implementation.

Note this breaks compatibility with the attributes we just recently
merged, but I'm assuming since it's so recent nobody is using it yet.

The example template at https://review.openstack.org/#/c/106424/ has
been updated to reflect the new interface.

Change-Id: Iac09aaa60ef5c1de27c9eeca7c65eca41c06907e
blueprint: native-waitcondition
",git fetch https://review.opendev.org/openstack/heat refs/changes/41/113541/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_waitcondition.py', 'heat/engine/resources/wait_condition.py']",2,965332bb622ee91d4039d3e8156a4e4351bebb24,bp/native-waitcondition8," CURL_CLI, 'curl_cli', CURL_CLI: attributes.Schema( 'prefix, which can be used for signalling handle completion or ' 'failure. If no data is passed, success is assumed, or ' 'you can signal failure by adding ' '--data-binary \'{""status"": ""FAILED""}\''), elif key == self.CURL_CLI:"," CURL_CLI_SUCCESS, CURL_CLI_FAILURE, 'curl_cli_success', 'curl_cli_failure', CURL_CLI_SUCCESS: attributes.Schema( 'which can be used for signalling handle completion'), cache_mode=attributes.Schema.CACHE_NONE ), CURL_CLI_FAILURE: attributes.Schema( _('Convenience attribute, provides curl CLI command ' 'which can be used for signalling handle failure'), elif key == self.CURL_CLI_SUCCESS: elif key == self.CURL_CLI_FAILURE: return ('curl -i -X POST ' '--data-binary \'{""status"": ""%(status)s""}\' ' '-H \'X-Auth-Token: %(token)s\' ' '-H \'Content-Type: application/json\' ' '-H \'Accept: application/json\' ' '%(endpoint)s' % dict(status=self.STATUS_FAILURE, token=self.data().get('token'), endpoint=self.data().get('endpoint')))",10,40
openstack%2Fpython-openstackclient~master~I5e7ffb6df38d9ccfc56c99b110a26ad20e40648b,openstack/python-openstackclient,master,I5e7ffb6df38d9ccfc56c99b110a26ad20e40648b,Use region instead of region_name,ABANDONED,2014-06-25 18:58:20.000000000,2014-08-15 12:34:02.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-06-25 18:58:20.000000000', 'files': ['openstackclient/tests/test_shell.py', 'doc/source/man/openstack.rst', 'openstackclient/compute/client.py', 'openstackclient/shell.py', 'openstackclient/common/clientmanager.py', 'openstackclient/identity/client.py', 'openstackclient/network/client.py', 'openstackclient/volume/client.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c860c466a4369f04efc5d5f01a73c351489a47a4', 'message': 'Use region instead of region_name\n\nThere are no names for regions in v3, just user defined ids.\nhttps://review.openstack.org/#/c/99456/2/examples/common.py\n\nChange-Id: I5e7ffb6df38d9ccfc56c99b110a26ad20e40648b\n'}]",0,102606,c860c466a4369f04efc5d5f01a73c351489a47a4,6,3,1,8736,,,0,"Use region instead of region_name

There are no names for regions in v3, just user defined ids.
https://review.openstack.org/#/c/99456/2/examples/common.py

Change-Id: I5e7ffb6df38d9ccfc56c99b110a26ad20e40648b
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/06/102606/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/test_shell.py', 'doc/source/man/openstack.rst', 'openstackclient/compute/client.py', 'openstackclient/shell.py', 'openstackclient/common/clientmanager.py', 'openstackclient/identity/client.py', 'openstackclient/network/client.py', 'openstackclient/volume/client.py']",8,c860c466a4369f04efc5d5f01a73c351489a47a4,region," region_name=instance._region,"," region_name=instance._region_name,",32,32
openstack%2Ffuel-ostf~master~I0778c1db99f8e49a7fc28235370cc0e9864d2795,openstack/fuel-ostf,master,I0778c1db99f8e49a7fc28235370cc0e9864d2795,Fixed issue with Heat OSTF tests in HA,ABANDONED,2014-07-25 11:14:31.000000000,2014-08-15 12:22:53.000000000,,"[{'_account_id': 3}, {'_account_id': 6502}, {'_account_id': 6577}, {'_account_id': 6719}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-25 11:14:31.000000000', 'files': ['fuel_health/tests/platform_tests/test_heat.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/908346d3bea6415a30e995cb0e0dd0e73ef184f7', 'message': 'Fixed issue with Heat OSTF tests in HA\n\nWe need to hide Heat OSTF tests in HA mode.\n\nChange-Id: I0778c1db99f8e49a7fc28235370cc0e9864d2795\nCloses-Bug: #1337858\n'}]",1,109547,908346d3bea6415a30e995cb0e0dd0e73ef184f7,12,8,1,7227,,,0,"Fixed issue with Heat OSTF tests in HA

We need to hide Heat OSTF tests in HA mode.

Change-Id: I0778c1db99f8e49a7fc28235370cc0e9864d2795
Closes-Bug: #1337858
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/47/109547/1 && git format-patch -1 --stdout FETCH_HEAD,['fuel_health/tests/platform_tests/test_heat.py'],1,908346d3bea6415a30e995cb0e0dd0e73ef184f7,," if 'ha' in self.config.compute.deployment_mode: self.skipTest(""This test can't be executed in HA mode."") ",,3,0
openstack%2Ffuel-library~master~Ia7383d54c3651344d97c3adcad35930e766f26f6,openstack/fuel-library,master,Ia7383d54c3651344d97c3adcad35930e766f26f6,Fix sysctl net.ipv4.ip_local_reserved_ports,MERGED,2014-08-15 10:52:00.000000000,2014-08-15 12:14:15.000000000,2014-08-15 12:00:44.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-15 10:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e06dbacb8c253879fd39ec06d58a6ac2d932f81d', 'message': 'Fix sysctl net.ipv4.ip_local_reserved_ports\n\nCorrect name is net.ipv4.ip_local_reserved_ports, not\nsys.net.ipv4.ip_local_reserved_ports\n\nChange-Id: Ia7383d54c3651344d97c3adcad35930e766f26f6\n'}, {'number': 2, 'created': '2014-08-15 10:57:27.000000000', 'files': ['deployment/puppet/zabbix/manifests/monitoring/rabbitmq_mon.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/81741445d4ab2db198585149815bb80a238a1214', 'message': 'Fix sysctl net.ipv4.ip_local_reserved_ports\n\nCorrect name is net.ipv4.ip_local_reserved_ports, not\nsys.net.ipv4.ip_local_reserved_ports\n\nCloses-bug: #1357317\n\nChange-Id: Ia7383d54c3651344d97c3adcad35930e766f26f6\n'}]",0,114500,81741445d4ab2db198585149815bb80a238a1214,23,5,2,9387,,,0,"Fix sysctl net.ipv4.ip_local_reserved_ports

Correct name is net.ipv4.ip_local_reserved_ports, not
sys.net.ipv4.ip_local_reserved_ports

Closes-bug: #1357317

Change-Id: Ia7383d54c3651344d97c3adcad35930e766f26f6
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/00/114500/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/zabbix/manifests/monitoring/rabbitmq_mon.pp'],1,e06dbacb8c253879fd39ec06d58a6ac2d932f81d,fix-sysctl, sysctl::value { 'net.ipv4.ip_local_reserved_ports': value => '55672' }, sysctl::value { 'sys.net.ipv4.ip_local_reserved_ports': value => '55672' },1,1
openstack%2Fswift~master~Id76b008e1f273c639ae61550affddc32c5d7c419,openstack/swift,master,Id76b008e1f273c639ae61550affddc32c5d7c419,Add a env var to use in-memory obj server in func,MERGED,2014-05-06 14:56:22.000000000,2014-08-15 12:01:04.000000000,2014-08-15 12:01:03.000000000,"[{'_account_id': 3}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 9625}]","[{'number': 1, 'created': '2014-05-06 14:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9518491997eb6b660259595146ddf32c00fa5e16', 'message': 'Add a env var to use in-memory obj server in func\n\nAdd an environment variable to enable the use of the in-memory object\nserver during functional tests.\n\nIt might be worth-while to just run both, but this at least enables it,\nwithout having to figure out how to make two test runs in two different\nenvironments.\n\nChange-Id: Id76b008e1f273c639ae61550affddc32c5d7c419\n'}, {'number': 2, 'created': '2014-05-06 14:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/158ac4b2d99c303cbbe3b5336a3ccc1d032af476', 'message': 'Add a env var to use in-memory obj server in func\n\nAdd an environment variable to enable the use of the in-memory object\nserver during in-process functional test runs.\n\nIt might be worth-while to just run under both object servers in-tree,\nbut this at least enables it, without having to figure out how to make\ntwo test runs in two different environments.\n\nChange-Id: Id76b008e1f273c639ae61550affddc32c5d7c419\n'}, {'number': 3, 'created': '2014-05-14 19:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/624c822ed842f39db3702482aec14c3714cfceb8', 'message': 'Add a env var to use in-memory obj server in func\n\nAdd an environment variable to enable the use of the in-memory object\nserver during in-process functional test runs.\n\nIt might be worth-while to just run under both object servers in-tree,\nbut this at least enables it, without having to figure out how to make\ntwo test runs in two different environments.\n\nChange-Id: Id76b008e1f273c639ae61550affddc32c5d7c419\n'}, {'number': 4, 'created': '2014-07-25 16:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fced1324ec1953e145fe1e8bcf52acef73ef9db6', 'message': 'Add a env var to use in-memory obj server in func\n\nAdd an environment variable to enable the use of the in-memory object\nserver during in-process functional test runs.\n\nIt might be worth-while to just run under both object servers in-tree,\nbut this at least enables it, without having to figure out how to make\ntwo test runs in two different environments.\n\nChange-Id: Id76b008e1f273c639ae61550affddc32c5d7c419\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 5, 'created': '2014-07-25 18:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/21fc3706658c13f2f7fa5b442688d49b5b11141e', 'message': 'Add a env var to use in-memory obj server in func\n\nAdd an environment variable to enable the use of the in-memory object\nserver during in-process functional test runs.\n\nIt might be worth-while to just run under both object servers in-tree,\nbut this at least enables it, without having to figure out how to make\ntwo test runs in two different environments.\n\nChange-Id: Id76b008e1f273c639ae61550affddc32c5d7c419\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 6, 'created': '2014-07-25 18:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3de4a38625d14f08955596f53e8911ba797d5fe8', 'message': 'Add a env var to use in-memory obj server in func\n\nAdd an environment variable to enable the use of the in-memory object\nserver during in-process functional test runs.\n\nIt might be worth-while to just run under both object servers in-tree,\nbut this at least enables it, without having to figure out how to make\ntwo test runs in two different environments.\n\nChange-Id: Id76b008e1f273c639ae61550affddc32c5d7c419\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 7, 'created': '2014-08-04 16:03:47.000000000', 'files': ['doc/source/development_saio.rst', 'swift/obj/mem_diskfile.py', 'test/functional/__init__.py', 'doc/source/development_guidelines.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/3e04606f87c8cb3207ffeb717a6f5407b77b4d12', 'message': 'Add a env var to use in-memory obj server in func\n\nAdd an environment variable to enable the use of the in-memory object\nserver during in-process functional test runs.\n\nIt might be worth-while to just run under both object servers in-tree,\nbut this at least enables it, without having to figure out how to make\ntwo test runs in two different environments.\n\nDocImpact\n\nChange-Id: Id76b008e1f273c639ae61550affddc32c5d7c419\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}]",2,92381,3e04606f87c8cb3207ffeb717a6f5407b77b4d12,45,6,7,6198,,,0,"Add a env var to use in-memory obj server in func

Add an environment variable to enable the use of the in-memory object
server during in-process functional test runs.

It might be worth-while to just run under both object servers in-tree,
but this at least enables it, without having to figure out how to make
two test runs in two different environments.

DocImpact

Change-Id: Id76b008e1f273c639ae61550affddc32c5d7c419
Signed-off-by: Thiago da Silva <thiago@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/81/92381/5 && git format-patch -1 --stdout FETCH_HEAD,['test/functional/__init__.py'],1,9518491997eb6b660259595146ddf32c00fa5e16,inmemfunc,"from swift.obj import server as object_server, mem_server as mem_object_server in_mem_obj_env = os.environ.get('SWIFT_TEST_IN_MEMORY_OBJ') in_mem_obj = utils.config_true_value(in_mem_obj_env) in_process_setup(the_object_server=( mem_object_server if in_mem_obj else object_server))",from swift.obj import server as object_server in_process_setup(),5,2
openstack%2Fceilometer~stable%2Fhavana~Ic5082b74a362ded8b35cbc75cf178fe6e0db62d0,openstack/ceilometer,stable/havana,Ic5082b74a362ded8b35cbc75cf178fe6e0db62d0,Update ensure()/reconnect() to catch MessagingError,MERGED,2014-07-28 12:47:37.000000000,2014-08-15 12:00:57.000000000,2014-08-15 12:00:56.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 7729}, {'_account_id': 8052}, {'_account_id': 9656}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-07-28 12:47:37.000000000', 'files': ['ceilometer/openstack/common/rpc/impl_qpid.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ff3f25b35b965a439c30f4501cebbe2d0288fe97', 'message': 'Update ensure()/reconnect() to catch MessagingError\n\nThe error handling code that gets connections reset if necessary\ncaught ConnectionError. It really needs to catch MessagingError,\nwhich ConnectionError inherits from. There are other types of\nMessagingErrors that may occur, such as InternalError, and they need\nto cause the connection to reset, as well.\n\nThis fix has already been merged into oslo.messaging.\n\n--\n\nCherry-picked from oslo-incubator 234f64d608266f43d8856ff98c89ceba6699d752\nSee also https://bugzilla.redhat.com/show_bug.cgi?id=1086077\n\nCloses-bug: #1303890\nChange-Id: Ic5082b74a362ded8b35cbc75cf178fe6e0db62d0\n'}]",0,109993,ff3f25b35b965a439c30f4501cebbe2d0288fe97,28,8,1,8052,,,0,"Update ensure()/reconnect() to catch MessagingError

The error handling code that gets connections reset if necessary
caught ConnectionError. It really needs to catch MessagingError,
which ConnectionError inherits from. There are other types of
MessagingErrors that may occur, such as InternalError, and they need
to cause the connection to reset, as well.

This fix has already been merged into oslo.messaging.

--

Cherry-picked from oslo-incubator 234f64d608266f43d8856ff98c89ceba6699d752
See also https://bugzilla.redhat.com/show_bug.cgi?id=1086077

Closes-bug: #1303890
Change-Id: Ic5082b74a362ded8b35cbc75cf178fe6e0db62d0
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/93/109993/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/openstack/common/rpc/impl_qpid.py'],1,ff3f25b35b965a439c30f4501cebbe2d0288fe97,, except qpid_exceptions.MessagingError: except qpid_exceptions.MessagingError as e: qpid_exceptions.MessagingError) as e:, except qpid_exceptions.ConnectionError: except qpid_exceptions.ConnectionError as e: qpid_exceptions.ConnectionError) as e:,3,3
openstack%2Foslo.vmware~master~Id08d5fa4f7ce077102bbf77f4c8c2d6b2bfc4c31,openstack/oslo.vmware,master,Id08d5fa4f7ce077102bbf77f4c8c2d6b2bfc4c31,Add Pylint testenv environment,MERGED,2014-08-04 13:29:36.000000000,2014-08-15 12:00:50.000000000,2014-08-15 12:00:49.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 5638}, {'_account_id': 9171}]","[{'number': 1, 'created': '2014-08-04 13:29:36.000000000', 'files': ['pylintrc', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/788e9447c3717aca90bab26f611c170d050d2b4c', 'message': 'Add Pylint testenv environment\n\nChange-Id: Id08d5fa4f7ce077102bbf77f4c8c2d6b2bfc4c31\n'}]",2,111725,788e9447c3717aca90bab26f611c170d050d2b4c,12,4,1,167,,,0,"Add Pylint testenv environment

Change-Id: Id08d5fa4f7ce077102bbf77f4c8c2d6b2bfc4c31
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/25/111725/1 && git format-patch -1 --stdout FETCH_HEAD,"['pylintrc', 'test-requirements.txt', 'tox.ini']",3,788e9447c3717aca90bab26f611c170d050d2b4c,add_pylint,[testenv:pylint] commands = pylint oslo ,,35,0
openstack%2Fdesignate~master~I4971892222b97811110dc71085f38a0337e132d1,openstack/designate,master,I4971892222b97811110dc71085f38a0337e132d1,Add two more hacking checks,MERGED,2014-08-12 18:44:39.000000000,2014-08-15 11:56:32.000000000,2014-08-15 11:56:31.000000000,"[{'_account_id': 3}, {'_account_id': 8094}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-08-12 18:44:39.000000000', 'files': ['designate/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/8ce3742045a033fe879c4585324465c1dc8a4e14', 'message': 'Add two more hacking checks\n\n* Ensure graduated oslo libraries are not used.\n* Ensure we explicitly import the _ method, rather than using the\n  python built in (Grabbed from nova/hacking/checks.py).\n\nChange-Id: I4971892222b97811110dc71085f38a0337e132d1\n'}]",0,113610,8ce3742045a033fe879c4585324465c1dc8a4e14,10,3,1,741,,,0,"Add two more hacking checks

* Ensure graduated oslo libraries are not used.
* Ensure we explicitly import the _ method, rather than using the
  python built in (Grabbed from nova/hacking/checks.py).

Change-Id: I4971892222b97811110dc71085f38a0337e132d1
",git fetch https://review.opendev.org/openstack/designate refs/changes/10/113610/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/hacking/checks.py'],1,8ce3742045a033fe879c4585324465c1dc8a4e14,,"# Copyright (c) 2012, CloudscalingUNDERSCORE_IMPORT_FILES = [] string_translation = re.compile(r""[^_]*_\(\s*('|\"")"")translated_log = re.compile( r""(.)*LOG\.(audit|error|info|warn|warning|critical|exception)"" ""\(\s*_\(\s*('|\"")"") underscore_import_check = re.compile(r""(.)*import _(.)*"") # We need this for cases where they have created their own _ function. custom_underscore_check = re.compile(r""(.)*_\s*=\s*(.)*"") graduated_oslo_libraries_import_re = re.compile( r""^\s*(?:import|from) designate\.openstack\.common\.?.*?"" ""(gettextutils|rpc)"" "".*?"")def check_explicit_underscore_import(logical_line, filename): """"""Check for explicit import of the _ function We need to ensure that any files that are using the _() function to translate logs are explicitly importing the _ function. We can't trust unit test to catch whether the import has been added so we need to check for it here. """""" # Build a list of the files that have _ imported. No further # checking needed once it is found. if filename in UNDERSCORE_IMPORT_FILES: pass elif (underscore_import_check.match(logical_line) or custom_underscore_check.match(logical_line)): UNDERSCORE_IMPORT_FILES.append(filename) elif (translated_log.match(logical_line) or string_translation.match(logical_line)): yield(0, ""D703: Found use of _() without explicit import of _!"") def no_import_graduated_oslo_libraries(logical_line, filename): """"""Check that we don't continue to use o.c. oslo libraries after graduation After a library graduates from oslo-incubator, as we make the switch, we should ensure we don't continue to use the oslo-incubator versions. In many cases, it's not possible to immediatly remove the code from the openstack/common folder due to dependancy issues. """""" # We can't modify oslo-incubator code, so ignore it here. if ""designate/openstack/common"" in filename: return matches = graduated_oslo_libraries_import_re.match(logical_line) if matches: yield(0, ""D704: Found import of %s. This oslo library has been "" ""graduated!"" % matches.group(1)) register(check_explicit_underscore_import) register(no_import_graduated_oslo_libraries)",# # Author: Kiall Mac Innes <kiall@hp.com>,56,3
openstack%2Fhorizon~master~Ia3b6b114f976429e82cfc5664c3172a9302703c9,openstack/horizon,master,Ia3b6b114f976429e82cfc5664c3172a9302703c9,Stop preloading the Volumes tabs,MERGED,2014-08-13 14:47:27.000000000,2014-08-15 11:07:36.000000000,2014-08-15 11:07:35.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}, {'_account_id': 11880}]","[{'number': 1, 'created': '2014-08-13 14:47:27.000000000', 'files': ['openstack_dashboard/dashboards/project/volumes/snapshots/tests.py', 'openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'openstack_dashboard/dashboards/project/volumes/backups/tests.py', 'openstack_dashboard/dashboards/project/volumes/tabs.py', 'openstack_dashboard/dashboards/project/volumes/test.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8eaa1fb8ba29a197efc98cf2ec031af7284f7a32', 'message': ""Stop preloading the Volumes tabs\n\nIt can take quite a long time to make all the API calls. No need to\npreload all the tabs before they're actually needed.\n\nChange-Id: Ia3b6b114f976429e82cfc5664c3172a9302703c9\nCloses-Bug: #1334608\n""}]",0,113913,8eaa1fb8ba29a197efc98cf2ec031af7284f7a32,11,4,1,4978,,,0,"Stop preloading the Volumes tabs

It can take quite a long time to make all the API calls. No need to
preload all the tabs before they're actually needed.

Change-Id: Ia3b6b114f976429e82cfc5664c3172a9302703c9
Closes-Bug: #1334608
",git fetch https://review.opendev.org/openstack/horizon refs/changes/13/113913/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/volumes/snapshots/tests.py', 'openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'openstack_dashboard/dashboards/project/volumes/backups/tests.py', 'openstack_dashboard/dashboards/project/volumes/tabs.py', 'openstack_dashboard/dashboards/project/volumes/test.py']",5,8eaa1fb8ba29a197efc98cf2ec031af7284f7a32,bug/1334608,"VOLUME_SNAPSHOTS_TAB_URL = reverse('horizon:project:volumes:snapshots_tab') VOLUME_BACKUPS_TAB_URL = reverse('horizon:project:volumes:backups_tab') # Explicitly load the other tabs. If this doesn't work the test # will fail due to ""Expected methods never called."" res = self.client.get(VOLUME_SNAPSHOTS_TAB_URL) self.assertEqual(res.status_code, 200) self.assertTemplateUsed(res, 'project/volumes/index.html') if backup_supported: res = self.client.get(VOLUME_BACKUPS_TAB_URL) self.assertTemplateUsed(res, 'project/volumes/index.html') def test_index_backup_supported(self):", def test_index_back_supported(self):,26,66
openstack%2Ffuel-library~stable%2F5.0~I2e3ccb467d03d4c6f84865b76b649f9455442785,openstack/fuel-library,stable/5.0,I2e3ccb467d03d4c6f84865b76b649f9455442785,Set rsync parameters for nailgun rsync server,ABANDONED,2014-08-14 13:43:07.000000000,2014-08-15 11:06:51.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7227}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-14 13:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/38e77c5ff2fc5900b1ebf6ffebda00bcb0003d0b', 'message': 'Set rsync parameters for nailgun rsync server\n\nSet xinetd parameters for nailgun rsyncd server\nas it is configured by separate template\n\nChange-Id: I2e3ccb467d03d4c6f84865b76b649f9455442785\nCloses-bug: #1322577\n'}, {'number': 2, 'created': '2014-08-15 08:09:33.000000000', 'files': ['deployment/puppet/nailgun/templates/rsyncd_xinetd.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ead8cb7fef3a3d0c2a2d524cf823aa67247a314e', 'message': 'Set rsync parameters for nailgun rsync server\n\nSet xinetd parameters for nailgun rsyncd server\nas it is configured by separate template\n\nChange-Id: I2e3ccb467d03d4c6f84865b76b649f9455442785\nCloses-bug: #1322577\n'}]",2,114247,ead8cb7fef3a3d0c2a2d524cf823aa67247a314e,20,9,2,8786,,,0,"Set rsync parameters for nailgun rsync server

Set xinetd parameters for nailgun rsyncd server
as it is configured by separate template

Change-Id: I2e3ccb467d03d4c6f84865b76b649f9455442785
Closes-bug: #1322577
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/47/114247/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/templates/rsyncd_xinetd.erb'],1,38e77c5ff2fc5900b1ebf6ffebda00bcb0003d0b,bug/1322577-5.0, cps = 512 10 flags = IPv4 per_source = UNLIMITED} ,},4,1
openstack%2Fnova~master~I5fb59f82dc2f87bc49809be14489fd14de1ccee4,openstack/nova,master,I5fb59f82dc2f87bc49809be14489fd14de1ccee4,Fix scheduling failure for disk_filter,ABANDONED,2014-08-11 04:00:27.000000000,2014-08-15 10:27:56.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-11 04:00:27.000000000', 'files': ['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/disk_filter.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2081b754cd3ddd9a7b871fb39da2b0f8a678ead6', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add\nthe\nVm's root_db which created by volume\n\nChange-Id: I5fb59f82dc2f87bc49809be14489fd14de1ccee4\nCloses-Bug: #1334974\n""}]",0,113161,2081b754cd3ddd9a7b871fb39da2b0f8a678ead6,11,6,1,11531,,,0,"Fix scheduling failure for disk_filter

Create Vm by volume,the disk_filter should not be check the root_gb size
and compute node report the resource(local_gb_used) should not be add
the
Vm's root_db which created by volume

Change-Id: I5fb59f82dc2f87bc49809be14489fd14de1ccee4
Closes-Bug: #1334974
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/113161/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/disk_filter.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py']",4,2081b754cd3ddd9a7b871fb39da2b0f8a678ead6,bug/1334974,"# Copyright (c) 2012 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Track resources like memory and disk for a compute host. Provides the scheduler with useful information about availability through the ComputeNode model. """""" from oslo.config import cfg from nova.compute import claims from nova.compute import flavors from nova.compute import monitors from nova.compute import resources as ext_resources from nova.compute import task_states from nova.compute import vm_states from nova import conductor from nova import context from nova import exception from nova.i18n import _ from nova import objects from nova.objects import base as obj_base from nova.openstack.common import importutils from nova.openstack.common import jsonutils from nova.openstack.common import log as logging from nova.pci import pci_manager from nova import rpc from nova import utils resource_tracker_opts = [ cfg.IntOpt('reserved_host_disk_mb', default=0, help='Amount of disk in MB to reserve for the host'), cfg.IntOpt('reserved_host_memory_mb', default=512, help='Amount of memory in MB to reserve for the host'), cfg.StrOpt('compute_stats_class', default='nova.compute.stats.Stats', help='Class that will manage stats for the local compute host'), cfg.ListOpt('compute_resources', default=['vcpu'], help='The names of the extra resources to track.'), ] CONF = cfg.CONF CONF.register_opts(resource_tracker_opts) LOG = logging.getLogger(__name__) COMPUTE_RESOURCE_SEMAPHORE = ""compute_resources"" CONF.import_opt('my_ip', 'nova.netconf') class ResourceTracker(object): """"""Compute helper class for keeping track of resource usage as instances are built and destroyed. """""" def __init__(self, host, driver, nodename): self.host = host self.driver = driver self.pci_tracker = None self.nodename = nodename self.compute_node = None self.stats = importutils.import_object(CONF.compute_stats_class) self.tracked_instances = {} self.tracked_migrations = {} self.conductor_api = conductor.API() monitor_handler = monitors.ResourceMonitorHandler() self.monitors = monitor_handler.choose_monitors(self) self.ext_resources_handler = \ ext_resources.ResourceHandler(CONF.compute_resources) self.notifier = rpc.get_notifier() self.old_resources = {} @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def instance_claim(self, context, instance_ref, limits=None): """"""Indicate that some resources are needed for an upcoming compute instance build operation. This should be called before the compute node is about to perform an instance build operation that will consume additional resources. :param context: security context :param instance_ref: instance to reserve resources for :param limits: Dict of oversubscription limits for memory, disk, and CPUs. :returns: A Claim ticket representing the reserved resources. It can be used to revert the resource usage if an error occurs during the instance build. """""" if self.disabled: # compute_driver doesn't support resource tracking, just # set the 'host' and node fields and continue the build: self._set_instance_host_and_node(context, instance_ref) return claims.NopClaim() # sanity checks: if instance_ref['host']: LOG.warning(_(""Host field should not be set on the instance until "" ""resources have been claimed.""), instance=instance_ref) if instance_ref['node']: LOG.warning(_(""Node field should not be set on the instance "" ""until resources have been claimed.""), instance=instance_ref) # get memory overhead required to build this instance: overhead = self.driver.estimate_instance_overhead(instance_ref) LOG.debug(""Memory overhead for %(flavor)d MB instance; %(overhead)d "" ""MB"", {'flavor': instance_ref['memory_mb'], 'overhead': overhead['memory_mb']}) claim = claims.Claim(instance_ref, self, self.compute_node, overhead=overhead, limits=limits) self._set_instance_host_and_node(context, instance_ref) # Mark resources in-use and update stats self._update_usage_from_instance(self.compute_node, instance_ref) elevated = context.elevated() # persist changes to the compute node: self._update(elevated, self.compute_node) return claim @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def resize_claim(self, context, instance, instance_type, limits=None): """"""Indicate that resources are needed for a resize operation to this compute host. :param context: security context :param instance: instance object to reserve resources for :param instance_type: new instance_type being resized to :param limits: Dict of oversubscription limits for memory, disk, and CPUs :returns: A Claim ticket representing the reserved resources. This should be turned into finalize a resource claim or free resources after the compute operation is finished. """""" if self.disabled: # compute_driver doesn't support resource tracking, just # generate the migration record and continue the resize: migration = self._create_migration(context, instance, instance_type) return claims.NopClaim(migration=migration) # get memory overhead required to build this instance: overhead = self.driver.estimate_instance_overhead(instance_type) LOG.debug(""Memory overhead for %(flavor)d MB instance; %(overhead)d "" ""MB"", {'flavor': instance_type['memory_mb'], 'overhead': overhead['memory_mb']}) instance_ref = obj_base.obj_to_primitive(instance) claim = claims.ResizeClaim(instance_ref, instance_type, self, self.compute_node, overhead=overhead, limits=limits) migration = self._create_migration(context, instance_ref, instance_type) claim.migration = migration # Mark the resources in-use for the resize landing on this # compute host: self._update_usage_from_migration(context, instance_ref, self.compute_node, migration) elevated = context.elevated() self._update(elevated, self.compute_node) return claim def _create_migration(self, context, instance, instance_type): """"""Create a migration record for the upcoming resize. This should be done while the COMPUTE_RESOURCES_SEMAPHORE is held so the resource claim will not be lost if the audit process starts. """""" old_instance_type = flavors.extract_flavor(instance) migration = objects.Migration() migration.dest_compute = self.host migration.dest_node = self.nodename migration.dest_host = self.driver.get_host_ip_addr() migration.old_instance_type_id = old_instance_type['id'] migration.new_instance_type_id = instance_type['id'] migration.status = 'pre-migrating' migration.instance_uuid = instance['uuid'] migration.source_compute = instance['host'] migration.source_node = instance['node'] migration.create(context.elevated()) return migration def _set_instance_host_and_node(self, context, instance_ref): """"""Tag the instance as belonging to this host. This should be done while the COMPUTE_RESOURCES_SEMAPHORE is held so the resource claim will not be lost if the audit process starts. """""" values = {'host': self.host, 'node': self.nodename, 'launched_on': self.host} self.conductor_api.instance_update(context, instance_ref['uuid'], **values) instance_ref['host'] = self.host instance_ref['launched_on'] = self.host instance_ref['node'] = self.nodename @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def abort_instance_claim(self, instance): """"""Remove usage from the given instance."""""" # flag the instance as deleted to revert the resource usage # and associated stats: instance['vm_state'] = vm_states.DELETED self._update_usage_from_instance(self.compute_node, instance) ctxt = context.get_admin_context() self._update(ctxt, self.compute_node) @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def drop_resize_claim(self, instance, instance_type=None, prefix='new_'): """"""Remove usage for an incoming/outgoing migration."""""" if instance['uuid'] in self.tracked_migrations: migration, itype = self.tracked_migrations.pop(instance['uuid']) if not instance_type: ctxt = context.get_admin_context() instance_type = self._get_instance_type(ctxt, instance, prefix) if instance_type['id'] == itype['id']: if self.pci_tracker: self.pci_tracker.update_pci_for_migration(instance, sign=-1) self._update_usage(self.compute_node, itype, sign=-1) ctxt = context.get_admin_context() self._update(ctxt, self.compute_node) @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def update_usage(self, context, instance): """"""Update the resource usage and stats after a change in an instance """""" if self.disabled: return uuid = instance['uuid'] # don't update usage for this instance unless it submitted a resource # claim first: if uuid in self.tracked_instances: self._update_usage_from_instance(self.compute_node, instance) self._update(context.elevated(), self.compute_node) @property def disabled(self): return self.compute_node is None def _get_host_metrics(self, context, nodename): """"""Get the metrics from monitors and notify information to message bus. """""" metrics = [] metrics_info = {} for monitor in self.monitors: try: metrics += monitor.get_metrics(nodename=nodename) except Exception: LOG.warn(_(""Cannot get the metrics from %s.""), monitors) if metrics: metrics_info['nodename'] = nodename metrics_info['metrics'] = metrics metrics_info['host'] = self.host metrics_info['host_ip'] = CONF.my_ip notifier = rpc.get_notifier(service='compute', host=nodename) notifier.info(context, 'compute.metrics.update', metrics_info) return metrics @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def update_available_resource(self, context): """"""Override in-memory calculations of compute node resource usage based on data audited from the hypervisor layer. Add in resource claims in progress to account for operations that have declared a need for resources, but not necessarily retrieved them from the hypervisor layer yet. """""" LOG.audit(_(""Auditing locally available compute resources"")) resources = self.driver.get_available_resource(self.nodename) if not resources: # The virt driver does not support this function LOG.audit(_(""Virt driver does not support "" ""'get_available_resource' Compute tracking is disabled."")) self.compute_node = None return resources['host_ip'] = CONF.my_ip self._verify_resources(resources) self._report_hypervisor_resource_view(resources) if 'pci_passthrough_devices' in resources: if not self.pci_tracker: self.pci_tracker = pci_manager.PciDevTracker() self.pci_tracker.set_hvdevs(jsonutils.loads(resources.pop( 'pci_passthrough_devices'))) # Grab all instances assigned to this node: instances = objects.InstanceList.get_by_host_and_node( context, self.host, self.nodename) # Now calculate usage based on instance utilization: self._update_usage_from_instances(resources, instances) # Grab all in-progress migrations: capi = self.conductor_api migrations = capi.migration_get_in_progress_by_host_and_node(context, self.host, self.nodename) self._update_usage_from_migrations(context, resources, migrations) # Detect and account for orphaned instances that may exist on the # hypervisor, but are not in the DB: orphans = self._find_orphaned_instances() self._update_usage_from_orphans(resources, orphans) # NOTE(yjiang5): Because pci device tracker status is not cleared in # this periodic task, and also because the resource tracker is not # notified when instances are deleted, we need remove all usages # from deleted instances. if self.pci_tracker: self.pci_tracker.clean_usage(instances, migrations, orphans) resources['pci_stats'] = jsonutils.dumps(self.pci_tracker.stats) else: resources['pci_stats'] = jsonutils.dumps([]) self._report_final_resource_view(resources) metrics = self._get_host_metrics(context, self.nodename) resources['metrics'] = jsonutils.dumps(metrics) self._sync_compute_node(context, resources) def _sync_compute_node(self, context, resources): """"""Create or update the compute node DB record."""""" if not self.compute_node: # we need a copy of the ComputeNode record: service = self._get_service(context) if not service: # no service record, disable resource return compute_node_refs = service['compute_node'] if compute_node_refs: for cn in compute_node_refs: if cn.get('hypervisor_hostname') == self.nodename: self.compute_node = cn if self.pci_tracker: self.pci_tracker.set_compute_node_id(cn['id']) break if not self.compute_node: # Need to create the ComputeNode record: resources['service_id'] = service['id'] self._create(context, resources) if self.pci_tracker: self.pci_tracker.set_compute_node_id(self.compute_node['id']) LOG.info(_('Compute_service record created for %(host)s:%(node)s') % {'host': self.host, 'node': self.nodename}) else: # just update the record: self._update(context, resources) LOG.info(_('Compute_service record updated for %(host)s:%(node)s') % {'host': self.host, 'node': self.nodename}) def _write_ext_resources(self, resources): resources['stats'] = {} resources['stats'].update(self.stats) self.ext_resources_handler.write_resources(resources) def _create(self, context, values): """"""Create the compute node in the DB."""""" # initialize load stats from existing instances: self._write_ext_resources(values) # NOTE(pmurray): the stats field is stored as a json string. The # json conversion will be done automatically by the ComputeNode object # so this can be removed when using ComputeNode. values['stats'] = jsonutils.dumps(values['stats']) self.compute_node = self.conductor_api.compute_node_create(context, values) def _get_service(self, context): try: return self.conductor_api.service_get_by_compute_host(context, self.host) except exception.NotFound: LOG.warn(_(""No service record for host %s""), self.host) def _report_hypervisor_resource_view(self, resources): """"""Log the hypervisor's view of free resources. This is just a snapshot of resource usage recorded by the virt driver. The following resources are logged: - free memory - free disk - free CPUs - assignable PCI devices """""" free_ram_mb = resources['memory_mb'] - resources['memory_mb_used'] free_disk_gb = resources['local_gb'] - resources['local_gb_used'] LOG.debug(""Hypervisor: free ram (MB): %s"" % free_ram_mb) LOG.debug(""Hypervisor: free disk (GB): %s"" % free_disk_gb) vcpus = resources['vcpus'] if vcpus: free_vcpus = vcpus - resources['vcpus_used'] LOG.debug(""Hypervisor: free VCPUs: %s"" % free_vcpus) else: LOG.debug(""Hypervisor: VCPU information unavailable"") if 'pci_passthrough_devices' in resources and \ resources['pci_passthrough_devices']: LOG.debug(""Hypervisor: assignable PCI devices: %s"" % resources['pci_passthrough_devices']) else: LOG.debug(""Hypervisor: no assignable PCI devices"") def _report_final_resource_view(self, resources): """"""Report final calculate of physical memory, used virtual memory, disk, usable vCPUs, used virtual CPUs and PCI devices, including instance calculations and in-progress resource claims. These values will be exposed via the compute node table to the scheduler. """""" LOG.audit(_(""Total physical ram (MB): %(pram)s, "" ""total allocated virtual ram (MB): %(vram)s""), {'pram': resources['memory_mb'], 'vram': resources['memory_mb_used']}) LOG.audit(_(""Free disk (GB): %s"") % resources['free_disk_gb']) vcpus = resources['vcpus'] if vcpus: LOG.audit(_(""Total usable vcpus: %(tcpu)s, "" ""total allocated vcpus: %(ucpu)s""), {'tcpu': vcpus, 'ucpu': resources['vcpus_used']}) else: LOG.audit(_(""Free VCPU information unavailable"")) if 'pci_stats' in resources: LOG.audit(_(""PCI stats: %s""), resources['pci_stats']) def _resource_change(self, resources): """"""Check to see if any resouces have changed."""""" if cmp(resources, self.old_resources) != 0: self.old_resources = resources return True return False def _update(self, context, values): """"""Persist the compute node updates to the DB."""""" self._write_ext_resources(values) # NOTE(pmurray): the stats field is stored as a json string. The # json conversion will be done automatically by the ComputeNode object # so this can be removed when using ComputeNode. values['stats'] = jsonutils.dumps(values['stats']) if not self._resource_change(values): return if ""service"" in self.compute_node: del self.compute_node['service'] self.compute_node = self.conductor_api.compute_node_update( context, self.compute_node, values) if self.pci_tracker: self.pci_tracker.save(context) def _update_usage(self, resources, usage, sign=1): mem_usage = usage['memory_mb'] overhead = self.driver.estimate_instance_overhead(usage) mem_usage += overhead['memory_mb'] resources['memory_mb_used'] += sign * mem_usage resources['local_gb_used'] += sign * usage.get('root_gb', 0) resources['local_gb_used'] += sign * usage.get('ephemeral_gb', 0) # free ram and disk may be negative, depending on policy: resources['free_ram_mb'] = (resources['memory_mb'] - resources['memory_mb_used']) resources['free_disk_gb'] = (resources['local_gb'] - resources['local_gb_used']) resources['running_vms'] = self.stats.num_instances self.ext_resources_handler.update_from_instance(usage, sign) def _update_usage_from_migration(self, context, instance, resources, migration): """"""Update usage for a single migration. The record may represent an incoming or outbound migration. """""" uuid = migration['instance_uuid'] LOG.audit(_(""Updating from migration %s"") % uuid) incoming = (migration['dest_compute'] == self.host and migration['dest_node'] == self.nodename) outbound = (migration['source_compute'] == self.host and migration['source_node'] == self.nodename) same_node = (incoming and outbound) record = self.tracked_instances.get(uuid, None) itype = None if same_node: # same node resize. record usage for whichever instance type the # instance is *not* in: if (instance['instance_type_id'] == migration['old_instance_type_id']): itype = self._get_instance_type(context, instance, 'new_', migration['new_instance_type_id']) else: # instance record already has new flavor, hold space for a # possible revert to the old instance type: itype = self._get_instance_type(context, instance, 'old_', migration['old_instance_type_id']) elif incoming and not record: # instance has not yet migrated here: itype = self._get_instance_type(context, instance, 'new_', migration['new_instance_type_id']) elif outbound and not record: # instance migrated, but record usage for a possible revert: itype = self._get_instance_type(context, instance, 'old_', migration['old_instance_type_id']) if itype: if self.pci_tracker: self.pci_tracker.update_pci_for_migration(instance) self._update_usage(resources, itype) if self.pci_tracker: resources['pci_stats'] = jsonutils.dumps( self.pci_tracker.stats) else: resources['pci_stats'] = jsonutils.dumps([]) self.tracked_migrations[uuid] = (migration, itype) def _update_usage_from_migrations(self, context, resources, migrations): self.tracked_migrations.clear() filtered = {} # do some defensive filtering against bad migrations records in the # database: for migration in migrations: instance = migration['instance'] if not instance: # migration referencing deleted instance continue uuid = instance['uuid'] # skip migration if instance isn't in a resize state: if not self._instance_in_resize_state(instance): LOG.warn(_(""Instance not resizing, skipping migration.""), instance_uuid=uuid) continue # filter to most recently updated migration for each instance: m = filtered.get(uuid, None) if not m or migration['updated_at'] >= m['updated_at']: filtered[uuid] = migration for migration in filtered.values(): instance = migration['instance'] try: self._update_usage_from_migration(context, instance, resources, migration) except exception.FlavorNotFound: LOG.warn(_(""Flavor could not be found, skipping "" ""migration.""), instance_uuid=uuid) continue def _update_usage_from_instance(self, resources, instance): """"""Update usage for a single instance."""""" uuid = instance['uuid'] is_new_instance = uuid not in self.tracked_instances is_deleted_instance = instance['vm_state'] == vm_states.DELETED if is_new_instance: self.tracked_instances[uuid] = obj_base.obj_to_primitive(instance) sign = 1 if is_deleted_instance: self.tracked_instances.pop(uuid) sign = -1 self.stats.update_stats_for_instance(instance) if self.pci_tracker: self.pci_tracker.update_pci_for_instance(instance) # if it's a new or deleted instance: if is_new_instance or is_deleted_instance: # new instance, update compute node resource usage: self._update_usage(resources, instance, sign=sign) resources['current_workload'] = self.stats.calculate_workload() if self.pci_tracker: resources['pci_stats'] = jsonutils.dumps(self.pci_tracker.stats) else: resources['pci_stats'] = jsonutils.dumps([]) def _update_usage_from_instances(self, resources, instances): """"""Calculate resource usage based on instance utilization. This is different than the hypervisor's view as it will account for all instances assigned to the local compute host, even if they are not currently powered on. """""" self.tracked_instances.clear() # purge old stats and init with anything passed in by the driver self.stats.clear() self.stats.digest_stats(resources.get('stats')) # set some initial values, reserve room for host/hypervisor: resources['local_gb_used'] = CONF.reserved_host_disk_mb / 1024 resources['memory_mb_used'] = CONF.reserved_host_memory_mb resources['free_ram_mb'] = (resources['memory_mb'] - resources['memory_mb_used']) resources['free_disk_gb'] = (resources['local_gb'] - resources['local_gb_used']) resources['current_workload'] = 0 resources['running_vms'] = 0 # Reset values for extended resources self.ext_resources_handler.reset_resources(resources, self.driver) for instance in instances: if instance['vm_state'] != vm_states.DELETED: self._update_usage_from_instance(resources, instance) def _find_orphaned_instances(self): """"""Given the set of instances and migrations already account for by resource tracker, sanity check the hypervisor to determine if there are any ""orphaned"" instances left hanging around. Orphans could be consuming memory and should be accounted for in usage calculations to guard against potential out of memory errors. """""" uuids1 = frozenset(self.tracked_instances.keys()) uuids2 = frozenset(self.tracked_migrations.keys()) uuids = uuids1 | uuids2 usage = self.driver.get_per_instance_usage() vuuids = frozenset(usage.keys()) orphan_uuids = vuuids - uuids orphans = [usage[uuid] for uuid in orphan_uuids] return orphans def _update_usage_from_orphans(self, resources, orphans): """"""Include orphaned instances in usage."""""" for orphan in orphans: memory_mb = orphan['memory_mb'] LOG.warn(_(""Detected running orphan instance: %(uuid)s (consuming "" ""%(memory_mb)s MB memory)""), {'uuid': orphan['uuid'], 'memory_mb': memory_mb}) # just record memory usage for the orphan usage = {'memory_mb': memory_mb} self._update_usage(resources, usage) def _verify_resources(self, resources): resource_keys = [""vcpus"", ""memory_mb"", ""local_gb"", ""cpu_info"", ""vcpus_used"", ""memory_mb_used"", ""local_gb_used""] missing_keys = [k for k in resource_keys if k not in resources] if missing_keys: reason = _(""Missing keys: %s"") % missing_keys raise exception.InvalidInput(reason=reason) def _instance_in_resize_state(self, instance): vm = instance['vm_state'] task = instance['task_state'] if vm == vm_states.RESIZED: return True if (vm in [vm_states.ACTIVE, vm_states.STOPPED] and task in [task_states.RESIZE_PREP, task_states.RESIZE_MIGRATING, task_states.RESIZE_MIGRATED, task_states.RESIZE_FINISH]): return True return False def _get_instance_type(self, context, instance, prefix, instance_type_id=None): """"""Get the instance type from sys metadata if it's stashed. If not, fall back to fetching it via the object API. See bug 1164110 """""" try: return flavors.extract_flavor(instance, prefix) except KeyError: if not instance_type_id: instance_type_id = instance['instance_type_id'] return objects.Flavor.get_by_id(context, instance_type_id) ","# Copyright (c) 2012 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Track resources like memory and disk for a compute host. Provides the scheduler with useful information about availability through the ComputeNode model. """""" from oslo.config import cfg from nova.compute import claims from nova.compute import flavors from nova.compute import monitors from nova.compute import resources as ext_resources from nova.compute import task_states from nova.compute import vm_states from nova import conductor from nova import context from nova import exception from nova.i18n import _ from nova import objects from nova.objects import base as obj_base from nova.openstack.common import importutils from nova.openstack.common import jsonutils from nova.openstack.common import log as logging from nova.pci import pci_manager from nova import rpc from nova import utils resource_tracker_opts = [ cfg.IntOpt('reserved_host_disk_mb', default=0, help='Amount of disk in MB to reserve for the host'), cfg.IntOpt('reserved_host_memory_mb', default=512, help='Amount of memory in MB to reserve for the host'), cfg.StrOpt('compute_stats_class', default='nova.compute.stats.Stats', help='Class that will manage stats for the local compute host'), cfg.ListOpt('compute_resources', default=['vcpu'], help='The names of the extra resources to track.'), ] CONF = cfg.CONF CONF.register_opts(resource_tracker_opts) LOG = logging.getLogger(__name__) COMPUTE_RESOURCE_SEMAPHORE = ""compute_resources"" CONF.import_opt('my_ip', 'nova.netconf') class ResourceTracker(object): """"""Compute helper class for keeping track of resource usage as instances are built and destroyed. """""" def __init__(self, host, driver, nodename): self.host = host self.driver = driver self.pci_tracker = None self.nodename = nodename self.compute_node = None self.stats = importutils.import_object(CONF.compute_stats_class) self.tracked_instances = {} self.tracked_migrations = {} self.conductor_api = conductor.API() monitor_handler = monitors.ResourceMonitorHandler() self.monitors = monitor_handler.choose_monitors(self) self.ext_resources_handler = \ ext_resources.ResourceHandler(CONF.compute_resources) self.notifier = rpc.get_notifier() self.old_resources = {} @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def instance_claim(self, context, instance_ref, limits=None): """"""Indicate that some resources are needed for an upcoming compute instance build operation. This should be called before the compute node is about to perform an instance build operation that will consume additional resources. :param context: security context :param instance_ref: instance to reserve resources for :param limits: Dict of oversubscription limits for memory, disk, and CPUs. :returns: A Claim ticket representing the reserved resources. It can be used to revert the resource usage if an error occurs during the instance build. """""" if self.disabled: # compute_driver doesn't support resource tracking, just # set the 'host' and node fields and continue the build: self._set_instance_host_and_node(context, instance_ref) return claims.NopClaim() # sanity checks: if instance_ref['host']: LOG.warning(_(""Host field should not be set on the instance until "" ""resources have been claimed.""), instance=instance_ref) if instance_ref['node']: LOG.warning(_(""Node field should not be set on the instance "" ""until resources have been claimed.""), instance=instance_ref) # get memory overhead required to build this instance: overhead = self.driver.estimate_instance_overhead(instance_ref) LOG.debug(""Memory overhead for %(flavor)d MB instance; %(overhead)d "" ""MB"", {'flavor': instance_ref['memory_mb'], 'overhead': overhead['memory_mb']}) claim = claims.Claim(instance_ref, self, self.compute_node, overhead=overhead, limits=limits) self._set_instance_host_and_node(context, instance_ref) # Mark resources in-use and update stats self._update_usage_from_instance(self.compute_node, instance_ref) elevated = context.elevated() # persist changes to the compute node: self._update(elevated, self.compute_node) return claim @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def resize_claim(self, context, instance, instance_type, limits=None): """"""Indicate that resources are needed for a resize operation to this compute host. :param context: security context :param instance: instance object to reserve resources for :param instance_type: new instance_type being resized to :param limits: Dict of oversubscription limits for memory, disk, and CPUs :returns: A Claim ticket representing the reserved resources. This should be turned into finalize a resource claim or free resources after the compute operation is finished. """""" if self.disabled: # compute_driver doesn't support resource tracking, just # generate the migration record and continue the resize: migration = self._create_migration(context, instance, instance_type) return claims.NopClaim(migration=migration) # get memory overhead required to build this instance: overhead = self.driver.estimate_instance_overhead(instance_type) LOG.debug(""Memory overhead for %(flavor)d MB instance; %(overhead)d "" ""MB"", {'flavor': instance_type['memory_mb'], 'overhead': overhead['memory_mb']}) instance_ref = obj_base.obj_to_primitive(instance) claim = claims.ResizeClaim(instance_ref, instance_type, self, self.compute_node, overhead=overhead, limits=limits) migration = self._create_migration(context, instance_ref, instance_type) claim.migration = migration # Mark the resources in-use for the resize landing on this # compute host: self._update_usage_from_migration(context, instance_ref, self.compute_node, migration) elevated = context.elevated() self._update(elevated, self.compute_node) return claim def _create_migration(self, context, instance, instance_type): """"""Create a migration record for the upcoming resize. This should be done while the COMPUTE_RESOURCES_SEMAPHORE is held so the resource claim will not be lost if the audit process starts. """""" old_instance_type = flavors.extract_flavor(instance) migration = objects.Migration() migration.dest_compute = self.host migration.dest_node = self.nodename migration.dest_host = self.driver.get_host_ip_addr() migration.old_instance_type_id = old_instance_type['id'] migration.new_instance_type_id = instance_type['id'] migration.status = 'pre-migrating' migration.instance_uuid = instance['uuid'] migration.source_compute = instance['host'] migration.source_node = instance['node'] migration.create(context.elevated()) return migration def _set_instance_host_and_node(self, context, instance_ref): """"""Tag the instance as belonging to this host. This should be done while the COMPUTE_RESOURCES_SEMAPHORE is held so the resource claim will not be lost if the audit process starts. """""" values = {'host': self.host, 'node': self.nodename, 'launched_on': self.host} self.conductor_api.instance_update(context, instance_ref['uuid'], **values) instance_ref['host'] = self.host instance_ref['launched_on'] = self.host instance_ref['node'] = self.nodename @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def abort_instance_claim(self, instance): """"""Remove usage from the given instance."""""" # flag the instance as deleted to revert the resource usage # and associated stats: instance['vm_state'] = vm_states.DELETED self._update_usage_from_instance(self.compute_node, instance) ctxt = context.get_admin_context() self._update(ctxt, self.compute_node) @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def drop_resize_claim(self, instance, instance_type=None, prefix='new_'): """"""Remove usage for an incoming/outgoing migration."""""" if instance['uuid'] in self.tracked_migrations: migration, itype = self.tracked_migrations.pop(instance['uuid']) if not instance_type: ctxt = context.get_admin_context() instance_type = self._get_instance_type(ctxt, instance, prefix) if instance_type['id'] == itype['id']: if self.pci_tracker: self.pci_tracker.update_pci_for_migration(instance, sign=-1) self._update_usage(self.compute_node, itype, sign=-1) ctxt = context.get_admin_context() self._update(ctxt, self.compute_node) @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def update_usage(self, context, instance): """"""Update the resource usage and stats after a change in an instance """""" if self.disabled: return uuid = instance['uuid'] # don't update usage for this instance unless it submitted a resource # claim first: if uuid in self.tracked_instances: self._update_usage_from_instance(self.compute_node, instance) self._update(context.elevated(), self.compute_node) @property def disabled(self): return self.compute_node is None def _get_host_metrics(self, context, nodename): """"""Get the metrics from monitors and notify information to message bus. """""" metrics = [] metrics_info = {} for monitor in self.monitors: try: metrics += monitor.get_metrics(nodename=nodename) except Exception: LOG.warn(_(""Cannot get the metrics from %s.""), monitors) if metrics: metrics_info['nodename'] = nodename metrics_info['metrics'] = metrics metrics_info['host'] = self.host metrics_info['host_ip'] = CONF.my_ip notifier = rpc.get_notifier(service='compute', host=nodename) notifier.info(context, 'compute.metrics.update', metrics_info) return metrics @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE) def update_available_resource(self, context): """"""Override in-memory calculations of compute node resource usage based on data audited from the hypervisor layer. Add in resource claims in progress to account for operations that have declared a need for resources, but not necessarily retrieved them from the hypervisor layer yet. """""" LOG.audit(_(""Auditing locally available compute resources"")) resources = self.driver.get_available_resource(self.nodename) if not resources: # The virt driver does not support this function LOG.audit(_(""Virt driver does not support "" ""'get_available_resource' Compute tracking is disabled."")) self.compute_node = None return resources['host_ip'] = CONF.my_ip self._verify_resources(resources) self._report_hypervisor_resource_view(resources) if 'pci_passthrough_devices' in resources: if not self.pci_tracker: self.pci_tracker = pci_manager.PciDevTracker() self.pci_tracker.set_hvdevs(jsonutils.loads(resources.pop( 'pci_passthrough_devices'))) # Grab all instances assigned to this node: instances = objects.InstanceList.get_by_host_and_node( context, self.host, self.nodename) # Now calculate usage based on instance utilization: self._update_usage_from_instances(resources, instances) # Grab all in-progress migrations: capi = self.conductor_api migrations = capi.migration_get_in_progress_by_host_and_node(context, self.host, self.nodename) self._update_usage_from_migrations(context, resources, migrations) # Detect and account for orphaned instances that may exist on the # hypervisor, but are not in the DB: orphans = self._find_orphaned_instances() self._update_usage_from_orphans(resources, orphans) # NOTE(yjiang5): Because pci device tracker status is not cleared in # this periodic task, and also because the resource tracker is not # notified when instances are deleted, we need remove all usages # from deleted instances. if self.pci_tracker: self.pci_tracker.clean_usage(instances, migrations, orphans) resources['pci_stats'] = jsonutils.dumps(self.pci_tracker.stats) else: resources['pci_stats'] = jsonutils.dumps([]) self._report_final_resource_view(resources) metrics = self._get_host_metrics(context, self.nodename) resources['metrics'] = jsonutils.dumps(metrics) self._sync_compute_node(context, resources) def _sync_compute_node(self, context, resources): """"""Create or update the compute node DB record."""""" if not self.compute_node: # we need a copy of the ComputeNode record: service = self._get_service(context) if not service: # no service record, disable resource return compute_node_refs = service['compute_node'] if compute_node_refs: for cn in compute_node_refs: if cn.get('hypervisor_hostname') == self.nodename: self.compute_node = cn if self.pci_tracker: self.pci_tracker.set_compute_node_id(cn['id']) break if not self.compute_node: # Need to create the ComputeNode record: resources['service_id'] = service['id'] self._create(context, resources) if self.pci_tracker: self.pci_tracker.set_compute_node_id(self.compute_node['id']) LOG.info(_('Compute_service record created for %(host)s:%(node)s') % {'host': self.host, 'node': self.nodename}) else: # just update the record: self._update(context, resources) LOG.info(_('Compute_service record updated for %(host)s:%(node)s') % {'host': self.host, 'node': self.nodename}) def _write_ext_resources(self, resources): resources['stats'] = {} resources['stats'].update(self.stats) self.ext_resources_handler.write_resources(resources) def _create(self, context, values): """"""Create the compute node in the DB."""""" # initialize load stats from existing instances: self._write_ext_resources(values) # NOTE(pmurray): the stats field is stored as a json string. The # json conversion will be done automatically by the ComputeNode object # so this can be removed when using ComputeNode. values['stats'] = jsonutils.dumps(values['stats']) self.compute_node = self.conductor_api.compute_node_create(context, values) def _get_service(self, context): try: return self.conductor_api.service_get_by_compute_host(context, self.host) except exception.NotFound: LOG.warn(_(""No service record for host %s""), self.host) def _report_hypervisor_resource_view(self, resources): """"""Log the hypervisor's view of free resources. This is just a snapshot of resource usage recorded by the virt driver. The following resources are logged: - free memory - free disk - free CPUs - assignable PCI devices """""" free_ram_mb = resources['memory_mb'] - resources['memory_mb_used'] free_disk_gb = resources['local_gb'] - resources['local_gb_used'] LOG.debug(""Hypervisor: free ram (MB): %s"" % free_ram_mb) LOG.debug(""Hypervisor: free disk (GB): %s"" % free_disk_gb) vcpus = resources['vcpus'] if vcpus: free_vcpus = vcpus - resources['vcpus_used'] LOG.debug(""Hypervisor: free VCPUs: %s"" % free_vcpus) else: LOG.debug(""Hypervisor: VCPU information unavailable"") if 'pci_passthrough_devices' in resources and \ resources['pci_passthrough_devices']: LOG.debug(""Hypervisor: assignable PCI devices: %s"" % resources['pci_passthrough_devices']) else: LOG.debug(""Hypervisor: no assignable PCI devices"") def _report_final_resource_view(self, resources): """"""Report final calculate of physical memory, used virtual memory, disk, usable vCPUs, used virtual CPUs and PCI devices, including instance calculations and in-progress resource claims. These values will be exposed via the compute node table to the scheduler. """""" LOG.audit(_(""Total physical ram (MB): %(pram)s, "" ""total allocated virtual ram (MB): %(vram)s""), {'pram': resources['memory_mb'], 'vram': resources['memory_mb_used']}) LOG.audit(_(""Free disk (GB): %s"") % resources['free_disk_gb']) vcpus = resources['vcpus'] if vcpus: LOG.audit(_(""Total usable vcpus: %(tcpu)s, "" ""total allocated vcpus: %(ucpu)s""), {'tcpu': vcpus, 'ucpu': resources['vcpus_used']}) else: LOG.audit(_(""Free VCPU information unavailable"")) if 'pci_stats' in resources: LOG.audit(_(""PCI stats: %s""), resources['pci_stats']) def _resource_change(self, resources): """"""Check to see if any resouces have changed."""""" if cmp(resources, self.old_resources) != 0: self.old_resources = resources return True return False def _update(self, context, values): """"""Persist the compute node updates to the DB."""""" self._write_ext_resources(values) # NOTE(pmurray): the stats field is stored as a json string. The # json conversion will be done automatically by the ComputeNode object # so this can be removed when using ComputeNode. values['stats'] = jsonutils.dumps(values['stats']) if not self._resource_change(values): return if ""service"" in self.compute_node: del self.compute_node['service'] self.compute_node = self.conductor_api.compute_node_update( context, self.compute_node, values) if self.pci_tracker: self.pci_tracker.save(context) def _update_usage(self, resources, usage, sign=1): mem_usage = usage['memory_mb'] overhead = self.driver.estimate_instance_overhead(usage) mem_usage += overhead['memory_mb'] resources['memory_mb_used'] += sign * mem_usage resources['local_gb_used'] += sign * usage.get('root_gb', 0) resources['local_gb_used'] += sign * usage.get('ephemeral_gb', 0) # free ram and disk may be negative, depending on policy: resources['free_ram_mb'] = (resources['memory_mb'] - resources['memory_mb_used']) resources['free_disk_gb'] = (resources['local_gb'] - resources['local_gb_used']) resources['running_vms'] = self.stats.num_instances self.ext_resources_handler.update_from_instance(usage, sign) def _update_usage_from_migration(self, context, instance, resources, migration): """"""Update usage for a single migration. The record may represent an incoming or outbound migration. """""" uuid = migration['instance_uuid'] LOG.audit(_(""Updating from migration %s"") % uuid) incoming = (migration['dest_compute'] == self.host and migration['dest_node'] == self.nodename) outbound = (migration['source_compute'] == self.host and migration['source_node'] == self.nodename) same_node = (incoming and outbound) record = self.tracked_instances.get(uuid, None) itype = None if same_node: # same node resize. record usage for whichever instance type the # instance is *not* in: if (instance['instance_type_id'] == migration['old_instance_type_id']): itype = self._get_instance_type(context, instance, 'new_', migration['new_instance_type_id']) else: # instance record already has new flavor, hold space for a # possible revert to the old instance type: itype = self._get_instance_type(context, instance, 'old_', migration['old_instance_type_id']) elif incoming and not record: # instance has not yet migrated here: itype = self._get_instance_type(context, instance, 'new_', migration['new_instance_type_id']) elif outbound and not record: # instance migrated, but record usage for a possible revert: itype = self._get_instance_type(context, instance, 'old_', migration['old_instance_type_id']) if itype: if self.pci_tracker: self.pci_tracker.update_pci_for_migration(instance) self._update_usage(resources, itype) if self.pci_tracker: resources['pci_stats'] = jsonutils.dumps( self.pci_tracker.stats) else: resources['pci_stats'] = jsonutils.dumps([]) self.tracked_migrations[uuid] = (migration, itype) def _update_usage_from_migrations(self, context, resources, migrations): self.tracked_migrations.clear() filtered = {} # do some defensive filtering against bad migrations records in the # database: for migration in migrations: instance = migration['instance'] if not instance: # migration referencing deleted instance continue uuid = instance['uuid'] # skip migration if instance isn't in a resize state: if not self._instance_in_resize_state(instance): LOG.warn(_(""Instance not resizing, skipping migration.""), instance_uuid=uuid) continue # filter to most recently updated migration for each instance: m = filtered.get(uuid, None) if not m or migration['updated_at'] >= m['updated_at']: filtered[uuid] = migration for migration in filtered.values(): instance = migration['instance'] try: self._update_usage_from_migration(context, instance, resources, migration) except exception.FlavorNotFound: LOG.warn(_(""Flavor could not be found, skipping "" ""migration.""), instance_uuid=uuid) continue def _update_usage_from_instance(self, resources, instance): """"""Update usage for a single instance."""""" uuid = instance['uuid'] is_new_instance = uuid not in self.tracked_instances is_deleted_instance = instance['vm_state'] == vm_states.DELETED if is_new_instance: self.tracked_instances[uuid] = obj_base.obj_to_primitive(instance) sign = 1 if is_deleted_instance: self.tracked_instances.pop(uuid) sign = -1 self.stats.update_stats_for_instance(instance) if self.pci_tracker: self.pci_tracker.update_pci_for_instance(instance) # if it's a new or deleted instance: if is_new_instance or is_deleted_instance: # new instance, update compute node resource usage: self._update_usage(resources, instance, sign=sign) resources['current_workload'] = self.stats.calculate_workload() if self.pci_tracker: resources['pci_stats'] = jsonutils.dumps(self.pci_tracker.stats) else: resources['pci_stats'] = jsonutils.dumps([]) def _update_usage_from_instances(self, resources, instances): """"""Calculate resource usage based on instance utilization. This is different than the hypervisor's view as it will account for all instances assigned to the local compute host, even if they are not currently powered on. """""" self.tracked_instances.clear() # purge old stats and init with anything passed in by the driver self.stats.clear() self.stats.digest_stats(resources.get('stats')) # set some initial values, reserve room for host/hypervisor: resources['local_gb_used'] = CONF.reserved_host_disk_mb / 1024 resources['memory_mb_used'] = CONF.reserved_host_memory_mb resources['free_ram_mb'] = (resources['memory_mb'] - resources['memory_mb_used']) resources['free_disk_gb'] = (resources['local_gb'] - resources['local_gb_used']) resources['current_workload'] = 0 resources['running_vms'] = 0 # Reset values for extended resources self.ext_resources_handler.reset_resources(resources, self.driver) for instance in instances: if instance['vm_state'] != vm_states.DELETED: self._update_usage_from_instance(resources, instance) def _find_orphaned_instances(self): """"""Given the set of instances and migrations already account for by resource tracker, sanity check the hypervisor to determine if there are any ""orphaned"" instances left hanging around. Orphans could be consuming memory and should be accounted for in usage calculations to guard against potential out of memory errors. """""" uuids1 = frozenset(self.tracked_instances.keys()) uuids2 = frozenset(self.tracked_migrations.keys()) uuids = uuids1 | uuids2 usage = self.driver.get_per_instance_usage() vuuids = frozenset(usage.keys()) orphan_uuids = vuuids - uuids orphans = [usage[uuid] for uuid in orphan_uuids] return orphans def _update_usage_from_orphans(self, resources, orphans): """"""Include orphaned instances in usage."""""" for orphan in orphans: memory_mb = orphan['memory_mb'] LOG.warn(_(""Detected running orphan instance: %(uuid)s (consuming "" ""%(memory_mb)s MB memory)""), {'uuid': orphan['uuid'], 'memory_mb': memory_mb}) # just record memory usage for the orphan usage = {'memory_mb': memory_mb} self._update_usage(resources, usage) def _verify_resources(self, resources): resource_keys = [""vcpus"", ""memory_mb"", ""local_gb"", ""cpu_info"", ""vcpus_used"", ""memory_mb_used"", ""local_gb_used""] missing_keys = [k for k in resource_keys if k not in resources] if missing_keys: reason = _(""Missing keys: %s"") % missing_keys raise exception.InvalidInput(reason=reason) def _instance_in_resize_state(self, instance): vm = instance['vm_state'] task = instance['task_state'] if vm == vm_states.RESIZED: return True if (vm in [vm_states.ACTIVE, vm_states.STOPPED] and task in [task_states.RESIZE_PREP, task_states.RESIZE_MIGRATING, task_states.RESIZE_MIGRATED, task_states.RESIZE_FINISH]): return True return False def _get_instance_type(self, context, instance, prefix, instance_type_id=None): """"""Get the instance type from sys metadata if it's stashed. If not, fall back to fetching it via the object API. See bug 1164110 """""" try: return flavors.extract_flavor(instance, prefix) except KeyError: if not instance_type_id: instance_type_id = instance['instance_type_id'] return objects.Flavor.get_by_id(context, instance_type_id)",3976,3976
openstack%2Ffuel-astute~master~Ieefc843ccba0cdb0441679c73d2e39d6729a4fb0,openstack/fuel-astute,master,Ieefc843ccba0cdb0441679c73d2e39d6729a4fb0,Add splay sleep before reboot nodes,MERGED,2014-08-13 15:47:27.000000000,2014-08-15 10:14:44.000000000,2014-08-15 10:14:43.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 9705}]","[{'number': 1, 'created': '2014-08-13 15:47:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/82145c2b7675cd3301b63fd308bb975e1f12c0b9', 'message': 'Add splay sleep before reboot nodes\n\nResolves concurrency issue when deploying\nlarge clusters. Uses formula of nodes /\nIOPS * 360 to determine how large the\nsplay size should be.\n\nChange-Id: Ieefc843ccba0cdb0441679c73d2e39d6729a4fb0\nCloses-Bug: #1355347\n'}, {'number': 2, 'created': '2014-08-13 15:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/24ca2a858e435c53a8d48e1a70b391249d756c20', 'message': 'Add splay sleep before reboot nodes\n\nResolves concurrency issue when deploying\nlarge clusters. Uses formula of nodes /\nIOPS * 360 to determine how large the\nsplay size should be.\n\ndepends on:\n\nhttps://review.openstack.org/#/c/113924/\nhttps://review.openstack.org/#/c/113920/\nChange-Id: Ieefc843ccba0cdb0441679c73d2e39d6729a4fb0\nCloses-Bug: #1355347'}, {'number': 3, 'created': '2014-08-14 12:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/2059df6a82e48438c1df47566e83a50c5fc32e02', 'message': 'Add splay sleep before reboot nodes\n\nResolves concurrency issue when deploying\nlarge clusters. Uses formula of nodes /\nIOPS * 180 to determine how large the\nsplay size should be.\n\ndepends on:\n\nhttps://review.openstack.org/#/c/113924/\nhttps://review.openstack.org/#/c/113920/\nChange-Id: Ieefc843ccba0cdb0441679c73d2e39d6729a4fb0\nCloses-Bug: #1355347\n'}, {'number': 4, 'created': '2014-08-14 13:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/45fb4e392196ecf6d29e9a475a132819d1caf526', 'message': 'Add splay sleep before reboot nodes\n\nBug:\n Resolves concurrency issue when deploying\n large clusters. Uses formula of nodes /\n IOPS * 180 to determine how large the\n splay size should be.\n\nRefactoring:\n- speed up tests\n\nCo-Authored-By: Matthew Mosesohn <mmosesohn@mirantis.com>\n\nDepends on:\n- https://review.openstack.org/#/c/113924/\n- https://review.openstack.org/#/c/113920/\n\nChange-Id: Ieefc843ccba0cdb0441679c73d2e39d6729a4fb0\nCloses-Bug: #1355347\n'}, {'number': 5, 'created': '2014-08-14 13:12:34.000000000', 'files': ['lib/astute/config.rb', 'spec/unit/cobbler_manager_spec.rb', 'lib/astute/cobbler_manager.rb', 'spec/unit/orchestrator_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/35c4403067c550cfbd556afcdde251d732d7ed4f', 'message': 'Add splay sleep before reboot nodes\n\nBug:\n Resolves concurrency issue when deploying\n large clusters. Uses formula of nodes /\n IOPS * 180 to determine how large the\n splay size should be.\n\nRefactoring:\n- speed up tests\n\nCo-Authored-By: Matthew Mosesohn <mmosesohn@mirantis.com>\n\nDepends on:\n- https://review.openstack.org/#/c/113924/\n- https://review.openstack.org/#/c/113920/\n\nChange-Id: Ieefc843ccba0cdb0441679c73d2e39d6729a4fb0\nCloses-Bug: #1355347\n'}]",6,113942,35c4403067c550cfbd556afcdde251d732d7ed4f,34,9,5,7195,,,0,"Add splay sleep before reboot nodes

Bug:
 Resolves concurrency issue when deploying
 large clusters. Uses formula of nodes /
 IOPS * 180 to determine how large the
 splay size should be.

Refactoring:
- speed up tests

Co-Authored-By: Matthew Mosesohn <mmosesohn@mirantis.com>

Depends on:
- https://review.openstack.org/#/c/113924/
- https://review.openstack.org/#/c/113920/

Change-Id: Ieefc843ccba0cdb0441679c73d2e39d6729a4fb0
Closes-Bug: #1355347
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/42/113942/4 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/config.rb', 'lib/astute/cobbler.rb', 'lib/astute/cobbler_manager.rb']",3,82145c2b7675cd3301b63fd308bb975e1f12c0b9,bug/1355347," splay=(Astute.config.iops / nodes.size * 360) reboot_events.merge(cobbler_name => @engine.power_reboot(cobbler_name, splay))", reboot_events.merge(cobbler_name => @engine.power_reboot(cobbler_name)),7,3
openstack%2Ffuel-main~master~I1917482226020efc835e950eaa7372d8769b6cb3,openstack/fuel-main,master,I1917482226020efc835e950eaa7372d8769b6cb3,Added python-pylibmc and libmemcached,MERGED,2014-08-07 08:04:59.000000000,2014-08-15 10:12:32.000000000,2014-08-15 10:12:32.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 10474}]","[{'number': 1, 'created': '2014-08-07 08:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/597aa79bb4106db44b202cb9d571777794efbdc2', 'message': 'Added python-pylibmc\n\nChange-Id: I1917482226020efc835e950eaa7372d8769b6cb3\nRelated-Bug: #1353452\n'}, {'number': 2, 'created': '2014-08-14 13:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4b335451153b6d3fb96b923f009dd210fddfd579', 'message': 'Added python-pylibmc to rpm and deb\n\nChange-Id: I1917482226020efc835e950eaa7372d8769b6cb3\nRelated-Bug: #1353452'}, {'number': 3, 'created': '2014-08-14 14:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fdeb298b1443630c7bc24bec1cf33133c69b7268', 'message': 'Added python-pylibmc and libmemcached\n\nChange-Id: I1917482226020efc835e950eaa7372d8769b6cb3\nRelated-Bug: #1353452\n'}, {'number': 4, 'created': '2014-08-15 09:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8b248206891ea6cd721d55a407d29b5a110210c6', 'message': 'Added python-pylibmc and libmemcached\n\nChange-Id: I1917482226020efc835e950eaa7372d8769b6cb3\nRelated-Bug: #1353452\n'}, {'number': 5, 'created': '2014-08-15 09:08:48.000000000', 'files': ['requirements-rpm.txt', 'requirements-deb.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5fe44030148f347a713ae9bb9e5a1c1b69792443', 'message': 'Added python-pylibmc and libmemcached\n\nChange-Id: I1917482226020efc835e950eaa7372d8769b6cb3\nRelated-Bug: #1353452\n'}]",0,112503,5fe44030148f347a713ae9bb9e5a1c1b69792443,45,5,5,10836,,,0,"Added python-pylibmc and libmemcached

Change-Id: I1917482226020efc835e950eaa7372d8769b6cb3
Related-Bug: #1353452
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/03/112503/5 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-rpm.txt', 'requirements-deb.txt']",2,597aa79bb4106db44b202cb9d571777794efbdc2,bug/1353452,python-pylibmc,,2,0
openstack%2Fnova~master~I8560b692f7150bb01bc2a3ca49b264e587a1e5d1,openstack/nova,master,I8560b692f7150bb01bc2a3ca49b264e587a1e5d1,Make NovaObjectSerializer work with dicts,MERGED,2014-06-07 20:03:58.000000000,2014-08-15 10:09:25.000000000,2014-08-15 10:09:22.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1882}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-06-07 20:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc51efb132c54a8ff174ce984fcab54249aad44c', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 2, 'created': '2014-06-09 13:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2fdc7ee883b00337526ab65bfa424129c1ab38b', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 3, 'created': '2014-06-11 16:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/985b26f6ba2e4b28230b5da0b13520a9d707e641', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 4, 'created': '2014-06-12 07:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d25731c2bc7f918fe86ca5343d664220fd90b59c', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 5, 'created': '2014-06-13 07:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0772f1f50013bef891cf59367d20009325531a0d', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 6, 'created': '2014-06-13 15:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24e909cd9702cf72affb517d030e98facfd84064', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 7, 'created': '2014-06-16 10:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ee006a0ef496657622990ed74595c6523a95ad9', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 8, 'created': '2014-06-17 10:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f28f8e89afcb8205617a59bd0cc593a9b0154a4', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 9, 'created': '2014-06-17 11:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9f66cc3c198b38b7f579edd5690b1ec35e16297', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 10, 'created': '2014-07-02 13:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3bb0c1052c3412a56f447c4d24d5b2636646974', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 11, 'created': '2014-07-03 07:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/865fe7b9646ca6064718b433f76116d632f4e564', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nPart of blueprint: compute-manager-objects-juno\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 12, 'created': '2014-07-04 16:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ba6820cb59b5591ac9c26ebf205af9b89158fe6', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nPart of blueprint: compute-manager-objects-juno\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 13, 'created': '2014-07-17 09:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f95530c15c34975fef33c4c0e37e0526efd5437', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nPart of blueprint: compute-manager-objects-juno\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 14, 'created': '2014-07-28 11:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16278c7d2d74718b847c9b51bf5f6c3d2555da4a', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nPart of blueprint: compute-manager-objects-juno\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 15, 'created': '2014-07-29 14:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c6ece33a2984fe0a54162e188a3073a72d1986b', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe do have to special case update dicts that are the result of the\nobject_action remote call. The reason is that this is the only place\nwhere we would serialize fields before sending them into the client, so\nif the field value was in fact another object, the new serializer would\ndeserialize them which is not what we want.\nThis seemed like a sane design choice under the circumstances, as adding\na single field to the updates dictionary designating it to be\nspecial-cased by the serializer is fully backwards compatible and\nrelatively self contained as object_action implementation in the\nconductor is currently inherently coupled with the objects\nimplementation.\n\nPart of blueprint: compute-manager-objects-juno\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 16, 'created': '2014-08-14 12:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c7a17fd53499ede907c262d844ab748b04842da', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe also change how @remotable decorator treats update dicts it gets back\nfrom the object_action rpc call, as any fields that are ObjectFields,\nand were updated during the remote call in the conductor, would have\nalready been hydrated by the NovaObjectSerializer's new feature.\n\nPart of blueprint: compute-manager-objects-juno\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}, {'number': 17, 'created': '2014-08-14 22:56:49.000000000', 'files': ['nova/objects/base.py', 'nova/tests/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e36aca4f199d08daead7500abcb4e0f58f01679d', 'message': ""Make NovaObjectSerializer work with dicts\n\nPreviously we would only look at dicts when deserializing and only to\nmake sure if it is in fact a serialized version of an object.\n\nThis patch makes the NovaObjectSerializer treat dicts as iterables and\nattempt to serialize/deserialize them recursively. This behaviour is\nneeded for some of the cells RPC proxy calls that would make a dict out\nof all the kwargs to a standard RPC call and then pass it to the client\nlike that (likely done to avoid having to bump versions of cell RPC calls\nwhenever we do it for the corresponding non-cell one). Without this\nchange tho - we can't have objects in any of such calls as they would\nnot get serialized.\n\nWe also change how @remotable decorator treats update dicts it gets back\nfrom the object_action rpc call, as any fields that are ObjectFields,\nand were updated during the remote call in the conductor, would have\nalready been hydrated by the NovaObjectSerializer's new feature.\n\nPart of blueprint: compute-manager-objects-juno\n\nChange-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1\n""}]",6,98607,e36aca4f199d08daead7500abcb4e0f58f01679d,147,13,17,5511,,,0,"Make NovaObjectSerializer work with dicts

Previously we would only look at dicts when deserializing and only to
make sure if it is in fact a serialized version of an object.

This patch makes the NovaObjectSerializer treat dicts as iterables and
attempt to serialize/deserialize them recursively. This behaviour is
needed for some of the cells RPC proxy calls that would make a dict out
of all the kwargs to a standard RPC call and then pass it to the client
like that (likely done to avoid having to bump versions of cell RPC calls
whenever we do it for the corresponding non-cell one). Without this
change tho - we can't have objects in any of such calls as they would
not get serialized.

We also change how @remotable decorator treats update dicts it gets back
from the object_action rpc call, as any fields that are ObjectFields,
and were updated during the remote call in the conductor, would have
already been hydrated by the NovaObjectSerializer's new feature.

Part of blueprint: compute-manager-objects-juno

Change-Id: I8560b692f7150bb01bc2a3ca49b264e587a1e5d1
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/98607/16 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/tests/objects/test_objects.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py']",4,fc51efb132c54a8ff174ce984fcab54249aad44c,bp/compute-manager-objects-juno, updates['nova_object.updates'] = True,,32,5
openstack%2Fhorizon~master~I32833837980415f922964896a3ac4ba74147e72e,openstack/horizon,master,I32833837980415f922964896a3ac4ba74147e72e,Fix list of possible trove instnace status choices,MERGED,2014-08-13 20:55:55.000000000,2014-08-15 10:09:18.000000000,2014-08-15 10:09:17.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 5293}, {'_account_id': 6610}, {'_account_id': 9622}]","[{'number': 1, 'created': '2014-08-13 20:55:55.000000000', 'files': ['openstack_dashboard/dashboards/project/databases/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/dd452b5f1bfef8800080dc8701dfeadd5f4eed07', 'message': 'Fix list of possible trove instnace status choices\n\nThe current list of available status choices for a\ntrove instance is out of date.\n\nUpdated the list with the latest information from\nthe trove runtime\n\nChange-Id: I32833837980415f922964896a3ac4ba74147e72e\nCloses-Bug: #1356577\n'}]",2,114023,dd452b5f1bfef8800080dc8701dfeadd5f4eed07,17,6,1,9750,,,0,"Fix list of possible trove instnace status choices

The current list of available status choices for a
trove instance is out of date.

Updated the list with the latest information from
the trove runtime

Change-Id: I32833837980415f922964896a3ac4ba74147e72e
Closes-Bug: #1356577
",git fetch https://review.opendev.org/openstack/horizon refs/changes/23/114023/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/databases/tables.py'],1,dd452b5f1bfef8800080dc8701dfeadd5f4eed07,bug/1356577," or instance.status == 'SHUTDOWN')) or instance.status == 'SHUTDOWN')) (""ACTIVE"", True), (""BLOCKED"", True), (""BUILD"", True), (""FAILED"", False), (""REBOOT"", None), (""RESIZE"", None), (""BACKUP"", None), (""SHUTDOWN"", False), (""ERROR"", False), (""RESTART_REQUIRED"", None),"," or instance.status == 'SHUTOFF')) or instance.status == 'SHUTOFF')) (""active"", True), (""shutoff"", True), (""suspended"", True), (""paused"", True), (""error"", False),",12,7
openstack%2Fopenstack-manuals~master~I85693ef2d2c617327c707d13ffd5f05b4d97d1d7,openstack/openstack-manuals,master,I85693ef2d2c617327c707d13ffd5f05b4d97d1d7,Arch Design edits,MERGED,2014-08-13 18:27:07.000000000,2014-08-15 10:05:10.000000000,2014-08-15 10:05:09.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 8103}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-08-13 18:27:07.000000000', 'files': ['doc/arch-design/generalpurpose/section_user_requirements_general_purpose.xml', 'doc/arch-design/generalpurpose/section_tech_considerations_general_purpose.xml', 'doc/arch-design/generalpurpose/section_prescriptive_example_general_purpose.xml', 'doc/arch-design/generalpurpose/section_architecture_general_purpose.xml', 'doc/arch-design/introduction/section_how_this_book_is_organized.xml', 'doc/arch-design/compute_focus/section_architecture_compute_focus.xml', 'doc/arch-design/compute_focus/section_tech_considerations_compute_focus.xml', 'doc/arch-design/ch_hybrid.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0043fb7a7ca0b36e40912c9ca32c4de115925e8d', 'message': 'Arch Design edits\n\nMany minor edits:\nImprove markup, follow conventions, add glossary items, fix\ncapitalization,...\n\nChange-Id: I85693ef2d2c617327c707d13ffd5f05b4d97d1d7\n'}]",7,113985,0043fb7a7ca0b36e40912c9ca32c4de115925e8d,16,5,1,6547,,,0,"Arch Design edits

Many minor edits:
Improve markup, follow conventions, add glossary items, fix
capitalization,...

Change-Id: I85693ef2d2c617327c707d13ffd5f05b4d97d1d7
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/85/113985/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/arch-design/generalpurpose/section_user_requirements_general_purpose.xml', 'doc/arch-design/generalpurpose/section_tech_considerations_general_purpose.xml', 'doc/arch-design/generalpurpose/section_prescriptive_example_general_purpose.xml', 'doc/arch-design/generalpurpose/section_architecture_general_purpose.xml', 'doc/arch-design/introduction/section_how_this_book_is_organized.xml', 'doc/arch-design/compute_focus/section_architecture_compute_focus.xml', 'doc/arch-design/compute_focus/section_tech_considerations_compute_focus.xml', 'doc/arch-design/ch_hybrid.xml']",8,0043fb7a7ca0b36e40912c9ca32c4de115925e8d,arch-edits," (<link xlink:href=""http://manageiq.org/"">http://manageiq.org</link>), but there is no single CMP that can"," (http://manageiq.org/), but there is no single CMP that can",59,33
openstack%2Fmistral~master~I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42,openstack/mistral,master,I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42,Move gate tests under mistral/tests,MERGED,2014-08-08 10:45:15.000000000,2014-08-15 09:57:38.000000000,2014-08-15 09:57:38.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-08-08 10:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9d25ecda3dcb05a4e0647aa3ecf2e34abb1f6c27', 'message': ""Move gate tests under mistral/tests\n\n- Restructure mistral/tests folder, create two subfolders: unit and functional\n- Move all unit tests (which were in the mistral/tests filder) to the mistral/tests/unit folder\n- Move all gate tests from functionaltests folder to the mistral/tests/functional\n- Edit run directory for gate tests in the functionaltests/run_tests.sh\n- Correct imports in the files with unit tests, because of path to base file\nwas changed from 'mistral.tests' to the 'mistral.tests.unit'\n\nChange-Id: I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42\n""}, {'number': 2, 'created': '2014-08-08 11:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/738891fb33d1daf132e2b151ac8ff1ac4badd426', 'message': ""Move gate tests under mistral/tests\n\n- Restructure mistral/tests folder, create two subfolders: unit and functional\n- Move all unit tests (which were in the mistral/tests filder) to the mistral/tests/unit folder\n- Move all gate tests from functionaltests folder to the mistral/tests/functional\n- Edit run directory for gate tests in the functionaltests/run_tests.sh\n- Correct imports in the files with unit tests, because of path to base file\nwas changed from 'mistral.tests' to the 'mistral.tests.unit'\n\nChange-Id: I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42\n""}, {'number': 3, 'created': '2014-08-08 11:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/80a6052498ad208ee9b6977b95ec3ef2ea132b8d', 'message': ""Move gate tests under mistral/tests\n\n- Restructure mistral/tests folder, create two subfolders: unit and functional\n- Move all unit tests (which were in the mistral/tests filder) to the mistral/tests/unit folder\n- Move all gate tests from functionaltests folder to the mistral/tests/functional\n- Edit run directory for gate tests in the functionaltests/run_tests.sh\n- Correct imports in the files with unit tests, because of path to base file\nwas changed from 'mistral.tests' to the 'mistral.tests.unit'\n\nChange-Id: I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42\n""}, {'number': 4, 'created': '2014-08-08 13:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1e022b0b78572660acec0750010fc5570f96e7c4', 'message': ""Move gate tests under mistral/tests\n\n- Restructure mistral/tests folder, create two subfolders: unit and functional\n- Move all unit tests (which were in the mistral/tests filder) to the mistral/tests/unit folder\n- Move all gate tests from functionaltests folder to the mistral/tests/functional\n- Edit run directory for gate tests in the functionaltests/run_tests.sh\n- Correct imports in the files with unit tests, because of path to base file\nwas changed from 'mistral.tests' to the 'mistral.tests.unit'\n- Leave 'resources' folder in the 'mistral/tests' to use examples from it in the tempest tests\n\nChange-Id: I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42\n""}, {'number': 5, 'created': '2014-08-13 09:41:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9f5c92a92f20032b28649cdae3e12a3f7e8810df', 'message': ""Move gate tests under mistral/tests\n\n- Move all gate tests from functionaltests folder to the mistral/tests/functional\n- Edit run directory for gate tests in the functionaltests/run_tests.sh\n- Leave 'resources' folder in the 'mistral/tests' to use examples from it in the tempest tests\n\nChange-Id: I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42\n""}, {'number': 6, 'created': '2014-08-14 08:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9513affc0b16c1d5a216e1f0a974c71c2c7905a3', 'message': ""Move gate tests under mistral/tests\n\n- Move all gate tests from functionaltests folder to the mistral/tests/functional\n- Edit run directory for gate tests in the functionaltests/run_tests.sh\n- Leave 'resources' folder in the 'mistral/tests' to use examples from it in the tempest tests\n\nChange-Id: I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42\n""}, {'number': 7, 'created': '2014-08-14 08:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/0f1555b8ef64a2e76fe6498eee62a15315959272', 'message': ""Move gate tests under mistral/tests\n\n- Move all gate tests from functionaltests folder to the mistral/tests/functional\n- Edit run directory for gate tests in the functionaltests/run_tests.sh\n- Leave 'resources' folder in the 'mistral/tests' to use examples from it in the tempest tests\n\nChange-Id: I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42\n""}, {'number': 8, 'created': '2014-08-15 08:59:24.000000000', 'files': ['mistral/tests/functional/api/v1/demo.yaml', 'run_tests.sh', 'functionaltests/run_tests.sh', 'mistral/tests/functional/api/base.py', 'mistral/tests/functional/api/v1/test_mistral_basic.py', 'mistral/tests/functional/api/__init__.py', '.testr.conf', 'mistral/tests/functional/__init__.py', 'mistral/tests/functional/api/v1/__init__.py', 'functionaltests/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/mistral/commit/79a78b96c4ac9a2160f7e87fc3bc06348fcafae5', 'message': ""Move gate tests under mistral/tests\n\n- Move all gate tests from functionaltests folder to the mistral/tests/functional\n- Edit run directory for gate tests in the functionaltests/run_tests.sh\n- Leave 'resources' folder in the 'mistral/tests' to use examples from it in the tempest tests\n\nChange-Id: I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42\n""}]",2,112821,79a78b96c4ac9a2160f7e87fc3bc06348fcafae5,47,8,8,8592,,,0,"Move gate tests under mistral/tests

- Move all gate tests from functionaltests folder to the mistral/tests/functional
- Edit run directory for gate tests in the functionaltests/run_tests.sh
- Leave 'resources' folder in the 'mistral/tests' to use examples from it in the tempest tests

Change-Id: I4d6d6a653aab5af00c5cae7c21495f4a86ebfe42
",git fetch https://review.opendev.org/openstack/mistral refs/changes/21/112821/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/unit/actions/test_http_action.py', 'mistral/tests/unit/unit/utils/__init__.py', 'mistral/tests/unit/resources/retry_task/delay_retry_task.yaml', 'functionaltests/run_tests.sh', 'mistral/tests/unit/resources/control_flow/one_std_task.yaml', 'mistral/tests/unit/resources/control_flow/one_async_task.yaml', 'mistral/tests/unit/resources/control_flow/no_namespaces.yaml', 'mistral/tests/unit/resources/control_flow/direct_flow.yaml', 'mistral/tests/unit/unit/engine/test_data_flow.py', 'mistral/tests/unit/unit/engine/test_workflow.py', 'mistral/tests/unit/api/v1/controllers/test_listeners.py', 'mistral/tests/unit/resources/retry_task/sync_task.yaml', 'mistral/tests/unit/unit/db/test_sqlalchemy_db_api.py', 'mistral/tests/functional/api/v1/__init__.py', 'mistral/tests/unit/unit/triggers/test_triggers.py', 'mistral/tests/unit/api/v1/controllers/test_workbooks.py', 'mistral/tests/unit/resources/test_rest.yaml', 'mistral/tests/unit/unit/test_exception_base.py', 'mistral/tests/unit/base.py', 'mistral/tests/unit/unit/triggers/__init__.py', 'functionaltests/api/v1/__init__.py', 'mistral/tests/unit/resources/data_flow/two_dependent_tasks.yaml', 'mistral/tests/unit/unit/engine/default/test_engine.py', 'mistral/tests/unit/unit/engine/default/test_executor.py', 'mistral/tests/unit/resources/test_order.yaml', 'mistral/tests/functional/api/v1/demo.yaml', 'run_tests.sh', 'mistral/tests/unit/api/v1/controllers/__init__.py', 'mistral/tests/unit/resources/control_flow/one_sync_task.yaml', 'mistral/tests/unit/unit/engine/__init__.py', 'mistral/tests/unit/unit/engine/test_transport.py', 'mistral/tests/unit/resources/data_flow/two_subsequent_tasks.yaml', 'mistral/tests/unit/unit/__init__.py', 'mistral/tests/unit/unit/workbook/__init__.py', 'mistral/tests/unit/api/__init__.py', 'mistral/tests/unit/unit/engine/default/__init__.py', 'mistral/tests/unit/unit/test_expressions.py', 'mistral/tests/unit/api/v1/controllers/test_tasks.py', 'mistral/tests/unit/resources/retry_task/two_tasks.yaml', 'mistral/tests/unit/resources/data_flow/three_subsequent_tasks.yaml', 'mistral/tests/functional/api/__init__.py', 'functionaltests/api/__init__.py', 'mistral/tests/unit/unit/actions/test_action_factory.py', 'mistral/tests/unit/resources/data_flow/task_with_diamond_dependencies.yaml', 'mistral/tests/unit/unit/actions/test_std_adhoc_action.py', 'functionaltests/__init__.py', 'mistral/tests/unit/api/v1/__init__.py', 'functionaltests/post_test_hook.sh', 'mistral/tests/__init__.py', 'mistral/tests/unit/resources/control_flow/require_flow.yaml', 'mistral/tests/functional/api/base.py', 'mistral/tests/functional/api/v1/test_mistral_basic.py', 'mistral/tests/unit/unit/workbook/test_workbook.py', 'mistral/tests/unit/unit/workbook/test_get_on_state.py', 'mistral/tests/unit/api/v1/controllers/test_workbook_definition.py', 'mistral/tests/unit/unit/actions/test_std_echo_action.py', 'mistral/tests/unit/api/v1/test_root.py', 'mistral/tests/unit/resources/retry_task/retry_task.yaml', 'mistral/tests/unit/unit/db/__init__.py', 'mistral/tests/unit/unit/actions/__init__.py', 'mistral/tests/unit/api/v1/controllers/test_executions.py', 'mistral/tests/unit/resources/data_flow/task_with_two_dependencies.yaml', '.testr.conf', 'mistral/tests/unit/api/test_auth.py', 'mistral/tests/unit/unit/test_scheduler.py', 'mistral/tests/unit/api/base.py', 'mistral/tests/unit/unit/actions/test_std_email_action.py', 'mistral/tests/unit/unit/engine/test_task_retry.py', 'mistral/tests/unit/unit/engine/test_data_flow_module.py']",69,9d25ecda3dcb05a4e0647aa3ecf2e34abb1f6c27,move_itests,from mistral.tests.unit import base,from mistral.tests import base,33,45
openstack%2Fnova~master~I9b3da852b0ab11dc980524e2317ee876a3ec28b8,openstack/nova,master,I9b3da852b0ab11dc980524e2317ee876a3ec28b8,Include next link when default limit is reached,MERGED,2014-03-06 22:44:35.000000000,2014-08-15 09:56:32.000000000,2014-04-02 23:09:46.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10559}]","[{'number': 1, 'created': '2014-03-06 22:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1df6abd009ca82b52300ee38ed79d407eb351145', 'message': 'Include next link when default limit is reached\n\nThe /servers and /servers/detail APIs support pagination and a\n""next"" link should be included when more data is available. When\nthe default ""osapi_max"" limit is reached then the ""next"" link is\nnot included in the API reply. In this case, the caller cannot\ndetermine if there are any more servers and has no marker value\nsuch that they can retrieve the rest of the servers.\n\nThe fix for this is to include the ""next"" link when the number of\nservers being returned is the maximum limit, even if the ""limit""\nparameter is not supplied.\n\nChange-Id: I9b3da852b0ab11dc980524e2317ee876a3ec28b8\nCloses-bug: 1288466\n'}, {'number': 2, 'created': '2014-03-07 04:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4ceb2a1416d9dc8f59f93ea86af642e45f26653', 'message': 'Include next link when default limit is reached\n\nThe /servers and /servers/detail APIs support pagination and a\n""next"" link should be included when more data is available. When\nthe default ""osapi_max"" limit is reached then the ""next"" link is\nnot included in the API reply. In this case, the caller cannot\ndetermine if there are any more servers and has no marker value\nsuch that they can retrieve the rest of the servers.\n\nThe fix for this is to include the ""next"" link when the number of\nservers being returned is the maximum limit, even if the ""limit""\nparameter is not supplied.\n\nUpdated patch set to handle limit=0 and created associated\ntest cases.\n\nChange-Id: I9b3da852b0ab11dc980524e2317ee876a3ec28b8\nCloses-bug: 1288466\n'}, {'number': 3, 'created': '2014-03-18 14:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0d09dc577da127091dfa8b6860f2c57cb55b45b', 'message': 'Include next link when default limit is reached\n\nThe /servers and /servers/detail APIs support pagination and a\n""next"" link should be included when more data is available, see\nhttp://docs.openstack.org/api/openstack-compute/2/content/\nPaginated_Collections-d1e664.html. In the documentation it states\nthat \'collections are required to contain atom ""next"" links\'.\n\nWhen the default ""osapi_max"" limit is reached then the ""next"" link\nis not included in the API reply. In this case, the caller cannot\ndetermine if there are any more servers and has no marker value\nsuch that they can retrieve the rest of the servers.\n\nFor example, assume that there are 1050 VMs and the osapi_max value\nis the default of 1000. The /servers API will return the first 1000\nVMs but it will not include the ""next"" link; the caller has no way\nto determine if there are more then 1000 VMs and no way to retrieve\nthe other 50 VMs.\n\nThe fix for this is to include the ""next"" link when the number of\nservers being returned is the maximum limit, even if the ""limit""\nparameter is not supplied. Note: the caller could workaround this\nby specifying the exact ""osapi_max"" limit value (ie, limit=1000)\non the API call but this requires that the caller knows the\nconfigured limit.\n\nChange-Id: I9b3da852b0ab11dc980524e2317ee876a3ec28b8\nCloses-bug: 1288466\n'}, {'number': 4, 'created': '2014-03-19 18:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca442480239cd5e9b7e74df988921de03a774c10', 'message': 'Include next link when default limit is reached\n\nThe /servers and /servers/detail APIs support pagination and a\n""next"" link should be included when more data is available, see\nhttp://docs.openstack.org/api/openstack-compute/2/content/\nPaginated_Collections-d1e664.html. In the documentation it states\nthat \'collections are required to contain atom ""next"" links\'.\n\nWhen the default ""osapi_max"" limit is reached then the ""next"" link\nis not included in the API reply. In this case, the caller cannot\ndetermine if there are any more servers and has no marker value\nsuch that they can retrieve the rest of the servers.\n\nFor example, assume that there are 1050 VMs and the osapi_max value\nis the default of 1000. The /servers API will return the first 1000\nVMs but it will not include the ""next"" link; the caller has no way\nto determine if there are more then 1000 VMs and no way to retrieve\nthe other 50 VMs.\n\nThe fix for this is to include the ""next"" link when the number of\nservers being returned is the maximum limit, even if the ""limit""\nparameter is not supplied. Note: the caller could workaround this\nby specifying the exact ""osapi_max"" limit value (ie, limit=1000)\non the API call but this requires that the caller knows the\nconfigured limit.\n\nChange-Id: I9b3da852b0ab11dc980524e2317ee876a3ec28b8\nCloses-bug: 1288466\n'}, {'number': 5, 'created': '2014-03-19 19:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa8ff6f325787b8de50e651d13c1421360fa657b', 'message': 'Include next link when default limit is reached\n\nThe /servers and /servers/detail APIs support pagination and a\n""next"" link should be included when more data is available, see\nhttp://docs.openstack.org/api/openstack-compute/2/content/\nPaginated_Collections-d1e664.html. In the documentation it states\nthat \'collections are required to contain atom ""next"" links\'.\n\nWhen the default ""osapi_max"" limit is reached then the ""next"" link\nis not included in the API reply. In this case, the caller cannot\ndetermine if there are any more servers and has no marker value\nsuch that they can retrieve the rest of the servers.\n\nFor example, assume that there are 1050 VMs and the osapi_max value\nis the default of 1000. The /servers API will return the first 1000\nVMs but it will not include the ""next"" link; the caller has no way\nto determine if there are more then 1000 VMs and no way to retrieve\nthe other 50 VMs.\n\nThe fix for this is to include the ""next"" link when the number of\nservers being returned is the maximum limit, even if the ""limit""\nparameter is not supplied. Note: the caller could workaround this\nby specifying the exact ""osapi_max"" limit value (ie, limit=1000)\non the API call but this requires that the caller knows the\nconfigured limit.\n\nChange-Id: I9b3da852b0ab11dc980524e2317ee876a3ec28b8\nCloses-bug: 1288466\n'}, {'number': 6, 'created': '2014-03-19 19:39:53.000000000', 'files': ['nova/tests/api/openstack/test_common.py', 'nova/api/openstack/common.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/968c01afe7ff43346f5817e2a3adf97fd03106b1', 'message': 'Include next link when default limit is reached\n\nThe /servers and /servers/detail APIs support pagination and a\n""next"" link should be included when more data is available, see\nhttp://docs.openstack.org/api/openstack-compute/2/content/\nPaginated_Collections-d1e664.html. In the documentation it states\nthat \'collections are required to contain atom ""next"" links\'.\n\nWhen the default ""osapi_max"" limit is reached then the ""next"" link\nis not included in the API reply. In this case, the caller cannot\ndetermine if there are any more servers and has no marker value\nsuch that they can retrieve the rest of the servers.\n\nFor example, assume that there are 1050 VMs and the osapi_max value\nis the default of 1000. The /servers API will return the first 1000\nVMs but it will not include the ""next"" link; the caller has no way\nto determine if there are more then 1000 VMs and no way to retrieve\nthe other 50 VMs.\n\nThe fix for this is to include the ""next"" link when the number of\nservers being returned is the maximum limit, even if the ""limit""\nparameter is not supplied. Note: the caller could workaround this\nby specifying the exact ""osapi_max"" limit value (ie, limit=1000)\non the API call but this requires that the caller knows the\nconfigured limit.\n\nChange-Id: I9b3da852b0ab11dc980524e2317ee876a3ec28b8\nCloses-bug: 1288466\n'}]",14,78800,968c01afe7ff43346f5817e2a3adf97fd03106b1,76,10,6,10559,,,0,"Include next link when default limit is reached

The /servers and /servers/detail APIs support pagination and a
""next"" link should be included when more data is available, see
http://docs.openstack.org/api/openstack-compute/2/content/
Paginated_Collections-d1e664.html. In the documentation it states
that 'collections are required to contain atom ""next"" links'.

When the default ""osapi_max"" limit is reached then the ""next"" link
is not included in the API reply. In this case, the caller cannot
determine if there are any more servers and has no marker value
such that they can retrieve the rest of the servers.

For example, assume that there are 1050 VMs and the osapi_max value
is the default of 1000. The /servers API will return the first 1000
VMs but it will not include the ""next"" link; the caller has no way
to determine if there are more then 1000 VMs and no way to retrieve
the other 50 VMs.

The fix for this is to include the ""next"" link when the number of
servers being returned is the maximum limit, even if the ""limit""
parameter is not supplied. Note: the caller could workaround this
by specifying the exact ""osapi_max"" limit value (ie, limit=1000)
on the API call but this requires that the caller knows the
configured limit.

Change-Id: I9b3da852b0ab11dc980524e2317ee876a3ec28b8
Closes-bug: 1288466
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/78800/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/test_servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'nova/api/openstack/common.py']",3,1df6abd009ca82b52300ee38ed79d407eb351145,bug/1288466," """"""Retrieve 'next' link, if applicable. This is included if: 1) 'limit' param is specified and equals the number of servers. 2) 'limit' param is specified but it exceeds CONF.osapi_max_limit, in this case the number of servers is CONF.osapi_max_limit. 3) 'limit' param is NOT specified but the number of servers is CONF.osapi_max_limit. """""" max_items = min( int(request.params.get(""limit"", CONF.osapi_max_limit)), CONF.osapi_max_limit) if max_items == len(items):"," """"""Retrieve 'next' link, if applicable."""""" limit = int(request.params.get(""limit"", 0)) if limit and limit == len(items):",130,3
openstack%2Ffuel-library~master~Ib29c1cd981c4df2086050617320b56a70cacd50c,openstack/fuel-library,master,Ib29c1cd981c4df2086050617320b56a70cacd50c,Fix mysqld backend check dependency,MERGED,2014-08-14 07:48:34.000000000,2014-08-15 09:40:41.000000000,2014-08-15 09:40:40.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-14 07:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/abdbed71a090d2f7da27935ea3fa5c25e78dd591', 'message': 'Fix mysqld backend check dependency\n\nWaiting for haproxy mysqld backend should rely on\nhaproxy service for mysqld readiness.\n\nCloses-bug: #1356748\n\nChange-Id: Ib29c1cd981c4df2086050617320b56a70cacd50c\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2014-08-14 12:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/88f90963afef7adafecfa5c964839652b6ea78ff', 'message': 'Fix mysqld backend check dependency\n\nWaiting for haproxy mysqld backend should rely on\nhaproxy service for mysqld readiness\n\nCloses-bug: #1356748\n\nChange-Id: Ib29c1cd981c4df2086050617320b56a70cacd50c\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 3, 'created': '2014-08-14 13:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/46ba8e9ac6f459d4eefd2900bc0ff7c445771db3', 'message': 'Fix mysqld backend check dependency\n\nWaiting for haproxy mysqld backend should rely on\nhaproxy service for mysqld readiness.\n\nCloses-bug: #1356748\n\nChange-Id: Ib29c1cd981c4df2086050617320b56a70cacd50c\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 4, 'created': '2014-08-15 08:03:03.000000000', 'files': ['deployment/puppet/openstack/manifests/ha/mysqld.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3c28efd1afc6cbf0fa39199d0d7cc358c8dd0c50', 'message': 'Fix mysqld backend check dependency\n\nWaiting for haproxy mysqld backend should rely on\nhaproxy service for mysqld readiness\n\nCloses-bug: #1356748\n\nChange-Id: Ib29c1cd981c4df2086050617320b56a70cacd50c\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,114152,3c28efd1afc6cbf0fa39199d0d7cc358c8dd0c50,33,5,4,6926,,,0,"Fix mysqld backend check dependency

Waiting for haproxy mysqld backend should rely on
haproxy service for mysqld readiness

Closes-bug: #1356748

Change-Id: Ib29c1cd981c4df2086050617320b56a70cacd50c
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/52/114152/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/ha/mysqld.pp'],1,abdbed71a090d2f7da27935ea3fa5c25e78dd591,fix1356748, Openstack::Ha::Haproxy_service<| title == 'mysqld' |> -> Exec['wait-for-haproxy-mysql-backend'],,1,1
openstack%2Ffuel-library~master~I579f33d673925bea27ceab48f3380ed1dda40170,openstack/fuel-library,master,I579f33d673925bea27ceab48f3380ed1dda40170,Fix haproxy backend checks dependencies,MERGED,2014-08-13 12:55:35.000000000,2014-08-15 09:40:32.000000000,2014-08-15 09:40:32.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-13 12:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/54946fc72d09b1aecb54d29ed966aaedc0fda34f', 'message': ""Fix haproxy backend checks dependencies\n\nOpenstack::Ha::Haproxy_service['foo']\nshould always be evaluated *before* any\nExec['wait-for-foo'] backend checks.\n\nCloses-bug: #1352964\n\nChange-Id: I579f33d673925bea27ceab48f3380ed1dda40170\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}, {'number': 2, 'created': '2014-08-14 07:45:21.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bd89083f75b37c1119b8eb7e6e12103d4c68b6aa', 'message': ""Fix haproxy backend checks dependencies\n\nOpenstack::Ha::Haproxy_service['keystone*']\nshould always be evaluated *before* any\nExec['wait-for-keystone*'] backend checks.\n\nCloses-bug: #1352964\n\nChange-Id: I579f33d673925bea27ceab48f3380ed1dda40170\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",0,113870,bd89083f75b37c1119b8eb7e6e12103d4c68b6aa,23,5,2,6926,,,0,"Fix haproxy backend checks dependencies

Openstack::Ha::Haproxy_service['keystone*']
should always be evaluated *before* any
Exec['wait-for-keystone*'] backend checks.

Closes-bug: #1352964

Change-Id: I579f33d673925bea27ceab48f3380ed1dda40170
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/70/113870/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/ha/mysqld.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp']",2,54946fc72d09b1aecb54d29ed966aaedc0fda34f,fix1352964," Class['keystone', 'openstack::ha::keystone']-> Exec<| title=='wait-for-haproxy-keystone-backend' |> ->", Class['keystone']-> Exec<| title=='wait-for-haproxy-keystone-backend' |> ->,3,1
openstack%2Fnova~master~Id531377d5d34d76a4ffafaa02ecab585cbcb369b,openstack/nova,master,Id531377d5d34d76a4ffafaa02ecab585cbcb369b,Use common get_instance function in v2 attach_interface,MERGED,2014-08-11 06:35:42.000000000,2014-08-15 09:16:03.000000000,2014-08-14 11:54:33.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 11531}]","[{'number': 1, 'created': '2014-08-11 06:35:42.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_attach_interfaces.py', 'nova/api/openstack/compute/contrib/attach_interfaces.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5885517d7542c9695c43770be8b488117df57e2f', 'message': 'Use common get_instance function in v2 attach_interface\n\nThis patch use common get_instance function in v2 attach_interface.\nThat can make the instance behavior consistent with v2.1 api. Then\nv2.1 and v2 can share same unittest.\n\nChange-Id: Id531377d5d34d76a4ffafaa02ecab585cbcb369b\n'}]",0,113178,5885517d7542c9695c43770be8b488117df57e2f,24,9,1,5754,,,0,"Use common get_instance function in v2 attach_interface

This patch use common get_instance function in v2 attach_interface.
That can make the instance behavior consistent with v2.1 api. Then
v2.1 and v2 can share same unittest.

Change-Id: Id531377d5d34d76a4ffafaa02ecab585cbcb369b
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/113178/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_attach_interfaces.py', 'nova/api/openstack/compute/contrib/attach_interfaces.py']",2,5885517d7542c9695c43770be8b488117df57e2f,bp/v2-on-v3-api," common.get_instance(self.compute_api, context, server_id) instance = common.get_instance(self.compute_api, context, server_id, want_objects=True) instance = common.get_instance(self.compute_api, context, server_id, want_objects=True) LOG.audit(_(""Detach interface %s""), port_id, instance=instance) instance = common.get_instance(self.compute_api, context, server_id)"," try: self.compute_api.get(context, server_id) except exception.NotFound: raise exc.HTTPNotFound() instance = self.compute_api.get(context, server_id, want_objects=True) except exception.NotFound as e: raise exc.HTTPNotFound(explanation=e.format_message()) try: instance = self.compute_api.get(context, server_id, want_objects=True) LOG.audit(_(""Detach interface %s""), port_id, instance=instance) except exception.NotFound: raise exc.HTTPNotFound() try: instance = self.compute_api.get(context, server_id) except exception.NotFound: raise exc.HTTPNotFound() ",11,23
openstack%2Fnova~master~I311106fbb5070f71c1f2bb5c94ff293a4c9dbb8d,openstack/nova,master,I311106fbb5070f71c1f2bb5c94ff293a4c9dbb8d,Change v3 availability-zone API to v2.1,ABANDONED,2014-08-15 05:18:17.000000000,2014-08-15 09:15:46.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-08-15 05:18:17.000000000', 'files': ['doc/v3/api_samples/os-availability-zone/availability-zone-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-availability-zone/server-post-req.json.tpl', 'doc/v3/api_samples/os-availability-zone/availability-zone-list-resp.json', 'nova/tests/api/openstack/compute/plugins/v3/test_availability_zone.py', 'nova/tests/integrated/v3/api_samples/os-availability-zone/availability-zone-detail-resp.json.tpl', 'doc/v3/api_samples/os-availability-zone/server-post-req.json', 'nova/api/openstack/compute/plugins/v3/availability_zone.py', 'nova/tests/api/openstack/compute/contrib/test_availability_zone.py', 'nova/tests/integrated/v3/api_samples/os-availability-zone/availability-zone-list-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/2171db68a91a04d2260cecd9860bb712f00a4595', 'message': 'Change v3 availability-zone API to v2.1\n\nThis patch changes v3 availability-zone API to v2.1 and makes v2\nunit tests share between v2 and v2.1.\n\nThe differences between v2 and v3 are described on the wiki page\nhttps://wiki.openstack.org/wiki/NovaAPIv2tov3.\n\nNote - Addition unit tests implemented for V3 are already present\nin test_servers file.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I311106fbb5070f71c1f2bb5c94ff293a4c9dbb8d\n'}]",0,114434,2171db68a91a04d2260cecd9860bb712f00a4595,5,3,1,8556,,,0,"Change v3 availability-zone API to v2.1

This patch changes v3 availability-zone API to v2.1 and makes v2
unit tests share between v2 and v2.1.

The differences between v2 and v3 are described on the wiki page
https://wiki.openstack.org/wiki/NovaAPIv2tov3.

Note - Addition unit tests implemented for V3 are already present
in test_servers file.

Partially implements blueprint v2-on-v3-api

Change-Id: I311106fbb5070f71c1f2bb5c94ff293a4c9dbb8d
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/114434/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/v3/api_samples/os-availability-zone/availability-zone-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-availability-zone/server-post-req.json.tpl', 'doc/v3/api_samples/os-availability-zone/availability-zone-list-resp.json', 'nova/tests/api/openstack/compute/plugins/v3/test_availability_zone.py', 'nova/tests/integrated/v3/api_samples/os-availability-zone/availability-zone-detail-resp.json.tpl', 'doc/v3/api_samples/os-availability-zone/server-post-req.json', 'nova/api/openstack/compute/plugins/v3/availability_zone.py', 'nova/tests/api/openstack/compute/contrib/test_availability_zone.py', 'nova/tests/integrated/v3/api_samples/os-availability-zone/availability-zone-list-resp.json.tpl']",9,2171db68a91a04d2260cecd9860bb712f00a4595,bp/v2-on-v3-api," ""availabilityZoneInfo"": [ ""zoneName"": ""nova"", ""zoneState"": {"," ""availability_zone_info"": [ ""zone_name"": ""nova"", ""zone_state"": {",102,489
openstack%2Fnova~master~Ib62e430e678fe09c4a8475a636a8ecc11a194f5c,openstack/nova,master,Ib62e430e678fe09c4a8475a636a8ecc11a194f5c,Rename rbd.py to rbd_utils.py in libvirt driver directory,MERGED,2014-08-05 03:49:45.000000000,2014-08-15 08:53:13.000000000,2014-08-15 08:53:10.000000000,"[{'_account_id': 3}, {'_account_id': 1107}, {'_account_id': 1247}, {'_account_id': 1313}, {'_account_id': 1736}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6849}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12794}]","[{'number': 1, 'created': '2014-08-05 03:49:45.000000000', 'files': ['nova/tests/virt/libvirt/test_imagebackend.py', 'nova/virt/libvirt/driver.py', 'nova/virt/libvirt/rbd_utils.py', 'nova/tests/virt/libvirt/test_rbd.py', 'nova/tests/virt/libvirt/test_driver.py', 'nova/virt/libvirt/imagebackend.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/81348368c70cd39c6241e7da6d33629e577494f5', 'message': 'Rename rbd.py to rbd_utils.py in libvirt driver directory\n\nIn libvirt driver directory, rbd.py confict with global rbd library\nwhich is imported in rbd.py, so we rename rbd.py to rbd_utils.py.\n\nChange-Id: Ib62e430e678fe09c4a8475a636a8ecc11a194f5c\nCloses-Bug: #1352595\n'}]",0,111892,81348368c70cd39c6241e7da6d33629e577494f5,31,12,1,1313,,,0,"Rename rbd.py to rbd_utils.py in libvirt driver directory

In libvirt driver directory, rbd.py confict with global rbd library
which is imported in rbd.py, so we rename rbd.py to rbd_utils.py.

Change-Id: Ib62e430e678fe09c4a8475a636a8ecc11a194f5c
Closes-Bug: #1352595
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/111892/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_imagebackend.py', 'nova/virt/libvirt/driver.py', 'nova/virt/libvirt/rbd_utils.py', 'nova/tests/virt/libvirt/test_rbd.py', 'nova/tests/virt/libvirt/test_driver.py', 'nova/virt/libvirt/imagebackend.py']",6,81348368c70cd39c6241e7da6d33629e577494f5,bug/1352595,from nova.virt.libvirt import rbd_utils self.driver = rbd_utils.RBDDriver(,from nova.virt.libvirt import rbd self.driver = rbd.RBDDriver(,45,45
openstack%2Ffuel-library~stable%2F5.0~I6453e290464075a8bb0f1c4c07be45e5df86b55e,openstack/fuel-library,stable/5.0,I6453e290464075a8bb0f1c4c07be45e5df86b55e,Limit nova_floating_range to primary controller,ABANDONED,2014-08-14 12:54:33.000000000,2014-08-15 08:43:55.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}]","[{'number': 1, 'created': '2014-08-14 12:54:33.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/dc0e6b7258669aecc867d9119e05d1293b0ee4f2', 'message': 'Limit nova_floating_range to primary controller\n\nNova Floating ranges should be created on primary controller only.\n\nChange-Id: I6453e290464075a8bb0f1c4c07be45e5df86b55e\nCloses-Bug: 1334263\nSigned-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}]",0,114226,dc0e6b7258669aecc867d9119e05d1293b0ee4f2,10,8,1,11090,,,0,"Limit nova_floating_range to primary controller

Nova Floating ranges should be created on primary controller only.

Change-Id: I6453e290464075a8bb0f1c4c07be45e5df86b55e
Closes-Bug: 1334263
Signed-Off: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/26/114226/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'],1,dc0e6b7258669aecc867d9119e05d1293b0ee4f2,bug/1334263," nova_floating_range { $floating_ips_range: ensure => 'present', pool => 'nova', username => $access_hash[user], api_key => $access_hash[password], auth_method => 'password', auth_url => ""http://${::fuel_settings['management_vip']}:5000/v2.0/"", authtenant_name => $access_hash[tenant], api_retries => 10, } Class['nova::api', 'openstack::ha::nova'] -> Exec<| title=='wait-for-haproxy-nova-backend' |> -> Nova_floating_range <| |> }"," } nova_floating_range { $floating_ips_range: ensure => 'present', pool => 'nova', username => $access_hash[user], api_key => $access_hash[password], auth_method => 'password', auth_url => ""http://${::fuel_settings['management_vip']}:5000/v2.0/"", authtenant_name => $access_hash[tenant], api_retries => 10, } Class['nova::api', 'openstack::ha::nova'] -> Exec<| title=='wait-for-haproxy-nova-backend' |> -> Nova_floating_range <| |>",13,13
openstack%2Ftrove~stable%2Ficehouse~Ieed6898a157ff1e98136705d32883761ab505dd4,openstack/trove,stable/icehouse,Ieed6898a157ff1e98136705d32883761ab505dd4,Bump stable/icehouse next version to 2014.1.3,MERGED,2014-08-08 14:15:37.000000000,2014-08-15 08:38:09.000000000,2014-08-15 08:38:09.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 9656}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-08-08 14:15:37.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/trove/commit/318c2b71426380f6a35f1f6edaaa8da7912ae725', 'message': 'Bump stable/icehouse next version to 2014.1.3\n\nBump stable/icehouse next version to 2014.1.3\n\nChange-Id: Ieed6898a157ff1e98136705d32883761ab505dd4\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",0,112884,318c2b71426380f6a35f1f6edaaa8da7912ae725,12,4,1,24,,,0,"Bump stable/icehouse next version to 2014.1.3

Bump stable/icehouse next version to 2014.1.3

Change-Id: Ieed6898a157ff1e98136705d32883761ab505dd4
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/trove refs/changes/84/112884/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,318c2b71426380f6a35f1f6edaaa8da7912ae725,,version = 2014.1.3,version = 2014.1.2,1,1
openstack%2Fnova~master~Ic45ea131fa352fa3a1371301452bd90f74458d1b,openstack/nova,master,Ic45ea131fa352fa3a1371301452bd90f74458d1b,VMware: remove unused parameter for spawn,ABANDONED,2014-08-14 12:19:41.000000000,2014-08-15 08:33:21.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8247}, {'_account_id': 9172}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-08-14 12:19:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26844b26701ad535ed743c18a34387155c412d56', 'message': ""VMware: remove unused parameter for spawn\n\nThe rescue code no longer needs to have a suffix '-resuce'\nfor a rescue VM. This allows us to drop the instance-name\nparameter from the spawn method.\n\nChange-Id: Ic45ea131fa352fa3a1371301452bd90f74458d1b\n""}, {'number': 2, 'created': '2014-08-14 17:25:37.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1bf82b0a31defc3df8b33b3f4ca11b84cb5471f0', 'message': ""VMware: remove unused parameter for spawn\n\nThe rescue code no longer needs to have a suffix '-resuce'\nfor a rescue VM. This allows us to drop the instance-name\nparameter from the spawn method.\n\nChange-Id: Ic45ea131fa352fa3a1371301452bd90f74458d1b\n""}]",1,114220,1bf82b0a31defc3df8b33b3f4ca11b84cb5471f0,11,5,2,1653,,,0,"VMware: remove unused parameter for spawn

The rescue code no longer needs to have a suffix '-resuce'
for a rescue VM. This allows us to drop the instance-name
parameter from the spawn method.

Change-Id: Ic45ea131fa352fa3a1371301452bd90f74458d1b
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/114220/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_driver_api.py']",2,26844b26701ad535ed743c18a34387155c412d56,rescue-remove-unused-parameter,," instance_name=instance_name,",2,6
openstack%2Ffuel-library~master~Ib7e7d02bbf5f7185646c0fefbc4317d9bf5c4566,openstack/fuel-library,master,Ib7e7d02bbf5f7185646c0fefbc4317d9bf5c4566,Load rabbitmq plugins from OCF script,MERGED,2014-08-14 16:00:42.000000000,2014-08-15 08:30:49.000000000,2014-08-15 08:30:49.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-14 16:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/deb19a4a927b08158572611a629dabbd1cbf08f9', 'message': 'Load rabbitmq plugins from OCF script\n\nRabbitmq plugins do not work in HA mode since we start rabbitmq\nserver with RABBITMQ_NODE_ONLY=1 which disables plugins.\nSo we just load them with a piece of Erlang code sent to rabbitmq\nvia ""rabbitmqctl eval"".\n\nChange-Id: Ib7e7d02bbf5f7185646c0fefbc4317d9bf5c4566\nCloses-bug: #1354026\n'}, {'number': 2, 'created': '2014-08-14 16:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/82afe40e53ee29467f5e6689503dcbb6ea36f79f', 'message': 'Load rabbitmq plugins from OCF script\n\nRabbitmq plugins do not work in HA mode since we start rabbitmq\nserver with RABBITMQ_NODE_ONLY=1 which disables plugins.\nSo we just load them with a piece of Erlang code sent to rabbitmq\nvia ""rabbitmqctl eval"".\n\nChange-Id: Ib7e7d02bbf5f7185646c0fefbc4317d9bf5c4566\nCloses-bug: #1354026\n'}, {'number': 3, 'created': '2014-08-14 16:09:20.000000000', 'files': ['deployment/puppet/nova/files/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6274f28cd6b1fbb1a9af2be88450f0840ea533d3', 'message': 'Load rabbitmq plugins from OCF script\n\nRabbitmq plugins do not work in HA mode since we start rabbitmq\nserver with RABBITMQ_NODE_ONLY=1 which disables plugins.\nSo we just load them with a piece of Erlang code sent to rabbitmq\nvia ""rabbitmqctl eval"".\n\nChange-Id: Ib7e7d02bbf5f7185646c0fefbc4317d9bf5c4566\nCloses-bug: #1354026\n'}]",0,114282,6274f28cd6b1fbb1a9af2be88450f0840ea533d3,26,6,3,9387,,,0,"Load rabbitmq plugins from OCF script

Rabbitmq plugins do not work in HA mode since we start rabbitmq
server with RABBITMQ_NODE_ONLY=1 which disables plugins.
So we just load them with a piece of Erlang code sent to rabbitmq
via ""rabbitmqctl eval"".

Change-Id: Ib7e7d02bbf5f7185646c0fefbc4317d9bf5c4566
Closes-bug: #1354026
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/82/114282/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nova/files/ocf/rabbitmq'],1,deb19a4a927b08158572611a629dabbd1cbf08f9,bug/1354026,"load_modules() { local rc ${OCF_RESKEY_ctl} eval 'Plugins = rabbit_plugins:setup(), ToBeLoaded = Plugins, ok = app_utils:load_applications(ToBeLoaded), StartupApps = app_utils:app_dependency_order(ToBeLoaded,false), app_utils:start_applications(StartupApps).' rc=$? return $rc } list_active_modules() { local LIST=""${OCF_RESKEY_ctl} eval 'rabbit_plugins:active().'"" echo ""${LIST}"" } # Loading enabled modules ocf_log info ""${LH} start plugins."" load_modules local mrc=$? if [[ $mrc == 0 ]] ; then local MLIST=`list_active_modules` ocf_log info ""${LH} Starting plugins: $MLIST"" else ocf_log info ""${LH} Starting plugins: failed."" fi",,22,0
openstack%2Ffuel-library~master~I6979d9b54c1e9fed2f1629ebc1edc741f2136b56,openstack/fuel-library,master,I6979d9b54c1e9fed2f1629ebc1edc741f2136b56,Fix '/etc/init.d/supervisord status',MERGED,2014-08-14 10:36:03.000000000,2014-08-15 08:28:47.000000000,2014-08-15 08:28:47.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-14 10:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/00d154b538a7393111a85c1021007023885bdcf9', 'message': 'Fix \'/etc/init.d/supervisord status\'\n\n""service supervisord status"" reports wrong status (servise is up)\neven when supervisor is down. It uses ""supervisorctl status"" which\nreturns exit code ""0"" when supervisor is down. We\'re adding\nadditional check for status() function to fix this.\n\nCloses-bug: #1356805\n\nChange-Id: I6979d9b54c1e9fed2f1629ebc1edc741f2136b56\n'}, {'number': 2, 'created': '2014-08-14 13:17:26.000000000', 'files': ['deployment/puppet/nailgun/files/supervisor-init'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/32f61400c7d68804df46593f5bd392c364958f91', 'message': 'Fix \'/etc/init.d/supervisord status\'\n\n""service supervisord status"" reports wrong status (servise is up)\neven when supervisor is down. It uses ""supervisorctl status"" which\nreturns exit code ""0"" when supervisor is down. We\'re adding\nadditional check for status() function to fix this.\n\nCloses-bug: #1356805\n\nChange-Id: I6979d9b54c1e9fed2f1629ebc1edc741f2136b56\n'}]",1,114193,32f61400c7d68804df46593f5bd392c364958f91,25,5,2,9387,,,0,"Fix '/etc/init.d/supervisord status'

""service supervisord status"" reports wrong status (servise is up)
even when supervisor is down. It uses ""supervisorctl status"" which
returns exit code ""0"" when supervisor is down. We're adding
additional check for status() function to fix this.

Closes-bug: #1356805

Change-Id: I6979d9b54c1e9fed2f1629ebc1edc741f2136b56
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/93/114193/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/files/supervisor-init'],1,00d154b538a7393111a85c1021007023885bdcf9,bug/1356805, /usr/bin/supervisorctl status && ps -p `cat /var/run/supervisord.pid` &>/dev/null, /usr/bin/supervisorctl status,1,1
openstack%2Ffuel-library~master~Ia79b6e8b26a8ccf7846affbd2dbf6aa758ac4947,openstack/fuel-library,master,Ia79b6e8b26a8ccf7846affbd2dbf6aa758ac4947,Add the iptables rule to allow gre traffic,MERGED,2014-08-14 13:17:31.000000000,2014-08-15 08:11:48.000000000,2014-08-15 08:11:48.000000000,"[{'_account_id': 3}, {'_account_id': 5950}, {'_account_id': 6502}, {'_account_id': 7125}, {'_account_id': 7468}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-14 13:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/101d138441a2f34a60efe7b91fb93ebe8e5ce085', 'message': ""Add iptables rule to allow gre traffic\n\nCurrently there's no rule to accept gre packets which are required for the\nNeutron GRE networking case, so they are dropped due to the '999 drop all' rule\n\nChange-Id: Ia79b6e8b26a8ccf7846affbd2dbf6aa758ac4947\nCloses-bug: #1355794\n""}, {'number': 2, 'created': '2014-08-14 16:13:42.000000000', 'files': ['deployment/puppet/openstack/manifests/firewall.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/78e1b6a738223a1dda8b0b9c1f4e127d2903bdf1', 'message': ""Add the iptables rule to allow gre traffic\n\nCurrently there's no rule to accept gre packets which are required for the\nNeutron GRE networking case, so they are dropped due to the '999 drop all' rule\n\nChange-Id: Ia79b6e8b26a8ccf7846affbd2dbf6aa758ac4947\nCloses-bug: #1355794\n""}]",0,114241,78e1b6a738223a1dda8b0b9c1f4e127d2903bdf1,20,8,2,7604,,,0,"Add the iptables rule to allow gre traffic

Currently there's no rule to accept gre packets which are required for the
Neutron GRE networking case, so they are dropped due to the '999 drop all' rule

Change-Id: Ia79b6e8b26a8ccf7846affbd2dbf6aa758ac4947
Closes-bug: #1355794
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/41/114241/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/firewall.pp'],1,101d138441a2f34a60efe7b91fb93ebe8e5ce085,bug/1355794," firewall { '333 notrack gre': firewall { '334 accept gre': chain => 'INPUT', table => 'filter', proto => 'gre', action => 'accept', } ", firewall { '333 accept gre':,8,1
openstack%2Fhorizon~master~I70e1efc36df5e5cb34b4bc8a14d0d4cc3dcdb0cd,openstack/horizon,master,I70e1efc36df5e5cb34b4bc8a14d0d4cc3dcdb0cd,Imported Translations from Transifex,MERGED,2014-08-15 06:03:14.000000000,2014-08-15 08:05:46.000000000,2014-08-15 08:05:45.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-08-15 06:03:14.000000000', 'files': ['horizon/locale/es/LC_MESSAGES/django.po', 'horizon/locale/hi/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/hu/LC_MESSAGES/django.po', 'horizon/locale/pl_PL/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/django.po', 'horizon/locale/en/LC_MESSAGES/django.po', 'horizon/locale/ca/LC_MESSAGES/django.po', 'horizon/locale/es_MX/LC_MESSAGES/django.po', 'horizon/locale/sl_SI/LC_MESSAGES/django.po', 'horizon/locale/fr/LC_MESSAGES/django.po', 'horizon/locale/it/LC_MESSAGES/django.po', 'horizon/locale/tr_TR/LC_MESSAGES/django.po', 'horizon/locale/en_AU/LC_MESSAGES/django.po', 'horizon/locale/en_GB/LC_MESSAGES/django.po', 'horizon/locale/zh_CN/LC_MESSAGES/django.po', 'horizon/locale/zh_TW/LC_MESSAGES/django.po', 'horizon/locale/ru/LC_MESSAGES/django.po', 'horizon/locale/fil/LC_MESSAGES/django.po', 'horizon/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/nl_NL/LC_MESSAGES/django.po', 'horizon/locale/sr/LC_MESSAGES/django.po', 'horizon/locale/pt/LC_MESSAGES/django.po', 'horizon/locale/de/LC_MESSAGES/django.po', 'horizon/locale/pt_BR/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/492ecbb197009858c651aa333d6e02e962055ae6', 'message': 'Imported Translations from Transifex\n\nChange-Id: I70e1efc36df5e5cb34b4bc8a14d0d4cc3dcdb0cd\n'}]",0,114440,492ecbb197009858c651aa333d6e02e962055ae6,8,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I70e1efc36df5e5cb34b4bc8a14d0d4cc3dcdb0cd
",git fetch https://review.opendev.org/openstack/horizon refs/changes/40/114440/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/es/LC_MESSAGES/django.po', 'horizon/locale/hi/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/hu/LC_MESSAGES/django.po', 'horizon/locale/pl_PL/LC_MESSAGES/django.po', 'horizon/locale/cs/LC_MESSAGES/django.po', 'horizon/locale/en/LC_MESSAGES/django.po', 'horizon/locale/ca/LC_MESSAGES/django.po', 'horizon/locale/es_MX/LC_MESSAGES/django.po', 'horizon/locale/sl_SI/LC_MESSAGES/django.po', 'horizon/locale/fr/LC_MESSAGES/django.po', 'horizon/locale/it/LC_MESSAGES/django.po', 'horizon/locale/tr_TR/LC_MESSAGES/django.po', 'horizon/locale/en_AU/LC_MESSAGES/django.po', 'horizon/locale/en_GB/LC_MESSAGES/django.po', 'horizon/locale/zh_CN/LC_MESSAGES/django.po', 'horizon/locale/zh_TW/LC_MESSAGES/django.po', 'horizon/locale/ru/LC_MESSAGES/django.po', 'horizon/locale/fil/LC_MESSAGES/django.po', 'horizon/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/nl_NL/LC_MESSAGES/django.po', 'horizon/locale/sr/LC_MESSAGES/django.po', 'horizon/locale/pt/LC_MESSAGES/django.po', 'horizon/locale/de/LC_MESSAGES/django.po', 'horizon/locale/pt_BR/LC_MESSAGES/django.po']",25,492ecbb197009858c651aa333d6e02e962055ae6,transifex/translations,"""POT-Creation-Date: 2014-08-15 00:10-0500\n"" ""PO-Revision-Date: 2014-08-15 05:10+0000\n""#: tables/actions.py:457#: tables/actions.py:661#: tables/actions.py:663#: tables/actions.py:693 tables/base.py:1478#: tables/actions.py:722#: tables/actions.py:729#: tables/actions.py:735#: tables/actions.py:777#: tables/actions.py:778#: tables/actions.py:810#: tables/actions.py:811#: tables/base.py:1254#: tables/base.py:1394msgid ""Next&nbsp;&raquo;"" msgstr """"","""POT-Creation-Date: 2014-08-08 15:13-0500\n"" ""PO-Revision-Date: 2014-08-09 02:14+0000\n""#: tables/actions.py:444#: tables/actions.py:631#: tables/actions.py:633#: tables/actions.py:663 tables/base.py:1460#: tables/actions.py:692#: tables/actions.py:699#: tables/actions.py:705#: tables/actions.py:747#: tables/actions.py:748#: tables/actions.py:780#: tables/actions.py:781#: tables/base.py:1236#: tables/base.py:1376msgid ""More&nbsp;&raquo;"" msgstr ""Mais&nbsp;&raquo;""",378,378
openstack%2Ffuel-library~master~I848a86ef27f9ad8235024996b7417a30689daa4f,openstack/fuel-library,master,I848a86ef27f9ad8235024996b7417a30689daa4f,Enable retry for Ubuntu installs,MERGED,2014-08-13 12:38:44.000000000,2014-08-15 07:52:59.000000000,2014-08-15 07:52:59.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9705}]","[{'number': 1, 'created': '2014-08-13 12:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1b2dd892bf9e2d26d742c77c358ffa12e0bddaa9', 'message': 'Enable retry for Ubuntu installs\n\nThis is a proactive solution to bug\n1355347, which allows retries for failed\ndownloads of packages from apt mirror\nduring installation.\n\nChange-Id: I848a86ef27f9ad8235024996b7417a30689daa4f\nPartial-Bug: #1355347\n'}, {'number': 2, 'created': '2014-08-14 16:36:07.000000000', 'files': ['deployment/puppet/cobbler/templates/preseed/ubuntu-1204.preseed.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4ae17af4bf2cf775987de036b4fd09fb18b44767', 'message': 'Enable retry for Ubuntu installs\n\nThis is a proactive solution to bug\n1355347, which allows retries for failed\ndownloads of packages from apt mirror\nduring installation.\n\nChange-Id: I848a86ef27f9ad8235024996b7417a30689daa4f\nPartial-Bug: #1355347\n'}]",1,113867,4ae17af4bf2cf775987de036b4fd09fb18b44767,22,7,2,7195,,,0,"Enable retry for Ubuntu installs

This is a proactive solution to bug
1355347, which allows retries for failed
downloads of packages from apt mirror
during installation.

Change-Id: I848a86ef27f9ad8235024996b7417a30689daa4f
Partial-Bug: #1355347
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/67/113867/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cobbler/templates/preseed/ubuntu-1204.preseed.erb'],1,1b2dd892bf9e2d26d742c77c358ffa12e0bddaa9,bug/1355347,# Retry failed repo d-i apt-setup/mirror/error select Retry # Downloading a file failed # d-i apt-setup/use_mirror select Retry,,4,1
openstack%2Fkeystone-specs~master~I8ddf845038d8d4aac2321888d18196565678dc86,openstack/keystone-specs,master,I8ddf845038d8d4aac2321888d18196565678dc86,Endpoint policy extension,MERGED,2014-06-13 04:55:37.000000000,2014-08-15 07:49:50.000000000,2014-08-14 15:40:25.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 7}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 8866}, {'_account_id': 11022}, {'_account_id': 11045}, {'_account_id': 11387}, {'_account_id': 12404}]","[{'number': 1, 'created': '2014-06-13 04:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/fe5a156084e8a718439beb7e71ea3e7e9dd2c6a6', 'message': 'endpont policy\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86\n'}, {'number': 2, 'created': '2014-06-27 21:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/bd2ce15e4043a2b7a6e5761bca97f48e94faf90b', 'message': 'endpoint policy\n\nAllow assignment of a policy module to a specific endpoint\n\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86'}, {'number': 3, 'created': '2014-07-22 15:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e452b973ab3c2861410d816cfdfdc8ee05112fd6', 'message': 'Endpoint policy extension\n\nAllow associtation of a policy module to a specific endpoint(s)\n\nCo-Authored-By: Adam Young <ayoung@redhat.com>\nCo-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86\n'}, {'number': 4, 'created': '2014-07-22 15:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/8787ff11806f544da3812efb9db6145648f5e2ac', 'message': 'Endpoint policy extension\n\nAllow associtation of a policy module to a specific endpoint(s)\n\nCo-Authored-By: Adam Young <ayoung@redhat.com>\nCo-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86\n'}, {'number': 5, 'created': '2014-07-25 22:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/d4b88d5a3984983ed9aa3acf7df1e8ac9c440cb5', 'message': 'Endpoint policy extension\n\nAllow associtation of a policy module to a specific endpoint(s)\n\nCo-Authored-By: Adam Young <ayoung@redhat.com>\nCo-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86\n'}, {'number': 6, 'created': '2014-07-26 01:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e692115896b5910e60547f18fe5327c318e2f842', 'message': 'Endpoint policy extension\n\nProvide the ability to associate a given policy file with an endpoint\nor set of enpoints.\n\nCo-Authored-By: Adam Young <ayoung@redhat.com>\nCo-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86\n'}, {'number': 7, 'created': '2014-08-04 19:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/23b684e423de8b48c6829f6e1f851cd68bd320d9', 'message': 'Endpoint policy extension\n\nProvide the ability to associate a given policy file with an endpoint\nor set of enpoints.\n\nCo-Authored-By: Adam Young <ayoung@redhat.com>\nCo-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86\n'}, {'number': 8, 'created': '2014-08-04 19:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/52df456277feff1cfd0eec91ff699bd929a2ea99', 'message': 'Endpoint policy extension\n\nProvide the ability to associate a given policy file with an endpoint\nor set of enpoints.\n\nCo-Authored-By: Adam Young <ayoung@redhat.com>\nCo-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86\n'}, {'number': 9, 'created': '2014-08-06 21:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/985e41c776162d8717bce7c9a8dc5cdf45fb7df6', 'message': 'Endpoint policy extension\n\nProvide the ability to associate a given policy file with an endpoint\nor set of endpoints.\n\nCo-Authored-By: Adam Young <ayoung@redhat.com>\nCo-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86'}, {'number': 10, 'created': '2014-08-12 17:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/d0ab54ff4ddced4f89ebbfd53097b85b6397dbce', 'message': 'Endpoint policy extension\n\nProvide the ability to associate a given policy file with an endpoint\nor set of enpoints.\n\nCo-Authored-By: Adam Young <ayoung@redhat.com>\nCo-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86\n'}, {'number': 11, 'created': '2014-08-12 23:17:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/06d39caaa59f03fe9e30462c3b4327c299da8079', 'message': 'Endpoint policy extension\n\nProvide the ability to associate a given policy file with an endpoint\nor set of endpoints.\n\nCo-Authored-By: Adam Young <ayoung@redhat.com>\nCo-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86\n'}, {'number': 12, 'created': '2014-08-13 20:51:12.000000000', 'files': ['specs/juno/endpoint-policy.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/785f83eb1eace264de9fe0579911ce5b1d869609', 'message': 'Endpoint policy extension\n\nProvide the ability to associate a given policy file with an endpoint\nor set of enpoints.\n\nCo-Authored-By: Adam Young <ayoung@redhat.com>\nCo-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>\n\nChange-Id: I8ddf845038d8d4aac2321888d18196565678dc86\n'}]",82,99842,785f83eb1eace264de9fe0579911ce5b1d869609,83,15,12,2218,,,0,"Endpoint policy extension

Provide the ability to associate a given policy file with an endpoint
or set of enpoints.

Co-Authored-By: Adam Young <ayoung@redhat.com>
Co-Authored-By: Henry Nash <henryn@linux.vnet.ibm.com>

Change-Id: I8ddf845038d8d4aac2321888d18196565678dc86
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/42/99842/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/endpoint-policy.rst'],1,fe5a156084e8a718439beb7e71ea3e7e9dd2c6a6,endpoint_policy,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== `bp example <https://blueprints.launchpad.net/keystone/+spec/endpoint-policy>`_ Extension OS-POLICY Provides the means to assign policy files to specific endpoint, or to all endpoints for a specific services. This extension requires v3.X of the Identity API. Problem Description =================== Allow policy to vary between endpoints. Make it possible for an endpoint to fetch the policy relevant to itself. Proposed Change =============== After upload of policy, an admin will associate a policy file with and endpoint or a service. The user associated with that endpoint will be able to get a token for a project, and the endpoint can fetch the policy relevant to that project. Alternatives ------------ None. Canot be done today Data Model Impact ----------------- Endpoint and Services will need an extra field policy_id: default to None REST API Impact --------------- PROPOSAL: The API calls are: API The following additional APIs are supported by this extension: Assign policy file to all endpoints for a services : PUT /OS-POLICY/service/{service_id}/policy/{policy_id} The policy file role is applied to all endpoints for that service Response: Status: 204 No Content Assign a policy file to a specific endpoint for a service. If a policy file already covers a service, this specific rule takes priority. PUT /OS-POLICY/endpoint/{endpoint_id}/policy/{policy_id} The policy file role is applied to the specific endpoint Response: Status: 204 No Content Get a policy file for an endpoint GET /OS-POLICY/endpoint/{endpoint_id} The response contains the content that would also be returned by GET /v3/policy/{policy_id} for the policy file associated with the endpoint. If no specific policy file has been assigned to that endpoint, the response contains the policy file assigned to the service_id for the specified endpoint. Response: Status: 200 OK (Copy from policy exmaple in V3 API) Check if an endpoint has a poicy file HEAD /OS-POLICY/endpoint/{endpoint_id} Response: Status: 204 No Content GET /OS-POLICY/project/{project_id} Status: 200 OK Response will contain the set of policy rules that apply to that project. See policy.json in Keystone for format, Status: 409 Conflict If multiple policy files specify the same rule, and that rule differs, the policy for the project is invalid and cannot be downloaded. The response will provide the equivalent of a git conflict showing where two rules do not agree. Security Impact --------------- Policy will need to be better tested Notifications Impact -------------------- All policy changes shouldbe auditable events Other End User Impact --------------------- Client changes to fetch. Auth token middleware will need to consume. Performance Impact ------------------ Negligable. Policy will be fetched infrequently. Other Deployer Impact --------------------- Remoted service will need to change to take advantage of this feature. Developer Impact ---------------- Client changes required. Policy should be enofroces by keystone client to make max use. Implementation ============== Assignee(s) ----------- Primary assignee: ayoung Work Items ---------- Dependencies ============ Testing ======= Documentation Impact ==================== References ========== ",,176,0
openstack%2Fdjango_openstack_auth~master~I266ff7740cae49c2c33b8536bbdd52db97b9dabc,openstack/django_openstack_auth,master,I266ff7740cae49c2c33b8536bbdd52db97b9dabc,Updated from global requirements,MERGED,2014-08-13 23:18:26.000000000,2014-08-15 07:49:40.000000000,2014-08-15 07:49:40.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-08-13 23:18:26.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/41f868edaab2c9979459c338dde4b02e5f033f15', 'message': 'Updated from global requirements\n\nChange-Id: I266ff7740cae49c2c33b8536bbdd52db97b9dabc\n'}]",0,114055,41f868edaab2c9979459c338dde4b02e5f033f15,11,3,1,11131,,,0,"Updated from global requirements

Change-Id: I266ff7740cae49c2c33b8536bbdd52db97b9dabc
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/55/114055/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,41f868edaab2c9979459c338dde4b02e5f033f15,openstack/requirements,"Django>=1.4.2,<1.7","Django>=1.4,<1.7",1,1
openstack%2Fnova~master~Ic302943500dec68eb7dcbd8f167b44edbe7aaf46,openstack/nova,master,Ic302943500dec68eb7dcbd8f167b44edbe7aaf46,Volume create time rounded off for consistency,ABANDONED,2014-05-06 09:19:11.000000000,2014-08-15 07:47:24.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1247}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5538}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-06 09:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f9e95ab15db9619cee06657fcc08c053a847e82', 'message': ""Volume create time rounded off to consistency with get volume create time\n\nCreate volume returns the volume create time as 'yyyy-mm-ddThh:mm:ss.ssssss'.\nBut the get volume shows the create time as 'yyyy-mm-ddThh:mm:ss.000000'.\nTo be consistency with get volume create time, rounded off the create volume\ntime as 'yyyy-mm-ddThh:mm:ss.000000' before return statement of create_volume\nfunction.\n\nCloses-bug #1280948\n\nChange-Id: Ic302943500dec68eb7dcbd8f167b44edbe7aaf46\n""}, {'number': 2, 'created': '2014-05-09 13:47:35.000000000', 'files': ['nova/api/ec2/cloud.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1de3a8a49d1d8652218787de92c70f67c838fb10', 'message': ""Volume create time rounded off for consistency\n\nCreate volume returns the volume create time as\n'yyyy-mm-ddThh:mm:ss.ssssss'. But the get volume\nshows the create time as 'yyyy-mm-ddThh:mm:ss.000000'.\n\nTo be consistency with get volume create time, rounded off\nthe create volume time as 'yyyy-mm-ddThh:mm:ss.000000'\nbefore return statement of create_volume function.\n\nCloses-bug #1280948\n\nChange-Id: Ic302943500dec68eb7dcbd8f167b44edbe7aaf46\n""}]",3,92322,1de3a8a49d1d8652218787de92c70f67c838fb10,26,11,2,11224,,,0,"Volume create time rounded off for consistency

Create volume returns the volume create time as
'yyyy-mm-ddThh:mm:ss.ssssss'. But the get volume
shows the create time as 'yyyy-mm-ddThh:mm:ss.000000'.

To be consistency with get volume create time, rounded off
the create volume time as 'yyyy-mm-ddThh:mm:ss.000000'
before return statement of create_volume function.

Closes-bug #1280948

Change-Id: Ic302943500dec68eb7dcbd8f167b44edbe7aaf46
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/92322/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/ec2/cloud.py'],1,6f9e95ab15db9619cee06657fcc08c053a847e82,bug/1280948," # Fix nova/ec2 bug #1280948(Volume create time rounded off). # To be consistency with DB storage of volume create_time, here, # the volume[created_at] rounded off from 'yyyy-mm-ddThh:mm:ss.ssssss' # to 'yyyy-mm-ddThh:mm:ss.000000' before return statement. volume['created_at'] = volume['created_at'][:20] + '000000' ",,7,0
openstack%2Fopenstack-manuals~master~I8694f063e3dce09781d01dc193d9155a45197da6,openstack/openstack-manuals,master,I8694f063e3dce09781d01dc193d9155a45197da6,Imported Translations from Transifex,MERGED,2014-08-10 06:10:04.000000000,2014-08-15 07:40:31.000000000,2014-08-15 07:40:30.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-10 06:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cf4e34f33895c471659053f1dfb93f3f2da7ceef', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8694f063e3dce09781d01dc193d9155a45197da6\n'}, {'number': 2, 'created': '2014-08-11 06:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4c2fabc585556b85de6922034aecc87c5a89c937', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8694f063e3dce09781d01dc193d9155a45197da6\n'}, {'number': 3, 'created': '2014-08-12 06:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8f3e8537153f083692c9c295df8898e1d2299f28', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8694f063e3dce09781d01dc193d9155a45197da6\n'}, {'number': 4, 'created': '2014-08-13 06:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/df76a702f012a97549e065fc6d47f60cfd2b960e', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8694f063e3dce09781d01dc193d9155a45197da6\n'}, {'number': 5, 'created': '2014-08-14 06:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4c635cd26c3ae037781c211ab9888a95d64d7020', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8694f063e3dce09781d01dc193d9155a45197da6\n'}, {'number': 6, 'created': '2014-08-15 06:10:13.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/user-guide/locale/ja.po', 'doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/user-guide/locale/fr.po', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/glossary/locale/de.po', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/user-guide-admin/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/cli-reference/locale/cli-reference.pot', 'doc/common/locale/fr.po', 'doc/glossary/locale/glossary.pot', 'doc/networking-guide/locale/networking-guide.pot', 'doc/high-availability-guide/locale/ja.po', 'doc/user-guide-admin/locale/user-guide-admin.pot', 'doc/glossary/locale/ko_KR.po', 'doc/image-guide/locale/fr.po', 'doc/glossary/locale/ja.po', 'doc/image-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/57fd5becf408dcf699e1c614335a08f9da6fde4c', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8694f063e3dce09781d01dc193d9155a45197da6\n'}]",0,113113,57fd5becf408dcf699e1c614335a08f9da6fde4c,26,3,6,11131,,,0,"Imported Translations from Transifex

Change-Id: I8694f063e3dce09781d01dc193d9155a45197da6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/13/113113/6 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/user-guide/locale/ja.po', 'doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/user-guide/locale/fr.po', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/glossary/locale/de.po', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/user-guide-admin/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/common/locale/fr.po', 'doc/glossary/locale/glossary.pot', 'doc/networking-guide/locale/networking-guide.pot', 'doc/user-guide-admin/locale/user-guide-admin.pot', 'doc/glossary/locale/ko_KR.po', 'doc/glossary/locale/ja.po', 'doc/image-guide/locale/ja.po']",20,cf4e34f33895c471659053f1dfb93f3f2da7ceef,transifex/translations,"""POT-Creation-Date: 2014-08-09 21:18+0000\n"" ""PO-Revision-Date: 2014-08-09 16:12+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""#: ./doc/image-guide/section_centos-example.xml71(None) #: ./doc/image-guide/section_centos-example.xml74(None)#: ./doc/image-guide/section_centos-example.xml84(None)#: ./doc/image-guide/section_centos-example.xml93(None)#: ./doc/image-guide/section_centos-example.xml106(None)#: ./doc/image-guide/section_centos-example.xml157(None)msgid ""Assume that:"" msgstr """"""The name of your virtual machine image is <literal>centos-6.4</literal>; you"" "" need this name when you use <placeholder-1/> commands to manipulate the "" ""state of the image."" msgstr """" #: ./doc/image-guide/section_centos-example.xml50(para) msgid """" ""You saved the netinstall ISO image to the <filename>/data/isos</filename> "" ""directory."" msgstr """" #: ./doc/image-guide/section_centos-example.xml53(para) msgid """"#: ./doc/image-guide/section_centos-example.xml65(title) #: ./doc/image-guide/section_centos-example.xml146(title)#: ./doc/image-guide/section_centos-example.xml66(para)#: ./doc/image-guide/section_centos-example.xml79(title)#: ./doc/image-guide/section_centos-example.xml80(para)#: ./doc/image-guide/section_centos-example.xml89(title)#: ./doc/image-guide/section_centos-example.xml90(para)#: ./doc/image-guide/section_centos-example.xml96(para)#: ./doc/image-guide/section_centos-example.xml101(para)#: ./doc/image-guide/section_centos-example.xml109(para)#: ./doc/image-guide/section_centos-example.xml113(para)#: ./doc/image-guide/section_centos-example.xml116(para)#: ./doc/image-guide/section_centos-example.xml119(para)#: ./doc/image-guide/section_centos-example.xml124(title)#: ./doc/image-guide/section_centos-example.xml125(para)#: ./doc/image-guide/section_centos-example.xml129(title)#: ./doc/image-guide/section_centos-example.xml130(para)#: ./doc/image-guide/section_centos-example.xml136(title)#: ./doc/image-guide/section_centos-example.xml137(para)#: ./doc/image-guide/section_centos-example.xml142(para)#: ./doc/image-guide/section_centos-example.xml147(para)#: ./doc/image-guide/section_centos-example.xml152(title)#: ./doc/image-guide/section_centos-example.xml153(para)#: ./doc/image-guide/section_centos-example.xml163(replaceable) #: ./doc/image-guide/section_centos-example.xml322(replaceable)#: ./doc/image-guide/section_centos-example.xml160(para)#: ./doc/image-guide/section_centos-example.xml177(para)#: ./doc/image-guide/section_centos-example.xml185(title)#: ./doc/image-guide/section_centos-example.xml186(para)#: ./doc/image-guide/section_centos-example.xml190(title)#: ./doc/image-guide/section_centos-example.xml191(para)#: ./doc/image-guide/section_centos-example.xml195(para)#: ./doc/image-guide/section_centos-example.xml202(title)#: ./doc/image-guide/section_centos-example.xml203(para)#: ./doc/image-guide/section_centos-example.xml208(para)#: ./doc/image-guide/section_centos-example.xml213(para)#: ./doc/image-guide/section_centos-example.xml219(title)#: ./doc/image-guide/section_centos-example.xml220(para)#: ./doc/image-guide/section_centos-example.xml226(para)#: ./doc/image-guide/section_centos-example.xml229(para)#: ./doc/image-guide/section_centos-example.xml237(title)#: ./doc/image-guide/section_centos-example.xml238(para)#: ./doc/image-guide/section_centos-example.xml266(para)#: ./doc/image-guide/section_centos-example.xml274(para)#: ./doc/image-guide/section_centos-example.xml278(para)#: ./doc/image-guide/section_centos-example.xml285(title)#: ./doc/image-guide/section_centos-example.xml286(para)#: ./doc/image-guide/section_centos-example.xml291(title)#: ./doc/image-guide/section_centos-example.xml292(para)#: ./doc/image-guide/section_centos-example.xml298(replaceable)#: ./doc/image-guide/section_centos-example.xml301(title)#: ./doc/image-guide/section_centos-example.xml302(para)#: ./doc/image-guide/section_centos-example.xml306(title)#: ./doc/image-guide/section_centos-example.xml307(para)#: ./doc/image-guide/section_centos-example.xml313(para)#: ./doc/image-guide/section_centos-example.xml319(title)#: ./doc/image-guide/section_centos-example.xml320(para)#: ./doc/image-guide/section_centos-example.xml326(title)#: ./doc/image-guide/section_centos-example.xml327(para)","""POT-Creation-Date: 2014-08-05 15:21+0000\n"" ""PO-Revision-Date: 2014-08-06 05:30+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""#: ./doc/image-guide/section_centos-example.xml62(None) #: ./doc/image-guide/section_centos-example.xml65(None)#: ./doc/image-guide/section_centos-example.xml75(None)#: ./doc/image-guide/section_centos-example.xml84(None)#: ./doc/image-guide/section_centos-example.xml97(None)#: ./doc/image-guide/section_centos-example.xml148(None)msgid """" ""Assume that the name of your virtual machine image is "" ""<literal>centos-6.4</literal>; you need this name when you use "" ""<placeholder-1/> commands to manipulate the state of the image."" msgstr ""仮想マシンイメージの名前が <literal>centos-6.4</literal> であると仮定します。イメージを操作するために、<placeholder-1/> コマンドを使用する際に、この名前が必要になります。""#: ./doc/image-guide/section_centos-example.xml56(title) #: ./doc/image-guide/section_centos-example.xml137(title)#: ./doc/image-guide/section_centos-example.xml57(para)#: ./doc/image-guide/section_centos-example.xml70(title)#: ./doc/image-guide/section_centos-example.xml71(para)#: ./doc/image-guide/section_centos-example.xml80(title)#: ./doc/image-guide/section_centos-example.xml81(para)#: ./doc/image-guide/section_centos-example.xml87(para)#: ./doc/image-guide/section_centos-example.xml92(para)#: ./doc/image-guide/section_centos-example.xml100(para)#: ./doc/image-guide/section_centos-example.xml104(para)#: ./doc/image-guide/section_centos-example.xml107(para)#: ./doc/image-guide/section_centos-example.xml110(para)#: ./doc/image-guide/section_centos-example.xml115(title)#: ./doc/image-guide/section_centos-example.xml116(para)#: ./doc/image-guide/section_centos-example.xml120(title)#: ./doc/image-guide/section_centos-example.xml121(para)#: ./doc/image-guide/section_centos-example.xml127(title)#: ./doc/image-guide/section_centos-example.xml128(para)#: ./doc/image-guide/section_centos-example.xml133(para)#: ./doc/image-guide/section_centos-example.xml138(para)#: ./doc/image-guide/section_centos-example.xml143(title)#: ./doc/image-guide/section_centos-example.xml144(para)#: ./doc/image-guide/section_centos-example.xml154(replaceable) #: ./doc/image-guide/section_centos-example.xml313(replaceable)#: ./doc/image-guide/section_centos-example.xml151(para)#: ./doc/image-guide/section_centos-example.xml168(para)#: ./doc/image-guide/section_centos-example.xml176(title)#: ./doc/image-guide/section_centos-example.xml177(para)#: ./doc/image-guide/section_centos-example.xml181(title)#: ./doc/image-guide/section_centos-example.xml182(para)#: ./doc/image-guide/section_centos-example.xml186(para)#: ./doc/image-guide/section_centos-example.xml193(title)#: ./doc/image-guide/section_centos-example.xml194(para)#: ./doc/image-guide/section_centos-example.xml199(para)#: ./doc/image-guide/section_centos-example.xml204(para)#: ./doc/image-guide/section_centos-example.xml210(title)#: ./doc/image-guide/section_centos-example.xml211(para)#: ./doc/image-guide/section_centos-example.xml217(para)#: ./doc/image-guide/section_centos-example.xml220(para)#: ./doc/image-guide/section_centos-example.xml228(title)#: ./doc/image-guide/section_centos-example.xml229(para)#: ./doc/image-guide/section_centos-example.xml257(para)#: ./doc/image-guide/section_centos-example.xml265(para)#: ./doc/image-guide/section_centos-example.xml269(para)#: ./doc/image-guide/section_centos-example.xml276(title)#: ./doc/image-guide/section_centos-example.xml277(para)#: ./doc/image-guide/section_centos-example.xml282(title)#: ./doc/image-guide/section_centos-example.xml283(para)#: ./doc/image-guide/section_centos-example.xml289(replaceable)#: ./doc/image-guide/section_centos-example.xml292(title)#: ./doc/image-guide/section_centos-example.xml293(para)#: ./doc/image-guide/section_centos-example.xml297(title)#: ./doc/image-guide/section_centos-example.xml298(para)#: ./doc/image-guide/section_centos-example.xml304(para)#: ./doc/image-guide/section_centos-example.xml310(title)#: ./doc/image-guide/section_centos-example.xml311(para)#: ./doc/image-guide/section_centos-example.xml317(title)#: ./doc/image-guide/section_centos-example.xml318(para)",14446,13519
openstack%2Fmanila~master~I32403890e190969657ae813e7d3e34a951030321,openstack/manila,master,I32403890e190969657ae813e7d3e34a951030321,Remove manila-clear-rabbit-queues,MERGED,2014-08-14 11:15:37.000000000,2014-08-15 07:34:24.000000000,2014-08-15 07:34:24.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-08-14 11:15:37.000000000', 'files': ['bin/manila-clear-rabbit-queues', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/manila/commit/086d3bd69bfa6de25e52fe0b2fe6278dcaa9f149', 'message': 'Remove manila-clear-rabbit-queues\n\nThis script should be removed because it does not\nappear to be widely used and there is no user documentation for\nit. Also, RabbitMQ now includes a management plugin and CLI,\nrabbitmqadmin, that allows you to delete queues and exchanges.\n\nFor reference, this removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\nand removed from cinder:\nhttps://review.openstack.org/#/c/109786/\n\nChange-Id: I32403890e190969657ae813e7d3e34a951030321\n'}]",0,114202,086d3bd69bfa6de25e52fe0b2fe6278dcaa9f149,8,4,1,6547,,,0,"Remove manila-clear-rabbit-queues

This script should be removed because it does not
appear to be widely used and there is no user documentation for
it. Also, RabbitMQ now includes a management plugin and CLI,
rabbitmqadmin, that allows you to delete queues and exchanges.

For reference, this removed in nova as part of
https://review.openstack.org/#/c/40355/.

and removed from cinder:
https://review.openstack.org/#/c/109786/

Change-Id: I32403890e190969657ae813e7d3e34a951030321
",git fetch https://review.opendev.org/openstack/manila refs/changes/02/114202/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/manila-clear-rabbit-queues', 'setup.cfg']",2,086d3bd69bfa6de25e52fe0b2fe6278dcaa9f149,rm-clear-rabbit-queue,, bin/manila-clear-rabbit-queues,0,77
openstack%2Fmanila~master~I183eefc2ff13ed019ab2a041658e6d71a1fa1f57,openstack/manila,master,I183eefc2ff13ed019ab2a041658e6d71a1fa1f57,Flake8 in bin/*,MERGED,2014-08-14 11:20:32.000000000,2014-08-15 07:31:59.000000000,2014-08-15 07:31:58.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-08-14 11:20:32.000000000', 'files': ['bin/manila-all', 'bin/manila-scheduler', 'bin/manila-api', 'bin/manila-share', 'bin/manila-manage'], 'web_link': 'https://opendev.org/openstack/manila/commit/94a3b20ff90ebcbe8cc1a8d07cae5b1820e67f47', 'message': 'Flake8 in bin/*\n\nAddress flake8 issues in the bin directory:\n* wrong indents\n* Unneeded imports\n\nChange-Id: I183eefc2ff13ed019ab2a041658e6d71a1fa1f57\n'}]",0,114204,94a3b20ff90ebcbe8cc1a8d07cae5b1820e67f47,8,4,1,6547,,,0,"Flake8 in bin/*

Address flake8 issues in the bin directory:
* wrong indents
* Unneeded imports

Change-Id: I183eefc2ff13ed019ab2a041658e6d71a1fa1f57
",git fetch https://review.opendev.org/openstack/manila refs/changes/04/114204/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/manila-all', 'bin/manila-scheduler', 'bin/manila-api', 'bin/manila-share', 'bin/manila-manage']",5,94a3b20ff90ebcbe8cc1a8d07cae5b1820e67f47,pep8-bin, version=version.version_string()),"import uuid from sqlalchemy import create_engine, MetaData, Table from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmakerfrom manila import exception version=version.version_string())",13,18
openstack%2Ftripleo-incubator~master~I9fccd8ed2c0798f54443159e499663f37c0a588f,openstack/tripleo-incubator,master,I9fccd8ed2c0798f54443159e499663f37c0a588f,Use percona on debian systems,ABANDONED,2014-07-24 21:10:48.000000000,2014-08-15 07:24:39.000000000,,"[{'_account_id': 3}, {'_account_id': 6969}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-07-24 21:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/b57cfca70884f226c842927ff3449d0291131629', 'message': 'Use percona on debian systems\n\nAs per the thread: http://lists.openstack.org/pipermail/openstack-dev/2014-June/037864.html\nthis patch configures debian systems to use percona debian packages.\n\nPercona debian packages are directly included in trusty repositories.\n\nRelies on: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n\nChange-Id: I9fccd8ed2c0798f54443159e499663f37c0a588f\n'}, {'number': 2, 'created': '2014-08-07 10:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f3228817dbc9e34ce383ba2770c1bebbe01ab3f9', 'message': 'Use percona on debian systems\n\nAs per the thread: http://lists.openstack.org/pipermail/openstack-dev/2014-June/037864.html\nthis patch configures debian systems to use percona debian packages.\n\nPercona debian packages are directly included in trusty repositories.\n\nRelies on: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n\nChange-Id: I9fccd8ed2c0798f54443159e499663f37c0a588f\n'}, {'number': 3, 'created': '2014-08-13 15:34:14.000000000', 'files': ['scripts/devtest_undercloud.sh', 'scripts/devtest_variables.sh', 'scripts/devtest_overcloud.sh', 'scripts/boot-seed-vm'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/4d04c14c8b6783eb8f1e3a080c506d5c9c97827d', 'message': 'Use percona on debian systems\n\nAs per the thread: http://lists.openstack.org/pipermail/openstack-dev/2014-June/037864.html\nthis patch configures debian systems to use percona debian packages.\n\nPercona debian packages are directly included in trusty repositories.\n\nRelies on: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9\n\nChange-Id: I9fccd8ed2c0798f54443159e499663f37c0a588f\n'}]",2,109415,4d04c14c8b6783eb8f1e3a080c506d5c9c97827d,19,3,3,6969,,,0,"Use percona on debian systems

As per the thread: http://lists.openstack.org/pipermail/openstack-dev/2014-June/037864.html
this patch configures debian systems to use percona debian packages.

Percona debian packages are directly included in trusty repositories.

Relies on: Ie13bf0f7a972ed7f69623c9a661065b46441c3e9

Change-Id: I9fccd8ed2c0798f54443159e499663f37c0a588f
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/15/109415/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/devtest_undercloud.sh', 'scripts/devtest_variables.sh', 'scripts/devtest_overcloud.sh', 'scripts/boot-seed-vm']",4,b57cfca70884f226c842927ff3449d0291131629,use-percona,"elif [ ""$USE_PERCONA"" -eq 1 ] ; then SEED_DIB_EXTRA_ARGS=""$SEED_DIB_EXTRA_ARGS percona-deb""",,12,0
openstack%2Foperations-guide~master~I49837570ac8568c9cb1beffa491057b027fac4d8,openstack/operations-guide,master,I49837570ac8568c9cb1beffa491057b027fac4d8,Imported Translations from Transifex,MERGED,2014-08-15 06:01:03.000000000,2014-08-15 07:17:30.000000000,2014-08-15 07:17:30.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-15 06:01:03.000000000', 'files': ['doc/openstack-ops/locale/openstack-ops.pot'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/87eef831d966096bec7ed7b0e0af6d5613fa8d37', 'message': 'Imported Translations from Transifex\n\nChange-Id: I49837570ac8568c9cb1beffa491057b027fac4d8\n'}]",0,114439,87eef831d966096bec7ed7b0e0af6d5613fa8d37,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I49837570ac8568c9cb1beffa491057b027fac4d8
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/39/114439/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/locale/openstack-ops.pot'],1,87eef831d966096bec7ed7b0e0af6d5613fa8d37,transifex/translations,"""POT-Creation-Date: 2014-08-15 06:01+0000\n""#: ./doc/openstack-ops/part_architecture.xml:82(None) msgid ""@@image: 'figures/osog_0001.png'; md5=a7205423d6b8a8fb47e7f8387b65a87e""msgid ""As shown, end users can interact through the dashboard, CLIs, and APIs. All services authenticate through a common Identity Service, and individual services interact with each other through public APIs, except where privileged administrator commands are necessary. <xref linkend=\""openstack-diagram\""/> shows the most common, but not the only logical architecture for an OpenStack cloud.""#: ./doc/openstack-ops/part_architecture.xml:77(title) msgid ""OpenStack Logical Architecture (<link href=\""http://docs.openstack.org/openstack-ops/content/figures/2/figures/osog_0001.png\""/>)""","""POT-Creation-Date: 2014-08-13 06:01+0000\n""#: ./doc/openstack-ops/part_architecture.xml:83(None) msgid ""@@image: 'figures/osog_0001.png'; md5=c9f3718b9a5ec35ab62dd8d725d26b98""msgid ""As shown, end users can interact through the dashboard, CLIs, and APIs. All services authenticate through a common Identity Service, and individual services interact with each other through public APIs, except where privileged administrator commands are necessary. <xref linkend=\""openstack-havana-diagram\""/> shows the most common, but not the only logical architecture for an OpenStack cloud.""#: ./doc/openstack-ops/part_architecture.xml:78(title) msgid ""OpenStack Havana Logical Architecture (<link href=\""http://docs.openstack.org/openstack-ops/content/figures/2/figures/osog_0001.png\""/>)""",6,6
openstack%2Fdevstack~master~I063995d52b66e4023e360ba423684753e50a291c,openstack/devstack,master,I063995d52b66e4023e360ba423684753e50a291c,Hide output when configuring apt retry,MERGED,2014-06-30 12:55:20.000000000,2014-08-15 07:16:18.000000000,2014-08-15 07:16:18.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-30 12:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7416aacc2e46399c34b5e7d8bf96c10c25f09881', 'message': 'Hide output when configuring apt retry\n\nChange-Id: I063995d52b66e4023e360ba423684753e50a291c\n'}, {'number': 2, 'created': '2014-07-03 08:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5691aa3fddd41446d45d21e0147d901ead513261', 'message': 'Hide output when configuring apt retry\n\nChange-Id: I063995d52b66e4023e360ba423684753e50a291c\n'}, {'number': 3, 'created': '2014-08-05 12:44:07.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/9246d96e5c56e1b19e43e4c48c76577dcb77e4cc', 'message': 'Hide output when configuring apt retry\n\nChange-Id: I063995d52b66e4023e360ba423684753e50a291c\n'}]",0,103539,9246d96e5c56e1b19e43e4c48c76577dcb77e4cc,38,7,3,866,,,0,"Hide output when configuring apt retry

Change-Id: I063995d52b66e4023e360ba423684753e50a291c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/39/103539/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,7416aacc2e46399c34b5e7d8bf96c10c25f09881,hide-stdout," echo 'APT::Acquire::Retries ""20"";' | sudo tee /etc/apt/apt.conf.d/80retry >/dev/null"," echo 'APT::Acquire::Retries ""20"";' | sudo tee /etc/apt/apt.conf.d/80retry",1,1
openstack%2Fsecurity-doc~master~Ic274246ecbdad5b1d9a21890da02ad6f592a4e13,openstack/security-doc,master,Ic274246ecbdad5b1d9a21890da02ad6f592a4e13,Imported Translations from Transifex,MERGED,2014-08-15 06:05:56.000000000,2014-08-15 07:14:32.000000000,2014-08-15 07:14:32.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-15 06:05:56.000000000', 'files': ['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/33640c6915c8f5da581de289f6dfe760036bd39a', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic274246ecbdad5b1d9a21890da02ad6f592a4e13\n'}]",0,114441,33640c6915c8f5da581de289f6dfe760036bd39a,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Ic274246ecbdad5b1d9a21890da02ad6f592a4e13
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/41/114441/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po']",2,33640c6915c8f5da581de289f6dfe760036bd39a,transifex/translations,"""POT-Creation-Date: 2014-08-14 08:18+0000\n"" ""PO-Revision-Date: 2014-08-14 08:18+0000\n""#: ./security-guide/section_hardening-the-virtualization-layers.xml323(None) #: ./security-guide/section_hardening-the-virtualization-layers.xml327(None)""Therefore, it is important to take proactive steps to harden QEMU. Three "" ""specific steps are recommended: minimizing the code base, using compiler "" ""hardening, and using mandatory access controls such as sVirt, SELinux, or "" ""AppArmor."" msgstr """"""The following compiler options are recommend for GCC when compiling QEMU:"" msgstr """"""to run each QEMU process under a separate security context. AppArmor can be "" ""configured to provide similar functionality. We provide more details on "" ""sVirt and instance isolation in the <link linkend=\""hardening-the-"" ""virtualization-layers-idp510512\"">section below</link>."" msgstr """" #: ./security-guide/section_hardening-the-virtualization-layers.xml260(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml261(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml272(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml279(term) msgid ""Hypervisor threats"" msgstr """" #: ./security-guide/section_hardening-the-virtualization-layers.xml281(para)""A compromised application running within a virtual machine attacks the "" ""hypervisor to access underlying resources. For example, when a virtual "" ""machine is able to access the hypervisor OS, physical devices, or other "" ""applications. This threat vector represents considerable risk as a "" ""compromise on a hypervisor can infect the physical hardware as well as "" ""exposing other virtual machines and network segments."" msgstr """" #: ./security-guide/section_hardening-the-virtualization-layers.xml294(term) msgid ""Virtual Machine (multi-tenant) threats"" msgstr """" #: ./security-guide/section_hardening-the-virtualization-layers.xml296(para) msgid """" ""A compromised application running within a VM attacks the hypervisor to "" ""access or control another virtual machine and its resources. This is a "" ""threat vector unique to virtualization and represents considerable risk as a"" "" multitude of virtual machine file images could be compromised due to ""msgstr """" #: ./security-guide/section_hardening-the-virtualization-layers.xml311(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml331(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml340(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml341(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml352(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml361(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml366(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml367(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml371(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml379(emphasis)#: ./security-guide/section_hardening-the-virtualization-layers.xml380(emphasis)#: ./security-guide/section_hardening-the-virtualization-layers.xml385(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml386(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml389(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml390(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml393(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml394(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml397(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml398(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml401(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml402(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml405(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml406(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml409(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml410(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml413(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml414(para)","""POT-Creation-Date: 2014-08-13 12:36+0000\n"" ""PO-Revision-Date: 2014-08-13 12:37+0000\n""#: ./security-guide/section_hardening-the-virtualization-layers.xml310(None) #: ./security-guide/section_hardening-the-virtualization-layers.xml314(None)""For the reasons stated above, it is important to take proactive steps to "" ""harden QEMU. We recommend three specific steps: minimizing the code base, "" ""using compiler hardening, and using mandatory access controls, such as "" ""sVirt, SELinux, or AppArmor."" msgstr ""上記の理由として、QEMU 堅牢化の率先したステップの実行が重要である事が挙げられます。我々は３つの特定のステップを推奨しています。コードベースの最小化、コンパイラーの堅牢化、sVirt・SELinux・AppArmor 等の強制アクセス制御の使用です。""""Putting this all together, and adding in some additional useful protections,"" "" we recommend the following compiler options for GCC when compiling QEMU:"" msgstr ""すべてを一緒に利用し、いくつか追加の有用な保護を追加して、QEMU コンパイル時に以下の GCC コンパイラーオプションを推奨します。""""to run every QEMU process under a different security context. AppArmor can "" ""be configured to provide similar functionality. We provide more details on "" ""sVirt in the instance isolation section below."" msgstr ""コンパイラーのセキュリティ強化機能により、QEMU プロセスへの攻撃をより難しくできます。しかし、攻撃者が成功すると、攻撃の影響範囲を抑えたいでしょう。強制アクセス制御は、QEMU プロセスの権限を必要な範囲に制限することにより、これを実現します。これは sVirt / SELinux または AppArmor により実現できます。sVirt 利用時、SELinux はすべての QEMU プロセスが別々のセキュリティドメインで動作するよう設定されます。AppArmor は同様の機能を提供するよう設定できます。以下のインスタンス分離のセクションで sVirt の詳細を示します。"" #: ./security-guide/section_hardening-the-virtualization-layers.xml258(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml259(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml270(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml275(para) msgid """" ""<emphasis role=\""bold\"">Hypervisor threats</emphasis> A compromised "" ""application running within a virtual machine attacks the hypervisor to "" ""access underlying resources. For example, the host OS, applications, or "" ""devices within the physical machine. This is a threat vector unique to "" ""virtualization and represents considerable risk as the underlying real "" ""machine can be compromised due to vulnerability in a single virtual "" ""application."" msgstr ""<emphasis role=\""bold\"">ハイパーバイザーの脅威</emphasis> 仮想マシンの中で動作している侵入されたアプリケーションは、バックエンドのリソースにアクセスするためにハイパーバイザーを攻撃します。例えば、ホスト OS、アプリケーション、物理マシンにあるデバイスです。バックエンドの物理マシンが単一の仮想アプリケーションにある脆弱性のために侵入されうるため、これは仮想化に特有の脅威ベクターであり、考慮すべきリスクを表します。"" #: ./security-guide/section_hardening-the-virtualization-layers.xml285(para)""<emphasis role=\""bold\"">Virtual Machine (multi-tenant) threats</emphasis> A "" ""compromised application running within a VM attacks the hypervisor to "" ""access/control another virtual machine and its resources. This is a threat "" ""vector unique to virtualization and represents considerable risk as a "" ""multitude of virtual machine file images could be compromised due to ""msgstr ""<emphasis role=\""bold\"">仮想マシン (マルチテナント) の脅威</emphasis> 仮想マシンの中で動作している侵入されたアプリケーションは、他の仮想マシンとそのリソースにアクセスし、制御するためにハイパーバイザーを攻撃します。仮想マシンのイメージファイルの集合が単一のアプリケーションにある脆弱性のために侵入されうるため、これは仮想化に特有の脅威ベクターであり、考慮すべきリスクを表します。実ネットワークを保護するための管理技術が仮想マシン環境にそのまま適用できないため、この仮想ネットワークへの攻撃はおもな関心事です。"" #: ./security-guide/section_hardening-the-virtualization-layers.xml298(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml318(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml327(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml328(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml339(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml348(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml353(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml354(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml358(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml366(emphasis)#: ./security-guide/section_hardening-the-virtualization-layers.xml367(emphasis)#: ./security-guide/section_hardening-the-virtualization-layers.xml372(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml373(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml376(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml377(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml380(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml381(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml384(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml385(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml388(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml389(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml392(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml393(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml396(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml397(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml400(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml401(para)",116,102
openstack%2Fneutron~master~I37cfe2bb531a3f5015e729bed93d6a59d7d9c15d,openstack/neutron,master,I37cfe2bb531a3f5015e729bed93d6a59d7d9c15d,Fix duplicate function: test_getattr_unallowed_attr,MERGED,2014-08-13 05:52:05.000000000,2014-08-15 07:09:31.000000000,2014-08-15 07:09:30.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-08-13 05:52:05.000000000', 'files': ['neutron/tests/unit/agent/linux/test_ovs_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/754b1dd445858cf7d71a7b450e2c9ac7e2cf76b9', 'message': 'Fix duplicate function: test_getattr_unallowed_attr\n\nThis meant only one of the two test cases was ever being run.  Renamed\none.\n\nChange-Id: I37cfe2bb531a3f5015e729bed93d6a59d7d9c15d\n'}]",0,113778,754b1dd445858cf7d71a7b450e2c9ac7e2cf76b9,26,18,1,11279,,,0,"Fix duplicate function: test_getattr_unallowed_attr

This meant only one of the two test cases was ever being run.  Renamed
one.

Change-Id: I37cfe2bb531a3f5015e729bed93d6a59d7d9c15d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/78/113778/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/agent/linux/test_ovs_lib.py'],1,754b1dd445858cf7d71a7b450e2c9ac7e2cf76b9,ovs-dup-test, def test_getattr_unallowed_attr_failure(self):, def test_getattr_unallowed_attr(self):,1,1
openstack%2Fpython-neutronclient~master~I4564d546ca269ab05199a51ffd11678237a4d56f,openstack/python-neutronclient,master,I4564d546ca269ab05199a51ffd11678237a4d56f,Fix typo in cli help,MERGED,2014-08-14 19:46:01.000000000,2014-08-15 07:09:23.000000000,2014-08-15 07:09:23.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2592}]","[{'number': 1, 'created': '2014-08-14 19:46:01.000000000', 'files': ['neutronclient/neutron/v2_0/floatingip.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/74968bd391f6b76356d5d326b77c9ad3ecd14ee7', 'message': 'Fix typo in cli help\n\nThe help message for neutron floatingip-disassociate should say\nthe argument is the ID of the floating IP to disassociate\n\nChange-Id: I4564d546ca269ab05199a51ffd11678237a4d56f\n'}]",0,114323,74968bd391f6b76356d5d326b77c9ad3ecd14ee7,8,3,1,7770,,,0,"Fix typo in cli help

The help message for neutron floatingip-disassociate should say
the argument is the ID of the floating IP to disassociate

Change-Id: I4564d546ca269ab05199a51ffd11678237a4d56f
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/23/114323/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/floatingip.py'],1,74968bd391f6b76356d5d326b77c9ad3ecd14ee7,fix_typo, help=_('ID of the floating IP to disassociate.')), help=_('ID of the floating IP to associate.')),1,1
openstack%2Fhorizon~master~Iee8601c5b0f831b2dd598accfdc58cb8130cca13,openstack/horizon,master,Iee8601c5b0f831b2dd598accfdc58cb8130cca13,Exception handling is captured correctly when deleting a container.,MERGED,2014-08-11 19:52:49.000000000,2014-08-15 06:56:24.000000000,2014-08-15 06:56:23.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 9531}]","[{'number': 1, 'created': '2014-08-11 19:52:49.000000000', 'files': ['openstack_dashboard/dashboards/project/containers/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7f795e8fab8c3f7cfb58c0b28abca96b1f24c613', 'message': 'Exception handling is captured correctly when deleting a container.\n\nWhen deleting a container that is not empty, the exception code\ndoes not send the error message through exception.handle. Instead,\nit raises an exception which causes an error when Horizon is no\nlonger in debug mode.\n\nChange-Id: Iee8601c5b0f831b2dd598accfdc58cb8130cca13\nCloses-bug: 1355405\n'}]",0,113363,7f795e8fab8c3f7cfb58c0b28abca96b1f24c613,11,4,1,8984,,,0,"Exception handling is captured correctly when deleting a container.

When deleting a container that is not empty, the exception code
does not send the error message through exception.handle. Instead,
it raises an exception which causes an error when Horizon is no
longer in debug mode.

Change-Id: Iee8601c5b0f831b2dd598accfdc58cb8130cca13
Closes-bug: 1355405
",git fetch https://review.opendev.org/openstack/horizon refs/changes/63/113363/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/containers/tables.py'],1,7f795e8fab8c3f7cfb58c0b28abca96b1f24c613,bug/1355405," except exceptions.Conflict as exc: exceptions.handle(request, exc, redirect=self.success_url)"," except exceptions.Conflict: messages.error(request, _(""The container cannot be deleted since "" ""it's not empty."")) raise exceptions.Http302(self.success_url)",2,4
openstack%2Ftraining-guides~master~I93816961c2fab884f34fd6f27ed7a6ea94694fb2,openstack/training-guides,master,I93816961c2fab884f34fd6f27ed7a6ea94694fb2,Imported Translations from Transifex,MERGED,2014-08-15 06:00:22.000000000,2014-08-15 06:23:30.000000000,2014-08-15 06:23:30.000000000,"[{'_account_id': 3}, {'_account_id': 9853}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-15 06:00:22.000000000', 'files': ['doc/training-guides/locale/training-guides.pot'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/ae267572b4029751416e962bd452d32bbfbdd784', 'message': 'Imported Translations from Transifex\n\nChange-Id: I93816961c2fab884f34fd6f27ed7a6ea94694fb2\n'}]",0,114438,ae267572b4029751416e962bd452d32bbfbdd784,7,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I93816961c2fab884f34fd6f27ed7a6ea94694fb2
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/38/114438/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/locale/training-guides.pot'],1,ae267572b4029751416e962bd452d32bbfbdd784,transifex/translations,"""POT-Creation-Date: 2014-08-15 06:00+0000\n""msgid ""OpenStack is a true and innovative open standard. For more user stories, see <link href=\""http://www.openstack.org/user-stories\"">http://www.openstack.org/user-stories</link>.""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:177(None)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:195(None)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:231(None)msgid ""OpenStack Compute requires a hypervisor and Compute controls the hypervisors through an API server. The process for selecting a hypervisor usually means prioritizing and making decisions based on budget and resource constraints as well as the inevitable list of supported features and required technical specifications. The majority of development is done with the KVM and Xen-based hypervisors. Refer to <link href=\""http://wiki.openstack.org/HypervisorSupportMatrix\""/> for a detailed list of features and support across the hypervisors.""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:30(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:36(para) msgid ""KVM- Kernel-based Virtual Machine (visit <link href=\""http://www.linux-kvm.org/\"">http://www.linux-kvm.org/</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:41(para) msgid ""LXC- Linux Containers (through libvirt) (visit <link href=\""http://linuxcontainers.org/\"">http://linuxcontainers.org/</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:46(para) msgid ""QEMU- Quick EMUlator (visit <link href=\""http://www.qemu.org/\"">http://www.qemu.org/</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:51(para) msgid ""UML- User Mode Linux (visit <link href=\""http://en.wikipedia.org/wiki/User-mode_Linux\"">http://en.wikipedia.org/wiki/User-mode_Linux</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:56(para) msgid ""VMware vSphere4.1 update 1 and newer (visit <link href=\""http://vmware.com/products/vsphere\"">http://vmware.com/products/vsphere</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:61(para) msgid ""Xen- Xen, Citrix XenServer and Xen Cloud Platform (XCP) (visit <link href=\""http://wiki.xen.org/\"">http://wiki.xen.org/</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:66(para) msgid ""Bare Metal- Provisions physical hardware via pluggable sub-drivers. (visit <link href=\""https://wiki.openstack.org/wiki/GeneralBareMetalProvisioningFramework\"">Bare Metal wiki page</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:72(guilabel) ./doc/training-guides/common/section_block-storage.xml:132(guilabel)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:73(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:88(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:97(para) ./doc/training-guides/common/section_block-storage.xml:145(guilabel)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:101(para) ./doc/training-guides/common/section_block-storage.xml:149(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:104(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:108(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:111(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:114(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:119(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:124(guilabel) ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:162(guilabel)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:125(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:134(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:138(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:146(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:153(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:158(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:161(guilabel) ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:174(title)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:163(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:171(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:181(guilabel)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:182(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:189(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:192(title)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:199(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:212(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:219(guilabel) ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:228(title)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:220(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:225(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:235(para)#: ./doc/training-guides/common/section_brief-overview.xml:56(None)msgid ""To check out more information on OpenStack visit <link href=\""http://www.openstack.org/\"">http://www.openstack.org/</link>""msgid ""The OpenStack Foundation, established in September of 2012, is an independent body, providing shared resources to help achieve the OpenStack Mission by protecting, empowering, and promoting OpenStack software and the community around it. This includes users, developers and the entire ecosystem. For more information visit <link href=\""http://www.openstack.org/foundation\"">http://www.openstack.org/foundation</link>.""#: ./doc/training-guides/common/section_brief-overview.xml:39(guilabel)#: ./doc/training-guides/common/section_brief-overview.xml:40(para) msgid ""Founded by Rackspace Hosting and NASA, OpenStack has grown to be a global software community of developers collaborating on a standard and massively scalable open source cloud operating system. The OpenStack Foundation promotes the development, distribution and adoption of the OpenStack cloud operating system. As the independent home for OpenStack, the Foundation has already attracted more than 7,000 individual members from 100 countries and 850 different organizations. It has also secured more than $10 million in funding and is ready to fulfill the OpenStack mission of becoming the ubiquitous cloud computing platform. Checkout <link href=\""http://www.openstack.org/foundation\"">http://www.openstack.org/foundation</link>for more information.""#: ./doc/training-guides/common/section_brief-overview.xml:53(title)#: ./doc/training-guides/common/section_brief-overview.xml:60(para)#: ./doc/training-guides/common/section_brief-overview.xml:66(guilabel)#: ./doc/training-guides/common/section_brief-overview.xml:67(para)#: ./doc/training-guides/common/section_brief-overview.xml:72(guilabel)#: ./doc/training-guides/common/section_brief-overview.xml:73(para)#: ./doc/training-guides/common/section_brief-overview.xml:79(guilabel)#: ./doc/training-guides/common/section_brief-overview.xml:80(para)#: ./doc/training-guides/common/section_brief-overview.xml:83(guilabel)#: ./doc/training-guides/common/section_brief-overview.xml:84(para) msgid ""Organizations like CERN, Cisco WebEx, DreamHost, eBay, The Gap, HP, MercadoLibre, NASA, PayPal, Rackspace and University of Melbourne have deployed OpenStack clouds to achieve control, business agility and cost savings without the licensing fees and terms of proprietary software. For complete user stories visit <link href=\""http://www.openstack.org/user-stories\"">http://www.openstack.org/user-stories</link>, this should give you a good idea about the importance of OpenStack.""","""POT-Creation-Date: 2014-08-06 06:00+0000\n""msgid ""OpenStack is a true and innovative open standard. For more user stories, see <link href=\""http://goo.gl/aF4lsL\"">http://goo.gl/aF4lsL</link>.""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:178(None)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:196(None)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:232(None)msgid ""OpenStack Compute requires a hypervisor and Compute controls the hypervisors through an API server. The process for selecting a hypervisor usually means prioritizing and making decisions based on budget and resource constraints as well as the inevitable list of supported features and required technical specifications. The majority of development is done with the KVM and Xen-based hypervisors. Refer to <link href=\""http://wiki.openstack.org/HypervisorSupportMatrix\""/><link href=\""http://goo.gl/n7AXnC\""> http://goo.gl/n7AXnC</link> for a detailed list of features and support across the hypervisors.""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:32(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:38(para) msgid ""KVM- Kernel-based Virtual Machine (visit <link href=\""http://goo.gl/70dvRb\"">http://goo.gl/70dvRb</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:43(para) msgid ""LXC- Linux Containers (through libvirt) (visit <link href=\""http://goo.gl/Ous3ly\"">http://goo.gl/Ous3ly</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:48(para) msgid ""QEMU- Quick EMUlator (visit <link href=\""http://goo.gl/WWV9lL\"">http://goo.gl/WWV9lL</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:53(para) msgid ""UML- User Mode Linux (visit <link href=\""http://goo.gl/4HAkJj\"">http://goo.gl/4HAkJj</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:58(para) msgid ""VMware vSphere4.1 update 1 and newer (visit <link href=\""http://goo.gl/0DBeo5\"">http://goo.gl/0DBeo5</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:63(para) msgid ""Xen- Xen, Citrix XenServer and Xen Cloud Platform (XCP) (visit <link href=\""http://goo.gl/yXP9t1\"">http://goo.gl/yXP9t1</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:68(para) msgid ""Bare Metal- Provisions physical hardware via pluggable sub-drivers. (visit <link href=\""http://goo.gl/exfeSg\"">http://goo.gl/exfeSg</link>)""#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:73(guilabel) ./doc/training-guides/common/section_block-storage.xml:132(guilabel)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:74(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:89(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:98(para) ./doc/training-guides/common/section_block-storage.xml:145(guilabel)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:102(para) ./doc/training-guides/common/section_block-storage.xml:149(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:105(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:109(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:112(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:115(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:120(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:125(guilabel) ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:163(guilabel)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:126(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:135(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:139(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:147(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:154(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:159(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:162(guilabel) ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:175(title)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:164(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:172(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:182(guilabel)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:183(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:190(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:193(title)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:200(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:213(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:220(guilabel) ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:229(title)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:221(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:226(para)#: ./doc/training-guides/common/section_vm-provisioning-walk-through.xml:236(para)#: ./doc/training-guides/common/section_brief-overview.xml:54(None)msgid ""To check out more information on OpenStack visit <link href=\""http://goo.gl/Ye9DFT\"">http://goo.gl/Ye9DFT</link>""msgid ""The OpenStack Foundation, established in September of 2012, is an independent body, providing shared resources to help achieve the OpenStack Mission by protecting, empowering, and promoting OpenStack software and the community around it. This includes users, developers and the entire ecosystem. For more information visit http://goo.gl/3uvmNX.""#: ./doc/training-guides/common/section_brief-overview.xml:38(guilabel)#: ./doc/training-guides/common/section_brief-overview.xml:39(para) msgid ""Founded by Rackspace Hosting and NASA, OpenStack has grown to be a global software community of developers collaborating on a standard and massively scalable open source cloud operating system. The OpenStack Foundation promotes the development, distribution and adoption of the OpenStack cloud operating system. As the independent home for OpenStack, the Foundation has already attracted more than 7,000 individual members from 100 countries and 850 different organizations. It has also secured more than $10 million in funding and is ready to fulfill the OpenStack mission of becoming the ubiquitous cloud computing platform. Checkout <link href=\""http://goo.gl/BZHJKd\"">http://goo.gl/BZHJKd</link>for more on the same.""#: ./doc/training-guides/common/section_brief-overview.xml:51(title)#: ./doc/training-guides/common/section_brief-overview.xml:58(para)#: ./doc/training-guides/common/section_brief-overview.xml:64(guilabel)#: ./doc/training-guides/common/section_brief-overview.xml:65(para)#: ./doc/training-guides/common/section_brief-overview.xml:70(guilabel)#: ./doc/training-guides/common/section_brief-overview.xml:71(para)#: ./doc/training-guides/common/section_brief-overview.xml:77(guilabel)#: ./doc/training-guides/common/section_brief-overview.xml:78(para)#: ./doc/training-guides/common/section_brief-overview.xml:81(guilabel)#: ./doc/training-guides/common/section_brief-overview.xml:82(para) msgid ""Organizations like CERN, Cisco WebEx, DreamHost, eBay, The Gap, HP, MercadoLibre, NASA, PayPal, Rackspace and University of Melbourne have deployed OpenStack clouds to achieve control, business agility and cost savings without the licensing fees and terms of proprietary software. For complete user stories visit <link href=\""http://goo.gl/aF4lsL\"">http://goo.gl/aF4lsL</link>, this should give you a good idea about the importance of OpenStack.""",68,68
openstack%2Fdevstack~master~Ic32d913c2bc6fae339b4d5ec509a77df5a21de72,openstack/devstack,master,Ic32d913c2bc6fae339b4d5ec509a77df5a21de72,"Add keepalived, conntrackd as dependencies",MERGED,2014-07-30 15:28:32.000000000,2014-08-15 06:16:35.000000000,2014-08-15 06:16:34.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2035}, {'_account_id': 7118}, {'_account_id': 7141}, {'_account_id': 7448}, {'_account_id': 8871}, {'_account_id': 8873}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-30 15:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b46242f01ccbff63dac54d4e2e93d1cf0a332a3f', 'message': 'Add keepalived, conntrackd as dependencies\n\nNeutron L3 HA blueprint l3-high-availability requires\nkeepalived and conntrackd in order to work for developers as\nwell as for functional tests.\n\nChange-Id: Ic32d913c2bc6fae339b4d5ec509a77df5a21de72\n'}, {'number': 2, 'created': '2014-07-30 18:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3c6a5e04a8366ae03cb30df5ad151cb9ad5a85ba', 'message': 'Add keepalived, conntrackd as dependencies\n\nNeutron L3 HA blueprint l3-high-availability requires\nkeepalived and conntrackd in order to work for developers as\nwell as for functional tests.\n\nChange-Id: Ic32d913c2bc6fae339b4d5ec509a77df5a21de72\n'}, {'number': 3, 'created': '2014-08-14 11:39:45.000000000', 'files': ['files/rpms/q-l3', 'files/apts/q-l3'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7f31a93ba017c6caa6de007f1f2d39e62f1f7e6c', 'message': 'Add keepalived, conntrackd as dependencies\n\nNeutron L3 HA blueprint l3-high-availability requires\nkeepalived and conntrackd in order to work for developers as\nwell as for functional tests.\n\nChange-Id: Ic32d913c2bc6fae339b4d5ec509a77df5a21de72\n'}]",3,110679,7f31a93ba017c6caa6de007f1f2d39e62f1f7e6c,37,12,3,8873,,,0,"Add keepalived, conntrackd as dependencies

Neutron L3 HA blueprint l3-high-availability requires
keepalived and conntrackd in order to work for developers as
well as for functional tests.

Change-Id: Ic32d913c2bc6fae339b4d5ec509a77df5a21de72
",git fetch https://review.opendev.org/openstack/devstack refs/changes/79/110679/1 && git format-patch -1 --stdout FETCH_HEAD,"['files/rpms/neutron', 'files/apts/neutron']",2,b46242f01ccbff63dac54d4e2e93d1cf0a332a3f,bp/l3-high-availability,conntrackdkeepalived,,4,0
openstack%2Ftaskflow~master~Ia7e7530e26b44a3023cbf79b04495061c043f76c,openstack/taskflow,master,Ia7e7530e26b44a3023cbf79b04495061c043f76c,Remove need for big db lock,ABANDONED,2014-02-11 07:32:08.000000000,2014-08-15 06:15:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-02-11 07:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ae0db0c233b2d91e98983227a8794a2a09ec556b', 'message': ""Remove need for big db lock\n\nThe infra team just recently allowed the test mysql\nuser to create and drop databases, so instead of using\nfile locks to avoid concurrent create/drop we can now\ncreate a unique database per test and use this to avoid\nany concurrency issues (each thread/test will get its\nown database to operate on and therefore can't collide\nwith other threads/processes).\n\nChange-Id: Ia7e7530e26b44a3023cbf79b04495061c043f76c\n""}, {'number': 2, 'created': '2014-02-11 07:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/82b25fc118ece43dee17171ebd9080767a76ff11', 'message': ""Remove need for big db lock\n\nThe infra team just recently allowed the test mysql\nuser to create and drop databases, so instead of using\nfile locks to avoid concurrent create/drop we can now\ncreate a unique database per test and use this to avoid\nany concurrency issues (each thread/test will get its\nown database to operate on and therefore can't collide\nwith other threads/processes).\n\nChange-Id: Ia7e7530e26b44a3023cbf79b04495061c043f76c\n""}, {'number': 3, 'created': '2014-02-11 23:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/64a15ea9bc79f4a205547ee85e0b50a6347a408b', 'message': ""Remove need for big db lock\n\nThe infra team just recently allowed the test mysql\nuser to create and drop databases, so instead of using\nfile locks to avoid concurrent create/drop we can now\ncreate a unique database per test and use this to avoid\nany concurrency issues (each thread/test will get its\nown database to operate on and therefore can't collide\nwith other threads/processes).\n\nChange-Id: Ia7e7530e26b44a3023cbf79b04495061c043f76c\n""}, {'number': 4, 'created': '2014-02-22 00:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b1c28a5892026c0c199c0d3c51965d959c8f396b', 'message': ""Remove need for big db lock\n\nThe infra team just recently allowed the test mysql\nuser to create and drop databases, so instead of using\nfile locks to avoid concurrent create/drop we can now\ncreate a unique database per test and use this to avoid\nany concurrency issues (each thread/test will get its\nown database to operate on and therefore can't collide\nwith other threads/processes).\n\nChange-Id: Ia7e7530e26b44a3023cbf79b04495061c043f76c\n""}, {'number': 5, 'created': '2014-02-22 00:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ca447dafc2567c54e1dee1797c7bf49143d0c5a1', 'message': ""Remove need for big db lock\n\nThe infra team just recently allowed the test mysql\nuser to create and drop databases, so instead of using\nfile locks to avoid concurrent create/drop we can now\ncreate a unique database per test and use this to avoid\nany concurrency issues (each thread/test will get its\nown database to operate on and therefore can't collide\nwith other threads/processes).\n\nChange-Id: Ia7e7530e26b44a3023cbf79b04495061c043f76c\n""}, {'number': 6, 'created': '2014-02-22 00:54:56.000000000', 'files': ['taskflow/tests/unit/persistence/test_sql_persistence.py', 'taskflow/tests/db_utils.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/66765a599376ffe42dff75291274b96b0b8f4c15', 'message': ""Remove need for big db lock\n\nThe infra team just recently allowed the test mysql\nuser to create and drop databases, so instead of using\nfile locks to avoid concurrent create/drop we can now\ncreate a unique database per test and use this to avoid\nany concurrency issues (each thread/test will get its\nown database to operate on and therefore can't collide\nwith other threads/processes).\n\nChange-Id: Ia7e7530e26b44a3023cbf79b04495061c043f76c\n""}]",0,72572,66765a599376ffe42dff75291274b96b0b8f4c15,42,2,6,1297,,,0,"Remove need for big db lock

The infra team just recently allowed the test mysql
user to create and drop databases, so instead of using
file locks to avoid concurrent create/drop we can now
create a unique database per test and use this to avoid
any concurrency issues (each thread/test will get its
own database to operate on and therefore can't collide
with other threads/processes).

Change-Id: Ia7e7530e26b44a3023cbf79b04495061c043f76c
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/72/72572/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/tests/unit/persistence/test_sql_persistence.py'],1,ae0db0c233b2d91e98983227a8794a2a09ec556b,no-db-lock,"import functoolsfrom taskflow.openstack.common import uuidutils def _setup_database(self, database): """"""Sets up the database, and returns the uri to that database."""""" raise NotImplementedError() def _teardown_database(self, database): """"""Cleans up the database."""""" database = ""tf_db_test_%s"" % (uuidutils.generate_uuid()[0:8]) 'connection': self._reset_database(database), self.addCleanup(functools.partial(self._teardown_database, database)) self.backend = impl_sqlalchemy.SQLAlchemyBackend(conf) self.addCleanup(self.backend.close) with contextlib.closing(self._get_connection()) as conn: conn.upgrade() def _teardown_database(self, database): for variant in MYSQL_VARIANTS: engine = None try: db_uri = _get_connect_string('mysql', USER, PASSWD, variant=variant) engine = sa.create_engine(db_uri) with contextlib.closing(engine.connect()) as conn: conn.execute(""DROP DATABASE IF EXISTS %s"" % database) except Exception: pass finally: if engine is not None: try: engine.dispose() except Exception: pass def _setup_database(self, database): conn.execute(""DROP DATABASE IF EXISTS %s"" % database) conn.execute(""CREATE DATABASE %s"" % database) database=database, def _setup_database(self, database): conn.execute(""DROP DATABASE IF EXISTS %s"" % database) conn.execute(""CREATE DATABASE %s"" % database) return _get_connect_string('postgres', USER, PASSWD, database=database) def _teardown_database(self, database): engine = None try: db_uri = _get_connect_string('postgres', USER, PASSWD, database='template1') engine = sa.create_engine(db_uri) with contextlib.closing(engine.connect()) as conn: conn.connection.set_isolation_level(0) conn.execute(""DROP DATABASE IF EXISTS %s"" % database) conn.connection.set_isolation_level(1) finally: if engine is not None: try: engine.dispose() except Exception: pass","import threadingfrom taskflow.utils import lock_utils LOCK_NAME = None def _reset_database(self): """"""Resets the database, and returns the uri to that database. Called *only* after locking succeeds. """""" self.backend = None self.big_lock.acquire() self.addCleanup(self.big_lock.release) 'connection': self._reset_database(), try: self.backend = impl_sqlalchemy.SQLAlchemyBackend(conf) self.addCleanup(self.backend.close) with contextlib.closing(self._get_connection()) as conn: conn.upgrade() except Exception as e: self.skipTest(""Failed to setup your database;"" "" testing being skipped due to: %s"" % (e)) LOCK_NAME = 'mysql_persistence_test' def __init__(self, *args, **kwargs): test.TestCase.__init__(self, *args, **kwargs) # We need to make sure that each test goes through a set of locks # to ensure that multiple tests are not modifying the database, # dropping it, creating it at the same time. To accomplish this we use # a lock that ensures multiple parallel processes can't run at the # same time as well as a in-process lock to ensure that multiple # threads can't run at the same time. lock_path = os.path.join(tempfile.gettempdir(), 'taskflow-%s.lock' % (self.LOCK_NAME)) locks = [ lock_utils.InterProcessLock(lock_path), threading.RLock(), ] self.big_lock = lock_utils.MultiLock(locks) def _reset_database(self): conn.execute(""DROP DATABASE IF EXISTS %s"" % DATABASE) conn.execute(""CREATE DATABASE %s"" % DATABASE) database=DATABASE, LOCK_NAME = 'postgres_persistence_test' def __init__(self, *args, **kwargs): test.TestCase.__init__(self, *args, **kwargs) # We need to make sure that each test goes through a set of locks # to ensure that multiple tests are not modifying the database, # dropping it, creating it at the same time. To accomplish this we use # a lock that ensures multiple parallel processes can't run at the # same time as well as a in-process lock to ensure that multiple # threads can't run at the same time. lock_path = os.path.join(tempfile.gettempdir(), 'taskflow-%s.lock' % (self.LOCK_NAME)) locks = [ lock_utils.InterProcessLock(lock_path), threading.RLock(), ] self.big_lock = lock_utils.MultiLock(locks) def _reset_database(self): conn.execute(""DROP DATABASE IF EXISTS %s"" % DATABASE) conn.execute(""CREATE DATABASE %s"" % DATABASE) return _get_connect_string('postgres', USER, PASSWD, database=DATABASE)",56,62
openstack%2Fkeystone~master~I6c67a2c448f9d3d00867fe45233f7119fe627e93,openstack/keystone,master,I6c67a2c448f9d3d00867fe45233f7119fe627e93,Bump hacking to 0.9.x series,MERGED,2014-06-10 10:02:26.000000000,2014-08-15 06:01:52.000000000,2014-08-15 06:01:51.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 167}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-06-10 10:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f790dd0cda29fac6e2eed482cb97d93085a65a8e', 'message': 'Bump hacking to 0.9.x series\n\nRequire at least 0.9.1 because 0.9.0. had a minor bug.\n\nThis patch ignores all newly introduced and stricter rules.\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 2, 'created': '2014-06-10 11:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/541c2367e8b71d8e2b3dcedbfe3d66eedfba0d35', 'message': 'WIP: Bump hacking to 0.9.x series\n\nRequire at least 0.9.1 because 0.9.0. had a minor bug.\n\nThis patch ignores all newly introduced and stricter rules.\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 3, 'created': '2014-07-16 11:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/af0a647479507c99940ee3aae2d72c0347bfa3e9', 'message': 'Bump hacking to 0.9.x series\n\nRequire at least 0.9.1 because 0.9.0. had a minor bug.\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 4, 'created': '2014-07-16 11:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/48289e8d98227e53f9811c75c29583258a5e3993', 'message': 'Bump hacking to 0.9.x series\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 5, 'created': '2014-07-16 11:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/518a323ac7f7bacd0381733e0f7af81611588fd1', 'message': 'Bump hacking to 0.9.x series\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 6, 'created': '2014-08-01 19:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f8cf01fbeda48c4b4df430d27c5ea67d6e69987a', 'message': 'Bump hacking to 0.9.x series\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 7, 'created': '2014-08-01 20:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b6aa2fa2bd00578b1d6fc84a7bcaf221b544b078', 'message': 'Bump hacking to 0.9.x series\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 8, 'created': '2014-08-02 06:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/14083c4fba34b18753d7dff9bd522f9f114b0224', 'message': 'Bump hacking to 0.9.x series\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 9, 'created': '2014-08-02 06:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/345dda5e51aceb33923796330c372effc2822edc', 'message': 'Bump hacking to 0.9.x series\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 10, 'created': '2014-08-13 08:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c8de8cc0f91fb6257e889bcd593b83643dadf0d8', 'message': 'Bump hacking to 0.9.x series\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 11, 'created': '2014-08-14 19:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a8d0d394af6e5055a9d67fb83f2802babd484aac', 'message': 'Bump hacking to 0.9.x series\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}, {'number': 12, 'created': '2014-08-15 03:42:47.000000000', 'files': ['keystone/contrib/ec2/controllers.py', 'keystone/tests/test_keystoneclient.py', 'test-requirements.txt', 'keystone/models/token_model.py', 'keystone/tests/test_no_admin_token_auth.py', 'keystone/common/environment/__init__.py', 'keystone/tests/test_keystoneclient_sql.py', 'keystone/tests/test_v3_auth.py', 'keystone/tests/test_ldap_pool_livetest.py', 'keystone/tests/test_backend.py', 'keystone/tests/test_pemutils.py', 'keystone/tests/test_contrib_stats_core.py', 'keystone/tests/test_ldap_livetest.py', 'keystone/token/providers/common.py', 'keystone/tests/core.py', 'keystone/common/validation/validators.py', 'keystone/common/ldap/core.py', 'keystone/service.py', 'keystone/tests/test_driver_hints.py', 'keystone/contrib/oauth1/core.py', 'test-requirements-py3.txt', 'tox.ini', 'keystone/cli.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0fdc042313955baf43aea5107757bf2dfc87ae86', 'message': 'Bump hacking to 0.9.x series\n\nChange-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93\nPartial-Bug: #1328469\n'}]",6,98996,0fdc042313955baf43aea5107757bf2dfc87ae86,57,7,12,167,,,0,"Bump hacking to 0.9.x series

Change-Id: I6c67a2c448f9d3d00867fe45233f7119fe627e93
Partial-Bug: #1328469
",git fetch https://review.opendev.org/openstack/keystone refs/changes/96/98996/12 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,f790dd0cda29fac6e2eed482cb97d93085a65a8e,bug/1328469,"# New in hacking 0.9: E129, E131, E265, E713, H407, H405, H904 # Stricter in hacking 0.9: E111, E112, E113, E251, E303, F402, F812, H401, H402 ignore = H803,E129,E131,E265,E713,H407,H405,H904,E111,E112,E113,E251,E303,F402,F812,H401,H402",ignore = H803,4,2
openstack%2Fneutron~master~I40d635bcf47c683663cb4dedf20323902dff2c7f,openstack/neutron,master,I40d635bcf47c683663cb4dedf20323902dff2c7f,Fix PortNotFound error during update_device_up for DVR,MERGED,2014-08-13 18:49:15.000000000,2014-08-15 05:36:04.000000000,2014-08-15 05:36:03.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6876}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-08-13 18:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/195de114a6c8b10e9c2e22aa8984f47897c4ef76', 'message': ""Fix PortNotFound error during update_device_up for DVR\n\nAn agent's request to update the ARP entry for a VM port\nmay come after a deletion request has been processed,\nresulting in a PortNotFound exception being raised.\n\nThis patch takes care of this condition. A test has\nbeen added, which required a minor refactoring of the\ntest case class, in order to accommodate the use of\nside effects for the objects being mocked.\n\nCloses-bug: #1356120\n\nChange-Id: I40d635bcf47c683663cb4dedf20323902dff2c7f\n""}, {'number': 2, 'created': '2014-08-13 18:54:15.000000000', 'files': ['neutron/plugins/ml2/rpc.py', 'neutron/tests/unit/ml2/test_rpcapi.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b025ccff2c7320caecfc005cfcbc3f4dfadfa505', 'message': ""Fix PortNotFound error during update_device_up for DVR\n\nAn agent's request to update the ARP entry for a VM port\nmay come after a deletion request has been processed,\nresulting in a PortNotFound exception being raised.\n\nThis patch takes care of this condition. A test has\nbeen added, which required a minor refactoring of the\ntest case class, in order to accommodate the use of\nside effects for the objects being mocked.\n\nCloses-bug: #1356120\n\nChange-Id: I40d635bcf47c683663cb4dedf20323902dff2c7f\n""}]",4,113993,b025ccff2c7320caecfc005cfcbc3f4dfadfa505,45,23,2,748,,,0,"Fix PortNotFound error during update_device_up for DVR

An agent's request to update the ARP entry for a VM port
may come after a deletion request has been processed,
resulting in a PortNotFound exception being raised.

This patch takes care of this condition. A test has
been added, which required a minor refactoring of the
test case class, in order to accommodate the use of
side effects for the objects being mocked.

Closes-bug: #1356120

Change-Id: I40d635bcf47c683663cb4dedf20323902dff2c7f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/113993/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/rpc.py', 'neutron/tests/unit/ml2/test_rpcapi.py']",2,195de114a6c8b10e9c2e22aa8984f47897c4ef76,bug/1356120,"from neutron.common import exceptionsclass RpcCallbacksTestCase(base.BaseTestCase): super(RpcCallbacksTestCase, self).setUp() self.manager = mock.patch.object( plugin_rpc.manager, 'NeutronManager').start() self.l3plugin = mock.Mock() self.manager.get_service_plugins.return_value = { 'L3_ROUTER_NAT': self.l3plugin } with mock.patch.object(self.callbacks, '_device_to_port_id'): type(self.l3plugin).supported_extension_aliases = ( mock.PropertyMock(return_value=extensions)) self.callbacks.update_device_up(mock.ANY, **kwargs) self._test_update_device_up(['router'], kwargs) self.assertFalse(self.l3plugin.dvr_vmarp_table_update.call_count) self._test_update_device_up(['router', 'dvr'], kwargs) self.l3plugin.dvr_vmarp_table_update.assert_called_once_with( def test_update_device_up_with_dvr_when_port_not_found(self): kwargs = { 'agent_id': 'foo_agent', 'device': 'foo_device' } self.l3plugin.dvr_vmarp_table_update.side_effect = ( exceptions.PortNotFound(port_id='foo_port_id')) self._test_update_device_up(['router', 'dvr'], kwargs) self.l3plugin.dvr_vmarp_table_update.assert_called_once_with( mock.ANY, mock.ANY, 'add') class RpcCallbacksTestCase(base.BaseTestCase): def setUp(self): super(RpcCallbacksTestCase, self).setUp() self.callbacks = plugin_rpc.RpcCallbacks(mock.Mock(), mock.Mock()) self.manager = mock.patch.object( plugin_rpc.manager, 'NeutronManager').start() self.l3plugin = mock.Mock() self.manager.get_service_plugins.return_value = { 'L3_ROUTER_NAT': self.l3plugin } def _test_update_device_up(self, extensions, kwargs): with mock.patch.object(self.callbacks, '_device_to_port_id'): type(self.l3plugin).supported_extension_aliases = ( mock.PropertyMock(return_value=extensions)) self.callbacks.update_device_up(mock.ANY, **kwargs) def test_update_device_up_without_dvr(self): kwargs = { 'agent_id': 'foo_agent', 'device': 'foo_device' } self._test_update_device_up(['router'], kwargs) self.assertFalse(self.l3plugin.dvr_vmarp_table_update.call_count) def test_update_device_up_with_dvr(self): kwargs = { 'agent_id': 'foo_agent', 'device': 'foo_device' } self._test_update_device_up(['router', 'dvr'], kwargs) self.l3plugin.dvr_vmarp_table_update.assert_called_once_with( mock.ANY, mock.ANY, 'add') def test_update_device_up_with_dvr_when_port_not_found(self): kwargs = { 'agent_id': 'foo_agent', 'device': 'foo_device' } self.l3plugin.dvr_vmarp_table_update.side_effect = ( exceptions.PortNotFound(port_id='foo_port_id')) self._test_update_device_up(['router', 'dvr'], kwargs) self.assertTrue(self.l3plugin.dvr_vmarp_table_update.call_count) ","class RpcCallbacks(base.BaseTestCase): super(RpcCallbacks, self).setUp() with mock.patch.object(plugin_rpc.manager, 'NeutronManager') as mgr: with mock.patch.object(self.callbacks, '_device_to_port_id'): mock_l3plugin = mock.Mock() mgr.get_service_plugins.return_value = { 'L3_ROUTER_NAT': mock_l3plugin } type(mock_l3plugin).supported_extension_aliases = ( mock.PropertyMock(return_value=extensions)) self.callbacks.update_device_up(mock.ANY, **kwargs) return mock_l3plugin l3plugin = self._test_update_device_up(['router'], kwargs) self.assertFalse(l3plugin.dvr_vmarp_table_update.call_count) l3plugin = self._test_update_device_up(['router', 'dvr'], kwargs) l3plugin.dvr_vmarp_table_update.assert_called_once_with(",79,17
openstack%2Fopenstack-manuals~master~Id68ec3b6e5dfa20123807ffa42a19c79c3123b41,openstack/openstack-manuals,master,Id68ec3b6e5dfa20123807ffa42a19c79c3123b41,Included a 'Caching' section to the Identity chapter,MERGED,2014-08-05 00:24:58.000000000,2014-08-15 05:33:05.000000000,2014-08-15 05:33:04.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 8103}]","[{'number': 1, 'created': '2014-08-05 00:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/08eaa0ef2b7cdf687d6d620c28f23a1867f104d9', 'message': ""Included a 'Caching' section to the Identity chapter\n\nNew section for 'Caching' with subsections for tokens and\ntoken validation and assignment using CRUD.\n\nChange-Id: Id68ec3b6e5dfa20123807ffa42a19c79c3123b41\nCloses-bug: #1216478\nCloses-bug: #1218194\n""}, {'number': 2, 'created': '2014-08-06 01:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b699f22586381fac04a42b8eb9a932688deffd0a', 'message': ""Included a 'Caching' section to the Identity chapter\n\nNew section for 'Caching' with subsections for tokens and\ntoken validation and assignment using CRUD.\n\nChange-Id: Id68ec3b6e5dfa20123807ffa42a19c79c3123b41\nCloses-bug: #1216478\nCloses-bug: #1218194\n""}, {'number': 3, 'created': '2014-08-06 06:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d6a66930e38d2987c2d2b89711a46571484bedce', 'message': ""Included a 'Caching' section to the Identity chapter\n\nNew section for 'Caching' with subsections for tokens and\ntoken validation and assignment using CRUD.\n\nChange-Id: Id68ec3b6e5dfa20123807ffa42a19c79c3123b41\nCloses-bug: #1216478\nCloses-bug: #1218194\n""}, {'number': 4, 'created': '2014-08-08 01:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5413f4e4d07069cab2b3fa5e687e8102201aeb2f', 'message': ""Included a 'Caching' section to the Identity chapter\n\nNew section for 'Caching' with subsections for tokens and\ntoken validation and assignment using CRUD.\n\nChange-Id: Id68ec3b6e5dfa20123807ffa42a19c79c3123b41\nCloses-bug: #1216478\nCloses-bug: #1218194\n""}, {'number': 5, 'created': '2014-08-08 02:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d76a122d72188967442de7f0e009e7c7c3492e21', 'message': ""Included a 'Caching' section to the Identity chapter\n\nNew section for 'Caching' with subsections for tokens and\ntoken validation and assignment using CRUD.\n\nChange-Id: Id68ec3b6e5dfa20123807ffa42a19c79c3123b41\nCloses-bug: #1216478\nCloses-bug: #1218194\n""}, {'number': 6, 'created': '2014-08-08 02:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b654c27d77264707b5b7aefc65b71dc6aa0c06f8', 'message': ""Included a 'Caching' section to the Identity chapter\n\nNew section for 'Caching' with subsections for tokens and\ntoken validation and assignment using CRUD.\n\nChange-Id: Id68ec3b6e5dfa20123807ffa42a19c79c3123b41\nCloses-bug: #1216478\nCloses-bug: #1218194\n""}, {'number': 7, 'created': '2014-08-12 01:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/effc31bb3587f03f8cbbb36197b04ed528c7da02', 'message': ""Included a 'Caching' section to the Identity chapter\n\nNew section for 'Caching' with subsections for tokens and\ntoken validation and assignment using CRUD.\n\nChange-Id: Id68ec3b6e5dfa20123807ffa42a19c79c3123b41\nCloses-bug: #1216478\nCloses-bug: #1218194\n""}, {'number': 8, 'created': '2014-08-13 05:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/38bd10e07df2fe9bb0fa3efd40a2e2bcf4d3d130', 'message': ""Included a 'Caching' section to the Identity chapter\n\nNew section for 'Caching' with subsections for tokens and\ntoken validation and assignment using CRUD.\n\nChange-Id: Id68ec3b6e5dfa20123807ffa42a19c79c3123b41\nCloses-bug: #1216478\nCloses-bug: #1218194\n""}, {'number': 9, 'created': '2014-08-13 06:39:29.000000000', 'files': ['doc/admin-guide-cloud/ch_identity_mgmt.xml', 'doc/admin-guide-cloud/identity/section_caching-layer.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5d2bad390a6cb98f0678754ea891d3488715b631', 'message': ""Included a 'Caching' section to the Identity chapter\n\nNew section for 'Caching' with subsections for tokens and\ntoken validation and assignment using CRUD.\n\nChange-Id: Id68ec3b6e5dfa20123807ffa42a19c79c3123b41\nCloses-bug: #1216478\nCloses-bug: #1218194\n""}]",90,111871,5d2bad390a6cb98f0678754ea891d3488715b631,54,6,9,8103,,,0,"Included a 'Caching' section to the Identity chapter

New section for 'Caching' with subsections for tokens and
token validation and assignment using CRUD.

Change-Id: Id68ec3b6e5dfa20123807ffa42a19c79c3123b41
Closes-bug: #1216478
Closes-bug: #1218194
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/71/111871/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/ch_identity_mgmt.xml', 'doc/admin-guide-cloud/identity/section_caching-layer.xml']",2,08eaa0ef2b7cdf687d6d620c28f23a1867f104d9,lp1216478-token-caching,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""section_caching-layer""> <?dbhtml stop-chunking?> <title>Caching Layer</title> <para>OpenStack Identity service supports a caching layer that is above the configurable subsystems (e.g. token, identity, etc). OpenStack Identity service uses the <literal>dogpile.cache</literal> library which allows for flexible cache backends. The majority of the caching configuration options are set in the [cache] section of the <literal>keystone.conf</literal> file. However, each section that has the capability to be cached usually has a caching boolean value that will toggle caching for that specific section. The current default behavior is that subsystem caching is enabled, but the global toggle is set to disabled.</para> <!--<para>Current keystone systems that have caching capabilities:</para>--> <section xml:id=""token""> <title>Caching for tokens and tokens validation</title> <para> The token system has a separate <literal>cache_time</literal> configuration option, that can be set to a value above or below the global <literal>expiration_time</literal> default, allowing for different caching behavior from the other systems in OpenStack Identity service. This option is set in the [token] section of the configuration file. </para> <para> The Token Revocation List cache time is handled by the configuration option <literal>revocation_cache_time</literal> in the [token] section. The revocation list is refreshed whenever a token is revoked. It typically sees significantly more requests than specific token retrievals or token validation calls. </para> <para>Token caching caches the following methods:</para> <itemizedlist> <listitem><para><literal>token_api.get_token</literal></para></listitem> <listitem><para><literal>token_api.list_revoked_tokens</literal></para></listitem> <listitem><para><literal>token_provider_api.validate_v3_token</literal></para></listitem> <listitem><para><literal>token_provider_api.check_v3_token</literal></para></listitem> <listitem><para><literal>token_provider_api.check_v2_token</literal></para></listitem> <listitem><para><literal>token_provider_api.validate_v2_token</literal></para></listitem> <listitem><para><literal>token_provider_api.validate_token</literal></para></listitem> </itemizedlist> <para>Calls to <literal>token_api.delete_token</literal> and <literal>token_api.delete_tokens</literal> will properly invalidate the cache for the tokens being acted upon, as well as invalidating the cache for the <literal>revoked_tokens_list</literal> and the validate/check token calls.</para> <para>Token caching is configurable independently of the <literal>revocation_list</literal> caching. Lifted expiration checks from the token drivers to the token manager. This ensures that cached tokens will still raise a <literal>TokenNotFound</literal> flag when expired.</para> <para>For cache consistency, all token_ids are transformed into the short token hash at the provider and token_driver level. Some methods have access to the full ID (PKI Tokens), and some methods do not. Cache invalidation is inconsistent without token_id normalization.</para> </section> <section xml:id=""assignment""> <title>Caching around assignment CRUD</title> <para>The assignment system has a separate <literal>cache_time</literal> configuration option, that can be set to a value above or below the global <literal>expiration_time</literal> default, allowing for different caching behavior from the other systems in Identity service. This option is set in the [assignment] section of the configuration file.</para> <para> Currently <literal>assignment</literal> has caching for <literal>project</literal>, <literal>domain</literal>, and <literal>role</literal> specific requests (primarily around the CRUD actions). Caching is currently not implemented on grants. The list (<literal>list_projects</literal>, <literal>list_domains</literal>) methods are not subject to caching.</para> <para>Caching around basic assignment CRUD actions:</para> <itemizedlist> <listitem><para><literal>assignment_api.get_domain</literal></para></listitem> <listitem><para><literal>assignmnet_api.get_domain_by_name</literal></para></listitem> <listitem><para><literal>assignment_api.get_project</literal></para></listitem> <listitem><para><literal>assignment_api.get_project_by_name</literal></para></listitem> <listitem><para><literal>assignment_api.get_role</literal></para></listitem> </itemizedlist> <para>The Create, Update, and Delete actions for domains, projects and roles will perform proper invalidations of the cached methods listed above.</para> <note> <para> If a read-only <literal>assignment</literal> backend is in use, the cache will not immediately reflect changes on the back end. Any given change may take up to the <literal>cache_time</literal> (if set in the [assignment] section of the configuration file) or the global <literal>expiration_time</literal> (set in the [cache] section of the configuration file) before it is reflected. If this type of delay (when using a read-only <literal>assignment</literal> backend) is an issue, it is recommended that caching be disabled on <literal>assignment</literal>. To disable caching specifically on <literal>assignment</literal>, in the [assignment] section of the configuration set <literal>caching</literal> to <literal>False</literal>.</para> </note> </section> </section>",,98,0
openstack%2Fopenstack-manuals~master~Id54b4fbb02d2cd08f0701d53f9b61a7a630202a7,openstack/openstack-manuals,master,Id54b4fbb02d2cd08f0701d53f9b61a7a630202a7,Update for python-saharaclient 0.7.1,MERGED,2014-08-14 21:48:41.000000000,2014-08-15 05:17:27.000000000,2014-08-15 05:17:26.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-14 21:48:41.000000000', 'files': ['doc/cli-reference/generated/ch_cli_sahara_commands.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0a100bd2c3b61fada842a2d9dc55eccb0eded621', 'message': 'Update for python-saharaclient 0.7.1\n\nRegenerate ch_cli_sahara_commands.xml with\npython-sahara 0.7.1 version release.\n\nChange-Id: Id54b4fbb02d2cd08f0701d53f9b61a7a630202a7\n'}]",0,114367,0a100bd2c3b61fada842a2d9dc55eccb0eded621,7,2,1,167,,,0,"Update for python-saharaclient 0.7.1

Regenerate ch_cli_sahara_commands.xml with
python-sahara 0.7.1 version release.

Change-Id: Id54b4fbb02d2cd08f0701d53f9b61a7a630202a7
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/67/114367/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/generated/ch_cli_sahara_commands.xml'],1,0a100bd2c3b61fada842a2d9dc55eccb0eded621,update_sahara_client, (CLI) for the Data processing API and its extensions. This chapter documents <command>sahara</command> version 0.7.1. Store data in the internal DB. Store data in the internal DB. Use 'swift upload' instead of this command. Use this command only if Swift is not available. Create a job. Prints all of the commands to stdout to support bash completion. Prints all of the commands and options to stdout so that the sahara.bash_completion script doesn't have to hard code them.Store data in the internal DB. Store data in the internal DB. Use 'swift upload' instead of this command. Use this command only if Swift is not available.Create a job., (CLI) for the Data processing and its extensions. This chapter documents <command>sahara</command> version 0.7.0. Store data in the internal DB. Use 'swift upload' instead of this command. Use this command only if Swift is not available. Prints all of the commands and options to stdout so that the sahara.bash_completion script doesn't have to hard code them.Store data in the internal DB. Use 'swift upload' instead of this command. Use this command only if Swift is not available.,15,10
openstack%2Fopenstack-manuals~master~Idb81f970b8862e61bffd604ba400d0a18bb3b3fe,openstack/openstack-manuals,master,Idb81f970b8862e61bffd604ba400d0a18bb3b3fe,Improve NTP section,MERGED,2014-08-09 02:53:13.000000000,2014-08-15 05:17:20.000000000,2014-08-15 05:17:19.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-08-09 02:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c86b499efb6e62d0a6b6c2b9778ef8f4c85f3b93', 'message': 'Improve NTP section\n\nI improved the NTP section with additional configuration keys\non the server and some other minor clarifications.\n\nChange-Id: Idb81f970b8862e61bffd604ba400d0a18bb3b3fe\nCloses-Bug: #1337793\n'}, {'number': 2, 'created': '2014-08-14 14:21:30.000000000', 'files': ['doc/install-guide/section_basics-ntp.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3351f94ec486645bda260ef5d9d4d89b3aa33670', 'message': 'Improve NTP section\n\nI improved the NTP section with additional configuration keys\non the server and some other minor clarifications.\n\nChange-Id: Idb81f970b8862e61bffd604ba400d0a18bb3b3fe\nCloses-Bug: #1337793\n'}]",7,113055,3351f94ec486645bda260ef5d9d4d89b3aa33670,20,5,2,9515,,,0,"Improve NTP section

I improved the NTP section with additional configuration keys
on the server and some other minor clarifications.

Change-Id: Idb81f970b8862e61bffd604ba400d0a18bb3b3fe
Closes-Bug: #1337793
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/55/113055/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_basics-ntp.xml'],1,c86b499efb6e62d0a6b6c2b9778ef8f4c85f3b93,bug/1337793," <title>Controller node</title> <para>Edit the <filename>/etc/ntp.conf</filename> file and add, change, or remove the following keys as necessary for your environment:</para> <programlisting>server <replaceable>NTP_SERVER</replaceable> iburst restrict -4 default kod notrap nomodify restrict -6 default kod notrap nomodify</programlisting> <para>Replace <replaceable>NTP_SERVER</replaceable> with the hostname or IP address of a suitable upstream NTP server.</para> <note> <para>For the <literal>restrict</literal> keys, you essentially remove the <literal>nopeer</literal> and <literal>noquery</literal> options.</para> </note> <title>Other nodes</title>"," <title>Configure controller node</title> <para>Edit the <filename>/etc/ntp.conf</filename> file:</para> <para>Add, change, or remove the <literal>server</literal> keys as necessary for your environment. Replace <replaceable>NTP_SERVER</replaceable> with the hostname or IP address of suitable NTP server.</para> <programlisting>server <replaceable>NTP_SERVER</replaceable> iburst</programlisting> <title>Configure other nodes</title> <title>To verify NTP synchronization</title>",15,9
openstack%2Fopenstack-manuals~master~I4dc4a3bf2b7236a4f8a01490106ef3860ec3e049,openstack/openstack-manuals,master,I4dc4a3bf2b7236a4f8a01490106ef3860ec3e049,"Networking Guide: Adjust abstract, add glossary",MERGED,2014-08-09 08:44:56.000000000,2014-08-15 05:10:42.000000000,2014-08-15 05:10:41.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 8369}]","[{'number': 1, 'created': '2014-08-09 08:44:56.000000000', 'files': ['doc/networking-guide/bk-networking.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f59e863d98d553bec50cf5e2af7a318c4b52542c', 'message': 'Networking Guide: Adjust abstract, add glossary\n\nAdd glossary so that glossterm entries are seen directly.\nRewrite abstract.\n\nimplements bp create-networking-guide\n\nChange-Id: I4dc4a3bf2b7236a4f8a01490106ef3860ec3e049\n'}]",1,113082,f59e863d98d553bec50cf5e2af7a318c4b52542c,12,4,1,6547,,,0,"Networking Guide: Adjust abstract, add glossary

Add glossary so that glossterm entries are seen directly.
Rewrite abstract.

implements bp create-networking-guide

Change-Id: I4dc4a3bf2b7236a4f8a01490106ef3860ec3e049
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/82/113082/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/bk-networking.xml'],1,f59e863d98d553bec50cf5e2af7a318c4b52542c,bp/create-networking-guide," <para> This guide targets OpenStack administrators seeking to deploy and manage OpenStack Networking. </para> <glossary role=""auto""/>", <para>OpenStack offers open source software for cloud administrators to manage and troubleshoot an OpenStack cloud.</para>,6,2
openstack%2Fpython-neutronclient~master~I76b901d6a27fbe6f103baf2f03ea17912123a46b,openstack/python-neutronclient,master,I76b901d6a27fbe6f103baf2f03ea17912123a46b,Remove incorrect super() call,MERGED,2014-08-12 05:43:09.000000000,2014-08-15 05:10:39.000000000,2014-08-15 05:10:39.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 11279}]","[{'number': 1, 'created': '2014-08-12 05:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/25381a318a91d68569a97ee6abfd00ad5220bdec', 'message': ""Remove incorrect super() call\n\nextension.ShowExt.get_parser called super() with the *parent* class,\nskipping the parent's own get_parser.  This is quite surprising without\nany additional comments to explain the situation.\n\nThe only difference between the two get_parsers is the string that\nappears in the usage help text (EXT_ALIAS vs EXTENSION).  Rather than\nimprove the above super() call, this change removes the specialised\nShowExt.get_parser() implementation entirely since it appears the\ngeneric version is sufficient.\n\nChange-Id: I76b901d6a27fbe6f103baf2f03ea17912123a46b\n""}, {'number': 2, 'created': '2014-08-12 07:18:18.000000000', 'files': ['neutronclient/neutron/v2_0/extension.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e254392e7de66becb818ee4794379ade6afa7ece', 'message': ""Remove incorrect super() call\n\nextension.ShowExt.get_parser called super() with the *parent* class,\nskipping the parent's own get_parser.  This is quite surprising without\nany additional comments to explain the situation.\n\nThe only difference between the two get_parsers is the string that\nappears in the usage help text (EXT_ALIAS vs EXTENSION).  Rather than\nimprove the above super() call, this change removes the specialised\nShowExt.get_parser() implementation entirely since it appears the\ngeneric version is sufficient.\n\nChange-Id: I76b901d6a27fbe6f103baf2f03ea17912123a46b\n""}]",0,113439,e254392e7de66becb818ee4794379ade6afa7ece,14,4,2,11279,,,0,"Remove incorrect super() call

extension.ShowExt.get_parser called super() with the *parent* class,
skipping the parent's own get_parser.  This is quite surprising without
any additional comments to explain the situation.

The only difference between the two get_parsers is the string that
appears in the usage help text (EXT_ALIAS vs EXTENSION).  Rather than
improve the above super() call, this change removes the specialised
ShowExt.get_parser() implementation entirely since it appears the
generic version is sufficient.

Change-Id: I76b901d6a27fbe6f103baf2f03ea17912123a46b
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/39/113439/2 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/extension.py'],1,25381a318a91d68569a97ee6abfd00ad5220bdec,bad-super,," def get_parser(self, prog_name): parser = super(cmd_base.ShowCommand, self).get_parser(prog_name) cmd_base.add_show_list_common_argument(parser) parser.add_argument( 'id', metavar='EXT-ALIAS', help=_('The extension alias.')) return parser",0,8
openstack%2Fneutron~master~Idfe67632893592859990db486393a7108362447e,openstack/neutron,master,Idfe67632893592859990db486393a7108362447e,Define some abstract methods in VpnDriver class,MERGED,2014-07-23 19:24:27.000000000,2014-08-15 05:07:21.000000000,2014-08-15 05:07:20.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5892}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6695}, {'_account_id': 6854}, {'_account_id': 7016}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10068}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10361}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12376}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-07-23 19:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/04bf4ac91f0ec808b792a4b87821743de44130b5', 'message': 'Summary line\nDefine some abstract methods in VpnDriver class.\nAdditional text\nDefine the <op>_ipsec_site_connection() methods to ensure any new\nservice drivers will implement them.\nCloses-Bug: 1326793\n\nChange-Id: Idfe67632893592859990db486393a7108362447e\n'}, {'number': 2, 'created': '2014-07-23 19:48:44.000000000', 'files': ['neutron/services/vpn/service_drivers/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/940d125922f16ae8c2aa4187b46304fc66648c52', 'message': 'Define some abstract methods in VpnDriver class\n\nDefine the <op>_ipsec_site_connection() methods to ensure any new\nservice drivers will implement them.\n\nCloses-Bug: 1326793\n\nChange-Id: Idfe67632893592859990db486393a7108362447e\n'}]",3,109087,940d125922f16ae8c2aa4187b46304fc66648c52,53,30,2,10147,,,0,"Define some abstract methods in VpnDriver class

Define the <op>_ipsec_site_connection() methods to ensure any new
service drivers will implement them.

Closes-Bug: 1326793

Change-Id: Idfe67632893592859990db486393a7108362447e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/87/109087/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/vpn/service_drivers/__init__.py'],1,04bf4ac91f0ec808b792a4b87821743de44130b5,bug/1326793," @abc.abstractmethod def create_ipsec_site_connection(self, context, ipsec_site_connection): pass @abc.abstractmethod def update_ipsec_site_connection(self, context, old_ipsec_site_connection, ipsec_site_connection): pass @abc.abstractmethod def delete_ipsec_site_connection(self, context, ipsec_site_connection): pass ",,13,0
openstack%2Fdevstack~master~Id12d175143ed3b8e024d057d65fa67505c08042a,openstack/devstack,master,Id12d175143ed3b8e024d057d65fa67505c08042a,Work around pip installed pkgs on Rackspace image,MERGED,2014-08-04 05:47:50.000000000,2014-08-15 05:07:17.000000000,2014-08-15 05:07:16.000000000,"[{'_account_id': 3}, {'_account_id': 532}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-04 05:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/724b63144b49e725eec421dd20f89568e1b866e2', 'message': 'Work around pip installed pkgs on Rackspace image\n\nThe upstream rackspace image has a bunch of pip installed packages.\nThis can break some system package installs, such as markdown, which\nfails with\n\n---\n Error unpacking rpm package python-markdown-2.4.1-1.el7.noarch\n  error: unpacking of archive failed on file\n   /usr/lib/python2.7/site-packages/Markdown-2.4.1-py2.7.egg-info: cpio: rename\n---\n\nBecause that is a directory for the package, and a file in the RPM\n\nRemove all pip installed packages before we start to work around this.\nI have filed an upstream issue with Rackspace (ticket-id\n140804-ord-0000134)\n\nChange-Id: Id12d175143ed3b8e024d057d65fa67505c08042a\n'}, {'number': 2, 'created': '2014-08-04 05:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/05e0b7d6cec11c04a7aa37cd57196c9934277a72', 'message': 'Work around pip installed pkgs on Rackspace image\n\nThe upstream rackspace image has a bunch of pip installed packages.\nThis can break some system package installs, such as markdown, which\nfails with\n\n---\n Error unpacking rpm package python-markdown-2.4.1-1.el7.noarch\n  error: unpacking of archive failed on file\n   /usr/lib/python2.7/site-packages/Markdown-2.4.1-py2.7.egg-info: cpio: rename\n---\n\nBecause that is a directory for the package, and a file in the RPM\n\nRemove all pip installed packages before we start to work around this.\nI have filed an upstream issue with Rackspace (ticket-id\n140804-ord-0000134)\n\nChange-Id: Id12d175143ed3b8e024d057d65fa67505c08042a\n'}, {'number': 3, 'created': '2014-08-05 01:33:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8f4129d1add7f3d2215d579335048daf3c2a758f', 'message': 'Work around pip installed pkgs on Rackspace image\n\nThe upstream rackspace image has a bunch of pip installed packages.\nThis can break some system package installs, such as markdown, which\nfails with\n\n---\n Error unpacking rpm package python-markdown-2.4.1-1.el7.noarch\n  error: unpacking of archive failed on file\n   /usr/lib/python2.7/site-packages/Markdown-2.4.1-py2.7.egg-info: cpio: rename\n---\n\nBecause that is a directory for the package, and a file in the RPM\n\nRemove all pip installed packages before we start to work around this.\nI have filed an upstream issue with Rackspace (ticket-id\n140804-ord-0000134)\n\nChange-Id: Id12d175143ed3b8e024d057d65fa67505c08042a\n'}, {'number': 4, 'created': '2014-08-05 04:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d308dcd7f09f1800d729daa9622859a10500e35f', 'message': 'Work around pip installed pkgs on Rackspace image\n\nThe upstream rackspace image has a bunch of pip installed packages as\ncloud-init was installed via pip due to a lack of available system\npackages.  This can break further system package installs, such as\nmarkdown, which fails with\n\n---\n Error unpacking rpm package python-markdown-2.4.1-1.el7.noarch\n  error: unpacking of archive failed on file\n   /usr/lib/python2.7/site-packages/Markdown-2.4.1-py2.7.egg-info: cpio: rename\n---\n\nBecause that is a directory for the pip-installed package, and a file\nin the RPM\n\nRemove all pip installed packages on rackspace images before we start\nto work around this.  I have filed an upstream issue with Rackspace\n(ticket-id 140804-ord-0000134) and the issue is being worked on.\n\nChange-Id: Id12d175143ed3b8e024d057d65fa67505c08042a\n'}, {'number': 5, 'created': '2014-08-05 04:45:17.000000000', 'files': ['functions-common', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/bdc90c5f0243e3d2b3efa893cfd080d039fed8e4', 'message': 'Work around pip installed pkgs on Rackspace image\n\nThe upstream rackspace image has a bunch of pip installed packages as\ncloud-init was installed via pip due to a lack of available system\npackages.  This can break further system package installs, such as\nmarkdown, which fails with\n\n---\n Error unpacking rpm package python-markdown-2.4.1-1.el7.noarch\n  error: unpacking of archive failed on file\n   /usr/lib/python2.7/site-packages/Markdown-2.4.1-py2.7.egg-info: cpio: rename\n---\n\nBecause that is a directory for the pip-installed package, and a file\nin the RPM\n\nRemove all pip installed packages on rackspace images before we start\nto work around this.  I have filed an upstream issue with Rackspace\n(ticket-id 140804-ord-0000134) and the issue is being worked on.\n\nChange-Id: Id12d175143ed3b8e024d057d65fa67505c08042a\n'}]",0,111646,bdc90c5f0243e3d2b3efa893cfd080d039fed8e4,34,6,5,7118,,,0,"Work around pip installed pkgs on Rackspace image

The upstream rackspace image has a bunch of pip installed packages as
cloud-init was installed via pip due to a lack of available system
packages.  This can break further system package installs, such as
markdown, which fails with

---
 Error unpacking rpm package python-markdown-2.4.1-1.el7.noarch
  error: unpacking of archive failed on file
   /usr/lib/python2.7/site-packages/Markdown-2.4.1-py2.7.egg-info: cpio: rename
---

Because that is a directory for the pip-installed package, and a file
in the RPM

Remove all pip installed packages on rackspace images before we start
to work around this.  I have filed an upstream issue with Rackspace
(ticket-id 140804-ord-0000134) and the issue is being worked on.

Change-Id: Id12d175143ed3b8e024d057d65fa67505c08042a
",git fetch https://review.opendev.org/openstack/devstack refs/changes/46/111646/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,724b63144b49e725eec421dd20f89568e1b866e2,rackspace-pip-remove, # RHEL7 if [[ $DISTRO =~ (rhel7) ]]; then # upstream Rackspace centos images have an issue where too much is # installed via pip. remove it (sudo pip freeze | xargs sudo pip uninstall -y) || true fi,,8,0
openstack%2Fcinder~master~Ib5738e9c463856dd71a47717b7abb8dff785b3b1,openstack/cinder,master,Ib5738e9c463856dd71a47717b7abb8dff785b3b1,Fix unit test test_import_record_with_verify,MERGED,2014-07-31 10:33:12.000000000,2014-08-15 04:53:00.000000000,2014-08-14 20:21:10.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 7872}, {'_account_id': 8415}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12018}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-07-31 10:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6fd46097f40c57758a3e262ff83056d62a2edc87', 'message': ""Fix unit test test_import_record_with_verify\n\nThe test case test_import_record_with_verify it's intended to call\na backup service class with a defined verify function.\n\nChange-Id: Ib5738e9c463856dd71a47717b7abb8dff785b3b1\nCloses-bug: #1350699\n""}, {'number': 2, 'created': '2014-08-01 06:48:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6472865fadf511d7cbf2f86f52d25be114f7c85c', 'message': ""Fix unit test test_import_record_with_verify\n\nThe test case test_import_record_with_verify is intended to call a\nbackup service class with a defined verify function. This verify\nfunction wasn't overloaded by the fake service.\n\nChange-Id: Ib5738e9c463856dd71a47717b7abb8dff785b3b1\nCloses-bug: #1350699\n""}, {'number': 3, 'created': '2014-08-05 12:46:04.000000000', 'files': ['cinder/tests/backup/fake_service_with_verify.py', 'cinder/tests/test_backup.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce8893f4d3fae402494328bfbd07ea6642aae836', 'message': ""Fix unit test test_import_record_with_verify\n\nThe test case test_import_record_with_verify is intended to call a\nbackup service class with a defined verify function. This verify\nfunction wasn't overloaded by the fake service.\n\nChange-Id: Ib5738e9c463856dd71a47717b7abb8dff785b3b1\nCloses-bug: #1350699\n""}]",2,110897,ce8893f4d3fae402494328bfbd07ea6642aae836,41,12,3,7872,,,0,"Fix unit test test_import_record_with_verify

The test case test_import_record_with_verify is intended to call a
backup service class with a defined verify function. This verify
function wasn't overloaded by the fake service.

Change-Id: Ib5738e9c463856dd71a47717b7abb8dff785b3b1
Closes-bug: #1350699
",git fetch https://review.opendev.org/openstack/cinder refs/changes/97/110897/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/backup/fake_service.py', 'cinder/tests/test_backup.py']",2,6fd46097f40c57758a3e262ff83056d62a2edc87,bug/1350699, backup_driver = self.backup_mgr.service.\ get_backup_driver_with_verify(self.ctxt), backup_driver = self.backup_mgr.service.get_backup_driver(self.ctxt),13,6
openstack%2Fdevstack~master~I0d5d16c5601d022f034df2cc291106c5dc13511e,openstack/devstack,master,I0d5d16c5601d022f034df2cc291106c5dc13511e,Add swift tempurl support to devstack,MERGED,2014-08-05 18:09:02.000000000,2014-08-15 04:51:29.000000000,2014-08-15 04:51:28.000000000,"[{'_account_id': 3}, {'_account_id': 97}, {'_account_id': 532}, {'_account_id': 970}, {'_account_id': 1420}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 7118}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-05 18:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/593cb2185ed00157bc786228c8c621d49c0872f1', 'message': 'Add swift tempurl support to devstack\n\nThis commit adds the ability to automatically set a tempurl key\nin swift for service accounts.\n\nChange-Id: I0d5d16c5601d022f034df2cc291106c5dc13511e\n'}, {'number': 2, 'created': '2014-08-06 20:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/86bb1e0e23586c495b6c8a67373fe884a94e5bdc', 'message': 'Add swift tempurl support to devstack\n\nThis commit adds the ability to automatically set a tempurl key\nin swift for service accounts.\n\nChange-Id: I0d5d16c5601d022f034df2cc291106c5dc13511e\n'}, {'number': 3, 'created': '2014-08-07 17:46:49.000000000', 'files': ['lib/swift', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/abbb0e9a0d6c183b6c6f10e197bed6aa2dde20b1', 'message': 'Add swift tempurl support to devstack\n\nThis commit adds the ability to automatically set a tempurl key\nin swift for service accounts.\n\nChange-Id: I0d5d16c5601d022f034df2cc291106c5dc13511e\n'}]",6,112095,abbb0e9a0d6c183b6c6f10e197bed6aa2dde20b1,36,11,3,10343,,,0,"Add swift tempurl support to devstack

This commit adds the ability to automatically set a tempurl key
in swift for service accounts.

Change-Id: I0d5d16c5601d022f034df2cc291106c5dc13511e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/95/112095/2 && git format-patch -1 --stdout FETCH_HEAD,"['lib/swift', 'stack.sh']",2,593cb2185ed00157bc786228c8c621d49c0872f1,ipa-support," if [[ -z ""$SWIFT_TEMPURL_KEY"" ]] && [[ ""$SWIFT_ENABLE_TEMPURLS"" == ""True"" ]]; then read_password SWIFT_TEMPURL_KEY ""ENTER A KEY FOR SWIFT TEMPURLS."" fi",,19,0
openstack%2Fnova~stable%2Fhavana~I090765802bfe443440f16722bc7c43b6280fe56a,openstack/nova,stable/havana,I090765802bfe443440f16722bc7c43b6280fe56a,make libvirt driver get_connection thread-safe,MERGED,2013-10-30 17:40:26.000000000,2014-08-15 04:33:41.000000000,2014-08-15 03:35:06.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1706}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7641}, {'_account_id': 8125}, {'_account_id': 8213}, {'_account_id': 8290}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 10118}]","[{'number': 1, 'created': '2013-10-30 17:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85bd253c5cdc04ba7064771da24d6faa35d5523b', 'message': ""make libvirt driver get_connection thread-safe\n\nlibvirt driver's get_connection is not thread safe in the\npresence of a libvirtd restart during concurrent incoming\nrequests.\n\nWith existing code each will in turn call get_connection,\nfind the connection is broken, try to create new one, block\nfor a while and yield to the next thread to do the same.\nYou get as many connections as there are incoming requests\nand only the last one is used finally. If enough are incoming\nthese connections can exhaust the client pool configured\nfor libvirtd.\nOne fix is to hold a lock while creating the connection.\nNote that has_min_version calls _conn which calls get_connection\nand thus the direct call to _has_min_version()\n\nAlso added the exception text if it fails to register an event\nhandler for lifecycle events.\n\nChange-Id: I090765802bfe443440f16722bc7c43b6280fe56a\nFixes: bug #1240905\n(cherry picked from commit b2e64e379835f57128e66f507438130eda716814)\n""}, {'number': 2, 'created': '2014-08-06 21:40:48.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/98ab49bbb29890730ce544b785f1babff3e694e1', 'message': ""make libvirt driver get_connection thread-safe\n\nlibvirt driver's get_connection is not thread safe in the\npresence of a libvirtd restart during concurrent incoming\nrequests.\n\nWith existing code each will in turn call get_connection,\nfind the connection is broken, try to create new one, block\nfor a while and yield to the next thread to do the same.\nYou get as many connections as there are incoming requests\nand only the last one is used finally. If enough are incoming\nthese connections can exhaust the client pool configured\nfor libvirtd.\nOne fix is to hold a lock while creating the connection.\nNote that has_min_version calls _conn which calls get_connection\nand thus the direct call to _has_min_version()\n\nAlso added the exception text if it fails to register an event\nhandler for lifecycle events.\n\nChange-Id: I090765802bfe443440f16722bc7c43b6280fe56a\nFixes: bug #1240905\n(cherry picked from commit b2e64e379835f57128e66f507438130eda716814)\n""}]",0,54595,98ab49bbb29890730ce544b785f1babff3e694e1,43,13,2,979,,,0,"make libvirt driver get_connection thread-safe

libvirt driver's get_connection is not thread safe in the
presence of a libvirtd restart during concurrent incoming
requests.

With existing code each will in turn call get_connection,
find the connection is broken, try to create new one, block
for a while and yield to the next thread to do the same.
You get as many connections as there are incoming requests
and only the last one is used finally. If enough are incoming
these connections can exhaust the client pool configured
for libvirtd.
One fix is to hold a lock while creating the connection.
Note that has_min_version calls _conn which calls get_connection
and thus the direct call to _has_min_version()

Also added the exception text if it fails to register an event
handler for lifecycle events.

Change-Id: I090765802bfe443440f16722bc7c43b6280fe56a
Fixes: bug #1240905
(cherry picked from commit b2e64e379835f57128e66f507438130eda716814)
",git fetch https://review.opendev.org/openstack/nova refs/changes/95/54595/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py']",2,85bd253c5cdc04ba7064771da24d6faa35d5523b,bug/1266711-havana," @staticmethod def _has_min_version(conn, lv_ver=None, hv_ver=None, hv_type=None): libvirt_version = conn.getLibVersion() hypervisor_version = conn.getVersion() hypervisor_type = conn.getType() def has_min_version(self, lv_ver=None, hv_ver=None, hv_type=None): return self._has_min_version(self._conn, lv_ver, hv_ver, hv_type) # multiple concurrent connections are protected by _wrapped_conn_lock if not wrapped_conn or not self._test_connection(wrapped_conn): LOG.debug(_('Connecting to libvirt: %s'), self.uri()) if not CONF.libvirt_nonblocking: wrapped_conn = self._connect(self.uri(), self.read_only) else: wrapped_conn = tpool.proxy_call( (libvirt.virDomain, libvirt.virConnect), self._connect, self.uri(), self.read_only) except Exception as e: LOG.warn(_(""URI %(uri)s does not support events: %(error)s""), {'uri': self.uri(), 'error': e}) if self._has_min_version(wrapped_conn, MIN_LIBVIRT_CLOSE_CALLBACK_VERSION): except libvirt.libvirtError as e: LOG.warn(_(""URI %(uri)s does not support connection"" "" events: %(error)s""), {'uri': self.uri(), 'error': e})"," def has_min_version(self, lv_ver=None, hv_ver=None, hv_type=None): libvirt_version = self._conn.getLibVersion() hypervisor_version = self._conn.getVersion() hypervisor_type = self._conn.getType() if not wrapped_conn or not self._test_connection(wrapped_conn): LOG.debug(_('Connecting to libvirt: %s'), self.uri()) if not CONF.libvirt_nonblocking: wrapped_conn = self._connect(self.uri(), self.read_only) else: wrapped_conn = tpool.proxy_call( (libvirt.virDomain, libvirt.virConnect), self._connect, self.uri(), self.read_only) with self._wrapped_conn_lock: except Exception: LOG.warn(_(""URI %s does not support events""), self.uri()) if self.has_min_version(MIN_LIBVIRT_CLOSE_CALLBACK_VERSION): except libvirt.libvirtError: LOG.debug(_(""URI %s does not support connection events""), self.uri())",74,20
openstack%2Fneutron~master~Ie7a5bb76445e15cde9fbf9ff3d2101a014637b37,openstack/neutron,master,Ie7a5bb76445e15cde9fbf9ff3d2101a014637b37,Use jsonutils instead of stdlib json,MERGED,2014-08-07 22:13:57.000000000,2014-08-15 04:25:43.000000000,2014-08-14 13:12:34.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7763}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9828}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-08-07 22:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/94119362cc47886870f654a44199479e5c906f03', 'message': ""Use jsonutils instead of stdlib json\n\njsonutils provides multiple benefits in comparison to pure stdlib json\n(like using simplejson on Python 2.6).\n\nSimilar patch was already merged before [1], but since it lacked hacking\nrule to enforce jsonutils usage, new occurrences of stdlib json module\nusage were introduced.\n\nThis patch switches all the code to using jsonutils and adds a hacking\nrule to enforce the rule.\n\nThe hacking rule requires that jsonutils module does not mimic as 'json'\nthru using import renames, so the code was updated not to rename the\nmodule when doing import.\n\nThe hacking rule was shamelessly copied from the corresponding nova\nreview [2].\n\n[1]: https://review.openstack.org/#/c/99760/\n[2]: https://review.openstack.org/111296/\n\nChange-Id: Ie7a5bb76445e15cde9fbf9ff3d2101a014637b37\n""}, {'number': 2, 'created': '2014-08-08 12:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2c99e207a35aa13fe90714bfb1eefb82bc01e641', 'message': ""Use jsonutils instead of stdlib json\n\njsonutils provides multiple benefits in comparison to pure stdlib json\n(like using simplejson on Python 2.6).\n\nSimilar patch was already merged before [1], but since it lacked hacking\nrule to enforce jsonutils usage, new occurrences of stdlib json module\nusage were introduced.\n\nThis patch switches all the code to using jsonutils and adds a hacking\nrule to enforce the rule.\n\nThe hacking rule requires that jsonutils module does not mimic as 'json'\nthru using import renames, so the code was updated not to rename the\nmodule when doing import.\n\nThe hacking rule was shamelessly copied from the corresponding nova\nreview [2].\n\n[1]: https://review.openstack.org/#/c/99760/\n[2]: https://review.openstack.org/111296/\n\nChange-Id: Ie7a5bb76445e15cde9fbf9ff3d2101a014637b37\n""}, {'number': 3, 'created': '2014-08-09 07:04:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ef92c4c4128a5016eb8eecf09b4ac6bf517acd28', 'message': ""Use jsonutils instead of stdlib json\n\njsonutils provides multiple benefits in comparison to pure stdlib json\n(like using simplejson on Python 2.6).\n\nSimilar patch was already merged before [1], but since it lacked hacking\nrule to enforce jsonutils usage, new occurrences of stdlib json module\nusage were introduced.\n\nThis patch switches all the code to using jsonutils and adds a hacking\nrule to enforce the rule.\n\nThe hacking rule requires that jsonutils module does not mimic as 'json'\nthru using import renames, so the code was updated not to rename the\nmodule when doing import.\n\nThe hacking rule was shamelessly copied from the corresponding nova\nreview [2].\n\n[1]: https://review.openstack.org/#/c/99760/\n[2]: https://review.openstack.org/111296/\n\nChange-Id: Ie7a5bb76445e15cde9fbf9ff3d2101a014637b37\n""}, {'number': 4, 'created': '2014-08-12 13:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ed6001d4243c558dbee670f6a6e6b730e320b872', 'message': ""Use jsonutils instead of stdlib json\n\njsonutils provides multiple benefits in comparison to pure stdlib json\n(like using simplejson on Python 2.6).\n\nSimilar patch was already merged before [1], but since it lacked hacking\nrule to enforce jsonutils usage, new occurrences of stdlib json module\nusage were introduced.\n\nThis patch switches all the code to using jsonutils and adds a hacking\nrule to enforce the rule.\n\nThe hacking rule requires that jsonutils module does not mimic as 'json'\nthru using import renames, so the code was updated not to rename the\nmodule when doing import.\n\nThe hacking rule was shamelessly copied from the corresponding nova\nreview [2].\n\n[1]: https://review.openstack.org/#/c/99760/\n[2]: https://review.openstack.org/111296/\n\nChange-Id: Ie7a5bb76445e15cde9fbf9ff3d2101a014637b37\n""}, {'number': 5, 'created': '2014-08-14 08:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/abc02e5f4ce01045a233284ade1d072d1f01fca1', 'message': ""Use jsonutils instead of stdlib json\n\njsonutils provides multiple benefits in comparison to pure stdlib json\n(like using simplejson on Python 2.6).\n\nSimilar patch was already merged before [1], but since it lacked hacking\nrule to enforce jsonutils usage, new occurrences of stdlib json module\nusage were introduced.\n\nThis patch switches all the code to using jsonutils and adds a hacking\nrule to enforce the rule.\n\nThe hacking rule requires that jsonutils module does not mimic as 'json'\nthru using import renames, so the code was updated not to rename the\nmodule when doing import.\n\nThe hacking rule was shamelessly copied from the corresponding nova\nreview [2].\n\n[1]: https://review.openstack.org/#/c/99760/\n[2]: https://review.openstack.org/111296/\n\nChange-Id: Ie7a5bb76445e15cde9fbf9ff3d2101a014637b37\n""}, {'number': 6, 'created': '2014-08-14 10:46:19.000000000', 'files': ['neutron/plugins/nec/common/ofc_client.py', 'neutron/plugins/vmware/nsxlib/lsn.py', 'neutron/plugins/vmware/nsxlib/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py', 'neutron/hacking/checks.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/bigswitch/tests/test_server.py', 'neutron/tests/unit/vmware/test_nsx_sync.py', 'neutron/plugins/vmware/api_client/eventlet_request.py', 'neutron/tests/unit/vmware/vshield/fake_vcns.py', 'neutron/tests/unit/test_policy.py', 'neutron/tests/unit/vmware/nsxlib/test_lsn.py', 'neutron/plugins/vmware/nsxlib/secgroup.py', 'neutron/services/loadbalancer/drivers/radware/driver.py', 'neutron/plugins/oneconvergence/lib/plugin_helper.py', 'neutron/tests/unit/oneconvergence/test_plugin_helper.py', 'neutron/tests/unit/bigswitch/fake_server.py', 'neutron/tests/unit/test_hacking.py', 'neutron/plugins/cisco/cfg_agent/device_drivers/dummy_driver.py', 'neutron/plugins/vmware/nsxlib/l2gateway.py', 'neutron/tests/unit/vmware/apiclient/fake.py', 'neutron/plugins/vmware/nsxlib/switch.py', 'neutron/tests/unit/nec/test_ofc_client.py', 'neutron/tests/unit/oneconvergence/test_nvsdlib.py', 'neutron/plugins/oneconvergence/lib/nvsdlib.py', 'neutron/services/firewall/agents/varmour/varmour_api.py', 'HACKING.rst', 'neutron/plugins/ml2/drivers/cisco/apic/apic_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a75865b1f9bb728d6c1efc8b49586537526ed88', 'message': ""Use jsonutils instead of stdlib json\n\njsonutils provides multiple benefits in comparison to pure stdlib json\n(like using simplejson on Python 2.6).\n\nSimilar patch was already merged before [1], but since it lacked hacking\nrule to enforce jsonutils usage, new occurrences of stdlib json module\nusage were introduced.\n\nThis patch switches all the code to using jsonutils and adds a hacking\nrule to enforce the rule.\n\nThe hacking rule requires that jsonutils module does not mimic as 'json'\nthru using import renames, so the code was updated not to rename the\nmodule when doing import.\n\nThe hacking rule was shamelessly copied from the corresponding nova\nreview [2].\n\n[1]: https://review.openstack.org/#/c/99760/\n[2]: https://review.openstack.org/111296/\n\nChange-Id: Ie7a5bb76445e15cde9fbf9ff3d2101a014637b37\n""}]",5,112708,0a75865b1f9bb728d6c1efc8b49586537526ed88,169,29,6,9656,,,0,"Use jsonutils instead of stdlib json

jsonutils provides multiple benefits in comparison to pure stdlib json
(like using simplejson on Python 2.6).

Similar patch was already merged before [1], but since it lacked hacking
rule to enforce jsonutils usage, new occurrences of stdlib json module
usage were introduced.

This patch switches all the code to using jsonutils and adds a hacking
rule to enforce the rule.

The hacking rule requires that jsonutils module does not mimic as 'json'
thru using import renames, so the code was updated not to rename the
module when doing import.

The hacking rule was shamelessly copied from the corresponding nova
review [2].

[1]: https://review.openstack.org/#/c/99760/
[2]: https://review.openstack.org/111296/

Change-Id: Ie7a5bb76445e15cde9fbf9ff3d2101a014637b37
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/112708/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/nec/common/ofc_client.py', 'neutron/plugins/vmware/nsxlib/lsn.py', 'neutron/plugins/vmware/nsxlib/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py', 'neutron/hacking/checks.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/bigswitch/tests/test_server.py', 'neutron/tests/unit/vmware/test_nsx_sync.py', 'neutron/plugins/vmware/api_client/eventlet_request.py', 'neutron/tests/unit/vmware/vshield/fake_vcns.py', 'neutron/tests/unit/test_policy.py', 'neutron/tests/unit/vmware/nsxlib/test_lsn.py', 'neutron/plugins/vmware/nsxlib/secgroup.py', 'neutron/services/loadbalancer/drivers/radware/driver.py', 'neutron/plugins/oneconvergence/lib/plugin_helper.py', 'neutron/tests/unit/oneconvergence/test_plugin_helper.py', 'neutron/tests/unit/bigswitch/fake_server.py', 'neutron/tests/unit/test_hacking.py', 'neutron/plugins/cisco/cfg_agent/device_drivers/dummy_driver.py', 'neutron/plugins/vmware/nsxlib/l2gateway.py', 'neutron/tests/unit/vmware/apiclient/fake.py', 'neutron/plugins/vmware/nsxlib/switch.py', 'neutron/tests/unit/nec/test_ofc_client.py', 'neutron/tests/unit/oneconvergence/test_nvsdlib.py', 'neutron/plugins/oneconvergence/lib/nvsdlib.py', 'neutron/services/firewall/agents/varmour/varmour_api.py', 'neutron/plugins/ml2/drivers/cisco/apic/apic_client.py']",27,94119362cc47886870f654a44199479e5c906f03,(detached,from neutron.openstack.common import jsonutils return jsonutils.dumps({key: {'attributes': attrs}}),from neutron.openstack.common import jsonutils as json return json.dumps({key: {'attributes': attrs}}),196,151
openstack%2Fswift~master~I561bc0a043f3451bb0a84cad274fedc907e61ee8,openstack/swift,master,I561bc0a043f3451bb0a84cad274fedc907e61ee8,Increase Account Auditor Test Code Coverage,MERGED,2014-07-04 16:50:44.000000000,2014-08-15 03:34:59.000000000,2014-08-15 03:34:59.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7233}, {'_account_id': 7479}]","[{'number': 1, 'created': '2014-07-04 16:50:44.000000000', 'files': ['swift/account/auditor.py', 'test/unit/account/test_auditor.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/51fa32f53d81864e9267fc40ce3fcfe494b62437', 'message': 'Increase Account Auditor Test Code Coverage\n\nSome simple additional test code to bring coverage from 82% to 99%\n\nChange-Id: I561bc0a043f3451bb0a84cad274fedc907e61ee8\n'}]",0,104935,51fa32f53d81864e9267fc40ce3fcfe494b62437,18,6,1,7479,,,0,"Increase Account Auditor Test Code Coverage

Some simple additional test code to bring coverage from 82% to 99%

Change-Id: I561bc0a043f3451bb0a84cad274fedc907e61ee8
",git fetch https://review.opendev.org/openstack/swift refs/changes/35/104935/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/account/auditor.py', 'test/unit/account/test_auditor.py']",2,51fa32f53d81864e9267fc40ce3fcfe494b62437,aud_cover,"from eventlet import Timeout # now force timeout path code coverage def fake_one_audit_pass(reported): raise Timeout() with mock.patch('swift.account.auditor.AccountAuditor._one_audit_pass', fake_one_audit_pass): with mock.patch('swift.account.auditor.time', FakeTime()): self.assertRaises(ValueError, test_auditor.run_forever) self.assertEqual(test_auditor.account_failures, 2 * call_times) self.assertEqual(test_auditor.account_passes, 3 * call_times) def test_one_audit_pass(self): conf = {} test_auditor = auditor.AccountAuditor(conf) def fake_audit_location_generator(*args, **kwargs): files = os.listdir(self.testdir) return [(os.path.join(self.testdir, f), '', '') for f in files] # force code coverage for logging path test_auditor.logging_interval = 0 with mock.patch('swift.account.auditor.audit_location_generator', fake_audit_location_generator): test_auditor._one_audit_pass(test_auditor.logging_interval) self.assertEqual(test_auditor.account_failures, 0) self.assertEqual(test_auditor.account_passes, 0) @mock.patch('swift.account.auditor.AccountBroker', FakeAccountBroker)",,31,1
openstack%2Fnova~master~Ibf40ef9108f209b70ffbab6e2387d2d469f7373e,openstack/nova,master,Ibf40ef9108f209b70ffbab6e2387d2d469f7373e,Return 404 instead of 501 for unsupported actions,MERGED,2014-08-07 11:03:26.000000000,2014-08-15 03:29:35.000000000,2014-08-14 11:54:59.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-07 11:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62a242c9e79a392797ed084d00b570c3ca12107c', 'message': ""Return 404 instead of 501 for unsupported actions in ips extension\n\nRemove the create/delete function, let the wsgi return 404 for them.\nThat's consistent behavior for unsupported actions.\n\nChange-Id: Ibf40ef9108f209b70ffbab6e2387d2d469f7373e\n""}, {'number': 2, 'created': '2014-08-07 11:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55ef2dcac1f09a850b6f18785713d07cbfdb2ae7', 'message': ""Return 404 instead of 501 for unsupported actions\n\nRmove the unsupported actions return 501 explicitly. Let the wsgi\nreturn 404 for them. That's consistent behavior for unsupported actions\nin nova REST API.\n\nChange-Id: Ibf40ef9108f209b70ffbab6e2387d2d469f7373e\n""}, {'number': 3, 'created': '2014-08-07 12:47:39.000000000', 'files': ['nova/api/openstack/compute/ips.py', 'nova/api/openstack/compute/plugins/v3/ips.py', 'nova/api/openstack/compute/consoles.py', 'nova/api/openstack/compute/contrib/attach_interfaces.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1b0e4725ae0efa52de76ec211bba9d061eb04140', 'message': 'Return 404 instead of 501 for unsupported actions\n\nChange unsupported actions return code to 404 from 501 to ensure\nconsistency with other unsupported actions in the REST API.\n\nChange-Id: Ibf40ef9108f209b70ffbab6e2387d2d469f7373e\n'}]",2,112553,1b0e4725ae0efa52de76ec211bba9d061eb04140,36,11,3,5754,,,0,"Return 404 instead of 501 for unsupported actions

Change unsupported actions return code to 404 from 501 to ensure
consistency with other unsupported actions in the REST API.

Change-Id: Ibf40ef9108f209b70ffbab6e2387d2d469f7373e
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/112553/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/ips.py', 'nova/api/openstack/compute/plugins/v3/ips.py']",2,62a242c9e79a392797ed084d00b570c3ca12107c,remove_notimp,," def create(self, req, server_id, body): raise exc.HTTPNotImplemented() def delete(self, req, server_id, id): raise exc.HTTPNotImplemented() ",0,12
openstack%2Fkeystone~master~I0863e909997be630c7c17106c87ab383293b191d,openstack/keystone,master,I0863e909997be630c7c17106c87ab383293b191d,Rename bash8 requirement,MERGED,2014-08-13 09:55:09.000000000,2014-08-15 02:45:49.000000000,2014-08-15 02:45:48.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-13 09:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/57855360066aedae9255f7f0b160e058e56d2a2c', 'message': 'Rename bash8 requirement\n\nThe package bash8 has been renamed to bashate.\n\nChange-Id: I0863e909997be630c7c17106c87ab383293b191d\n'}, {'number': 2, 'created': '2014-08-13 10:17:03.000000000', 'files': ['test-requirements.txt', 'test-requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3a09c1f5a37fa820eaaa4e5437ee0158369bc801', 'message': 'Rename bash8 requirement\n\nThe package bash8 has been renamed to bashate.\n\nChange-Id: I0863e909997be630c7c17106c87ab383293b191d\n'}]",0,113828,3a09c1f5a37fa820eaaa4e5437ee0158369bc801,19,5,2,6547,,,0,"Rename bash8 requirement

The package bash8 has been renamed to bashate.

Change-Id: I0863e909997be630c7c17106c87ab383293b191d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/28/113828/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,57855360066aedae9255f7f0b160e058e56d2a2c,bashate,bashate >= 0.2,bash8,1,1
openstack-attic%2Fidentity-api~master~I54252f3f412f09d860777000f3ab0cb282d947e0,openstack-attic/identity-api,master,I54252f3f412f09d860777000f3ab0cb282d947e0,Make API specification match our token format.,MERGED,2014-08-08 16:00:38.000000000,2014-08-15 02:37:35.000000000,2014-08-15 02:37:34.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-08-08 16:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/a5cabcc3c7742935212c0eacd499c169143bda16', 'message': 'Make API specification match our token format for role list.\n\nChange-Id: I54252f3f412f09d860777000f3ab0cb282d947e0\n'}, {'number': 2, 'created': '2014-08-08 16:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/f6d98004067fe5cdfbc260e871550a5ec218bddc', 'message': 'Make API specification match our token format for role list.\n\nCloses-Bug 1354408\nChange-Id: I54252f3f412f09d860777000f3ab0cb282d947e0\n'}, {'number': 3, 'created': '2014-08-08 17:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/d4684bc6e1fb8ce1dd6cd4a96b4706fa4f623cb6', 'message': 'Make API specification match our token format.\n\nWe do not include self links in any of the entities we include\nin a token response.\n\nCloses-Bug: 1354408\nChange-Id: I54252f3f412f09d860777000f3ab0cb282d947e0\n'}, {'number': 4, 'created': '2014-08-08 17:50:49.000000000', 'files': ['v3/src/markdown/identity-api-v3.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/58197385398e08c3fad94586e85e46d6fb09d5f7', 'message': 'Make API specification match our token format.\n\nWe do not include self links in any of the entities we include\nin a token response.\n\nCloses-Bug: 1354408\nChange-Id: I54252f3f412f09d860777000f3ab0cb282d947e0\n'}]",2,112959,58197385398e08c3fad94586e85e46d6fb09d5f7,19,6,4,5707,,,0,"Make API specification match our token format.

We do not include self links in any of the entities we include
in a token response.

Closes-Bug: 1354408
Change-Id: I54252f3f412f09d860777000f3ab0cb282d947e0
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/59/112959/3 && git format-patch -1 --stdout FETCH_HEAD,['v3/src/markdown/identity-api-v3.md'],1,a5cabcc3c7742935212c0eacd499c169143bda16,bug/1354408,," ""links"": { ""self"": ""http://identity:35357/v3/roles/76e72a"" }, ""links"": { ""self"": ""http://identity:35357/v3/roles/f4f392"" }, ""links"": { ""self"": ""http://identity:35357/v3/roles/76e72a"" }, ""links"": { ""self"": ""http://identity:35357/v3/roles/f4f392"" },",0,12
openstack%2Fkeystone-specs~master~I0b76ea3cd4cb31ea26326b54965f453c8520f796,openstack/keystone-specs,master,I0b76ea3cd4cb31ea26326b54965f453c8520f796,Role assignment notifications,MERGED,2014-08-12 22:36:09.000000000,2014-08-15 02:28:51.000000000,2014-08-15 02:28:50.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 10487}, {'_account_id': 11045}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-08-12 22:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e999f2b454c47979a178ed3cb88ee6d3a5292d5c', 'message': 'Role assignment notifications\n\nCreate a specification for adding role assignment notifications.\n\nChange-Id: I0b76ea3cd4cb31ea26326b54965f453c8520f796\n'}, {'number': 2, 'created': '2014-08-12 23:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/2f463680e37b3549e8a1c57cd1ff64ccda9a116e', 'message': 'Role assignment notifications\n\nCreate a specification for adding role assignment notifications.\n\nChange-Id: I0b76ea3cd4cb31ea26326b54965f453c8520f796\n'}, {'number': 3, 'created': '2014-08-13 14:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/d88fcf047abff14c2f9816bbce827248d1656fb2', 'message': 'Role assignment notifications\n\nCreate a specification for adding role assignment notifications.\n\nChange-Id: I0b76ea3cd4cb31ea26326b54965f453c8520f796\n'}, {'number': 4, 'created': '2014-08-14 04:11:39.000000000', 'files': ['specs/juno/role-assignment-notifications.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/3276a2e6219d5b9ccd5d7081dddccd748018f140', 'message': 'Role assignment notifications\n\nCreate a specification for adding role assignment notifications.\n\nChange-Id: I0b76ea3cd4cb31ea26326b54965f453c8520f796\n'}]",20,113669,3276a2e6219d5b9ccd5d7081dddccd748018f140,26,17,4,6482,,,0,"Role assignment notifications

Create a specification for adding role assignment notifications.

Change-Id: I0b76ea3cd4cb31ea26326b54965f453c8520f796
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/69/113669/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/role-assignment-notifications.rst'],1,e999f2b454c47979a178ed3cb88ee6d3a5292d5c,role_assignment_notifications,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================= Role Assignment Notifications ============================= `bp role-assignment-notifications <https://blueprints.launchpad.net/keystone/+spec/role-assignment-notifications>`_ In the Juno release, expand on the notifications that are emitted from Keystone by adding support for role assignments. Problem Description =================== Suppose a user maliciously decides to grant a role assignment to another user they shouldn't have, or remove another user's role assignment. As of the Icehouse release, it would only be possible to figure out the responsible party by looking at Keystone logs. If Keystone were to emit notifications for these types of events, auditing would become much easier. Proposed Change =============== 1. Create a new decorator to emit notifications for create_grant and delete grant events. 2. Within the payload of the notification should be the role id, the user id or group id (the actor), and the project id or domain id (the target). Alternatives ------------ The admin may look at Keystone logs to find the responsible user, however this could be very hard to do, given the size of the log file. Security Impact --------------- None Notifications Impact -------------------- Create notifications for ``create_grant`` and ``delete_grant`` at the manager level of the assignment API. Other End User Impact --------------------- None Performance Impact ------------------ None Other Deployer Impact --------------------- None Developer Impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: * stevemar (Steve Martinelli <stevemar@ca.ibm.com>) Work Items ---------- * Expose ``create_grant`` to the manager level. * Create a new decorate specific to role assignments. Dependencies ============ None Documentation Impact ==================== Enhance the existing documentation to include the expected payload for a role assignment event. References ========== * `Blueprint <https://blueprints.launchpad.net/keystone/+spec/role-assignment-notifications>`_ * `Notification Docs <docs.openstack.org/developer/keystone/event_notifications.html>`_ ",,106,0
openstack%2Fneutron~master~If1fc1717fec37bd187c73a42899e2e33b1fdc7bf,openstack/neutron,master,If1fc1717fec37bd187c73a42899e2e33b1fdc7bf,Remove unused parameter,ABANDONED,2014-08-14 03:41:34.000000000,2014-08-15 01:57:53.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 8976}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10692}, {'_account_id': 10971}]","[{'number': 1, 'created': '2014-08-14 03:41:34.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a1f36a5adb6ca1f0115e689193aa4753349f1481', 'message': 'Remove unused parameter\n\nremove the unused parameter in _map_internal_interfaces.\n\nChange-Id: If1fc1717fec37bd187c73a42899e2e33b1fdc7bf\n'}]",0,114113,a1f36a5adb6ca1f0115e689193aa4753349f1481,22,18,1,8976,,,0,"Remove unused parameter

remove the unused parameter in _map_internal_interfaces.

Change-Id: If1fc1717fec37bd187c73a42899e2e33b1fdc7bf
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/114113/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py']",2,a1f36a5adb6ca1f0115e689193aa4753349f1481,bug/remove-unused-parameter," res_port = agent._map_internal_interfaces(internal_ports[0], res_ip = agent._map_internal_interfaces(internal_ports[0],"," res_port = agent._map_internal_interfaces(ri, internal_ports[0], res_ip = agent._map_internal_interfaces(ri, internal_ports[0],",6,9
openstack%2Fhorizon~master~I9f8680fb51aa7dcf249e7487efa46240200a0ef2,openstack/horizon,master,I9f8680fb51aa7dcf249e7487efa46240200a0ef2,"Adds keypair create,delete integration tests",MERGED,2014-05-28 09:24:20.000000000,2014-08-15 01:52:00.000000000,2014-08-15 01:51:59.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1687}, {'_account_id': 1795}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 8090}, {'_account_id': 8577}, {'_account_id': 8871}, {'_account_id': 9531}, {'_account_id': 9981}, {'_account_id': 10185}, {'_account_id': 11473}, {'_account_id': 11690}, {'_account_id': 12355}]","[{'number': 1, 'created': '2014-05-28 09:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/83d03c297e55218c842ce2b554981558c2d3cac6', 'message': 'Adds keypair create,delete tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 2, 'created': '2014-05-30 06:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cdfd50031748b7510dbba526c412bb2222dd0ba7', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 3, 'created': '2014-06-03 14:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1203e5e42d177559c00be7efe460fac1703d3b05', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 4, 'created': '2014-06-11 09:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/741aea9b1b22ffaea4d538bd3e65d3a187c41b53', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 5, 'created': '2014-06-16 09:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/007c291db8688832c9869d63e6e51fd38a6f1048', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 6, 'created': '2014-06-16 09:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d49973ede471e92aa417b4868d3f40bf3001d14f', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 7, 'created': '2014-06-16 11:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/898c27191e1afc68d910abda89ddd4a0c3804179', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 8, 'created': '2014-06-16 11:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3bba8de7ee68f4dddedfdd30a27a57df88c1a6ec', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 9, 'created': '2014-06-16 11:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d67a9595805865e2625a30b4bf747b00d1d98400', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 10, 'created': '2014-06-16 12:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a67cac7500d2253acf1b24d7958d35f34182ac63', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 11, 'created': '2014-06-24 10:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/29f922f6988a88798db13fc2041ca8e5fadb9214', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 12, 'created': '2014-06-27 09:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/238a68779f0037d4575ccc8c8d47849311d7cc8f', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 13, 'created': '2014-07-01 12:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/792170205cc10d9286bdb263c15253e1628f81bf', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nRemoved dependency: https://review.openstack.org/#/c/95370/\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 14, 'created': '2014-07-21 09:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/99ecaa27b10aa95da6e3f9b65608adc629dd09b0', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. Also modified helpers.py\nI have added accesssecuritypage.py which has\n_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 15, 'created': '2014-08-01 11:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/151806b702f078288e21bc9f5d90a5bd43495b32', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. I have added\naccesssecuritypage.py which has_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}, {'number': 16, 'created': '2014-08-05 12:16:16.000000000', 'files': ['openstack_dashboard/test/integration_tests/pages/accesssecuritypage.py', 'openstack_dashboard/test/integration_tests/pages/keypairpage.py', 'openstack_dashboard/test/integration_tests/tests/test_keypair.py', 'openstack_dashboard/test/integration_tests/pages/basepage.py', 'openstack_dashboard/test/integration_tests/pages/projectpage.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6e7681a607835a3d13096c7ef97c71f43775d9d3', 'message': 'Adds keypair create,delete integration tests\n\nI have added test_keypair.py which tests create keypair and delete\nkeypair methods. And to allow this I have added keypairpage.py with\ntwo methods to create and delete keypairs. I have added\naccesssecuritypage.py which has_click_on_keypair_link method.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2\n'}]",120,96111,6e7681a607835a3d13096c7ef97c71f43775d9d3,107,17,16,1795,,,0,"Adds keypair create,delete integration tests

I have added test_keypair.py which tests create keypair and delete
keypair methods. And to allow this I have added keypairpage.py with
two methods to create and delete keypairs. I have added
accesssecuritypage.py which has_click_on_keypair_link method.

Partially implements blueprint: selenium-integration-testing

Change-Id: I9f8680fb51aa7dcf249e7487efa46240200a0ef2
",git fetch https://review.opendev.org/openstack/horizon refs/changes/11/96111/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/integration_tests/pages/keypairpage.py', 'openstack_dashboard/test/integration_tests/helpers.py', 'openstack_dashboard/test/integration_tests/tests/test_keypair.py']",3,83d03c297e55218c842ce2b554981558c2d3cac6,bp/selenium-integration-testing,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack_dashboard.test.integration_tests import helpers from openstack_dashboard.test.integration_tests.pages import keypairpage from openstack_dashboard.test.integration_tests.pages import loginpage import random class TestKeypair(helpers.BaseTestCase): """"""This is a basic scenario test: * checks able to login as a regular user * checks that the user able to create/delete keypair """""" def test_keyapir(self): home_page = loginpage.LoginPage( self.driver, self.conf).login_to_horizon() keypair_pg = keypairpage.KeypairPage(self.driver, self.conf) keypair_name = 'horizonkeypair' + str(random.randint(0, 1000)) keypair_status = keypair_pg.create_keypair(keypair_name) self.assertTrue(keypair_status) keypair_status = keypair_pg.delete_keypair(keypair_name) self.assertFalse(keypair_status) home_page.log_out() ",,149,0
openstack%2Fkeystone~master~I52caacc01a94428e4986ef68d032ad317e09b276,openstack/keystone,master,I52caacc01a94428e4986ef68d032ad317e09b276,Keystone service throws error on receiving SIGHUP,MERGED,2014-07-16 19:45:11.000000000,2014-08-15 01:21:02.000000000,2014-08-15 01:21:01.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1091}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 9303}, {'_account_id': 10795}, {'_account_id': 11428}, {'_account_id': 12215}]","[{'number': 1, 'created': '2014-07-16 19:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dd6777dac57dcabed8a8dab5838aaf808a7c649d', 'message': ""Keystone service throws error on SIGHUP signal\n\nAdded reset method in Server class.\n\nAfter adding reset method when SIGHUP signal is sent to\nwsgi service parent process, it stops the service and then calls\nservice start method again. When it stops the service, it\nkills the eventlet thread, which internally closes the wsgi\nserver socket object. This server socket object is now not\nusable again and it throws following error, while restarting\nthe service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nCloses-Bug: #1337850\nChange-Id: I52caacc01a94428e4986ef68d032ad317e09b276\n""}, {'number': 2, 'created': '2014-07-21 11:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cb1287ecf27d767601539def58cf9e85e6f50a0d', 'message': ""Keystone service throws error on SIGHUP signal\n\nAdded reset method in Server class.\n\nResize the greenpool size to zero while stopping service so\nthat WSGI server stops accepting new requests and complete\nrunning requests. Resetting the greenpool size to default\nvalue, on service restart.\n\nAfter adding reset method when SIGHUP signal is sent to\nwsgi service parent process, it stops the service and then calls\nservice start method again. When it stops the service, it\nkills the eventlet thread, which internally closes the wsgi\nserver socket object. This server socket object is now not\nusable again and it throws following error, while restarting\nthe service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nCloses-Bug: #1337850\nChange-Id: I52caacc01a94428e4986ef68d032ad317e09b276\n""}, {'number': 3, 'created': '2014-07-23 12:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3457a2607d7a17bf9867c1690ad57a7587ea4307', 'message': ""Keystone service throws error on SIGHUP signal\n\nAdded reset method in Server class.\n\nAfter adding reset method when SIGHUP signal is sent to\nwsgi service parent process, it stops the service and then calls\nservice start method again. When it stops the service, it\nkills the eventlet thread, which internally closes the wsgi\nserver socket object. This server socket object is now not\nusable again and it throws following error, while restarting\nthe service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nCloses-Bug: #1337850\nChange-Id: I52caacc01a94428e4986ef68d032ad317e09b276\n""}, {'number': 4, 'created': '2014-07-23 15:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ad2f315091906d47df51e912d5c1b80f870a0cfa', 'message': ""Keystone service throws error on SIGHUP signal\n\nAdded reset method in Server class.\n\nAfter adding reset method when SIGHUP signal is sent to\nwsgi service parent process, it stops the service and then calls\nservice start method again. When it stops the service, it\nkills the eventlet thread, which internally closes the wsgi\nserver socket object. This server socket object is now not\nusable again and it throws following error, while restarting\nthe service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nCloses-Bug: #1337850\nChange-Id: I52caacc01a94428e4986ef68d032ad317e09b276\n""}, {'number': 5, 'created': '2014-07-30 12:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/214162b20355d7976c548e9e9fe22b6abf20b2d5', 'message': ""Keystone service throws error on SIGHUP signal\n\nAdded reset method in Server class. After adding reset method\nwhen SIGHUP signal is sent to wsgi service parent process, it\nstops the service and then calls service start method again.\nWhen it stops the service, it kills the eventlet thread, which\ninternally closes the wsgi server socket object. This server\nsocket object is now not usable again and it throws following\nerror, while restarting the service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nCloses-Bug: #1337850\nChange-Id: I52caacc01a94428e4986ef68d032ad317e09b276\n""}, {'number': 6, 'created': '2014-08-01 08:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bd20f72c457b36bd20b558699dbfdcd32d6b971d', 'message': ""Keystone service throws error on SIGHUP signal\n\nAdded reset method in Server class. After adding reset method\nwhen SIGHUP signal is sent to wsgi service parent process, it\nstops the service and then calls service start method again.\nWhen it stops the service, it kills the eventlet thread, which\ninternally closes the wsgi server socket object. This server\nsocket object is now not usable again and it throws following\nerror, while restarting the service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nCloses-Bug: #1337850\nChange-Id: I52caacc01a94428e4986ef68d032ad317e09b276\n""}, {'number': 7, 'created': '2014-08-08 10:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6210f2cdbc0c37818f422f07fb6baf04e26dfccc', 'message': ""Keystone service throws error on receiving SIGHUP\n\nThis patch resolves following erorrs:\n1. AttributeError: 'Server' object has no attribute 'reset'.\n2. error: [Errno 9] Bad file descriptor\n3. Can't dup an ssl object\n\nWhen the SIGHUp signal is received by the service launcher in\ncommon service framework, it calls the server's reset method.\nAs reset method is not present in Sever class of\nkeystone.common.environment.eventlet_server module, it raises\nAttributeError: 'Server' object has no attribute 'reset'.\n\nAfter adding reset method when SIGHUP signal is sent to service\nparent process, it stops the service and then calls service start\nmethod again. When it stops the service, it kills the eventlet\nthread, which internally closes the wsgi server socket object.\nThis server socket object is now not usable again and it throws\nfollowing error, while restarting the service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nAs ssl object can not be duplicated, creating duplicate\nsocket object before converting a regular socket into an\nSSL socket.\n\nCloses-Bug: #1337850\nChange-Id: I52caacc01a94428e4986ef68d032ad317e09b276\n""}, {'number': 8, 'created': '2014-08-11 06:40:39.000000000', 'files': ['keystone/tests/ksfixtures/appserver.py', 'keystone/tests/test_wsgi.py', 'keystone/common/environment/eventlet_server.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/825f3e7820423e3accae413070f88bd12e6c9b57', 'message': ""Keystone service throws error on receiving SIGHUP\n\nThis patch resolves following erorrs:\n1. AttributeError: 'Server' object has no attribute 'reset'.\n2. error: [Errno 9] Bad file descriptor\n3. Can't dup an SSL object\n\nWhen the SIGHUP signal is received by the service launcher in\ncommon service framework, it calls the server's reset method.\nAs reset method is not present in Sever class of\nkeystone.common.environment.eventlet_server module, it raises\nAttributeError: 'Server' object has no attribute 'reset'.\n\nAfter adding reset method when SIGHUP signal is sent to service\nparent process, it stops the service and then calls service start\nmethod again. When it stops the service, it kills the eventlet\nthread, which internally closes the wsgi server socket object.\nThis server socket object is now not usable again and it throws\nfollowing error, while restarting the service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nAs SSL object can not be duplicated, creating duplicate\nsocket object before converting a regular socket into an\nSSL socket.\n\nCloses-Bug: #1337850\nChange-Id: I52caacc01a94428e4986ef68d032ad317e09b276\n""}]",38,107482,825f3e7820423e3accae413070f88bd12e6c9b57,93,11,8,9303,,,0,"Keystone service throws error on receiving SIGHUP

This patch resolves following erorrs:
1. AttributeError: 'Server' object has no attribute 'reset'.
2. error: [Errno 9] Bad file descriptor
3. Can't dup an SSL object

When the SIGHUP signal is received by the service launcher in
common service framework, it calls the server's reset method.
As reset method is not present in Sever class of
keystone.common.environment.eventlet_server module, it raises
AttributeError: 'Server' object has no attribute 'reset'.

After adding reset method when SIGHUP signal is sent to service
parent process, it stops the service and then calls service start
method again. When it stops the service, it kills the eventlet
thread, which internally closes the wsgi server socket object.
This server socket object is now not usable again and it throws
following error, while restarting the service:

error: [Errno 9] Bad file descriptor

To resolve 'Bad file descriptor' error, creating duplicate
socket object, every time service starts.

As SSL object can not be duplicated, creating duplicate
socket object before converting a regular socket into an
SSL socket.

Closes-Bug: #1337850
Change-Id: I52caacc01a94428e4986ef68d032ad317e09b276
",git fetch https://review.opendev.org/openstack/keystone refs/changes/82/107482/8 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_wsgi.py', 'bin/keystone-all', 'keystone/common/environment/eventlet_server.py']",3,dd6777dac57dcabed8a8dab5838aaf808a7c649d,bug/1337850," keepalive=False, keepidle=None, backlog=128): self.pool_size = threads self.pool = eventlet.GreenPool(self.pool_size) bind_addr = (host, port) # TODO(dims): eventlet's green dns/socket module does not actually # support IPv6 in getaddrinfo(). We need to get around this in the # future or monitor upstream for a fix try: info = socket.getaddrinfo(bind_addr[0], bind_addr[1], socket.AF_UNSPEC, socket.SOCK_STREAM)[0] family = info[0] bind_addr = info[-1] except Exception: family = socket.AF_INET try: self.socket = eventlet.listen(bind_addr, family, backlog=backlog) except EnvironmentError: LOG.error(_(""Could not bind to %(host)s:%(port)s""), {'host': host, 'port': port}) raise def start(self, key=None, backlog=128): """"""Run a WSGI server with the given application."""""" dup_socket = self.socket.dup() if key: self.socket_info[key] = self.socket.getsockname() dup_socket = eventlet.wrap_ssl(dup_socket, certfile=self.certfile, keyfile=self.keyfile, server_side=True, cert_reqs=cert_reqs, ca_certs=self.ca_certs) dup_socket.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1) dup_socket.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPIDLE, self.keepidle) self.greenthread = self.pool.spawn(self._run, self.application, dup_socket) def reset(self): """"""Reset server greenpool size to default. :returns: None """""" self.pool.resize(self.pool_size) "," keepalive=False, keepidle=None): self.pool = eventlet.GreenPool(threads) def start(self, key=None, backlog=128): """"""Run a WSGI server with the given application."""""" if self.socket is None: self.listen(key=key, backlog=backlog) self.greenthread = self.pool.spawn(self._run, self.application, self.socket) def listen(self, key=None, backlog=128): """"""Create and start listening on socket. Call before forking worker processes. Raises Exception if this has already been called. """""" if self.socket is not None: raise Exception(_('Server can only listen once.')) # TODO(dims): eventlet's green dns/socket module does not actually # support IPv6 in getaddrinfo(). We need to get around this in the # future or monitor upstream for a fix info = socket.getaddrinfo(self.host, self.port, socket.AF_UNSPEC, socket.SOCK_STREAM)[0] _socket = eventlet.listen(info[-1], family=info[0], backlog=backlog) if key: self.socket_info[key] = _socket.getsockname() sslsocket = eventlet.wrap_ssl(_socket, certfile=self.certfile, keyfile=self.keyfile, server_side=True, cert_reqs=cert_reqs, ca_certs=self.ca_certs) _socket = sslsocket _socket.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1) _socket.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPIDLE, self.keepidle) self.socket = _socket",80,55
openstack%2Fnova~master~I5e8ef84fd69b5fdf9f4598defaf178256ea9d7da,openstack/nova,master,I5e8ef84fd69b5fdf9f4598defaf178256ea9d7da,Fixes unit tests failing on Jenkins,ABANDONED,2014-08-14 16:29:36.000000000,2014-08-15 01:19:31.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-08-14 16:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9afe32fa0d56a58db0110153c4b7ec42f87ebf2', 'message': 'Fixes unit tests failing on Jenkins\n\nFixes failing tests test_migrationops and test_vmops from\nthe Hyper-V unit tests module.\n\nFixes-Bug: #1356971\n\nChange-Id: I5e8ef84fd69b5fdf9f4598defaf178256ea9d7da\n'}, {'number': 2, 'created': '2014-08-14 16:33:18.000000000', 'files': ['nova/tests/virt/hyperv/test_migrationops.py', 'nova/tests/virt/hyperv/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dc6e86ceefeecbe039a574a7fbff925c914f3f9c', 'message': 'Fixes unit tests failing on Jenkins\n\nFixes failing tests test_migrationops and test_vmops from\nthe Hyper-V unit tests module.\n\nFixes-Bug: #1356971\n\nChange-Id: I5e8ef84fd69b5fdf9f4598defaf178256ea9d7da\n'}]",0,114293,dc6e86ceefeecbe039a574a7fbff925c914f3f9c,8,4,2,8213,,,0,"Fixes unit tests failing on Jenkins

Fixes failing tests test_migrationops and test_vmops from
the Hyper-V unit tests module.

Fixes-Bug: #1356971

Change-Id: I5e8ef84fd69b5fdf9f4598defaf178256ea9d7da
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/114293/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/hyperv/test_migrationops.py', 'nova/tests/virt/hyperv/test_vmops.py']",2,e9afe32fa0d56a58db0110153c4b7ec42f87ebf2,bug/1356971,"import mock patched_func = mock.patch.object(vmops.utilsfactory, ""get_hostutils"") patched_func.start() self.addCleanup(patched_func.stop) ",,12,0
openstack%2Fopenstack-manuals~master~I1c67754c6bb9e8be61afe18bf17000180769277b,openstack/openstack-manuals,master,I1c67754c6bb9e8be61afe18bf17000180769277b,Add ProphetStor DPL Storage server volume driver for Cinder,MERGED,2014-06-03 05:40:57.000000000,2014-08-15 01:15:09.000000000,2014-08-15 01:15:08.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 9416}, {'_account_id': 12311}]","[{'number': 1, 'created': '2014-06-03 05:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e014cb2fa33641ceb0c337156605793016265950', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 2, 'created': '2014-06-03 09:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e1f6950d14feb8a228737829b156e5a957ef5d73', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 3, 'created': '2014-07-15 02:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d1f0f7fee5f358e6d3893d41c3067ef9b9e8c010', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 4, 'created': '2014-08-11 08:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ca382c4be8f06d377678a13bccd17a3b1bcc1927', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 5, 'created': '2014-08-11 08:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dfbe4be68602159eba563b20f0091bc610e66248', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 6, 'created': '2014-08-13 03:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a9250bf4c936b09c682a9605e6bae43f68df609d', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/08/13] https://review.openstack.org/#/c/97396/ merged.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 7, 'created': '2014-08-13 13:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/445cbac131c8c2b1a9534bcc086eb480a3bcd51e', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/08/13] https://review.openstack.org/#/c/97396/ merged.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 8, 'created': '2014-08-14 02:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0f9fce6e0d55f59073b841153a3fe3c4ebf0e737', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 9, 'created': '2014-08-14 06:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/307ebea71b1ebddbc7b97488dd304bfedbe35208', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 10, 'created': '2014-08-14 07:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e378a0011a6e29e5cfc9868838a49caa0f274449', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 11, 'created': '2014-08-14 08:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e04531813bd30f855f8ba7eb5cadee46267b02fc', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 12, 'created': '2014-08-14 09:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/31564b903247a4da3c7fafebbb3be77d0788bb0f', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 13, 'created': '2014-08-14 14:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/016ffd0062e91fb75258dca6978694eeb3ef57db', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 14, 'created': '2014-08-14 15:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/31aca73a071df9a260900fd0b196dbf809892011', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 15, 'created': '2014-08-14 15:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b274e85887d1189728d1aa2a3dca68454fd1277a', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 16, 'created': '2014-08-14 16:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2ffc5f21667ffac57cc33a4813fb5afa39a9d2ea', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 17, 'created': '2014-08-14 16:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/da1917117d00ed8e17af3378cc4710c7877eece3', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}, {'number': 18, 'created': '2014-08-14 16:44:43.000000000', 'files': ['doc/common/tables/cinder-prophststor_dpl.xml', 'doc/config-reference/block-storage/section_volume-drivers.xml', 'doc/config-reference/block-storage/drivers/prophetstor-dpl-driver.xml', 'tools/autogenerate-config-flagmappings/cinder.flagmappings'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/93e5693a375578f2b6c23da3bf72598b04d91a5f', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: I1c67754c6bb9e8be61afe18bf17000180769277b\n'}]",62,97396,93e5693a375578f2b6c23da3bf72598b04d91a5f,101,8,18,9416,,,0,"Add ProphetStor DPL Storage server volume driver for Cinder

ProphetStor DPL Storage server enables x86 commodity hardware as
enterprise-grade storage systems.

Implements: blueprint prophetstor-dpl-driver
Change-Id: I1c67754c6bb9e8be61afe18bf17000180769277b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/96/97396/17 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/tables/cinder-prophststor_dpl.xml', 'doc/config-reference/block-storage/drivers/prophet-dpl-driver.xml']",2,e014cb2fa33641ceb0c337156605793016265950,bp/prophetstor-dpl-driver,"<section xml:id=""prophetstor-dpl-driver"" xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0""> <title>ProphetStor DPL Fiber Channel and iSCSI drivers</title> <para>The <filename>DPLFCDriver</filename> and <filename>DPLISCSIDriver</filename> drivers, which are based on the Block Storage service (Cindeer) plug-in architecture, run volume operations by communicating with the ProphetStor DPL storage system over HTTPS.</para> <para>For information about hot to manage ProphetStor DPL storage systems, see the ProphetStor user documentation.</para> <section xml:id=""prophetstor-dpl-supported-ops""> <title>Supported operations</title> <itemizedlist> <listitem> <para>Volume Create/Delete.</para> </listitem> <listitem> <para>Volume Attach/Detach.</para> </listitem> <listitem> <para>Snapshot Create/Delete.</para> </listitem> <listitem> <para>Create Volume from Snapshot.</para> </listitem> <listitem> <para>Get Volume stats.</para> </listitem> <listitem> <para>Clone Volume.</para> </listitem> <listitem> <para>Extend Volume.</para> </listitem> <listitem> <para>In addition to the minimum feature set, DPL Storage Server also provides: Volume Rollback</para> </listitem> </itemizedlist> </section> <section xml:id=""'enable-prophetstor-dpl-fiber-channel""> <title>Enable the ProphetStor Fiber Channel and iSCSI drivers</title> <para>The <filename>DPLFCDriver</filename> and <filename>DPLISCSIDriver</filename> are installed with the OpenStack software.</para> <procedure> <step> <para>Make the following changes in the <filename>/etc/cinder/cinder.conf</filename> files.</para> <programlisting language=""ini""><emphasis role=""'blod"">## REQUIRED SETTINGS</emphasis> # IP address of SAN controller (string value) #san_ip=127.0.0.1 # Username for SAN controller (string value) #san_login=admin # Password for SAN controller (string value) #san_password=password # DPL pool uuid in which DPL volumes are stored. (string # value) #dpl_pool=e92fa0d971e344be8d1b0e206cb2231e # DPL port number. (integer value) #dpl_port=8357 # FIBER CHANNEL(uncomment the next line to enable the FC driver) # volume_driver=cinder.volume.drivers.prophetstor.dpl_iscsi.DPLISCSIDriver # iSCSI (uncomment the next line to enable the iSCSI driver and # hp3par_iscsi_ips or iscsi_ip_address) #volume_driver=cinder.volume.drivers.prophetstor.dpl_fc.DPLFCDriver </programlisting> </step> <step> <para>Save the changes to the <filename>cinder.conf</filename> file and restart the <systemitem class=""service"" >cinder-volume</systemitem> service.</para> </step> </procedure> <para>The HP 3PAR Fibre Channel and iSCSI drivers are now enabled on your OpenStack system. If you experience problems, review the Block Storage service log files for errors.</para> </section> </section>",,134,0
openstack%2Fdevstack~master~I96cef118daf931b648c0483525ac7d2287fec2e0,openstack/devstack,master,I96cef118daf931b648c0483525ac7d2287fec2e0,Modify `glance image-create` commands to use openstackclient,MERGED,2014-08-03 03:48:29.000000000,2014-08-15 00:50:41.000000000,2014-08-15 00:50:41.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 7350}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-03 03:48:29.000000000', 'files': ['lib/ironic', 'functions', 'lib/baremetal'], 'web_link': 'https://opendev.org/openstack/devstack/commit/8d3ac2df582730717392798ae46b436238d91b70', 'message': 'Modify `glance image-create` commands to use openstackclient\n\nChange `glance image-create` commands to use `openstack image create`,\nin an effort to unify the CLI.\n\nChange-Id: I96cef118daf931b648c0483525ac7d2287fec2e0\n'}]",0,111538,8d3ac2df582730717392798ae46b436238d91b70,12,6,1,6482,,,0,"Modify `glance image-create` commands to use openstackclient

Change `glance image-create` commands to use `openstack image create`,
in an effort to unify the CLI.

Change-Id: I96cef118daf931b648c0483525ac7d2287fec2e0
",git fetch https://review.opendev.org/openstack/devstack refs/changes/38/111538/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ironic', 'functions', 'lib/baremetal']",3,8d3ac2df582730717392798ae46b436238d91b70,update_glance_create," BM_DEPLOY_KERNEL_ID=$(openstack \ --os-token $token \ --os-url http://$GLANCE_HOSTPORT \ image create \ $BM_DEPLOY_KERNEL \ --public --disk-format=aki \ BM_DEPLOY_RAMDISK_ID=$(openstack \ --os-token $token \ --os-url http://$GLANCE_HOSTPORT \ image create \ $BM_DEPLOY_RAMDISK \ --public --disk-format=ari \ KERNEL_ID=$(openstack \ --os-token $token \ --os-url http://$GLANCE_HOSTPORT \ image create \ $image_name-kernel \ --public --disk-format=aki \ RAMDISK_ID=$(openstack \ --os-token $token \ --os-url http://$GLANCE_HOSTPORT \ image create \ $image_name-initrd \ --public --disk-format=ari \ KERNEL_ID=$(openstack \ --os-token $token \ --os-url http://$GLANCE_HOSTPORT \ image create \ ""$IMAGE_NAME-kernel"" --public \ RAMDISK_ID=$(openstack \ --os-token $token \ --os-url http://$GLANCE_HOSTPORT \ image create \ ""$IMAGE_NAME-ramdisk"" --public \ openstack \ --os-token $token \ --os-url http://$GLANCE_HOSTPORT \ image create \ ""${IMAGE_NAME%.img}"" --public \"," BM_DEPLOY_KERNEL_ID=$(glance \ --os-auth-token $token \ --os-image-url http://$GLANCE_HOSTPORT \ image-create \ --name $BM_DEPLOY_KERNEL \ --is-public True --disk-format=aki \ BM_DEPLOY_RAMDISK_ID=$(glance \ --os-auth-token $token \ --os-image-url http://$GLANCE_HOSTPORT \ image-create \ --name $BM_DEPLOY_RAMDISK \ --is-public True --disk-format=ari \ KERNEL_ID=$(glance \ --os-auth-token $token \ --os-image-url http://$GLANCE_HOSTPORT \ image-create \ --name $image_name-kernel \ --is-public True --disk-format=aki \ RAMDISK_ID=$(glance \ --os-auth-token $token \ --os-image-url http://$GLANCE_HOSTPORT \ image-create \ --name $image_name-initrd \ --is-public True --disk-format=ari \ KERNEL_ID=$(glance \ --os-auth-token $token \ --os-image-url http://$GLANCE_HOSTPORT \ image-create \ --name ""$IMAGE_NAME-kernel"" --is-public True \ RAMDISK_ID=$(glance \ --os-auth-token $token \ --os-image-url http://$GLANCE_HOSTPORT \ image-create \ --name ""$IMAGE_NAME-ramdisk"" --is-public True \ glance \ --os-auth-token $token \ --os-image-url http://$GLANCE_HOSTPORT \ image-create \ --name ""${IMAGE_NAME%.img}"" --is-public True \",68,68
openstack%2Fneutron~master~I044daf04216ec61245ddb51689f8e50be5666e34,openstack/neutron,master,I044daf04216ec61245ddb51689f8e50be5666e34,Fixing neutron-db-manage with some options other than upgrade/downgrade,MERGED,2014-08-06 00:45:08.000000000,2014-08-15 00:19:02.000000000,2014-08-15 00:19:00.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2711}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7448}, {'_account_id': 7962}, {'_account_id': 8655}, {'_account_id': 9380}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 11701}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-06 00:45:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c637a5c3327854d7354bb51f38623df6d6a06e42', 'message': 'Fixing neutron-db-manage with some of non-upgrade/downgrade options\n\n""mysql-engine"" argument was added to upgrade and downgrade option of\nneutron-db-manage.\nReference commit: https://github.com/openstack/neutron/commit/466e89970f11918a809aafe8a048d138d4664299\n\nmigration environment\'s run_migration_offline/online() gets called even for\nother neutron-db-manage options as well such as current, history, stamp, branches etc.\nFor those options since the argument can not be set, it throws oslo.config.cfg.NoSuchOptError.\nThis fix tries to catch it and set the value accordingly.\n\nFixes bug:1353180\n\nChange-Id: I044daf04216ec61245ddb51689f8e50be5666e34\n'}, {'number': 2, 'created': '2014-08-06 00:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d5d338b3ef05d2fb284d33071a20e32ea3e65c9f', 'message': 'Fixing neutron-db-manage with some of non-upgrade/downgrade options\n\n""mysql-engine"" argument was added to upgrade and downgrade option of\nneutron-db-manage.\nReference commit: https://github.com/openstack/neutron/commit/466e89970f11918a809aafe8a048d138d4664299\n\nmigration environment\'s run_migration_offline/online() gets called even for\nother neutron-db-manage options as well such as current, history, stamp, branches etc.\nFor those options since the argument can not be set, it throws oslo.config.cfg.NoSuchOptError.\nThis fix tries to catch it and set the value accordingly.\n\nCloses-bug: #1353180\n\nChange-Id: I044daf04216ec61245ddb51689f8e50be5666e34\n'}, {'number': 3, 'created': '2014-08-11 16:38:16.000000000', 'files': ['neutron/db/migration/alembic_migrations/env.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/01b2eedd05fb91aa8970c64b753d831257243598', 'message': 'Fixing neutron-db-manage with some options other than upgrade/downgrade\n\n""mysql-engine"" argument was added to upgrade and downgrade option of\nneutron-db-manage.\nReference commit: http://tinyurl.com/mzepbmq\n\nmigration environment\'s run_migration_offline/online() gets called\neven for other neutron-db-manage options as well such as current,\nhistory, stamp, branches etc. For those options since the argument\ncan not be set, it throws oslo.config.cfg.NoSuchOptError.\nThis fix tries to catch it and set the value accordingly.\n\nCloses-bug: #1353180\n\nChange-Id: I044daf04216ec61245ddb51689f8e50be5666e34\n'}]",6,112171,01b2eedd05fb91aa8970c64b753d831257243598,64,25,3,7962,,,0,"Fixing neutron-db-manage with some options other than upgrade/downgrade

""mysql-engine"" argument was added to upgrade and downgrade option of
neutron-db-manage.
Reference commit: http://tinyurl.com/mzepbmq

migration environment's run_migration_offline/online() gets called
even for other neutron-db-manage options as well such as current,
history, stamp, branches etc. For those options since the argument
can not be set, it throws oslo.config.cfg.NoSuchOptError.
This fix tries to catch it and set the value accordingly.

Closes-bug: #1353180

Change-Id: I044daf04216ec61245ddb51689f8e50be5666e34
",git fetch https://review.opendev.org/openstack/neutron refs/changes/71/112171/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/env.py'],1,c637a5c3327854d7354bb51f38623df6d6a06e42,bug/1353180,from oslo.config import cfgdef set_mysql_engine(): try: mysql_engine = neutron_config.command.mysql_engine except cfg.NoSuchOptError: mysql_engine = None set_mysql_engine() set_mysql_engine(),def set_mysql_engine(mysql_engine): set_mysql_engine(neutron_config.command.mysql_engine) set_mysql_engine(neutron_config.command.mysql_engine),9,3
openstack%2Fswift~feature%2Fec~I605719bd9ab26b36310a06dbf518efc69ba41172,openstack/swift,feature/ec,I605719bd9ab26b36310a06dbf518efc69ba41172,"EC: Add support for policy types, 'erasure_coding' policy",MERGED,2014-06-30 19:49:11.000000000,2014-08-15 00:18:55.000000000,2014-08-15 00:18:54.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 4608}, {'_account_id': 5189}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7485}, {'_account_id': 9625}, {'_account_id': 11608}]","[{'number': 1, 'created': '2014-06-30 19:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e40fa61eeb5a52ca193f980ef5e6bd3c96d40656', 'message': 'EC: Add support for policy types, \'erasure_coding\' policy\n\nThis patch extends the StoragePolicy class for non-replication storage\npolicies, the first candidate being ""erasure coding"".\n\nChanges:\n\n - Add \'policy_type\' support to base StoragePolicy class\n\n - Subclass StoragePolicy\n\n   - ""ReplicationStoragePolicy"":\n     . Replication policy, default\n     . policy_type = \'replication\'\n\n   - ""ECStoragePolicy"":\n     . Erasure Coding policy\n     . policy_type = \'erasure_coding\'\n     . Private member variables\n       ec_type (EC backend),\n       ec_num_data_fragments (number of fragments original\n         data split into after erasure coding operation),\n       ec_num_parity_fragments (number of redundant parity\n         fragments generated during erasure coding)\n     . Private methods\n       EC specific metadata and ring validator methods.\n\n - Swift will use PyECLib, a Python Erasure Coding library,\n   for erasure coding operations. This patch adds PyECLib to\n   Swift requirements.txt (https://bitbucket.org/kmgreen2/pyeclib/)\n\n - Add test cases for\n   - \'policy_type\' StoragePolicy member\n   - policy_type == \'erasure_coding\'\n   - common util \'positive_int_value\'\n\nImplements: blueprint ec-proxy-work\nChange-Id: I605719bd9ab26b36310a06dbf518efc69ba41172\n'}, {'number': 2, 'created': '2014-07-08 17:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/729a679991b0c64ff25a286ea9fdca35fc04f3f3', 'message': 'EC: Add support for policy types, \'erasure_coding\' policy\n\nThis patch extends the StoragePolicy class for non-replication storage\npolicies, the first one being ""erasure coding"".\n\nChanges:\n\n - Add \'policy_type\' support to base StoragePolicy class\n\n - Subclass StoragePolicy\n\n   - ""ReplicationStoragePolicy"":\n     . Replication policy, default\n     . policy_type = \'replication\'\n\n   - ""ECStoragePolicy"":\n     . Erasure Coding policy\n     . policy_type = \'erasure_coding\'\n     . Private member variables\n       ec_type (EC backend),\n       ec_num_data_fragments (number of fragments original\n         data split into after erasure coding operation),\n       ec_num_parity_fragments (number of parity fragments\n       generated during erasure coding)\n     . Private methods\n       EC specific metadata and ring validator methods.\n\n - Swift will use PyECLib, a Python Erasure Coding library,\n   for erasure coding operations. This patch adds PyECLib to\n   Swift requirements.txt. PyECLib is already an approved\n   OpenStack core requirement.\n   (https://bitbucket.org/kmgreen2/pyeclib/)\n\n - Add test cases for\n   - \'policy_type\' StoragePolicy member\n   - policy_type == \'erasure_coding\'\n   - common util \'positive_int_value\'\n\nImplements: blueprint ec-proxy-work\nChange-Id: I605719bd9ab26b36310a06dbf518efc69ba41172\n'}, {'number': 3, 'created': '2014-07-14 18:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e2c47187b32952e24a210b62ab0cb495e152c6fb', 'message': 'EC: Add support for policy types, \'erasure_coding\' policy\n\nThis patch extends the StoragePolicy class for non-replication storage\npolicies, the first one being ""erasure coding"".\n\nChanges:\n\n - Add \'policy_type\' support to base StoragePolicy class\n - Disallow direct instatiation of StoragePolicy class\n\n - Subclass StoragePolicy\n\n   - ""ReplicationStoragePolicy"":\n     . Replication policy, default\n     . policy_type = \'replication\'\n\n   - ""ECStoragePolicy"":\n     . Erasure Coding policy\n     . policy_type = \'erasure_coding\'\n     . Private member variables\n       ec_type (EC backend),\n       ec_num_data_fragments (number of fragments original\n         data split into after erasure coding operation),\n       ec_num_parity_fragments (number of parity fragments\n       generated during erasure coding)\n     . Private methods\n       EC specific metadata and ring validator methods.\n\n - Swift will use PyECLib, a Python Erasure Coding library,\n   for erasure coding operations. This patch adds PyECLib to\n   Swift requirements.txt. PyECLib is already an approved\n   OpenStack core requirement.\n   (https://bitbucket.org/kmgreen2/pyeclib/)\n\n - Add test cases for\n   - \'policy_type\' StoragePolicy member\n   - policy_type == \'erasure_coding\'\n   - common util \'positive_int_value\'\n\n - Make default policy type for StoragePolicy tests cases\n   \'ReplicationStoragePolicy\'\n\nImplements: blueprint ec-proxy-work\nChange-Id: I605719bd9ab26b36310a06dbf518efc69ba41172\n'}, {'number': 4, 'created': '2014-07-23 04:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/91d79d1a3af02db6862ed1a0f58effd1b755d920', 'message': 'EC: Add support for policy types, \'erasure_coding\' policy\n\nThis patch extends the StoragePolicy class for non-replication storage\npolicies, the first one being ""erasure coding"".\n\nChanges:\n\n - Add \'policy_type\' support to base StoragePolicy class\n - Disallow direct instatiation of StoragePolicy class\n\n - Subclass StoragePolicy\n\n   - ""ReplicationStoragePolicy"":\n     . Replication policy, default\n     . policy_type = \'replication\'\n\n   - ""ECStoragePolicy"":\n     . Erasure Coding policy\n     . policy_type = \'erasure_coding\'\n     . Private member variables\n       ec_type (EC backend),\n       ec_num_data_fragments (number of fragments original\n         data split into after erasure coding operation),\n       ec_num_parity_fragments (number of parity fragments\n       generated during erasure coding)\n     . Private methods\n       EC specific metadata and ring validator methods.\n\n - Swift will use PyECLib, a Python Erasure Coding library,\n   for erasure coding operations. This patch adds PyECLib to\n   Swift requirements.txt. PyECLib is already an approved\n   OpenStack core requirement.\n   (https://bitbucket.org/kmgreen2/pyeclib/)\n\n - Add test cases for\n   - \'policy_type\' StoragePolicy member\n   - policy_type == \'erasure_coding\'\n   - common util \'positive_int_value\'\n\n - Make default policy type for StoragePolicy tests cases\n   \'ReplicationStoragePolicy\'\n\nImplements: blueprint ec-proxy-work\nChange-Id: I605719bd9ab26b36310a06dbf518efc69ba41172\n'}, {'number': 5, 'created': '2014-07-30 04:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/acac77677f5cda588e66f6cc855216ddc3245638', 'message': 'EC: Add support for policy types, \'erasure_coding\' policy\n\nThis patch extends the StoragePolicy class for non-replication storage\npolicies, the first one being ""erasure coding"".\n\nChanges:\n\n - Add \'policy_type\' support to base StoragePolicy class\n - Disallow direct instatiation of StoragePolicy class\n\n - Subclass StoragePolicy\n\n   - ""ReplicationStoragePolicy"":\n     . Replication policy, default\n     . policy_type = \'replication\'\n\n   - ""ECStoragePolicy"":\n     . Erasure Coding policy\n     . policy_type = \'erasure_coding\'\n     . Private member variables\n       ec_type (EC backend),\n       ec_num_data_fragments (number of fragments original\n         data split into after erasure coding operation),\n       ec_num_parity_fragments (number of parity fragments\n       generated during erasure coding)\n     . Private methods\n       EC specific metadata and ring validator methods.\n\n - Swift will use PyECLib, a Python Erasure Coding library,\n   for erasure coding operations. This patch adds PyECLib to\n   Swift requirements.txt. PyECLib is already an approved\n   OpenStack core requirement.\n   (https://bitbucket.org/kmgreen2/pyeclib/)\n\n - Add test cases for\n   - \'policy_type\' StoragePolicy member\n   - policy_type == \'erasure_coding\'\n   - common util \'positive_int_value\'\n\n - Make default policy type for StoragePolicy tests cases\n   \'ReplicationStoragePolicy\'\n\nDocImpact\n\nImplements: blueprint ec-proxy-work\nChange-Id: I605719bd9ab26b36310a06dbf518efc69ba41172\n'}, {'number': 6, 'created': '2014-07-30 16:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2da6f3c66d43e8d9810465e077b152c6c5e0ba88', 'message': 'EC: Add support for policy types, \'erasure_coding\' policy\n\nThis patch extends the StoragePolicy class for non-replication storage\npolicies, the first one being ""erasure coding"".\n\nChanges:\n\n - Add \'policy_type\' support to base StoragePolicy class\n - Disallow direct instatiation of StoragePolicy class\n\n - Subclass StoragePolicy\n\n   - ""ReplicationStoragePolicy"":\n     . Replication policy, default\n     . policy_type = \'replication\'\n\n   - ""ECStoragePolicy"":\n     . Erasure Coding policy\n     . policy_type = \'erasure_coding\'\n     . Private member variables\n       ec_type (EC backend),\n       ec_num_data_fragments (number of fragments original\n         data split into after erasure coding operation),\n       ec_num_parity_fragments (number of parity fragments\n       generated during erasure coding)\n     . Private methods\n       EC specific metadata and ring validator methods.\n\n - Swift will use PyECLib, a Python Erasure Coding library,\n   for erasure coding operations. This patch adds PyECLib to\n   Swift requirements.txt. PyECLib is already an approved\n   OpenStack core requirement.\n   (https://bitbucket.org/kmgreen2/pyeclib/)\n\n - Add test cases for\n   - \'policy_type\' StoragePolicy member\n   - policy_type == \'erasure_coding\'\n   - common util \'positive_int_value\'\n\n - Make default policy type for StoragePolicy tests cases\n   \'ReplicationStoragePolicy\'\n\nDocImpact\n\nImplements: blueprint ec-proxy-work\nChange-Id: I605719bd9ab26b36310a06dbf518efc69ba41172\n'}, {'number': 7, 'created': '2014-07-31 20:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/18c2b920727f386e25425635c18a76b393f2b7f5', 'message': 'EC: Add support for policy types, \'erasure_coding\' policy\n\nThis patch extends the StoragePolicy class for non-replication storage\npolicies, the first one being ""erasure coding"".\n\nChanges:\n\n - Add \'policy_type\' support to base StoragePolicy class\n - Disallow direct instatiation of StoragePolicy class\n\n - Subclass StoragePolicy\n\n   - ""ReplicationStoragePolicy"":\n     . Replication policy, default\n     . policy_type = \'replication\'\n\n   - ""ECStoragePolicy"":\n     . Erasure Coding policy\n     . policy_type = \'erasure_coding\'\n     . Private member variables\n       ec_type (EC backend),\n       ec_num_data_fragments (number of fragments original\n         data split into after erasure coding operation),\n       ec_num_parity_fragments (number of parity fragments\n       generated during erasure coding)\n     . Private methods\n       EC specific metadata and ring validator methods.\n\n - Swift will use PyECLib, a Python Erasure Coding library,\n   for erasure coding operations. This patch adds PyECLib to\n   Swift requirements.txt. PyECLib is already an approved\n   OpenStack core requirement.\n   (https://bitbucket.org/kmgreen2/pyeclib/)\n\n - Add test cases for\n   - \'policy_type\' StoragePolicy member\n   - policy_type == \'erasure_coding\'\n   - common util \'positive_int_value\'\n\n - Make default policy type for StoragePolicy tests cases\n   \'ReplicationStoragePolicy\'\n\nDocImpact\n\nImplements: blueprint ec-proxy-work\nChange-Id: I605719bd9ab26b36310a06dbf518efc69ba41172\n'}, {'number': 8, 'created': '2014-08-01 00:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5da30cb59e19feafe152a750e59374ce93d22602', 'message': 'EC: Add support for policy types, \'erasure_coding\' policy\n\nThis patch extends the StoragePolicy class for non-replication storage\npolicies, the first one being ""erasure coding"".\n\nChanges:\n\n - Add \'policy_type\' support to base StoragePolicy class\n - Disallow direct instatiation of StoragePolicy class\n\n - Subclass StoragePolicy\n\n   - ""ReplicationStoragePolicy"":\n     . Replication policy, default\n     . policy_type = \'replication\'\n\n   - ""ECStoragePolicy"":\n     . Erasure Coding policy\n     . policy_type = \'erasure_coding\'\n     . Private member variables\n       ec_type (EC backend),\n       ec_num_data_fragments (number of fragments original\n         data split into after erasure coding operation),\n       ec_num_parity_fragments (number of parity fragments\n       generated during erasure coding)\n     . Private methods\n       EC specific metadata and ring validator methods.\n\n - Swift will use PyECLib, a Python Erasure Coding library,\n   for erasure coding operations. This patch adds PyECLib to\n   Swift requirements.txt. PyECLib is already an approved\n   OpenStack core requirement.\n   (https://bitbucket.org/kmgreen2/pyeclib/)\n\n - Add test cases for\n   - \'policy_type\' StoragePolicy member\n   - policy_type == \'erasure_coding\'\n\n - Make default policy type for StoragePolicy tests cases\n   \'ReplicationStoragePolicy\'\n\nDocImpact\n\nImplements: blueprint ec-proxy-work\nChange-Id: I605719bd9ab26b36310a06dbf518efc69ba41172\n'}, {'number': 9, 'created': '2014-08-06 08:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f2a4e09ea3bf4af9ca00409b3340077aa2d896dc', 'message': 'EC: Add support for policy types, \'erasure_coding\' policy\n\nThis patch extends the StoragePolicy class for non-replication storage\npolicies, the first one being ""erasure coding"".\n\nChanges:\n\n - Add \'policy_type\' support to base StoragePolicy class\n - Disallow direct instatiation of StoragePolicy class\n\n - Subclass StoragePolicy\n\n   - ""ReplicationStoragePolicy"":\n     . Replication policy, default\n     . policy_type = \'replication\'\n\n   - ""ECStoragePolicy"":\n     . Erasure Coding policy\n     . policy_type = \'erasure_coding\'\n     . Private member variables\n       ec_type (EC backend),\n       ec_num_data_fragments (number of fragments original\n         data split into after erasure coding operation),\n       ec_num_parity_fragments (number of parity fragments\n       generated during erasure coding)\n     . Private methods\n       EC specific metadata and ring validator methods.\n\n - Swift will use PyECLib, a Python Erasure Coding library,\n   for erasure coding operations. This patch adds PyECLib to\n   Swift requirements.txt. PyECLib is already an approved\n   OpenStack core requirement.\n   (https://bitbucket.org/kmgreen2/pyeclib/)\n\n - Add test cases for\n   - \'policy_type\' StoragePolicy member\n   - policy_type == \'erasure_coding\'\n\n - Make default policy type for StoragePolicy tests cases\n   \'ReplicationStoragePolicy\'\n\nDocImpact\n\nImplements: blueprint ec-proxy-work\nChange-Id: I605719bd9ab26b36310a06dbf518efc69ba41172\n'}, {'number': 10, 'created': '2014-08-08 18:12:42.000000000', 'files': ['test/unit/account/test_reaper.py', 'test/unit/account/test_server.py', 'test/unit/common/test_storage_policy.py', 'test/unit/proxy/controllers/test_account.py', 'test/unit/cli/test_info.py', 'test/unit/proxy/test_server.py', 'test/unit/__init__.py', 'test/unit/proxy/controllers/test_obj.py', 'test/unit/obj/test_server.py', 'test/unit/proxy/controllers/test_container.py', 'test/unit/obj/test_replicator.py', 'test/unit/proxy/controllers/test_base.py', 'test/unit/common/middleware/test_list_endpoints.py', 'test/unit/container/test_server.py', 'test/unit/account/test_backend.py', 'test/unit/obj/test_updater.py', 'test/unit/obj/test_auditor.py', 'requirements.txt', 'test/unit/common/test_internal_client.py', 'test/unit/container/test_sync.py', 'swift/common/storage_policy.py', 'test/unit/proxy/test_sysmeta.py', 'etc/swift.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/ef81d2ff1f1fc50bbe651c495d5fef6667ea6f48', 'message': 'EC: Add support for policy types, \'erasure_coding\' policy\n\nThis patch extends the StoragePolicy class for non-replication storage\npolicies, the first one being ""erasure coding"".\n\nChanges:\n\n - Add \'policy_type\' support to base StoragePolicy class\n - Disallow direct instatiation of StoragePolicy class\n\n - Subclass StoragePolicy\n\n   - ""ReplicationStoragePolicy"":\n     . Replication policy, default\n     . policy_type = \'replication\'\n\n   - ""ECStoragePolicy"":\n     . Erasure Coding policy\n     . policy_type = \'erasure_coding\'\n     . Private member variables\n       ec_type (EC backend),\n       ec_num_data_fragments (number of fragments original\n         data split into after erasure coding operation),\n       ec_num_parity_fragments (number of parity fragments\n       generated during erasure coding)\n     . Private methods\n       EC specific metadata and ring validator methods.\n\n - Swift will use PyECLib, a Python Erasure Coding library,\n   for erasure coding operations. This patch adds PyECLib to\n   Swift requirements.txt. PyECLib is already an approved\n   OpenStack core requirement.\n   (https://bitbucket.org/kmgreen2/pyeclib/)\n\n - Add test cases for\n   - \'policy_type\' StoragePolicy member\n   - policy_type == \'erasure_coding\'\n\n - Make default policy type for StoragePolicy tests cases\n   \'ReplicationStoragePolicy\'\n\nDocImpact\n\nImplements: blueprint ec-proxy-work\nChange-Id: I605719bd9ab26b36310a06dbf518efc69ba41172\n'}]",82,103644,ef81d2ff1f1fc50bbe651c495d5fef6667ea6f48,154,11,10,7485,,,0,"EC: Add support for policy types, 'erasure_coding' policy

This patch extends the StoragePolicy class for non-replication storage
policies, the first one being ""erasure coding"".

Changes:

 - Add 'policy_type' support to base StoragePolicy class
 - Disallow direct instatiation of StoragePolicy class

 - Subclass StoragePolicy

   - ""ReplicationStoragePolicy"":
     . Replication policy, default
     . policy_type = 'replication'

   - ""ECStoragePolicy"":
     . Erasure Coding policy
     . policy_type = 'erasure_coding'
     . Private member variables
       ec_type (EC backend),
       ec_num_data_fragments (number of fragments original
         data split into after erasure coding operation),
       ec_num_parity_fragments (number of parity fragments
       generated during erasure coding)
     . Private methods
       EC specific metadata and ring validator methods.

 - Swift will use PyECLib, a Python Erasure Coding library,
   for erasure coding operations. This patch adds PyECLib to
   Swift requirements.txt. PyECLib is already an approved
   OpenStack core requirement.
   (https://bitbucket.org/kmgreen2/pyeclib/)

 - Add test cases for
   - 'policy_type' StoragePolicy member
   - policy_type == 'erasure_coding'

 - Make default policy type for StoragePolicy tests cases
   'ReplicationStoragePolicy'

DocImpact

Implements: blueprint ec-proxy-work
Change-Id: I605719bd9ab26b36310a06dbf518efc69ba41172
",git fetch https://review.opendev.org/openstack/swift refs/changes/44/103644/10 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test/unit/common/test_storage_policy.py', 'swift/common/utils.py', 'swift/common/storage_policy.py', 'etc/swift.conf-sample', 'test/unit/common/test_utils.py']",6,e40fa61eeb5a52ca193f980ef5e6bd3c96d40656,bp/swift-ec," def test_positive_int_value(self): expectations = { # value: expected, '1': 1, 1: 1, -1: ValueError, 0: ValueError, 'one': ValueError, None: ValueError, } for value, expected in expectations.items(): try: rv = utils.positive_int_value(value) except Exception as e: if e.__class__ is not expected: raise else: self.assertEquals(expected, rv) ",,412,9
openstack%2Fcinder~master~I98455fb7c2b846699d78be8c63ca12e6a63157a6,openstack/cinder,master,I98455fb7c2b846699d78be8c63ca12e6a63157a6,Add Fujitsu ETERNUS DX support,ABANDONED,2014-08-01 07:19:16.000000000,2014-08-15 00:10:14.000000000,,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 6547}, {'_account_id': 8871}, {'_account_id': 9043}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12018}, {'_account_id': 12033}, {'_account_id': 12641}]","[{'number': 1, 'created': '2014-08-01 07:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/04851ba223db818564a447e54f269038511c8553', 'message': 'Add Fujitsu ETERNUS DX support\n\nSupport protocols\n-Fibre Channel\n-iSCSI\n\nSupport functions\n-create/delete volume\n-create/delete snapshot\n-attach/detach volume\n-list snapshots\n-create volume from snapshot\n-create volume from image\n-create volume from volume\n-create image from volume\n-extend volume\n-volume migration(host assisted)\n\nChange-Id: I98455fb7c2b846699d78be8c63ca12e6a63157a6\nImplements: blueprint fujitsu-dx-volume-driver\n'}, {'number': 2, 'created': '2014-08-04 03:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2cffa74efad17512dc8938583712983d2cd41577', 'message': 'Add Fujitsu ETERNUS DX support\n\nSupport protocols\n-Fibre Channel\n-iSCSI\n\nSupport functions\n-create/delete volume\n-create/delete snapshot\n-attach/detach volume\n-list snapshots\n-create volume from snapshot\n-create volume from image\n-create volume from volume\n-create image from volume\n-extend volume\n-volume migration(host assisted)\n\nChange-Id: I98455fb7c2b846699d78be8c63ca12e6a63157a6\nImplements: blueprint fujitsu-dx-volume-driver\n'}, {'number': 3, 'created': '2014-08-04 08:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/01a536113a9cf482b69d39c08b56176d8c0c45b9', 'message': 'Add Fujitsu ETERNUS DX support\n\nSupport protocols\n-Fibre Channel\n-iSCSI\n\nSupport functions\n-create/delete volume\n-create/delete snapshot\n-attach/detach volume\n-list snapshots\n-create volume from snapshot\n-create volume from image\n-create volume from volume\n-create image from volume\n-extend volume\n-volume migration(host assisted)\n\nChange-Id: I98455fb7c2b846699d78be8c63ca12e6a63157a6\nImplements: blueprint fujitsu-dx-volume-driver\n'}, {'number': 4, 'created': '2014-08-05 00:24:56.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/fujitsu_eternus_dx_fc.py', 'cinder/tests/test_fujitsu.py', 'cinder/volume/drivers/fujitsu_eternus_dx_iscsi.py', 'cinder/volume/drivers/fujitsu_eternus_dx_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/513ae99ba97ce3c0839844b9b9ee64c2355c142f', 'message': 'Add Fujitsu ETERNUS DX support\n\nSupport protocols\n-Fibre Channel\n-iSCSI\n\nSupport functions\n-create/delete volume\n-create/delete snapshot\n-attach/detach volume\n-list snapshots\n-create volume from snapshot\n-create volume from image\n-create volume from volume\n-create image from volume\n-extend volume\n-volume migration(host assisted)\n\nChange-Id: I98455fb7c2b846699d78be8c63ca12e6a63157a6\nImplements: blueprint fujitsu-dx-volume-driver\n'}]",0,111185,513ae99ba97ce3c0839844b9b9ee64c2355c142f,40,12,4,9043,,,0,"Add Fujitsu ETERNUS DX support

Support protocols
-Fibre Channel
-iSCSI

Support functions
-create/delete volume
-create/delete snapshot
-attach/detach volume
-list snapshots
-create volume from snapshot
-create volume from image
-create volume from volume
-create image from volume
-extend volume
-volume migration(host assisted)

Change-Id: I98455fb7c2b846699d78be8c63ca12e6a63157a6
Implements: blueprint fujitsu-dx-volume-driver
",git fetch https://review.opendev.org/openstack/cinder refs/changes/85/111185/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/fujitsu_eternus_dx_fc.py', 'cinder/tests/test_fujitsu.py', 'cinder/volume/drivers/fujitsu_eternus_dx_iscsi.py', 'cinder/volume/drivers/fujitsu_eternus_dx_common.py']",5,04851ba223db818564a447e54f269038511c8553,bp/fujitsu-dx-volume-driver,"# Copyright (c) 2014 FUJITSU LIMITED # Copyright (c) 2012 - 2014 EMC Corporation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Common class for SMI-S based FUJITSU ETERNUS DX volume drivers. This common class is for FUJITSU ETERNUS DX volume drivers based on SMI-S. """""" import base64 import hashlib import time from oslo.config import cfg from xml.dom.minidom import parseString from cinder import exception from cinder.openstack.common.gettextutils import _ from cinder.openstack.common import log as logging from cinder.openstack.common import units from cinder.volume import volume_types LOG = logging.getLogger(__name__) CONF = cfg.CONF try: import pywbem except ImportError: LOG.info(_('Module PyWBEM not installed. ' 'Install PyWBEM using the python-pywbem package.')) CINDER_CONFIG_FILE = '/etc/cinder/cinder_fujitsu_eternus_dx.xml' SMIS_ROOT = 'root/eternus' PROVISIONING = 'storagetype:provisioning' POOL = 'storagetype:pool' STOR_CONF_SVC = 'FUJITSU_StorageConfigurationService' SCSI_PROT_CTR = 'FUJITSU_AffinityGroupController' STOR_HWID = 'FUJITSU_StorageHardwareID' CTRL_CONF_SVC = 'FUJITSU_ControllerConfigurationService' STOR_HWID_MNG_SVC = 'FUJITSU_StorageHardwareIDManagementService' STOR_VOL = 'FUJITSU_StorageVolume' REPL_SVC = 'FUJITSU_ReplicationService' STOR_POOLS = ['FUJITSU_ThinProvisioningPool', 'FUJITSU_RAIDStoragePool'] AUTH_PRIV = 'FUJITSU_AuthorizedPrivilege' STOR_SYNC = 'FUJITSU_StorageSynchronized' VOL_PREFIX = 'FJosv_' drv_opts = [ cfg.StrOpt('cinder_smis_config_file', default=CINDER_CONFIG_FILE, help='The configuration file for the Cinder ' 'SMI-S driver'), ] CONF.register_opts(drv_opts) BROKEN = 5 SNAPOPC = 4 OPC = 5 RETURN_TO_RESOURCEPOOL = 19 DETACH = 8 OPERATION_dic = {SNAPOPC: RETURN_TO_RESOURCEPOOL, OPC: DETACH } RETCODE_dic = {'0': 'Success', '1': 'Method Not Supported', '4': 'Failed', '5': 'Invalid Parameter', '4097': 'Size Not Supported', '32769': 'Maximum number of Logical Volume in' ' a RAID group has been reached', '32770': 'Maximum number of Logical Volume in' ' the storage device has been reached', '32771': 'Maximum number of registered Host WWN' ' has been reached', '32772': 'Maximum number of affinity group has been reached', '32773': 'Maximum number of host affinity has been reached', '32785': 'The RAID group is in busy state', '32786': 'The Logical Volume is in busy state', '32787': 'The device is in busy state', '32788': 'Element Name is in use', '32792': 'No Copy License', '32796': 'Quick Format Error', '32801': 'The CA port is in invalid setting', '32802': 'The Logical Volume is Mainframe volume', '32803': 'The RAID group is not operative', '32804': 'The Logical Volume is not operative', '32808': 'No Thin Provisioning License', '32809': 'The Logical Element is ODX volume', '32811': 'This operation cannot be performed' ' to the NAS resources', '32812': 'This operation cannot be performed' ' to the Storage' ' Cluster resources', '32816': 'Fatal error generic', '35302': 'Invalid LogicalElement', '35304': 'LogicalElement state error', '35316': 'Multi-hop error', '35318': 'Maximum number of multi-hop has been reached', '35324': 'RAID is broken', '35331': 'Maximum number of session has been reached' '(per device)', '35333': 'Maximum number of session has been reached' '(per SourceElement)', '35334': 'Maximum number of session has been reached' '(per TargetElement)', '35335': 'Maximum number of Snapshot generation has been' ' reached (per SourceElement)', '35346': 'Copy table size is not setup', '35347': 'Copy table size is not enough' } class FJDXCommon(): """"""Common code that can be used by ISCSI and FC drivers."""""" stats = {'driver_version': '1.2', 'free_capacity_gb': 0, 'reserved_percentage': 0, 'storage_protocol': None, 'total_capacity_gb': 0, 'vendor_name': 'FUJITSU', 'volume_backend_name': None} def __init__(self, prtcl, configuration=None): self.protocol = prtcl self.configuration = configuration self.configuration.append_config_values(drv_opts) ip, port = self._get_ecom_server() self.user, self.passwd = self._get_ecom_cred() self.url = 'http://' + ip + ':' + port self.conn = self._get_ecom_connection() def create_volume(self, volume): """"""Creates a volume."""""" LOG.debug('Entering create_volume.') volumesize = int(volume['size']) * units.Gi volumename = self._create_volume_name(volume['id']) LOG.info(_('Create Volume: %(volume)s Size: %(size)lu') % {'volume': volumename, 'size': volumesize}) self.conn = self._get_ecom_connection() storage_type = self._get_storage_type(volume) LOG.debug('Create Volume: %(volume)s ' 'Storage type: %(storage_type)s' % {'volume': volumename, 'storage_type': storage_type}) pool, storage_system = self._find_pool(storage_type[POOL]) LOG.debug('Create Volume: %(volume)s Pool: %(pool)s ' 'Storage System: %(storage_system)s' % {'volume': volumename, 'pool': pool, 'storage_system': storage_system}) configservice = self._find_storage_configuration_service( storage_system) if configservice is None: exception_message = (_(""Error Create Volume: %(volumename)s. "" ""Storage Configuration Service not found "" ""for pool %(storage_type)s."") % {'volumename': volumename, 'storage_type': storage_type}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) provisioning = self._get_provisioning(storage_type) LOG.debug('Create Volume: %(name)s Method: ' 'CreateOrModifyElementFromStoragePool ConfigServicie: ' '%(service)s ElementName: %(name)s InPool: %(pool)s ' 'ElementType: %(provisioning)s Size: %(size)lu' % {'service': configservice, 'name': volumename, 'pool': pool, 'provisioning': provisioning, 'size': volumesize}) rc, job = self.conn.InvokeMethod( 'CreateOrModifyElementFromStoragePool', configservice, ElementName=volumename, InPool=pool, ElementType=self._getnum(provisioning, '16'), Size=self._getnum(volumesize, '64')) LOG.debug('Create Volume: %(volumename)s Return code: %(rc)lu' % {'volumename': volumename, 'rc': rc}) if rc == 5L: # for DX S2 # retry with 16 digit of volume name volumename = volumename[:16] LOG.debug('Retry with 16 digit of volme name.' 'Create Volume: %(name)s Method: ' 'CreateOrModifyElementFromStoragePool' ' ConfigServicie: %(service)s' ' ElementName: %(name)s InPool: %(pool)s ' 'ElementType: %(provisioning)s Size: %(size)lu' % {'service': configservice, 'name': volumename, 'pool': pool, 'provisioning': provisioning, 'size': volumesize}) rc, job = self.conn.InvokeMethod( 'CreateOrModifyElementFromStoragePool', configservice, ElementName=volumename, InPool=pool, ElementType=self._getnum(provisioning, '16'), Size=self._getnum(volumesize, '64')) LOG.debug('Create Volume: %(volumename)s Return code: %(rc)lu' % {'volumename': volumename, 'rc': rc}) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(job) else: errordesc = RETCODE_dic[str(rc)] if rc != 0L: LOG.error(_('Error Create Volume: %(volumename)s. ' 'Return code: %(rc)lu. Error: %(error)s') % {'volumename': volumename, 'rc': rc, 'error': errordesc}) raise exception.VolumeBackendAPIException(data=errordesc) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TheElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_volume: %(volumename)s ' 'Return code: %(rc)lu ' 'volume instance: %(name)s' % {'volumename': volumename, 'rc': rc, 'name': name}) return name def create_volume_from_snapshot(self, volume, snapshot): """"""Creates a volume from a snapshot."""""" LOG.debug('Entering create_volume_from_snapshot.') snapshotname = snapshot['name'] volumename = self._create_volume_name(volume['id']) vol_instance = None LOG.info(_('Create Volume from Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s') % {'volumename': volumename, 'snapshotname': snapshotname}) self.conn = self._get_ecom_connection() snapshot_instance = self._find_lun(snapshot) storage_system = snapshot_instance['SystemName'] LOG.debug('Create Volume from Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Snapshot Instance: ' '%(snapshotinstance)s Storage System: %(storage_system)s.' % {'volumename': volumename, 'snapshotname': snapshotname, 'snapshotinstance': snapshot_instance.path, 'storage_system': storage_system}) isVMAX = storage_system.find('SYMMETRIX') if isVMAX > -1: exception_message = (_('Error Create Volume from Snapshot: ' 'Volume: %(volumename)s Snapshot: ' '%(snapshotname)s. Create Volume ' 'from Snapshot is NOT supported on VMAX.') % {'volumename': volumename, 'snapshotname': snapshotname}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) repservice = self._find_replication_service(storage_system) if repservice is None: exception_message = (_('Error Create Volume from Snapshot: ' 'Volume: %(volumename)s Snapshot: ' '%(snapshotname)s. Cannot find Replication ' 'Service to create volume from snapshot.') % {'volumename': volumename, 'snapshotname': snapshotname}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug('Create Volume from Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Method: CreateElementReplica ' 'ReplicationService: %(service)s ElementName: ' '%(elementname)s SyncType: 8 SourceElement: ' '%(sourceelement)s' % {'volumename': volumename, 'snapshotname': snapshotname, 'service': repservice, 'elementname': volumename, 'sourceelement': snapshot_instance.path}) # Create a Clone from snapshot name = self.create_volume(volume) instancename = self._getinstancename(name['classname'], name['keybindings']) vol_instance = self.conn.GetInstance(instancename) rc, job = self.conn.InvokeMethod( 'CreateElementReplica', repservice, ElementName=volumename, SyncType=self._getnum(8, '16'), SourceElement=snapshot_instance.path, TargetElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(job) else: errordesc = RETCODE_dic[str(rc)] if rc != 0L: exception_message = (_('Error Create Volume from Snapshot: ' 'Volume: %(volumename)s Snapshot:' '%(snapshotname)s. ' 'Return code: %(rc)lu.' 'Error: %(error)s') % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) volume['provider_location'] = str(name) self.delete_volume(volume) raise exception.VolumeBackendAPIException( data=exception_message) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TargetElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_volume_from_snapshot: Volume: ' '%(volumename)s Snapshot: %(snapshotname)s ' 'Return code: %(rc)lu.' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) return name def create_cloned_volume(self, volume, src_vref): """"""Creates a clone of the specified volume."""""" LOG.debug('Entering create_cloned_volume.') srcname = self._create_volume_name(src_vref['id']) volumename = self._create_volume_name(volume['id']) LOG.info(_('Create a Clone from Volume: Volume: %(volumename)s ' 'Source Volume: %(srcname)s') % {'volumename': volumename, 'srcname': srcname}) self.conn = self._get_ecom_connection() src_instance = self._find_lun(src_vref) storage_system = src_instance['SystemName'] LOG.debug('Create Cloned Volume: Volume: %(volumename)s ' 'Source Volume: %(srcname)s Source Instance: ' '%(src_instance)s Storage System: %(storage_system)s.' % {'volumename': volumename, 'srcname': srcname, 'src_instance': src_instance.path, 'storage_system': storage_system}) repservice = self._find_replication_service(storage_system) if repservice is None: exception_message = (_('Error Create Cloned Volume: ' 'Volume: %(volumename)s Source Volume: ' '%(srcname)s. Cannot find Replication ' 'Service to create cloned volume.') % {'volumename': volumename, 'srcname': srcname}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug('Create Cloned Volume: Volume: %(volumename)s ' 'Source Volume: %(srcname)s Method: CreateElementReplica ' 'ReplicationService: %(service)s ElementName: ' '%(elementname)s SyncType: 8 SourceElement: ' '%(sourceelement)s' % {'volumename': volumename, 'srcname': srcname, 'service': repservice, 'elementname': volumename, 'sourceelement': src_instance.path}) # Create a Clone from source volume name = self.create_volume(volume) instancename = self._getinstancename(name['classname'], name['keybindings']) vol_instance = self.conn.GetInstance(instancename) rc, job = self.conn.InvokeMethod( 'CreateElementReplica', repservice, ElementName=volumename, SyncType=self._getnum(8, '16'), SourceElement=src_instance.path, TargetElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(job) else: errordesc = RETCODE_dic[str(rc)] if rc != 0L: exception_message = (_('Error Create Cloned Volume: ' 'Volume: %(volumename)s Source Volume:' '%(srcname)s. Return code: %(rc)lu.' 'Error: %(error)s') % {'volumename': volumename, 'srcname': srcname, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) volume['provider_location'] = str(name) self.delete_volume(volume) raise exception.VolumeBackendAPIException( data=exception_message) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TargetElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_cloned_volume: Volume: ' '%(volumename)s Source Volume: %(srcname)s ' 'Return code: %(rc)lu.' % {'volumename': volumename, 'srcname': srcname, 'rc': rc}) return name def delete_volume(self, volume): """"""Deletes an volume."""""" LOG.debug('Entering delete_volume.') volumename = self._create_volume_name(volume['id']) LOG.info(_('Delete Volume: %(volume)s') % {'volume': volumename}) self.conn = self._get_ecom_connection() cpsession, storage_system = self._find_copysession(volume) if cpsession is not None: LOG.debug('delete_volume,volumename:%(volumename)s,' 'volume is using by copysession[%(cpsession)s].' 'delete copysession.' % {'volumename': volumename, 'cpsession': cpsession}) self._delete_copysession(storage_system, cpsession) vol_instance = self._find_lun(volume) if vol_instance is None: LOG.error(_('Volume %(name)s not found on the array. ' 'No volume to delete.') % {'name': volumename}) return configservice =\ self._find_storage_configuration_service(storage_system) if configservice is None: exception_message = (_(""Error Delete Volume: %(volumename)s. "" ""Storage Configuration Service not found."") % {'volumename': volumename}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) device_id = vol_instance['DeviceID'] LOG.debug('Delete Volume: %(name)s DeviceID: %(deviceid)s' % {'name': volumename, 'deviceid': device_id}) LOG.debug('Delete Volume: %(name)s Method: ReturnToStoragePool ' 'ConfigServic: %(service)s TheElement: %(vol_instance)s' % {'service': configservice, 'name': volumename, 'vol_instance': vol_instance.path}) rc, job =\ self.conn.InvokeMethod('ReturnToStoragePool', configservice, TheElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(job) else: errordesc = RETCODE_dic[str(rc)] if rc != 0L: exception_message = (_('Error Delete Volume: %(volumename)s. ' 'Return code: %(rc)lu. ' 'Error: %(error)s') % {'volumename': volumename, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) LOG.debug('Leaving delete_volume: %(volumename)s Return code: ' '%(rc)lu' % {'volumename': volumename, 'rc': rc}) def create_snapshot(self, snapshot, volume): """"""Creates a snapshot."""""" LOG.debug('Entering create_snapshot.') snapshotname = self._create_volume_name(snapshot['id']) volumename = snapshot['volume_name'] LOG.info(_('Create snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) self.conn = self._get_ecom_connection() vol_instance = self._find_lun(volume) device_id = vol_instance['DeviceID'] storage_type = self._get_storage_type(volume) pool, storage_system = self._find_pool(storage_type[POOL]) LOG.debug('Device ID: %(deviceid)s: Storage System: ' '%(storagesystem)s' % {'deviceid': device_id, 'storagesystem': storage_system}) repservice = self._find_replication_service(storage_system) if repservice is None: LOG.error(_(""Cannot find Replication Service to create snapshot "" ""for volume %s."") % volumename) exception_message = (_(""Cannot find Replication Service to "" ""create snapshot for volume %s."") % volumename) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug(""Create Snapshot: Method: CreateElementReplica: "" ""Target: %(snapshot)s Source: %(volume)s Replication "" ""Service: %(service)s ElementName: %(elementname)s Sync "" ""Type: 7 SourceElement: %(sourceelement)s."" % {'snapshot': snapshotname, 'volume': volumename, 'service': repservice, 'elementname': snapshotname, 'sourceelement': vol_instance.path}) rc, job =\ self.conn.InvokeMethod('CreateElementReplica', repservice, ElementName=snapshotname, SyncType=self._getnum(7, '16'), TargetPool=pool, SourceElement=vol_instance.path) LOG.debug('Create Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Return code: %(rc)lu' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) if rc == 5L: # for DX S2 # retry by CreateReplica snapshotname = snapshotname[:16] LOG.debug('retry Create Snapshot: ' 'snapshotname:%(snapshotname)s,' 'source volume name:%(volumename)s,' 'vol_instance.path:%(vol_instance)s,' 'Invoke CreateReplica' % {'snapshotname': snapshotname, 'volumename': volumename, 'vol_instance': str(vol_instance.path)}) configservice = self._find_storage_configuration_service( storage_system) if configservice is None: exception_message = (_(""Create Snapshot: %(snapshotname)s. "" ""Storage Configuration Service "" ""not found"") % {'snapshotname': snapshotname}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) # Invoke method for create snapshot rc, job = self.conn.InvokeMethod( 'CreateReplica', configservice, ElementName=snapshotname, TargetPool=pool, CopyType=self._getnum(4, '16'), SourceElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(job) else: errordesc = RETCODE_dic[str(rc)] if rc != 0L: exception_message = (_('Error Create Snapshot: %(snapshot)s ' 'Volume: %(volume)s ' 'Error: %(errordesc)s') % {'snapshot': snapshotname, 'volume': volumename, 'errordesc': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TargetElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_snapshot: Snapshot: %(snapshot)s ' 'Volume: %(volume)s Return code: %(rc)lu.' % {'snapshot': snapshotname, 'volume': volumename, 'rc': rc}) return name def delete_snapshot(self, snapshot, volume): """"""Deletes a snapshot."""""" LOG.debug('Entering delete_snapshot.') snapshotname = snapshot['name'] volumename = snapshot['volume_name'] LOG.info(_('Delete Snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) self.conn = self._get_ecom_connection() LOG.debug('Delete Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Finding StorageSychronization_SV_SV.' % {'snapshot': snapshotname, 'volume': volumename}) sync_name, storage_system =\ self._find_storage_sync_sv_sv(snapshot, volume, False) if sync_name is None: LOG.error(_('Snapshot: %(snapshot)s: volume: %(volume)s ' 'not found on the array. No snapshot to delete.') % {'snapshot': snapshotname, 'volume': volumename}) return repservice = self._find_replication_service(storage_system) if repservice is None: exception_message = (_(""Cannot find Replication Service to "" ""create snapshot for volume %s."") % volumename) raise exception.VolumeBackendAPIException(data=exception_message) # Delete snapshot - deletes both the target element # and the snap session LOG.debug(""Delete Snapshot: Target: %(snapshot)s "" ""Source: %(volume)s. Method: "" ""ModifyReplicaSynchronization: "" ""Replication Service: %(service)s Operation: 19 "" ""Synchronization: %(sync_name)s."" % {'snapshot': snapshotname, 'volume': volumename, 'service': repservice, 'sync_name': sync_name}) rc, job =\ self.conn.InvokeMethod('ModifyReplicaSynchronization', repservice, Operation=self._getnum(19, '16'), Synchronization=sync_name) LOG.debug('Delete Snapshot: Volume: %(volumename)s Snapshot: ' '%(snapshotname)s Return code: %(rc)lu' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) if rc != 0L: rc, errordesc = self._wait_for_job_complete(job) if rc != 0L: exception_message = (_('Error Delete Snapshot: Volume: ' '%(volumename)s Snapshot: ' '%(snapshotname)s. ' 'Return code: %(rc)lu.' ' Error: %(error)s') % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) # It takes a while for the relationship between the snapshot # and the source volume gets cleaned up. Needs to wait until # it is cleaned up. Otherwise, the source volume can't be # deleted immediately after the snapshot deletion because it # still has snapshot. wait_timeout = int(self._get_timeout()) wait_interval = 10 start = int(time.time()) while True: try: sync_name, storage_system =\ self._find_storage_sync_sv_sv(snapshot, volume, False) if sync_name is None: LOG.info(_('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot is deleted.') % {'snapshot': snapshotname, 'volume': volumename}) break time.sleep(wait_interval) if int(time.time()) - start >= wait_timeout: LOG.warn(_('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot deleted but cleanup timed out.') % {'snapshot': snapshotname, 'volume': volumename}) break except Exception as ex: if ex.args[0] == 6: # 6 means object not found, so snapshot is deleted cleanly LOG.info(_('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot is deleted.') % {'snapshot': snapshotname, 'volume': volumename}) else: LOG.warn(_('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot deleted but error during cleanup. ' 'Error: %(error)s') % {'snapshot': snapshotname, 'volume': volumename, 'error': str(ex.args)}) break LOG.debug('Leaving delete_snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Return code: %(rc)lu.' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) # Mapping method def _expose_paths(self, configservice, vol_instance, connector): """"""This method maps a volume to a host. It adds a volume and initiator to a Storage Group and therefore maps the volume to the host. """""" results = [] volumename = vol_instance['ElementName'] lun_name = vol_instance['Name'] initiators = self._find_initiator_names(connector) storage_system = vol_instance['SystemName'] lunmask_ctrls = self._find_lunmasking_scsi_protocol_controller( storage_system, connector) targets = self.get_target_portid(connector) if len(lunmask_ctrls) == 0: # create new lunmasking for target in targets: LOG.debug('ExposePaths: %(vol)s ConfigServicie: %(service)s ' 'LUNames: %(lun_name)s ' 'InitiatorPortIDs: %(initiator)s ' 'TargetPortIDs: %(target)s DeviceAccesses: 2' % {'vol': vol_instance.path, 'service': configservice, 'lun_name': lun_name, 'initiator': initiators, 'target': target}) rc, controller =\ self.conn.InvokeMethod('ExposePaths', configservice, LUNames=[lun_name], InitiatorPortIDs=initiators, TargetPortIDs=[target], DeviceAccesses=[self._getnum(2, '16' )]) results.append(rc) if rc != 0L: msg = (_('Error mapping volume %(volumename)s.rc:%(rc)lu') % {'volumename': volumename, 'rc': rc}) LOG.warn(msg) else: # add lun to lunmasking for lunmask_ctrl in lunmask_ctrls: LOG.debug('ExposePaths parameter ' 'LunMaskingSCSIProtocolController: ' '%(lunmasking)s' % {'lunmasking': lunmask_ctrl}) rc, controller =\ self.conn.InvokeMethod('ExposePaths', configservice, LUNames=[lun_name], DeviceAccesses=[ self._getnum(2, '16')], ProtocolControllers=[lunmask_ctrl]) results.append(rc) if rc != 0L: msg = (_('Error mapping volume %(volumename)s.rc:%(rc)lu') % {'volumename': volumename, 'rc': rc}) LOG.warn(msg) if 0L not in results: msg = (_('Error mapping volume %(volumename)s:%(results)s.') % {'volumename': volumename, 'results': results}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('ExposePaths for volume %s completed successfully.' % volumename) # Unmapping method def _hide_paths(self, configservice, vol_instance, connector): """"""This method unmaps a volume from the host. Removes a volume from the Storage Group and therefore unmaps the volume from the host. """""" volumename = vol_instance['ElementName'] lun_name = vol_instance['Name'] lunmask_ctrls =\ self._find_lunmasking_scsi_protocol_controller_for_vol( vol_instance, connector) for lunmask_ctrl in lunmask_ctrls: LOG.debug('HidePaths: %(vol)s ConfigServicie: %(service)s ' 'LUNames: %(lun_name)s' ' LunMaskingSCSIProtocolController: ' '%(lunmasking)s' % {'vol': vol_instance.path, 'service': configservice, 'lun_name': lun_name, 'lunmasking': lunmask_ctrl}) rc, controller = self.conn.InvokeMethod( 'HidePaths', configservice, LUNames=[lun_name], ProtocolControllers=[lunmask_ctrl]) if rc != 0L: msg = (_('Error unmapping volume %(volumename)s.rc:%(rc)lu') % {'volumename': volumename, 'rc': rc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('HidePaths for volume %s completed successfully.' % volumename) # Mapping method for VMAX def _add_members(self, configservice, vol_instance): """"""This method maps a volume to a host. Add volume to the Device Masking Group that belongs to a Masking View. """""" volumename = vol_instance['ElementName'] masking_group = self._find_device_masking_group() LOG.debug('AddMembers: ConfigServicie: %(service)s MaskingGroup: ' '%(masking_group)s Members: %(vol)s' % {'service': configservice, 'masking_group': masking_group, 'vol': vol_instance.path}) rc, job =\ self.conn.InvokeMethod('AddMembers', configservice, MaskingGroup=masking_group, Members=[vol_instance.path]) if rc != 0L: rc, errordesc = self._wait_for_job_complete(job) if rc != 0L: msg = (_('Error mapping volume %(vol)s. %(error)s') % {'vol': volumename, 'error': errordesc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('AddMembers for volume %s completed successfully.' % volumename) # Unmapping method for VMAX def _remove_members(self, configservice, vol_instance): """"""This method unmaps a volume from a host. Removes volume from the Device Masking Group that belongs to a Masking View. """""" volumename = vol_instance['ElementName'] masking_group = self._find_device_masking_group() LOG.debug('RemoveMembers: ConfigServicie: %(service)s ' 'MaskingGroup: %(masking_group)s Members: %(vol)s' % {'service': configservice, 'masking_group': masking_group, 'vol': vol_instance.path}) rc, job = self.conn.InvokeMethod('RemoveMembers', configservice, MaskingGroup=masking_group, Members=[vol_instance.path]) if rc != 0L: rc, errordesc = self._wait_for_job_complete(job) if rc != 0L: msg = (_('Error unmapping volume %(vol)s. %(error)s') % {'vol': volumename, 'error': errordesc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('RemoveMembers for volume %s completed successfully.' % volumename) def _map_lun(self, volume, connector): """"""Maps a volume to the host."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_('Map volume: %(volume)s') % {'volume': volumename}) vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] configservice = self._find_controller_configuration_service( storage_system) if configservice is None: exception_message = (_(""Cannot find Controller Configuration "" ""Service for storage system %s"") % storage_system) raise exception.VolumeBackendAPIException(data=exception_message) isVMAX = storage_system.find('SYMMETRIX') if isVMAX > -1: self._add_members(configservice, vol_instance) else: self._expose_paths(configservice, vol_instance, connector) def _unmap_lun(self, volume, connector): """"""Unmaps a volume from the host."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_('Unmap volume: %(volume)s') % {'volume': volumename}) device_info = self.find_device_number(volume, connector) device_number = device_info['hostlunid'] if device_number is None: LOG.info(_(""Volume %s is not mapped. No volume to unmap."") % (volumename)) return vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] configservice = self._find_controller_configuration_service( storage_system) if configservice is None: exception_message = (_(""Cannot find Controller Configuration "" ""Service for storage system %s"") % storage_system) raise exception.VolumeBackendAPIException(data=exception_message) isVMAX = storage_system.find('SYMMETRIX') if isVMAX > -1: self._remove_members(configservice, vol_instance) else: self._hide_paths(configservice, vol_instance, connector) def initialize_connection(self, volume, connector): """"""Initializes the connection and returns connection info."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_('Initialize connection: %(volume)s') % {'volume': volumename}) self.conn = self._get_ecom_connection() device_info = self.find_device_number(volume, connector) device_number = device_info['hostlunid'] if device_number is not None: LOG.info(_(""Volume %s is already mapped."") % (volumename)) else: self._map_lun(volume, connector) # Find host lun id again after the volume is exported to the host device_info = self.find_device_number(volume, connector) return device_info def terminate_connection(self, volume, connector): """"""Disallow connection from connector."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_('Terminate connection: %(volume)s') % {'volume': volumename}) self.conn = self._get_ecom_connection() self._unmap_lun(volume, connector) def extend_volume(self, volume, new_size): """"""Extends an existing volume."""""" LOG.debug('Entering extend_volume.') volumesize = int(new_size) * units.Gi volumename = self._create_volume_name(volume['id']) LOG.info(_('Extend Volume: %(volume)s New size: %(size)lu') % {'volume': volumename, 'size': volumesize}) self.conn = self._get_ecom_connection() storage_type = self._get_storage_type(volume) vol_instance = self._find_lun(volume) device_id = vol_instance['DeviceID'] storage_system = vol_instance['SystemName'] LOG.debug('Device ID: %(deviceid)s: Storage System: ' '%(storagesystem)s' % {'deviceid': device_id, 'storagesystem': storage_system}) configservice = self._find_storage_configuration_service( storage_system) if configservice is None: exception_message = (_(""Error Extend Volume: %(volumename)s. "" ""Storage Configuration Service not found."") % {'volumename': volumename}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) provisioning = self._get_provisioning(storage_type) LOG.debug('Extend Volume: %(name)s Method: ' 'CreateOrModifyElementFromStoragePool ConfigServicie: ' '%(service)s ElementType: %(provisioning)s Size: %(size)lu' 'Volume path: %(volumepath)s' % {'service': configservice, 'name': volumename, 'provisioning': provisioning, 'size': volumesize, 'volumepath': vol_instance.path}) rc, job = self.conn.InvokeMethod( 'CreateOrModifyElementFromStoragePool', configservice, ElementType=self._getnum(provisioning, '16'), Size=self._getnum(volumesize, '64'), TheElement=vol_instance.path) LOG.debug('Extend Volume: %(volumename)s Return code: %(rc)lu' % {'volumename': volumename, 'rc': rc}) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(job) else: errordesc = RETCODE_dic[str(rc)] if rc != 0L: exception_message = (_('Error Extend Volume: %(volumename)s. ' 'Return code: %(rc)lu. ' 'Error: %(error)s') % {'volumename': volumename, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) LOG.debug('Leaving extend_volume: %(volumename)s ' 'Return code: %(rc)lu ' % {'volumename': volumename, 'rc': rc}) def update_volume_stats(self): """"""Retrieve stats info."""""" LOG.debug(""Updating volume stats"") self.stats['total_capacity_gb'] = 'unknown' self.stats['free_capacity_gb'] = 'unknown' return self.stats def _get_storage_type(self, volume, filename=None): """"""Get storage type. Look for user input volume type first. If not available, fall back to finding it in conf file. """""" specs = self._get_volumetype_extraspecs(volume) if not specs: specs = self._get_storage_type_conffile() LOG.debug(""Storage Type: %s"" % (specs)) return specs def _get_storage_type_conffile(self, filename=None): """"""Get the storage type from the config file."""""" if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) storageTypes = dom.getElementsByTagName('StorageType') if storageTypes is not None and len(storageTypes) > 0: storageType = storageTypes[0].toxml() storageType = storageType.replace('<StorageType>', '') storageType = storageType.replace('</StorageType>', '') LOG.debug(""Found Storage Type in config file: %s"" % (storageType)) specs = {} specs[POOL] = storageType return specs else: exception_message = (_(""Storage type not found."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) def _get_masking_view(self, filename=None): if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) views = dom.getElementsByTagName('MaskingView') if views is not None and len(views) > 0: view = views[0].toxml().replace('<MaskingView>', '') view = view.replace('</MaskingView>', '') LOG.debug(""Found Masking View: %s"" % (view)) return view else: LOG.debug(""Masking View not found."") return None def _get_timeout(self, filename=None): if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) timeouts = dom.getElementsByTagName('Timeout') if timeouts is not None and len(timeouts) > 0: timeout = timeouts[0].toxml().replace('<Timeout>', '') timeout = timeout.replace('</Timeout>', '') LOG.debug(""Found Timeout: %s"" % (timeout)) return timeout else: LOG.debug(""Timeout not specified."") return 10 def _get_ecom_cred(self, filename=None): if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) ecomUsers = dom.getElementsByTagName('EcomUserName') if ecomUsers is not None and len(ecomUsers) > 0: ecomUser = ecomUsers[0].toxml().replace('<EcomUserName>', '') ecomUser = ecomUser.replace('</EcomUserName>', '') ecomPasswds = dom.getElementsByTagName('EcomPassword') if ecomPasswds is not None and len(ecomPasswds) > 0: ecomPasswd = ecomPasswds[0].toxml().replace('<EcomPassword>', '') ecomPasswd = ecomPasswd.replace('</EcomPassword>', '') if ecomUser is not None and ecomPasswd is not None: return ecomUser, ecomPasswd else: LOG.debug(""Ecom user not found."") return None def _get_ecom_server(self, filename=None): if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) ecomIps = dom.getElementsByTagName('EcomServerIp') if ecomIps is not None and len(ecomIps) > 0: ecomIp = ecomIps[0].toxml().replace('<EcomServerIp>', '') ecomIp = ecomIp.replace('</EcomServerIp>', '') ecomPorts = dom.getElementsByTagName('EcomServerPort') if ecomPorts is not None and len(ecomPorts) > 0: ecomPort = ecomPorts[0].toxml().replace('<EcomServerPort>', '') ecomPort = ecomPort.replace('</EcomServerPort>', '') if ecomIp is not None and ecomPort is not None: LOG.debug(""Ecom IP: %(ecomIp)s Port: %(ecomPort)s"", {'ecomIp': ecomIp, 'ecomPort': ecomPort}) return ecomIp, ecomPort else: LOG.debug(""Ecom server not found."") return None def _get_ecom_connection(self, filename=None): conn = pywbem.WBEMConnection(self.url, (self.user, self.passwd), default_namespace=SMIS_ROOT) if conn is None: exception_message = (_(""Cannot connect to ECOM server"")) raise exception.VolumeBackendAPIException(data=exception_message) return conn def _find_replication_service(self, storage_system): foundRepService = None repservices = self.conn.EnumerateInstanceNames( REPL_SVC) for repservice in repservices: if storage_system == repservice['SystemName']: foundRepService = repservice LOG.debug(""Found Replication Service: %s"" % (repservice)) break return foundRepService def _find_storage_configuration_service(self, storage_system): foundConfigService = None configservices = self.conn.EnumerateInstanceNames( STOR_CONF_SVC) for configservice in configservices: if storage_system == configservice['SystemName']: foundConfigService = configservice LOG.debug(""Found Storage Configuration Service: %s"" % (configservice)) break return foundConfigService def _find_controller_configuration_service(self, storage_system): foundConfigService = None configservices = self.conn.EnumerateInstanceNames( CTRL_CONF_SVC) for configservice in configservices: if storage_system == configservice['SystemName']: foundConfigService = configservice LOG.debug(""Found Controller Configuration Service: %s"" % (configservice)) break return foundConfigService def _find_storage_hardwareid_service(self, storage_system): foundConfigService = None configservices = self.conn.EnumerateInstanceNames( STOR_HWID_MNG_SVC) for configservice in configservices: if storage_system == configservice['SystemName']: foundConfigService = configservice LOG.debug(""Found Storage Hardware ID Management Service: %s"" % (configservice)) break return foundConfigService # Find pool based on storage_type def _find_pool(self, storage_type, details=False): foundPool = None systemname = None poolinstanceid = None # Only get instance names if details flag is False; # Otherwise get the whole instances systemname, port = self._get_ecom_server() poolinstanceid = self._get_pool_instance_id(storage_type) if details is False: pools = self.conn.EnumerateInstanceNames( 'CIM_StoragePool') else: pools = self.conn.EnumerateInstances( 'CIM_StoragePool') for pool in pools: if str(pool['InstanceID']) == str(poolinstanceid): foundPool = pool break if foundPool is None: exception_message = (_(""Pool %(storage_type)s is not found."") % {'storage_type': storage_type}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) if systemname is None: exception_message = (_(""Storage system not found for pool "" ""%(storage_type)s."") % {'storage_type': storage_type}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug(""Pool: %(pool)s SystemName: %(systemname)s."" % {'pool': foundPool, 'systemname': systemname}) return foundPool, systemname def _parse_pool_instance_id(self, instanceid): # Example of pool InstanceId: CLARiiON+APM00115204878+U+Pool 0 poolname = None systemname = None endp = instanceid.rfind('+') if endp > -1: poolname = instanceid[endp + 1:] idarray = instanceid.split('+') if len(idarray) > 2: systemname = idarray[0] + '+' + idarray[1] LOG.debug(""Pool name: %(poolname)s System name: %(systemname)s."" % {'poolname': poolname, 'systemname': systemname}) return poolname, systemname def _find_lun(self, volume): foundinstance = None volumename = self._create_volume_name(volume['id']) loc = volume['provider_location'] try: name = eval(loc) instancename = self._getinstancename(name['classname'], name['keybindings']) foundinstance = self.conn.GetInstance(instancename) except Exception: foundinstance = None if foundinstance is None: LOG.debug(""Volume %(volumename)s not found on the array."" ""volume instance is None."" % {'volumename': volumename}) elif volumename.find(foundinstance['ElementName']) != 0: LOG.debug(""Volume %(volumename)s not found on the array."" ""Volume name unmatch.ElementName:%(ElementName)s"" % {'volumename': volumename, 'ElementName': foundinstance['ElementName']}) foundinstance = None else: LOG.debug(""Volume name: %(volumename)s Volume instance: "" ""%(vol_instance)s."" % {'volumename': volumename, 'vol_instance': foundinstance.path}) return foundinstance def _find_storage_sync_sv_sv(self, snapshot, volume, waitforsync=True): foundsyncname = None storage_system = None percent_synced = 0 snapshotname = self._create_volume_name(snapshot['id']) volumename = self._create_volume_name(volume['id']) LOG.debug(""Source: %(volumename)s Target: %(snapshotname)s."" % {'volumename': volumename, 'snapshotname': snapshotname}) snapshot_instance = self._find_lun(snapshot) volume_instance = self._find_lun(volume) if snapshot_instance is None or volume_instance is None: LOG.info(_('Snapshot Volume %(snapshotname)s, ' 'Source Volume %(volumename)s not found on the array.') % {'snapshotname': snapshotname, 'volumename': volumename}) return None, None storage_system = volume_instance['SystemName'] classname = STOR_SYNC bindings = {'SyncedElement': snapshot_instance.path, 'SystemElement': volume_instance.path} foundsyncname = self._getinstancename(classname, bindings) if foundsyncname is None: LOG.debug(""Source: %(volumename)s Target: %(snapshotname)s. "" ""Storage Synchronized not found. "" % {'volumename': volumename, 'snapshotname': snapshotname}) else: LOG.debug(""Storage system: %(storage_system)s "" ""Storage Synchronized instance: %(sync)s."" % {'storage_system': storage_system, 'sync': foundsyncname}) # Wait for SE_StorageSynchronized_SV_SV to be fully synced while waitforsync and percent_synced < 100: time.sleep(10) sync_instance = self.conn.GetInstance(foundsyncname, LocalOnly=False) percent_synced = sync_instance['PercentSynced'] return foundsyncname, storage_system def _find_initiator_names(self, connector): foundinitiatornames = [] iscsi = 'iscsi' fc = 'fc' name = 'initiator name' if self.protocol.lower() == iscsi and connector['initiator']: foundinitiatornames.append(connector['initiator']) elif self.protocol.lower() == fc and connector['wwpns']: for wwn in connector['wwpns']: foundinitiatornames.append(wwn) name = 'world wide port names' if foundinitiatornames is None or len(foundinitiatornames) == 0: msg = (_('Error finding %s.') % name) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug(""Found %(name)s: %(initiator)s."" % {'name': name, 'initiator': foundinitiatornames}) return foundinitiatornames def _wait_for_job_complete(self, job): jobinstancename = job['Job'] while True: jobinstance = self.conn.GetInstance(jobinstancename, LocalOnly=False) jobstate = jobinstance['JobState'] # From ValueMap of JobState in CIM_ConcreteJob # 2L=New, 3L=Starting, 4L=Running, 32767L=Queue Pending # ValueMap(""2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13..32767, # 32768..65535""), # Values(""New, Starting, Running, Suspended, Shutting Down, # Completed, Terminated, Killed, Exception, Service, # Query Pending, DMTF Reserved, Vendor Reserved"")] if jobstate in [2L, 3L, 4L, 32767L]: time.sleep(10) else: break rc = jobinstance['ErrorCode'] errordesc = jobinstance['ErrorDescription'] return rc, errordesc # Find LunMaskingSCSIProtocolController for the local host on the # specified storage system def _find_lunmasking_scsi_protocol_controller(self, storage_system, connector): foundCtrls = [] initiators = self._find_initiator_names(connector) controllers = self.conn.EnumerateInstanceNames( SCSI_PROT_CTR) for ctrl in controllers: if storage_system != ctrl['SystemName']: continue associators =\ self.conn.Associators(ctrl, ResultClass=AUTH_PRIV) for assoc in associators: for initiator in initiators: if initiator.lower() not in assoc['InstanceID'].lower(): continue LOG.debug('_find_lunmasking_scsi_protocol_controller,' 'AffinityGroup:%(ag)s' % {'ag': ctrl}) foundCtrls.append(ctrl) break break LOG.debug(""LunMaskingSCSIProtocolController for storage system "" ""%(storage_system)s and initiator %(initiator)s is "" ""%(ctrl)s."" % {'storage_system': storage_system, 'initiator': initiators, 'ctrl': foundCtrls}) return foundCtrls # Find LunMaskingSCSIProtocolController for the local host and the # specified storage volume def _find_lunmasking_scsi_protocol_controller_for_vol(self, vol_instance, connector): foundCtrls = [] initiators = self._find_initiator_names(connector) controllers =\ self.conn.AssociatorNames( vol_instance.path, ResultClass=SCSI_PROT_CTR) LOG.debug('_find_lunmasking_scsi_protocol_controller_for_vol:' 'controllers:%(controllers)s' % {'controllers': controllers}) for ctrl in controllers: associators =\ self.conn.Associators( ctrl, ResultClass=AUTH_PRIV) foundCtrl = None for assoc in associators: for initiator in initiators: if initiator.lower() not in assoc['InstanceID'].lower(): continue LOG.debug('_find_lunmasking_scsi_protocol_controller' '_for_vol,' 'AffinityGroup:%(ag)s' % {'ag': ctrl}) foundCtrl = ctrl foundCtrls.append(foundCtrl) break if foundCtrl is not None: break LOG.debug(""LunMaskingSCSIProtocolController for storage volume "" ""%(vol)s and initiator %(initiator)s is %(ctrl)s."" % {'vol': vol_instance.path, 'initiator': initiators, 'ctrl': foundCtrls}) return foundCtrls # Find out how many volumes are mapped to a host # assoociated to the LunMaskingSCSIProtocolController def get_num_volumes_mapped(self, volume, connector): numVolumesMapped = 0 volumename = volume['name'] vol_instance = self._find_lun(volume) if vol_instance is None: msg = (_('Volume %(name)s not found on the array. ' 'Cannot determine if there are volumes mapped.') % {'name': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) storage_system = vol_instance['SystemName'] ctrl = self._find_lunmasking_scsi_protocol_controller( storage_system, connector) LOG.debug(""LunMaskingSCSIProtocolController for storage system "" ""%(storage)s and %(connector)s is %(ctrl)s."" % {'storage': storage_system, 'connector': connector, 'ctrl': ctrl}) associators = self.conn.Associators( ctrl, resultClass=STOR_VOL) numVolumesMapped = len(associators) LOG.debug(""Found %(numVolumesMapped)d volumes on storage system "" ""%(storage)s mapped to %(connector)s."" % {'numVolumesMapped': numVolumesMapped, 'storage': storage_system, 'connector': connector}) return numVolumesMapped # Find an available device number that a host can see def _find_avail_device_number(self, storage_system): out_device_number = '000000' out_num_device_number = 0 numlist = [] myunitnames = [] unitnames = self.conn.EnumerateInstanceNames( 'CIM_ProtocolControllerForUnit') for unitname in unitnames: controller = unitname['Antecedent'] if storage_system != controller['SystemName']: continue classname = controller['CreationClassName'] index = classname.find('LunMaskingSCSIProtocolController') if index > -1: unitinstance = self.conn.GetInstance(unitname, LocalOnly=False) numDeviceNumber = int(unitinstance['DeviceNumber']) numlist.append(numDeviceNumber) myunitnames.append(unitname) maxnum = max(numlist) out_num_device_number = maxnum + 1 out_device_number = '%06d' % out_num_device_number LOG.debug(""Available device number on %(storage)s: %(device)s."" % {'storage': storage_system, 'device': out_device_number}) return out_device_number # Find a device number that a host can see for a volume def find_device_number(self, volume, connector): out_num_device_number = None volumename = self._create_volume_name(volume['id']) vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] sp = None try: sp = vol_instance['EMCCurrentOwningStorageProcessor'] except KeyError: # VMAX LUN doesn't have this property # ETERNUS DX LUN doesn't have this property pass indexVMAX = storage_system.find('SYMMETRIX') if indexVMAX == -1: # find out whether the volume is already attached to the host ctrls = self._find_lunmasking_scsi_protocol_controller_for_vol( vol_instance, connector) LOG.debug(""LunMaskingSCSIProtocolController for "" ""volume %(vol)s and connector %(connector)s "" ""is %(ctrl)s."" % {'vol': vol_instance.path, 'connector': connector, 'ctrl': ctrls}) if indexVMAX > -1 or len(ctrls) != 0: unitnames = self.conn.ReferenceNames( vol_instance.path, ResultClass='CIM_ProtocolControllerForUnit') for unitname in unitnames: controller = unitname['Antecedent'] classname = controller['CreationClassName'] index = classname.find(SCSI_PROT_CTR) if index > -1: if ctrls[0]['DeviceID'] != controller['DeviceID']: continue # Get an instance of CIM_ProtocolControllerForUnit unitinstance = self.conn.GetInstance(unitname, LocalOnly=False) numDeviceNumber = int(unitinstance['DeviceNumber'], 16) out_num_device_number = numDeviceNumber break else: index = classname.find('Symm_LunMaskingView') if index > -1: # VMAX unitinstance = self.conn.GetInstance(unitname, LocalOnly=False) numDeviceNumber = int(unitinstance['DeviceNumber'], 16) out_num_device_number = numDeviceNumber break if out_num_device_number is None: LOG.info(_(""Device number not found for volume "" ""%(volumename)s %(vol_instance)s."") % {'volumename': volumename, 'vol_instance': vol_instance.path}) else: LOG.debug(""Found device number %(device)d for volume "" ""%(volumename)s %(vol_instance)s."" % {'device': out_num_device_number, 'volumename': volumename, 'vol_instance': vol_instance.path}) data = {'hostlunid': out_num_device_number, 'storagesystem': storage_system, 'owningsp': sp} LOG.debug(""Device info: %(data)s."" % {'data': data}) return data def _find_device_masking_group(self): """"""Finds the Device Masking Group in a masking view."""""" foundMaskingGroup = None maskingview_name = self._get_masking_view() maskingviews = self.conn.EnumerateInstanceNames( SCSI_PROT_CTR) for view in maskingviews: instance = self.conn.GetInstance(view, LocalOnly=False) if maskingview_name == instance['ElementName']: foundView = view break groups = self.conn.AssociatorNames( foundView, ResultClass='SE_DeviceMaskingGroup') foundMaskingGroup = groups[0] LOG.debug(""Masking view: %(view)s DeviceMaskingGroup: %(masking)s."" % {'view': maskingview_name, 'masking': foundMaskingGroup}) return foundMaskingGroup # Find a StorageProcessorSystem given sp and storage system def _find_storage_processor_system(self, owningsp, storage_system): foundSystem = None systems = self.conn.EnumerateInstanceNames( 'EMC_StorageProcessorSystem') for system in systems: # Clar_StorageProcessorSystem.CreationClassName= # ""Clar_StorageProcessorSystem"",Name=""CLARiiON+APM00123907237+SP_A"" idarray = system['Name'].split('+') if len(idarray) > 2: storsystemname = idarray[0] + '+' + idarray[1] sp = idarray[2] if (storage_system == storsystemname and owningsp == sp): foundSystem = system LOG.debug(""Found Storage Processor System: %s"" % (system)) break return foundSystem # Find EMC_iSCSIProtocolEndpoint for the specified sp def _find_iscsi_protocol_endpoints(self, owningsp, storage_system): foundEndpoints = [] processor = self._find_storage_processor_system( owningsp, storage_system) associators = self.conn.Associators( processor, resultClass='EMC_iSCSIProtocolEndpoint') for assoc in associators: # Name = iqn.1992-04.com.emc:cx.apm00123907237.a8,t,0x0001 # SystemName = CLARiiON+APM00123907237+SP_A+8 arr = assoc['SystemName'].split('+') if len(arr) > 2: processor_name = arr[0] + '+' + arr[1] + '+' + arr[2] if processor_name == processor['Name']: arr2 = assoc['Name'].split(',') if len(arr2) > 1: foundEndpoints.append(arr2[0]) LOG.debug(""iSCSIProtocolEndpoint for storage system "" ""%(storage_system)s and SP %(sp)s is "" ""%(endpoint)s."" % {'storage_system': storage_system, 'sp': owningsp, 'endpoint': foundEndpoints}) return foundEndpoints def _getnum(self, num, datatype): try: result = { '8': pywbem.Uint8(num), '16': pywbem.Uint16(num), '32': pywbem.Uint32(num), '64': pywbem.Uint64(num) } result = result.get(datatype, num) except NameError: result = num return result def _getinstancename(self, classname, bindings): instancename = None try: instancename = pywbem.CIMInstanceName( classname, namespace=SMIS_ROOT, keybindings=bindings) except NameError: instancename = None return instancename # Find target WWNs def get_target_wwns(self, storage_system, connector): target_wwns = [] configservice = self._find_storage_hardwareid_service( storage_system) if configservice is None: exception_msg = (_(""Error finding Storage Hardware ID Service."")) LOG.error(exception_msg) raise exception.VolumeBackendAPIException(data=exception_msg) hardwareids = self._find_storage_hardwareids(connector) LOG.debug('EMCGetTargetEndpoints: Service: %(service)s ' 'Storage HardwareIDs: %(hardwareids)s.' % {'service': configservice, 'hardwareids': hardwareids}) for hardwareid in hardwareids: rc, targetendpoints = self.conn.InvokeMethod( 'EMCGetTargetEndpoints', configservice, HardwareId=hardwareid) if rc != 0L: msg = (_('Error finding Target WWNs.')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) endpoints = targetendpoints['TargetEndpoints'] for targetendpoint in endpoints: wwn = targetendpoint['Name'] # Add target wwn to the list if it is not already there if not any(d == wwn for d in target_wwns): target_wwns.append(wwn) LOG.debug('Add target WWN: %s.' % wwn) LOG.debug('Target WWNs: %s.' % target_wwns) return target_wwns # Find Storage Hardware IDs def _find_storage_hardwareids(self, connector): foundInstances = [] wwpns = self._find_initiator_names(connector) hardwareids = self.conn.EnumerateInstances( STOR_HWID) for hardwareid in hardwareids: storid = hardwareid['StorageID'] for wwpn in wwpns: if wwpn.lower() == storid.lower(): foundInstances.append(hardwareid.path) LOG.debug(""Storage Hardware IDs for %(wwpns)s is "" ""%(foundInstances)s."" % {'wwpns': wwpns, 'foundInstances': foundInstances}) return foundInstances def _get_volumetype_extraspecs(self, volume): specs = {} type_id = volume['volume_type_id'] if type_id is not None: specs = volume_types.get_volume_type_extra_specs(type_id) # If specs['storagetype:pool'] not defined, # set specs to {} so we can ready from config file later if POOL not in specs: specs = {} return specs def _get_provisioning(self, storage_type): # provisioning is thin (5) by default provisioning = 5 thick_str = 'thick' try: type_prov = storage_type[PROVISIONING] if type_prov.lower() == thick_str.lower(): provisioning = 2 except KeyError: # Default to thin if not defined pass return provisioning def _create_volume_name(self, id_code): """"""create volume_name on ETERNUS from id on OpenStack."""""" LOG.debug('_create_volume_name [%s],Enter method.' % id_code) if id_code is None: msg = (_('_create_volume_name,' 'id_code is None.')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) m = hashlib.md5() m.update(id_code) volname = base64.urlsafe_b64encode(m.digest()) ret = VOL_PREFIX + str(volname) LOG.debug('_create_volume_name: ' ' id:%(id)s' ' volumename:%(ret)s' ' Exit method.' % {'id': id_code, 'ret': ret}) return ret def _get_pool_instance_id(self, poolname): """"""get pool instacne_id from pool name"""""" LOG.debug('_get_pool_instance_id,' 'Enter method,poolname:%s' % (poolname)) poolinstanceid = None pool = None pools = [] msg = None try: pools = self.conn.EnumerateInstances( 'CIM_StoragePool') except Exception: msg = (_('_get_pool_instance_id,' 'poolname:%(poolname)s,' 'EnumerateInstances,' 'cannot connect to ETERNUS.') % {'poolname': poolname}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) for pool in pools: pool_elementname = pool['ElementName'] poolclass = pool.path.classname LOG.debug('poolname from file or VolumeType:%s' ' poolname from smis:%s' ' poolclass from smis:%s' % (poolname, pool_elementname, poolclass)) if str(poolname) == str(pool_elementname): if poolclass in STOR_POOLS: poolinstanceid = pool['InstanceID'] break if poolinstanceid is None: msg = (_('_get_pool_instance_id,' 'poolname:%(poolname)s,' 'poolinstanceid is None.') % {'poolname': poolname}) LOG.info(msg) LOG.debug('_get_pool_instance_id,' 'Exit method,poolinstanceid:%s' % (poolinstanceid)) return poolinstanceid def get_target_portid(self, connector): """"""return target_portid"""""" LOG.debug('get_target_portid,Enter method') target_portidlist = [] tgtportlist = [] tgtport = None conn_type = {'fc': 2, 'iscsi': 7} try: tgtportlist = self.conn.EnumerateInstances( 'CIM_SCSIProtocolEndpoint') except Exception: msg = (_('get_target_portid,' 'connector:%(connector)s,' 'EnumerateInstances,' 'cannot connect to ETERNUS.') % {'connector': connector}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) for tgtport in tgtportlist: if tgtport['ConnectionType'] == conn_type[self.protocol.lower()]: target_portidlist.append(tgtport['Name']) LOG.debug('get_target_portid,' 'portid:%(portid)s,' 'connection type:%(cont)s,' % {'portid': tgtport['Name'], 'cont': tgtport['ConnectionType']}) LOG.debug('get_target_portid,' 'target portid: %(target_portid)s ' % {'target_portid': target_portidlist}) if len(target_portidlist) == 0: msg = (_('get_target_portid,' 'protcol:%(protocol)s,' 'connector:%(connector)s,' 'target_portid does not found.') % {'protocol': self.protocol, 'connector': connector}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('get_target_portid,Exit method') return target_portidlist def _find_copysession(self, volume): """"""find copysession from volumename on ETERNUS"""""" LOG.debug('_find_copysession, Enter method') cpsession = None vol_instance = None repservice = None rc = 0 replicarellist = None replicarel = None snapshot_vol_instance = None msg = None errordesc = None cpsession_instance = None vol_instance = self._find_lun(volume) if vol_instance is None: return None, None volumename = vol_instance['ElementName'] storage_system = vol_instance['SystemName'] if vol_instance is not None: # find target_volume # get copysession list repservice = self._find_replication_service(storage_system) if repservice is None: msg = (_('_find_copysession,' 'Cannot find Replication Service to ' 'find copysession')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # find copysession for source_volume while True: LOG.debug('_find_copysession,source_volume' ' while copysession') cpsession = None rc, replicarellist = self.conn.InvokeMethod( 'GetReplicationRelationships', repservice, Type=self._getnum(2, '16'), Mode=self._getnum(2, '16'), Locality=self._getnum(2, '16')) errordesc = RETCODE_dic[str(rc)] if rc != 0L: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s') % {'volumename': volumename, 'rc': rc, 'errordesc': errordesc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) for replicarel in replicarellist['Synchronizations']: LOG.debug('_find_copysession,' 'source_volume,' 'replicarel:%(replicarel)s' % {'replicarel': replicarel}) try: snapshot_vol_instance = self.conn.GetInstance( replicarel['SystemElement'], LocalOnly=False) except Exception: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'GetInstance,' 'cannot connect to ETERNUS.') % {'volumename': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('_find_copysession,' 'snapshot ElementName:%(elementname)s,' 'source_volumename:%(volumename)s' % {'elementname': snapshot_vol_instance['ElementName'], 'volumename': volumename}) if volumename == snapshot_vol_instance['ElementName']: # find copysession cpsession = replicarel LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized instance:%(sync)s' % {'volumename': volumename, 'sync': str(cpsession)}) msg = (_('_find_copy_session,' 'source_volumename:%(volumename)s,' 'wait for end of copysession') % {'volumename': volumename}) LOG.info(msg) try: cpsession_instance = self.conn.GetInstance( replicarel) except Exception: break LOG.debug('_find_copysession,' 'status:%(status)s' % {'status': cpsession_instance['CopyState']}) if cpsession_instance['CopyState'] == BROKEN: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'copysession state is BROKEN') % {'volumename': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) time.sleep(10) break else: LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized not found.' % {'volumename': volumename}) if cpsession is None: break # find copysession for target_volume for replicarel in replicarellist['Synchronizations']: LOG.debug('_find_copysession,' 'replicarel:%(replicarel)s' % {'replicarel': replicarel}) # target volume try: snapshot_vol_instance = self.conn.GetInstance( replicarel['SyncedElement'], LocalOnly=False) except Exception: msg = (_('_find_copysession,' 'target_volumename:%(volumename)s,' 'GetInstance,' 'cannot connect to ETERNUS.') % {'volumename': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('_find_copysession,' 'snapshot ElementName:%(elementname)s,' 'volumename:%(volumename)s' % {'elementname': snapshot_vol_instance['ElementName'], 'volumename': volumename}) if volumename == snapshot_vol_instance['ElementName']: # find copysession cpsession = replicarel LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized instance:%(sync)s' % {'volumename': volumename, 'sync': str(cpsession)}) break else: LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized not found.' % {'volumename': volumename}) else: # does not find target_volume of copysession msg = (_('_find_copysession,' 'volumename:%(volumename)s,' 'not found.') % {'volumename': volumename}) LOG.info(msg) LOG.debug('_find_copysession,Exit method') return cpsession, storage_system def _delete_copysession(self, storage_system, cpsession): """"""delete copysession"""""" LOG.debug('_delete_copysession,Entering') LOG.debug('_delete_copysession,[%s]' % cpsession) snapshot_instance = None msg = None errordesc = None try: snapshot_instance = self.conn.GetInstance( cpsession, LocalOnly=False) except Exception: msg = (_('_delete_copysession, ' 'copysession:%(cpsession)s,' 'GetInstance,' 'cannot connect to ETERNUS.') % {'cpsession': cpsession}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) copytype = snapshot_instance['CopyType'] # set oparation code operation = OPERATION_dic[copytype] repservice = self._find_replication_service(storage_system) if repservice is None: msg = (_('_delete_copysession,' 'Cannot find Replication Service to ' 'delete copysession')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # Invoke method for delete copysession rc, job = self.conn.InvokeMethod( 'ModifyReplicaSynchronization', repservice, Operation=self._getnum(operation, '16'), Synchronization=cpsession, Force=True, WaitForCopyState=self._getnum(15, '16')) errordesc = RETCODE_dic[str(rc)] LOG.debug('_delete_copysession,' 'copysession:%(cpsession)s,' 'operation:%(operation)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s,' 'Exit method' % {'cpsession': cpsession, 'operation': operation, 'rc': rc, 'errordesc': errordesc}) if rc != 0L: msg = (_('_delete_copysession,' 'copysession:%(cpsession)s,' 'operation:%(operation)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s') % {'cpsession': cpsession, 'operation': operation, 'rc': rc, 'errordesc': errordesc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return ",,3617,0
openstack%2Ftrove~master~I2ada09f6fe7675b32538f9638cdd94670a5e21c0,openstack/trove,master,I2ada09f6fe7675b32538f9638cdd94670a5e21c0,Unit tests for clusters guest code,ABANDONED,2014-08-14 01:28:04.000000000,2014-08-15 00:07:15.000000000,,"[{'_account_id': 3}, {'_account_id': 8415}, {'_account_id': 9683}]","[{'number': 1, 'created': '2014-08-14 01:28:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/041e9d3960bf1f70ce56f1f627efd9b1d7a828fa', 'message': 'Unit tests for clusters guest code\n\nAdds tests for mongodb guest code as first implementation\n\nCo-Authored-By: svenkataramanaia <svenkataramanaia@ebaysf.com>\n\nPartially implements: blueprint clustering\n\nChange-Id: I2ada09f6fe7675b32538f9638cdd94670a5e21c0\n'}, {'number': 2, 'created': '2014-08-14 02:59:47.000000000', 'files': ['trove/tests/unittests/guestagent/test_mongodb_cluster_manager.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/6a059dce101383178e57d315a1d4bbd607546820', 'message': 'Unit tests for clusters guest code\n\nAdds tests for mongodb guest code as first implementation\n\nCo-Authored-By: svenkataramanaia <svenkataramanaia@ebaysf.com>\n\nPartially implements: blueprint clustering\n\nChange-Id: I2ada09f6fe7675b32538f9638cdd94670a5e21c0\n'}]",0,114096,6a059dce101383178e57d315a1d4bbd607546820,8,3,2,10139,,,0,"Unit tests for clusters guest code

Adds tests for mongodb guest code as first implementation

Co-Authored-By: svenkataramanaia <svenkataramanaia@ebaysf.com>

Partially implements: blueprint clustering

Change-Id: I2ada09f6fe7675b32538f9638cdd94670a5e21c0
",git fetch https://review.opendev.org/openstack/trove refs/changes/96/114096/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/unittests/guestagent/test_mongodb_cluster_manager.py'],1,041e9d3960bf1f70ce56f1f627efd9b1d7a828fa,bp/clustering,"# Copyright 2014 eBay Software Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testtools from mock import patch from trove.common import instance as ds_instance from trove.common import utils from trove.common.context import TroveContext from trove.guestagent import volume from trove.guestagent.common import operating_system from trove.guestagent.datastore.mongodb import service as mongo_service from trove.guestagent.datastore.mongodb.manager import Manager from trove.guestagent.datastore.mongodb.service import MongoDBApp class GuestAgentMongoDBClusterManagerTest(testtools.TestCase): def setUp(self): super(GuestAgentMongoDBClusterManagerTest, self).setUp() self.context = TroveContext() self.manager = Manager() def tearDown(self): super(GuestAgentMongoDBClusterManagerTest, self).tearDown() @patch.object(mongo_service.MongoDbAppStatus, 'set_status') @patch.object(MongoDBApp, 'add_members', side_effect=RuntimeError(""Boom!"")) def test_add_members_failure(self, mock_add_members, mock_set_status): members = {""test1"", ""test2""} self.assertRaises(RuntimeError, self.manager.add_members, self.context, members) mock_set_status.assert_called_with(ds_instance.ServiceStatuses.FAILED) @patch.object(utils, 'poll_until') @patch.object(MongoDBApp, 'do_mongo') def test_add_member(self, mock_do_mongo, mock_poll): members = {""test1"", ""test2""} self.manager.add_members(self.context, members) mock_do_mongo.assert_any_call(""rs.initiate()"") mock_do_mongo.assert_any_call(""rs.add(\""test1\"")"") mock_do_mongo.assert_any_call(""rs.add(\""test2\"")"") @patch.object(mongo_service.MongoDbAppStatus, 'set_status') @patch.object(MongoDBApp, 'add_shard', side_effect=RuntimeError(""Boom!"")) def test_add_shard_failure(self, mock_add_shard, mock_set_status): self.assertRaises(RuntimeError, self.manager.add_shard, self.context, ""rs"", ""rs_member"") mock_set_status.assert_called_with(ds_instance.ServiceStatuses.FAILED) @patch.object(MongoDBApp, 'do_mongo') def test_add_shard(self, mock_do_mongo): self.manager.add_shard(self.context, ""rs"", ""rs_member"") mock_do_mongo.assert_called_with( ""db.adminCommand({addShard: \""rs/rs_member:27017\""})"") @patch.object(mongo_service.MongoDbAppStatus, 'set_status') @patch.object(MongoDBApp, 'add_config_servers', side_effect=RuntimeError(""Boom!"")) def test_add_config_server_failure(self, mock_add_config, mock_set_status): self.assertRaises(RuntimeError, self.manager.add_config_servers, self.context, [""cfg_server1"", ""cfg_server2""]) mock_set_status.assert_called_with(ds_instance.ServiceStatuses.FAILED) @patch.object(MongoDBApp, 'start_db_with_conf_changes') @patch.object(MongoDBApp, '_add_config_parameter', return_value="""") @patch.object(MongoDBApp, '_delete_config_parameters', return_value="""") @patch.object(MongoDBApp, '_read_config', return_value="""") def test_add_config_servers(self, mock_read, mock_delete, mock_add, mock_start): self.manager.add_config_servers(self.context, [""cfg_server1"", ""cfg_server2""]) mock_read.assert_called_with() mock_delete.assert_called_with("""", [""dbpath"", ""nojournal"", ""smallfiles"", ""journal"", ""noprealloc"", ""configdb""]) mock_add.assert_called_with("""", ""configdb"", ""cfg_server1:27019,cfg_server2:27019"") mock_start.assert_called_with("""") @patch.object(mongo_service.MongoDbAppStatus, 'set_status') @patch.object(MongoDBApp, 'write_mongos_upstart') @patch.object(MongoDBApp, 'reset_configuration') @patch.object(MongoDBApp, 'update_config_contents') @patch.object(operating_system, 'get_ip_address', return_value=""10.0.0.2"") def test_prepare_mongos(self, mock_ip_address, mock_update, mock_reset, mock_upstart, mock_set_status): self._prepare_method(""test-id-1"", ""query_router"") mock_update.assert_called_with(None, {'bind_ip': '10.0.0.2'}) self.assertTrue(self.manager.app.status.is_query_router) mock_set_status.assert_called_with( ds_instance.ServiceStatuses.BUILD_PENDING) @patch.object(mongo_service.MongoDbAppStatus, 'set_status') @patch.object(utils, 'poll_until') @patch.object(MongoDBApp, 'start_db_with_conf_changes') @patch.object(MongoDBApp, 'update_config_contents') @patch.object(operating_system, 'get_ip_address', return_value=""10.0.0.3"") def test_prepare_config_server(self, mock_ip_address, mock_update, mock_start, mock_poll, mock_set_status): self._prepare_method(""test-id-2"", ""config_server"") mock_update.assert_called_with(None, {'configsvr': 'true', 'smallfiles': 'true', 'bind_ip': '10.0.0.3', 'dbpath': '/var/lib/mongodb'}) self.assertTrue(self.manager.app.status.is_config_server) mock_set_status.assert_called_with( ds_instance.ServiceStatuses.BUILD_PENDING) @patch.object(mongo_service.MongoDbAppStatus, 'set_status') @patch.object(utils, 'poll_until') @patch.object(MongoDBApp, 'start_db_with_conf_changes') @patch.object(MongoDBApp, 'update_config_contents') @patch.object(operating_system, 'get_ip_address', return_value=""10.0.0.4"") def test_prepare_member(self, mock_ip_address, mock_update, mock_start, mock_poll, mock_set_status): self._prepare_method(""test-id-3"", ""member"") mock_update.assert_called_with(None, {'smallfiles': 'true', 'bind_ip': '10.0.0.4', 'dbpath': '/var/lib/mongodb', 'replSet': 'rs1'}) mock_set_status.assert_called_with( ds_instance.ServiceStatuses.BUILD_PENDING) @patch.object(volume.VolumeDevice, 'mount_points', return_value=[]) @patch.object(volume.VolumeDevice, 'mount', return_value=None) @patch.object(volume.VolumeDevice, 'migrate_data', return_value=None) @patch.object(volume.VolumeDevice, 'format', return_value=None) @patch.object(MongoDBApp, 'clear_storage') @patch.object(MongoDBApp, 'start_db') @patch.object(MongoDBApp, 'stop_db') @patch.object(MongoDBApp, 'install_if_needed') @patch.object(mongo_service.MongoDbAppStatus, 'begin_install') def _prepare_method(self, instance_id, instance_type, *args): cluster_config = {""id"": instance_id, ""shard_id"": ""test_shard_id"", ""instance_type"": instance_type, ""replica_set_name"": ""rs1""} # invocation self.manager.prepare(context=self.context, databases=None, packages=['package'], memory_mb='2048', users=None, mount_point='/var/lib/mongodb', overrides=None, cluster_config=cluster_config) ",,163,0
openstack%2Ftempest~master~Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f,openstack/tempest,master,Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f,Enable E128 ignore E129,MERGED,2014-06-09 21:52:25.000000000,2014-08-15 00:03:44.000000000,2014-08-15 00:03:43.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 7350}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9828}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-09 21:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b2f2aca246a9bb89ecbfac0b97a57d25c08d11ca', 'message': 'Enable E129,E128 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}, {'number': 2, 'created': '2014-06-10 12:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/824801f4d1d99cb2fb726630d198452196873d7e', 'message': 'Enable E129,E128 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}, {'number': 3, 'created': '2014-06-10 14:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/96637d216e14194c2bb420fa52f75084ea67b5a7', 'message': 'Enable E129,E128 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}, {'number': 4, 'created': '2014-06-11 12:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e6d2bd6b3dd09bd8c03b3546a974ca77d8ae9451', 'message': 'Enable E129,E128 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}, {'number': 5, 'created': '2014-06-17 23:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0d53af2d6cf8f21b18c00c3f28ba35137359be98', 'message': 'Enable E129,E128 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}, {'number': 6, 'created': '2014-06-18 00:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/04c3d3fcce61878979130d56af49113ff0cee5b0', 'message': 'Enable E128 ignore E129\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}, {'number': 7, 'created': '2014-06-18 02:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7522402fd568c3c55238089397e150391609db51', 'message': 'Enable E128 ignore E129\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}, {'number': 8, 'created': '2014-07-02 14:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2c8eeefa043ed29526471f44deb55a9bace63680', 'message': 'Enable E128 ignore E129\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}, {'number': 9, 'created': '2014-07-24 15:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ea3cea10da1516bf167f310ec8dead798e718b14', 'message': 'Enable E128 ignore E129\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}, {'number': 10, 'created': '2014-08-12 21:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f8cd2656e8c4762706ab4b6512bca79dc766fb16', 'message': 'Enable E128 ignore E129\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}, {'number': 11, 'created': '2014-08-13 21:53:28.000000000', 'files': ['tempest/api/compute/test_authorization.py', 'tempest/common/rest_client.py', 'tempest/services/network/json/network_client.py', 'tempest/common/waiters.py', 'tempest/tests/test_glance_http.py', 'tempest/api/network/test_allowed_address_pair.py', 'tempest/api/compute/admin/test_aggregates.py', 'tempest/tests/negative/test_negative_auto_test.py', 'tempest/api/network/test_routers.py', 'tempest/stress/actions/volume_attach_delete.py', 'tempest/cmd/javelin.py', 'tempest/thirdparty/boto/test.py', 'tempest/api/network/test_load_balancer.py', 'tempest/api/compute/v3/admin/test_aggregates.py', 'tempest/services/network/xml/network_client.py', 'tempest/exceptions.py', 'tempest/stress/actions/volume_attach_verify.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1d14c54fd8594e26643fba302afe30380d99d651', 'message': 'Enable E128 ignore E129\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f\n'}]",4,98909,1d14c54fd8594e26643fba302afe30380d99d651,85,12,11,5196,,,0,"Enable E128 ignore E129

After bumping the hacking version to the 0.9.x series ignores were
added for several rules. This commit fixes the violations for a subset
of these rules and re-enables the checks.

Change-Id: Iaff25fc9e2ecfad0c0574b39ddce0c5188d6c31f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/09/98909/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/network/json/network_client.py', 'tempest/tests/test_glance_http.py', 'tempest/stress/actions/unit_test.py', 'tempest/api/compute/admin/test_aggregates.py', 'tempest/tests/negative/test_negative_auto_test.py', 'tempest/api/network/test_extra_dhcp_options.py', 'tempest/stress/actions/volume_attach_delete.py', 'tempest/stress/run_stress.py', 'tempest/api/compute/base.py', 'tempest/common/isolated_creds.py', 'tempest/thirdparty/boto/test.py', 'tempest/api/network/test_load_balancer.py', 'tempest/api/compute/v3/admin/test_aggregates.py', 'tempest/services/network/xml/network_client.py', 'tempest/api/network/base.py', 'tempest/stress/actions/volume_attach_verify.py', 'tox.ini', 'tempest/test.py']",18,b2f2aca246a9bb89ecbfac0b97a57d25c08d11ca,hacking," if os.environ.get('OS_LOG_CAPTURE') != 'False': if os.environ.get('OS_LOG_CAPTURE') != '0': log_format = '%(asctime)-15s %(message)s' self.useFixture(fixtures.LoggerFixture(nuke_handlers=False, format=log_format, level=None)) if expected_result is None: if ""default_result_code"" in description: expected_result = description[""default_result_code""]"," if (os.environ.get('OS_LOG_CAPTURE') != 'False' and os.environ.get('OS_LOG_CAPTURE') != '0'): log_format = '%(asctime)-15s %(message)s' self.useFixture(fixtures.LoggerFixture(nuke_handlers=False, format=log_format, level=None)) if (expected_result is None and ""default_result_code"" in description): expected_result = description[""default_result_code""]",168,155
openstack%2Fnova~master~I31710b787c39d23870fb45a460f460663ecb261c,openstack/nova,master,I31710b787c39d23870fb45a460f460663ecb261c,libvirt: volume snapshot delete for network-attached disks,MERGED,2014-06-13 18:31:01.000000000,2014-08-14 23:59:12.000000000,2014-08-14 19:13:48.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4523}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-13 18:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae2c228368199b1d7e56b5b391b434c0cce4a955', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 2, 'created': '2014-06-16 14:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/801b1f5990f3d3dadc21db141977d77f8a54b741', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 3, 'created': '2014-06-17 16:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/446608cfe0ea019ad09cc30995383ae75d6f83a3', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 4, 'created': '2014-06-17 18:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3db39dd15b418b159c2f870a32e3968d385660e2', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 5, 'created': '2014-06-18 15:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/05a86a80e5490245aca4342b18524925693cd94f', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 6, 'created': '2014-06-19 20:15:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6497e707fce24fcf7e74f9332c4b582b6217ef87', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 7, 'created': '2014-06-20 14:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aae320bb4cbeff4491110ce18d4d79116f7f6323', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 8, 'created': '2014-06-23 20:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c3150e64c60ef5636e408d75ff4c669f4808005', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 9, 'created': '2014-06-24 17:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24ca2045f6718ac3854443af88f870fb15f34098', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 10, 'created': '2014-07-22 19:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8df021beb0e7b2d7a9f45ca2636793ebc585f1aa', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 11, 'created': '2014-07-28 13:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7da1368184d27bc311bb64c438b4c074c400fe7e', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 12, 'created': '2014-07-28 16:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ff713a590d4e1298139632da1a20aed94cb2325', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}, {'number': 13, 'created': '2014-08-04 22:40:54.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/fakelibvirt.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bdf11c856266114bf3d150eb482d4e55f5f37245', 'message': ""libvirt: volume snapshot delete for network-attached disks\n\nAdd support for performing a volume snapshot delete for\na network/(libgfapi)-attached disk based on the proposal\nat:\n\nhttp://www.redhat.com/archives/libvir-list/2014-February/msg01226.html\n\nUses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit\ncalls which keeps qcow2 backing file entries as relative filenames\nrather than prepending them with path information when blockCommit\noperations are performed.\n\nSupport for this flag is required and heuristically detected rather\nthan based on version number.\n\nSelection of disk for blockCommit/blockRebase is handled by\nsearching the snapshot hierarchy and using an identifier such as\nvda[2] meaning the second item in the snapshot chain for disk\n'vda'.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I31710b787c39d23870fb45a460f460663ecb261c\n""}]",6,99982,bdf11c856266114bf3d150eb482d4e55f5f37245,117,11,13,4523,,,0,"libvirt: volume snapshot delete for network-attached disks

Add support for performing a volume snapshot delete for
a network/(libgfapi)-attached disk based on the proposal
at:

http://www.redhat.com/archives/libvir-list/2014-February/msg01226.html

Uses a new VIR_DOMAIN_BLOCK_COMMIT_RELATIVE flag for blockCommit
calls which keeps qcow2 backing file entries as relative filenames
rather than prepending them with path information when blockCommit
operations are performed.

Support for this flag is required and heuristically detected rather
than based on version number.

Selection of disk for blockCommit/blockRebase is handled by
searching the snapshot hierarchy and using an identifier such as
vda[2] meaning the second item in the snapshot chain for disk
'vda'.

Implements: blueprint libvirt-volume-snap-network-disk

Change-Id: I31710b787c39d23870fb45a460f460663ecb261c
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/99982/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/fakelibvirt.py', 'nova/tests/virt/libvirt/test_driver.py']",3,ae2c228368199b1d7e56b5b391b434c0cce4a955,bp/libvirt-volume-snap-network-disk," # alternate domain info with network-backed snapshot chain self.dom_netdisk_xml = """""" <domain type='kvm'> <devices> <disk type='file'> <source file='disk1_file'/> <target dev='vda' bus='virtio'/> <serial>0e38683e-f0af-418f-a3f1-6b67eaffffff</serial> </disk> <disk type='network' device='disk'> <driver name='qemu' type='qcow2'/> <source protocol='gluster' name='vol1/root.img'> <host name='server1' port='24007'/> </source> <backingStore type='network' index='1'> <driver name='qemu' type='qcow2'/> <source protocol='gluster' name='vol1/snap.img'> <host name='server1' port='24007'/> </source> <backingStore type='network' index='2'> <driver name='qemu' type='qcow2'/> <source protocol='gluster' name='vol1/snap-b.img'> <host name='server1' port='24007'/> </source> <backingStore/> </backingStore> </backingStore> <target dev='vdb' bus='virtio'/> <serial>0e38683e-f0af-418f-a3f1-6b67ea0f919d</serial> </disk> </devices> </domain> """""" self.delete_info_netdisk = {'type': 'qcow2', 'file_to_merge': 'snap.img', 'merge_target_file': 'root.img'} def test_volume_snapshot_delete_netdisk_1(self): """"""Delete newest snapshot -- blockRebase for libgfapi/network disk."""""" class FakeNetdiskDomain(FakeVirtDomain): def __init__(self, *args, **kwargs): super(FakeNetdiskDomain, self).__init__(*args, **kwargs) def XMLDesc(self, *args): return self.dom_netdisk_xml instance = db.instance_create(self.c, self.inst) snapshot_id = 'snapshot-1234' domain = FakeNetdiskDomain(fake_xml=self.dom_netdisk_xml) self.mox.StubOutWithMock(domain, 'XMLDesc') domain.XMLDesc(0).AndReturn(self.dom_netdisk_xml) self.mox.StubOutWithMock(self.conn, '_lookup_by_name') self.mox.StubOutWithMock(self.conn, 'has_min_version') self.mox.StubOutWithMock(domain, 'blockRebase') self.mox.StubOutWithMock(domain, 'blockCommit') self.mox.StubOutWithMock(domain, 'blockJobInfo') self.conn._lookup_by_name('instance-%s' % instance['id']).\ AndReturn(domain) self.conn.has_min_version(mox.IgnoreArg()).AndReturn(True) domain.blockRebase('vdb', 'vdb[1]', 0, 0) domain.blockJobInfo('vdb', 0).AndReturn({'cur': 1, 'end': 1000}) domain.blockJobInfo('vdb', 0).AndReturn({'cur': 1000, 'end': 1000}) self.mox.ReplayAll() self.conn._volume_snapshot_delete(self.c, instance, self.volume_uuid, snapshot_id, self.delete_info_1) self.mox.VerifyAll() def test_volume_snapshot_delete_netdisk_2(self): """"""Delete older snapshot -- blockCommit for libgfapi/network disk."""""" class FakeNetdiskDomain(FakeVirtDomain): def __init__(self, *args, **kwargs): super(FakeNetdiskDomain, self).__init__(*args, **kwargs) def XMLDesc(self, *args): return self.dom_netdisk_xml instance = db.instance_create(self.c, self.inst) snapshot_id = 'snapshot-1234' domain = FakeNetdiskDomain(fake_xml=self.dom_netdisk_xml) self.mox.StubOutWithMock(domain, 'XMLDesc') domain.XMLDesc(0).AndReturn(self.dom_netdisk_xml) self.mox.StubOutWithMock(self.conn, '_lookup_by_name') self.mox.StubOutWithMock(self.conn, 'has_min_version') self.mox.StubOutWithMock(domain, 'blockRebase') self.mox.StubOutWithMock(domain, 'blockCommit') self.mox.StubOutWithMock(domain, 'blockJobInfo') self.conn._lookup_by_name('instance-%s' % instance['id']).\ AndReturn(domain) self.conn.has_min_version(mox.IgnoreArg()).AndReturn(True) domain.blockCommit('vdb', 'vdb[0]', 'vdb[1]', 0, libvirt.VIR_DOMAIN_BLOCK_COMMIT_RELATIVE) domain.blockJobInfo('vdb', 0).AndReturn({'cur': 1, 'end': 1000}) domain.blockJobInfo('vdb', 0).AndReturn({'cur': 1000, 'end': 1000}) self.mox.ReplayAll() self.conn._volume_snapshot_delete(self.c, instance, self.volume_uuid, snapshot_id, self.delete_info_netdisk) self.mox.VerifyAll()",,215,10
openstack%2Ftempest~master~I8f14cd2ca6afc38d3fe8ee758272071111022896,openstack/tempest,master,I8f14cd2ca6afc38d3fe8ee758272071111022896,"Enable H407,H305,H307,E122 ignore E123",MERGED,2014-06-09 22:45:15.000000000,2014-08-14 23:53:35.000000000,2014-08-14 23:53:35.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 7428}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-09 22:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a4293e874326d1f66e25707d3346dad9e7bc5507', 'message': 'Enable H407,H305,E123,H307,E122 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 2, 'created': '2014-06-10 12:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e6801c4e048caf2ecd21877cc58d4ac68315d1a9', 'message': 'Enable H407,H305,E123,H307,E122 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 3, 'created': '2014-06-10 14:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/22b0734b1f7b3649be97f6210986a88d2d85b9eb', 'message': 'Enable H407,H305,E123,H307,E122 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 4, 'created': '2014-06-11 12:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/99c3bf30c3c4ca5fab3c8f1930de4125d86d646f', 'message': 'Enable H407,H305,E123,H307,E122 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 5, 'created': '2014-06-17 23:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6354beb4069a66a82da518e80db523779bd5b2ce', 'message': 'Enable H407,H305,E123,H307,E122 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 6, 'created': '2014-06-18 00:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ceac47ce47b9b662015b1a4295dd00a6443ec385', 'message': 'Enable H407,H305,E123,H307,E122 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 7, 'created': '2014-06-18 00:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c3eed8b62511b4378fbf422b70df241b6887d51', 'message': 'Enable H407,H305,E123,H307,E122 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 8, 'created': '2014-06-18 02:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9063473ab1c31badeec36c74ba0a03bf61591066', 'message': 'Enable H407,H305,E123,H307,E122 rules\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 9, 'created': '2014-07-02 13:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ab367b751bc05fa2bae4d14b0b36ddba6b4e9844', 'message': 'Enable H407,H305,H307,E122 ignore E123\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nE123 is ignored because this rule is ignored in the default pep8 by\ndefault, due to a lack of consensus around it.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 10, 'created': '2014-07-02 14:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/305f15e97489a73e77ac3fece1e9804a2daf6206', 'message': 'Enable H407,H305,H307,E122 ignore E123\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nE123 is ignored because this rule is ignored in the default pep8 by\ndefault, due to a lack of consensus around it.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 11, 'created': '2014-07-24 15:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a995b54972c9fb134f3d90fe456b1c9b9a2a49cf', 'message': 'Enable H407,H305,H307,E122 ignore E123\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nE123 is ignored because this rule is ignored in the default pep8 by\ndefault, due to a lack of consensus around it.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}, {'number': 12, 'created': '2014-08-12 21:49:40.000000000', 'files': ['tempest/api/volume/test_volumes_list.py', 'tempest/api/identity/admin/v3/test_trusts.py', 'tempest/cli/simple_read_only/test_heat.py', 'tempest/scenario/manager.py', 'tempest/tests/fake_identity.py', 'tempest/tests/fake_http.py', 'tempest/api/orchestration/stacks/test_nova_keypair_resources.py', 'tempest/thirdparty/boto/test.py', 'tempest/api/object_storage/test_object_services.py', 'tempest/cli/simple_read_only/test_cinder.py', 'tempest/services/network/xml/network_client.py', 'tempest/api_schema/response/compute/v3/servers.py', 'tempest/services/compute/xml/security_groups_client.py', 'tempest/common/rest_client.py', 'tools/colorizer.py', 'tempest/tests/test_rest_client.py', 'tempest/api/compute/servers/test_server_actions.py', 'tempest/common/ssh.py', 'tempest/common/utils/linux/remote_client.py', 'tempest/tests/test_commands.py', 'tempest/cmd/run_stress.py', 'tempest/common/accounts.py', 'tox.ini', 'tempest/services/object_storage/account_client.py', 'tools/check_logs.py', 'tempest/auth.py', 'tempest/cmd/verify_tempest_config.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/api/orchestration/stacks/test_neutron_resources.py', 'tempest/common/debug.py', 'tempest/services/telemetry/telemetry_client_base.py', 'tempest/services/volume/xml/admin/volume_quotas_client.py', 'tempest/api_schema/response/compute/v3/hypervisors.py', 'tempest/tests/base.py', 'tempest/scenario/orchestration/test_autoscaling.py', 'tools/find_stack_traces.py', 'tempest/cmd/javelin.py', 'tempest/services/compute/xml/hosts_client.py', 'tempest/api/queuing/test_queues.py', 'tempest/api/compute/v3/servers/test_server_actions.py', 'tempest/services/object_storage/container_client.py', 'tempest/tests/test_glance_http.py', 'tempest/common/glance_http.py', 'tempest/common/cred_provider.py', 'tempest/services/compute/xml/floating_ips_client.py', 'tempest/services/volume/xml/volumes_client.py', 'tempest/api/compute/volumes/test_volumes_get.py', 'tempest/api/orchestration/base.py', 'tempest/tests/test_tenant_isolation.py', 'tempest/api_schema/response/compute/v2/hypervisors.py', 'tempest/services/volume/json/admin/volume_quotas_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/96e9e88dc06a5527b764a0ff4efe05d86c6054a8', 'message': 'Enable H407,H305,H307,E122 ignore E123\n\nAfter bumping the hacking version to the 0.9.x series ignores were\nadded for several rules. This commit fixes the violations for a subset\nof these rules and re-enables the checks.\n\nE123 is ignored because this rule is ignored in the default pep8 by\ndefault, due to a lack of consensus around it.\n\nChange-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896\n'}]",7,98918,96e9e88dc06a5527b764a0ff4efe05d86c6054a8,83,13,12,5196,,,0,"Enable H407,H305,H307,E122 ignore E123

After bumping the hacking version to the 0.9.x series ignores were
added for several rules. This commit fixes the violations for a subset
of these rules and re-enables the checks.

E123 is ignored because this rule is ignored in the default pep8 by
default, due to a lack of consensus around it.

Change-Id: I8f14cd2ca6afc38d3fe8ee758272071111022896
",git fetch https://review.opendev.org/openstack/tempest refs/changes/18/98918/12 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/volume/test_volumes_list.py', 'tempest/api/identity/admin/v3/test_trusts.py', 'tempest/cli/simple_read_only/test_heat.py', 'tempest/scenario/manager.py', 'tempest/tests/fake_identity.py', 'tempest/tests/fake_http.py', 'tempest/stress/run_stress.py', 'tempest/thirdparty/boto/test.py', 'tempest/api/object_storage/test_object_services.py', 'tempest/cli/simple_read_only/test_cinder.py', 'tempest/services/network/xml/network_client.py', 'tempest/services/compute/xml/security_groups_client.py', 'tempest/common/rest_client.py', 'tempest/api/volume/v2/test_volumes_list.py', 'tools/colorizer.py', 'tempest/tests/test_rest_client.py', 'tempest/api/compute/servers/test_server_actions.py', 'tempest/common/ssh.py', 'tempest/api_schema/compute/v3/servers.py', 'tempest/common/utils/linux/remote_client.py', 'tempest/api_schema/compute/aggregates.py', 'tempest/tests/test_commands.py', 'tox.ini', 'tempest/services/object_storage/account_client.py', 'tools/check_logs.py', 'tempest/auth.py', 'tempest/cmd/verify_tempest_config.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/common/debug.py', 'tempest/services/telemetry/telemetry_client_base.py', 'tempest/services/volume/xml/admin/volume_quotas_client.py', 'tempest/tests/base.py', 'tempest/scenario/orchestration/test_autoscaling.py', 'tools/find_stack_traces.py', 'tempest/api_schema/compute/v2/hypervisors.py', 'tempest/cmd/javelin.py', 'tempest/services/compute/xml/hosts_client.py', 'tempest/api/queuing/test_queues.py', 'tempest/api/compute/v3/servers/test_server_actions.py', 'tempest/services/object_storage/container_client.py', 'tempest/tests/test_glance_http.py', 'tempest/common/glance_http.py', 'tempest/services/compute/xml/floating_ips_client.py', 'tempest/services/volume/xml/volumes_client.py', 'tempest/api/compute/volumes/test_volumes_get.py', 'tempest/tests/test_tenant_isolation.py', 'tempest/services/volume/json/admin/volume_quotas_client.py', 'tempest/api_schema/compute/v3/hypervisors.py']",48,a4293e874326d1f66e25707d3346dad9e7bc5507,hacking, }}, } },73,52
openstack%2Fdiskimage-builder~master~I89f51d7f3489db37c4a7090cc63311e6d87b8427,openstack/diskimage-builder,master,I89f51d7f3489db37c4a7090cc63311e6d87b8427,foo,ABANDONED,2014-08-14 22:59:57.000000000,2014-08-14 23:42:03.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-14 22:59:57.000000000', 'files': ['elements/package-installs/bin/package-installs', 'elements/package-installs/bin/package-uninstalls'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c1f326b199d5953019d2f81cbc23b5413872fae3', 'message': 'foo\n\nChange-Id: I89f51d7f3489db37c4a7090cc63311e6d87b8427\n'}]",0,114385,c1f326b199d5953019d2f81cbc23b5413872fae3,3,1,1,7144,,,0,"foo

Change-Id: I89f51d7f3489db37c4a7090cc63311e6d87b8427
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/85/114385/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/package-installs/bin/package-installs', 'elements/package-installs/bin/package-uninstalls']",2,c1f326b199d5953019d2f81cbc23b5413872fae3,package-installs," basefile=$(basename $PACKAGEFILE) element_name=${basefile#""package-installs-""}"," element_name=${PACKAGEFILE#""package-installs-""}",4,2
openstack%2Ftempest~master~I0375bee55fb3e99a8b01fba27ebf77523dd383bd,openstack/tempest,master,I0375bee55fb3e99a8b01fba27ebf77523dd383bd,"Revert ""Added neutron cli test case""",MERGED,2014-08-14 15:24:30.000000000,2014-08-14 23:13:12.000000000,2014-08-14 23:13:11.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-08-14 15:24:30.000000000', 'files': ['tempest/cli/simple_read_only/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/821af690e36dfe64e7108182a18a0510abd2d290', 'message': 'Revert ""Added neutron cli test case""\n\nThis change causes issues in parallel run, because routers\ncan disappear after listing.\n\nThe safe way would be to create the router by the test itself,\nand maybe wait for scheduling.\n\nOr using a pre configured router for example router1 created by\ndevstack.\n\nFor now it should be reverted.\n\nThis reverts commit 693db20aa8c4c7912743d57b82f1a368e3ef4960.\n\nChange-Id: I0375bee55fb3e99a8b01fba27ebf77523dd383bd\n'}]",0,114269,821af690e36dfe64e7108182a18a0510abd2d290,17,5,1,5803,,,0,"Revert ""Added neutron cli test case""

This change causes issues in parallel run, because routers
can disappear after listing.

The safe way would be to create the router by the test itself,
and maybe wait for scheduling.

Or using a pre configured router for example router1 created by
devstack.

For now it should be reverted.

This reverts commit 693db20aa8c4c7912743d57b82f1a368e3ef4960.

Change-Id: I0375bee55fb3e99a8b01fba27ebf77523dd383bd
",git fetch https://review.opendev.org/openstack/tempest refs/changes/69/114269/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cli/simple_read_only/test_neutron.py'],1,821af690e36dfe64e7108182a18a0510abd2d290,remove-rrr,," @test.attr(type='smoke') @test.requires_ext(extension='l3_agent_scheduler', service='network') def test_neutron_l3_agent_list_hosting_router(self): router_list = self.parser.listing(self.neutron('router-list')) for router in router_list: l3_list = self.parser.listing(self.neutron ('l3-agent-list-hosting-router', params=router['id'])) self.assertTableStruct(l3_list, ['id', 'host', 'admin_state_up', 'alive']) ",0,11
openstack%2Ftripleo-image-elements~master~Ibf3f79ada00d9934d9fbec699eacc58683847aff,openstack/tripleo-image-elements,master,Ibf3f79ada00d9934d9fbec699eacc58683847aff,Add rdo-release element,MERGED,2014-07-03 15:59:54.000000000,2014-08-14 22:53:48.000000000,2014-08-14 22:53:47.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 7144}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 8532}, {'_account_id': 9712}]","[{'number': 1, 'created': '2014-07-03 15:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e09b4cceafd05d97b7aa4e910b2829e18912cd7e', 'message': 'Add rdo-release element\n\nThis element sets up the appropriate repository to install RDO on\nRed Hat based operating systems.\n\nChange-Id: Ibf3f79ada00d9934d9fbec699eacc58683847aff\n'}, {'number': 2, 'created': '2014-07-21 21:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/dfdd19c01f1e5297939939e97fd24f493289e582', 'message': 'Add rdo-release element\n\nThis element sets up the appropriate repository to install RDO on\nRed Hat based operating systems.\n\nChange-Id: Ibf3f79ada00d9934d9fbec699eacc58683847aff\n'}, {'number': 3, 'created': '2014-07-21 21:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/900e7a2e425fe4f46b10766bd6ae9d9a0e984fe9', 'message': 'Add rdo-release element\n\nThis element sets up the appropriate repository to install RDO on\nRed Hat based operating systems.\n\nChange-Id: Ibf3f79ada00d9934d9fbec699eacc58683847aff\n'}, {'number': 4, 'created': '2014-08-01 12:36:01.000000000', 'files': ['elements/rdo-release/README.md', 'elements/rdo-release/pre-install.d/10-rdo-release-repo'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/bbf82e08a9a6f0953a6c6872c86d5ac64efe9528', 'message': 'Add rdo-release element\n\nThis element sets up the appropriate repository to install RDO on\nRed Hat based operating systems.\n\nChange-Id: Ibf3f79ada00d9934d9fbec699eacc58683847aff\n'}]",4,104598,bbf82e08a9a6f0953a6c6872c86d5ac64efe9528,55,7,4,8532,,,0,"Add rdo-release element

This element sets up the appropriate repository to install RDO on
Red Hat based operating systems.

Change-Id: Ibf3f79ada00d9934d9fbec699eacc58683847aff
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/98/104598/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/rdo-release/README.md', 'elements/rdo-release/pre-install.d/10-rdo-release-repo']",2,e09b4cceafd05d97b7aa4e910b2829e18912cd7e,add-rdo-release-element-1,#!/bin/bash set -eux install-packages http://rdo.fedorapeople.org/openstack-$RDO_RELEASE/rdo-release-$RDO_RELEASE.rpm ,,9,0
openstack%2Fmonasca-api~master~I9659fe518cc5c35c8eb96bbc75399e64ede45327,openstack/monasca-api,master,I9659fe518cc5c35c8eb96bbc75399e64ede45327,Added support for querying metrics created since a timestamp.,ABANDONED,2014-07-22 01:37:31.000000000,2014-08-14 22:11:29.000000000,,"[{'_account_id': 3}, {'_account_id': 1976}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-07-22 01:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/398a24fdf2700210eb8ae7185714b760c576f027', 'message': 'Added support for querying metrics created since a timestamp.\n\nChange-Id: I9659fe518cc5c35c8eb96bbc75399e64ede45327\n'}, {'number': 2, 'created': '2014-08-01 17:05:17.000000000', 'files': ['src/test/java/com/hpcloud/mon/infrastructure/persistence/vertica/MetricDefinitionVerticaRepositoryImplTest.java', 'src/main/java/com/hpcloud/mon/resource/MetricResource.java', 'src/main/java/com/hpcloud/mon/domain/model/metric/MetricDefinitionRepository.java', 'src/main/java/com/hpcloud/mon/infrastructure/persistence/vertica/MetricDefinitionVerticaRepositoryImpl.java', 'src/main/java/com/hpcloud/mon/infrastructure/persistence/influxdb/MetricDefinitionInfluxDbRepositoryImpl.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/5f5afbfc7d00308f167c55906bb6ff4fd660a550', 'message': 'Added support for querying metrics created since a timestamp.\n\nChange-Id: I9659fe518cc5c35c8eb96bbc75399e64ede45327\n'}]",2,108552,5f5afbfc7d00308f167c55906bb6ff4fd660a550,14,5,2,1976,,,0,"Added support for querying metrics created since a timestamp.

Change-Id: I9659fe518cc5c35c8eb96bbc75399e64ede45327
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/52/108552/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/main/java/com/hpcloud/mon/resource/MetricResource.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/vertica/MetricDefinitionVerticaRepositoryImplTest.java', 'src/main/java/com/hpcloud/mon/domain/model/metric/MetricDefinitionRepository.java', 'src/main/java/com/hpcloud/mon/infrastructure/persistence/vertica/MetricDefinitionVerticaRepositoryImpl.java', 'src/main/java/com/hpcloud/mon/infrastructure/persistence/influxdb/MetricDefinitionInfluxDbRepositoryImpl.java']",5,398a24fdf2700210eb8ae7185714b760c576f027,alarm-mgr,"import org.joda.time.DateTime; public List<MetricDefinition> find(String tenantId, String name, Map<String, String> dimensions, DateTime createdSince) throws Exception {"," public List<MetricDefinition> find(String tenantId, String name, Map<String, String> dimensions) throws Exception {",29,13
openstack%2Foslo-incubator~master~I5e3ac71dda2e70a623a585a7e014f1404ee23760,openstack/oslo-incubator,master,I5e3ac71dda2e70a623a585a7e014f1404ee23760,Set stevedore log level to WARN by default,MERGED,2014-08-14 21:49:58.000000000,2014-08-14 22:06:36.000000000,2014-08-14 22:06:35.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-08-14 21:49:58.000000000', 'files': ['openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/037dee004c3e2239e402546ab65bc93775b8dcd2', 'message': ""Set stevedore log level to WARN by default\n\nOur *-api logs are very big right now, with a good chunk of the logs\ncoming from stevedore. Since we aren't trying to debug stevedore and it\njust works for us, set it to INFO Log.\n\nChange-Id: I5e3ac71dda2e70a623a585a7e014f1404ee23760\n""}]",0,114368,037dee004c3e2239e402546ab65bc93775b8dcd2,8,3,1,1849,,,0,"Set stevedore log level to WARN by default

Our *-api logs are very big right now, with a good chunk of the logs
coming from stevedore. Since we aren't trying to debug stevedore and it
just works for us, set it to INFO Log.

Change-Id: I5e3ac71dda2e70a623a585a7e014f1404ee23760
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/68/114368/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/log.py'],1,037dee004c3e2239e402546ab65bc93775b8dcd2,stevedore," ""keystonemiddleware=WARN"", ""routes.middleware=WARN"", ""stevedore=WARN""]"," ""keystonemiddleware=WARN"", ""routes.middleware=WARN""]",2,1
openstack%2Fopenstack-manuals~master~Ifed8b7ad8a5b406ba274b2ff5dd774eb810ff12f,openstack/openstack-manuals,master,Ifed8b7ad8a5b406ba274b2ff5dd774eb810ff12f,Change the text Windows 2012 server to Windows,MERGED,2014-08-07 10:48:04.000000000,2014-08-14 21:56:26.000000000,2014-08-14 21:56:25.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6772}, {'_account_id': 8103}]","[{'number': 1, 'created': '2014-08-07 10:48:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1a0f4e62b86d27b01f39457d56836e11f6437a29', 'message': 'Fix typo about Windows Server\n\n""Windows 2012 server"" -> ""Windows Server 2012""\n\nChange-Id: Ifed8b7ad8a5b406ba274b2ff5dd774eb810ff12f\nCloses-Bug: 1353948\n'}, {'number': 2, 'created': '2014-08-07 13:45:34.000000000', 'files': ['doc/image-guide/section_windows-example.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4656e9a6559ee28631db401171158bb059aa9a01', 'message': 'Change the text Windows 2012 server to Windows\n\nchange the text ""Windows 2012 server"" to ""Windows""\nincluding Windows Server 2012, Windows 7, 8\n\nChange-Id: Ifed8b7ad8a5b406ba274b2ff5dd774eb810ff12f\nCloses-Bug: 1353948\n'}]",1,112551,4656e9a6559ee28631db401171158bb059aa9a01,18,4,2,10497,,,0,"Change the text Windows 2012 server to Windows

change the text ""Windows 2012 server"" to ""Windows""
including Windows Server 2012, Windows 7, 8

Change-Id: Ifed8b7ad8a5b406ba274b2ff5dd774eb810ff12f
Closes-Bug: 1353948
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/51/112551/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/image-guide/section_windows-example.xml'],1,1a0f4e62b86d27b01f39457d56836e11f6437a29,bug/1353948," a virtual machine image. On Windows Server 2012, invoke sysprep, as follows:"," a virtual machine image. On Windows 2012 server, invoke sysprep, as follows:",1,1
openstack%2Fnova~master~Icb45182fa58d69e7c5e3a77ea31eddc492ac46ec,openstack/nova,master,Icb45182fa58d69e7c5e3a77ea31eddc492ac46ec,Add debug log for availability zone filter,MERGED,2014-07-03 10:03:18.000000000,2014-08-14 21:30:51.000000000,2014-08-14 11:27:40.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 7133}, {'_account_id': 7166}, {'_account_id': 7641}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-07-03 10:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc54986bb05b2b22bbd575861650a9b72d57da59', 'message': ""Add debug log for availability zone filter\n\nSometimes operator need information why the host doesn't pass\nthe check of scheduler, this patch adds information for available\nzone filter if the host doesn't belong to required available zone.\n\nChange-Id: Icb45182fa58d69e7c5e3a77ea31eddc492ac46ec\nPartial-Bug: #1301830\n""}, {'number': 2, 'created': '2014-07-07 01:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/271bc8daa98b1d588fe741c1e7b8d850e9665fc5', 'message': ""Add debug log for availability zone filter\n\nSometimes operator need information why the host doesn't pass\nthe check of scheduler, this patch adds information for available\nzone filter if the host doesn't belong to required available zone.\n\nChange-Id: Icb45182fa58d69e7c5e3a77ea31eddc492ac46ec\nPartial-Bug: #1301830\n""}, {'number': 3, 'created': '2014-07-07 06:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/507e8b18cc55c38524cdd505cef77e5aef96d21c', 'message': ""Add debug log for availability zone filter\n\nSometimes operator need information why the host doesn't pass\nthe check of scheduler, this patch adds information for available\nzone filter if the host doesn't belong to required available zone.\n\nChange-Id: Icb45182fa58d69e7c5e3a77ea31eddc492ac46ec\nPartial-Bug: #1301830\n""}, {'number': 4, 'created': '2014-07-31 09:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71deeb5c3a903751cf14583e227966bb5411b866', 'message': ""Add debug log for availability zone filter\n\nSometimes operator need information why the host doesn't pass\nthe check of scheduler, this patch adds information for available\nzone filter if the host doesn't belong to required available zone.\n\nChange-Id: Icb45182fa58d69e7c5e3a77ea31eddc492ac46ec\nPartial-Bug: #1301830\n""}, {'number': 5, 'created': '2014-08-06 03:04:20.000000000', 'files': ['nova/scheduler/filters/availability_zone_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9a0f85953638a64c7589ffbbd798106f8d7e44b2', 'message': ""Add debug log for availability zone filter\n\nSometimes operator need information why the host doesn't pass\nthe check of scheduler, this patch adds information for available\nzone filter if the host doesn't belong to required available zone\nand modify the logic a little to make it less nested.\n\nChange-Id: Icb45182fa58d69e7c5e3a77ea31eddc492ac46ec\nPartial-Bug: #1301830\n""}]",7,104503,9a0f85953638a64c7589ffbbd798106f8d7e44b2,107,17,5,6062,,,0,"Add debug log for availability zone filter

Sometimes operator need information why the host doesn't pass
the check of scheduler, this patch adds information for available
zone filter if the host doesn't belong to required available zone
and modify the logic a little to make it less nested.

Change-Id: Icb45182fa58d69e7c5e3a77ea31eddc492ac46ec
Partial-Bug: #1301830
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/104503/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/filters/availability_zone_filter.py'],1,fc54986bb05b2b22bbd575861650a9b72d57da59,bug/1301830-2,"from nova.openstack.common import log as loggingLOG = logging.getLogger(__name__) if not availability_zone in metadata['availability_zone']: LOG.debug(""%(host_state)s requires to find %(az)s, "" ""it is not in host available zone "" ""%(host_az)s"", {'host_state': host_state, 'az': availability_zone, 'host_az': metadata['availability_zone']}) return False return True else: if availability_zone != CONF.default_availability_zone: LOG.debug(""%(host_state)s requires to find %(az)s, "" ""it is not equal to default available zone"" ""%(host_az)s"", {'host_state': host_state, 'az': availability_zone, 'host_az': CONF.default_availability_zone}) return False return True", return availability_zone in metadata['availability_zone'] else: return availability_zone == CONF.default_availability_zone,21,2
openstack%2Fpython-neutronclient~master~I8a2010332be0acfe6762bf3190248fe17f42cadb,openstack/python-neutronclient,master,I8a2010332be0acfe6762bf3190248fe17f42cadb,Print exception when verbose is over DEBUG_LEVEL,MERGED,2014-08-06 13:25:21.000000000,2014-08-14 21:11:31.000000000,2014-08-14 21:11:31.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 5950}, {'_account_id': 7170}, {'_account_id': 10370}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-06 13:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/553f02e0b6f3bece9bc90f7dd751b1ef30c3b774', 'message': 'Print exception when verbose is over DEBUG_LEVEL\n\nChange-Id: I8a2010332be0acfe6762bf3190248fe17f42cadb\nCloses-bug: #1353496\n'}, {'number': 2, 'created': '2014-08-14 07:21:12.000000000', 'files': ['neutronclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8f59a306e269fea21d3f5643b11de49c73cacc19', 'message': 'Print exception when verbose is over DEBUG_LEVEL\n\nChange-Id: I8a2010332be0acfe6762bf3190248fe17f42cadb\nCloses-bug: #1353496\n'}]",0,112295,8f59a306e269fea21d3f5643b11de49c73cacc19,18,7,2,7170,,,0,"Print exception when verbose is over DEBUG_LEVEL

Change-Id: I8a2010332be0acfe6762bf3190248fe17f42cadb
Closes-bug: #1353496
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/95/112295/2 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/shell.py'],1,553f02e0b6f3bece9bc90f7dd751b1ef30c3b774,master, if self.options.verbose_level >= self.DEBUG_LEVEL: if self.options.verbose_level >= self.DEBUG_LEVEL: if self.options.verbose_level >= self.DEBUG_LEVEL: if self.options.verbose_level >= self.DEBUG_LEVEL: if self.options.verbose_level >= self.DEBUG_LEVEL:, if self.options.verbose_level == self.DEBUG_LEVEL: if self.options.verbose_level == self.DEBUG_LEVEL: if self.options.verbose_level == self.DEBUG_LEVEL: if self.options.verbose_level == self.DEBUG_LEVEL: if self.options.verbose_level == self.DEBUG_LEVEL:,5,5
openstack%2Ftempest~master~I5647ad905e5962b5eb024183dfc8877be13ee4d0,openstack/tempest,master,I5647ad905e5962b5eb024183dfc8877be13ee4d0,Remove unorthodox credentials for orchestration scenarios,ABANDONED,2014-05-20 03:29:26.000000000,2014-08-14 21:09:31.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 8576}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10090}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-20 03:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/871f419e214b8435dc91555e1d7bfd8f547bbd39', 'message': 'Remove unorthodox credentials for orchestration scenarios\n\nThis change runs the orchestration scenario tests using standard\nuser credentials rather than admin user on demo tenant. This change\nhas already been made to the api tests and it was an oversight that\nthey were not done here too.\n\nThe orchestration scenario tests are not yet ready to run in\nisolated mode.\n\nChange-Id: I5647ad905e5962b5eb024183dfc8877be13ee4d0\n'}, {'number': 2, 'created': '2014-07-18 02:48:51.000000000', 'files': ['tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/444a45c37d86c1a387967e9ed12ae32a5a65c188', 'message': 'Remove unorthodox credentials for orchestration scenarios\n\nThis change runs the orchestration scenario tests using standard\nuser credentials rather than admin user on demo tenant. This change\nhas already been made to the api tests and it was an oversight that\nthey were not done here too.\n\nThe orchestration scenario tests are not yet ready to run in\nisolated mode.\n\nChange-Id: I5647ad905e5962b5eb024183dfc8877be13ee4d0\n'}]",1,94300,444a45c37d86c1a387967e9ed12ae32a5a65c188,29,10,2,4571,,,0,"Remove unorthodox credentials for orchestration scenarios

This change runs the orchestration scenario tests using standard
user credentials rather than admin user on demo tenant. This change
has already been made to the api tests and it was an oversight that
they were not done here too.

The orchestration scenario tests are not yet ready to run in
isolated mode.

Change-Id: I5647ad905e5962b5eb024183dfc8877be13ee4d0
",git fetch https://review.opendev.org/openstack/tempest refs/changes/00/94300/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,871f419e214b8435dc91555e1d7bfd8f547bbd39,heat-creds, return creds, admin_creds = auth.get_default_credentials('identity_admin') admin_creds.tenant_name = creds.tenant_name return admin_creds,1,3
openstack%2Ftempest~master~I33b36cfbc326330ff41640f8e257124317f3aa00,openstack/tempest,master,I33b36cfbc326330ff41640f8e257124317f3aa00,WIP scenario test for heat software-config,ABANDONED,2014-05-08 00:09:38.000000000,2014-08-14 21:08:52.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 5689}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-08 00:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/69248eeb91a3cf58b553e8d56be535ab147e7b63', 'message': 'WIP scenario test for heat software-config\n\nThis scenario deploys simple configs using scripts, puppet and\ncfn-init. The outputs from each deployment resource are asserted\nto confirm that the config ran.\n\nThis test could be further enhanced by doing a stack update with\ndifferent cfg* params and asserting the result.\n\nAnother enhancement would be to have a config run in action DELETE\nand assert that the delete config did something.\n\nThis test will only run with a custom diskimage-builder based image\nsuch as what is built with this devstack series:\nhttps://review.openstack.org/#/c/92260/\n\nChange-Id: I33b36cfbc326330ff41640f8e257124317f3aa00\n'}, {'number': 2, 'created': '2014-05-20 03:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/20dd9624b634f7da785592c69e2dd6d576028d81', 'message': 'WIP scenario test for heat software-config\n\nThis scenario deploys simple configs using scripts, puppet and\ncfn-init. The outputs from each deployment resource are asserted\nto confirm that the config ran.\n\nThis test could be further enhanced by doing a stack update with\ndifferent cfg* params and asserting the result.\n\nAnother enhancement would be to have a config run in action DELETE\nand assert that the delete config did something.\n\nThis test will only run with a custom diskimage-builder based image\nsuch as what is built with this devstack series:\nhttps://review.openstack.org/#/c/92260/\n\nChange-Id: I33b36cfbc326330ff41640f8e257124317f3aa00\n'}, {'number': 3, 'created': '2014-07-21 15:44:48.000000000', 'files': ['tempest/scenario/orchestration/software_config.yaml', 'tempest/scenario/orchestration/test_server_software_config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/47c754d085ce23d44a615beaa82edc9201de7188', 'message': 'WIP scenario test for heat software-config\n\nThis scenario deploys simple configs using scripts, puppet and\ncfn-init. The outputs from each deployment resource are asserted\nto confirm that the config ran.\n\nThis test could be further enhanced by doing a stack update with\ndifferent cfg* params and asserting the result.\n\nAnother enhancement would be to have a config run in action DELETE\nand assert that the delete config did something.\n\nThis test will only run with a custom diskimage-builder based image\nsuch as what is built with this devstack series:\nhttps://review.openstack.org/#/c/92260/\n\nChange-Id: I33b36cfbc326330ff41640f8e257124317f3aa00\n'}]",0,92731,47c754d085ce23d44a615beaa82edc9201de7188,27,8,3,4571,,,0,"WIP scenario test for heat software-config

This scenario deploys simple configs using scripts, puppet and
cfn-init. The outputs from each deployment resource are asserted
to confirm that the config ran.

This test could be further enhanced by doing a stack update with
different cfg* params and asserting the result.

Another enhancement would be to have a config run in action DELETE
and assert that the delete config did something.

This test will only run with a custom diskimage-builder based image
such as what is built with this devstack series:
https://review.openstack.org/#/c/92260/

Change-Id: I33b36cfbc326330ff41640f8e257124317f3aa00
",git fetch https://review.opendev.org/openstack/tempest refs/changes/31/92731/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/orchestration/software_config.yaml', 'tempest/scenario/orchestration/test_server_software_config.py']",2,69248eeb91a3cf58b553e8d56be535ab147e7b63,software_config,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest import config from tempest import exceptions from tempest.openstack.common import log as logging from tempest.scenario import manager from tempest import test CONF = config.CONF LOG = logging.getLogger(__name__) CFG1_SH = '''#!/bin/sh echo ""Writing to /tmp/$bar"" echo $foo > /tmp/$bar echo -n ""The file /tmp/$bar contains `cat /tmp/$bar` for server \ $deploy_server_id during $deploy_action"" > $heat_outputs_path.result echo ""Written to /tmp/$bar"" echo ""Output to stderr"" 1>&2 ''' CFG3_PP = '''file {'barfile': ensure => file, mode => 0644, path => ""/tmp/$::bar"", content => ""$::foo"", } file {'output_result': ensure => file, path => ""$::heat_outputs_path.result"", mode => 0644, content => ""The file /tmp/$::bar contains $::foo for server \ $::deploy_server_id during $::deploy_action"", }''' class SoftwareConfigScenarioTest(manager.OrchestrationScenarioTest): def setUp(self): super(SoftwareConfigScenarioTest, self).setUp() if not CONF.orchestration.image_ref: raise self.skipException(""No image available to test"") self.client = self.orchestration_client self.template_name = 'software_config.yaml' def assign_keypair(self): self.stack_name = self._stack_rand_name() if CONF.orchestration.keypair_name: self.keypair = None self.keypair_name = CONF.orchestration.keypair_name else: self.keypair = self.create_keypair() self.keypair_name = self.keypair.id def launch_stack(self): net = self._get_default_network() self.parameters = { 'key_name': self.keypair_name, 'flavor': CONF.orchestration.instance_type, 'image': CONF.orchestration.image_ref, 'network': net['id'] } # create the stack self.template = self._load_template(__file__, self.template_name) self.client.stacks.create( stack_name=self.stack_name, template=self.template, parameters=self.parameters, files={ 'cfg1.sh': CFG1_SH, 'cfg3.pp': CFG3_PP }) self.stack = self.client.stacks.get(self.stack_name) self.stack_identifier = '%s/%s' % (self.stack_name, self.stack.id) # if a keypair was set, do not delete the stack on exit to allow # for manual post-mortums if not CONF.orchestration.keypair_name: self.set_resource('stack', self.stack) def check_stack(self): sid = self.stack_identifier for res in ('cfg2a', 'cfg2b', 'cfg1', 'cfg3', 'server'): self._wait_for_resource_status( sid, res, 'CREATE_COMPLETE') server_resource = self.client.resources.get(sid, 'server') server_id = server_resource.physical_resource_id server = self.compute_client.servers.get(server_id) try: for res in ('dep2a', 'dep2b', 'dep1', 'dep3'): self._wait_for_resource_status( sid, res, 'CREATE_COMPLETE') except (exceptions.StackResourceBuildErrorException, exceptions.TimeoutException) as e: raise e finally: # attempt to log the server console regardless of deployment # going to complete. This allows successful and failed cloud-init # logs to be compared self._log_console_output(servers=[server]) self.status_timeout(self.client.stacks, sid, 'COMPLETE', error_status='FAILED') stack = self.client.stacks.get(sid) res1 = self._stack_output(stack, 'res1') self.assertEqual( 'The file %s contains %s for server %s during %s' % ( '/tmp/baaaaa', 'fooooo', server_id, 'CREATE'), res1['result']) self.assertEqual(0, res1['status_code']) self.assertEqual('Output to stderr\n', res1['stderr']) self.assertTrue(len(res1['stdout']) > 0) res2 = self._stack_output(stack, 'res2') self.assertEqual( 'The file %s contains %s for server %s during %s' % ( '/tmp/cfn-init-foo', 'barrr', server_id, 'CREATE'), res2['result']) self.assertEqual(0, res2['status_code']) self.assertEqual('', res2['stderr']) self.assertEqual('', res2['stdout']) res3 = self._stack_output(stack, 'res3') self.assertEqual( 'The file %s contains %s for server %s during %s' % ( '/tmp/ba', 'fo', server_id, 'CREATE'), res3['result']) self.assertEqual(0, res3['status_code']) self.assertEqual('', res3['stderr']) self.assertTrue(len(res1['stdout']) > 0) @test.attr(type='slow') @test.services('orchestration', 'compute') def test_server_software_config(self): self.assign_keypair() self.launch_stack() self.check_stack() ",,311,0
openstack%2Ftempest~master~I71457702d2d1c456270446c71994aeb525e103e4,openstack/tempest,master,I71457702d2d1c456270446c71994aeb525e103e4,Autoscaling trigger scale-down with template update,ABANDONED,2013-09-03 22:33:51.000000000,2014-08-14 21:08:29.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 7350}, {'_account_id': 7872}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2013-09-03 22:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/21c94a0b7323279f9ee53866e34ef5bc32981496', 'message': 'Autoscaling trigger scale-down with template update\n\nPreviously the autoscaling test triggered scaling down at a set\ntime after stack launch. This has some issues:\n- it depended on synchronized clocks\n- in the period before scale down, time is wasted doing nothing\n- if scale-up took longer than typical, scale-down may occur before\n  scale-up had finished\n\nThis change triggers scale-down by doing a stack update with\nchanged metadata as soon as scale-up is complete.\n\nThe consume_memory script polls for the metadata change and quits\nto release the memory.\n\nThis test now runs quicker, is less race prone, and adds\nstack updates to its test scenario.\n\nChange-Id: I71457702d2d1c456270446c71994aeb525e103e4\n'}, {'number': 2, 'created': '2014-03-18 17:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e0fa58de1d2d9889f22c89e2468f2e78862af7f9', 'message': 'Autoscaling trigger scale-down with template update\n\nPreviously the autoscaling test triggered scaling down at a set\ntime after stack launch. This has some issues:\n- it depended on synchronized clocks\n- in the period before scale down, time is wasted doing nothing\n- if scale-up took longer than typical, scale-down may occur before\n  scale-up had finished\n\nThis change triggers scale-down by doing a stack update with\nchanged metadata as soon as scale-up is complete.\n\nThe consume_memory.py script now pushes artificial watch stats and polls the\nmetadata to find out whether to push a high memory value or a low one.\n\nThis test now runs quicker, is less race prone, and adds\nstack updates to its test scenario.\n\nChange-Id: I71457702d2d1c456270446c71994aeb525e103e4'}, {'number': 3, 'created': '2014-03-23 20:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f2e19498a2195347f863ced2734481d66ef8b8c4', 'message': 'Autoscaling trigger scale-down with template update\n\nPreviously the autoscaling test triggered scaling down at a set\ntime after stack launch. This has some issues:\n- it depended on synchronized clocks\n- in the period before scale down, time is wasted doing nothing\n- if scale-up took longer than typical, scale-down may occur before\n  scale-up had finished\n\nThis change triggers scale-down by doing a stack update with\nchanged metadata as soon as scale-up is complete.\n\nThe consume_memory.py script now pushes artificial watch stats and polls the\nmetadata to find out whether to push a high memory value or a low one.\n\nThis test now runs quicker, is less race prone, and adds\nstack updates to its test scenario.\n\nChange-Id: I71457702d2d1c456270446c71994aeb525e103e4'}, {'number': 4, 'created': '2014-03-31 21:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9e5398ca910bdee1434ffbdf69b2f41e9d2c48dc', 'message': 'Autoscaling trigger scale-down with template update\n\nPreviously the autoscaling test triggered scaling down at a set\ntime after stack launch. This has some issues:\n- it depended on synchronized clocks\n- in the period before scale down, time is wasted doing nothing\n- if scale-up took longer than typical, scale-down may occur before\n  scale-up had finished\n\nThis change triggers scale-down by doing a stack update with\nchanged metadata as soon as scale-up is complete.\n\nThe consume_memory.py script now pushes artificial watch stats and polls the\nmetadata to find out whether to push a high memory value or a low one.\n\nThis test now runs quicker, is less race prone, and adds\nstack updates to its test scenario.\n\nChange-Id: I71457702d2d1c456270446c71994aeb525e103e4'}, {'number': 5, 'created': '2014-04-16 01:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3036ccf5d3417d67212ee36246e6848b8a91653c', 'message': 'Autoscaling trigger scale-down with template update\n\nPreviously the autoscaling test triggered scaling down at a set\ntime after stack launch. This has some issues:\n- it depended on synchronized clocks\n- in the period before scale down, time is wasted doing nothing\n- if scale-up took longer than typical, scale-down may occur before\n  scale-up had finished\n\nThis change triggers scale-down by doing a stack update with\nchanged metadata as soon as scale-up is complete.\n\nThe consume_memory.py script now pushes artificial watch stats and polls the\nmetadata to find out whether to push a high memory value or a low one.\n\nThis test now runs quicker, is less race prone, and adds\nstack updates to its test scenario.\n\nCloses-Bug: #1257575\nChange-Id: I71457702d2d1c456270446c71994aeb525e103e4'}, {'number': 6, 'created': '2014-05-27 01:37:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f4e6ada1806f7524ae4f663983094ecf08941b38', 'message': 'Autoscaling trigger scale-down with template update\n\nPreviously the autoscaling test triggered scaling down at a set\ntime after stack launch. This has some issues:\n- it depended on synchronized clocks\n- in the period before scale down, time is wasted doing nothing\n- if scale-up took longer than typical, scale-down may occur before\n  scale-up had finished\nThis change triggers scale-down by doing a stack update with\nchanged metadata as soon as scale-up is complete.\nThe consume_memory.py script now pushes artificial watch stats and polls the\nmetadata to find out whether to push a high memory value or a low one.\nThis test now runs quicker, is less race prone, and adds\nstack updates to its test scenario.\nCloses-Bug: #1257575\nChange-Id: I71457702d2d1c456270446c71994aeb525e103e4\n'}, {'number': 7, 'created': '2014-05-29 22:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dabf27aeed336600e4eccb6f475364b6734b4277', 'message': 'Autoscaling trigger scale-down with template update\n\nPreviously the autoscaling test triggered scaling down at a set\ntime after stack launch. This has some issues:\n- it depended on synchronized clocks\n- in the period before scale down, time is wasted doing nothing\n- if scale-up took longer than typical, scale-down may occur before\n  scale-up had finished\nThis change triggers scale-down by doing a stack update with\nchanged metadata as soon as scale-up is complete.\nThe consume_memory.py script now pushes artificial watch stats and polls the\nmetadata to find out whether to push a high memory value or a low one.\nThis test now runs quicker, is less race prone, and adds\nstack updates to its test scenario.\nCloses-Bug: #1257575\nChange-Id: I71457702d2d1c456270446c71994aeb525e103e4\n'}, {'number': 8, 'created': '2014-08-06 01:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a32dfba8aae8a86c20e42af332ab3bbc92e8be78', 'message': 'Autoscaling trigger scale-down with template update\n\nPreviously the autoscaling test triggered scaling down at a set\ntime after stack launch. This has some issues:\n- it depended on synchronized clocks\n- in the period before scale down, time is wasted doing nothing\n- if scale-up took longer than typical, scale-down may occur before\n  scale-up had finished\nThis change triggers scale-down by doing a stack update with\nchanged metadata as soon as scale-up is complete.\nThe consume_memory.py script now pushes artificial watch stats and polls the\nmetadata to find out whether to push a high memory value or a low one.\nThis test now runs quicker, is less race prone, and adds\nstack updates to its test scenario.\nCloses-Bug: #1257575\nChange-Id: I71457702d2d1c456270446c71994aeb525e103e4\n'}, {'number': 9, 'created': '2014-08-06 02:30:54.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/scenario/orchestration/test_autoscaling.yaml', 'tempest/scenario/orchestration/test_autoscaling.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/30e4aede42f5019a8ececa2d03d8ec49360ae60c', 'message': 'Autoscaling trigger scale-down with template update\n\nPreviously the autoscaling test triggered scaling down at a set\ntime after stack launch. This has some issues:\n- it depended on synchronized clocks\n- in the period before scale down, time is wasted doing nothing\n- if scale-up took longer than typical, scale-down may occur before\n  scale-up had finished\nThis change triggers scale-down by doing a stack update with\nchanged metadata as soon as scale-up is complete.\nThe consume_memory.py script now pushes artificial watch stats and polls the\nmetadata to find out whether to push a high memory value or a low one.\nThis test now runs quicker, is less race prone, and adds\nstack updates to its test scenario.\nCloses-Bug: #1257575\nChange-Id: I71457702d2d1c456270446c71994aeb525e103e4\n'}]",19,44967,30e4aede42f5019a8ececa2d03d8ec49360ae60c,81,12,9,4571,,,0,"Autoscaling trigger scale-down with template update

Previously the autoscaling test triggered scaling down at a set
time after stack launch. This has some issues:
- it depended on synchronized clocks
- in the period before scale down, time is wasted doing nothing
- if scale-up took longer than typical, scale-down may occur before
  scale-up had finished
This change triggers scale-down by doing a stack update with
changed metadata as soon as scale-up is complete.
The consume_memory.py script now pushes artificial watch stats and polls the
metadata to find out whether to push a high memory value or a low one.
This test now runs quicker, is less race prone, and adds
stack updates to its test scenario.
Closes-Bug: #1257575
Change-Id: I71457702d2d1c456270446c71994aeb525e103e4
",git fetch https://review.opendev.org/openstack/tempest refs/changes/67/44967/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/orchestration/test_autoscaling.yaml', 'tempest/scenario/orchestration/test_autoscaling.py']",2,21c94a0b7323279f9ee53866e34ef5bc32981496,bug/1257575,"import yaml self.template = yaml.load(self._load_template( __file__, 'test_autoscaling.yaml')) metadata = self.template['Resources']['LaunchConfig']['Metadata'] metadata['ConsumeNow'] = '0' self.stack.update( template=self.template, parameters=self.parameters) "," self.template = self._load_template(__file__, 'test_autoscaling.yaml')",35,20
openstack%2Fdevstack-gate~master~I0364e0e18c43ee24b9778c3a72c77cadf795771e,openstack/devstack-gate,master,I0364e0e18c43ee24b9778c3a72c77cadf795771e,Updated from global requirements,MERGED,2014-08-13 23:17:45.000000000,2014-08-14 21:07:44.000000000,2014-08-14 21:07:44.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-08-13 23:17:45.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/a7c8e6b597064317b7b4e05d00da8f2b5b7f24b7', 'message': 'Updated from global requirements\n\nChange-Id: I0364e0e18c43ee24b9778c3a72c77cadf795771e\n'}]",0,114054,a7c8e6b597064317b7b4e05d00da8f2b5b7f24b7,15,4,1,11131,,,0,"Updated from global requirements

Change-Id: I0364e0e18c43ee24b9778c3a72c77cadf795771e
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/54/114054/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,a7c8e6b597064317b7b4e05d00da8f2b5b7f24b7,openstack/requirements,bashate>=0.2 # Apache-2.0,bashate>=0.2,1,1
openstack%2Fcongress~master~I81a5ed9d5ecbd647e0fbda021c6dc008f00c9c9d,openstack/congress,master,I81a5ed9d5ecbd647e0fbda021c6dc008f00c9c9d,API Model: return dict in get_items(),MERGED,2014-08-14 05:17:11.000000000,2014-08-14 21:07:38.000000000,2014-08-14 21:07:38.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-08-14 05:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/2f14728e946c384fcb396fafcdbdbe83350b68d4', 'message': ""API Model: return dict in get_items()\n\nIn some cases, the data model may wish to return supplimental data along\nwith the items associated with the request.  The get_items() call is now\nexpected to return a dict with a mandatory 'results' item, and optional\nadditional items it wishes to be returned to the user.\n\nChange-Id: I81a5ed9d5ecbd647e0fbda021c6dc008f00c9c9d\nCloses-Bug: #1356686\n""}, {'number': 2, 'created': '2014-08-14 16:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d4de0130d31a5d1a75675bcef58d1880ce58c18f', 'message': ""API Model: return dict in get_items()\n\nIn some cases, the data model may wish to return supplimental data along\nwith the items associated with the request.  The get_items() call is now\nexpected to return a dict with a mandatory 'results' item, and optional\nadditional items it wishes to be returned to the user.\n\nChange-Id: I81a5ed9d5ecbd647e0fbda021c6dc008f00c9c9d\nCloses-Bug: #1356686\n""}, {'number': 3, 'created': '2014-08-14 17:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/ce6a8e4dfce0dec1091edb8c9879f6a9d704a0aa', 'message': ""API Model: return dict in get_items()\n\nIn some cases, the data model may wish to return supplimental data along\nwith the items associated with the request.  The get_items() call is now\nexpected to return a dict with a mandatory 'results' item, and optional\nadditional items it wishes to be returned to the user.\n\nChange-Id: I81a5ed9d5ecbd647e0fbda021c6dc008f00c9c9d\nCloses-Bug: #1356686\n""}, {'number': 4, 'created': '2014-08-14 20:52:16.000000000', 'files': ['congress/tests/api/test_webservice.py', 'congress/tests/test_congress.py', 'congress/api/webservice.py', 'congress/api/datasource_model.py', 'congress/api/table_model.py', 'congress/api/policy_model.py', 'congress/api/row_model.py', 'congress/api/rule_model.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/e81e63966baf5f6ff6e2e861e711478696076de4', 'message': ""API Model: return dict in get_items()\n\nIn some cases, the data model may wish to return supplimental data along\nwith the items associated with the request.  The get_items() call is now\nexpected to return a dict with a mandatory 'results' item, and optional\nadditional items it wishes to be returned to the user.\n\nChange-Id: I81a5ed9d5ecbd647e0fbda021c6dc008f00c9c9d\nCloses-Bug: #1356686\n""}]",0,114123,e81e63966baf5f6ff6e2e861e711478696076de4,19,4,4,9253,,,0,"API Model: return dict in get_items()

In some cases, the data model may wish to return supplimental data along
with the items associated with the request.  The get_items() call is now
expected to return a dict with a mandatory 'results' item, and optional
additional items it wishes to be returned to the user.

Change-Id: I81a5ed9d5ecbd647e0fbda021c6dc008f00c9c9d
Closes-Bug: #1356686
",git fetch https://review.opendev.org/openstack/congress refs/changes/23/114123/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/api/test_webservice.py', 'congress/tests/test_congress.py', 'congress/api/datasource_model.py', 'congress/api/webservice.py', 'congress/api/table_model.py', 'congress/api/policy_model.py', 'congress/api/row_model.py', 'congress/api/rule_model.py']",8,2f14728e946c384fcb396fafcdbdbe83350b68d4,, Returns: A dict containing at least a 'results' key whose value is a list of items in the model. Additional keys set in the dict will also be rendered for the user. results = [] results.append(d) return {'results': results}," Returns: A sequence of (id, item) for all items in model. result = [] result.append((rule.id, d)) return result",69,50
openstack%2Fzaqar~master~I43b2020f6ea98737baa23aa7e0a234506839f7b4,openstack/zaqar,master,I43b2020f6ea98737baa23aa7e0a234506839f7b4,Setting up a development environment docs,MERGED,2014-08-08 15:55:23.000000000,2014-08-14 21:05:47.000000000,2014-08-14 21:05:47.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 6944}, {'_account_id': 8803}]","[{'number': 1, 'created': '2014-08-08 15:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/aca29f5e16134d953de9705d2cc07ddeee93a9d6', 'message': 'Setting up a development environment docs\n\nThis changes adds information about how to get Zaqar code,\ninitial configuration and how to run the zaqar-server both\nin a virtualenv and with DevStack to the developers manual.\n\nChange-Id: I43b2020f6ea98737baa23aa7e0a234506839f7b4\n'}, {'number': 2, 'created': '2014-08-08 16:11:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/994af9ef03cbf6e4361133bfeff8ec43d6385321', 'message': 'Setting up a development environment docs\n\nThis changes adds information about how to get Zaqar code,\ninitial configuration and how to run the zaqar-server both\nin a virtualenv and with DevStack to the developers manual.\n\nChange-Id: I43b2020f6ea98737baa23aa7e0a234506839f7b4\n'}, {'number': 3, 'created': '2014-08-11 12:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/38f6791a88f88e26aaced262bec914b7e92c7187', 'message': 'Setting up a development environment docs\n\nThis changes adds information about how to get Zaqar code,\ninitial configuration and how to run the zaqar-server both\nin a virtualenv and with DevStack to the developers manual.\n\nChange-Id: I43b2020f6ea98737baa23aa7e0a234506839f7b4\n'}, {'number': 4, 'created': '2014-08-11 21:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5aa6968e41aaa236af20e20994822752a74f95f0', 'message': 'Setting up a development environment docs\n\nThis changes adds information about how to get Zaqar code,\ninitial configuration and how to run the zaqar-server both\nin a virtualenv and with DevStack to the developers manual.\n\nChange-Id: I43b2020f6ea98737baa23aa7e0a234506839f7b4\n'}, {'number': 5, 'created': '2014-08-12 19:23:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/466367918f7d2723304845f8d928e39661e3399a', 'message': 'Setting up a development environment docs\n\nThis changes adds information about how to get Zaqar code,\ninitial configuration and how to run the zaqar-server both\nin a virtualenv and with DevStack to the developers manual.\n\nChange-Id: I43b2020f6ea98737baa23aa7e0a234506839f7b4\n'}, {'number': 6, 'created': '2014-08-13 19:30:22.000000000', 'files': ['doc/source/index.rst', 'doc/source/development-environment.rst'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7992846f4191d77c52d3ffcc4ea123eb1f17a0c6', 'message': 'Setting up a development environment docs\n\nThis changes adds information about how to get Zaqar code,\ninitial configuration and how to run the zaqar-server both\nin a virtualenv and with DevStack to the developers manual.\n\nChange-Id: I43b2020f6ea98737baa23aa7e0a234506839f7b4\n'}]",82,112957,7992846f4191d77c52d3ffcc4ea123eb1f17a0c6,33,5,6,6413,,,0,"Setting up a development environment docs

This changes adds information about how to get Zaqar code,
initial configuration and how to run the zaqar-server both
in a virtualenv and with DevStack to the developers manual.

Change-Id: I43b2020f6ea98737baa23aa7e0a234506839f7b4
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/57/112957/6 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/development-environment.rst']",2,aca29f5e16134d953de9705d2cc07ddeee93a9d6,doc-rock-day,".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Setting up a development environment ==================================== This page describes how to setup a working Python development environment that can be used in developing Zaqar on Ubuntu or Fedora. These instructions assume you're already familiar with Git. Refer to GettingTheCode_ for additional information. .. _GettingTheCode: http://wiki.openstack.org/GettingTheCode Virtual environments -------------------- We advice using virtualenv_ to track and manage Python dependencies while in development and testing. This allows you to install all of the Python package dependencies in a virtual environment or ""virtualenv"" (a special subdirectory of your Zaqar directory), instead of installing the packages at the system level. .. _virtualenv: http://pypi.python.org/pypi/virtualenv .. note:: Virtualenv is useful for development purposes, but is not typically used for full integration testing or production usage. Install GNU/Linux system dependencies ##################################### .. note:: This section is tested for Zaqar on Ubuntu 14.04 (Trusty) and Fedora-based (RHEL 6.1) distributions. Feel free to add notes and change according to your experiences or operating system. Install the prerequisite packages. On Ubuntu:: $ sudo apt-get install python-pip python-dev git-core On Fedora-based distributions (e.g., Fedora/RHEL/CentOS):: $ sudo yum install python-pip python-devel git Install MongoDB ############### You will also need to have MongoDB_ installed and running. .. _MongoDB: http://www.mongodb.org On Ubuntu, follow the instructions in the `MongoDB on Ubuntu installation guide`_. .. _`MongoDB on Ubuntu installation guide`: http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/` On Fedora-based distributions, follow the instructions in the `MongoDB on Red Hat Enterprise, CentOS, Fedora, or Amazon Linux installation guide`_. .. _`MongoDB on Red Hat Enterprise, CentOS, Fedora, or Amazon Linux installation guide`: http://docs.mongodb.org/manual/tutorial/install-mongodb-on-red-hat-centos-or-fedora-linux/`. Getting the code ################ Grab the code from GitHub:: $ git clone https://github.com/openstack/zaqar.git Configuration ############# 1. From your home folder create the ~/.zaqar folder. This directory will hold the configuration files for Zaqar:: $ mkdir ~/.zaqar 2. Copy the Zaqar configuration files samples to the directory .zaqar/:: $ cp zaqar/etc/zaqar.conf.sample ~/.zaqar/zaqar.conf $ cp zaqar/etc/logging.conf.sample ~/.zaqar/logging.conf 3. Find [drivers] section in ~/.zaqar/zaqar.conf and specify to use mongodb storage:: storage = mongodb 4. Then find the [drivers:storage:mongodb] section and modify the URI to point to your local mongod instance:: uri = mongodb://$MONGODB_HOST:$MONGODB_PORT # default = mongodb://localhost:27017 5. For logging, find the [DEFAULT] section in ~/.zaqar/zaqar.conf and modify as desired:: log_file = server.log Installing and using the virtualenv ################################### 1. You can install virtualenv running:: $ pip install virtualenv 2. And start it from your local repository with:: $ virtualenv marconi $ source zaqar/bin/activate 3. Now, you have to perform the Zaqar installation calling:: $ python setup.py develop 4. Start the Zaqar server:: $ zaqar-server -v 5. Test out that Zaqar is working by creating a queue:: $ curl -i -X PUT http://localhost:8888/v1/queues/samplequeue -H ""Content-type: application/json"" 6. You are ready to code! Remember to reinstall (step 3) to test your changes. Devstack -------- In order to use Zaqar with DevStack_, you'll need to add the following setting in your local.conf:: enable-service zaqar-server .. _DevStack: http://devstack.org Then run the stack.sh script as usual. You can start the Zaqar server and test it by following steps 5 and 6 from the previous section. Running unit tests ------------------ See :doc:`running_tests` for details. Contributing your work ---------------------- Once your work is complete, you may wish to contribute it to the project. Zaqar uses the Gerrit code review system. For information on how to submit your branch to Gerrit, see GerritWorkflow_. .. _GerritWorkflow: http://wiki.openstack.org/GerritWorkflow",,164,0
openstack%2Fhorizon~master~Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39,openstack/horizon,master,Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39,Add Volume Snapshots table to Admin Volumes,MERGED,2014-07-10 22:50:33.000000000,2014-08-14 21:03:48.000000000,2014-08-13 06:11:10.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 8090}, {'_account_id': 8871}, {'_account_id': 9531}, {'_account_id': 9576}, {'_account_id': 9981}, {'_account_id': 10295}, {'_account_id': 11592}, {'_account_id': 11880}, {'_account_id': 11973}]","[{'number': 1, 'created': '2014-07-10 22:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/56e24664cf7373103219165c91eca456752bba4d', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nImplements: blueprint cinder-reset-snapshot-state\n'}, {'number': 2, 'created': '2014-07-21 17:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ce2f217a33abb2d37ea5bdb9cff49ec5676345f0', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nImplements: blueprint cinder-reset-snapshot-state\n'}, {'number': 3, 'created': '2014-07-21 18:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/23ea9794a0d7892bd23a4b1645b73e33a449b945', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nPartial-Implements: blueprint cinder-reset-snapshot-state\nCloses-Bug: #1332077\n'}, {'number': 4, 'created': '2014-07-28 19:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bc64e894b8bc7c7274b4f2d3dfc5d35e8d368d55', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nPartial-Implements: blueprint cinder-reset-snapshot-state\nCloses-Bug: #1332077\n'}, {'number': 5, 'created': '2014-07-29 20:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e5045465fd47167501b4abaad04e69f08ec08b64', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nPartial-Implements: blueprint cinder-reset-snapshot-state\nCloses-Bug: #1332077\n'}, {'number': 6, 'created': '2014-07-30 19:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4bba427f60bbc974807c70637e19ceed38c145e1', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nPartial-Implements: blueprint cinder-reset-snapshot-state\nCloses-Bug: #1332077\nCloses-Bug: #1350502'}, {'number': 7, 'created': '2014-08-04 15:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/74e02d03f402ef2ffaae777a0defd145e237cacd', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nPartial-Implements: blueprint cinder-reset-snapshot-state\nCloses-Bug: #1332077\n'}, {'number': 8, 'created': '2014-08-04 19:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c879da83361fd9107170d8c67ddff65b31cb9551', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nPartial-Implements: blueprint cinder-reset-snapshot-state\nCloses-Bug: #1332077\n'}, {'number': 9, 'created': '2014-08-05 17:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9c07b000414cc48b2a512887bdcbedf62b255a1f', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nPartial-Implements: blueprint cinder-reset-snapshot-state\nCloses-Bug: #1332077\n'}, {'number': 10, 'created': '2014-08-08 18:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8910fdc3adf54b495ceb7e6512075414db28f137', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nThere are also a few Bootstrap 3 fixes included in this submit. \n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nPartial-Implements: blueprint cinder-reset-snapshot-state\nCloses-Bug: #1332077\nCloses-Bug: #1351381'}, {'number': 11, 'created': '2014-08-11 17:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0af200446fb1441ce756a637ba6c1bc5b292124c', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nPartial-Implements: blueprint cinder-reset-snapshot-state\nCloses-Bug: #1332077\n'}, {'number': 12, 'created': '2014-08-12 15:39:12.000000000', 'files': ['openstack_dashboard/dashboards/admin/volumes/templates/volumes/index.html', 'openstack_dashboard/dashboards/admin/volumes/snapshots/forms.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/urls.py', 'openstack_dashboard/dashboards/admin/volumes/volumes/views.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/snapshots/_update_status.html', 'openstack_dashboard/dashboards/project/volumes/snapshots/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/volumes/extras/_create.html', 'openstack_dashboard/dashboards/project/volumes/snapshots/views.py', 'openstack_dashboard/dashboards/admin/volumes/tests.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/views.py', 'openstack_dashboard/test/api_tests/cinder_tests.py', 'openstack_dashboard/dashboards/admin/volumes/urls.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/tests.py', 'openstack_dashboard/dashboards/admin/volumes/volumes/extras/tests.py', 'openstack_dashboard/dashboards/project/volumes/volumes/views.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/volumes/extras/_edit.html', 'openstack_dashboard/dashboards/admin/volumes/snapshots/__init__.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/snapshots/update_status.html', 'openstack_dashboard/dashboards/admin/volumes/views.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/volumes/extras/_index.html', 'openstack_dashboard/dashboards/admin/volumes/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/334789312bc9e50c391861ddd9e34012dc25129e', 'message': 'Add Volume Snapshots table to Admin Volumes\n\nThis is part 2 of the work for the BP. The Volume Snapshots table\nresides inside the new ""Volume Snapshots"" tab which is the second tab\nwithin the Admin Volumes panel. There are two table actions: ""Delete\nVolume Snapshot"" and ""Update Volume Snapshot Status"". The Update\nVolume Snapshot Status action implements a cinder command that was\nonly available through CLI as per stated in the BP.\n\nChange-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39\nPartial-Implements: blueprint cinder-reset-snapshot-state\nCloses-Bug: #1332077\n'}]",43,106192,334789312bc9e50c391861ddd9e34012dc25129e,98,12,12,11592,,,0,"Add Volume Snapshots table to Admin Volumes

This is part 2 of the work for the BP. The Volume Snapshots table
resides inside the new ""Volume Snapshots"" tab which is the second tab
within the Admin Volumes panel. There are two table actions: ""Delete
Volume Snapshot"" and ""Update Volume Snapshot Status"". The Update
Volume Snapshot Status action implements a cinder command that was
only available through CLI as per stated in the BP.

Change-Id: Ife2da2c142467e47a7ac5bfcb8a477ff578b4d39
Partial-Implements: blueprint cinder-reset-snapshot-state
Closes-Bug: #1332077
",git fetch https://review.opendev.org/openstack/horizon refs/changes/92/106192/12 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/volumes/snapshots/__init__.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/snapshots/update_status.html', 'openstack_dashboard/dashboards/admin/volumes/snapshots/forms.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/urls.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/volumes/views.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/snapshots/_update_status.html', 'openstack_dashboard/dashboards/admin/volumes/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/tests.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/views.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/tables.py', 'openstack_dashboard/test/api_tests/cinder_tests.py', 'openstack_dashboard/dashboards/admin/volumes/urls.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/tests.py']",14,56e24664cf7373103219165c91eca456752bba4d,bp/cinder-reset-snapshot-state-1,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from django.core.urlresolvers import reverse from django import http from mox import IsA # noqa from openstack_dashboard.api import cinder from openstack_dashboard.test import helpers as test class VolumeSnapshotsViewTests(test.BaseAdminViewTests): @test.create_stubs({cinder: ('volume_snapshot_reset_state', 'volume_snapshot_get')}) def test_update_snapshot_status(self): snapshot = self.cinder_volume_snapshots.first() state = 'error' cinder.volume_snapshot_get(IsA(http.HttpRequest), snapshot.id) \ .AndReturn(snapshot) cinder.volume_snapshot_reset_state(IsA(http.HttpRequest), snapshot.id, state) self.mox.ReplayAll() formData = {'status': state} url = reverse('horizon:admin:volumes:snapshots:update_status', args=(snapshot.id,)) res = self.client.post(url, formData) self.assertNoFormErrors(res) ",,371,8
openstack%2Fneutron~master~I7e856a61ecefdb89edd814608643851c39b3fa80,openstack/neutron,master,I7e856a61ecefdb89edd814608643851c39b3fa80,Allow creating floatingip with floating_ip_address,ABANDONED,2014-08-13 22:04:45.000000000,2014-08-14 21:01:42.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-08-13 22:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aef6e2c55a6e3ca4bc157b9a6008885288bbefd7', 'message': 'Allow creating floatingip with floating_ip_address\n\nThe floating_ip_address is allowed in a POST (create) request,\ndefaulting to ATTR_NOT_SPECIFIED for automatic assignment.\n\nThe value is passed in the fixed_ips list to the underlying\ncreate_port call on the external network, which does all necessary\nvalidation checks already.\n\nTests for creation of floatingips with a specific address are added;\nno changes in existing tests.\n\nCloses-Bug: 1355183\n\nChange-Id: I7e856a61ecefdb89edd814608643851c39b3fa80\n'}, {'number': 2, 'created': '2014-08-14 08:00:00.000000000', 'files': ['neutron/tests/unit/test_l3_plugin.py', 'neutron/extensions/l3.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eccbfd659a382d322aa604d2463c702028618d64', 'message': 'Allow creating floatingip with floating_ip_address\n\nThe floating_ip_address is allowed in a POST (create) request,\ndefaulting to ATTR_NOT_SPECIFIED for automatic assignment.\n\nThe value is passed in the fixed_ips list to the underlying\ncreate_port call on the external network, which does all necessary\nvalidation checks already.\n\nTests for creation of floatingips with a specific address are added;\nno changes in existing tests.\n\nCloses-Bug: 1355183\n\nChange-Id: I7e856a61ecefdb89edd814608643851c39b3fa80\n'}]",0,114043,eccbfd659a382d322aa604d2463c702028618d64,38,18,2,12697,,,0,"Allow creating floatingip with floating_ip_address

The floating_ip_address is allowed in a POST (create) request,
defaulting to ATTR_NOT_SPECIFIED for automatic assignment.

The value is passed in the fixed_ips list to the underlying
create_port call on the external network, which does all necessary
validation checks already.

Tests for creation of floatingips with a specific address are added;
no changes in existing tests.

Closes-Bug: 1355183

Change-Id: I7e856a61ecefdb89edd814608643851c39b3fa80
",git fetch https://review.opendev.org/openstack/neutron refs/changes/43/114043/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_l3_plugin.py', 'neutron/extensions/l3.py', 'neutron/db/l3_db.py']",3,aef6e2c55a6e3ca4bc157b9a6008885288bbefd7,bug/1355183," floating_ip_address = fip['floating_ip_address'] if floating_ip_address != attributes.ATTR_NOT_SPECIFIED: floating_ip_address = [{'ip_address': floating_ip_address}] 'fixed_ips': floating_ip_address,"," 'fixed_ips': attributes.ATTR_NOT_SPECIFIED,",67,7
openstack%2Fopenstacksdk~master~I53d32018cc50b35a005434f816e0475312bc808b,openstack/openstacksdk,master,I53d32018cc50b35a005434f816e0475312bc808b,Various standard server actions,MERGED,2014-08-09 03:14:03.000000000,2014-08-14 20:56:50.000000000,2014-08-14 20:56:50.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-09 03:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/69876721988e907ec8e9e1cede68b9e65f3dedad', 'message': 'Various standard server actions\n\nChange-Id: I53d32018cc50b35a005434f816e0475312bc808b\n'}, {'number': 2, 'created': '2014-08-14 17:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/25018a06abd6fb4ce0016ff3650d15bb3513cc39', 'message': 'Various standard server actions\n\nChange-Id: I53d32018cc50b35a005434f816e0475312bc808b\n'}, {'number': 3, 'created': '2014-08-14 17:33:42.000000000', 'files': ['openstack/tests/compute/v2/test_server.py', 'openstack/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/fa5b9ffdc2310393ec01d0731c7dd37819c2c610', 'message': 'Various standard server actions\n\nChange-Id: I53d32018cc50b35a005434f816e0475312bc808b\n'}]",3,113056,fa5b9ffdc2310393ec01d0731c7dd37819c2c610,14,3,3,8736,,,0,"Various standard server actions

Change-Id: I53d32018cc50b35a005434f816e0475312bc808b
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/56/113056/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/compute/v2/test_server.py', 'openstack/compute/v2/server.py']",2,69876721988e907ec8e9e1cede68b9e65f3dedad,server_actions,"from openstack import utils def action(self, session, body): """"""Preform server actions given the message body."""""" url = utils.urljoin(self.base_path, self.id, 'action') resp = session.put(url, service=self.service, json=body).body return resp def change_password(self, session, new_password): """"""Change the administrator password to the given password."""""" body = {'changePassword': {'adminPass': new_password}} return self.action(session, body) def reboot(self, session, reboot_type): """"""Reboot server where reboot_type might be 'SOFT' or 'HARD'."""""" body = {'reboot': {'type': reboot_type}} return self.action(session, body) def rebuild(self, session, **kwargs): """"""Rebuild the server with the given arguments. The arguments may be for example: * imageRef * name * adminPass * accessIPv4 * accessIPv6 * metadata * personality """""" body = {'rebuild': kwargs} return self.action(session, body) def resize(self, session, flavor): """"""Resize server to flavor reference."""""" body = {'resize': {'flavorRef': flavor}} return self.action(session, body) def confirm_resize(self, session): """"""Confirm the resize of the server."""""" body = {'confirmResize': None} return self.action(session, body) def revert_resize(self, session): """"""Revert the resize of the server."""""" body = {'revertResize': None} return self.action(session, body) def create_image(self, session, name, metadata): """"""Create image from server."""""" body = {'createImage': {'name': name, 'metadata': metadata}} return self.action(session, body)",,137,0
openstack%2Fopenstacksdk~master~If9cd07fbac6449e13c9cd94f4eb8bef014d7ce0e,openstack/openstacksdk,master,If9cd07fbac6449e13c9cd94f4eb8bef014d7ce0e,compute/v2 server resource,MERGED,2014-08-08 21:26:25.000000000,2014-08-14 20:55:49.000000000,2014-08-14 20:55:49.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-08 21:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0386c7dbcd531e96ef3f878a38275c2b1bd6ac18', 'message': 'compute/v2 server resource\n\nChange-Id: If9cd07fbac6449e13c9cd94f4eb8bef014d7ce0e\n'}, {'number': 2, 'created': '2014-08-14 11:19:10.000000000', 'files': ['openstack/tests/compute/v2/test_server.py', 'openstack/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/cba708365ead4cc13bc40f745d625d3ba6a6998c', 'message': 'compute/v2 server resource\n\nChange-Id: If9cd07fbac6449e13c9cd94f4eb8bef014d7ce0e\n'}]",3,113028,cba708365ead4cc13bc40f745d625d3ba6a6998c,15,3,2,8736,,,0,"compute/v2 server resource

Change-Id: If9cd07fbac6449e13c9cd94f4eb8bef014d7ce0e
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/28/113028/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/compute/v2/test_server.py', 'openstack/compute/v2/server.py']",2,0386c7dbcd531e96ef3f878a38275c2b1bd6ac18,server,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack.compute import compute_service from openstack import resource class Server(resource.Resource): resource_key = 'server' resources_key = 'servers' base_path = '/servers' service = compute_service.ComputeService() # capabilities allow_create = True allow_retrieve = True allow_update = True allow_delete = True allow_list = True # Properties accessIPv4 = resource.prop('accessIPv4') accessIPv6 = resource.prop('accessIPv6') addresses = resource.prop('addresses', type=dict) created = resource.prop('created') flavor = resource.prop('flavor', type=dict) hostId = resource.prop('hostId') image = resource.prop('image', type=dict) links = resource.prop('links') metadata = resource.prop('metadata') name = resource.prop('name') progress = resource.prop('progress', type=int) project_id = resource.prop('tenant_id') status = resource.prop('status') updated = resource.prop('updated') user_id = resource.prop('user_id') ",,114,0
openstack%2Fdiskimage-builder~master~I812fe66b4f1e6c86a9a91d9b07bc97f212c405b8,openstack/diskimage-builder,master,I812fe66b4f1e6c86a9a91d9b07bc97f212c405b8,Ignore comments,ABANDONED,2014-07-21 17:16:41.000000000,2014-08-14 20:55:19.000000000,,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 4190}, {'_account_id': 7471}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 8688}, {'_account_id': 9369}, {'_account_id': 10375}]","[{'number': 1, 'created': '2014-07-21 17:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/40475dec0563b8b291e91b078b56e9143d1303a7', 'message': 'Ignore comments\n\nIgnore lines starting with ""#"" in the package-installs and\npackage-uninstalls scripts to allow for having comments in the read\nfiles.\n\nChange-Id: I812fe66b4f1e6c86a9a91d9b07bc97f212c405b8\n'}, {'number': 2, 'created': '2014-07-21 18:27:06.000000000', 'files': ['elements/package-installs/bin/package-installs', 'elements/package-installs/bin/package-uninstalls'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9c6cba67ef7e35a449012fec5629836a16ad4247', 'message': 'Ignore comments\n\nIgnore lines starting with ""#"" in the package-installs and\npackage-uninstalls scripts to allow for having comments in the read\nfiles.\n\nChange-Id: I812fe66b4f1e6c86a9a91d9b07bc97f212c405b8\n'}]",0,108440,9c6cba67ef7e35a449012fec5629836a16ad4247,20,9,2,7144,,,0,"Ignore comments

Ignore lines starting with ""#"" in the package-installs and
package-uninstalls scripts to allow for having comments in the read
files.

Change-Id: I812fe66b4f1e6c86a9a91d9b07bc97f212c405b8
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/40/108440/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/package-installs/bin/package-installs', 'elements/package-installs/bin/package-uninstalls']",2,40475dec0563b8b291e91b078b56e9143d1303a7,package-installs," # Ignore comments if [ ${pkg:0:1} = ""#"" ]; then continue fi",,8,0
openstack%2Fnova~master~I7e604a408387438105c435ad16a1fa3d6491b642,openstack/nova,master,I7e604a408387438105c435ad16a1fa3d6491b642,Hacking: a new hacking check was added that used an existing number,MERGED,2014-08-14 10:42:55.000000000,2014-08-14 20:51:45.000000000,2014-08-14 20:45:17.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 9578}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-08-14 10:42:55.000000000', 'files': ['nova/hacking/checks.py', 'nova/tests/test_hacking.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/a0a6017f9b58941a4f8e67300a5dc57e34aada35', 'message': 'Hacking: a new hacking check was added that used an existing number\n\nCommit 243879f5c51fc45f03491bcb78765945ddf76be8 added in a new hacking\ncheck that used an existing number.\n\nThe new number is 324 (and not 323)\n\nChange-Id: I7e604a408387438105c435ad16a1fa3d6491b642\nCloses-bug: #1356815\n'}]",0,114195,a0a6017f9b58941a4f8e67300a5dc57e34aada35,12,7,1,1653,,,0,"Hacking: a new hacking check was added that used an existing number

Commit 243879f5c51fc45f03491bcb78765945ddf76be8 added in a new hacking
check that used an existing number.

The new number is 324 (and not 323)

Change-Id: I7e604a408387438105c435ad16a1fa3d6491b642
Closes-bug: #1356815
",git fetch https://review.opendev.org/openstack/nova refs/changes/95/114195/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/hacking/checks.py', 'nova/tests/test_hacking.py', 'HACKING.rst']",3,a0a6017f9b58941a4f8e67300a5dc57e34aada35,update-hacking,- [N324] Ensure that jsonutils.%(fun)s must be used instead of json.%(fun)s,,3,2
openstack%2Ftripleo-ci~master~I4198856fb101f5e77ed9500dcfa8791a4fe0deff,openstack/tripleo-ci,master,I4198856fb101f5e77ed9500dcfa8791a4fe0deff,Remove unneeded CI workarounds,MERGED,2014-08-11 08:57:51.000000000,2014-08-14 20:48:42.000000000,2014-08-14 20:48:41.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 7144}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-08-11 08:57:51.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/82cb0fdf2661e6d10ea100a30b4f1ac51b8ee657', 'message': ""Remove unneeded CI workarounds\n\nRemove the nova temprevert it no longer does anything (conflict) and\ndoesn't appear to be needed any longer. Remove the horizon cherry-pick\na fix for this problem has been merged in\nIe57de8314df08f3353e65ba6a46f186d1d28af90.\n\nChange-Id: I4198856fb101f5e77ed9500dcfa8791a4fe0deff\n""}]",0,113195,82cb0fdf2661e6d10ea100a30b4f1ac51b8ee657,12,4,1,1926,,,0,"Remove unneeded CI workarounds

Remove the nova temprevert it no longer does anything (conflict) and
doesn't appear to be needed any longer. Remove the horizon cherry-pick
a fix for this problem has been merged in
Ie57de8314df08f3353e65ba6a46f186d1d28af90.

Change-Id: I4198856fb101f5e77ed9500dcfa8791a4fe0deff
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/95/113195/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,82cb0fdf2661e6d10ea100a30b4f1ac51b8ee657,rm-workarounds,# temprevert <projectname> <commit-hash-to-revert> <bugnumber>,# https://review.openstack.org/#/c/107511/ (revert fix for scheduler bug) temprevert nova 963ad71af4750e28745b6de262da11816b403801 1342919# Cherry pick in horizon fix for bug https://launchpad.net/bugs/1349774 loc=$(pwd) cd $DIB_REPOLOCATION_horizon git fetch https://review.openstack.org/openstack/horizon refs/changes/55/110755/2 && git cherry-pick FETCH_HEAD cd $loc ,1,8
openstack%2Foslo-incubator~master~I7313c36b41fa92b81432d33290b7efd960e6cca6,openstack/oslo-incubator,master,I7313c36b41fa92b81432d33290b7efd960e6cca6,Make graduate.sh commit filtering more correct,MERGED,2014-07-26 00:04:59.000000000,2014-08-14 20:48:31.000000000,2014-08-14 20:48:31.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1247}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 7763}]","[{'number': 1, 'created': '2014-07-26 00:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/fc76cba214876b08d7b54699c85305b6b928dfb9', 'message': ""Make graduate.sh commit filtering more correct\n\nCurrent version of graduate.sh have a series of drawbacks:\na) it rebases all commits to one straight line, which not only isn't correct\nfrom history pov but also can introduce merge conflicts during rebase\n(suggesting to finish script's work by hand);\nb) it loses Comitter and Commit Date info overwriting it with current user and\nAuthor Date correspondingly;\nc) it runs expensive git-filter-branch 3 times with 3 different filtes while it\ncan handle them all at once.\n\nThis commit introduces following changes:\na) 3 filters are applied by git-filter-branch at once;\nb) proper detection of all roots of files we need to keep (there can be more\nthan one);\nc) keeping all commits along with their merge commits in order they were in\noriginal repo;\nd) as a side effect of doing all dirty work in filter-branch, all metadata in\ncommits is saved, and different runs of the script with the same initial\ndata provide the exact same results (all hashes are the same).\n\nChange-Id: I7313c36b41fa92b81432d33290b7efd960e6cca6\n""}, {'number': 2, 'created': '2014-08-09 07:39:27.000000000', 'files': ['tools/graduate.sh'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/009ed3088628e0a31fd91617f64c220ae8214331', 'message': ""Make graduate.sh commit filtering more correct\n\nCurrent version of graduate.sh have a series of drawbacks:\na) it rebases all commits to one straight line, which not only isn't\ncorrect from history pov but also can introduce merge conflicts during\nrebase (suggesting to finish script's work by hand);\nb) it loses Comitter and Commit Date info overwriting it with Author and\nAuthor Date correspondingly;\nc) it runs expensive git-filter-branch 3 times with 3 different filtes\nwhile it can handle them all at once.\n\nThis commit introduces following changes:\na) 3 filters are applied by git-filter-branch at once;\nb) proper detection of all roots of files we need to keep (there can be\nmore than one);\nc) keeping all commits along with their merge commits in order they were\nin original repo;\nd) as a side effect of doing all dirty work in filter-branch, all\nmetadata in commits is saved, and different runs of the script with the\nsame initial data provide the exact same results (all hashes are the\nsame).\n\nChange-Id: I7313c36b41fa92b81432d33290b7efd960e6cca6\n""}]",2,109779,009ed3088628e0a31fd91617f64c220ae8214331,22,6,2,708,,,0,"Make graduate.sh commit filtering more correct

Current version of graduate.sh have a series of drawbacks:
a) it rebases all commits to one straight line, which not only isn't
correct from history pov but also can introduce merge conflicts during
rebase (suggesting to finish script's work by hand);
b) it loses Comitter and Commit Date info overwriting it with Author and
Author Date correspondingly;
c) it runs expensive git-filter-branch 3 times with 3 different filtes
while it can handle them all at once.

This commit introduces following changes:
a) 3 filters are applied by git-filter-branch at once;
b) proper detection of all roots of files we need to keep (there can be
more than one);
c) keeping all commits along with their merge commits in order they were
in original repo;
d) as a side effect of doing all dirty work in filter-branch, all
metadata in commits is saved, and different runs of the script with the
same initial data provide the exact same results (all hashes are the
same).

Change-Id: I7313c36b41fa92b81432d33290b7efd960e6cca6
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/79/109779/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/graduate.sh'],1,fc76cba214876b08d7b54699c85305b6b928dfb9,graduate-optimization,"# Build the grep pattern for ignoring files that we want to keep# Prune all other files in every commit# Find all first commits with listed files and find a subset of them that # predates all others roots="""" for file in $files_to_keep; do file_root=""$(git rev-list --reverse HEAD -- $file | head -n1)"" fail=0 for root in $roots; do if git merge-base --is-ancestor $root $file_root; then fail=1 break elif !git merge-base --is-ancestor $file_root $root; then new_roots=""$new_roots $root"" fi done if [ $fail -ne 1 ]; then roots=""$new_roots $file_root"" fi done # Purge all parents for those commits set_roots="" if [ '' $(for root in $roots; do echo "" -o \""\$GIT_COMMIT\"" == '$root' ""; done) ]; then echo '' else cat fi"" # Enhance git_commit_non_empty_tree to skip merges with: # a) either two equal parents (commit that was about to land got purged as well # as all commits on mainline); # b) or with second parent being an ancestor to the first one (just as with a) # but when there are some commits on mainline). # In both cases drop second parent and let git_commit_non_empty_tree to decide # if commit worth doing (most likely not). skip_empty=$(cat << \EOF if [ $# = 5 ] && git merge-base --is-ancestor $5 $3; then git_commit_non_empty_tree $1 -p $3 else git_commit_non_empty_tree ""$@"" fi EOF ) git filter-branch --index-filter ""$pruner"" --parent-filter ""$set_roots"" --commit-filter ""$skip_empty"" HEAD","# Build the grep pattern for ignoring files that we want to keep, so # the prune script won't delete them from index.git filter-branch --index-filter ""$pruner"" --prune-empty HEAD # Find the earliest commit earliest_commit=$(git log --format='format:%H' $files_to_keep | tail -1) echo ""Resetting git history to start with $earliest_commit"" git show --quiet $earliest_commit count_commits # Remove the parent of the earliest commit to make it the first one we # will keep echo ""Resetting parent of $earliest_commit ..."" git filter-branch -f --parent-filter \ ""test \$GIT_COMMIT = $earliest_commit && echo '' || cat"" HEAD count_commits # Fix up dates, since we have touched the commits echo ""Fixing committer dates..."" git rebase --committer-date-is-author-date $(git log --format='format:%H' | tail -1) # Fix up committer, since we have touched the commits echo ""Fixing committer name..."" git filter-branch -f --commit-filter \ 'GIT_COMMITTER_NAME=""$GIT_AUTHOR_NAME"" GIT_COMMITTER_EMAIL=""$GIT_AUTHOR_EMAIL"" git commit-tree ""$@""' HEAD",49,28
openstack%2Ftempest~stable%2Fhavana~I69f7ca5ca0e1d9505334f081b7de1f43e6b2f86c,openstack/tempest,stable/havana,I69f7ca5ca0e1d9505334f081b7de1f43e6b2f86c,Removed deprecated command from glance cli,MERGED,2014-08-14 13:03:37.000000000,2014-08-14 20:45:49.000000000,2014-08-14 20:45:48.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1420}, {'_account_id': 7872}, {'_account_id': 9096}, {'_account_id': 9656}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-08-14 13:03:37.000000000', 'files': ['tempest/cli/simple_read_only/test_glance.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d8923e9ff8e047020e6653c0659be5eb1a292ba9', 'message': 'Removed deprecated command from glance cli\n\nMember-add is no longer a command in python-glanceclient and\nshould be removed since it has been deprecated. We are removing\nall the deprecated glance client commands in this patch\nhttps://review.openstack.org/#/c/98862/.\n\nChange-Id: I69f7ca5ca0e1d9505334f081b7de1f43e6b2f86c\n(cherry picked from commit 17889d08bd340a42ea578801414051630c88ee36)\n'}]",0,114240,d8923e9ff8e047020e6653c0659be5eb1a292ba9,11,7,1,5196,,,0,"Removed deprecated command from glance cli

Member-add is no longer a command in python-glanceclient and
should be removed since it has been deprecated. We are removing
all the deprecated glance client commands in this patch
https://review.openstack.org/#/c/98862/.

Change-Id: I69f7ca5ca0e1d9505334f081b7de1f43e6b2f86c
(cherry picked from commit 17889d08bd340a42ea578801414051630c88ee36)
",git fetch https://review.opendev.org/openstack/tempest refs/changes/40/114240/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cli/simple_read_only/test_glance.py'],1,d8923e9ff8e047020e6653c0659be5eb1a292ba9,glance-cli-backport," 'member-create', 'member-delete',"," 'member-add', 'member-create', 'member-delete',",1,1
openstack%2Ftempest~master~Icc37e9f3497fb7bd72f359197663c71abbf16921,openstack/tempest,master,Icc37e9f3497fb7bd72f359197663c71abbf16921,Add console_output compute feature flag,MERGED,2014-07-15 23:45:41.000000000,2014-08-14 20:45:46.000000000,2014-08-14 20:45:45.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1420}, {'_account_id': 5196}, {'_account_id': 7227}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-15 23:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/720665a436597c34cc497e7b35af9bcf392ed483', 'message': 'Add console_output compute feature flag\n\nNot all hypervisors support getting serial console logs.  This adds\na new compute feature flag.  It skips tests that stress this call and\navoids logging console logs to debug if it is not supported.\n\nChange-Id: Icc37e9f3497fb7bd72f359197663c71abbf16921\n'}, {'number': 2, 'created': '2014-08-06 23:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/660c220f79d16a7061e7ead4d50be4cf4e5eed80', 'message': 'Add console_output compute feature flag\n\nNot all hypervisors support getting serial console logs.  This adds\na new compute feature flag.  It skips tests that stress this call and\navoids logging console logs to debug if it is not supported.\n\nChange-Id: Icc37e9f3497fb7bd72f359197663c71abbf16921\n'}, {'number': 3, 'created': '2014-08-12 03:31:50.000000000', 'files': ['tempest/api/compute/v3/servers/test_server_actions.py', 'tempest/api/compute/servers/test_server_actions.py', 'tempest/scenario/manager.py', 'etc/tempest.conf.sample', 'tempest/api/orchestration/stacks/test_neutron_resources.py', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c6eefb4b4a4b779a77efc4c8fb49b919cb64fe42', 'message': 'Add console_output compute feature flag\n\nNot all hypervisors support getting serial console logs.  This adds\na new compute feature flag.  It skips tests that stress this call and\navoids logging console logs to debug if it is not supported.\n\nChange-Id: Icc37e9f3497fb7bd72f359197663c71abbf16921\n'}]",1,107203,c6eefb4b4a4b779a77efc4c8fb49b919cb64fe42,49,9,3,1420,,,0,"Add console_output compute feature flag

Not all hypervisors support getting serial console logs.  This adds
a new compute feature flag.  It skips tests that stress this call and
avoids logging console logs to debug if it is not supported.

Change-Id: Icc37e9f3497fb7bd72f359197663c71abbf16921
",git fetch https://review.opendev.org/openstack/tempest refs/changes/03/107203/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/v3/servers/test_server_actions.py', 'tempest/scenario/manager.py', 'etc/tempest.conf.sample', 'tempest/api/orchestration/stacks/test_neutron_resources.py', 'tempest/config.py']",6,720665a436597c34cc497e7b35af9bcf392ed483,ironic_tempest," cfg.BoolOpt('console_output', default=True, help=""Does the test environment obtaining instance serial "" ""console output?""),",,30,10
openstack%2Fheat~master~Id34b461f5c76187928dd0419d8537e9a6cb6178c,openstack/heat,master,Id34b461f5c76187928dd0419d8537e9a6cb6178c,Implement check for Instance resource,MERGED,2014-04-23 17:53:40.000000000,2014-08-14 20:45:38.000000000,2014-08-14 20:45:37.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4571}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7233}, {'_account_id': 7256}, {'_account_id': 7404}, {'_account_id': 8328}, {'_account_id': 8435}, {'_account_id': 8537}, {'_account_id': 8871}, {'_account_id': 9189}, {'_account_id': 9542}, {'_account_id': 11599}]","[{'number': 1, 'created': '2014-04-23 17:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ef10009183244ed137a8ccab00b0b197954fe3ee', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 2, 'created': '2014-04-23 17:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9433c26b7a98528a2c6a0e8691f7463286ea5f7d', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 3, 'created': '2014-05-05 13:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/58a3b29184f2b5fd168db37fd7426601ed0e00dd', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 4, 'created': '2014-05-05 13:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0181c117479d1f7cc8e2a4475c5bc4cdaa90b618', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 5, 'created': '2014-05-20 01:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0075521fb9602de10831221ada0b470e847636b3', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 6, 'created': '2014-05-27 15:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/abc7ff342cee8f2798c785a99221c3cade4abb84', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 7, 'created': '2014-05-30 14:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d67755ecacae25e578fafd0d0ecd4cb45514f84b', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 8, 'created': '2014-06-10 18:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ed185ffe056b0eb7101d6f6773df48bb8d278a51', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 9, 'created': '2014-06-19 20:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/29cacfb764aff4ee4d525c65fa9a55ea308c33b8', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nCo-Authored-By: Richard Lee <rblee88@gmail.com>\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 10, 'created': '2014-07-08 17:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f0bfea2c779ef458200701ae8246f6cd272d337f', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nCo-Authored-By: Richard Lee <rblee88@gmail.com>\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 11, 'created': '2014-07-22 16:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/45eb351460930e1b18493b68c90b1f7911e2eb14', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nCo-Authored-By: Richard Lee <rblee88@gmail.com>\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 12, 'created': '2014-08-04 14:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/861338a0e3f280eeac70bf7fd8bf9b801fdd7695', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nCo-Authored-By: Richard Lee <rblee88@gmail.com>\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 13, 'created': '2014-08-07 22:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/76174de8e8e3bf4fed47f2651f1f2ee53877817b', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nCo-Authored-By: Richard Lee <rblee88@gmail.com>\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 14, 'created': '2014-08-08 14:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8a396cd1a8800797b369c9e0e37ff8003b185870', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nCo-Authored-By: Richard Lee <rblee88@gmail.com>\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}, {'number': 15, 'created': '2014-08-12 14:58:09.000000000', 'files': ['heat/tests/test_instance.py', 'heat/engine/resources/instance.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ea65aebcdb7c939542e115d971a3936a70dfc69b', 'message': ""Implement check for Instance resource\n\nInstance resource will raise an error if it's not active at the time of\nthe check.\n\nCo-Authored-By: Richard Lee <rblee88@gmail.com>\nImplements: blueprint stack-check (partial)\nChange-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c\n""}]",16,89906,ea65aebcdb7c939542e115d971a3936a70dfc69b,104,17,15,9189,,,0,"Implement check for Instance resource

Instance resource will raise an error if it's not active at the time of
the check.

Co-Authored-By: Richard Lee <rblee88@gmail.com>
Implements: blueprint stack-check (partial)
Change-Id: Id34b461f5c76187928dd0419d8537e9a6cb6178c
",git fetch https://review.opendev.org/openstack/heat refs/changes/06/89906/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_instance.py', 'heat/engine/resources/instance.py']",2,ef10009183244ed137a8ccab00b0b197954fe3ee,bp/stack-check," exc = exception.Error(_(""Server %(server)s "" exc = exception.Error(_(""Server %(server)s failed "" def handle_check(self): server = self.nova().servers.get(self.resource_id) if not self._check_active(server): raise exception.Error(_(""Instance is not ACTIVE (was: %s)"") % server.status.strip()) "," exc = exception.Error(_(""Creation of server %(server)s "" exc = exception.Error(_(""Creation of server %(server)s failed """,18,4
openstack%2Fnova~master~I277dba08fdd30734409eee36008cebda35886968,openstack/nova,master,I277dba08fdd30734409eee36008cebda35886968,Fix hacking check for jsonutils,MERGED,2014-08-14 05:51:02.000000000,2014-08-14 20:45:00.000000000,2014-08-14 20:44:57.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 8412}, {'_account_id': 9578}, {'_account_id': 9656}, {'_account_id': 11069}]","[{'number': 1, 'created': '2014-08-14 05:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c64f4d50fce0d20e3f1f1972546c9c99811af6b', 'message': 'Fix hacking check for jsonutils\n\nHacking checks with logical_lines should use yield not return.\n\nThe jsonutils rule was added in:\nI86ed6cd3316dd4da5e1b10b36a3ddba3739316d3\n\nChange-Id: I277dba08fdd30734409eee36008cebda35886968\nCloses-Bug: #1356687\n'}, {'number': 2, 'created': '2014-08-14 07:22:02.000000000', 'files': ['nova/hacking/checks.py', 'nova/tests/test_hacking.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/42d017c0d498aa4034032104f9cdd56300c866e0', 'message': ""Fix hacking check for jsonutils\n\nHacking checks with logical_lines should use yield not return.\n\nThe jsonutils rule was added in:\nI86ed6cd3316dd4da5e1b10b36a3ddba3739316d3\n\nNow that the function uses yield, it can trigger twice in dumps (dump\nand dump), so look for a '(' at the afterwards. Don't display the '(' at\nthe end of the error message since its confusing to read.\n\nChange-Id: I277dba08fdd30734409eee36008cebda35886968\nCloses-Bug: #1356687\n""}]",0,114125,42d017c0d498aa4034032104f9cdd56300c866e0,19,8,2,1849,,,0,"Fix hacking check for jsonutils

Hacking checks with logical_lines should use yield not return.

The jsonutils rule was added in:
I86ed6cd3316dd4da5e1b10b36a3ddba3739316d3

Now that the function uses yield, it can trigger twice in dumps (dump
and dump), so look for a '(' at the afterwards. Don't display the '(' at
the end of the error message since its confusing to read.

Change-Id: I277dba08fdd30734409eee36008cebda35886968
Closes-Bug: #1356687
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/114125/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/hacking/checks.py'],1,9c64f4d50fce0d20e3f1f1972546c9c99811af6b,bug/1356687," yield (pos, msg % {'fun': f})"," return (pos, msg % {'fun': f})",1,1
openstack%2Fpython-novaclient~master~I1155f67196b5a8393ff53361ac9c63f3f7c23ad0,openstack/python-novaclient,master,I1155f67196b5a8393ff53361ac9c63f3f7c23ad0,Updated from global requirements,MERGED,2014-08-13 23:24:29.000000000,2014-08-14 20:44:54.000000000,2014-08-14 20:44:53.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-08-13 23:24:29.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/9758ffc85dee10f1bfc4bfb1b5691f86d21347e5', 'message': 'Updated from global requirements\n\nChange-Id: I1155f67196b5a8393ff53361ac9c63f3f7c23ad0\n'}]",0,114070,9758ffc85dee10f1bfc4bfb1b5691f86d21347e5,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: I1155f67196b5a8393ff53361ac9c63f3f7c23ad0
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/70/114070/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,9758ffc85dee10f1bfc4bfb1b5691f86d21347e5,openstack/requirements,requests-mock>=0.4.0 # Apache-2.0,requests-mock>=0.4.0,2,2
openstack%2Ftripleo-image-elements~master~Ic1b53d896f2deb23a0f31a7a457eeb20dd38ab5f,openstack/tripleo-image-elements,master,Ic1b53d896f2deb23a0f31a7a457eeb20dd38ab5f,Remove hard-coded ports form ring builder script,MERGED,2014-08-07 02:41:24.000000000,2014-08-14 20:41:58.000000000,2014-08-14 20:41:58.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-08-07 02:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6f17ee571b48aa87ed3f1dc1df6727314826e98d', 'message': 'Remove hard-coded ports form ring builder script\n\nThe swift ring builder script was hard-coded with the default ports.\n\nThe script now reads the ports from the configuration files under\n/etc/swift if bind_port is specified. If bind_port is not specified\nthen the default ports are used.\n\nChange-Id: Ic1b53d896f2deb23a0f31a7a457eeb20dd38ab5f\n'}, {'number': 2, 'created': '2014-08-14 02:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1586c99e1cbbb42a9d48b1ff1a2a5c4c57678b1c', 'message': 'Remove hard-coded ports form ring builder script\n\nThe swift ring builder script was hard-coded with the default ports.\n\nThe script now reads the ports from the configuration files under\n/etc/swift if bind_port is specified. If bind_port is not specified\nthen the default ports are used.\n\nChange-Id: Ic1b53d896f2deb23a0f31a7a457eeb20dd38ab5f\n'}, {'number': 3, 'created': '2014-08-14 04:56:14.000000000', 'files': ['elements/swift/os-refresh-config/configure.d/73-swift'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a3a101267fb69b2019d72f98c6e1e202358a585a', 'message': 'Remove hard-coded ports form ring builder script\n\nThe swift ring builder script was hard-coded with the default ports.\n\nThe script now reads the ports from the configuration files under\n/etc/swift if bind_port is specified. If bind_port is not specified\nthen the default ports are used.\n\nChange-Id: Ic1b53d896f2deb23a0f31a7a457eeb20dd38ab5f\n'}]",3,112455,a3a101267fb69b2019d72f98c6e1e202358a585a,26,4,3,7471,,,0,"Remove hard-coded ports form ring builder script

The swift ring builder script was hard-coded with the default ports.

The script now reads the ports from the configuration files under
/etc/swift if bind_port is specified. If bind_port is not specified
then the default ports are used.

Change-Id: Ic1b53d896f2deb23a0f31a7a457eeb20dd38ab5f
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/55/112455/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/swift/os-refresh-config/configure.d/73-swift'],1,6f17ee571b48aa87ed3f1dc1df6727314826e98d,swift-ring,"set -euxOBJECT_PORT=""6000"" CONTAINER_PORT=""6001"" ACCOUNT_PORT=""6002"" if grep bind_port /etc/swift/object-server.conf; then OBJECT_PORT=$(cat /etc/swift/object-server.conf | awk '/bind_port/ {print $3}') fi if grep bind_port /etc/swift/container-server.conf; then CONTAINER_PORT=$(cat /etc/swift/container-server.conf | awk '/bind_port/ {print $3}') fi if grep bind_port /etc/swift/account-server.conf; then ACCOUNT_PORT=$(cat /etc/swift/account-server.conf | awk '/bind_port/ {print $3}') fi swift-ring-builder /etc/swift/object.builder add ${DEVICE/\%PORT\%/$OBJECT_PORT} 100 swift-ring-builder /etc/swift/container.builder add ${DEVICE/\%PORT\%/$CONTAINER_PORT} 100 swift-ring-builder /etc/swift/account.builder add ${DEVICE/\%PORT\%/$ACCOUNT_PORT} 100",set -eu swift-ring-builder /etc/swift/object.builder add ${DEVICE/\%PORT\%/6000} 100 swift-ring-builder /etc/swift/container.builder add ${DEVICE/\%PORT\%/6001} 100 swift-ring-builder /etc/swift/account.builder add ${DEVICE/\%PORT\%/6002} 100,20,4
openstack%2Ftripleo-incubator~master~I3a9b037ffa9f545a599035b4550f8125ddb62c1a,openstack/tripleo-incubator,master,I3a9b037ffa9f545a599035b4550f8125ddb62c1a,Base decision to use MariaDB on NODE_DIST,MERGED,2014-08-12 15:26:01.000000000,2014-08-14 20:40:12.000000000,2014-08-14 20:40:11.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 6969}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-08-12 15:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/6304c9bc5de32e73050abb924b0d9a4b40795510', 'message': ""Base decision to use MariaDB on NODE_DIST\n\nDon't use TRIPLEO_OS_FAMILY as it is a reference to the distro on which\ndevtest is running not the distro of the images being built.\n\nChange-Id: I3a9b037ffa9f545a599035b4550f8125ddb62c1a\n""}, {'number': 2, 'created': '2014-08-13 15:34:14.000000000', 'files': ['scripts/devtest_variables.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/fccd857ff4aad33b7ae247fa513b73803725b57e', 'message': ""Base decision to use MariaDB on NODE_DIST\n\nDon't use TRIPLEO_OS_FAMILY as it is a reference to the distro on which\ndevtest is running not the distro of the images being built.\n\nChange-Id: I3a9b037ffa9f545a599035b4550f8125ddb62c1a\n""}]",0,113557,fccd857ff4aad33b7ae247fa513b73803725b57e,19,5,2,1926,,,0,"Base decision to use MariaDB on NODE_DIST

Don't use TRIPLEO_OS_FAMILY as it is a reference to the distro on which
devtest is running not the distro of the images being built.

Change-Id: I3a9b037ffa9f545a599035b4550f8125ddb62c1a
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/57/113557/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_variables.sh'],1,6304c9bc5de32e73050abb924b0d9a4b40795510,use-percona,## default on Fedora based distributions because MariaDB packages are included ## directly in distributionif [[ $NODE_DIST =~ .*(fedora|rhel|centos).* ]] ; then,"## default on Fedora because MariaDB packages are included directly in ## distributionif [ ""$TRIPLEO_OS_FAMILY"" = ""redhat"" ]; then",3,3
openstack%2Fcongress~master~If74c0960f1907fe72b02f2fc465c1a3648559cea,openstack/congress,master,If74c0960f1907fe72b02f2fc465c1a3648559cea,Support API errors from data models,MERGED,2014-08-14 03:48:15.000000000,2014-08-14 20:38:37.000000000,2014-08-14 20:38:37.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-08-14 03:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/0f3d135258df14b56c1257b322783ff080e93907', 'message': 'Support API errors from data models\n\nWhile the API framework is designed to provide a level of call\nvalidation (using JSON-Schema), the data model may provide additional\nvalidation that may fail.  In these cases, the data model may throw a\nDataModelException to pass the appropriate response back to the API caller.\n\nChange-Id: If74c0960f1907fe72b02f2fc465c1a3648559cea\nPartial-Bug: #1356619\n'}, {'number': 2, 'created': '2014-08-14 16:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/b17565af01024b3e42c234286479c68d0db4db93', 'message': 'Support API errors from data models\n\nWhile the API framework is designed to provide a level of call\nvalidation (using JSON-Schema), the data model may provide additional\nvalidation that may fail.  In these cases, the data model may throw a\nDataModelException to pass the appropriate response back to the API caller.\n\nChange-Id: If74c0960f1907fe72b02f2fc465c1a3648559cea\nPartial-Bug: #1356619\n'}, {'number': 3, 'created': '2014-08-14 17:17:12.000000000', 'files': ['congress/api/webservice.py', 'congress/api/application.py', 'congress/tests/api/test_application.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/1be15fc58977455f06360b43d57e2c1e8bfae0e4', 'message': 'Support API errors from data models\n\nWhile the API framework is designed to provide a level of call\nvalidation (using JSON-Schema), the data model may provide additional\nvalidation that may fail.  In these cases, the data model may throw a\nDataModelException to pass the appropriate response back to the API caller.\n\nChange-Id: If74c0960f1907fe72b02f2fc465c1a3648559cea\nPartial-Bug: #1356619\n'}]",13,114115,1be15fc58977455f06360b43d57e2c1e8bfae0e4,18,4,3,9253,,,0,"Support API errors from data models

While the API framework is designed to provide a level of call
validation (using JSON-Schema), the data model may provide additional
validation that may fail.  In these cases, the data model may throw a
DataModelException to pass the appropriate response back to the API caller.

Change-Id: If74c0960f1907fe72b02f2fc465c1a3648559cea
Partial-Bug: #1356619
",git fetch https://review.opendev.org/openstack/congress refs/changes/15/114115/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/api/test_webservice.py', 'congress/api/webservice.py']",2,0f3d135258df14b56c1257b322783ff080e93907,," 'description': description,class DataModelException(Exception): """"""Congress API Data Model Exception Custom exception raised by API Data Model methods to communicate errors to the API framework. """""" def __init__(self, error_code, description, data=None, http_status_code=httplib.BAD_REQUEST): super(DataModelException, self).__init__(description) self.error_code = error_code self.description = description self.data = data self.http_status_code = http_status_code def rest_response(self): return error_response(self.http_status_code, self.error_code, self.description, self.data) try: #TODO(pballand): validation if request.method == 'GET' and self.allow_read: return self.read(request) #TODO(pballand): POST for controller semantics elif request.method == 'PUT' and self.allow_replace: return self.replace(request) elif request.method == 'PATCH' and self.allow_update: return self.update(request) elif request.method == 'DELETE' and self.allow_delete: return self.delete(request) return NOT_SUPPORTED_RESPONSE except DataModelException as e: return e.rest_response() try: #TODO(pballand): validation if request.method == 'GET' and self.allow_list: return self.list_members(request) elif request.method == 'POST' and self.allow_create: return self.create_member(request) return NOT_SUPPORTED_RESPONSE except DataModelException as e: return e.rest_response()"," 'descripton': description, #TODO(pballand): validation if request.method == 'GET' and self.allow_read: return self.read(request) #TODO(pballand): POST for controller semantics elif request.method == 'PUT' and self.allow_replace: return self.replace(request) elif request.method == 'PATCH' and self.allow_update: return self.update(request) elif request.method == 'DELETE' and self.allow_delete: return self.delete(request) return NOT_SUPPORTED_RESPONSE #TODO(pballand): validation if request.method == 'GET' and self.allow_list: return self.list_members(request) elif request.method == 'POST' and self.allow_create: return self.create_member(request) return NOT_SUPPORTED_RESPONSE",81,19
openstack%2Fneutron~master~I4f2e375775e511160e4f1b1614e383806a9b6d4d,openstack/neutron,master,I4f2e375775e511160e4f1b1614e383806a9b6d4d,test,ABANDONED,2014-08-14 07:44:00.000000000,2014-08-14 20:25:44.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7715}, {'_account_id': 9681}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-08-14 07:44:00.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7bdce654ab391e8414bb4b9eb705b0f4a0cbc677', 'message': 'test\n\nChange-Id: I4f2e375775e511160e4f1b1614e383806a9b6d4d\n'}]",0,114150,7bdce654ab391e8414bb4b9eb705b0f4a0cbc677,24,15,1,7715,,,0,"test

Change-Id: I4f2e375775e511160e4f1b1614e383806a9b6d4d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/50/114150/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,7bdce654ab391e8414bb4b9eb705b0f4a0cbc677,test,test,,1,0
openstack%2Foslo.messaging~master~Id54ca1f448f466304b72b1695a5c646311bbd453,openstack/oslo.messaging,master,Id54ca1f448f466304b72b1695a5c646311bbd453,Make tests pass with random python hashseed,MERGED,2014-08-13 23:26:38.000000000,2014-08-14 20:21:21.000000000,2014-08-14 20:21:20.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 7763}]","[{'number': 1, 'created': '2014-08-13 23:26:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2e541f2e44167ecab46f5d026ffcaccc603b78ef', 'message': 'Make tests pass with random python hashseed.\n\nUnder python3 and latest tox a random python hashseed is used. Currently\noslo.messaging tests do not pass this because one test assumes the\nresulting list conversion from a list of lists has a specific order.\nSort both lists so that the order is explicit when checking for equality\nin this test. Doing so makes the test pass with a random python hash\nseed.\n\nNote I am not actually familiar enough with oslo.messaging to know if\nthis failure is correct and the drivers or something deeper should be\nreturning lists with an explicit order. This would be the case if order\nin these lists is important.\n\nChange-Id: Id54ca1f448f466304b72b1695a5c646311bbd453\n'}, {'number': 2, 'created': '2014-08-14 00:56:59.000000000', 'files': ['tests/notify/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/220ccb816c75fe72f32a3112dae0b3c0790645fe', 'message': 'Make tests pass with random python hashseed\n\nUnder python3 and latest tox a random python hashseed is used. Currently\noslo.messaging tests do not pass this because one test assumes the\nresulting list conversion from a list of lists has a specific order.\nSort both lists so that the order is explicit when checking for equality\nin this test. Doing so makes the test pass with a random python hash\nseed.\n\nNote I am not actually familiar enough with oslo.messaging to know if\nthis failure is correct and the drivers or something deeper should be\nreturning lists with an explicit order. This would be the case if order\nin these lists is important.\n\nChange-Id: Id54ca1f448f466304b72b1695a5c646311bbd453\n'}]",0,114079,220ccb816c75fe72f32a3112dae0b3c0790645fe,13,6,2,4146,,,0,"Make tests pass with random python hashseed

Under python3 and latest tox a random python hashseed is used. Currently
oslo.messaging tests do not pass this because one test assumes the
resulting list conversion from a list of lists has a specific order.
Sort both lists so that the order is explicit when checking for equality
in this test. Doing so makes the test pass with a random python hash
seed.

Note I am not actually familiar enough with oslo.messaging to know if
this failure is correct and the drivers or something deeper should be
returning lists with an explicit order. This would be the case if order
in these lists is important.

Change-Id: Id54ca1f448f466304b72b1695a5c646311bbd453
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/79/114079/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/notify/test_notifier.py'],1,2e541f2e44167ecab46f5d026ffcaccc603b78ef,random-hashseed-safety," self.assertEqual(sorted(['rpc', 'foo']), sorted(pm.map.call_args[0][6]))"," self.assertEqual(['rpc', 'foo'], pm.map.call_args[0][6])",2,1
openstack%2Frequirements~master~I3d0abe8deabbad237bd3858c68654d047675e679,openstack/requirements,master,I3d0abe8deabbad237bd3858c68654d047675e679,Set a minimum version for python-ironicclient,MERGED,2014-08-12 14:43:25.000000000,2014-08-14 20:21:18.000000000,2014-08-14 20:21:17.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7680}, {'_account_id': 10239}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-08-12 14:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/92673c9e1c0bdd3141718af272e11321c0694ecc', 'message': 'Set a minimum version for python-ironicclient\n\nPython-ironicclient has no min version currently.\nThis sets the minimum version to the latest minor release version, 0.2.0\n\nChange-Id: I3d0abe8deabbad237bd3858c68654d047675e679\n'}, {'number': 2, 'created': '2014-08-12 14:52:02.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d1978a33494650c8be0494c5e885a1139a800d72', 'message': 'Set a minimum version for python-ironicclient\n\nPython-ironicclient has no min version currently.  This sets the minimum\nversion to the current version, which contains bug fixes critical to the\nperformance of the nova driver.\n\nChange-Id: I3d0abe8deabbad237bd3858c68654d047675e679\n'}]",0,113542,d1978a33494650c8be0494c5e885a1139a800d72,15,5,2,2889,,,0,"Set a minimum version for python-ironicclient

Python-ironicclient has no min version currently.  This sets the minimum
version to the current version, which contains bug fixes critical to the
performance of the nova driver.

Change-Id: I3d0abe8deabbad237bd3858c68654d047675e679
",git fetch https://review.opendev.org/openstack/requirements refs/changes/42/113542/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,92673c9e1c0bdd3141718af272e11321c0694ecc,ironicclient-version,python-ironicclient>=0.2.0,python-ironicclient,1,1
openstack%2Foslo.vmware~master~I8e428169e1593beca379a2273d82b1e55e5260d5,openstack/oslo.vmware,master,I8e428169e1593beca379a2273d82b1e55e5260d5,Imported Translations from Transifex,MERGED,2014-08-13 06:08:28.000000000,2014-08-14 20:21:08.000000000,2014-08-14 20:21:07.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-08-13 06:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/cea7be67095e66f3542f025222a41d1ad773de6c', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8e428169e1593beca379a2273d82b1e55e5260d5\n'}, {'number': 2, 'created': '2014-08-14 06:08:29.000000000', 'files': ['oslo.vmware/locale/oslo.vmware.pot'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/d33c19550860291859ffabd74c0148f60d1be196', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8e428169e1593beca379a2273d82b1e55e5260d5\n'}]",0,113785,d33c19550860291859ffabd74c0148f60d1be196,10,2,2,11131,,,0,"Imported Translations from Transifex

Change-Id: I8e428169e1593beca379a2273d82b1e55e5260d5
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/85/113785/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo.vmware/locale/oslo.vmware.pot'],1,cea7be67095e66f3542f025222a41d1ad773de6c,transifex/translations,"""Project-Id-Version: oslo.vmware 0.5.0.2.g81beebb\n""""POT-Creation-Date: 2014-08-13 06:08+0000\n""#: oslo/vmware/api.py:313#: oslo/vmware/api.py:416#: oslo/vmware/api.py:470#: oslo/vmware/api.py:477#: oslo/vmware/objects/datastore.py:31 msgid ""Datastore name cannot be None"" msgstr """" #: oslo/vmware/objects/datastore.py:33 msgid ""Datastore reference cannot be None"" msgstr """" #: oslo/vmware/objects/datastore.py:35 msgid ""Invalid capacity"" msgstr """" #: oslo/vmware/objects/datastore.py:38 msgid ""Capacity is smaller than free space"" msgstr """" #: oslo/vmware/objects/datastore.py:98 msgid ""Datastore name cannot be empty"" msgstr """" #: oslo/vmware/objects/datastore.py:103 oslo/vmware/objects/datastore.py:144 msgid ""Path component cannot be None"" msgstr """" #: oslo/vmware/objects/datastore.py:157 msgid ""Datastore path cannot be empty"" msgstr """" ","""Project-Id-Version: oslo.vmware 0.4.0.3.g1dc80c7\n""""POT-Creation-Date: 2014-07-14 06:00+0000\n""#: oslo/vmware/api.py:306#: oslo/vmware/api.py:409#: oslo/vmware/api.py:463#: oslo/vmware/api.py:470",34,6
openstack%2Fnova~master~I17f15852c098af88afd270084c62eb87693c60d4,openstack/nova,master,I17f15852c098af88afd270084c62eb87693c60d4,Fix live-migration failure in FC multipath case,MERGED,2014-06-09 10:49:20.000000000,2014-08-14 20:16:24.000000000,2014-08-14 10:25:59.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 6491}, {'_account_id': 6896}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9466}, {'_account_id': 9578}, {'_account_id': 9924}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10628}]","[{'number': 1, 'created': '2014-06-09 10:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/442425ad5b480adedbebb439386a0a33f709168d', 'message': 'Use multipath_id properly so that live-migration of VM with multipath FC\naccess to volumes can succeed\n\nCurrently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is used to\naccess multipath FC volumes by Compute Node and multipath_id in\nconnnection_info is not maintained properly and may be lost during connection\nrefreshing.\n\nThis implementation will make source Compute Node and destination Compute Node\nfail to disconnect/connect to volumes properly and result in live-migration\nfailure.\n\nTo fix it, like iSCSI multipath, use /dev/mapper/<multipath_id> instead of\n/dev/dm-<NUM> to access multipath devices. And add logic to preserve the\nunique (across Compute Nodes) multipath_id.\n\nChange-Id: I17f15852c098af88afd270084c62eb87693c60d4\nCloses-Bug: #1327497\n'}, {'number': 2, 'created': '2014-06-09 14:19:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/531f32639b294aaac8ebca80fe5f6887ea261305', 'message': 'Fix live-migration failure in FC multipath case\n\nCurrently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is\nused to access multipath FC volumes by Compute Node and\nmultipath_id in connnection_info is not maintained properly and\nmay be lost during connection refreshing.\n\nThis implementation will make source Compute Node and destination\nCompute Node fail to disconnect/connect to volumes properly and\nresult in live-migration failure.\n\nTo fix it, like iSCSI multipath, use /dev/mapper/<multipath_id>\ninstead of /dev/dm-<NUM> to access multipath devices. And add logic\nto preserve the unique (across Compute Nodes) multipath_id.\n\nChange-Id: I17f15852c098af88afd270084c62eb87693c60d4\nCloses-Bug: #1327497\n'}, {'number': 3, 'created': '2014-06-22 03:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4cc3d92b57e96b041299727f4d7f4067fdfcb74', 'message': 'Fix live-migration failure in FC multipath case\n\nCurrently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is\nused to access multipath FC volumes by Compute Node and\nmultipath_id in connnection_info is not maintained properly and\nmay be lost during connection refreshing.\n\nThis implementation will make source Compute Node and destination\nCompute Node fail to disconnect/connect to volumes properly and\nresult in live-migration failure.\n\nTo fix it, /dev/mapper<multipath_id> will be used instead of\n/dev/dm-<NUM> to access multipath devices, just like iSCSI multipath\nimplementation, and logic to preserve the unique (across Compute\nNodes) multipath_id is also added.\n\nChange-Id: I17f15852c098af88afd270084c62eb87693c60d4\nCloses-Bug: #1327497\n'}, {'number': 4, 'created': '2014-06-29 14:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e56a043f552e3397a8503d6b55162880b44952c7', 'message': 'Fix live-migration failure in FC multipath case\n\nCurrently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is\nused to access multipath FC volumes by Compute Node and\nmultipath_id in connection_info is not maintained properly and\nmay be lost during connection refreshing.\n\nThis implementation will make source Compute Node and destination\nCompute Node fail to disconnect/connect to volumes properly and\nresult in live-migration failure.\n\nTo fix it, /dev/mapper<multipath_id> will be used instead of\n/dev/dm-<NUM> to access multipath devices, just like iSCSI multipath\nimplementation, and logic to preserve the unique (across Compute\nNodes) multipath_id is also added.\n\nChange-Id: I17f15852c098af88afd270084c62eb87693c60d4\nCloses-Bug: #1327497\n'}, {'number': 5, 'created': '2014-06-30 04:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9dec6fdb2deb5584736d9eb3dda9286cdd36e8e', 'message': 'Fix live-migration failure in FC multipath case\n\nCurrently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is\nused to access multipath FC volumes by Compute Node and\nmultipath_id in connection_info is not maintained properly and\nmay be lost during connection refreshing.\n\nThis implementation will make source Compute Node and destination\nCompute Node fail to disconnect/connect to volumes properly and\nresult in live-migration failure.\n\nTo fix it, /dev/mapper<multipath_id> will be used instead of\n/dev/dm-<NUM> to access multipath devices, just like iSCSI multipath\nimplementation, and logic to preserve the unique (across Compute\nNodes) multipath_id is also added.\n\nChange-Id: I17f15852c098af88afd270084c62eb87693c60d4\nCloses-Bug: #1327497\n'}, {'number': 6, 'created': '2014-07-03 02:25:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba2adedae9dc397cb9607b4d1ed589765771b6bb', 'message': 'Fix live-migration failure in FC multipath case\n\nCurrently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is\nused to access multipath FC volumes by Compute Node and\nmultipath_id in connection_info is not maintained properly and\nmay be lost during connection refreshing.\n\nThis implementation will make source Compute Node and destination\nCompute Node fail to disconnect/connect to volumes properly and\nresult in live-migration failure.\n\nTo fix it, /dev/mapper<multipath_id> will be used instead of\n/dev/dm-<NUM> to access multipath devices, just like iSCSI multipath\nimplementation, and logic to preserve the unique (across Compute\nNodes) multipath_id is also added.\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: I17f15852c098af88afd270084c62eb87693c60d4\nCloses-Bug: #1327497\n'}, {'number': 7, 'created': '2014-07-15 17:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10e6c4f19a7c14338e586ee2d17ac7fbf5a4c025', 'message': 'Fix live-migration failure in FC multipath case\n\nCurrently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is\nused to access multipath FC volumes by Compute Node and\nmultipath_id in connection_info is not maintained properly and\nmay be lost during connection refreshing.\n\nThis implementation will make source Compute Node and destination\nCompute Node fail to disconnect/connect to volumes properly and\nresult in live-migration failure.\n\nTo fix it, /dev/mapper<multipath_id> will be used instead of\n/dev/dm-<NUM> to access multipath devices, just like iSCSI multipath\nimplementation, and logic to preserve the unique (across Compute\nNodes) multipath_id is also added.\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: I17f15852c098af88afd270084c62eb87693c60d4\nCloses-Bug: #1327497\n'}, {'number': 8, 'created': '2014-07-21 06:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9668676ad83b3daa15ac87c5c114764e9f36f324', 'message': 'Fix live-migration failure in FC multipath case\n\nCurrently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is\nused to access multipath FC volumes by Compute Node and\nmultipath_id in connection_info is not maintained properly and\nmay be lost during connection refreshing.\n\nThis implementation will make source Compute Node and destination\nCompute Node fail to disconnect/connect to volumes properly and\nresult in live-migration failure.\n\nTo fix it, /dev/mapper<multipath_id> will be used instead of\n/dev/dm-<NUM> to access multipath devices, just like iSCSI multipath\nimplementation, and logic to preserve the unique (across Compute\nNodes) multipath_id is also added.\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: I17f15852c098af88afd270084c62eb87693c60d4\nCloses-Bug: #1327497\n'}, {'number': 9, 'created': '2014-07-31 04:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/152ee9b4d0a6f06a16cdf92de9a65127f4d8338b', 'message': 'Fix live-migration failure in FC multipath case\n\nCurrently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is\nused to access multipath FC volumes by Compute Node and\nmultipath_id in connection_info is not maintained properly and\nmay be lost during connection refreshing.\n\nThis implementation will make source Compute Node and destination\nCompute Node fail to disconnect/connect to volumes properly and\nresult in live-migration failure.\n\nTo fix it, /dev/mapper<multipath_id> will be used instead of\n/dev/dm-<NUM> to access multipath devices, just like iSCSI multipath\nimplementation, and logic to preserve the unique (across Compute\nNodes) multipath_id is also added.\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: I17f15852c098af88afd270084c62eb87693c60d4\nCloses-Bug: #1327497\n'}, {'number': 10, 'created': '2014-08-08 16:04:23.000000000', 'files': ['nova/tests/test_linuxscsi.py', 'nova/storage/linuxscsi.py', 'nova/tests/virt/test_block_device.py', 'nova/virt/libvirt/volume.py', 'nova/compute/manager.py', 'nova/tests/virt/libvirt/test_volume.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3ea14e8a70a946dbb162ecafa848e4f2fa29772a', 'message': 'Fix live-migration failure in FC multipath case\n\nCurrently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is\nused to access multipath FC volumes by Compute Node and\nmultipath_id in connection_info is not maintained properly and\nmay be lost during connection refreshing.\n\nThis implementation will make source Compute Node and destination\nCompute Node fail to disconnect/connect to volumes properly and\nresult in live-migration failure.\n\nTo fix it, /dev/mapper<multipath_id> will be used instead of\n/dev/dm-<NUM> to access multipath devices, just like iSCSI multipath\nimplementation, and logic to preserve the unique (across Compute\nNodes) multipath_id is also added.\n\nChange-Id: I17f15852c098af88afd270084c62eb87693c60d4\nCloses-Bug: #1327497\n'}]",30,98738,3ea14e8a70a946dbb162ecafa848e4f2fa29772a,138,21,10,9924,,,0,"Fix live-migration failure in FC multipath case

Currently, /dev/dm-<NUM> instead of /dev/mapper/<multipath_id> is
used to access multipath FC volumes by Compute Node and
multipath_id in connection_info is not maintained properly and
may be lost during connection refreshing.

This implementation will make source Compute Node and destination
Compute Node fail to disconnect/connect to volumes properly and
result in live-migration failure.

To fix it, /dev/mapper<multipath_id> will be used instead of
/dev/dm-<NUM> to access multipath devices, just like iSCSI multipath
implementation, and logic to preserve the unique (across Compute
Nodes) multipath_id is also added.

Change-Id: I17f15852c098af88afd270084c62eb87693c60d4
Closes-Bug: #1327497
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/98738/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/storage/linuxscsi.py', 'nova/virt/libvirt/config.py', 'nova/virt/libvirt/volume.py', 'nova/virt/block_device.py']",5,442425ad5b480adedbebb439386a0a33f709168d,bug/1327497," if self['connection_info'] and 'data' in self['connection_info']: if 'multipath_id' in self['connection_info']['data']: connection_info['data']['multipath_id'] =\ self['connection_info']['data']['multipath_id'] LOG.info(_('preserve multipath_id %s'), connection_info['data']['multipath_id']) if self['connection_info'] and 'data' in self['connection_info']: if 'multipath_id' in self['connection_info']['data']: connection_info['data']['multipath_id'] =\ self['connection_info']['data']['multipath_id'] LOG.info(_('preserve multipath_id %s'), connection_info['data']['multipath_id'])",,34,3
openstack%2Fneutron~master~I39614c7ea2a7dcc35bf969c90045adc5926ea9df,openstack/neutron,master,I39614c7ea2a7dcc35bf969c90045adc5926ea9df,Preserve link local IP allocations for DVR fip ns across restart,MERGED,2014-07-25 04:06:34.000000000,2014-08-14 20:12:04.000000000,2014-08-14 20:12:03.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 6876}, {'_account_id': 7448}, {'_account_id': 9077}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 12524}]","[{'number': 1, 'created': '2014-07-25 04:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a482c0467458a987d41b285e7250286dce1f38a3', 'message': 'Preserve link local IP allocations for DVR fip ns across restart\n\nThe L3 agent allocates link local address pairs used in connecting the\nrouters to the floating ip namespace.  When those allocations are\nforgetten by restarting the L3 agent they all get rewired on restart.\nThis change preserves the allocations using a file in the local file\nsystem.  Storing them in the database would be overkill and would\naffect system performance.\n\nChange-Id: I39614c7ea2a7dcc35bf969c90045adc5926ea9df\nCloses-Bug: #1348306\nPartially-Implements: blueprint neutron-ovs-dvr\n'}, {'number': 2, 'created': '2014-07-25 18:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1afea2bb767c8982a6080036212e81d897d3172d', 'message': 'Preserve link local IP allocations for DVR fip ns across restart\n\nThe L3 agent allocates link local address pairs used in connecting the\nrouters to the floating ip namespace.  When those allocations are\nforgetten by restarting the L3 agent they all get rewired on restart.\nThis change preserves the allocations using a file in the local file\nsystem.  Storing them in the database would be overkill and would\naffect system performance.\n\nChange-Id: I39614c7ea2a7dcc35bf969c90045adc5926ea9df\nCloses-Bug: #1348306\nPartially-Implements: blueprint neutron-ovs-dvr\nCo-Authored-By: Rajeev Grover <rajeev.grover@hp.com>\n'}, {'number': 3, 'created': '2014-07-31 03:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8435d523d25fd8671877ee22163fd79cf4cc5115', 'message': 'Preserve link local IP allocations for DVR fip ns across restart\n\nThe L3 agent allocates link local address pairs used in connecting the\nrouters to the floating ip namespace.  When those allocations are\nforgetten by restarting the L3 agent they all get rewired on restart.\nThis change preserves the allocations using a file in the local file\nsystem.  Storing them in the database would be overkill and would\naffect system performance.\n\nChange-Id: I39614c7ea2a7dcc35bf969c90045adc5926ea9df\nCloses-Bug: #1348306\nPartially-Implements: blueprint neutron-ovs-dvr\nCo-Authored-By: Rajeev Grover <rajeev.grover@hp.com>\n'}, {'number': 4, 'created': '2014-08-04 16:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eadad0f56107dd3a50cc295f9ee879420f437e6f', 'message': 'Preserve link local IP allocations for DVR fip ns across restart\n\nThe L3 agent allocates link local address pairs used in connecting the\nrouters to the floating ip namespace.  When those allocations are\nforgetten by restarting the L3 agent they all get rewired on restart.\nThis change preserves the allocations using a file in the local file\nsystem.  Storing them in the database would be overkill and would\naffect system performance.\n\nChange-Id: I39614c7ea2a7dcc35bf969c90045adc5926ea9df\nCloses-Bug: #1348306\nPartially-Implements: blueprint neutron-ovs-dvr\nCo-Authored-By: Rajeev Grover <rajeev.grover@hp.com>\n'}, {'number': 5, 'created': '2014-08-04 18:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c048c63012f7193e1e205f8f29cc387f3095078', 'message': 'Preserve link local IP allocations for DVR fip ns across restart\n\nThe L3 agent allocates link local address pairs used in connecting the\nrouters to the floating ip namespace.  When those allocations are\nforgetten by restarting the L3 agent they all get rewired on restart.\nThis change preserves the allocations using a file in the local file\nsystem.  Storing them in the database would be overkill and would\naffect system performance.\n\nChange-Id: I39614c7ea2a7dcc35bf969c90045adc5926ea9df\nCloses-Bug: #1348306\nPartially-Implements: blueprint neutron-ovs-dvr\nCo-Authored-By: Rajeev Grover <rajeev.grover@hp.com>\n'}, {'number': 6, 'created': '2014-08-05 19:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/123934f95b3db2dfc8dd4dd231e1c34defb6437b', 'message': 'Preserve link local IP allocations for DVR fip ns across restart\n\nThe L3 agent allocates link local address pairs used in connecting the\nrouters to the floating ip namespace.  When those allocations are\nforgetten by restarting the L3 agent they all get rewired on restart.\nThis change preserves the allocations using a file in the local file\nsystem.  Storing them in the database would be overkill and would\naffect system performance.\n\nChange-Id: I39614c7ea2a7dcc35bf969c90045adc5926ea9df\nCloses-Bug: #1348306\nPartially-Implements: blueprint neutron-ovs-dvr\nCo-Authored-By: Rajeev Grover <rajeev.grover@hp.com>\n'}, {'number': 7, 'created': '2014-08-12 16:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69ecc53df86e078056f2f9b0084a0e970938bbbe', 'message': 'Preserve link local IP allocations for DVR fip ns across restart\n\nThe L3 agent allocates link local address pairs used in connecting the\nrouters to the floating ip namespace.  When those allocations are\nforgetten by restarting the L3 agent they all get rewired on restart.\nThis change preserves the allocations using a file in the local file\nsystem.  Storing them in the database would be overkill and would\naffect system performance.\n\nChange-Id: I39614c7ea2a7dcc35bf969c90045adc5926ea9df\nCloses-Bug: #1348306\nPartially-Implements: blueprint neutron-ovs-dvr\nCo-Authored-By: Rajeev Grover <rajeev.grover@hp.com>\n'}, {'number': 8, 'created': '2014-08-12 20:37:19.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/tests/unit/services/firewall/agents/varmour/test_varmour_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c3c9f580393aea658571b00b3afd0b729dffe89b', 'message': 'Preserve link local IP allocations for DVR fip ns across restart\n\nThe L3 agent allocates link local address pairs used in connecting the\nrouters to the floating ip namespace.  When those allocations are\nforgetten by restarting the L3 agent they all get rewired on restart.\nThis change preserves the allocations using a file in the local file\nsystem.  Storing them in the database would be overkill and would\naffect system performance.\n\nChange-Id: I39614c7ea2a7dcc35bf969c90045adc5926ea9df\nCloses-Bug: #1348306\nPartially-Implements: blueprint neutron-ovs-dvr\nCo-Authored-By: Rajeev Grover <rajeev.grover@hp.com>\n'}]",13,109486,c3c9f580393aea658571b00b3afd0b729dffe89b,195,28,8,7448,,,0,"Preserve link local IP allocations for DVR fip ns across restart

The L3 agent allocates link local address pairs used in connecting the
routers to the floating ip namespace.  When those allocations are
forgetten by restarting the L3 agent they all get rewired on restart.
This change preserves the allocations using a file in the local file
system.  Storing them in the database would be overkill and would
affect system performance.

Change-Id: I39614c7ea2a7dcc35bf969c90045adc5926ea9df
Closes-Bug: #1348306
Partially-Implements: blueprint neutron-ovs-dvr
Co-Authored-By: Rajeev Grover <rajeev.grover@hp.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/86/109486/8 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3_agent.py'],1,a482c0467458a987d41b285e7250286dce1f38a3,bp/neutron-ovs-dvr,"FIP_LL_SUBNET = '169.254.30.0/23' # Linklocal subnet for router and floating IP namespace link self.rtr_fip_subnet = None ipn = netaddr.IPNetwork(FIP_LL_SUBNET) self.local_subnets = set(ipn.subnet(31)) def get_rtr_int_device_ip(self, subnet): return netaddr.IPNetwork(""%s/%s"" % (subnet.network, subnet.prefixlen)) def get_fip_int_device_ip(self, subnet): return netaddr.IPNetwork(""%s/%s"" % (subnet.broadcast, subnet.prefixlen)) if ri.rtr_fip_subnet is None: ri.rtr_fip_subnet = self.local_subnets.pop() rtr_2_fip = self.get_rtr_int_device_ip(ri.rtr_fip_subnet) fip_2_rtr = self.get_fip_int_device_ip(ri.rtr_fip_subnet) self.internal_ns_interface_added(str(rtr_2_fip), self.internal_ns_interface_added(str(fip_2_rtr), device.route.add_gateway(str(fip_2_rtr.ip), table=FIP_RT_TBL) rtr_2_fip = self.get_rtr_int_device_ip(ri.rtr_fip_subnet) device.route.add_route(fip_cidr, str(rtr_2_fip.ip)) rtr_2_fip = self.get_rtr_int_device_ip(ri.rtr_fip_subnet) fip_2_rtr = self.get_fip_int_device_ip(ri.rtr_fip_subnet) device.route.delete_route(fip_cidr, str(rtr_2_fip.ip)) device.route.delete_gateway(str(fip_2_rtr.ip), table=FIP_RT_TBL) self.local_subnets.add(ri.rtr_fip_subnet) ri.rtr_fip_subnet = None","FIP_LL_PREFIX = '169.254.30.' # Linklocal router to floating IP addr self.rtr_2_fip = None # Linklocal floating to router IP addr self.fip_2_rtr = None self.local_ips = set(range(2, 251)) if ri.rtr_2_fip is None: ri.rtr_2_fip = FIP_LL_PREFIX + str(self.local_ips.pop()) if ri.fip_2_rtr is None: ri.fip_2_rtr = FIP_LL_PREFIX + str(self.local_ips.pop()) self.internal_ns_interface_added(ri.rtr_2_fip + '/31', self.internal_ns_interface_added(ri.fip_2_rtr + '/31', device.route.add_gateway(ri.fip_2_rtr, table=FIP_RT_TBL) device.route.add_route(fip_cidr, ri.rtr_2_fip) device.route.delete_route(fip_cidr, ri.rtr_2_fip) device.route.delete_gateway(ri.fip_2_rtr, table=FIP_RT_TBL) self.local_ips.add(ri.rtr_2_fip.rsplit('.', 1)[1]) ri.rtr_2_fip = None self.local_ips.add(ri.fip_2_rtr.rsplit('.', 1)[1]) ri.fip_2_rtr = None",28,20
openstack%2Fneutron~master~I48b5c0530c413402bc87b12dbd9364ffe0a955b9,openstack/neutron,master,I48b5c0530c413402bc87b12dbd9364ffe0a955b9,Add extra gettextutils methods to flake8 builtins,ABANDONED,2014-08-14 07:20:33.000000000,2014-08-14 20:02:37.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-08-14 07:20:33.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e38793641a71ef5af008deb898b0abd172783c1e', 'message': ""Add extra gettextutils methods to flake8 builtins\n\nThe translations offer more functions to be used\nin logging calls.[1] These need to be added to the\nflake8 builtins so pep8 checks don't fail when\npeople try to use them.\n\n1. (https://github.com/openstack/neutron/blob/\n    8b89667fcd7132df4954014f2bfb66412df3e4c6/\n    neutron/openstack/common/gettextutils.py#L133)\n\nChange-Id: I48b5c0530c413402bc87b12dbd9364ffe0a955b9\n""}]",0,114147,e38793641a71ef5af008deb898b0abd172783c1e,18,14,1,7787,,,0,"Add extra gettextutils methods to flake8 builtins

The translations offer more functions to be used
in logging calls.[1] These need to be added to the
flake8 builtins so pep8 checks don't fail when
people try to use them.

1. (https://github.com/openstack/neutron/blob/
    8b89667fcd7132df4954014f2bfb66412df3e4c6/
    neutron/openstack/common/gettextutils.py#L133)

Change-Id: I48b5c0530c413402bc87b12dbd9364ffe0a955b9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/47/114147/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e38793641a71ef5af008deb898b0abd172783c1e,allow_more_translation_functions,"builtins = _,_LI,_LW,_LE,_LC",builtins = _,1,1
openstack%2Fbarbican~master~I84693a65c6e6b44cb81973590ff8c62f28c0b068,openstack/barbican,master,I84693a65c6e6b44cb81973590ff8c62f28c0b068,Refactor secret_store for consistency,MERGED,2014-08-12 14:05:47.000000000,2014-08-14 20:00:32.000000000,2014-08-14 20:00:32.000000000,"[{'_account_id': 3}, {'_account_id': 1091}, {'_account_id': 7789}, {'_account_id': 7874}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-08-12 14:05:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/de2dc7ecb2a26b87e53204ec337a1c27a62bf584', 'message': 'Refactor secret_store for cosistency\n\nMostly re-arranged the code a bit, so that for...else... statements are\nused in a more consistent way.\n\nChange-Id: I84693a65c6e6b44cb81973590ff8c62f28c0b068\n'}, {'number': 2, 'created': '2014-08-12 15:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/104f5814d4b5e6cf4fda60af73bb05d3dc3961f2', 'message': 'Refactor secret_store for consistency\n\nMostly re-arranged the code a bit, so that for...else... Statements are\nused in a more consistent way.\n\nChange-Id: I84693a65c6e6b44cb81973590ff8c62f28c0b068\n'}, {'number': 3, 'created': '2014-08-12 15:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/44791ccd6eda8b2013d278b7dad7be41d34d3fad', 'message': 'Refactor secret_store for consistency\n\nMostly re-arranged the code a bit, so that for...else... Statements are\nused in a more consistent way.\n\nChange-Id: I84693a65c6e6b44cb81973590ff8c62f28c0b068\n'}, {'number': 4, 'created': '2014-08-12 15:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/70d198ac6d27a47f2c96f0047ebbf7e3b0360cc7', 'message': 'Refactor secret_store for consistency\n\nMostly re-arranged the code a bit, so that for...else... Statements are\nused in a more consistent way.\n\nChange-Id: I84693a65c6e6b44cb81973590ff8c62f28c0b068\n'}, {'number': 5, 'created': '2014-08-13 07:17:48.000000000', 'files': ['barbican/tests/plugin/interface/test_secret_store.py', 'barbican/plugin/interface/secret_store.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/b14590de56875339c684454bf343a4bbf67953ea', 'message': 'Refactor secret_store for consistency\n\nMostly re-arranged the code a bit, so that for...else... Statements are\nused in a more consistent way. On the other, the exception\nSecretStorePluginsNotConfigured was introduced to more properly reflect\nthe occations where the plugins have not been configured correctly.\n\nChange-Id: I84693a65c6e6b44cb81973590ff8c62f28c0b068\n'}]",27,113531,b14590de56875339c684454bf343a4bbf67953ea,37,9,5,10873,,,0,"Refactor secret_store for consistency

Mostly re-arranged the code a bit, so that for...else... Statements are
used in a more consistent way. On the other, the exception
SecretStorePluginsNotConfigured was introduced to more properly reflect
the occations where the plugins have not been configured correctly.

Change-Id: I84693a65c6e6b44cb81973590ff8c62f28c0b068
",git fetch https://review.opendev.org/openstack/barbican refs/changes/31/113531/5 && git format-patch -1 --stdout FETCH_HEAD,['barbican/plugin/interface/secret_store.py'],1,de2dc7ecb2a26b87e53204ec337a1c27a62bf584,secret_store_consistency, else: raise SecretStoreSupportedPluginNotFound() return ext.obj return ext.obj, raise SecretStoreSupportedPluginNotFound() retrieve_delete_plugin = ext.obj break return retrieve_delete_plugin generate_plugin = ext.obj break return generate_plugin,4,9
openstack%2Fneutron~master~I4eafd9cfb94a77a2f0229f89de5483dad23725cf,openstack/neutron,master,I4eafd9cfb94a77a2f0229f89de5483dad23725cf,Use information from the dnsmasq hosts file to call dhcp_release,MERGED,2013-11-13 18:41:20.000000000,2014-08-14 19:58:33.000000000,2014-02-05 15:05:42.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 2031}, {'_account_id': 2035}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 2733}, {'_account_id': 4395}, {'_account_id': 5572}, {'_account_id': 6316}, {'_account_id': 7183}, {'_account_id': 7448}, {'_account_id': 8449}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9885}, {'_account_id': 9925}]","[{'number': 1, 'created': '2013-11-13 18:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/deb977a250ba8f0146cac3aa0381254c8cf1793e', 'message': ""Use information from the dnsmasq hosts file to call dhcp_release\n\nCertain situations can cause the DHCP agent's local cache to get out\nof sync with the leases held internally by dnsmasq.  This method of\ndetecting when to call dhcp_release is idempotent and not dependent on\nthe cache.   It is more robust.\n\nChange-Id: I4eafd9cfb94a77a2f0229f89de5483dad23725cf\nCloses-Bug: #1250644\n""}, {'number': 2, 'created': '2013-12-03 19:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc016849ee5817659175590752e4c2812847d57d', 'message': ""Use information from the dnsmasq hosts file to call dhcp_release\n\nCertain situations can cause the DHCP agent's local cache to get out\nof sync with the leases held internally by dnsmasq.  This method of\ndetecting when to call dhcp_release is idempotent and not dependent on\nthe cache.   It is more robust.\n\nChange-Id: I4eafd9cfb94a77a2f0229f89de5483dad23725cf\nCloses-Bug: #1250644\n""}, {'number': 3, 'created': '2013-12-05 21:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd00665233d3db41192d9bd52fa60161fb50acba', 'message': ""Use information from the dnsmasq hosts file to call dhcp_release\n\nCertain situations can cause the DHCP agent's local cache to get out\nof sync with the leases held internally by dnsmasq.  This method of\ndetecting when to call dhcp_release is idempotent and not dependent on\nthe cache.   It is more robust.\n\nChange-Id: I4eafd9cfb94a77a2f0229f89de5483dad23725cf\nCloses-Bug: #1250644\n""}, {'number': 4, 'created': '2013-12-18 23:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/363c5a56e78c81cfa62664875adecdadb5d009c7', 'message': ""Use information from the dnsmasq hosts file to call dhcp_release\n\nCertain situations can cause the DHCP agent's local cache to get out\nof sync with the leases held internally by dnsmasq.  This method of\ndetecting when to call dhcp_release is idempotent and not dependent on\nthe cache.   It is more robust.\n\nChange-Id: I4eafd9cfb94a77a2f0229f89de5483dad23725cf\nCloses-Bug: #1250644\n""}, {'number': 6, 'created': '2013-12-19 18:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/518b5cb23dd2eb5f35892b082f71bc5e94bec926', 'message': ""Use information from the dnsmasq hosts file to call dhcp_release\n\nCertain situations can cause the DHCP agent's local cache to get out\nof sync with the leases held internally by dnsmasq.  This method of\ndetecting when to call dhcp_release is idempotent and not dependent on\nthe cache.   It is more robust.\n\nChange-Id: I4eafd9cfb94a77a2f0229f89de5483dad23725cf\nCloses-Bug: #1250644\n""}, {'number': 5, 'created': '2013-12-19 18:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d095a1acee03f3e598798d723e7c928750daf720', 'message': ""Use information from the dnsmasq hosts file to call dhcp_release\n\nCertain situations can cause the DHCP agent's local cache to get out\nof sync with the leases held internally by dnsmasq.  This method of\ndetecting when to call dhcp_release is idempotent and not dependent on\nthe cache.   It is more robust.\n\nChange-Id: I4eafd9cfb94a77a2f0229f89de5483dad23725cf\nCloses-Bug: #1250644\n""}, {'number': 8, 'created': '2014-01-13 17:21:34.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/965542bfac90194bd032e5e6aeb6a507dcb11088', 'message': ""Use information from the dnsmasq hosts file to call dhcp_release\n\nCertain situations can cause the DHCP agent's local cache to get out\nof sync with the leases held internally by dnsmasq.  This method of\ndetecting when to call dhcp_release is idempotent and not dependent on\nthe cache.  It is more robust.\n\nChange-Id: I4eafd9cfb94a77a2f0229f89de5483dad23725cf\nCloses-Bug: #1250644\n""}, {'number': 7, 'created': '2014-01-13 17:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/41b42f30c5a696e33748536861620f66f30790e3', 'message': ""Use information from the dnsmasq hosts file to call dhcp_release\n\nCertain situations can cause the DHCP agent's local cache to get out\nof sync with the leases held internally by dnsmasq.  This method of\ndetecting when to call dhcp_release is idempotent and not dependent on\nthe cache.  It is more robust.\n\nChange-Id: I4eafd9cfb94a77a2f0229f89de5483dad23725cf\nCloses-Bug: #1250644\n""}]",30,56263,965542bfac90194bd032e5e6aeb6a507dcb11088,278,22,8,7448,,,0,"Use information from the dnsmasq hosts file to call dhcp_release

Certain situations can cause the DHCP agent's local cache to get out
of sync with the leases held internally by dnsmasq.  This method of
detecting when to call dhcp_release is idempotent and not dependent on
the cache.  It is more robust.

Change-Id: I4eafd9cfb94a77a2f0229f89de5483dad23725cf
Closes-Bug: #1250644
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/56263/8 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py']",2,deb977a250ba8f0146cac3aa0381254c8cf1793e,bug/1250644," def test_output_hosts_file_release_leases(self): dm = dhcp.Dnsmasq(self.conf, FakeDualNetwork()) dm._read_old_leases = mock.Mock() dm._read_old_leases.return_value = {'ip1': 'mac1', 'ip2': 'mac2'} dm._release_lease = mock.Mock() dm.network.ports = [] dm._output_hosts_file() dm._release_lease.assert_has_calls([mock.call('mac1', ['ip1']), mock.call('mac2', ['ip2'])], any_order=True) def test_output_hosts_file_release_one_lease(self): dm = dhcp.Dnsmasq(self.conf, FakeDualNetwork(), version=float(2.59)) dm._read_old_leases = mock.Mock() dm._read_old_leases.return_value = {'192.168.0.2': '00:00:80:aa:bb:cc', '192.168.0.3': '00:00:80:cc:bb:aa'} dm._release_lease = mock.Mock() dm.network.ports = [FakePort1()] dm._output_hosts_file() dm._release_lease.assert_called_once_with('00:00:80:cc:bb:aa', ['192.168.0.3']) "," def test_release_lease(self): dm = dhcp.Dnsmasq(self.conf, FakeDualNetwork(), version=float(2.59)) dm.release_lease(mac_address=FakePort2.mac_address, removed_ips=[FakePort2.fixed_ips[0].ip_address]) exp_args = ['ip', 'netns', 'exec', 'qdhcp-ns', 'dhcp_release', dm.interface_name, FakePort2.fixed_ips[0].ip_address, FakePort2.mac_address] self.execute.assert_called_once_with(exp_args, root_helper='sudo', check_exit_code=True) ",53,13
openstack%2Fkeystone~master~I4128c2d0f08ba5ae25bb1e96a8cbb073978fade5,openstack/keystone,master,I4128c2d0f08ba5ae25bb1e96a8cbb073978fade5,Enable hacking H104 - Full of only comments,ABANDONED,2014-08-14 19:53:57.000000000,2014-08-14 19:56:05.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-14 19:53:57.000000000', 'files': ['keystone/token/backends/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2552cd3ab79942e10d8f96d95a5cfb2c3d749bd6', 'message': ""Enable hacking H104 - Full of only comments\n\nThe error was supressed for a single deprecated file, but I'd\nlike it enabled so that nothing else will violate it. The error:\n\n    H104  File contains nothing but comments\n\nChange-Id: I4128c2d0f08ba5ae25bb1e96a8cbb073978fade5\n""}]",0,114327,2552cd3ab79942e10d8f96d95a5cfb2c3d749bd6,3,1,1,7725,,,0,"Enable hacking H104 - Full of only comments

The error was supressed for a single deprecated file, but I'd
like it enabled so that nothing else will violate it. The error:

    H104  File contains nothing but comments

Change-Id: I4128c2d0f08ba5ae25bb1e96a8cbb073978fade5
",git fetch https://review.opendev.org/openstack/keystone refs/changes/27/114327/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/backends/__init__.py', 'tox.ini']",2,2552cd3ab79942e10d8f96d95a5cfb2c3d749bd6,bug/1328469,"ignore = H405,H803,H904","# H104 File contains nothing but commentsignore = H104,H405,H803,H904",3,2
openstack%2Fbarbican~master~If54911718188eb26b7380331d0b61d70206522a5,openstack/barbican,master,If54911718188eb26b7380331d0b61d70206522a5,remove project-id from resource URIs,MERGED,2014-07-08 19:25:18.000000000,2014-08-14 19:47:22.000000000,2014-08-14 19:47:21.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 1091}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7874}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9946}, {'_account_id': 10873}, {'_account_id': 11860}, {'_account_id': 11970}, {'_account_id': 12843}]","[{'number': 1, 'created': '2014-07-08 19:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/73a05feeaba937c985831c2ea1d5118be116c8ae', 'message': 'remove tenant-id from resource URIs\n\nAll Barbican resources have a tenant-id in their URI. This helps to\ncorrelate the resource with the specified tenant when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe tenant-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the tenant-id in the\nURI redundant. This commit remove tenant-id from the URI.\n\nTests have been updated as well to not expect tenant-id in the URI.\n\nSpec: https://review.openstack.org/#/c/100386\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n'}, {'number': 2, 'created': '2014-07-08 23:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3066cf4cd4b3beed8348348fa4b149787be0de4e', 'message': 'remove project-id from resource URIs\n\nAll Barbican resources have a project-id in their URI. This helps to\ncorrelate the resource with the specified project when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe project-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the project-id in the\nURI redundant. This commit removes project-id from the URI.\n\nTests have been updated as well to not expect project-id in the URI.\n\nSpec: https://review.openstack.org/#/c/100386\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n'}, {'number': 3, 'created': '2014-07-10 04:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/65e760ae20a38e9f90fd6deee0d6f03dc3c61c18', 'message': ""remove project-id from resource URIs\n\nAll Barbican resources have a project-id in their URI. This helps to\ncorrelate the resource with the specified project when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe project-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the project-id in the\nURI redundant. This commit removes project-id from the URI.\n\nTests have been updated as well to not expect project-id in the URI.\n\nPatch 3:\n  removed unauthenticated-context from admin pipeline to fix\n  tempest failure. version api doesn't need auth context now\nSpec: https://review.openstack.org/#/c/100386\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n""}, {'number': 4, 'created': '2014-07-11 05:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3d36e4b3e6e960090b42d027e1e6a417bd393037', 'message': ""remove project-id from resource URIs\n\nAll Barbican resources have a project-id in their URI. This helps to\ncorrelate the resource with the specified project when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe project-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the project-id in the\nURI redundant. This commit removes project-id from the URI.\n\nTests have been updated as well to not expect project-id in the URI.\n\nPatch 3:\n  removed unauthenticated-context from admin pipeline to fix\n  tempest failure. version api doesn't need auth context now\nPatch 4:\n  refactored based on review comments\n  removed the Noop policy enforcer class\n\nSpec: https://review.openstack.org/#/c/100386\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n""}, {'number': 5, 'created': '2014-07-22 23:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/41b8a535cc1c9b0daf5c30df9d43c3345cd38b5b', 'message': ""remove project-id from resource URIs\n\nAll Barbican resources have a project-id in their URI. This helps to\ncorrelate the resource with the specified project when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe project-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the project-id in the\nURI redundant. This commit removes project-id from the URI.\n\nTests have been updated as well to not expect project-id in the URI.\n\nPatch 3:\n  removed unauthenticated-context from admin pipeline to fix\n  tempest failure. version api doesn't need auth context now\nPatch 4:\n  refactored based on review comments\n  removed the Noop policy enforcer class\nPatch 5:\n  rebased and fixed failing tests\n  fixed issue in parsing performance_uri\n\nSpec: https://review.openstack.org/#/c/100386\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n""}, {'number': 6, 'created': '2014-07-29 20:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/7d417c71b4fe1a5462e250c60ede4ae972722fad', 'message': ""remove project-id from resource URIs\n\nAll Barbican resources have a project-id in their URI. This helps to\ncorrelate the resource with the specified project when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe project-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the project-id in the\nURI redundant. This commit removes project-id from the URI.\n\nTests have been updated as well to not expect project-id in the URI.\n\nPatch 3:\n  removed unauthenticated-context from admin pipeline to fix\n  tempest failure. version api doesn't need auth context now\nPatch 4:\n  refactored based on review comments\n  removed the Noop policy enforcer class\nPatch 5:\n  rebased and fixed failing tests\n  fixed issue in parsing performance_uri\nPatch 6:\n  updated functional tests to remove project-id from uri\n  removed rbac check for versions controller\n  expecting X-Project-ID to be present in request for all requests\n  this needs to be fixed in the next pass when the admin paste\n  pipeline is updated\n\nSpec: https://review.openstack.org/#/c/100386\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n""}, {'number': 7, 'created': '2014-07-29 23:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/9f7ae0fcee8f655e51600b1588c5656972215c30', 'message': ""remove project-id from resource URIs\n\nAll Barbican resources have a project-id in their URI. This helps to\ncorrelate the resource with the specified project when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe project-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the project-id in the\nURI redundant. This commit removes project-id from the URI.\n\nTests have been updated as well to not expect project-id in the URI.\n\nPatch 3:\n  removed unauthenticated-context from admin pipeline to fix\n  tempest failure. version api doesn't need auth context now\nPatch 4:\n  refactored based on review comments\n  removed the Noop policy enforcer class\nPatch 5:\n  rebased and fixed failing tests\n  fixed issue in parsing performance_uri\nPatch 6:\n  updated functional tests to remove project-id from uri\n  removed rbac check for versions controller\n  expecting X-Project-ID to be present in request for all requests\n  this needs to be fixed in the next pass when the admin paste\n  pipeline is updated\nPatch 7:\n  fixed failing functional test\n  refactoring based on review comments\n\nSpec: https://review.openstack.org/#/c/100386\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n""}, {'number': 8, 'created': '2014-08-05 23:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c886d7fa09e017eb64f23bad8cffd57076c98d1d', 'message': ""remove project-id from resource URIs\n\nAll Barbican resources have a project-id in their URI. This helps to\ncorrelate the resource with the specified project when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe project-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the project-id in the\nURI redundant. This commit removes project-id from the URI.\n\nTests have been updated as well to not expect project-id in the URI.\n\nPatch 3:\n  removed unauthenticated-context from admin pipeline to fix\n  tempest failure. version api doesn't need auth context now\nPatch 4:\n  refactored based on review comments\n  removed the Noop policy enforcer class\nPatch 5:\n  rebased and fixed failing tests\n  fixed issue in parsing performance_uri\nPatch 6:\n  updated functional tests to remove project-id from uri\n  removed rbac check for versions controller\n  expecting X-Project-ID to be present in request for all requests\n  this needs to be fixed in the next pass when the admin paste\n  pipeline is updated\nPatch 7:\n  fixed failing functional test\n  refactoring based on review comments\nPatch 8:\n  rebased and fixed failing unit tests\n\nSpec: https://review.openstack.org/#/c/100386\nClient CR: https://review.openstack.org/#/c/112149\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n""}, {'number': 9, 'created': '2014-08-12 20:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/8e7a6b0673cdce3f3efb7df75481dec2d801dd9f', 'message': ""remove project-id from resource URIs\n\nAll Barbican resources have a project-id in their URI. This helps to\ncorrelate the resource with the specified project when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe project-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the project-id in the\nURI redundant. This commit removes project-id from the URI.\n\nTests have been updated as well to not expect project-id in the URI.\n\nPatch 3:\n  removed unauthenticated-context from admin pipeline to fix\n  tempest failure. version api doesn't need auth context now\nPatch 4:\n  refactored based on review comments\n  removed the Noop policy enforcer class\nPatch 5:\n  rebased and fixed failing tests\n  fixed issue in parsing performance_uri\nPatch 6:\n  updated functional tests to remove project-id from uri\n  removed rbac check for versions controller\n  expecting X-Project-ID to be present in request for all requests\n  this needs to be fixed in the next pass when the admin paste\n  pipeline is updated\nPatch 7:\n  fixed failing functional test\n  refactoring based on review comments\nPatch 8:\n  rebased and fixed failing unit tests\nPatch 9:\n  fixed merge issue by removing keystone_id from few more lines\n  and files\n\nSpec: https://review.openstack.org/#/c/100386\nClient CR: https://review.openstack.org/#/c/112149\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n""}, {'number': 10, 'created': '2014-08-12 22:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f6d77e9fe682353cdc485a16d458181544d1eb07', 'message': ""remove project-id from resource URIs\n\nAll Barbican resources have a project-id in their URI. This helps to\ncorrelate the resource with the specified project when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe project-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the project-id in the\nURI redundant. This commit removes project-id from the URI.\n\nTests have been updated as well to not expect project-id in the URI.\n\nPatch 3:\n  removed unauthenticated-context from admin pipeline to fix\n  tempest failure. version api doesn't need auth context now\nPatch 4:\n  refactored based on review comments\n  removed the Noop policy enforcer class\nPatch 5:\n  rebased and fixed failing tests\n  fixed issue in parsing performance_uri\nPatch 6:\n  updated functional tests to remove project-id from uri\n  removed rbac check for versions controller\n  expecting X-Project-ID to be present in request for all requests\n  this needs to be fixed in the next pass when the admin paste\n  pipeline is updated\nPatch 7:\n  fixed failing functional test\n  refactoring based on review comments\nPatch 8:\n  rebased and fixed failing unit tests\nPatch 9:\n  fixed merge issue by removing keystone_id from few more lines\n  and files\nPatch 10:\n  fixed failing functional tests (consumers)\n\nSpec: https://review.openstack.org/#/c/100386\nClient CR: https://review.openstack.org/#/c/112149\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n""}, {'number': 11, 'created': '2014-08-12 22:50:15.000000000', 'files': ['barbican/tests/common/test_utils.py', 'barbican/api/controllers/orders.py', 'barbican/api/controllers/transportkeys.py', 'functionaltests/run_tests.sh', 'barbican/tests/api/test_transport_keys_resource.py', 'barbican/common/utils.py', 'barbican/api/controllers/versions.py', 'barbican/api/controllers/consumers.py', 'barbican/api/controllers/containers.py', 'etc/barbican/barbican-api-paste.ini', 'barbican/api/controllers/hrefs.py', 'barbican/api/controllers/secrets.py', 'barbican/api/controllers/__init__.py', 'barbican/api/middleware/context.py', 'functionaltests/api/v1/test_secrets.py', 'barbican/api/app.py', 'functionaltests/api/v1/test_orders.py', 'functionaltests/api/v1/test_consumers.py', 'barbican/tests/api/test_resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/d15f8db5974749fc97cf606b8a6b023ab0b5e219', 'message': ""remove project-id from resource URIs\n\nAll Barbican resources have a project-id in their URI. This helps to\ncorrelate the resource with the specified project when no external\nauthentication mechanism is used. However, most Barbican deployments\nwould use Keystone to authenticate the API requests. With Keystone,\nthe project-id information is already obtained when the X-Auth-Token\nheader from the request is validated. This makes the project-id in the\nURI redundant. This commit removes project-id from the URI.\n\nTests have been updated as well to not expect project-id in the URI.\n\nPatch 3:\n  removed unauthenticated-context from admin pipeline to fix\n  tempest failure. version api doesn't need auth context now\nPatch 4:\n  refactored based on review comments\n  removed the Noop policy enforcer class\nPatch 5:\n  rebased and fixed failing tests\n  fixed issue in parsing performance_uri\nPatch 6:\n  updated functional tests to remove project-id from uri\n  removed rbac check for versions controller\n  expecting X-Project-ID to be present in request for all requests\n  this needs to be fixed in the next pass when the admin paste\n  pipeline is updated\nPatch 7:\n  fixed failing functional test\n  refactoring based on review comments\nPatch 8:\n  rebased and fixed failing unit tests\nPatch 9:\n  fixed merge issue by removing keystone_id from few more lines\n  and files\nPatch 10:\n  fixed failing functional tests (consumers)\n\nSpec: https://review.openstack.org/#/c/100386\nClient CR: https://review.openstack.org/#/c/112149\nChange-Id: If54911718188eb26b7380331d0b61d70206522a5\nBlueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id\n""}]",88,105562,d15f8db5974749fc97cf606b8a6b023ab0b5e219,97,18,11,7874,,,0,"remove project-id from resource URIs

All Barbican resources have a project-id in their URI. This helps to
correlate the resource with the specified project when no external
authentication mechanism is used. However, most Barbican deployments
would use Keystone to authenticate the API requests. With Keystone,
the project-id information is already obtained when the X-Auth-Token
header from the request is validated. This makes the project-id in the
URI redundant. This commit removes project-id from the URI.

Tests have been updated as well to not expect project-id in the URI.

Patch 3:
  removed unauthenticated-context from admin pipeline to fix
  tempest failure. version api doesn't need auth context now
Patch 4:
  refactored based on review comments
  removed the Noop policy enforcer class
Patch 5:
  rebased and fixed failing tests
  fixed issue in parsing performance_uri
Patch 6:
  updated functional tests to remove project-id from uri
  removed rbac check for versions controller
  expecting X-Project-ID to be present in request for all requests
  this needs to be fixed in the next pass when the admin paste
  pipeline is updated
Patch 7:
  fixed failing functional test
  refactoring based on review comments
Patch 8:
  rebased and fixed failing unit tests
Patch 9:
  fixed merge issue by removing keystone_id from few more lines
  and files
Patch 10:
  fixed failing functional tests (consumers)

Spec: https://review.openstack.org/#/c/100386
Client CR: https://review.openstack.org/#/c/112149
Change-Id: If54911718188eb26b7380331d0b61d70206522a5
Blueprint: https://blueprints.launchpad.net/barbican/+spec/api-remove-uri-tenant-id
",git fetch https://review.opendev.org/openstack/barbican refs/changes/62/105562/11 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/common/test_utils.py', 'barbican/api/controllers/orders.py', 'barbican/api/controllers/transportkeys.py', 'barbican/tests/api/test_transport_keys_resource.py', 'barbican/common/utils.py', 'barbican/api/controllers/containers.py', 'etc/barbican/barbican-api-paste.ini', 'barbican/api/controllers/hrefs.py', 'barbican/api/controllers/secrets.py', 'barbican/api/controllers/__init__.py', 'barbican/api/middleware/context.py', 'barbican/api/app.py', 'barbican/tests/api/test_resources.py']",13,73a05feeaba937c985831c2ea1d5118be116c8ae,api-remove-uri-project-id,"import barbican.contextdef get_barbican_env(keystone_id): """"""Create and return a NO-OP barbican.context for use with the RBAC decorator while injecting the provided keystone_id """""" class NoopPolicyEnforcer(object): def enforce(self, *args, **kwargs): return kwargs = {'roles': None, 'user': None, 'tenant': keystone_id, 'is_admin': True, 'policy_enforcer': NoopPolicyEnforcer()} barbican_env = {'barbican.context': barbican.context.RequestContext(**kwargs)} return barbican_env self.app.extra_environ = get_barbican_env(self.keystone_id) '/secrets/', '/secrets/', '/secrets/', self.app.post_json('/secrets/', self.secret_req) '/secrets/', '/secrets/', '/secrets/', '/secrets/', '/secrets/', '/secrets/', '/secrets/', '/secrets/', '/secrets/', '/secrets/', '/secrets/', '/secrets/', '/secrets/', self.app.extra_environ = get_barbican_env(self.keystone_id) '/secrets/', '/secrets/', '/secrets/', '/secrets/', return '/secrets?limit={0}&offset={1}'.format(limit, offset) else: return '/secrets' self.app.extra_environ = get_barbican_env(self.keystone_id) '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id), '/secrets/%s/' % (self.secret.id) '/secrets/%s/' % (self.secret.id), self.app.extra_environ = get_barbican_env(self.tenant_keystone_id) '/orders/', '/orders/', '/orders/', '/orders/', self.app.extra_environ = get_barbican_env(self.keystone_id) resp = self.app.get('/orders/', self.params) resp = self.app.get('/orders/', self.params) resp = self.app.get('/orders/', self.params) return '/orders?limit={0}&offset={1}'.format(limit, offset) else: return '/orders' self.app.extra_environ = get_barbican_env(self.tenant_keystone_id) self.app.get('/orders/%s/' % (self.order.id)) self.app.delete('/orders/%s/' % (self.order.id)) '/orders/%s/' % (self.order.id), '/orders/%s/' % (self.order.id), self.app.extra_environ = get_barbican_env(self.tenant_keystone_id) '/containers/', '/containers/', '/containers/', self.app.extra_environ = get_barbican_env(self.tenant_keystone_id) self.app.get('/containers/%s/' % ( self.container.id self.app.delete('/containers/%s/' % ( self.container.id resp = self.app.get('/containers/%s/' % ( self.container.id resp = self.app.delete('/containers/%s/' % ( self.container.id self.app.extra_environ = get_barbican_env(self.keystone_id) '/containers/', '/containers/', '/containers/', return '/containers' \ '?limit={0}&offset={1}'.format(limit, offset) else: return '/containers'"," '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, self.app.post_json('/%s/secrets/' % self.keystone_id, self.secret_req) '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, '/%s/secrets/' % self.keystone_id, return '/{0}/secrets?limit={1}&offset={2}'.format(keystone_id, limit, offset) else: return '/{0}/secrets'.format(keystone_id) '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/secrets/%s/' % (self.keystone_id, self.secret.id) '/%s/secrets/%s/' % (self.keystone_id, self.secret.id), '/%s/orders/' % self.tenant_keystone_id, '/%s/orders/' % self.tenant_keystone_id, '/%s/orders/' % self.tenant_keystone_id, '/%s/orders/' % self.tenant_keystone_id, resp = self.app.get('/%s/orders/' % self.keystone_id, self.params) resp = self.app.get('/%s/orders/' % self.keystone_id, self.params) resp = self.app.get('/%s/orders/' % self.keystone_id, self.params) return '/{0}/orders?limit={1}&offset={2}'.format(keystone_id, limit, offset) else: return '/{0}/orders'.format(self.keystone_id) self.app.get('/%s/orders/%s/' % (self.tenant_keystone_id, self.order.id)) self.app.delete('/%s/orders/%s/' % (self.tenant_keystone_id, self.order.id)) '/%s/orders/%s/' % (self.tenant_keystone_id, self.order.id), '/%s/orders/%s/' % (self.tenant_keystone_id, self.order.id), self.keystone_id, self.keystone_id, self.keystone_id, '/%s/containers/' % self.tenant_keystone_id, '/%s/containers/' % self.tenant_keystone_id, '/%s/containers/' % self.tenant_keystone_id, self.app.get('/%s/containers/%s/' % ( self.tenant_keystone_id, self.container.id self.app.delete('/%s/containers/%s/' % ( self.tenant_keystone_id, self.container.id resp = self.app.get('/%s/containers/%s/' % ( self.tenant_keystone_id, self.container.id resp = self.app.delete('/%s/containers/%s/' % ( self.tenant_keystone_id, self.container.id '/%s/containers/' % self.keystone_id, '/%s/containers/' % self.keystone_id, '/%s/containers/' % self.keystone_id, return '/{0}/containers' \ '?limit={1}&offset={2}'.format(keystone_id, limit, offset) else: return '/{0}/containers'.format(self.keystone_id)",219,183
openstack%2Fcookbook-openstack-block-storage~master~Ic4f56f19e2d85cadaa4566323409ca093d435f6a,openstack/cookbook-openstack-block-storage,master,Ic4f56f19e2d85cadaa4566323409ca093d435f6a,Update cinder conf files for Juno,MERGED,2014-08-05 15:58:57.000000000,2014-08-14 19:37:49.000000000,2014-08-14 19:37:49.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 7128}, {'_account_id': 8410}]","[{'number': 1, 'created': '2014-08-05 15:58:57.000000000', 'files': ['templates/default/api-paste.ini.erb', 'CHANGELOG.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/cfcfccc01eec70516ed79e75bb3bdd0cd2c16761', 'message': 'Update cinder conf files for Juno\n\n* Update api-paste with request-id\n\nChange-Id: Ic4f56f19e2d85cadaa4566323409ca093d435f6a\nCloses-Bug: #1352974\n'}]",0,112052,cfcfccc01eec70516ed79e75bb3bdd0cd2c16761,17,5,1,7128,,,0,"Update cinder conf files for Juno

* Update api-paste with request-id

Change-Id: Ic4f56f19e2d85cadaa4566323409ca093d435f6a
Closes-Bug: #1352974
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/52/112052/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/default/api-paste.ini.erb', 'CHANGELOG.md']",2,cfcfccc01eec70516ed79e75bb3bdd0cd2c16761,bug/1352974,* Sync conf files with Juno,,10,6
openstack%2Fcookbook-openstack-orchestration~master~Ie70594a5d12e76f4d30e07b5620dd4776995c4f8,openstack/cookbook-openstack-orchestration,master,Ie70594a5d12e76f4d30e07b5620dd4776995c4f8,Update heat conf files for Juno,MERGED,2014-08-05 19:58:53.000000000,2014-08-14 19:20:34.000000000,2014-08-14 19:20:33.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 7128}, {'_account_id': 8410}]","[{'number': 1, 'created': '2014-08-05 19:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-orchestration/commit/5ac21029830f7e35ca66d10d4e09c06bf37e89f4', 'message': 'Update glance conf files for Juno\n\n* Update paste.ini\n* Update conf\n  - Add in description comments\n  - Put section in order\n\nChange-Id: Ie70594a5d12e76f4d30e07b5620dd4776995c4f8\nCloses-Bug: #1353063\n'}, {'number': 2, 'created': '2014-08-05 20:00:06.000000000', 'files': ['templates/default/heat.conf.erb', 'templates/default/api-paste.ini.erb', 'CHANGELOG.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-orchestration/commit/0aaa20863dc37295218fa40c2c3ffe8c4afb45fe', 'message': 'Update heat conf files for Juno\n\n* Update paste.ini\n* Update conf\n  - Add in description comments\n  - Put section in order\n\nChange-Id: Ie70594a5d12e76f4d30e07b5620dd4776995c4f8\nCloses-Bug: #1353063\n'}]",0,112123,0aaa20863dc37295218fa40c2c3ffe8c4afb45fe,24,5,2,7128,,,0,"Update heat conf files for Juno

* Update paste.ini
* Update conf
  - Add in description comments
  - Put section in order

Change-Id: Ie70594a5d12e76f4d30e07b5620dd4776995c4f8
Closes-Bug: #1353063
",git fetch https://review.opendev.org/openstack/cookbook-openstack-orchestration refs/changes/23/112123/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/default/heat.conf.erb', 'templates/default/api-paste.ini.erb', 'CHANGELOG.md']",3,5ac21029830f7e35ca66d10d4e09c06bf37e89f4,bug/1353063,* Sync conf files with Juno,,449,389
openstack%2Fcookbook-openstack-telemetry~stable%2Ficehouse~Ie67e84e5695bd5f9ceaa6ed6682cfe33f7ed0b68,openstack/cookbook-openstack-telemetry,stable/icehouse,Ie67e84e5695bd5f9ceaa6ed6682cfe33f7ed0b68,Support VMware hypervisor inspector,MERGED,2014-08-05 01:21:22.000000000,2014-08-14 19:18:57.000000000,2014-08-14 19:18:57.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 6526}, {'_account_id': 7128}]","[{'number': 1, 'created': '2014-08-05 01:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/d5339e9760c56eeb6783567ca26facac383e2b1b', 'message': 'Support VMware hypervisor inspector\n\n1. If the compute driver is vmwareapi.VMwareESXDriver or\nvmwareapi.VMwareVCDriver, set the hypervisor_inspector to vsphere and\nadd vmware section in conf file.\n2. Reuse the vmware related attribute from compute cookbooks since\nceilometer need monitor the same vsphere.\n3. Update the testcases\n\nConflicts:\n        CHANGELOG.md\n        metadata.rb\n        spec/spec_helper.rb\n\nCloses-Bug: #1351619\nChange-Id: Ie67e84e5695bd5f9ceaa6ed6682cfe33f7ed0b68\n(cherry picked from commit 4529146a83cc4f5d1ec8c5c0f5cbf5346a05b022)\n'}, {'number': 2, 'created': '2014-08-05 01:22:41.000000000', 'files': ['spec/common_spec.rb', 'templates/default/ceilometer.conf.erb', 'spec/spec_helper.rb', 'attributes/default.rb', 'CHANGELOG.md', 'metadata.rb', 'recipes/common.rb', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/60e9cf107c288e5b2d338f0c388a216b471f5d2e', 'message': 'Support VMware hypervisor inspector\n\n1. If the compute driver is vmwareapi.VMwareESXDriver or\nvmwareapi.VMwareVCDriver, set the hypervisor_inspector to vsphere and\nadd vmware section in conf file.\n2. Reuse the vmware related attribute from compute cookbooks since\nceilometer need monitor the same vsphere.\n3. Update the testcases\n\nConflicts:\n        CHANGELOG.md\n        metadata.rb\n        spec/spec_helper.rb\n\nCloses-Bug: #1351619\nChange-Id: Ie67e84e5695bd5f9ceaa6ed6682cfe33f7ed0b68\n(cherry picked from commit 4529146a83cc4f5d1ec8c5c0f5cbf5346a05b022)\n'}]",0,111880,60e9cf107c288e5b2d338f0c388a216b471f5d2e,27,4,2,6526,,,0,"Support VMware hypervisor inspector

1. If the compute driver is vmwareapi.VMwareESXDriver or
vmwareapi.VMwareVCDriver, set the hypervisor_inspector to vsphere and
add vmware section in conf file.
2. Reuse the vmware related attribute from compute cookbooks since
ceilometer need monitor the same vsphere.
3. Update the testcases

Conflicts:
        CHANGELOG.md
        metadata.rb
        spec/spec_helper.rb

Closes-Bug: #1351619
Change-Id: Ie67e84e5695bd5f9ceaa6ed6682cfe33f7ed0b68
(cherry picked from commit 4529146a83cc4f5d1ec8c5c0f5cbf5346a05b022)
",git fetch https://review.opendev.org/openstack/cookbook-openstack-telemetry refs/changes/80/111880/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/common_spec.rb', 'templates/default/ceilometer.conf.erb', 'spec/spec_helper.rb', 'attributes/default.rb', 'CHANGELOG.md', 'metadata.rb', 'recipes/common.rb', 'README.md']",8,d5339e9760c56eeb6783567ca26facac383e2b1b,bug/1351619,| **Author** | David Geng (<gengjh@cn.ibm.com>) |,,43,2
openstack%2Fmonasca-agent~master~I86e5e86ce4a5e942158103fb96372fbd0663f9f6,openstack/monasca-agent,master,I86e5e86ce4a5e942158103fb96372fbd0663f9f6,Copy /root/.my.cnf credentials into mysql.yaml,MERGED,2014-07-30 21:15:22.000000000,2014-08-14 19:15:36.000000000,2014-08-14 19:15:36.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 11094}, {'_account_id': 12108}]","[{'number': 1, 'created': '2014-07-30 21:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/56dafeec4e66b6e15861c58aebc0dcb3ced310d3', 'message': 'Copy /root/.my.cnf credentials into mysql.yaml\n\nChange-Id: I86e5e86ce4a5e942158103fb96372fbd0663f9f6\n'}, {'number': 2, 'created': '2014-08-14 18:17:37.000000000', 'files': ['monsetup/detection/plugins/mysql.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/4c7301570cc186d69fe6179d9fb6ae24106ff10e', 'message': 'Copy /root/.my.cnf credentials into mysql.yaml\n\nChange-Id: I86e5e86ce4a5e942158103fb96372fbd0663f9f6\n'}]",7,110792,4c7301570cc186d69fe6179d9fb6ae24106ff10e,16,4,2,12443,,,0,"Copy /root/.my.cnf credentials into mysql.yaml

Change-Id: I86e5e86ce4a5e942158103fb96372fbd0663f9f6
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/92/110792/1 && git format-patch -1 --stdout FETCH_HEAD,['monsetup/detection/plugins/mysql.py'],1,56dafeec4e66b6e15861c58aebc0dcb3ced310d3,feature/mysql-conf-fix," This plugin needs user/pass infor for mysql setup, this is best placed in /root/.my.cnf in a format such as ""\tConfiguring MySQL plugin using auth settings from /root/.my.cnf"") # Read the /root/.my.cnf file to extract the needed variables. # While the agent mysql.conf file has the ability to read the # /root/.my.cnf file directly as 'defaults_file,' the agent # user would likely not have permission to do so. client_section = False my_user = None my_pass = None try: cnf = open(""/root/.my.cnf"", ""r"") for row in cnf: if client_section: if ""["" in row: break if ""user="" in row: my_user = row.split(""="")[1].rstrip() if ""password="" in row: my_pass = row.split(""="")[1].rstrip().strip(""'"") if ""[client]"" in row: client_section = True cnf.close() config['mysql'] = {'init_config': None, 'instances': [{'server': 'localhost', 'port': 3306, 'user': my_user, 'pass': my_pass}]} except IOError: pass [{'server': 'localhost', 'user': 'root', 'pass': 'password', 'port': 3306}]}"," This plugin needs user/pass infor for mysql setup, this is best placed in /root/.my.cnf in a format such as ""\tConfiguring MySQL plugin to connect with auth settings from /root/.my.cnf"") config['mysql'] = {'init_config': None, 'instances': [{'server': 'localhost', 'user': 'root', 'defaults_file': '/root/.my.cnf'}]} [{'server': 'localhost', 'user': 'root', 'pass': 'password', 'port': 3306}]}",30,5
openstack%2Fheat~master~I8e47ee94e15309f378f62f2a9f6534a4eeddb389,openstack/heat,master,I8e47ee94e15309f378f62f2a9f6534a4eeddb389,Appropriate exception for signal handling failure,MERGED,2014-07-23 19:53:51.000000000,2014-08-14 19:13:40.000000000,2014-08-14 19:13:39.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6348}, {'_account_id': 6488}, {'_account_id': 7193}, {'_account_id': 8246}, {'_account_id': 10090}]","[{'number': 1, 'created': '2014-07-23 19:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7bfed47a4ec1ccc386e3a6b3734fd03882e501b8', 'message': ""Appropriate exception for signal handling failure\n\nRaise an appropriate exception, mapped to a 400 error for signals\nto resources which cannot handle signals.  In this case, the request\nis inherently impossible to satisfy, because the plugin doesn't\nsupport signals, so we should alert the user to this by saying it's\na bad request (rather than the current response which is a 500 error)\n\nChange-Id: I8e47ee94e15309f378f62f2a9f6534a4eeddb389\nCloses-Bug: #1346849\n""}, {'number': 2, 'created': '2014-07-24 19:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bc71d3a989d65fdeac5bd5bbfa2090c82a657dd2', 'message': ""Appropriate exception for signal handling failure\n\nRaise an appropriate exception, mapped to a 400 error for signals\nto resources which cannot handle signals.  In this case, the request\nis inherently impossible to satisfy, because the plugin doesn't\nsupport signals, so we should alert the user to this by saying it's\na bad request (rather than the current response which is a 500 error)\n\nChange-Id: I8e47ee94e15309f378f62f2a9f6534a4eeddb389\nCloses-Bug: #1346849\n""}, {'number': 3, 'created': '2014-07-25 13:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/63f06a4ab97746401152055fe4850548b81916ce', 'message': ""Appropriate exception for signal handling failure\n\nRaise an appropriate exception, mapped to a 400 error for signals\nto resources which cannot handle signals.  In this case, the request\nis inherently impossible to satisfy, because the plugin doesn't\nsupport signals, so we should alert the user to this by saying it's\na bad request (rather than the current response which is a 500 error)\n\nChange-Id: I8e47ee94e15309f378f62f2a9f6534a4eeddb389\nCloses-Bug: #1346849\n""}, {'number': 4, 'created': '2014-08-11 09:29:45.000000000', 'files': ['heat/api/middleware/fault.py', 'heat/api/aws/exception.py', 'heat/tests/test_signal.py', 'heat/common/exception.py', 'heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0909340b4ce49f25a8d858be9bb081fd163a4dab', 'message': ""Appropriate exception for signal handling failure\n\nRaise an appropriate exception, mapped to a 400 error for signals\nto resources which cannot handle signals.  In this case, the request\nis inherently impossible to satisfy, because the plugin doesn't\nsupport signals, so we should alert the user to this by saying it's\na bad request (rather than the current response which is a 500 error)\n\nChange-Id: I8e47ee94e15309f378f62f2a9f6534a4eeddb389\nCloses-Bug: #1346849\n""}]",0,109096,0909340b4ce49f25a8d858be9bb081fd163a4dab,24,8,4,4328,,,0,"Appropriate exception for signal handling failure

Raise an appropriate exception, mapped to a 400 error for signals
to resources which cannot handle signals.  In this case, the request
is inherently impossible to satisfy, because the plugin doesn't
support signals, so we should alert the user to this by saying it's
a bad request (rather than the current response which is a 500 error)

Change-Id: I8e47ee94e15309f378f62f2a9f6534a4eeddb389
Closes-Bug: #1346849
",git fetch https://review.opendev.org/openstack/heat refs/changes/96/109096/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/api/middleware/fault.py', 'heat/api/aws/exception.py', 'heat/tests/test_signal.py', 'heat/common/exception.py', 'heat/engine/resource.py']",5,7bfed47a4ec1ccc386e3a6b3734fd03882e501b8,bug/1346849," if not callable(getattr(self, 'handle_signal', None)): raise exception.ResourceActionNotSupported(action='signal')"," if not callable(getattr(self, 'handle_signal', None)): msg = (_('Resource %s is not able to receive a signal') % str(self)) raise Exception(msg) ",9,6
openstack%2Frequirements~master~I56be581b1a31d73d367ede16bd2d85dc28a0ca26,openstack/requirements,master,I56be581b1a31d73d367ede16bd2d85dc28a0ca26,Add pip_missing_reqs package,MERGED,2014-08-14 04:57:38.000000000,2014-08-14 19:13:36.000000000,2014-08-14 19:13:36.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-08-14 04:57:38.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/aa5fe08da02c18865c31d65789e0151b5bd508cd', 'message': 'Add pip_missing_reqs package\n\nThis package supplies the pip-missing-reqs tool which will be used\nto sanity-check requirements.txt files for OpenStack projects.\n\nChange-Id: I56be581b1a31d73d367ede16bd2d85dc28a0ca26\n'}]",0,114121,aa5fe08da02c18865c31d65789e0151b5bd508cd,8,3,1,12071,,,0,"Add pip_missing_reqs package

This package supplies the pip-missing-reqs tool which will be used
to sanity-check requirements.txt files for OpenStack projects.

Change-Id: I56be581b1a31d73d367ede16bd2d85dc28a0ca26
",git fetch https://review.opendev.org/openstack/requirements refs/changes/21/114121/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,aa5fe08da02c18865c31d65789e0151b5bd508cd,add-pip-missing-reqs,pip_missing_reqs>=1.1.5,,1,0
openstack%2Ftripleo-heat-templates~master~Ibac193781d31d6f81e955e7b9381e13cfdd0ab1d,openstack/tripleo-heat-templates,master,Ibac193781d31d6f81e955e7b9381e13cfdd0ab1d,Replace occurrences of list_join with Fn::Join,MERGED,2014-08-14 17:11:05.000000000,2014-08-14 18:52:26.000000000,2014-08-14 18:52:25.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-08-14 17:11:05.000000000', 'files': ['overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2656fa938d6ff1b8807d59fd06afff14786dbd74', 'message': 'Replace occurrences of list_join with Fn::Join\n\nWhen change I6730ffe1e27d952d563c16a9480298fbef9f61fe got merged we\nintroduced some occurrences of list_join which should have been\nmigrated to Fn::Join (change I039f57ab39c1fcfc319a7a34265ba4fabf4ccd08)\n\nThis caused overcloud CI jobs to fail with:\nProperty error : allNodesConfig: config Items to join must be strings\n\nThis change fixes this by replacing newly introduced occurrences\nof list_join with Fn::Join\n\nChange-Id: Ibac193781d31d6f81e955e7b9381e13cfdd0ab1d\n'}]",0,114300,2656fa938d6ff1b8807d59fd06afff14786dbd74,10,4,1,6796,,,0,"Replace occurrences of list_join with Fn::Join

When change I6730ffe1e27d952d563c16a9480298fbef9f61fe got merged we
introduced some occurrences of list_join which should have been
migrated to Fn::Join (change I039f57ab39c1fcfc319a7a34265ba4fabf4ccd08)

This caused overcloud CI jobs to fail with:
Property error : allNodesConfig: config Items to join must be strings

This change fixes this by replacing newly introduced occurrences
of list_join with Fn::Join

Change-Id: Ibac193781d31d6f81e955e7b9381e13cfdd0ab1d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/00/114300/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-source.yaml'],1,2656fa938d6ff1b8807d59fd06afff14786dbd74,postmerge_fix_list_join, Fn::Join: - Fn::Join: - Fn::Join: Fn::Join: - Fn::Join: - Fn::Join:, list_join: - list_join: - list_join: list_join: - list_join: - list_join:,6,6
openstack%2Fopenstack-manuals~master~I976c4d5120bc8bf36ce03329ae875f17864b09f8,openstack/openstack-manuals,master,I976c4d5120bc8bf36ce03329ae875f17864b09f8,Capitalize Internet,MERGED,2014-08-14 15:46:52.000000000,2014-08-14 18:41:01.000000000,2014-08-14 18:41:00.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-14 15:46:52.000000000', 'files': ['doc/arch-design/generalpurpose/section_tech_considerations_general_purpose.xml', 'doc/install-guide/ch_overview.xml', 'doc/admin-guide-cloud/compute/section_compute-image-mgt.xml', 'doc/arch-design/hybrid/section_tech_considerations_hybrid.xml', 'doc/image-guide/section_ubuntu-example.xml', 'doc/install-guide/section_basics-networking-neutron.xml', 'doc/install-guide/section_basics-networking-nova.xml', 'doc/install-guide/section_nova-networking-initial-network.xml', 'doc/install-guide/section_neutron-initial-networks.xml', 'doc/arch-design/compute_focus/section_tech_considerations_compute_focus.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/791efd470d8459d7c4ebd73922347923d64a6aa7', 'message': 'Capitalize Internet\n\nUse Internet in a consistent way in all guides.\n\nChange-Id: I976c4d5120bc8bf36ce03329ae875f17864b09f8\n'}]",0,114279,791efd470d8459d7c4ebd73922347923d64a6aa7,11,4,1,6547,,,0,"Capitalize Internet

Use Internet in a consistent way in all guides.

Change-Id: I976c4d5120bc8bf36ce03329ae875f17864b09f8
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/114279/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/arch-design/generalpurpose/section_tech_considerations_general_purpose.xml', 'doc/install-guide/ch_overview.xml', 'doc/admin-guide-cloud/compute/section_compute-image-mgt.xml', 'doc/arch-design/hybrid/section_tech_considerations_hybrid.xml', 'doc/image-guide/section_ubuntu-example.xml', 'doc/install-guide/section_basics-networking-neutron.xml', 'doc/install-guide/section_basics-networking-nova.xml', 'doc/install-guide/section_neutron-initial-networks.xml', 'doc/install-guide/section_nova-networking-initial-network.xml', 'doc/arch-design/compute_focus/section_tech_considerations_compute_focus.xml']",10,791efd470d8459d7c4ebd73922347923d64a6aa7,Internet, Internet access to instances should consider this domain to be, internet access to instances should consider this domain to be,25,22
openstack%2Fcongress~master~Ia98a57b4fe2cfd5886617b001b2aae9b7b244a85,openstack/congress,master,Ia98a57b4fe2cfd5886617b001b2aae9b7b244a85,Login as admin instead of demo,ABANDONED,2014-08-11 22:08:29.000000000,2014-08-14 18:33:09.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}]","[{'number': 1, 'created': '2014-08-11 22:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/f22cbea172c5f918e0c22c479a5aa8f13350e994', 'message': 'Login as admin instead of demo\n\nThe prior version logged into services as demo, but the demo user\ncannot read some items from nova.  Instead, login as admin.\n\nChange-Id: Ia98a57b4fe2cfd5886617b001b2aae9b7b244a85\n'}, {'number': 2, 'created': '2014-08-11 23:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/6761ca54400a1257e4c9c0810796ef34ec70edaa', 'message': 'Login as admin instead of demo\n\nThe prior version logged into services as demo, but the demo user\ncannot read some items from nova.  Instead, login as admin.\n\nChange-Id: Ia98a57b4fe2cfd5886617b001b2aae9b7b244a85\n'}, {'number': 3, 'created': '2014-08-11 23:45:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/2645b44fc54ba46edd0c0d00aeb31fc14d71770d', 'message': 'Login as admin instead of demo\n\nThe prior version logged into services as demo, but the demo user\ncannot read some items from nova.  Instead, login as admin.\n\nChange-Id: Ia98a57b4fe2cfd5886617b001b2aae9b7b244a85\n'}, {'number': 4, 'created': '2014-08-13 17:38:47.000000000', 'files': ['congress/datasources/settings.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/393ddec709e7ea94679042d1f4e83ddac1b8daaf', 'message': 'Login as admin instead of demo\n\nThe prior version logged into services as demo, but the demo user\ncannot read some items from nova.  Instead, login as admin.\n\nChange-Id: Ia98a57b4fe2cfd5886617b001b2aae9b7b244a85\n'}]",0,113384,393ddec709e7ea94679042d1f4e83ddac1b8daaf,13,3,4,12875,,,0,"Login as admin instead of demo

The prior version logged into services as demo, but the demo user
cannot read some items from nova.  Instead, login as admin.

Change-Id: Ia98a57b4fe2cfd5886617b001b2aae9b7b244a85
",git fetch https://review.opendev.org/openstack/congress refs/changes/84/113384/3 && git format-patch -1 --stdout FETCH_HEAD,['congress/datasources/settings.py'],1,f22cbea172c5f918e0c22c479a5aa8f13350e994,x,"OS_USERNAME = ""admin"" OS_PASSWORD = ""dc5a32aecb066b4d2a03""OS_TENANT_NAME = ""admin""","OS_USERNAME = ""demo"" OS_PASSWORD = ""password""OS_TENANT_NAME = ""demo""",3,3
openstack%2Fneutron~master~I911ee986caef8fcf9b97ef622a03856d4351bee0,openstack/neutron,master,I911ee986caef8fcf9b97ef622a03856d4351bee0,Remove ignored do_request timeout argument,MERGED,2014-08-01 09:48:50.000000000,2014-08-14 18:26:30.000000000,2014-08-14 03:50:17.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 11279}, {'_account_id': 12614}]","[{'number': 1, 'created': '2014-08-01 09:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3501e7caa3d7f5fb7c0fd85fd33bbaa7e4c5ab4c', 'message': 'Remove ignored do_request timeout argument\n\nThe timeout to the underlying request was always self._request_timeout,\nregardless of the value of the do_request(timeout) arg provided.  Both\ncallers always pass timeout=self._request_timeout anyway, so just remove\nthis unused/misleading argument.\n\nChange-Id: I911ee986caef8fcf9b97ef622a03856d4351bee0\n'}, {'number': 2, 'created': '2014-08-02 11:56:28.000000000', 'files': ['neutron/plugins/oneconvergence/lib/plugin_helper.py', 'neutron/tests/unit/oneconvergence/test_plugin_helper.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/db053e705b9f125b5acc772922fabdf79314bce7', 'message': 'Remove ignored do_request timeout argument\n\nThe timeout to the underlying request was always self._request_timeout,\nregardless of the value of the do_request(timeout) arg provided.  Both\ncallers always pass timeout=self._request_timeout anyway, so just remove\nthis unused/misleading argument.\n\nChange-Id: I911ee986caef8fcf9b97ef622a03856d4351bee0\n'}]",0,111222,db053e705b9f125b5acc772922fabdf79314bce7,54,21,2,11279,,,0,"Remove ignored do_request timeout argument

The timeout to the underlying request was always self._request_timeout,
regardless of the value of the do_request(timeout) arg provided.  Both
callers always pass timeout=self._request_timeout anyway, so just remove
this unused/misleading argument.

Change-Id: I911ee986caef8fcf9b97ef622a03856d4351bee0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/111222/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/oneconvergence/lib/plugin_helper.py'],1,3501e7caa3d7f5fb7c0fd85fd33bbaa7e4c5ab4c,oneconv-timeout," def do_request(self, method, url=None, headers=None, data=None): headers=headers, data=data) headers=headers, data=body)"," def do_request(self, method, url=None, headers=None, data=None, timeout=10): headers=headers, data=data, timeout=self._request_timeout) headers=headers, data=body, timeout=self._request_timeout)",3,6
openstack%2Fnova~master~Ie19b39e99b223862ca86b9a54c5372b56e1f5d74,openstack/nova,master,Ie19b39e99b223862ca86b9a54c5372b56e1f5d74,"Revert ""libvirt: add version cap tied to gate CI testing""",MERGED,2014-07-30 18:57:34.000000000,2014-08-14 18:10:13.000000000,2014-08-14 07:09:16.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 782}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6172}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-30 18:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7de6ae9225556987475c1244bb2304e1fd2e39c', 'message': 'Revert ""libvirt: add version cap tied to gate CI testing""\n\nThis seems like it was really a policy change that should have had more community discussion. I think it\'s appropriate to revert this now and have this as a full community discussion about options here.\n\nThis reverts commit 3bfc25a74e9dfbeb664eecf89d959428713eb178.\n\nChange-Id: Ie19b39e99b223862ca86b9a54c5372b56e1f5d74\n'}, {'number': 2, 'created': '2014-07-30 19:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5ddf9715932cec59bcc01678715160a726a495f', 'message': 'Revert ""libvirt: add version cap tied to gate CI testing""\n\nThis seems like it was really a policy change that should have had more community discussion. \nI think it\'s appropriate to revert this now and have this as a full community discussion about \noptions here.\n\nThis reverts commit 3bfc25a74e9dfbeb664eecf89d959428713eb178.\n\nChange-Id: Ie19b39e99b223862ca86b9a54c5372b56e1f5d74\n'}, {'number': 3, 'created': '2014-07-30 22:18:37.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5dea55785a52b7edb383cf61fab2f65f2ae79a72', 'message': 'Revert ""libvirt: add version cap tied to gate CI testing""\n\nThis seems like it was really a policy change that should have had\nmore community discussion.  I think it\'s appropriate to revert this\nnow and have this as a full community discussion about options here.\n\nThis reverts commit 3bfc25a74e9dfbeb664eecf89d959428713eb178.\n\nChange-Id: Ie19b39e99b223862ca86b9a54c5372b56e1f5d74\n'}]",1,110754,5dea55785a52b7edb383cf61fab2f65f2ae79a72,58,19,3,2750,,,0,"Revert ""libvirt: add version cap tied to gate CI testing""

This seems like it was really a policy change that should have had
more community discussion.  I think it's appropriate to revert this
now and have this as a full community discussion about options here.

This reverts commit 3bfc25a74e9dfbeb664eecf89d959428713eb178.

Change-Id: Ie19b39e99b223862ca86b9a54c5372b56e1f5d74
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/110754/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py']",2,a7de6ae9225556987475c1244bb2304e1fd2e39c,libvirt-version-cap,," def test_min_version_cap(self): drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) with mock.patch.object(drvr._conn, 'getLibVersion') as mock_ver: mock_ver.return_value = utils.convert_version_to_int((1, 5, 0)) self.flags(version_cap=""2.0.0"", group=""libvirt"") self.assertTrue(drvr._has_min_version((1, 4, 0))) self.flags(version_cap=""1.3.0"", group=""libvirt"") self.assertFalse(drvr._has_min_version((1, 4, 0))) self.flags(version_cap="""", group=""libvirt"") self.assertTrue(drvr._has_min_version((1, 4, 0))) ",0,28
openstack%2Fneutron~master~I7bfe266288670fba0c90990bf350f43ef7829bad,openstack/neutron,master,I7bfe266288670fba0c90990bf350f43ef7829bad,Fix interface add for dvr with gateway,MERGED,2014-08-12 00:57:04.000000000,2014-08-14 18:05:25.000000000,2014-08-14 05:22:36.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9077}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10971}]","[{'number': 1, 'created': '2014-08-12 00:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3ebe1acb6f170c35f3a454a8324e8787827a085d', 'message': 'Fix interface add for dvr with gateway\n\nwhen a interface is added after router gateway set, external\nconnectivity using snat fails. Method internal_network_added(..)\nre-adding all the snat ports, with wrong cidr, instead of just\nadding the snat port for the new subnet.\n\nChange-Id: I7bfe266288670fba0c90990bf350f43ef7829bad\nCloses-bug: #1355087\n'}, {'number': 2, 'created': '2014-08-12 01:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/19d22b10022be8bd3eb5398046306acf5ad1fcd1', 'message': 'Fix interface add for dvr with gateway\n\nwhen an interface is added after router gateway set, external\nconnectivity using snat fails. Instead of just adding the snat port for\nthe new subnet, method internal_network_added(..) incorrectly re-adds\nall the snat ports with wrong cidr.\n\nMarking as WIP due to pending unit test.\n\nChange-Id: I7bfe266288670fba0c90990bf350f43ef7829bad\nCloses-bug: #1355087\n'}, {'number': 3, 'created': '2014-08-13 18:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f87f15e2859c78e1945f5256663d56e9ee3441f', 'message': 'Fix interface add for dvr with gateway\n\nwhen an interface is added after router gateway set, external\nconnectivity using snat fails. Instead of just adding the snat port for\nthe new subnet, method internal_network_added(..) incorrectly re-adds\nall the snat ports with wrong cidr.\n\nChange-Id: I7bfe266288670fba0c90990bf350f43ef7829bad\nCloses-bug: #1355087\n'}, {'number': 4, 'created': '2014-08-13 22:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/484db265f035def7915f59839af6038914a7b57e', 'message': 'Fix interface add for dvr with gateway\n\nwhen an interface is added after router gateway set, external\nconnectivity using snat fails. Instead of just adding the snat port for\nthe new subnet, method internal_network_added(..) incorrectly re-adds\nall the snat ports with wrong cidr.\n\nChange-Id: I7bfe266288670fba0c90990bf350f43ef7829bad\nCloses-bug: #1355087\n'}, {'number': 5, 'created': '2014-08-14 00:13:41.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/11ca12dd8752a7d8fc13027c21ee572233becb74', 'message': 'Fix interface add for dvr with gateway\n\nwhen an interface is added after router gateway set, external\nconnectivity using snat fails. Instead of just adding the snat port for\nthe new subnet, method internal_network_added(..) incorrectly re-adds\nall the snat ports with wrong cidr.\n\nChange-Id: I7bfe266288670fba0c90990bf350f43ef7829bad\nCloses-bug: #1355087\n'}]",11,113412,11ca12dd8752a7d8fc13027c21ee572233becb74,111,21,5,9077,,,0,"Fix interface add for dvr with gateway

when an interface is added after router gateway set, external
connectivity using snat fails. Instead of just adding the snat port for
the new subnet, method internal_network_added(..) incorrectly re-adds
all the snat ports with wrong cidr.

Change-Id: I7bfe266288670fba0c90990bf350f43ef7829bad
Closes-bug: #1355087
",git fetch https://review.opendev.org/openstack/neutron refs/changes/12/113412/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3_agent.py'],1,3ebe1acb6f170c35f3a454a8324e8787827a085d,snat_fix," sn_port = self._map_internal_interfaces(ri, port, snat_ports) if sn_port: self._snat_redirect_add(ri, sn_port['fixed_ips'][0] if self.conf.agent_mode == 'dvr_snat' and ( ri.router['gw_port_host'] == self.host): ns_name = self.get_snat_ns_name(ri.router['id']) self._set_subnet_info(sn_port) interface_name = ( self.get_snat_int_device_name(sn_port['id'])) self._internal_network_added(ns_name, sn_port['network_id'], sn_port['id'], internal_cidr, sn_port['mac_address'],"," snat_ip = self._map_internal_interfaces(ri, port, snat_ports) if snat_ip: self._snat_redirect_add(ri, snat_ip['fixed_ips'][0] if self.conf.agent_mode == 'dvr_snat' and ( ri.router['gw_port_host'] == self.host): ns_name = self.get_snat_ns_name(ri.router['id']) for port in snat_ports: self._set_subnet_info(port) interface_name = self.get_snat_int_device_name(port['id']) self._internal_network_added(ns_name, port['network_id'], port['id'], internal_cidr, port['mac_address'],",13,12
openstack%2Fnova~master~I4ba6a0f9c3b9c2ce0e1750f8414625235d01d422,openstack/nova,master,I4ba6a0f9c3b9c2ce0e1750f8414625235d01d422,VMware: implement get_host_ip_addr,MERGED,2014-08-13 15:10:28.000000000,2014-08-14 17:58:23.000000000,2014-08-14 17:05:08.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 8027}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-13 15:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a2b09eef4e90fef1c77fe865e17988214d67832', 'message': 'VMware: implement get_host_ip_addr\n\nThis patch fixes a regression caused by commit\n1deb31f85a8f5d1e261b2cf1eddc537a5da7f60b. The function get_host_ip_addr\nis indirectly used by tempest and if it is missing Minesweeper fails.\n\nChange-Id: I4ba6a0f9c3b9c2ce0e1750f8414625235d01d422\n'}, {'number': 2, 'created': '2014-08-13 15:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5527aa1e69a5a5107071f11d6cf1f85fec616310', 'message': 'VMware: implement get_host_ip_addr\n\nThis patch fixes a regression caused by commit\n1deb31f85a8f5d1e261b2cf1eddc537a5da7f60b. The function get_host_ip_addr\nis used by the resource_tracker and if it is not implemented all resize\noperations fail.\n\nChange-Id: I4ba6a0f9c3b9c2ce0e1750f8414625235d01d422\n'}, {'number': 3, 'created': '2014-08-13 16:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/235637d5947b0f83bd27a5fa55ad131172132209', 'message': 'VMware: implement get_host_ip_addr\n\nThis patch fixes a regression caused by commit\n1deb31f85a8f5d1e261b2cf1eddc537a5da7f60b. The function get_host_ip_addr\nis used by the resource_tracker and if it is not implemented all resize\noperations fail.\n\nCloses-bug: #1356449\n\nChange-Id: I4ba6a0f9c3b9c2ce0e1750f8414625235d01d422\n'}, {'number': 4, 'created': '2014-08-13 23:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13b53fa8c1fc38d2d0eaf104dd9804dd0e29e991', 'message': 'VMware: implement get_host_ip_addr\n\nThis patch fixes a regression caused by commit\n1deb31f85a8f5d1e261b2cf1eddc537a5da7f60b. The function get_host_ip_addr\nis used by the resource_tracker and if it is not implemented all resize\noperations fail.\n\nCloses-bug: #1356449\n\nChange-Id: I4ba6a0f9c3b9c2ce0e1750f8414625235d01d422\n'}, {'number': 5, 'created': '2014-08-14 01:12:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5114c93ea9e9151a46327b63df24b30bef6653dd', 'message': 'VMware: implement get_host_ip_addr\n\nThis patch fixes a regression caused by commit\n1deb31f85a8f5d1e261b2cf1eddc537a5da7f60b. The function get_host_ip_addr\nis used by the resource_tracker and if it is not implemented all resize\noperations fail.\n\nCloses-bug: #1356449\n\nChange-Id: I4ba6a0f9c3b9c2ce0e1750f8414625235d01d422\n'}, {'number': 6, 'created': '2014-08-14 05:43:26.000000000', 'files': ['nova/virt/vmwareapi/driver.py', 'nova/tests/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/06df067ab3fa4b3c6be63ad49741a114373cc1ad', 'message': 'VMware: implement get_host_ip_addr\n\nThis patch fixes a regression caused by commit\n1deb31f85a8f5d1e261b2cf1eddc537a5da7f60b. The function get_host_ip_addr\nis used by the resource_tracker and if it is not implemented all resize\noperations fail.\n\nAlso put back the check for missing host, user, password config options\nin the driver constructor.\n\nCloses-bug: #1356449\n\nChange-Id: I4ba6a0f9c3b9c2ce0e1750f8414625235d01d422\n'}]",8,113923,06df067ab3fa4b3c6be63ad49741a114373cc1ad,62,15,6,9172,,,0,"VMware: implement get_host_ip_addr

This patch fixes a regression caused by commit
1deb31f85a8f5d1e261b2cf1eddc537a5da7f60b. The function get_host_ip_addr
is used by the resource_tracker and if it is not implemented all resize
operations fail.

Also put back the check for missing host, user, password config options
in the driver constructor.

Closes-bug: #1356449

Change-Id: I4ba6a0f9c3b9c2ce0e1750f8414625235d01d422
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/113923/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/driver.py'],1,4a2b09eef4e90fef1c77fe865e17988214d67832,bug/1356449," def get_host_ip_addr(self): """"""Returns the IP address of the vCenter host."""""" return CONF.vmware.host_ip ",,4,0
openstack%2Fneutron~master~I42aeb48a062d35038116978d70c8dac4139a5583,openstack/neutron,master,I42aeb48a062d35038116978d70c8dac4139a5583,"l2pop: get_agent_ports: Don't yield (None, {})",MERGED,2014-08-11 03:56:54.000000000,2014-08-14 17:53:48.000000000,2014-08-14 17:53:47.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 704}, {'_account_id': 2711}, {'_account_id': 2888}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8213}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-11 03:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7f9d17a5d1332f14125fa90514a402d18252b9df', 'message': ""l2pop: get_agent_ports don't yield (None, {})\n\nThere's no point to yield None lvm with empty entries.\n\nChange-Id: I42aeb48a062d35038116978d70c8dac4139a5583\n""}, {'number': 2, 'created': '2014-08-11 05:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4cec0ce2bb6b76d1770d60e5b12d9fba808c13f4', 'message': ""l2pop: get_agent_ports: Don't yield (None, {})\n\nThere's no point to yield None lvm with empty entries.\n\nChange-Id: I42aeb48a062d35038116978d70c8dac4139a5583\n""}, {'number': 3, 'created': '2014-08-12 11:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb5284d927ded1d7b06e11f128d424af741514d9', 'message': ""l2pop: get_agent_ports: Don't yield (None, {})\n\nThere's no point to yield None lvm with empty entries.\n\nCloses-Bug: #1355759\nRelated: blueprint ofagent-l2pop\nChange-Id: I42aeb48a062d35038116978d70c8dac4139a5583\n""}, {'number': 4, 'created': '2014-08-13 08:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44463c6087c22c2006fcf7cf9c498ec4c5514a9a', 'message': ""l2pop: get_agent_ports: Don't yield (None, {})\n\nThere's no point to yield None lvm with empty entries.\n\nCloses-Bug: #1355759\nRelated: blueprint ofagent-l2pop\nChange-Id: I42aeb48a062d35038116978d70c8dac4139a5583\n""}, {'number': 5, 'created': '2014-08-13 23:35:52.000000000', 'files': ['neutron/tests/unit/agent/test_l2population_rpc.py', 'neutron/agent/l2population_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0125cf7815acb677b619905e2d9d258a9bae1c48', 'message': ""l2pop: get_agent_ports: Don't yield (None, {})\n\nThere's no point to yield None lvm with empty entries.\n\nCloses-Bug: #1355759\nRelated: blueprint ofagent-l2pop\nChange-Id: I42aeb48a062d35038116978d70c8dac4139a5583\n""}]",9,113159,0125cf7815acb677b619905e2d9d258a9bae1c48,117,30,5,6854,,,0,"l2pop: get_agent_ports: Don't yield (None, {})

There's no point to yield None lvm with empty entries.

Closes-Bug: #1355759
Related: blueprint ofagent-l2pop
Change-Id: I42aeb48a062d35038116978d70c8dac4139a5583
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/113159/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/test_l2population_rpc.py', 'neutron/agent/l2population_rpc.py']",2,7f9d17a5d1332f14125fa90514a402d18252b9df,bug/1355759, if lvm is None: continue agent_ports = values.get('ports'), agent_ports = values.get('ports') if lvm else {},3,2
openstack%2Fpython-openstackclient~master~I2ef2ddf428429c2baab38f9ee064eb372056ee91,openstack/python-openstackclient,master,I2ef2ddf428429c2baab38f9ee064eb372056ee91,Load balancer VIP CRUD,ABANDONED,2014-04-02 18:12:12.000000000,2014-08-14 17:47:32.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-04-02 18:12:12.000000000', 'files': ['openstackclient/network/v2_0/lb/vip.py', 'setup.cfg', 'openstackclient/tests/network/v2_0/lb/test_vip.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/82036c8b3e91c43c1f36c3d1ac7f3bab09538729', 'message': 'Load balancer VIP CRUD\n\nLoad balancer VIP create, delete, list, set and show\n\nChange-Id: I2ef2ddf428429c2baab38f9ee064eb372056ee91\nImplements: blueprint neutron\n'}]",0,84826,82036c8b3e91c43c1f36c3d1ac7f3bab09538729,3,1,1,8736,,,0,"Load balancer VIP CRUD

Load balancer VIP create, delete, list, set and show

Change-Id: I2ef2ddf428429c2baab38f9ee064eb372056ee91
Implements: blueprint neutron
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/26/84826/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/network/v2_0/lb/vip.py', 'setup.cfg', 'openstackclient/tests/network/v2_0/lb/test_vip.py']",3,82036c8b3e91c43c1f36c3d1ac7f3bab09538729,bp/neutron,"# Copyright 2013 OpenStack, LLC. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # from openstackclient.network.v2_0.lb import vip from openstackclient.tests.network import common class TestCreateLbVip(common.TestNetworkBase): def test_get_parser_nothing(self): given = ""--protocol-port 33 --protocol HTTP --subnet-id 33"" + \ "" pool1 vip1"" + self.given_default_show_options() parsed = self.given_args(vip.CreateVip, given) self.assertEqual('vip1', parsed.name) self.assertEqual('pool1', parsed.pool_id) self.assertEqual('33', parsed.protocol_port) self.assertEqual('HTTP', parsed.protocol) self.assertEqual('33', parsed.subnet_id) self.assertEqual(None, parsed.address) self.assertEqual(True, parsed.admin_state) self.assertEqual(None, parsed.connection_limit) self.assertEqual(None, parsed.description) self.assertEqual(None, parsed.tenant_id) self.then_default_show_options(parsed) def test_get_parser_all(self): given = ""--protocol-port 44 --protocol TCP --subnet-id 99"" + \ "" --address 127.0.0.1 --admin-state-down"" + \ "" --connection-limit 5 --description wow"" + \ "" pool2 too --project sneed "" given += self.given_all_show_options() parsed = self.given_args(vip.CreateVip, given) self.assertEqual('too', parsed.name) self.assertEqual('pool2', parsed.pool_id) self.assertEqual('44', parsed.protocol_port) self.assertEqual('TCP', parsed.protocol) self.assertEqual('99', parsed.subnet_id) self.assertEqual('127.0.0.1', parsed.address) self.assertEqual(False, parsed.admin_state) self.assertEqual('5', parsed.connection_limit) self.assertEqual('wow', parsed.description) self.assertEqual('sneed', parsed.tenant_id) self.then_all_show_options(parsed) class TestDeleteLbVip(common.TestNetworkBase): def test_get_parser_nothing(self): parsed = self.given_args(vip.DeleteVip, ""noo"") self.assertEqual('noo', parsed.identifier) class TestListLbVip(common.TestNetworkBase): def test_get_parser_nothing(self): given = """" + self.given_default_list_options() parsed = self.given_args(vip.ListVip, given) self.assertEqual(False, parsed.show_details) self.then_default_list_options(parsed) def test_get_parser_all(self): given = ""--long"" + self.given_all_list_options() parsed = self.given_args(vip.ListVip, given) self.assertEqual(True, parsed.show_details) self.then_all_list_options(parsed) class TestSetLbVip(common.TestNetworkBase): def test_get_parser_nothing(self): parsed = self.given_args(vip.SetVip, ""noo"") self.assertEqual('noo', parsed.identifier) class TestShowLbVip(common.TestNetworkBase): def test_get_parser_nothing(self): given = ""noo"" + self.given_default_show_options() parsed = self.given_args(vip.ShowVip, given) self.assertEqual('noo', parsed.identifier) self.then_default_show_options(parsed) def test_get_parser_all(self): given = ""too"" + self.given_all_show_options() parsed = self.given_args(vip.ShowVip, given) self.assertEqual('too', parsed.identifier) self.then_all_show_options(parsed) ",,191,0
openstack%2Fpython-openstackclient~master~Ie9e69c25122cd2a13ac65a3208a86a58bc7732c8,openstack/python-openstackclient,master,Ie9e69c25122cd2a13ac65a3208a86a58bc7732c8,Load balancer member CRUD,ABANDONED,2014-04-02 18:04:09.000000000,2014-08-14 17:47:19.000000000,,"[{'_account_id': 3}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-04-02 18:04:09.000000000', 'files': ['openstackclient/network/v2_0/lb/member.py', 'openstackclient/network/v2_0/lb/__init__.py', 'openstackclient/tests/network/v2_0/lb/test_member.py', 'openstackclient/tests/network/v2_0/lb/__init__.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/915459f04dc55ecea0ab066c7f795e6690e73454', 'message': 'Load balancer member CRUD\n\nLoad balancer member create, delete, list, show and set.\n\nChange-Id: Ie9e69c25122cd2a13ac65a3208a86a58bc7732c8\nImplements: blueprint neutron\n'}]",1,84821,915459f04dc55ecea0ab066c7f795e6690e73454,8,2,1,8736,,,0,"Load balancer member CRUD

Load balancer member create, delete, list, show and set.

Change-Id: Ie9e69c25122cd2a13ac65a3208a86a58bc7732c8
Implements: blueprint neutron
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/21/84821/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/network/v2_0/lb/member.py', 'openstackclient/network/v2_0/lb/__init__.py', 'openstackclient/tests/network/v2_0/lb/test_member.py', 'openstackclient/tests/network/v2_0/lb/__init__.py', 'setup.cfg']",5,915459f04dc55ecea0ab066c7f795e6690e73454,bp/neutron, lb_member_create = openstackclient.network.v2_0.lb.member:CreateMember lb_member_delete = openstackclient.network.v2_0.lb.member:DeleteMember lb_member_list = openstackclient.network.v2_0.lb.member:ListMember lb_member_set = openstackclient.network.v2_0.lb.member:SetMember lb_member_show = openstackclient.network.v2_0.lb.member:ShowMember,,196,1
openstack%2Fbarbican~master~I101e9fc1fa9fef59494eeafee5296d85be5ab8fd,openstack/barbican,master,I101e9fc1fa9fef59494eeafee5296d85be5ab8fd,First attempt at adding the symantecssl library,MERGED,2014-07-28 22:06:42.000000000,2014-08-14 17:45:47.000000000,2014-08-14 17:45:47.000000000,"[{'_account_id': 3}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7874}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 11661}, {'_account_id': 11662}, {'_account_id': 11970}]","[{'number': 1, 'created': '2014-07-28 22:06:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/4e7dfcc202f5f950c73f109cd7cfe7b326c9a5fa', 'message': 'First attempt at adding the symantecssl library\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 2, 'created': '2014-07-28 22:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/d18e533e0caee2f3818a4dccf9a3e870c0fa8a1c', 'message': 'First attempt at adding the symantecssl library\n\nAttempted to implement the functions to create, modify, check status, and cancel certificate orders using the symantecssl library. \n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 3, 'created': '2014-07-28 22:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3edc9f617f69b5e6e8fbc426cedb6f16d9e0c058', 'message': 'First attempt at adding the symantecssl library\n\nAttempted to implement the functions to create, \nmodify, check status, and cancel certificate orders \nusing the symantecssl library. \n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 4, 'created': '2014-07-30 16:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/197ce5856be2cdfafb3b0492e99bce777867b57d', 'message': 'First attempt at adding the symantecssl library\n\nAttempted to implement the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 5, 'created': '2014-07-30 20:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f87f1efa76012f6a15ad3ae3af4e901b61fc8fcd', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 6, 'created': '2014-08-01 18:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/6291fdec6e89be6ebb8904ebb0af536c80ba2542', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 7, 'created': '2014-08-01 18:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/8fc1ee4585f0624b6bc7ef112bff301ce4e3abec', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 8, 'created': '2014-08-01 19:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/a98bf24dbb54a9495d627799455710867921473b', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 9, 'created': '2014-08-04 18:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/fdac3a92974bbb0dde5d65bb878a13baf53b4aaa', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 10, 'created': '2014-08-06 21:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/181905d7961a124b562fd40baecfb9960473ae6f', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 11, 'created': '2014-08-06 21:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/207c0b1495c79e33c1dc1d9b3da28e3de68bc1aa', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 12, 'created': '2014-08-07 15:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/33bbf3170890ec4065059381a3ba8c185cd72650', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 13, 'created': '2014-08-07 18:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/faf5e29c70552b23e93f6db1e16eecbd901a39c4', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 14, 'created': '2014-08-07 20:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/88c598b19527a16396ad0e8157e0200462dcbf4a', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 15, 'created': '2014-08-08 18:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/657a3bc656bfe43113418ce849fefb83a153c50d', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 16, 'created': '2014-08-08 20:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3a4621cc84ffcff48e3a75ef688c1f1e9c2eba31', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 17, 'created': '2014-08-08 20:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/4013377ee737eb6fd96f12084e462dfaae43396a', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 18, 'created': '2014-08-08 21:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/67a8229a34af8d7dff62b6dce6e7ab422b3f0e3f', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 19, 'created': '2014-08-08 21:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c3b51cfaa81ce1bb9ff33a96232e381ab9b43268', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}, {'number': 20, 'created': '2014-08-14 15:43:46.000000000', 'files': ['barbican/plugin/symantec.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/c5e38dfbbe672885a849e31aad94be3dbbeaa93c', 'message': 'First attempt at adding the symantecssl library\n\nImplemented the functions to create,\nmodify, check status, and cancel certificate orders\nusing the symantecssl library.\n\nChange-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd\n'}]",80,110144,c5e38dfbbe672885a849e31aad94be3dbbeaa93c,103,10,20,11661,,,0,"First attempt at adding the symantecssl library

Implemented the functions to create,
modify, check status, and cancel certificate orders
using the symantecssl library.

Change-Id: I101e9fc1fa9fef59494eeafee5296d85be5ab8fd
",git fetch https://review.opendev.org/openstack/barbican refs/changes/44/110144/20 && git format-patch -1 --stdout FETCH_HEAD,['barbican/plugin/symantec.py'],1,4e7dfcc202f5f950c73f109cd7cfe7b326c9a5fa,wire_in_symantecssl,"This plugin supports the following state machine.from symantecssl import Symantec api = Symantec(plugin_meta[""username""], plugin_meta[""password""], plugin_meta[""url""]) """"""Needs several args from either order_meta or plugin_meta: partnercode productcode partnerorderid organization name address line 1 city region postalcode counter cont. """""" try: # From order_meta and plugin_meta: order_data = api.order( partnercode=order_meta[], productcode=order_meta[], partnerorderid=order_meta[], organizationname=order_meta[], addressline1=order_meta[], city=order_meta[], region=order_meta[], postalcode=order_meta[], country=order_meta[], organizationphone=order_meta[], validityperiod=order_meta[], servercount=order_meta[], webservertype=order_meta[], admincontactfirstname=order_meta[], admincontactlastname=order_meta[], admincontactphone=order_meta[], admincontactemail=order_meta[], admincontacttitle=order_meta[], admincontactaddressline1=order_meta[], admincontactaddressline2=order_meta[], admincontactcity=order_meta[], admincontactregion=order_meta[], admincontactpostalcode=order_meta[], admincontactcountry=order_meta[], techsameasadmin=order_meta[], # Or tech contact info billsameastech=order_meta[], # Or bill info approveremail=order_meta[], csr=order_meta[], ) plugin_meta[""GeotrustOrderID""] = order_data[""GeotrustOrderID""] plugin_meta[""PartnerOrderID""] = order_data[""PartnerOrderID""] return True, None, None except SymantecError as e: # Maybe be able to retry on error code -1001 return False, e, False # Some kind of exception with canretry = True can go here? except: return False, sys.exc_info()[0], False def _ca_get_order_status(self, order_meta, plugin_meta): """""" INFO NEEDED FOR getOrderByPartnerOrderID: partnerOrderId partnerCode """""" api = Symantec(plugin_meta[""username""], plugin_meta[""password""], plugin_meta[""url""]) try: order_data = api.get_order_by_partner_order_id( partnerorderid=plugin_meta[""PartnerOrderID""], partnercode=plugin_meta[""PartnerCode""], ) return True, None, None, order_data except SymantecError as e: return False, e, False def _ca_modify_order(self, order_meta, plugin_meta): """""" INFO NEEDED FOR modifyOrder: partnerorderid partnercode productcode modifyorderoperation """""" api = Symantec(plugin_meta[""username""], plugin_meta[""password""], plugin_meta[""url""]) try: order_data = api.modify_order( partnerorderid=plugin_meta[""PluginOrderID""], partnercode=plugin_meta[""PartnerCode""], productcode=order_meta[""productcode""], modifyorderoperation=order_meta[""modifyorderoperation""], ) return True, None, None except SymantecError as e: return False, e, False def _ca_cancel_order(self, order_meta, plugin_meta): """""" INFO NEEDED FOR modifyOrder when cancelling: partnerorderid partnercode productcode modifyoperation=cancel """""" api = Symantec(plugin_meta[""username""], plugin_meta[""password""], plugin_meta[""url""]) try: order_data = api.modify_order( partnerorderid=plugin_meta[""PartnerOrderID""], partnercode=plugin_meta[""PartnerCode""], productcode=order_meta[""ProductCode""], modifyorderoperation=cancel, ) return True, None, None except SymantecError as e: return False, e, False","This pl ugin supports the following state machine. return True, None, None",118,2
openstack%2Fpython-openstackclient~master~I72a6a90b28a185724d6fb6da5a751e09a0698fcc,openstack/python-openstackclient,master,I72a6a90b28a185724d6fb6da5a751e09a0698fcc,Firewall CRUD,ABANDONED,2014-04-02 16:34:32.000000000,2014-08-14 17:43:45.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-04-02 16:34:32.000000000', 'files': ['openstackclient/tests/network/v2_0/fw/__init__.py', 'openstackclient/network/v2_0/fw/firewall.py', 'openstackclient/tests/network/v2_0/fw/test_firewall.py', 'setup.cfg', 'openstackclient/network/v2_0/fw/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e567577faab2a87eddd96376716a54dbc73681d0', 'message': 'Firewall CRUD\n\nFirewall create, delete, list, set and show\n\nChange-Id: I72a6a90b28a185724d6fb6da5a751e09a0698fcc\nImplements: blueprint neutron\n'}]",0,84788,e567577faab2a87eddd96376716a54dbc73681d0,3,1,1,8736,,,0,"Firewall CRUD

Firewall create, delete, list, set and show

Change-Id: I72a6a90b28a185724d6fb6da5a751e09a0698fcc
Implements: blueprint neutron
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/88/84788/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2_0/fw/__init__.py', 'openstackclient/network/v2_0/fw/firewall.py', 'openstackclient/tests/network/v2_0/fw/test_firewall.py', 'setup.cfg', 'openstackclient/network/v2_0/fw/__init__.py']",5,e567577faab2a87eddd96376716a54dbc73681d0,bp/neutron,"# Copyright 2012-2013 OpenStack, LLC. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # ",,207,0
openstack%2Fpython-openstackclient~master~I808e15e82f4ae66861e9bb0c1c9cab82b7ead554,openstack/python-openstackclient,master,I808e15e82f4ae66861e9bb0c1c9cab82b7ead554,VPN IKE policy CRUD,ABANDONED,2014-04-02 18:24:12.000000000,2014-08-14 17:41:50.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-04-02 18:24:12.000000000', 'files': ['openstackclient/tests/network/v2_0/vpn/test_ikepolicy.py', 'openstackclient/tests/network/v2_0/vpn/__init__.py', 'openstackclient/network/v2_0/vpn/__init__.py', 'openstackclient/network/v2_0/vpn/ikepolicy.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9b5952883f5256ce74443486bb313d67c479a852', 'message': 'VPN IKE policy CRUD\n\nVPN IKE policy create, delete, list, set and show\n\nChange-Id: I808e15e82f4ae66861e9bb0c1c9cab82b7ead554\nImplements: blueprint neutron\n'}]",0,84831,9b5952883f5256ce74443486bb313d67c479a852,3,1,1,8736,,,0,"VPN IKE policy CRUD

VPN IKE policy create, delete, list, set and show

Change-Id: I808e15e82f4ae66861e9bb0c1c9cab82b7ead554
Implements: blueprint neutron
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/31/84831/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2_0/vpn/test_ikepolicy.py', 'openstackclient/tests/network/v2_0/vpn/__init__.py', 'openstackclient/network/v2_0/vpn/__init__.py', 'openstackclient/network/v2_0/vpn/ikepolicy.py', 'setup.cfg']",5,9b5952883f5256ce74443486bb313d67c479a852,bp/neutron, vpn_ikepolicy_create = openstackclient.network.v2_0.vpn.ikepolicy:CreateIkepolicy vpn_ikepolicy_delete = openstackclient.network.v2_0.vpn.ikepolicy:DeleteIkepolicy vpn_ikepolicy_list =openstackclient.network.v2_0.vpn.ikepolicy:ListIkepolicy vpn_ikepolicy_set =openstackclient.network.v2_0.vpn.ikepolicy:SetIkepolicy vpn_ikepolicy_show =openstackclient.network.v2_0.vpn.ikepolicy:ShowIkepolicy,,207,0
openstack%2Fpython-openstackclient~master~I2156dd17a44cb8e940098c7bacb0606a85f6455d,openstack/python-openstackclient,master,I2156dd17a44cb8e940098c7bacb0606a85f6455d,VPN IPSec Policy CRUD,ABANDONED,2014-04-02 18:35:48.000000000,2014-08-14 17:41:44.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-04-02 18:35:48.000000000', 'files': ['openstackclient/network/v2_0/vpn/ipsecpolicy.py', 'openstackclient/tests/network/v2_0/vpn/test_ipsecpolicy.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e7cb83f289fbcc331d77785da0182e5992a78b3c', 'message': 'VPN IPSec Policy CRUD\n\nVPN IPSec policy create, list, delete, set and show\n\nChange-Id: I2156dd17a44cb8e940098c7bacb0606a85f6455d\nImplements: blueprint neutron\n'}]",0,84835,e7cb83f289fbcc331d77785da0182e5992a78b3c,3,1,1,8736,,,0,"VPN IPSec Policy CRUD

VPN IPSec policy create, list, delete, set and show

Change-Id: I2156dd17a44cb8e940098c7bacb0606a85f6455d
Implements: blueprint neutron
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/35/84835/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/network/v2_0/vpn/ipsecpolicy.py', 'openstackclient/tests/network/v2_0/vpn/test_ipsecpolicy.py', 'setup.cfg']",3,e7cb83f289fbcc331d77785da0182e5992a78b3c,bp/neutron, vpn_ipsecpolicy_create = openstackclient.network.v2_0.vpn.ipsecpolicy:CreateIpsecpolicy vpn_ipsecpolicy_delete = openstackclient.network.v2_0.vpn.ipsecpolicy:DeleteIpsecpolicy vpn_ipsecpolicy_list =openstackclient.network.v2_0.vpn.ipsecpolicy:ListIpsecpolicy vpn_ipsecpolicy_set =openstackclient.network.v2_0.vpn.ipsecpolicy:SetIpsecpolicy vpn_ipsecpolicy_show =openstackclient.network.v2_0.vpn.ipsecpolicy:ShowIpsecpolicy,,205,0
openstack%2Fpython-openstackclient~master~Idaa7c2353212115a699585e423b61db6a23da6c9,openstack/python-openstackclient,master,Idaa7c2353212115a699585e423b61db6a23da6c9,VPN service CRUD,ABANDONED,2014-04-02 18:48:23.000000000,2014-08-14 17:41:38.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-04-02 18:48:23.000000000', 'files': ['openstackclient/network/v2_0/vpn/service.py', 'setup.cfg', 'openstackclient/tests/network/v2_0/vpn/test_service.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/244cc725252e62bd61fbea6e010e0bccf57bf4e1', 'message': 'VPN service CRUD\n\nVPN service create, delete, list, set and show\n\nChange-Id: Idaa7c2353212115a699585e423b61db6a23da6c9\nImplements: blueprint neutron\n'}]",0,84836,244cc725252e62bd61fbea6e010e0bccf57bf4e1,3,1,1,8736,,,0,"VPN service CRUD

VPN service create, delete, list, set and show

Change-Id: Idaa7c2353212115a699585e423b61db6a23da6c9
Implements: blueprint neutron
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/36/84836/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/network/v2_0/vpn/service.py', 'setup.cfg', 'openstackclient/tests/network/v2_0/vpn/test_service.py']",3,244cc725252e62bd61fbea6e010e0bccf57bf4e1,bp/neutron,"# Copyright 2013 OpenStack, LLC. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # from openstackclient.network.v2_0.vpn import service from openstackclient.tests.network import common class TestCreateService(common.TestNetworkBase): def test_get_parser_nothing(self): given = ""noo roo soo"" + self.given_default_show_options() parsed = self.given_args(service.CreateService, given) self.assertEqual('noo', parsed.name) self.assertEqual('roo', parsed.router) self.assertEqual('soo', parsed.subnet) self.assertEqual(True, parsed.admin_state) self.assertEqual(None, parsed.description) self.assertEqual(None, parsed.tenant_id) self.then_default_show_options(parsed) def test_get_parser_all(self): given = ""too roo soo --admin-state-down --description doo"" +\ "" --project sneed"" given += self.given_all_show_options() parsed = self.given_args(service.CreateService, given) self.assertEqual('too', parsed.name) self.assertEqual('roo', parsed.router) self.assertEqual('soo', parsed.subnet) self.assertEqual(False, parsed.admin_state) self.assertEqual('doo', parsed.description) self.assertEqual('sneed', parsed.tenant_id) self.then_all_show_options(parsed) class TestDeleteService(common.TestNetworkBase): def test_get_parser_nothing(self): parsed = self.given_args(service.DeleteService, ""noo"") self.assertEqual('noo', parsed.identifier) class TestListService(common.TestNetworkBase): def test_get_parser_nothing(self): given = """" + self.given_default_list_options() parsed = self.given_args(service.ListService, given) self.assertEqual(False, parsed.show_details) self.then_default_list_options(parsed) def test_get_parser_all(self): given = ""--long"" + self.given_all_list_options() parsed = self.given_args(service.ListService, given) self.assertEqual(True, parsed.show_details) self.then_all_list_options(parsed) class TestSetService(common.TestNetworkBase): def test_get_parser_nothing(self): parsed = self.given_args(service.SetService, ""noo"") self.assertEqual('noo', parsed.identifier) class TestShowService(common.TestNetworkBase): def test_get_parser_nothing(self): given = ""noo"" + self.given_default_show_options() parsed = self.given_args(service.ShowService, given) self.assertEqual('noo', parsed.identifier) self.then_default_show_options(parsed) def test_get_parser_all(self): given = ""too "" + self.given_all_show_options() parsed = self.given_args(service.ShowService, given) self.assertEqual('too', parsed.identifier) self.then_all_show_options(parsed) ",,162,0
openstack%2Fcongress~master~I221921c656a0425c4611878a165d65305d0c60d2,openstack/congress,master,I221921c656a0425c4611878a165d65305d0c60d2,Simplify prepare-devstack script,MERGED,2014-08-12 20:00:06.000000000,2014-08-14 17:23:25.000000000,2014-08-14 17:23:24.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-08-12 20:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/989d92d34e6041ee069ea90a6ca3d5fd28ff1272', 'message': ""Simplify prepare-devstack script\n\nPreviously one was required to clone the congress source tree then\nrun prepare-devstack.sh and then stack.sh. After stack.sh completed one\nmight be left with two congress directories depending if they put it\nin $DIST (/opt/stack) which could require them creating this directory and\nchowning it to themselves. In addition, it would require you to install\nrealpath as a dependency. Instead of doing this we've updated this script to\njust download the required files without haveing to clone the initial congress\nrepo.\n\nChange-Id: I221921c656a0425c4611878a165d65305d0c60d2\ncloses-bug: 1356022\n""}, {'number': 2, 'created': '2014-08-12 21:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/290d68eda9c5b0ef0a3fa96f471e825a169f5f21', 'message': ""Simplify prepare-devstack script\n\nPreviously one was required to clone the congress source tree then\nrun prepare-devstack.sh and then stack.sh. After stack.sh completed one\nmight be left with two congress directories depending if they put it\nin $DIST (/opt/stack) which could require them creating this directory and\nchowning it to themselves. In addition, it would require you to install\nrealpath as a dependency. Instead of doing this we've updated this script to\njust download the required files without haveing to clone the initial congress\nrepo.\n\nChange-Id: I221921c656a0425c4611878a165d65305d0c60d2\ncloses-bug: 1356022\n""}, {'number': 3, 'created': '2014-08-14 17:09:29.000000000', 'files': ['contrib/devstack/README.rst', 'contrib/devstack/prepare_devstack.sh'], 'web_link': 'https://opendev.org/openstack/congress/commit/cfe6ba1b36888a3a83e5e1bfc836918148c10f58', 'message': ""Simplify prepare-devstack script\n\nPreviously one was required to clone the congress source tree then\nrun prepare-devstack.sh and then stack.sh. After stack.sh completed one\nmight be left with two congress directories depending if they put it\nin $DIST (/opt/stack) which could require them creating this directory and\nchowning it to themselves. In addition, it would require you to install\nrealpath as a dependency. Instead of doing this we've updated this script to\njust download the required files without haveing to clone the initial congress\nrepo.\n\nChange-Id: I221921c656a0425c4611878a165d65305d0c60d2\ncloses-bug: 1356022\n""}]",2,113631,cfe6ba1b36888a3a83e5e1bfc836918148c10f58,19,4,3,4395,,,0,"Simplify prepare-devstack script

Previously one was required to clone the congress source tree then
run prepare-devstack.sh and then stack.sh. After stack.sh completed one
might be left with two congress directories depending if they put it
in $DIST (/opt/stack) which could require them creating this directory and
chowning it to themselves. In addition, it would require you to install
realpath as a dependency. Instead of doing this we've updated this script to
just download the required files without haveing to clone the initial congress
repo.

Change-Id: I221921c656a0425c4611878a165d65305d0c60d2
closes-bug: 1356022
",git fetch https://review.opendev.org/openstack/congress refs/changes/31/113631/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/devstack/README.rst', 'contrib/devstack/prepare_devstack.sh']",2,989d92d34e6041ee069ea90a6ca3d5fd28ff1272,bug/1356022,"DEVSTACKDIR=${DEVSTACKDIR:-""devstack""} if [ ! -d $DEVSTACKDIR ]; then echo ""Cannot find devstack directory: $DEVSTACKDIR"" exit 1 fi wget -O - http://git.openstack.org/cgit/stackforge/congress/plain/contrib/devstack/lib/congress > $DEVSTACKDIR/lib/congress wget -O - http://git.openstack.org/cgit/stackforge/congress/plain/contrib/devstack/extras.d/70-congress.sh > $DEVSTACKDIR/extras.d/70-congress.sh cat - <<-EOF >> $DEVSTACKDIR/localrc enable_service congress","CONGRESSDIR=$(realpath $(dirname $0)/../..) INSTALLDIR=${INSTALLDIR:-/opt/stack} cp $CONGRESSDIR/contrib/devstack/extras.d/70-congress.sh $INSTALLDIR/devstack/extras.d/ cp $CONGRESSDIR/contrib/devstack/lib/congress $INSTALLDIR/devstack/lib/ cat - <<-EOF >> $INSTALLDIR/devstack/localrc ENABLED_SERVICES+=,congress",14,11
openstack%2Fceilometer~master~I90e93bd426ac86eff4e22d5767d89660474616db,openstack/ceilometer,master,I90e93bd426ac86eff4e22d5767d89660474616db,Imported Translations from Transifex,MERGED,2014-08-14 06:08:52.000000000,2014-08-14 17:14:04.000000000,2014-08-14 17:14:03.000000000,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 7478}]","[{'number': 1, 'created': '2014-08-14 06:08:52.000000000', 'files': ['ceilometer/locale/ceilometer.pot', 'ceilometer/locale/en_US/LC_MESSAGES/ceilometer.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7903524100378b68a1bb93f94c09dd3d04fe903f', 'message': 'Imported Translations from Transifex\n\nChange-Id: I90e93bd426ac86eff4e22d5767d89660474616db\n'}]",0,114132,7903524100378b68a1bb93f94c09dd3d04fe903f,8,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I90e93bd426ac86eff4e22d5767d89660474616db
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/32/114132/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/locale/ceilometer.pot', 'ceilometer/locale/en_US/LC_MESSAGES/ceilometer.po']",2,7903524100378b68a1bb93f94c09dd3d04fe903f,transifex/translations,"""POT-Creation-Date: 2014-08-14 06:08+0000\n""#: ceilometer/storage/impl_hbase.py:154#: ceilometer/storage/impl_hbase.py:169#: ceilometer/storage/impl_hbase.py:177#: ceilometer/storage/impl_hbase.py:181#: ceilometer/storage/impl_hbase.py:192#: ceilometer/compute/virt/libvirt/inspector.py:129#: ceilometer/compute/virt/libvirt/inspector.py:164#: ceilometer/compute/virt/vmware/inspector.py:89 #: ceilometer/compute/virt/vmware/inspector.py:106 #: ceilometer/compute/virt/vmware/inspector.py:138 #: ceilometer/compute/virt/vmware/inspector.py:151#: ceilometer/storage/impl_hbase.py:291 ceilometer/storage/impl_hbase.py:340#: ceilometer/storage/impl_hbase.py:333#: ceilometer/storage/impl_hbase.py:381#: ceilometer/storage/impl_hbase.py:528","""POT-Creation-Date: 2014-08-04 06:08+0000\n""#: ceilometer/storage/impl_hbase.py:155#: ceilometer/storage/impl_hbase.py:170#: ceilometer/storage/impl_hbase.py:178#: ceilometer/storage/impl_hbase.py:182#: ceilometer/storage/impl_hbase.py:193#: ceilometer/compute/virt/libvirt/inspector.py:64 #, python-format msgid ""Connecting to libvirt: %s"" msgstr """" #: ceilometer/compute/virt/libvirt/inspector.py:77 msgid ""Connection to libvirt broke"" msgstr """" #: ceilometer/compute/virt/libvirt/inspector.py:117#: ceilometer/compute/virt/libvirt/inspector.py:152#: ceilometer/compute/virt/vmware/inspector.py:88 #: ceilometer/compute/virt/vmware/inspector.py:105 #: ceilometer/compute/virt/vmware/inspector.py:137 #: ceilometer/compute/virt/vmware/inspector.py:150#: ceilometer/storage/impl_hbase.py:295 ceilometer/storage/impl_hbase.py:344#: ceilometer/storage/impl_hbase.py:337#: ceilometer/storage/impl_hbase.py:385#: ceilometer/storage/impl_hbase.py:532",33,51
openstack%2Fneutron~master~Ic9393319e55f71d681124bd3052e939724ebab6b,openstack/neutron,master,Ic9393319e55f71d681124bd3052e939724ebab6b,Fix session's InvalidRequestError because of nested rollback,MERGED,2014-08-08 00:35:56.000000000,2014-08-14 17:10:17.000000000,2014-08-14 17:10:15.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-08 00:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6691331cdeb83e2ec44c1197c62c02aecae419cb', 'message': ""Fix session's InvalidRequestError because of nested rollback\n\nRace conditions may cause DBDuplicateEntry exceptions that\nrequire a transaction to be rollbacked back, and yet make\nthe whole operation succeed. A classic example is what has\nbeen solved in commit 5575f3b.\n\nHowever, if the rollback is done in a nested transaction,\nthe above mentioned exception is raised. To address the\nproblem, we could use savepoints by means of sqlalchemy's\nbegin_nested(); this would allow us to schedule more than\none router at once, and yet rollback only on the failure\nof a single bind operation. Even though this approach is\npreferable, it causes quite a bit of changes to make sure\nit works for unit tests and sqlite; it may also require\nthat certain DBMS, or certain DB backend configurations,\nsupport savepoints.\n\nThat said, this specific case can be addressed by removing\nthe extra nesting (which is effectively redundant), thus\nmaking the change rather trivial.\n\nCloses-bug: #1354072\n\nChange-Id: Ic9393319e55f71d681124bd3052e939724ebab6b\n""}, {'number': 2, 'created': '2014-08-08 23:10:16.000000000', 'files': ['neutron/scheduler/l3_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4eaa0520990f30519aaa073f352541f17b0577b', 'message': ""Fix session's InvalidRequestError because of nested rollback\n\nThis patch addresses the issue by removing the extra nesting\n(which is effectively redundant).\n\nThe longer story about this patch is the following:\n\nRace conditions may cause DBDuplicateEntry exceptions that\nrequire a transaction to be rollbacked back, and yet make\nthe whole operation succeed. A classic example is what has\nbeen solved in commit fbc6b99. If the rollback is done in a\nnested transaction, the above mentioned exception is raised.\n\nTo address the problem, we could use savepoints by means of\nsqlalchemy's begin_nested(); Even though this approach is\npreferable, it causes quite a bit of changes in the unit\ntests (because of sqlite); it may also require that certain\nDBMS, or certain DB backend configurations, support savepoints.\n\nIn the end, the simpler approach was chosen.\n\nCloses-bug: #1354072\n\nChange-Id: Ic9393319e55f71d681124bd3052e939724ebab6b\n""}]",15,112740,b4eaa0520990f30519aaa073f352541f17b0577b,79,23,2,748,,,0,"Fix session's InvalidRequestError because of nested rollback

This patch addresses the issue by removing the extra nesting
(which is effectively redundant).

The longer story about this patch is the following:

Race conditions may cause DBDuplicateEntry exceptions that
require a transaction to be rollbacked back, and yet make
the whole operation succeed. A classic example is what has
been solved in commit fbc6b99. If the rollback is done in a
nested transaction, the above mentioned exception is raised.

To address the problem, we could use savepoints by means of
sqlalchemy's begin_nested(); Even though this approach is
preferable, it causes quite a bit of changes in the unit
tests (because of sqlite); it may also require that certain
DBMS, or certain DB backend configurations, support savepoints.

In the end, the simpler approach was chosen.

Closes-bug: #1354072

Change-Id: Ic9393319e55f71d681124bd3052e939724ebab6b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/112740/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/scheduler/l3_agent_scheduler.py'],1,6691331cdeb83e2ec44c1197c62c02aecae419cb,bug/1354072," return self._schedule_router( plugin, context, router_id, candidates=candidates, hints=hints) return self._schedule_router( plugin, context, router_id, candidates=candidates, hints=hints)"," with context.session.begin(subtransactions=True): return self._schedule_router( plugin, context, router_id, candidates=candidates, hints=hints) with context.session.begin(subtransactions=True): return self._schedule_router( plugin, context, router_id, candidates=candidates, hints=hints)",4,6
openstack%2Fcongress~master~Ia2bacad9ad6290220f0a51f16a8fbd7665d60545,openstack/congress,master,Ia2bacad9ad6290220f0a51f16a8fbd7665d60545,Make openstack datasource settings configurable in devstack,ABANDONED,2014-08-12 19:32:44.000000000,2014-08-14 17:09:01.000000000,,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-08-12 19:32:44.000000000', 'files': ['contrib/devstack/lib/congress'], 'web_link': 'https://opendev.org/openstack/congress/commit/437d77dd80d855ce5fca0f959ecbe51ff2a2a75b', 'message': ""Make openstack datasource settings configurable in devstack\n\nNote: os_username/os_tenant_name are hadcoded to admin in stack.sh\nin devstack so I didn't create a bash varible for this.\n\nChange-Id: Ia2bacad9ad6290220f0a51f16a8fbd7665d60545\n""}]",0,113625,437d77dd80d855ce5fca0f959ecbe51ff2a2a75b,8,3,1,4395,,,0,"Make openstack datasource settings configurable in devstack

Note: os_username/os_tenant_name are hadcoded to admin in stack.sh
in devstack so I didn't create a bash varible for this.

Change-Id: Ia2bacad9ad6290220f0a51f16a8fbd7665d60545
",git fetch https://review.opendev.org/openstack/congress refs/changes/25/113625/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/congress'],1,437d77dd80d855ce5fca0f959ecbe51ff2a2a75b,, iniset $CONGRESS_CONF DEFAULT os_username admin iniset $CONGRESS_CONF DEFAULT os_tenant_name admin iniset $CONGRESS_CONF DEFAULT os_password $ADMIN_PASSWORD iniset $CONGRESS_CONF DEFAULT os_auth_url $KEYSTONE_SERVICE_URI/v2.0,,4,0
openstack%2Fheat~stable%2Ficehouse~I9256ef90cc4546cccd5c5d6af6432e6ca3e3a99e,openstack/heat,stable/icehouse,I9256ef90cc4546cccd5c5d6af6432e6ca3e3a99e,Bump stable/icehouse next version to 2014.1.3,MERGED,2014-08-08 14:24:52.000000000,2014-08-14 17:04:59.000000000,2014-08-14 17:04:59.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 8537}, {'_account_id': 9542}, {'_account_id': 9656}, {'_account_id': 11599}]","[{'number': 1, 'created': '2014-08-08 14:24:52.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/heat/commit/2866e4c8fbbbdd0f6906b92eb0e8b106cd2d1078', 'message': 'Bump stable/icehouse next version to 2014.1.3\n\nBump stable/icehouse next version to 2014.1.3\n\nChange-Id: I9256ef90cc4546cccd5c5d6af6432e6ca3e3a99e\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",0,112889,2866e4c8fbbbdd0f6906b92eb0e8b106cd2d1078,18,7,1,24,,,0,"Bump stable/icehouse next version to 2014.1.3

Bump stable/icehouse next version to 2014.1.3

Change-Id: I9256ef90cc4546cccd5c5d6af6432e6ca3e3a99e
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/heat refs/changes/89/112889/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,2866e4c8fbbbdd0f6906b92eb0e8b106cd2d1078,,version = 2014.1.3,version = 2014.1.2,1,1
openstack%2Ftripleo-incubator~master~I6ba65db401203883b88874f162fa52a5fb522c32,openstack/tripleo-incubator,master,I6ba65db401203883b88874f162fa52a5fb522c32,reenable boot an instance from a volume,MERGED,2014-08-08 17:25:15.000000000,2014-08-14 17:02:22.000000000,2014-08-14 17:02:22.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-08-08 17:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/c9a8e67224f72742d7b34ed015407ac2970cb7ad', 'message': 'renable boot an instance from a volume\n\nThis patch updates our nova boot command to boot\nan instance from a volume that is created on\nthe fly from a Glance image.\n\nThe motivation here is to expand our devtest\nscript so that it has some level of coverage\nacross Cinder which is commonly broken\nin upstream TripleO.\n\nThis patch was recently reverted to fix CI... but\nwas in fact catching a valid Nova upgrade issue:\n\nSee https://bugs.launchpad.net/nova/+bug/1354499\n\nChange-Id: I6ba65db401203883b88874f162fa52a5fb522c32\n'}, {'number': 2, 'created': '2014-08-14 12:23:03.000000000', 'files': ['scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/1b2ed7bcd64405488e9352f0bbd737a83be2723c', 'message': 'reenable boot an instance from a volume\n\nThis patch updates our nova boot command to boot\nan instance from a volume that is created on\nthe fly from a Glance image.\n\nThe motivation here is to expand our devtest\nscript so that it has some level of coverage\nacross Cinder which is commonly broken\nin upstream TripleO.\n\nThis patch was recently reverted to fix CI... but\nwas in fact catching a valid Nova upgrade issue:\n\nSee https://bugs.launchpad.net/nova/+bug/1354499\n\nChange-Id: I6ba65db401203883b88874f162fa52a5fb522c32'}]",1,112979,1b2ed7bcd64405488e9352f0bbd737a83be2723c,29,5,2,360,,,0,"reenable boot an instance from a volume

This patch updates our nova boot command to boot
an instance from a volume that is created on
the fly from a Glance image.

The motivation here is to expand our devtest
script so that it has some level of coverage
across Cinder which is commonly broken
in upstream TripleO.

This patch was recently reverted to fix CI... but
was in fact catching a valid Nova upgrade issue:

See https://bugs.launchpad.net/nova/+bug/1354499

Change-Id: I6ba65db401203883b88874f162fa52a5fb522c32",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/79/112979/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_overcloud.sh'],1,c9a8e67224f72742d7b34ed015407ac2970cb7ad,boot_from_volume," IMAGE_ID=$(glance image-show user | awk '/ id / {print $4}') nova boot --key-name default --flavor m1.tiny --block-device source=image,id=$IMAGE_ID,dest=volume,size=2,shutdown=preserve,bootindex=0 demo", nova boot --key-name default --flavor m1.tiny --image user demo,2,1
openstack%2Fcongress~master~I2098da576212cdc2c41bca9398ea48089d614ad4,openstack/congress,master,I2098da576212cdc2c41bca9398ea48089d614ad4,Fetch servers from all tenants from nova,MERGED,2014-08-11 22:08:29.000000000,2014-08-14 16:50:11.000000000,2014-08-14 16:50:11.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}]","[{'number': 1, 'created': '2014-08-11 22:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/1eed1bfaa0a6afa995b43717da31087f1f4bd9b0', 'message': 'Fetch servers from all tenants from nova\n\nThe prior version would leave out vm instances from other users.  This\nchange makes the nova driver request instances from all tenants.\n\nChange-Id: I2098da576212cdc2c41bca9398ea48089d614ad4\n'}, {'number': 2, 'created': '2014-08-11 23:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/68d7f34f565ccff012f78fb9452678e2712c1741', 'message': 'Fetch servers from all tenants from nova\n\nThe prior version would leave out vm instances from other users.  This\nchange makes the nova driver request instances from all tenants.\n\nChange-Id: I2098da576212cdc2c41bca9398ea48089d614ad4\n'}, {'number': 3, 'created': '2014-08-11 23:45:53.000000000', 'files': ['congress/datasources/nova_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/765f0810439f2d8bfdcf9ea9c25dc0d20a825e3e', 'message': 'Fetch servers from all tenants from nova\n\nThe prior version would leave out vm instances from other users.  This\nchange makes the nova driver request instances from all tenants.\n\nChange-Id: I2098da576212cdc2c41bca9398ea48089d614ad4\n'}]",0,113383,765f0810439f2d8bfdcf9ea9c25dc0d20a825e3e,15,3,3,12875,,,0,"Fetch servers from all tenants from nova

The prior version would leave out vm instances from other users.  This
change makes the nova driver request instances from all tenants.

Change-Id: I2098da576212cdc2c41bca9398ea48089d614ad4
",git fetch https://review.opendev.org/openstack/congress refs/changes/83/113383/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/datasources/nova_driver.py'],1,1eed1bfaa0a6afa995b43717da31087f1f4bd9b0,x," self.nova_client.servers.list(detailed=True, search_opts={ ""all_tenants"": 1 }), self.SERVERS)"," self.nova_client.servers.list(detailed=True), self.SERVERS)",2,1
openstack%2Fcongress~master~I6b82792af9beac069b87706a81b63e64495a8d9d,openstack/congress,master,I6b82792af9beac069b87706a81b63e64495a8d9d,Tests: reset config after each test,MERGED,2014-08-14 16:12:38.000000000,2014-08-14 16:44:25.000000000,2014-08-14 16:44:24.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}]","[{'number': 1, 'created': '2014-08-14 16:12:38.000000000', 'files': ['congress/tests/base.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/d5699c559afdec64bc0ea3bb4527aab16140e7ff', 'message': 'Tests: reset config after each test\n\nIn some cases, unit tests must override configuration values.  The\nbase.TestCase now resets the config between tests.\n\nChange-Id: I6b82792af9beac069b87706a81b63e64495a8d9d\n'}]",0,114284,d5699c559afdec64bc0ea3bb4527aab16140e7ff,8,3,1,9253,,,0,"Tests: reset config after each test

In some cases, unit tests must override configuration values.  The
base.TestCase now resets the config between tests.

Change-Id: I6b82792af9beac069b87706a81b63e64495a8d9d
",git fetch https://review.opendev.org/openstack/congress refs/changes/84/114284/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/tests/base.py'],1,d5699c559afdec64bc0ea3bb4527aab16140e7ff,,from oslo.config import cfg self.addCleanup(cfg.CONF.reset),,2,0
openstack%2Fhorizon~master~I39954ddb439f97238511f6eee5f992213690846f,openstack/horizon,master,I39954ddb439f97238511f6eee5f992213690846f,Initialize table action buttons for lazy-loaded tabs,MERGED,2014-07-01 13:54:52.000000000,2014-08-14 16:28:54.000000000,2014-08-14 16:28:53.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 4978}, {'_account_id': 8040}]","[{'number': 1, 'created': '2014-07-01 13:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/aabe27ca752aba67e631f6e0c8326f7c842a8045', 'message': 'Disable actions that should be disabled for lazy-loaded tabs\n\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\n'}, {'number': 2, 'created': '2014-07-02 15:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f1439b855c7dcdcec673a69c910beba0052f4fe7', 'message': 'Disable actions that should be disabled for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs - so, they were\nmoved to a separate function and reused.\n\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\n'}, {'number': 3, 'created': '2014-07-03 08:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5690732e411dfaa613961984911ba4d0247cd4bd', 'message': 'Initialize table action buttons for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs which are \nlazy-loaded (namely, are defined with `preload = False`) - \nso, they were moved to a separate function and reused.\n\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\n'}, {'number': 4, 'created': '2014-07-08 15:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a73a02061405c3f871cfb5900e1da3f051d95959', 'message': 'Initialize table action buttons for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs which are\nlazy-loaded (namely, are defined with `preload = False`) -\nso, they were moved to a separate function and reused.\n\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\n'}, {'number': 5, 'created': '2014-07-10 10:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ec90a1f81a65030838a6e19905ddd71750caf9f5', 'message': 'Initialize table action buttons for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs which are\nlazy-loaded (namely, are defined with `preload = False`) -\nso, they were moved to a separate function and reused.\n\nProvide tests for the fixed js regression using SeleniumTestCase\nwith authorization backend being stubbed out. This allows to use\nlazy tabs defined in django code instead of writing html fixtures (as\ndone for QUnit tests). Also rename selenium.py -> selenium_tests.py\nto avoid problems with importing from selenium package in these\nfiles.\n\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\nCloses-Bug: #1339023\n'}, {'number': 6, 'created': '2014-07-10 11:34:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a1ac1bf404f1443d59871b1c8c5d2c4dd9a27924', 'message': 'Initialize table action buttons for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs which are\nlazy-loaded (namely, are defined with `preload = False`) -\nso, they were moved to a separate function and reused.\n\nProvide tests for the fixed js regression using SeleniumTestCase\nwith authorization backend being stubbed out. This allows to use\nlazy tabs defined in django code instead of writing html fixtures (as\ndone for QUnit tests). Also rename selenium.py -> selenium_tests.py\nto avoid problems with importing from selenium package in these\nfiles.\n\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\nCloses-Bug: #1339023\n'}, {'number': 7, 'created': '2014-08-01 13:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6721ecd0add4b3531c4cd273665d2f63b07bb1a4', 'message': 'Initialize table action buttons for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs which are\nlazy-loaded (namely, are defined with `preload = False`) -\nso, they were moved to a separate function and reused.\nProvide tests for the fixed js regression using SeleniumTestCase\nwith authorization backend being stubbed out. This allows to use\nlazy tabs defined in django code instead of writing html fixtures (as\ndone for QUnit tests). Also rename selenium.py -> selenium_tests.py\nto avoid problems with importing from selenium package in these\nfiles.\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\nCloses-Bug: #1339023\n'}, {'number': 8, 'created': '2014-08-01 13:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bfe8d26f9d67de864ddb6027c5965fbfc06473f5', 'message': 'Initialize table action buttons for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs which are\nlazy-loaded (namely, are defined with `preload = False`) -\nso, they were moved to a separate function and reused.\nProvide tests for the fixed js regression using SeleniumTestCase\nwith authorization backend being stubbed out. This allows to use\nlazy tabs defined in django code instead of writing html fixtures (as\ndone for QUnit tests). Also rename selenium.py -> selenium_tests.py\nto avoid problems with importing from selenium package in these\nfiles.\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\nCloses-Bug: #1339023\n'}, {'number': 9, 'created': '2014-08-04 11:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e23d2024409fff2e1c97d94afed757bf94ab847c', 'message': 'Initialize table action buttons for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs which are lazy-loaded\n(namely, are defined with `preload = False`) - so, they were moved to\na separate function and reused.  Provide tests for the fixed js\nregression using SeleniumTestCase with authorization backend being\nstubbed out. This allows to use lazy tabs defined in django code\ninstead of writing html fixtures (as done for QUnit tests).\n\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\n'}, {'number': 10, 'created': '2014-08-04 12:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/eaafb1b18d892cb6a2eb11e8fe844f5f7d570619', 'message': 'Initialize table action buttons for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs which are lazy-loaded\n(namely, are defined with `preload = False`) - so, they were moved to\na separate function and reused.  Provide tests for the fixed js\nregression using SeleniumTestCase with authorization backend being\nstubbed out. This allows to use lazy tabs defined in django code\ninstead of writing html fixtures (as done for QUnit tests).\n\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\n'}, {'number': 11, 'created': '2014-08-07 09:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/409fe79d557885f011d16a5eab88a90927468164', 'message': 'Initialize table action buttons for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs which are lazy-loaded\n(namely, are defined with `preload = False`) - so, they were moved to\na separate function and reused.  Provide tests for the fixed js\nregression using SeleniumTestCase with authorization backend being\nstubbed out. This allows to use lazy tabs defined in django code\ninstead of writing html fixtures (as done for QUnit tests).\n\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\n'}, {'number': 12, 'created': '2014-08-11 14:01:31.000000000', 'files': ['horizon/test/test_dashboards/dogs/puppies/urls.py', 'horizon/test/dummy_auth/__init__.py', 'horizon/test/test_dashboards/dogs/puppies/tables.py', 'horizon/test/dummy_auth/backend.py', 'horizon/test/test_dashboards/dogs/puppies/tabs.py', 'horizon/test/test_dashboards/dogs/puppies/templates/puppies/two_tabs.html', 'horizon/test/test_dashboards/dogs/puppies/views.py', 'horizon/test/tests/selenium_tests.py', 'horizon/test/helpers.py', 'horizon/static/horizon/js/horizon.tables.js', 'horizon/test/utils.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/65c65dfafc550d4aff5e4de5bbff7f0cbec89d76', 'message': 'Initialize table action buttons for lazy-loaded tabs\n\nVarious checkbox elements listeners that were set only for\nhorizon.tables should also be set for tabs which are lazy-loaded\n(namely, are defined with `preload = False`) - so, they were moved to\na separate function and reused.  Provide tests for the fixed js\nregression using SeleniumTestCase with authorization backend being\nstubbed out. This allows to use lazy tabs defined in django code\ninstead of writing html fixtures (as done for QUnit tests).\n\nChange-Id: I39954ddb439f97238511f6eee5f992213690846f\nCloses-Bug: #1191006\n'}]",16,103895,65c65dfafc550d4aff5e4de5bbff7f0cbec89d76,68,5,12,8040,,,0,"Initialize table action buttons for lazy-loaded tabs

Various checkbox elements listeners that were set only for
horizon.tables should also be set for tabs which are lazy-loaded
(namely, are defined with `preload = False`) - so, they were moved to
a separate function and reused.  Provide tests for the fixed js
regression using SeleniumTestCase with authorization backend being
stubbed out. This allows to use lazy tabs defined in django code
instead of writing html fixtures (as done for QUnit tests).

Change-Id: I39954ddb439f97238511f6eee5f992213690846f
Closes-Bug: #1191006
",git fetch https://review.opendev.org/openstack/horizon refs/changes/95/103895/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.tables.js'],1,aabe27ca752aba67e631f6e0c8326f7c842a8045,bug/1191006, horizon.tabs.addTabLoadFunction(horizon.datatables.validate_button);,,1,0
openstack%2Fnova~master~I6c2e388e5a8d3f20054b552e4a7ac4fb44e1a417,openstack/nova,master,I6c2e388e5a8d3f20054b552e4a7ac4fb44e1a417,Fixed jsonutils hacking rule to return iterable,ABANDONED,2014-08-14 08:22:12.000000000,2014-08-14 16:17:24.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-08-14 08:22:12.000000000', 'files': ['nova/hacking/checks.py', 'nova/tests/test_hacking.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5ebe51ebf4b664464102e64e5a68c983e1de55ff', 'message': ""Fixed jsonutils hacking rule to return iterable\n\nflake8 expects to receive an iterable from registered hacking checks.\n\nWe don't want to see duplicate violation messages for the same error, so\ninstead of yielding, return a 1-element list for the first issue found.\n\nChange-Id: I6c2e388e5a8d3f20054b552e4a7ac4fb44e1a417\nCloses-Bug: 1356687\n""}]",0,114160,5ebe51ebf4b664464102e64e5a68c983e1de55ff,5,3,1,9656,,,0,"Fixed jsonutils hacking rule to return iterable

flake8 expects to receive an iterable from registered hacking checks.

We don't want to see duplicate violation messages for the same error, so
instead of yielding, return a 1-element list for the first issue found.

Change-Id: I6c2e388e5a8d3f20054b552e4a7ac4fb44e1a417
Closes-Bug: 1356687
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/114160/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/hacking/checks.py', 'nova/tests/test_hacking.py']",2,5ebe51ebf4b664464102e64e5a68c983e1de55ff,bug/1356687," return [(0, msg)]"," return (0, msg)",2,2
openstack-attic%2Fidentity-api~master~Ibab38272290ef2a60757089c818a12ec9ec9c8d7,openstack-attic/identity-api,master,Ibab38272290ef2a60757089c818a12ec9ec9c8d7,Removes WADL references from Identity v2.0 API,MERGED,2014-08-07 16:46:30.000000000,2014-08-14 16:04:12.000000000,2014-08-14 16:04:12.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 964}]","[{'number': 1, 'created': '2014-08-07 16:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/85654a792fa156b2ac0de81da592fd6953c94f34', 'message': 'Removes WADL references from Identity v2.0 API\n\n- Removes chapter files that pointed to WADL.\n\nChange-Id: Ibab38272290ef2a60757089c818a12ec9ec9c8d7\n'}, {'number': 2, 'created': '2014-08-07 19:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/ecb07cd165e2881ee3e6d72614a28c9ddcf8ccd6', 'message': 'Removes WADL references from Identity v2.0 API\n\n- Removes chapter files that pointed to WADL.\n\nChange-Id: Ibab38272290ef2a60757089c818a12ec9ec9c8d7\n'}, {'number': 3, 'created': '2014-08-08 15:32:14.000000000', 'files': ['v2.0/src/identity-dev-guide.xml', 'v2.0/src/ch_rax_identity_extensions.xml', 'v2.0/src/ch_identity-client-api.xml', 'v2.0/src/ch_hp_extensions.xml', 'v2.0/src/ch_rax_extensions.xml', 'v2.0/src/ch_identity-service-api.xml', 'v2.0/src/ch_os_extensions.xml'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/da2d7f528aa8db363b676ccb822a898574e5b5cc', 'message': 'Removes WADL references from Identity v2.0 API\n\n- Removes chapter files that pointed to WADL.\n\nChange-Id: Ibab38272290ef2a60757089c818a12ec9ec9c8d7\n'}]",0,112620,da2d7f528aa8db363b676ccb822a898574e5b5cc,18,3,3,964,,,0,"Removes WADL references from Identity v2.0 API

- Removes chapter files that pointed to WADL.

Change-Id: Ibab38272290ef2a60757089c818a12ec9ec9c8d7
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/20/112620/1 && git format-patch -1 --stdout FETCH_HEAD,"['v2.0/src/identity-dev-guide.xml', 'v2.0/src/ch_rax_identity_extensions.xml', 'v2.0/src/ch_identity-client-api.xml', 'v2.0/src/ch_hp_extensions.xml', 'v2.0/src/ch_rax_extensions.xml', 'v2.0/src/ch_identity-service-api.xml', 'v2.0/src/ch_os_extensions.xml']",7,85654a792fa156b2ac0de81da592fd6953c94f34,trim-wadl-from-ref,,"<?xml version='1.0' encoding='UTF-8'?> <chapter xmlns=""http://docbook.org/ns/docbook"" xml:id=""openstack_identity_extensions"" version=""5.0"" xmlns:xi=""http://www.w3.org/2001/XInclude"" role=""api-reference""> <title>OpenStack extensions to OpenStack Identity</title> <section xml:id=""os-ksadm-admin-ext""> <title>OS-KSADM extension</title> <section xml:id=""ksadm-users""> <title>Users</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#users-v2.0""> <wadl:method href=""#listUsers""/> <wadl:method href=""#addUser""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#userById-v2.0""> <wadl:method href=""#updateUser""/> <wadl:method href=""#deleteUser""/> </wadl:resource> </wadl:resources> </section> <section xml:id=""ksadm-roles""> <title>Roles</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#userRoles-v2.0""> <wadl:method href=""#listUserRoles""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#userRoleById-v2.0""> <wadl:method href=""#addUserRole""/> <wadl:method href=""#deleteUserRole""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#roles-v2.0""> <wadl:method href=""#getRoleByName""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#roles_list-v2.0""> <wadl:method href=""#listRoles""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#roles-v2.0""> <wadl:method href=""#addRole""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#roleId-v2.0""> <wadl:method href=""#getRole""/> <wadl:method href=""#deleteRole""/> </wadl:resource> </wadl:resources> </section> <section xml:id=""ksadm-tenants""> <title>Tenants</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#tenants-v2.0""> <wadl:method href=""#addTenant""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#tenantById-v2.0""> <wadl:method href=""#updateTenant""/> <wadl:method href=""#deleteTenant""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#usersForTenant-v2.0""> <wadl:method href=""#listUsersForTenant""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#userSpecificRoleForTenant-v2.0""> <wadl:method href=""#addRolesToUserOnTenant""/> <wadl:method href=""#deleteRoleFromUserOnTenant""/> </wadl:resource> </wadl:resources> </section> <section xml:id=""ksadm-services""> <title>Services</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#services-v2.0""> <wadl:method href=""#listServices""/> <wadl:method href=""#addService""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#serviceName-v2.0""> <wadl:method href=""#getServiceByName""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl#serviceId-v2.0""> <wadl:method href=""#getService""/> <wadl:method href=""#deleteService""/> </wadl:resource> </wadl:resources> </section> </section> <section xml:id=""Admin_API_Service_Developer_Operations-OS-KSCATALOG""> <title>OS-KSCATALOG extension</title> <section xml:id=""Endpoint_Operations_OS-KSCATALOG""> <title>Endpoints</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSCATALOG-admin.wadl#endpoints""> <wadl:method href=""#listEndpoints""/> <wadl:method href=""#addEndpoint""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSCATALOG-admin.wadl#endpoint""> <wadl:method href=""#getEndpoint""/> <wadl:method href=""#deleteEndpoint""/> </wadl:resource> </wadl:resources> </section> <section xml:id=""Endpoint_Template_Operations_OS-KSCATALOG""> <title>Endpoint templates</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSCATALOG-admin.wadl#endpointTemplates""> <wadl:method href=""#listEndpointTemplates""/> <wadl:method href=""#addEndpointTemplate""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSCATALOG-admin.wadl#endpointTemplateId""> <wadl:method href=""#getEndpointTemplate""/> <wadl:method href=""#updateEndpointTemplate""/> <wadl:method href=""#deleteEndpointTemplate""/> </wadl:resource> </wadl:resources> </section> </section> <section xml:id=""Admin_API_Service_Developer_Operations-OS-KSEC2""> <title>OS-KSEC2 extension</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSEC2-admin.wadl#userCredentials""> <wadl:method href=""#listCredentials""/> <wadl:method href=""#addUserCredential""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSEC2-admin.wadl#userCredentialsByType""> <wadl:method href=""#getUserCredential""/> <wadl:method href=""#updateUserCredential""/> <wadl:method href=""#deleteUserCredential""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSEC2-admin.wadl#type""> <wadl:method href=""#listCredentialsByType""/> </wadl:resource> </wadl:resources> </section> <section xml:id=""RackExt-0001""> <title>OS-KSS3 extension</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSS3-admin.wadl#userCredentials""> <wadl:method href=""#listCredentials""/> <wadl:method href=""#addUserCredential""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSS3-admin.wadl#userCredentialsByType""> <wadl:method href=""#getUserCredential""/> <wadl:method href=""#updateUserCredential""/> <wadl:method href=""#deleteUserCredential""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSS3-admin.wadl#type""> <wadl:method href=""#listCredentialsByType""/> </wadl:resource> </wadl:resources> </section> <section xml:id=""KSVALIDATE_OPERATIONS-token"" version=""5.0""> <title>OS-KSVALIDATE extension</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSVALIDATE-admin.wadl#validate""> <wadl:method href=""validateToken""/> <wadl:method href=""checkToken""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSVALIDATE-admin.wadl#endpointsForToken""> <wadl:method href=""listEndpointsForToken""/> </wadl:resource> </wadl:resources> </section> </chapter> ",13,581
openstack%2Ftripleo-heat-templates~master~I6730ffe1e27d952d563c16a9480298fbef9f61fe,openstack/tripleo-heat-templates,master,I6730ffe1e27d952d563c16a9480298fbef9f61fe,Add BlockStorage and SwiftStorage nodes into hosts,MERGED,2014-08-05 16:25:13.000000000,2014-08-14 15:50:23.000000000,2014-08-14 15:50:21.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}]","[{'number': 1, 'created': '2014-08-05 16:25:13.000000000', 'files': ['overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/115072f0f5dabbbcf43a8707280f0017926c2c19', 'message': 'Add BlockStorage and SwiftStorage nodes into hosts\n\nWith this we populate the hosts key (needed for /etc/hosts editing)\nwith the BlockStorage and SwiftStorage nodes too.\n\nChange-Id: I6730ffe1e27d952d563c16a9480298fbef9f61fe\n'}]",0,112064,115072f0f5dabbbcf43a8707280f0017926c2c19,20,5,1,6796,,,0,"Add BlockStorage and SwiftStorage nodes into hosts

With this we populate the hosts key (needed for /etc/hosts editing)
with the BlockStorage and SwiftStorage nodes too.

Change-Id: I6730ffe1e27d952d563c16a9480298fbef9f61fe
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/64/112064/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-source.yaml'],1,115072f0f5dabbbcf43a8707280f0017926c2c19,blockstoragescale_p3," BlockStorage0: list_join: - ' ' - - {get_attr: [BlockStorage0, networks, ctlplane, 0]} - {get_attr: [BlockStorage0, show, name]} - list_join: - '.' - - {get_attr: [BlockStorage0, show, name]} - 'novalocal' - list_join: - ""\n"" - Merge::Map: SwiftStorage0: list_join: - ' ' - - {get_attr: [SwiftStorage0, networks, ctlplane, 0]} - {get_attr: [SwiftStorage0, show, name]} - list_join: - '.' - - {get_attr: [SwiftStorage0, show, name]} - 'novalocal' - list_join: - ""\n"" - Merge::Map:",,24,0
openstack%2Ftripleo-heat-templates~master~I37614153d8c87d25aa17e759fcd228a8a1fda4a4,openstack/tripleo-heat-templates,master,I37614153d8c87d25aa17e759fcd228a8a1fda4a4,Fix BLOCKSTORAGESCALE and SWIFTSTORAGESCALE in Makefile,MERGED,2014-08-05 16:16:07.000000000,2014-08-14 15:47:30.000000000,2014-08-14 15:47:29.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}]","[{'number': 1, 'created': '2014-08-05 16:16:07.000000000', 'files': ['Makefile'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/24bdc7380f87f6e99e84a4b7e161f07a87633dd3', 'message': 'Fix BLOCKSTORAGESCALE and SWIFTSTORAGESCALE in Makefile\n\nThe BLOCKSTORAGESCALE and SWIFTSTORAGESCALE vars were incorrectly\nignored in the Makefile (and forcibly set to 0)\n\nChange-Id: I37614153d8c87d25aa17e759fcd228a8a1fda4a4\n'}]",0,112062,24bdc7380f87f6e99e84a4b7e161f07a87633dd3,12,4,1,6796,,,0,"Fix BLOCKSTORAGESCALE and SWIFTSTORAGESCALE in Makefile

The BLOCKSTORAGESCALE and SWIFTSTORAGESCALE vars were incorrectly
ignored in the Makefile (and forcibly set to 0)

Change-Id: I37614153d8c87d25aa17e759fcd228a8a1fda4a4
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/62/112062/1 && git format-patch -1 --stdout FETCH_HEAD,['Makefile'],1,24bdc7380f87f6e99e84a4b7e161f07a87633dd3,blockstoragescale_p2, python ./tripleo_heat_merge/merge.py --hot --scale NovaCompute=$${COMPUTESCALE:-'1'} --scale controller=$${CONTROLSCALE:-'1'} --scale SwiftStorage=$${SWIFTSTORAGESCALE:-'0'} --scale BlockStorage=$${BLOCKSTORAGESCALE:-'0'} overcloud-source.yaml block-storage.yaml swift-source.yaml swift-storage-source.yaml ssl-source.yaml swift-deploy.yaml nova-compute-config.yaml > $@.tmp python ./tripleo_heat_merge/merge.py --hot --scale NovaCompute=$${COMPUTESCALE:-'1'} --scale controller=$${CONTROLSCALE:-'1'} --scale SwiftStorage=$${SWIFTSTORAGESCALE:-'0'} --scale BlockStorage=$${BLOCKSTORAGESCALE:-'1'} overcloud-source.yaml block-storage-nfs.yaml nfs-server-source.yaml swift-source.yaml swift-storage-source.yaml ssl-source.yaml > $@.tmp, python ./tripleo_heat_merge/merge.py --hot --scale NovaCompute=$${COMPUTESCALE:-'1'} --scale controller=$${CONTROLSCALE:-'1'} --scale SwiftStorage=$${SWIFTSTORAGESCALE='0'} --scale BlockStorage=$${BLOCKSTORAGESCALE='0'} overcloud-source.yaml block-storage.yaml swift-source.yaml swift-storage-source.yaml ssl-source.yaml swift-deploy.yaml nova-compute-config.yaml > $@.tmp python ./tripleo_heat_merge/merge.py --hot --scale NovaCompute=$${COMPUTESCALE:-'1'} --scale controller=$${CONTROLSCALE:-'1'} --scale SwiftStorage=$${SWIFTSTORAGESCALE='0'} --scale BlockStorage=$${BLOCKSTORAGESCALE:-'1'} overcloud-source.yaml block-storage-nfs.yaml nfs-server-source.yaml swift-source.yaml swift-storage-source.yaml ssl-source.yaml > $@.tmp,2,2
openstack%2Fbarbican~master~I849af68e0aafdc37da07a0843db3172fbbf0e532,openstack/barbican,master,I849af68e0aafdc37da07a0843db3172fbbf0e532,Revert remove version from setup.cfg,MERGED,2014-08-13 23:29:18.000000000,2014-08-14 15:42:16.000000000,2014-08-14 15:42:15.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 8415}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10273}]","[{'number': 1, 'created': '2014-08-13 23:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/b1a2afe0aad34fb4ce541109cf703e9cf702e52a', 'message': 'Revert remove version from setup.cfg\n\nIt seems removing this borked the DevStack gate.\n\nChange-Id: I849af68e0aafdc37da07a0843db3172fbbf0e532\n'}, {'number': 2, 'created': '2014-08-14 15:07:23.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/barbican/commit/3f772bb6ec83af37344a12fcbda3c477b86dbac9', 'message': 'Revert remove version from setup.cfg\n\nIt seems removing this borked the DevStack gate.\n\nChange-Id: I849af68e0aafdc37da07a0843db3172fbbf0e532\n'}]",2,114080,3f772bb6ec83af37344a12fcbda3c477b86dbac9,20,8,2,7973,,,0,"Revert remove version from setup.cfg

It seems removing this borked the DevStack gate.

Change-Id: I849af68e0aafdc37da07a0843db3172fbbf0e532
",git fetch https://review.opendev.org/openstack/barbican refs/changes/80/114080/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,b1a2afe0aad34fb4ce541109cf703e9cf702e52a,version,version = 2014.1,,1,0
openstack%2Foperations-guide~master~I197329f659b16d6dd490c561d71a97012946b8b9,openstack/operations-guide,master,I197329f659b16d6dd490c561d71a97012946b8b9,Update the image of OpenStack Architecture,MERGED,2014-08-04 05:05:11.000000000,2014-08-14 15:40:31.000000000,2014-08-14 15:40:31.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-08-04 05:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/9ae824aa53b5dcc3dfe707d822450b8995796999', 'message': 'Update the image of OpenStack Architecture\n\nOpenStack Havana to Icehouse with names inside boxes\n\nChange-Id: I197329f659b16d6dd490c561d71a97012946b8b9\nCloses-Bug: 1340715\n'}, {'number': 2, 'created': '2014-08-07 06:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/dbfbd47e3e071887c110d12b47c67ca886dd77cb', 'message': 'Update the image of OpenStack Architecture\n\nOpenStack Havana to Icehouse with names inside boxes\nchange the text ""and so on"" to ""etc""\n\nChange-Id: I197329f659b16d6dd490c561d71a97012946b8b9\nCloses-Bug: 1340715\n'}, {'number': 3, 'created': '2014-08-12 09:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/83e8c0d766ec157dfd0edb02d264f126c9a3016a', 'message': 'Update the image of OpenStack Architecture\n\nOpenStack Havana to Icehouse with names inside boxes\nchange the text ""and so on"" to ""etc""\nchange the short link to the direct link\n\nChange-Id: I197329f659b16d6dd490c561d71a97012946b8b9\nCloses-Bug: 1340715\n'}, {'number': 4, 'created': '2014-08-14 15:20:36.000000000', 'files': ['doc/openstack-ops/figures/osog_0001.png', 'doc/openstack-ops/part_architecture.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/eb025cec3ff7a9936eaaa45b68a5d3adbb93e46f', 'message': 'Update the image of OpenStack Architecture\n\nOpenStack Havana to Icehouse with names inside boxes\nchange the text ""and so on"" to ""etc""\nchange the short link to the direct link\n\nChange-Id: I197329f659b16d6dd490c561d71a97012946b8b9\nCloses-Bug: 1340715\n'}]",2,111640,eb025cec3ff7a9936eaaa45b68a5d3adbb93e46f,24,4,4,10497,,,0,"Update the image of OpenStack Architecture

OpenStack Havana to Icehouse with names inside boxes
change the text ""and so on"" to ""etc""
change the short link to the direct link

Change-Id: I197329f659b16d6dd490c561d71a97012946b8b9
Closes-Bug: 1340715
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/40/111640/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/openstack-ops/figures/osog_0001.png', 'doc/openstack-ops/part_architecture.xml']",2,9ae824aa53b5dcc3dfe707d822450b8995796999,bug/1340715," linkend=""openstack-diagram"" /> shows the most common, but not the <figure xml:id=""openstack-diagram""> <title>OpenStack Logical Architecture (<link</part> "," linkend=""openstack-havana-diagram"" /> shows the most common, but not the <figure xml:id=""openstack-havana-diagram""> <title>OpenStack Havana Logical Architecture (<link</part>",4,4
openstack%2Fopenstack-manuals~master~Ie3361e08d7781c1c799c6953026d81c2325a83c3,openstack/openstack-manuals,master,Ie3361e08d7781c1c799c6953026d81c2325a83c3,Layer edits,MERGED,2014-08-09 21:24:40.000000000,2014-08-14 15:38:06.000000000,2014-08-14 15:38:05.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-08-09 21:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4a0d39a565ce0ebae75a770771fba175ecb63c65', 'message': 'Layer edits\n\nUse ""layer-2"" instead of ""layer 2"" if it is used as an adjective like\n""layer-2 network"".\n\nChange-Id: Ie3361e08d7781c1c799c6953026d81c2325a83c3\n'}, {'number': 2, 'created': '2014-08-12 05:16:04.000000000', 'files': ['doc/networking-guide/section_architecture-agents.xml', 'doc/arch-design/generalpurpose/section_tech_considerations_general_purpose.xml', 'doc/install-guide/ch_overview.xml', 'doc/admin-guide-cloud/networking/section_networking-adv-config.xml', 'doc/arch-design/network_focus/section_prescriptive_examples_network_focus.xml', 'doc/arch-design/network_focus/section_architecture_network_focus.xml', 'doc/arch-design/specialized/section_software_defined_networking_specialized.xml', 'doc/arch-design/specialized/section_networking_specialized.xml', 'doc/arch-design/network_focus/section_tech_considerations_network_focus.xml', 'doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bae2eb60d3f2e9adaf5b4688c3e1ba3d3b30e562', 'message': 'Layer edits\n\nUse ""layer-2"" instead of ""layer 2"" if it is used as an adjective like\n""layer-2 network"".\n\nChange-Id: Ie3361e08d7781c1c799c6953026d81c2325a83c3\n'}]",18,113097,bae2eb60d3f2e9adaf5b4688c3e1ba3d3b30e562,16,5,2,6547,,,0,"Layer edits

Use ""layer-2"" instead of ""layer 2"" if it is used as an adjective like
""layer-2 network"".

Change-Id: Ie3361e08d7781c1c799c6953026d81c2325a83c3
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/97/113097/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/section_architecture-agents.xml', 'doc/arch-design/generalpurpose/section_tech_considerations_general_purpose.xml', 'doc/install-guide/ch_overview.xml', 'doc/admin-guide-cloud/networking/section_networking-adv-config.xml', 'doc/arch-design/network_focus/section_prescriptive_examples_network_focus.xml', 'doc/arch-design/network_focus/section_architecture_network_focus.xml', 'doc/arch-design/specialized/section_software_defined_networking_specialized.xml', 'doc/arch-design/specialized/section_networking_specialized.xml', 'doc/arch-design/network_focus/section_tech_considerations_network_focus.xml', 'doc/glossary/glossary-terms.xml']",10,4a0d39a565ce0ebae75a770771fba175ecb63c65,layer-minus, The protocol by which layer-3 IP addresses are resolved into, The protocol by which layer 3 IP addresses are resolved into,59,59
openstack%2Fneutron~master~I6323d7ff438bb6c31e4a794bd3da96bf132fdc85,openstack/neutron,master,I6323d7ff438bb6c31e4a794bd3da96bf132fdc85,Delete DVR namespaces on node after removing last VM,MERGED,2014-08-07 04:03:15.000000000,2014-08-14 15:37:37.000000000,2014-08-14 04:41:39.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6659}, {'_account_id': 6876}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10971}]","[{'number': 1, 'created': '2014-08-07 04:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f8b142e05a423311cb59f6909adcc3748af3867', 'message': ""Delete DVR namespaces on node after removing last VM\n\nAfter removing the last VM using a distributed router,\nthe router's namespaces are still present on the VM host\nwhen the L3 agent should have deleted them. The problem\nis that the neutron API server never sent the router remove\nnotification to the VM host's L3 agent due to an error in\nthe DVR scheduler.\n\nThis patch fixes the error.\n\nChange-Id: I6323d7ff438bb6c31e4a794bd3da96bf132fdc85\nCloses-Bug: 1353165\n""}, {'number': 2, 'created': '2014-08-08 19:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d149871a72adfd198ccf09a1c442819028c619bb', 'message': ""Delete DVR namespaces on node after removing last VM\n\nAfter removing the last VM using a distributed router,\nthe router's namespaces are still present on the VM host\nwhen the L3 agent should have deleted them. The problem\nis that the neutron API server never sent the router remove\nnotification to the VM host's L3 agent due to an error in\nthe DVR scheduler.\n\nThis patch fixes the error.\n\nChange-Id: I6323d7ff438bb6c31e4a794bd3da96bf132fdc85\nCloses-Bug: 1353165\n""}, {'number': 3, 'created': '2014-08-11 15:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d832e671c60a02d8cd909b6f07844548dc218375', 'message': ""Delete DVR namespaces on node after removing last VM\n\nAfter removing the last VM using a distributed router,\nthe router's namespaces are still present on the VM host\nwhen the L3 agent should have deleted them. The problem\nis that the neutron API server never sent the router remove\nnotification to the VM host's L3 agent due to an error in\nthe DVR scheduler.\n\nThis patch fixes the error.\n\nChange-Id: I6323d7ff438bb6c31e4a794bd3da96bf132fdc85\nCloses-Bug: 1353165\n""}, {'number': 4, 'created': '2014-08-11 17:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/feac77ee108bee9a75b8d4764c050a4fb6328382', 'message': ""Delete DVR namespaces on node after removing last VM\n\nAfter removing the last VM using a distributed router,\nthe router's namespaces are still present on the VM host\nwhen the L3 agent should have deleted them. The problem\nis that the neutron API server never sent the router remove\nnotification to the VM host's L3 agent due to an error in\nthe DVR scheduler.\n\nThis patch fixes the error.\n\nChange-Id: I6323d7ff438bb6c31e4a794bd3da96bf132fdc85\nCloses-Bug: 1353165\n""}, {'number': 5, 'created': '2014-08-12 16:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d2f0b26c1cc29672e52eabbad506dd7c6ef0907c', 'message': ""Delete DVR namespaces on node after removing last VM\n\nAfter removing the last VM using a distributed router,\nthe router's namespaces are still present on the VM host\nThe problem is that the neutron API server sent the router\nremove notification to the L3 agent using the name of the\nhost running the L3 agent instead of the agent's uuid. This\ncaused an error when sending the notification. So the L3\nagent never had the chance to cleanup the namespace.\nThis problem is fixed here.\n\nAfterwards, it was found that the notification was still not\nsent. The reason is that the router/L3-agent binding has\nalready been deleted before the routine that sends the\nrouter removed notification was called. The notifier routine\nerrored out when it tried to delete the same router/L3 agent\nbinding. This problem is fixed in this patch by removing the\nbinding removal step from the DVR scheduler.\n\nChange-Id: I6323d7ff438bb6c31e4a794bd3da96bf132fdc85\nCloses-Bug: 1353165\n""}, {'number': 6, 'created': '2014-08-13 20:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/be3cf0e37ecfba7aef01e2461a1dcd7b319e7c63', 'message': ""Delete DVR namespaces on node after removing last VM\n\nAfter removing the last VM using a distributed router,\nthe router's namespaces are still present on the VM host\nThe problem is that the neutron API server sent the router\nremove notification to the L3 agent using the name of the\nhost running the L3 agent instead of the agent's uuid. This\ncaused an error when sending the notification. So the L3\nagent never had the chance to cleanup the namespace.\nThis problem is fixed here.\n\nAfterwards, it was found that the notification was still not\nsent. The reason is that the router/L3-agent binding has\nalready been deleted before the routine that sends the\nrouter removed notification was called. The notifier routine\nerrored out when it tried to delete the same router/L3 agent\nbinding. This problem is fixed in this patch by removing the\nbinding removal step from the DVR scheduler.\n\nChange-Id: I6323d7ff438bb6c31e4a794bd3da96bf132fdc85\nCloses-Bug: 1353165\n""}, {'number': 7, 'created': '2014-08-13 23:16:35.000000000', 'files': ['neutron/db/l3_dvrscheduler_db.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/69ce923ca30faf0865f3d59de4157fec21ed6e0d', 'message': ""Delete DVR namespaces on node after removing last VM\n\nAfter removing the last VM using a distributed router,\nthe router's namespaces are still present on the VM host\nThe problem is that the neutron API server sent the router\nremove notification to the L3 agent using the name of the\nhost running the L3 agent instead of the agent's uuid. This\ncaused an error when sending the notification. So the L3\nagent never had the chance to cleanup the namespace.\nThis problem is fixed here.\n\nAfterwards, it was found that the notification was still not\nsent. The reason is that the router/L3-agent binding has\nalready been deleted before the routine that sends the\nrouter removed notification was called. The notifier routine\nerrored out when it tried to delete the same router/L3 agent\nbinding. This problem is fixed in this patch by removing the\nbinding removal step from the DVR scheduler.\n\nChange-Id: I6323d7ff438bb6c31e4a794bd3da96bf132fdc85\nCloses-Bug: 1353165\n""}]",32,112465,69ce923ca30faf0865f3d59de4157fec21ed6e0d,168,27,7,6876,,,0,"Delete DVR namespaces on node after removing last VM

After removing the last VM using a distributed router,
the router's namespaces are still present on the VM host
The problem is that the neutron API server sent the router
remove notification to the L3 agent using the name of the
host running the L3 agent instead of the agent's uuid. This
caused an error when sending the notification. So the L3
agent never had the chance to cleanup the namespace.
This problem is fixed here.

Afterwards, it was found that the notification was still not
sent. The reason is that the router/L3-agent binding has
already been deleted before the routine that sends the
router removed notification was called. The notifier routine
errored out when it tried to delete the same router/L3 agent
binding. This problem is fixed in this patch by removing the
binding removal step from the DVR scheduler.

Change-Id: I6323d7ff438bb6c31e4a794bd3da96bf132fdc85
Closes-Bug: 1353165
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/112465/7 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_dvrscheduler_db.py', 'neutron/plugins/ml2/plugin.py']",2,1f8b142e05a423311cb59f6909adcc3748af3867,bug/1353165," context, router['agent_id'], router['router_id'])"," context, router['host'], router['router_id'])",6,16
openstack%2Ftempest~master~Ia9f057a07b0a9c0835448aeccaf97b02fad67c76,openstack/tempest,master,Ia9f057a07b0a9c0835448aeccaf97b02fad67c76,Added neutron cli test case,MERGED,2014-08-08 07:42:24.000000000,2014-08-14 15:24:18.000000000,2014-08-14 10:47:09.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1921}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8072}, {'_account_id': 8576}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11105}, {'_account_id': 12836}]","[{'number': 1, 'created': '2014-08-08 07:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/62f1947dd8b6ac0702aac3063e613183533e686f', 'message': 'Added neutron cli test case\n\nTest case added for below CLI:-\nl3-agent-list-hosting-router\n\nChange-Id: Ia9f057a07b0a9c0835448aeccaf97b02fad67c76\n'}, {'number': 2, 'created': '2014-08-12 05:55:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/977cab5b655a6e234e53969a48669bb58c8a50ce', 'message': 'Added neutron cli test case\n\nTest case added for below CLI:-\nl3-agent-list-hosting-router\n\nChange-Id: Ia9f057a07b0a9c0835448aeccaf97b02fad67c76\n'}, {'number': 3, 'created': '2014-08-12 06:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1131c7459f74c8ab3a08751a9e70abaab2def938', 'message': 'Added neutron cli test case\n\nTest case added for below CLI:-\nl3-agent-list-hosting-router\n\nChange-Id: Ia9f057a07b0a9c0835448aeccaf97b02fad67c76\n'}, {'number': 4, 'created': '2014-08-12 08:55:12.000000000', 'files': ['tempest/cli/simple_read_only/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/693db20aa8c4c7912743d57b82f1a368e3ef4960', 'message': 'Added neutron cli test case\n\nTest case added for below CLI:-\nl3-agent-list-hosting-router\n\nChange-Id: Ia9f057a07b0a9c0835448aeccaf97b02fad67c76\n'}]",4,112780,693db20aa8c4c7912743d57b82f1a368e3ef4960,37,12,4,12837,,,0,"Added neutron cli test case

Test case added for below CLI:-
l3-agent-list-hosting-router

Change-Id: Ia9f057a07b0a9c0835448aeccaf97b02fad67c76
",git fetch https://review.opendev.org/openstack/tempest refs/changes/80/112780/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cli/simple_read_only/test_neutron.py'],1,62f1947dd8b6ac0702aac3063e613183533e686f,master," @test.attr(type='smoke') def test_neutron_l3_agent_list_hosting_router(self): router_list = self.parser.listing(self.neutron('router-list')) for router in router_list: self.neutron('l3-agent-list-hosting-router', params=router['id'])",,6,0
openstack%2Ffuel-main~master~I19bbee60b9ff509064843a468f47c0061736b370,openstack/fuel-main,master,I19bbee60b9ff509064843a468f47c0061736b370,Add sysstat to Fuel Master and astute,MERGED,2014-08-13 15:02:46.000000000,2014-08-14 15:21:47.000000000,2014-08-14 15:21:46.000000000,"[{'_account_id': 3}, {'_account_id': 8776}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9705}]","[{'number': 1, 'created': '2014-08-13 15:02:46.000000000', 'files': ['docker/astute/Dockerfile', 'iso/ks.template'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/50cde45c09d3c0228fb3d357f412d6024964ea15', 'message': 'Add sysstat to Fuel Master and astute\n\nsysstat provides iostat which is useful\nfor calculating HDD throughput.\n\nChange-Id: I19bbee60b9ff509064843a468f47c0061736b370\nPartial-Bug: #1355347\n'}]",0,113920,50cde45c09d3c0228fb3d357f412d6024964ea15,12,7,1,7195,,,0,"Add sysstat to Fuel Master and astute

sysstat provides iostat which is useful
for calculating HDD throughput.

Change-Id: I19bbee60b9ff509064843a468f47c0061736b370
Partial-Bug: #1355347
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/20/113920/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/astute/Dockerfile', 'iso/ks.template']",2,50cde45c09d3c0228fb3d357f412d6024964ea15,add-sysstat,sysstat,,2,1
openstack%2Ffuel-web~master~I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71,openstack/fuel-web,master,I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71,Save astute keys and port them back to astute,MERGED,2014-08-14 12:38:06.000000000,2014-08-14 15:21:07.000000000,2014-08-14 15:21:07.000000000,"[{'_account_id': 3}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-08-14 12:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1189a5f103050a62950c01fc3047ce5677f1213b', 'message': 'Save astute keys and port them back to astute\n\nCloses-Bug: 1353497\nChange-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71\n'}, {'number': 2, 'created': '2014-08-14 13:54:54.000000000', 'files': ['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/config.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_docker_upgrader.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7d7e862ccbdbaa36785b95028d37ac91d7aca440', 'message': 'Save astute keys and port them back to astute\n\nCloses-Bug: 1353497\nChange-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71\n'}]",0,114223,7d7e862ccbdbaa36785b95028d37ac91d7aca440,17,4,2,8907,,,0,"Save astute keys and port them back to astute

Closes-Bug: 1353497
Change-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/23/114223/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/config.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_docker_upgrader.py']",3,1189a5f103050a62950c01fc3047ce5677f1213b,bug/1353497," 'save_astute_keys', @mock.patch('fuel_upgrade.engines.docker_engine.' 'utils.exec_cmd') def test_save_astute_keys(self, exec_cmd_mock): self.upgrader.save_astute_keys() exec_cmd_mock.assert_called_once_with( 'docker cp fuel-core-0-astute:/var/lib/astute/ ' '/tmp/upgrade/') self.called_once(exec_cmd_mock) ",,29,0
openstack%2Ffuel-web~stable%2F5.0~I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71,openstack/fuel-web,stable/5.0,I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71,Save astute keys and port them back to astute,MERGED,2014-08-14 11:48:30.000000000,2014-08-14 15:18:58.000000000,2014-08-14 15:18:57.000000000,"[{'_account_id': 3}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 10136}, {'_account_id': 10391}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-08-14 11:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0738142a1aa2f08f19e8eee909ce74d63d92cdb9', 'message': 'Save astute keys and port them back to astute\n\nChange-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71\n'}, {'number': 2, 'created': '2014-08-14 12:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/510e9ec7ffcf636faaa5fa02a782719ada7f1696', 'message': 'Save astute keys and port them back to astute\n\nChange-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71\n'}, {'number': 3, 'created': '2014-08-14 12:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ccd83c831ff5c01019c867eaf9d9cbbf82aa14f6', 'message': 'Save astute keys and port them back to astute\n\nChange-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71\n'}, {'number': 4, 'created': '2014-08-14 12:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/017da47095658883e3462a8c21f6c825f60559a6', 'message': 'Save astute keys and port them back to astute\n\nCloses-Bug: 1353497\nChange-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71\n'}, {'number': 5, 'created': '2014-08-14 13:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0cb03e13b584af3db7928219d7819952d5a96b6e', 'message': 'Save astute keys and port them back to astute\n\nChange-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71\n'}, {'number': 6, 'created': '2014-08-14 13:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aad7afe60f6ecde1adbb7f3636a72f1918c415b5', 'message': 'Save astute keys and port them back to astute\n\nCloses-Bug: 1353497\nChange-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71\n'}, {'number': 7, 'created': '2014-08-14 13:52:59.000000000', 'files': ['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/config.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_docker_upgrader.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/af3d1922bfc21345f81be3454115ab6139675c35', 'message': 'Save astute keys and port them back to astute\n\nCloses-Bug: 1353497\nChange-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71\n'}]",11,114211,af3d1922bfc21345f81be3454115ab6139675c35,59,10,7,8907,,,0,"Save astute keys and port them back to astute

Closes-Bug: 1353497
Change-Id: I5df75fc71fc7ac5d0fb6221caf6ab8097052eb71
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/11/114211/7 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/config.py']",2,0738142a1aa2f08f19e8eee909ce74d63d92cdb9,bug/1353497," 'after_container_creation_command': ( ""bash -c 'cp -rn /tmp/upgrade/astute/* "" ""/var/lib/astute/'""),",,18,0
openstack%2Fheat~master~I54d302dbec66ddd49c4a774376df99e7e9d63980,openstack/heat,master,I54d302dbec66ddd49c4a774376df99e7e9d63980,Move VolumeAttachment updates to Cinder resource,MERGED,2014-07-13 14:55:01.000000000,2014-08-14 15:13:04.000000000,2014-08-14 15:13:03.000000000,"[{'_account_id': 3}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8435}, {'_account_id': 8871}, {'_account_id': 9165}, {'_account_id': 9542}, {'_account_id': 11599}, {'_account_id': 12437}]","[{'number': 1, 'created': '2014-07-13 14:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/15c50ea81d09af5184fc40922c81838f24b1ffa9', 'message': 'Deprecate updates to AWS::EC2::VolumeAttachment\n\nAccording to AWS docs AWS::EC2::VolumeAttachment resource does not\nsupport any updates [1]. As updates to our AWS-compatible resource are part\nof Icehouse release first issue a deprecation warning and leave a\ncomment in code to move the update logic to the native\nOS::Cinder::VolumeAttachment resource after deprecation period.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volumeattachment.html\n\nChange-Id: I54d302dbec66ddd49c4a774376df99e7e9d63980\nPartial-Bug: #1340096\n'}, {'number': 2, 'created': '2014-07-14 10:48:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/91c0bb4f7c2b50989d6e93fddffee92c1c6b212b', 'message': 'Move VolumeAttachment updates to Cinder resource\n\nAccording to AWS docs AWS::EC2::VolumeAttachment resource does not\nsupport any updates [1]. Support of updates in our AWS-compatible\nresource is a bug and needs to be fixed without deprecation period.\n\nThis patch moves VolumeAttachment update logic to native Cinder\nresource.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volumeattachment.html\n\nChange-Id: I54d302dbec66ddd49c4a774376df99e7e9d63980\nPartial-Bug: #1340096\n'}, {'number': 3, 'created': '2014-07-15 08:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4d7335fcc276d150c9e9317056d15bb198785d20', 'message': 'Move VolumeAttachment updates to Cinder resource\n\nAccording to AWS docs AWS::EC2::VolumeAttachment resource does not\nsupport any updates [1]. Support of updates in our AWS-compatible\nresource is a bug and needs to be fixed without deprecation period.\n\nThis patch moves VolumeAttachment update logic to native Cinder\nresource.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volumeattachment.html\n\nChange-Id: I54d302dbec66ddd49c4a774376df99e7e9d63980\nPartial-Bug: #1340096\n'}, {'number': 4, 'created': '2014-07-16 13:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ec4c3fefae7e24b08312bfa626b71189a441c004', 'message': 'Move VolumeAttachment updates to Cinder resource\n\nAccording to AWS docs AWS::EC2::VolumeAttachment resource does not\nsupport any updates [1]. Support of updates in our AWS-compatible\nresource is a bug and needs to be fixed without deprecation period.\n\nThis patch moves VolumeAttachment update logic to native Cinder\nresource.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volumeattachment.html\n\nChange-Id: I54d302dbec66ddd49c4a774376df99e7e9d63980\nPartial-Bug: #1340096\n'}, {'number': 5, 'created': '2014-07-17 09:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/58fb38c73cad5db51359e36df346d12c632b2c69', 'message': 'Move VolumeAttachment updates to Cinder resource\n\nAccording to AWS docs AWS::EC2::VolumeAttachment resource does not\nsupport any updates [1]. Support of updates in our AWS-compatible\nresource is a bug and needs to be fixed without deprecation period.\n\nThis patch moves VolumeAttachment update logic to native Cinder\nresource.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volumeattachment.html\n\nChange-Id: I54d302dbec66ddd49c4a774376df99e7e9d63980\nPartial-Bug: #1340096\n'}, {'number': 6, 'created': '2014-07-22 17:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/11ebfd139c906e1027697b9db18dfb845af55c10', 'message': 'Move VolumeAttachment updates to Cinder resource\n\nAccording to AWS docs AWS::EC2::VolumeAttachment resource does not\nsupport any updates [1]. Support of updates in our AWS-compatible\nresource is a bug and needs to be fixed without deprecation period.\n\nThis patch moves VolumeAttachment update logic to native Cinder\nresource.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volumeattachment.html\n\nChange-Id: I54d302dbec66ddd49c4a774376df99e7e9d63980\nPartial-Bug: #1340096\n'}, {'number': 7, 'created': '2014-08-05 10:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f23318b267dce62261a685d135408788b92b2fec', 'message': 'Move VolumeAttachment updates to Cinder resource\n\nAccording to AWS docs AWS::EC2::VolumeAttachment resource does not\nsupport any updates [1]. Support of updates in our AWS-compatible\nresource is a bug and needs to be fixed without deprecation period.\n\nThis patch moves VolumeAttachment update logic to native Cinder\nresource.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volumeattachment.html\n\nChange-Id: I54d302dbec66ddd49c4a774376df99e7e9d63980\nPartial-Bug: #1340096\n'}, {'number': 8, 'created': '2014-08-13 08:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0ca581c791d1ea821a4da88db445248919386604', 'message': 'Move VolumeAttachment updates to Cinder resource\n\nAccording to AWS docs AWS::EC2::VolumeAttachment resource does not\nsupport any updates [1]. Support of updates in our AWS-compatible\nresource is a bug and needs to be fixed without deprecation period.\n\nThis patch moves VolumeAttachment update logic to native Cinder\nresource.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volumeattachment.html\n\nChange-Id: I54d302dbec66ddd49c4a774376df99e7e9d63980\nPartial-Bug: #1340096\n'}, {'number': 9, 'created': '2014-08-14 12:45:52.000000000', 'files': ['heat/engine/resources/volume.py', 'heat/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/234451b872523293e07c8767e810a634cccf0ee5', 'message': 'Move VolumeAttachment updates to Cinder resource\n\nAccording to AWS docs AWS::EC2::VolumeAttachment resource does not\nsupport any updates [1]. Support of updates in our AWS-compatible\nresource is a bug and needs to be fixed without deprecation period.\n\nThis patch moves VolumeAttachment update logic to native Cinder\nresource.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volumeattachment.html\n\nChange-Id: I54d302dbec66ddd49c4a774376df99e7e9d63980\nPartial-Bug: #1340096\n'}]",4,106623,234451b872523293e07c8767e810a634cccf0ee5,58,12,9,9542,,,0,"Move VolumeAttachment updates to Cinder resource

According to AWS docs AWS::EC2::VolumeAttachment resource does not
support any updates [1]. Support of updates in our AWS-compatible
resource is a bug and needs to be fixed without deprecation period.

This patch moves VolumeAttachment update logic to native Cinder
resource.

[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volumeattachment.html

Change-Id: I54d302dbec66ddd49c4a774376df99e7e9d63980
Partial-Bug: #1340096
",git fetch https://review.opendev.org/openstack/heat refs/changes/23/106623/3 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/volume.py'],1,15c50ea81d09af5184fc40922c81838f24b1ffa9,bug/1340096," # TODO(pshchelo): After deprecation period (in L cycle) # move the handle_update method to native OS::Cinder::Volume resource def handle_update(self, json_snippet, tmpl_diff, prop_diff): if type(self) is VolumeAttachment: LOG.warning(_(""Updates to AWS::EC2::VolumeAttachment "" ""are deprecated and will be removed - "" ""use native OS::Cinder::VolumeAttachment instead.""))"," def handle_update(self, json_snippet, tmpl_diff, prop_diff):",6,0
openstack%2Fpython-swiftclient~master~I7ad0ee6d88f8393e3a93e90cd52b9b592da7072d,openstack/python-swiftclient,master,I7ad0ee6d88f8393e3a93e90cd52b9b592da7072d,Clean up raw policy stats in account stat,MERGED,2014-07-31 12:05:25.000000000,2014-08-14 15:11:18.000000000,2014-08-14 15:11:18.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 5189}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-31 12:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/964f26ac905bc94b41486284c630524ea0f86871', 'message': ""Clean up raw policy stats in account stat\n\nStorage policy stats was not well parsed in account stat. This\npatch parses the stats and print out the stats in a sorted json\nformat like below:\n\n$swift account stat\n       Account: AUTH_test\n    Containers: 5\n       Objects: 1\n         Bytes: 2097152\nStorage_Policy_golden: {'objects': '1', 'bytes': '2097152'}\nStorage_Policy_silver: {'objects': '0', 'bytes': '0'}\n   X-Timestamp: 1404697760.88809\n    X-Trans-Id: txec519e24b44a413abb705-0053da2dcb\n  Content-Type: text/plain; charset=utf-8\n Accept-Ranges: bytes\n\nChange-Id: I7ad0ee6d88f8393e3a93e90cd52b9b592da7072d\n""}, {'number': 2, 'created': '2014-07-31 14:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/3428fe2e010c620b08d554cceddb1ed8e602a693', 'message': ""Clean up raw policy stats in account stat\n\nStorage policy stats was not well parsed in account stat. This\npatch parses the stats and print out the stats in a sorted json\nformat like below:\n\n$swift account stat\n       Account: AUTH_test\n    Containers: 5\n       Objects: 1\n         Bytes: 2097152\nStorage_Policy_golden: {'objects': '1', 'bytes': '2097152'}\nStorage_Policy_silver: {'objects': '0', 'bytes': '0'}\n   X-Timestamp: 1404697760.88809\n    X-Trans-Id: txec519e24b44a413abb705-0053da2dcb\n  Content-Type: text/plain; charset=utf-8\n Accept-Ranges: bytes\n\nChange-Id: I7ad0ee6d88f8393e3a93e90cd52b9b592da7072d\n""}, {'number': 3, 'created': '2014-08-01 01:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/14f09360885cb56f4d1f45556e94503269d3e53d', 'message': ""Clean up raw policy stats in account stat\n\nStorage policy stats was not well parsed in account stat. This\npatch parses the stats and print out the stats in a sorted json\nformat like below:\n\n$swift account stat\n       Account: AUTH_test\n    Containers: 5\n       Objects: 1\n         Bytes: 2097152\nStorage-Policy-golden: {'objects': '1', 'bytes': '2097152'}\nStorage-Policy-silver: {'objects': '0', 'bytes': '0'}\n   X-Timestamp: 1404697760.88809\n    X-Trans-Id: txec519e24b44a413abb705-0053da2dcb\n  Content-Type: text/plain; charset=utf-8\n Accept-Ranges: bytes\n\nChange-Id: I7ad0ee6d88f8393e3a93e90cd52b9b592da7072d\n""}, {'number': 4, 'created': '2014-08-01 02:35:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/692b2b6563769508b552eae24c7df53fb148e872', 'message': 'Clean up raw policy stats in account stat\n\nStorage policy stats was not well parsed in account stat. This\npatch parses the stats and print out the stats in a format like below:\n\n$swift account stat\n       Account: AUTH_test\n    Containers: 5\n       Objects: 1\n         Bytes: 2097152\nObjects in policy ""golden"": 1\nBytess in policy ""golden"": 2097152\nObjects in policy ""silver"": 0\nBytes in policy ""silver"": 0\n   X-Timestamp: 1404697760.88809\n    X-Trans-Id: txec519e24b44a413abb705-0053da2dcb\n  Content-Type: text/plain; charset=utf-8\n Accept-Ranges: bytes\n\nChange-Id: I7ad0ee6d88f8393e3a93e90cd52b9b592da7072d\n'}, {'number': 5, 'created': '2014-08-04 02:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/cd967ba9d6e58fb29857e99274b5a1a00c590bed', 'message': 'Clean up raw policy stats in account stat\n\nStorage policy stats was not well parsed in account stat. This\npatch parses the stats and print out the stats in a format like below:\n\n$swift account stat\n                   Account: AUTH_test\n                Containers: 5\n                   Objects: 1\n                     Bytes: 2097152\nObjects in policy ""golden"": 1\n Bytess in policy ""golden"": 2097152\nObjects in policy ""silver"": 0\n  Bytes in policy ""silver"": 0\n               X-Timestamp: 1404697760.88809\n                X-Trans-Id: txec519e24b44a413abb705-0053da2dcb\n              Content-Type: text/plain; charset=utf-8\n             Accept-Ranges: bytes\n\nChange-Id: I7ad0ee6d88f8393e3a93e90cd52b9b592da7072d\n'}, {'number': 6, 'created': '2014-08-04 03:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/10bb2bea8b556b68182fa77fb4be9347885b0a71', 'message': 'Clean up raw policy stats in account stat\n\nStorage policy stats was not well parsed in account stat. This\npatch parses the stats and print out the stats in a format like below:\n\n$swift account stat\n                   Account: AUTH_test\n                Containers: 5\n                   Objects: 1\n                     Bytes: 2097152\nObjects in policy ""golden"": 1\n Bytess in policy ""golden"": 2097152\nObjects in policy ""silver"": 0\n  Bytes in policy ""silver"": 0\n               X-Timestamp: 1404697760.88809\n                X-Trans-Id: txec519e24b44a413abb705-0053da2dcb\n              Content-Type: text/plain; charset=utf-8\n             Accept-Ranges: bytes\n\nChange-Id: I7ad0ee6d88f8393e3a93e90cd52b9b592da7072d\n'}, {'number': 7, 'created': '2014-08-06 08:10:33.000000000', 'files': ['swiftclient/command_helpers.py', 'tests/unit/test_shell.py', 'swiftclient/multithreading.py', 'tests/unit/test_command_helpers.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/776133bd299adfb644f2274143b9fba72672428d', 'message': 'Clean up raw policy stats in account stat\n\nStorage policy stats was not well parsed in account stat. This\npatch parses the stats and print out the stats in a format like below:\n\n$swift -A http://swift_cluster/auth/v1.0 -U test:tester -K testing stat\n                   Account: AUTH_test\n                Containers: 5\n                   Objects: 1\n                     Bytes: 2097152\nObjects in policy ""golden"": 1\n Bytess in policy ""golden"": 2097152\nObjects in policy ""silver"": 0\n  Bytes in policy ""silver"": 0\n               X-Timestamp: 1404697760.88809\n                X-Trans-Id: txec519e24b44a413abb705-0053da2dcb\n              Content-Type: text/plain; charset=utf-8\n             Accept-Ranges: bytes\n\nChange-Id: I7ad0ee6d88f8393e3a93e90cd52b9b592da7072d\n'}]",1,110929,776133bd299adfb644f2274143b9fba72672428d,45,7,7,5189,,,0,"Clean up raw policy stats in account stat

Storage policy stats was not well parsed in account stat. This
patch parses the stats and print out the stats in a format like below:

$swift -A http://swift_cluster/auth/v1.0 -U test:tester -K testing stat
                   Account: AUTH_test
                Containers: 5
                   Objects: 1
                     Bytes: 2097152
Objects in policy ""golden"": 1
 Bytess in policy ""golden"": 2097152
Objects in policy ""silver"": 0
  Bytes in policy ""silver"": 0
               X-Timestamp: 1404697760.88809
                X-Trans-Id: txec519e24b44a413abb705-0053da2dcb
              Content-Type: text/plain; charset=utf-8
             Accept-Ranges: bytes

Change-Id: I7ad0ee6d88f8393e3a93e90cd52b9b592da7072d
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/29/110929/4 && git format-patch -1 --stdout FETCH_HEAD,"['swiftclient/command_helpers.py', 'tests/unit/test_command_helpers.py']",2,964f26ac905bc94b41486284c630524ea0f86871,policy_output," def test_stat_account_policy_stat(self): # stub head_account stub_headers = { 'x-account-container-count': 42, 'x-account-object-count': 1000000, 'x-account-bytes-used': 2 ** 30, 'x-account-storage-policy-nada-bytes-used': 2 ** 30, 'x-account-storage-policy-nada-object-count': 1000000, } self.conn.head_account.return_value = stub_headers with self.thread_manager as thread_manager: h.stat_account(self.conn, self.options, thread_manager) expected = """""" Account: a Containers: 42 Objects: 1000000 Bytes: 1073741824 Storage_Policy_nada: {'objects': 1000000, 'bytes': 1073741824} """""" self.assertOut(expected) ",,35,0
openstack%2Fdevstack~master~I0c4bb8a10960ed3ee06b67a209703d7ee81cf1ca,openstack/devstack,master,I0c4bb8a10960ed3ee06b67a209703d7ee81cf1ca,Setup AMQP properly for glance-registry,MERGED,2014-08-13 15:21:59.000000000,2014-08-14 15:11:16.000000000,2014-08-14 15:11:15.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2537}, {'_account_id': 6172}, {'_account_id': 6549}, {'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-13 15:21:59.000000000', 'files': ['lib/glance'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0d02924639e1ca138f2c7eee795f2d208680e7ab', 'message': 'Setup AMQP properly for glance-registry\n\nAs we integrated OSprofiler with Glance:\nhttps://review.openstack.org/#/c/105635/\n\nglance-registry service started using notification API so it requires\nproper seted up AMQP.\n\nChange-Id: I0c4bb8a10960ed3ee06b67a209703d7ee81cf1ca\n'}]",0,113929,0d02924639e1ca138f2c7eee795f2d208680e7ab,23,8,1,6172,,,0,"Setup AMQP properly for glance-registry

As we integrated OSprofiler with Glance:
https://review.openstack.org/#/c/105635/

glance-registry service started using notification API so it requires
proper seted up AMQP.

Change-Id: I0c4bb8a10960ed3ee06b67a209703d7ee81cf1ca
",git fetch https://review.opendev.org/openstack/devstack refs/changes/29/113929/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/glance'],1,0d02924639e1ca138f2c7eee795f2d208680e7ab,fix_glance_registry_amqp_setup," if is_service_enabled qpid || [ -n ""$RABBIT_HOST"" ] && [ -n ""$RABBIT_PASSWORD"" ]; then iniset $GLANCE_REGISTRY_CONF DEFAULT notification_driver messaging fi iniset_rpc_backend glance $GLANCE_REGISTRY_CONF DEFAULT",,4,0
openstack%2Ftraining-guides~master~Ie1f9659c0f0a5525a8a653ab29345c637046173c,openstack/training-guides,master,Ie1f9659c0f0a5525a8a653ab29345c637046173c,Fix the broken links in Getting Started chapter,MERGED,2014-08-14 03:29:51.000000000,2014-08-14 15:10:28.000000000,2014-08-14 15:10:27.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 9853}, {'_account_id': 11109}, {'_account_id': 12834}]","[{'number': 1, 'created': '2014-08-14 03:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/bf1cee0318be5b72e2464cbdd86de84cfbb4cd7b', 'message': 'Fix the broken links in Getting Started chapter\n\nGoogle short URL links are no longer valid. We should directly\nuse the URL.\n\nChange-Id: Ie1f9659c0f0a5525a8a653ab29345c637046173c\nCloses-bug: #1341449\n'}, {'number': 2, 'created': '2014-08-14 04:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/308d169aea0ba2bf7d7615a1cee5369ef9e850e6', 'message': 'Fix the broken links in Getting Started chapter\n\nGoogle short URL links are no longer valid. We should directly\nuse the URL.\n\nChange-Id: Ie1f9659c0f0a5525a8a653ab29345c637046173c\nCloses-bug: #1341449\n'}, {'number': 3, 'created': '2014-08-14 04:50:32.000000000', 'files': ['doc/training-guides/common/section_brief-overview.xml', 'doc/training-guides/common/section_core-projects.xml', 'doc/training-guides/common/section_vm-provisioning-walk-through.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/d9e9ed3d103da6602fa7b0eff6599db3f80ef3c1', 'message': 'Fix the broken links in Getting Started chapter\n\nGoogle short URL links are no longer valid. We should directly\nuse the URL.\n\nChange-Id: Ie1f9659c0f0a5525a8a653ab29345c637046173c\nCloses-bug: #1341449\n'}]",12,114111,d9e9ed3d103da6602fa7b0eff6599db3f80ef3c1,20,5,3,9853,,,0,"Fix the broken links in Getting Started chapter

Google short URL links are no longer valid. We should directly
use the URL.

Change-Id: Ie1f9659c0f0a5525a8a653ab29345c637046173c
Closes-bug: #1341449
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/11/114111/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/training-guides/common/section_brief-overview.xml', 'doc/training-guides/common/section_core-projects.xml', 'doc/training-guides/locale/training-guides.pot', 'doc/training-guides/common/section_vm-provisioning-walk-through.xml']",4,bf1cee0318be5b72e2464cbdd86de84cfbb4cd7b,," xlink:href=""http://www.linux-kvm.org"" >http://www.linux-kvm.org</link>)</para> xlink:href=""http://linuxcontainers.org"" >http://linuxcontainers.org</link>)</para> xlink:href=""http://www.qemu.org"" >http://www.qemu.org</link>)</para> xlink:href=""http://en.wikipedia.org/wiki/User-mode_Linux"" >http://en.wikipedia.org/wiki/User-mode_Linux</link>)</para> xlink:href=""http://vmware.com/products/vsphere"" >http://vmware.com/products/vspher</link>)</para> (visit <link xlink:href=""http://wiki.xen.org"" >http://wiki.xen.org</link>)</para> sub-drivers. (visit <link xlink:href=""https://wiki.openstack.org/wiki/GeneralBareMetalProvisioningFrameworkhttp://goo.gl/exfeSg"" >this wiki page</link>)</para>"," <link xlink:href=""http://goo.gl/n7AXnC""> http://goo.gl/n7AXnC</link> xlink:href=""http://goo.gl/70dvRb"" >http://goo.gl/70dvRb</link>)</para> xlink:href=""http://goo.gl/Ous3ly"" >http://goo.gl/Ous3ly</link>)</para> xlink:href=""http://goo.gl/WWV9lL"" >http://goo.gl/WWV9lL</link>)</para> xlink:href=""http://goo.gl/4HAkJj"" >http://goo.gl/4HAkJj</link>)</para> xlink:href=""http://goo.gl/0DBeo5"" >http://goo.gl/0DBeo5</link>)</para> (visit <link xlink:href=""http://goo.gl/yXP9t1"" >http://goo.gl/yXP9t1</link>)</para> sub-drivers. (visit <link xlink:href=""http://goo.gl/exfeSg"" >http://goo.gl/exfeSg</link>)</para>",33,32
openstack%2Fzaqar~master~Iffc893407beddbf25d5b5c33a44581f3eb5dcded,openstack/zaqar,master,Iffc893407beddbf25d5b5c33a44581f3eb5dcded,Update files from oslo-incubator,MERGED,2014-08-13 13:25:24.000000000,2014-08-14 15:10:22.000000000,2014-08-14 15:10:22.000000000,"[{'_account_id': 3}, {'_account_id': 6427}]","[{'number': 1, 'created': '2014-08-13 13:25:24.000000000', 'files': ['zaqar/openstack/common/log.py', 'tools/config/check_uptodate.sh', 'zaqar/openstack/common/lockutils.py', 'tools/config/generate_sample.sh', 'zaqar/openstack/common/fileutils.py', 'zaqar/openstack/common/strutils.py', 'tools/config/oslo.config.generator.rc', 'zaqar/openstack/common/gettextutils.py', 'zaqar/openstack/common/jsonutils.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/62dc2476dbee52dcf3f722a862f1cdf0a1eb4bed', 'message': 'Update files from oslo-incubator\n\nChange-Id: Iffc893407beddbf25d5b5c33a44581f3eb5dcded\n'}]",0,113885,62dc2476dbee52dcf3f722a862f1cdf0a1eb4bed,9,2,1,6159,,,0,"Update files from oslo-incubator

Change-Id: Iffc893407beddbf25d5b5c33a44581f3eb5dcded
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/85/113885/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/openstack/common/log.py', 'tools/config/check_uptodate.sh', 'zaqar/openstack/common/lockutils.py', 'tools/config/generate_sample.sh', 'zaqar/openstack/common/fileutils.py', 'zaqar/openstack/common/strutils.py', 'tools/config/oslo.config.generator.rc', 'zaqar/openstack/common/gettextutils.py', 'zaqar/openstack/common/jsonutils.py']",9,62dc2476dbee52dcf3f722a862f1cdf0a1eb4bed,,"def dump(obj, fp, *args, **kwargs): return json.dump(obj, fp, *args, **kwargs) ",,187,138
openstack%2Fopenstack-manuals~master~Iaf09e0ba8e293c27eaeb5d5c9b75ea18ab94c9e7,openstack/openstack-manuals,master,Iaf09e0ba8e293c27eaeb5d5c9b75ea18ab94c9e7,Update the yum install maven in README,MERGED,2014-08-12 10:09:17.000000000,2014-08-14 15:06:02.000000000,2014-08-14 15:06:01.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-08-12 10:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/568dbe1f0aef79cea5a1e070d368a5a4521af8b6', 'message': 'Update the yum install maven in README\n\nI tried installing maven with ""yum install maven3"" and got\nerror ""No package maven3"" on F20. I did a yum search for maven\nand I did not find the maven3 package, but if I do,\n""yum install maven"" I get the maven package and dependencies with\nversion 3.\n\nI think we need to update the documentation with that.\n\nChange-Id: Iaf09e0ba8e293c27eaeb5d5c9b75ea18ab94c9e7\n'}, {'number': 2, 'created': '2014-08-12 11:34:44.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2b34c69fe2435c4758c9d8d4b89eb81c85cb19fa', 'message': 'Update the yum install maven in README\n\nMaven does not install on ""yum install maven3"" on Fedora20.\nSearching for Maven3 package does not give any results.\nThe correct way to install Maven3 on Fedora is to\nrun ""yum install maven"" instead.\nThis installs Maven3 and its dependencies.\n\nI think we need to update the documentation with that.\n\nChange-Id: Iaf09e0ba8e293c27eaeb5d5c9b75ea18ab94c9e7\n'}]",2,113474,2b34c69fe2435c4758c9d8d4b89eb81c85cb19fa,15,5,2,11105,,,0,"Update the yum install maven in README

Maven does not install on ""yum install maven3"" on Fedora20.
Searching for Maven3 package does not give any results.
The correct way to install Maven3 on Fedora is to
run ""yum install maven"" instead.
This installs Maven3 and its dependencies.

I think we need to update the documentation with that.

Change-Id: Iaf09e0ba8e293c27eaeb5d5c9b75ea18ab94c9e7
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/74/113474/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,568dbe1f0aef79cea5a1e070d368a5a4521af8b6,updateyuminstallmaven,On Fedora 20 and later:: yum install maven,On Fedora 15 and later:: yum install maven3,2,2
openstack%2Fopenstack-manuals~master~I04c0d5b2fe7d72e120b82da9039d116ad4c802cc,openstack/openstack-manuals,master,I04c0d5b2fe7d72e120b82da9039d116ad4c802cc,Typos and spellings errors in common/ dir,MERGED,2014-08-13 16:10:46.000000000,2014-08-14 15:05:55.000000000,2014-08-14 15:05:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9515}, {'_account_id': 12840}]","[{'number': 1, 'created': '2014-08-13 16:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8f0f412f02a6d6c66318cc3ed5ca4eceec33cb04', 'message': 'Typos and spellings errors in common/ dir\n\nThis is another series of typo/spelling errors fixing, in particular for\ncommon/ dir\n\nChange-Id: I04c0d5b2fe7d72e120b82da9039d116ad4c802cc\nCloses-Bug: #1356460\n'}, {'number': 2, 'created': '2014-08-14 09:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a7845438aa8d0208f8076668f9ca17cc9beebb29', 'message': 'Typos and spellings errors in common/ dir\n\nThis is another series of typo/spelling errors fixing, in particular for\ncommon/ dir\n\nChange-Id: I04c0d5b2fe7d72e120b82da9039d116ad4c802cc\nCloses-Bug: #1356460\n'}, {'number': 3, 'created': '2014-08-14 09:42:52.000000000', 'files': ['doc/common/section_getstart_networking.xml', 'doc/common/section_objectstorage-account-reaper.xml', 'doc/admin-guide-cloud/networking/section_networking_introduction.xml', 'doc/common/section_getstart_image.xml', 'doc/common/samples/ceilometer.conf', 'doc/common/section_getstart_block-storage.xml', 'doc/common/section_cli_help.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/aef24a18470bf248e432b2df737fefd13c75de02', 'message': 'Typos and spellings errors in common/ dir\n\nThis is another series of typo/spelling errors fixing, in particular for\ncommon/ dir\n\nChange-Id: I04c0d5b2fe7d72e120b82da9039d116ad4c802cc\nCloses-Bug: #1356460\n'}]",1,113951,aef24a18470bf248e432b2df737fefd13c75de02,20,4,3,12840,,,0,"Typos and spellings errors in common/ dir

This is another series of typo/spelling errors fixing, in particular for
common/ dir

Change-Id: I04c0d5b2fe7d72e120b82da9039d116ad4c802cc
Closes-Bug: #1356460
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/51/113951/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/tables/keystone-conf-changes-icehouse.xml', 'doc/cli-reference/generated/ch_cli_neutron_commands.xml', 'doc/common/tables/neutron-database.xml', 'doc/common/tables/neutron-auth_token.xml', 'doc/common/tables/ceilometer-conf-changes-icehouse.xml', 'doc/common/tables/keystone-zeromq.xml', 'doc/common/tables/nova-baremetal.xml', 'doc/common/tables/heat-auth_token.xml', 'doc/common/tables/cinder-conf-changes-icehouse.xml', 'doc/common/tables/glance-database.xml', 'doc/common/tables/ceilometer-vmware.xml', 'doc/common/samples/ceilometer.conf', 'doc/common/section_getstart_block-storage.xml', 'doc/common/tables/neutron-ml2_bigswitch.xml', 'doc/common/tables/keystone-rpc.xml', 'doc/common/tables/nova-rootwrap.xml', 'doc/common/tables/trove-auth_token.xml', 'doc/common/tables/cinder-images.xml', 'doc/common/tables/neutron-nuage.xml', 'doc/common/tables/trove-debug.xml', 'doc/common/tables/cinder-solidfire.xml', 'doc/common/tables/glance-logging.xml', 'doc/common/tables/nova-auth_token.xml', 'doc/common/tables/nova-network.xml', 'doc/common/tables/nova-common.xml', 'doc/common/tables/nova-zeromq.xml', 'doc/common/tables/nova-upgrade_levels.xml', 'doc/common/tables/swift-object-server-object-replicator.xml', 'doc/common/tables/neutron-midonet.xml', 'doc/common/tables/swift-proxy-server-filter-proxy-logging.xml', 'doc/common/tables/glance-swift.xml', 'doc/common/tables/neutron-metadata.xml', 'doc/common/tables/keystone-logging.xml', 'doc/common/tables/nova-volumes.xml', 'doc/common/tables/cinder-rootwrap.xml', 'doc/common/tables/trove-db_mongodb.xml', 'doc/common/tables/neutron-ml2_cisco_apic.xml', 'doc/common/tables/cinder-rpc.xml', 'doc/common/section_getstart_networking.xml', 'doc/common/tables/neutron-ml2_ofa.xml', 'doc/common/tables/swift-proxy-server-DEFAULT.xml', 'doc/common/tables/nova-xen.xml', 'doc/common/tables/keystone-debug.xml', 'doc/common/tables/trove-zeromq.xml', 'doc/common/tables/nova-database.xml', 'doc/common/tables/nova-testing.xml', 'doc/common/tables/nova-rpc_all.xml', 'doc/common/tables/swift-proxy-server-filter-cname_lookup.xml', 'doc/common/section_cli_help.xml', 'doc/common/tables/heat-database.xml', 'doc/common/tables/swift-conf-changes-icehouse.xml', 'doc/common/tables/glance-imagecache.xml', 'doc/common/tables/neutron-conf-changes-icehouse.xml', 'doc/common/tables/neutron-bigswitch.xml', 'doc/common/section_getstart_image.xml', 'doc/common/tables/ceilometer-rpc.xml', 'doc/common/tables/glance-zmq.xml', 'doc/common/tables/heat-debug.xml', 'doc/common/tables/glance-common.xml', 'doc/common/tables/neutron-zeromq.xml', 'doc/common/tables/neutron-rootwrap.xml', 'doc/common/tables/keystone-token.xml', 'doc/common/tables/neutron-testing.xml', 'doc/admin-guide-cloud/networking/section_networking_introduction.xml', 'doc/common/tables/neutron-common.xml', 'doc/common/tables/swift-swift-swift-hash.xml', 'doc/common/tables/nova-glance.xml', 'doc/common/tables/keystone-auth_token.xml', 'doc/common/tables/glance-cinder.xml', 'doc/common/tables/neutron-cisco.xml', 'doc/common/tables/neutron-rpc.xml', 'doc/common/section_objectstorage-account-reaper.xml', 'doc/common/tables/neutron-brocade.xml', 'doc/common/tables/glance-auth_token.xml', 'doc/common/tables/heat-rpc.xml', 'doc/common/tables/neutron-compute.xml', 'doc/common/tables/glance-rpc.xml', 'doc/common/tables/keystone-revoke.xml', 'doc/common/tables/nova-conf-changes-icehouse.xml', 'doc/common/tables/keystone-api.xml', 'doc/common/tables/neutron-vmware.xml', 'doc/common/tables/glance-conf-changes-icehouse.xml', 'doc/common/tables/neutron-ml2_arista.xml', 'doc/common/tables/trove-rpc.xml', 'doc/common/tables/heat-zeromq.xml', 'doc/common/tables/neutron-ml2_l2pop.xml', 'doc/common/tables/nova-s3.xml', 'doc/common/tables/nova-metadata.xml']",88,8f0f412f02a6d6c66318cc3ed5ca4eceec33cb04,fixing-typos-2, <td>(StrOpt) File to load JSON formatted vendor data from</td>, <td>(StrOpt) File to load json formatted vendor data from</td>,134,134
openstack%2Ftripleo-image-elements~master~Ie2289e75bb4a7f1240916c613e500f512937283d,openstack/tripleo-image-elements,master,Ie2289e75bb4a7f1240916c613e500f512937283d,Fix Fedora builds on Ubuntu,MERGED,2014-07-23 13:04:31.000000000,2014-08-14 15:05:29.000000000,2014-08-14 15:05:29.000000000,"[{'_account_id': 3}, {'_account_id': 114}, {'_account_id': 1926}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 8399}, {'_account_id': 9369}, {'_account_id': 9712}]","[{'number': 1, 'created': '2014-07-23 13:04:31.000000000', 'files': ['elements/selinux/bin/add-selinux-path-substitution', 'elements/selinux/install.d/00-install-and-load-selinux-policy'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e1e755b207dfbb336381444df298bee3480e2d55', 'message': 'Fix Fedora builds on Ubuntu\n\nChange Ibffa1b986b52a1dc28de8d3b8056eed92aae9ee7 broke Fedora\nbuilds on Ubuntu. The problem is load_policy has no policy to\nload in Ubuntu.\n\nUsing the -N option with semanage fcontext removes the need to\nload the SELinux policy.\n\nChange-Id: Ie2289e75bb4a7f1240916c613e500f512937283d\nCloses-Bug: 1347295\n'}]",0,108986,e1e755b207dfbb336381444df298bee3480e2d55,49,10,1,7471,,,0,"Fix Fedora builds on Ubuntu

Change Ibffa1b986b52a1dc28de8d3b8056eed92aae9ee7 broke Fedora
builds on Ubuntu. The problem is load_policy has no policy to
load in Ubuntu.

Using the -N option with semanage fcontext removes the need to
load the SELinux policy.

Change-Id: Ie2289e75bb4a7f1240916c613e500f512937283d
Closes-Bug: 1347295
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/86/108986/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/selinux/bin/add-selinux-path-substitution', 'elements/selinux/install.d/00-install-and-load-selinux-policy']",2,e1e755b207dfbb336381444df298bee3480e2d55,bug/1347295,,#!/bin/bash set -eux set -o pipefail [ -x /usr/sbin/semanage ] || exit 0 # Updates the selinux-policy if one is available. We should # be loading the latest version. install-packages selinux-policy selinux-policy-targeted # Loads the selinux policy during image build. # This allows commands like setsebool and semange to work # during image build. load_policy -i ,1,15
openstack%2Ftripleo-ci~master~I71a0080d68aeb25d8254783d20e28dcce6f95482,openstack/tripleo-ci,master,I71a0080d68aeb25d8254783d20e28dcce6f95482,Add /mnt/state/var/log contents to indexed test logs.,MERGED,2014-06-11 02:35:51.000000000,2014-08-14 15:03:39.000000000,2014-08-14 15:03:39.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 4220}, {'_account_id': 6928}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-06-11 02:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2abe330c430b889d56affe2cbc499673102e1390', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nMoving from tarballing everything to rsyncing desired directories\nand compressing them ourselves.\nWe continue to tarball the /etc directory.\nStore $instance/var/log in $instance/root\nStore $instance/mnt/state/var/log in $instance/mnt\nSome re-implementation of https://review.openstack.org/#/c/97947/2\ndue to the nature of these changes.\n\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 2, 'created': '2014-06-11 02:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9328d27b33e3dc81fc0b86f75f4803292017f82f', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nMoving from tarballing everything to rsyncing desired directories\nand compressing them ourselves.\nWe continue to tarball the /etc directory.\nStore $instance/var/log in $instance/root\nStore $instance/mnt/state/var/log in $instance/mnt\nSome re-implementation of https://review.openstack.org/#/c/97947/2\ndue to the nature of these changes.\n\nUpdated due to error in rsync call.\n\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 3, 'created': '2014-06-11 02:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8ca6abff552a974f45703602eafb7e919d68109e', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nMoving from tarballing everything to rsyncing desired directories\nand compressing them ourselves.\nWe continue to tarball the /etc directory.\nStore $instance/var/log in $instance/root\nStore $instance/mnt/state/var/log in $instance/mnt\nSome re-implementation of https://review.openstack.org/#/c/97947/2\ndue to the nature of these changes.\n\nUpdated due to error in rsync call.\n\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 4, 'created': '2014-06-11 04:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/4d04dd48b28e6a4a3c956d84d31ee8b15d9c28ac', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nMoving from tarballing everything to rsyncing desired directories\nand compressing them ourselves.\nWe continue to tarball the /etc directory.\nStore $instance/var/log in $instance/root\nStore $instance/mnt/state/var/log in $instance/mnt\nSome re-implementation of https://review.openstack.org/#/c/97947/2\ndue to the nature of these changes.\n\nUpdated due to error in rsync call.\nUpdated to fix test failures due to workspace path + to fix path in archive\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 5, 'created': '2014-06-11 06:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/385813d71318b105e08b84ae63a5be6e00fb3eee', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nMoving from tarballing everything to rsyncing desired directories\nand compressing them ourselves.\nWe continue to tarball the /etc directory.\nStore $instance/var/log in $instance/root\nStore $instance/mnt/state/var/log in $instance/mnt\nSome re-implementation of https://review.openstack.org/#/c/97947/2\ndue to the nature of these changes.\n\nUpdated due to error in rsync call.\nUpdated to fix test failures due to workspace path + to fix path in archive\nUpdated to properly clean up path items from etc tarball\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 6, 'created': '2014-06-11 06:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b102aa1781535f518ab8e9fc3ffdc3489ee36087', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nMoving from tarballing everything to rsyncing desired directories\nand compressing them ourselves.\nWe continue to tarball the /etc directory.\nStore $instance/var/log in $instance/root\nStore $instance/mnt/state/var/log in $instance/mnt\nSome re-implementation of https://review.openstack.org/#/c/97947/2\ndue to the nature of these changes.\n\nUpdated due to error in rsync call.\nUpdated to fix test failures due to workspace path + to fix path in archive\nUpdated to properly clean up path items from etc tarball\nFix trailing whitespace error\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 7, 'created': '2014-06-12 22:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bfb0f2ef64b8699a856ec12c7bace5092143feb4', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nMoving from tarballing everything to rsyncing desired directories\nand compressing them ourselves.\nWe continue to tarball the /etc directory.\nStore $instance/var/log in $instance/root\nStore $instance/mnt/state/var/log in $instance/mnt\nSome re-implementation of https://review.openstack.org/#/c/97947/2\ndue to the nature of these changes.\n\nUpdated due to error in rsync call.\nUpdated to fix test failures due to workspace path + to fix path in archive\nUpdated to properly clean up path items from etc tarball\nFix trailing whitespace error\nMerge from trunk\nUpdate etc tarball creation + incorporate bug feedback.\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 8, 'created': '2014-06-14 02:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/97021c45f4a6517e16a1654a40470e1f1e3220b4', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nMoving from tarballing everything to rsyncing desired directories\nand compressing them ourselves.\nWe continue to tarball the /etc directory.\nStore $instance/var/log in $instance/root\nStore $instance/mnt/state/var/log in $instance/mnt\nSome re-implementation of https://review.openstack.org/#/c/97947/2\ndue to the nature of these changes.\n\nUpdated due to error in rsync call.\nUpdated to fix test failures due to workspace path + to fix path in archive\nUpdated to properly clean up path items from etc tarball\nFix trailing whitespace error\nMerge from trunk\nUpdate etc tarball creation + incorporate bug feedback.\nAlter method for log gathering to use tarball vs. rsync\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 9, 'created': '2014-06-14 18:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/98f00ce0cc511366e0191164590d00685810ac92', 'message': ""Alter how we grab and store machine files to use logstash indexing.\n\nMoving from tarballing everything to rsyncing desired directories\nand compressing them ourselves.\nWe continue to tarball the /etc directory.\nStore $instance/var/log in $instance/root\nStore $instance/mnt/state/var/log in $instance/mnt\nSome re-implementation of https://review.openstack.org/#/c/97947/2\ndue to the nature of these changes.\n\nUpdated due to error in rsync call.\nUpdated to fix test failures due to workspace path + to fix path in archive\nUpdated to properly clean up path items from etc tarball\nFix trailing whitespace error\nMerge from trunk\nUpdate etc tarball creation + incorporate bug feedback.\nAlter method for log gathering to use tarball vs. rsync\nFix of script error / missing 'fi'\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n""}, {'number': 10, 'created': '2014-06-17 00:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/414cca5e76800581f956326aa260bf3305efb917', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nAltering script to extract more files from test machine tarballs.\nContents of /var/log go to $instance/root.\nContents of /mnt/state/var/log go to $instance/mnt.\nWe continue to extract system.journal information to $instance/root.\nThis allows those files to be indexed by logstash.\nThis in turn allows tripleo-ci to leverage elastic-recheck more effectively.\nWe gzip the contents of these directories to save infrastructure from needing to do so.\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 11, 'created': '2014-06-17 02:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3b9a01c10e58366f8a1e4fcdee17be2752d0610a', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nAltering script to extract more files from test machine tarballs.\nContents of /var/log go to $instance/root.\nContents of /mnt/state/var/log go to $instance/mnt.\nWe continue to extract system.journal information to $instance/root.\nThis allows those files to be indexed by logstash.\nThis in turn allows tripleo-ci to leverage elastic-recheck more effectively.\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 12, 'created': '2014-06-17 04:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/47e25114fa59469d167b468f37990797f3816208', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nAltering script to extract more files from test machine tarballs.\nContents of /var/log go to $instance/root.\nContents of /mnt/state/var/log go to $instance/mnt.\nWe continue to extract system.journal information to $instance/root.\nThis allows those files to be indexed by logstash.\nThis in turn allows tripleo-ci to leverage elastic-recheck more effectively.\nTrying to gzip files ourselves to save infra from the workload.\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 13, 'created': '2014-06-17 16:21:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/798e11e8a5d319d15e0c81eef2993fb1029cd1db', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nAltering script to extract more files from test machine tarballs.\nContents of /var/log go to $instance/root.\nContents of /mnt/state/var/log go to $instance/mnt.\nWe continue to extract system.journal information to $instance/root.\nThis allows those files to be indexed by logstash.\nThis in turn allows tripleo-ci to leverage elastic-recheck more effectively.\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 14, 'created': '2014-06-29 01:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e20f45f3208b50fb85f1bc00a0bc2238c1f1750c', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nSimplified patch to only extract /mnt/state/var/log from the tarball.\n\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 15, 'created': '2014-06-30 17:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6c58a7d679effd63ac83447aa47c612a86b2e490', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nThis patch alters / expands the files we extract from our instance tarballs.\nThis is to get these logs indexed by logstash, which expands troubleshooting\nand analysis capabilities.\n\nExtracting /var/log to $instance/root and /mnt/state/var/log to $instance/mnt.\n\nAltered extraction of hostinfo.txt from $instance/ to remain in /var/log.\n\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nCloses-Bug: #1328645\n'}, {'number': 16, 'created': '2014-07-04 03:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/dd5e5c3ef1abfa524310b68a3e465d8ac7432397', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nThis patch alters / expands the files we extract from our instance tarballs.\nThis is to get these logs indexed by logstash, which expands troubleshooting\nand analysis capabilities.\n\nExtracting contents of /mnt/state/var/log to $instance/mnt, if that\ndirectory exists in our tarball.  No mnt dir created if not.\n\nInitial step to expanding indexed log files\n\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nPartial-Bug: #1328645\n'}, {'number': 17, 'created': '2014-07-04 19:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/991eb9c65f94b96aa9c148f16b6f452103a0edc6', 'message': 'Alter how we grab and store machine files to use logstash indexing.\n\nThis patch alters / expands the files we extract from our instance tarballs.\nThis is to get these logs indexed by logstash, which expands troubleshooting\nand analysis capabilities.\n\nNow extracting all of /var/log to $instance/root vs. just upstart and system.journal info.\nChanging extraction of host_info.txt from $instance/ back to $instance/root.\n\nExtracting contents of /mnt/state/var/log to $instance/mnt, if that\ndirectory exists in our tarball.  No mnt dir created if not.\n\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nPartial-Bug: #1328645\n'}, {'number': 18, 'created': '2014-07-08 00:40:16.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a850d03bfe8e3f6536c010c46bee9d4c772d62de', 'message': 'Add /mnt/state/var/log contents to indexed test logs.\n\nThis patch expands the files we extract from our instance tarballs.\nThis is to get these logs indexed by logstash, which expands troubleshooting\nand analysis capabilities.\n\nExtracting contents of /mnt/state/var/log to $instance/mnt, if that\ndirectory exists in our tarball.  No mnt dir created if not.\n\nChange-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482\nPartial-Bug: #1328645\n'}]",6,99250,a850d03bfe8e3f6536c010c46bee9d4c772d62de,111,7,18,4220,,,0,"Add /mnt/state/var/log contents to indexed test logs.

This patch expands the files we extract from our instance tarballs.
This is to get these logs indexed by logstash, which expands troubleshooting
and analysis capabilities.

Extracting contents of /mnt/state/var/log to $instance/mnt, if that
directory exists in our tarball.  No mnt dir created if not.

Change-Id: I71a0080d68aeb25d8254783d20e28dcce6f95482
Partial-Bug: #1328645
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/50/99250/17 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,2abe330c430b889d56affe2cbc499673102e1390,alter-file-storage-for-logstash," ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=QUIET -o PasswordAuthentication=no $2 \ ""( set -x ; ps -ef ; df -h ; uptime ; sudo netstat -lpn ; sudo iptables-save ; sudo ovs-vsctl show ; ip addr ; free ; dpkg -l || rpm -qa) 2>&1 | sudo dd of=/var/log/host_info.txt &> /dev/null"" # rsync files from host to WORKSPACE rsync -avz ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=QUIET \ -o PasswordAuthentication=no $2:/var/log :/etc :/mnt/state/var/log $WORKSPACE/logs/$1_logs # Compress and clean up /etc directory sudo XZ_OPT=-3 tar -cJf $WORKSPACE/logs/$1_logs/$1_etc.tar.xz --exclude=udev/hwdb.bin --exclude=selinux/targeted --exclude=etc/services --exclude=etc/pki $WORKSPACE/logs/$1_logs/etc rm -rf $WORKSPACE/logs/$1_logs/etc # Move $instance/var/log to $instance/root/var/log mkdir $WORKSPACE/logs/$1_logs/root mv $WORKSPACE/logs/$1_logs/var/log $WORKSPACE/logs/$1_logs/root/ # Grab system.journal info for logstash in F20 builds SYSTEM_JOURNAL=$(find $WORKSPACE/logs/$1_logs/root/ -type f -name system.journal) if [ -n ""$SYSTEM_JOURNAL"" ]; then for UNIT in $(journalctl --file $SYSTEM_JOURNAL -F _SYSTEMD_UNIT) ; do journalctl --file $SYSTEM_JOURNAL -u $UNIT > $WORKSPACE/logs/$1_logs/root/${UNIT/.service/.log} done # Compress our files gzip -r -9 $WORKSPACE/logs/$1_logs/* "," ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=QUIET -o PasswordAuthentication=no $2 \ ""( set -x ; ps -ef ; df -h ; uptime ; sudo netstat -lpn ; sudo iptables-save ; sudo ovs-vsctl show ; ip addr ; free ; dpkg -l || rpm -qa) 2>&1 | sudo dd of=/var/log/host_info.txt &> /dev/null ; sudo XZ_OPT=-3 tar -cJf - --exclude=udev/hwdb.bin --exclude=selinux/targeted --exclude=etc/services --exclude=etc/pki /var/log /etc /mnt/state/var/log || true"" > $WORKSPACE/logs/$1_logs.tar.xz # Extract the upstart logs so we can add them to logstash.openstack.org for analysis if tar tf $WORKSPACE/logs/$1_logs.tar.xz var/log/upstart >/dev/null 2>&1; then tar xJvf $WORKSPACE/logs/$1_logs.tar.xz -C $WORKSPACE/logs/$1_logs var/log/upstart --strip-components=3",26,5
openstack%2Ffuel-library~stable%2F5.0~Icf7ad69947270ac50172d2a9db3b1bb2e84112fe,openstack/fuel-library,stable/5.0,Icf7ad69947270ac50172d2a9db3b1bb2e84112fe,Fix problem with domain name,ABANDONED,2014-08-14 14:14:04.000000000,2014-08-14 14:56:30.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11081}, {'_account_id': 12559}]","[{'number': 1, 'created': '2014-08-14 14:14:04.000000000', 'files': ['deployment/puppet/nailgun/examples/nailgun-only.pp', 'deployment/puppet/nailgun/manifests/venv.pp', 'deployment/puppet/nailgun/templates/settings.yaml.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/319eddde2d2102214e57c234f84b1aed9f649f54', 'message': 'Fix problem with domain name\n\nWe can use variables from astute.yaml file instead facter variables\n\nChange-Id: Icf7ad69947270ac50172d2a9db3b1bb2e84112fe\nCloses-Bug: #1346939\n'}]",1,114256,319eddde2d2102214e57c234f84b1aed9f649f54,9,9,1,11090,,,0,"Fix problem with domain name

We can use variables from astute.yaml file instead facter variables

Change-Id: Icf7ad69947270ac50172d2a9db3b1bb2e84112fe
Closes-Bug: #1346939
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/56/114256/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/nailgun/examples/nailgun-only.pp', 'deployment/puppet/nailgun/manifests/venv.pp', 'deployment/puppet/nailgun/templates/settings.yaml.erb']",3,319eddde2d2102214e57c234f84b1aed9f649f54,bug/1346939-5.0,"DNS_DOMAIN: ""<%= @dns_domain %>""DNS_SEARCH: ""<%= @dns_domain.gsub(/,/, ' ') %>""","DNS_DOMAIN: ""<%= @domain %>""DNS_SEARCH: ""<%= @domain %>""",8,2
openstack%2Frequirements~master~I0b4129ac3f4109f1d74d9b63781eb76330fdc5b6,openstack/requirements,master,I0b4129ac3f4109f1d74d9b63781eb76330fdc5b6,Add IDMapShift for Nova,ABANDONED,2014-06-09 20:46:07.000000000,2014-08-14 14:45:26.000000000,,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 5387}, {'_account_id': 7680}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-09 20:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/5b32b1ce9323b7384a66064ab54cb6cade929aa8', 'message': 'Add idmapshift for Nova\n\nIdmapshift is introduced in https://review.openstack.org/#/c/95279/\n\nIdmapshift is a simple utility used to properly set up ownership\nof filesystems used by containers running in user namespaced\nenvironments. It is used by Nova when spawning containers when\nuser namespaces is enabled.\n\nChange-Id: I0b4129ac3f4109f1d74d9b63781eb76330fdc5b6\nPyPI: https://pypi.python.org/pypi/IDMapShift\nGithub: https://github.com/ramielrowe/idmapshift\n'}, {'number': 2, 'created': '2014-06-09 20:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/8f55668b2b73387071470a9e2adf6e35ef4d17ab', 'message': 'Add idmapshift for Nova\n\nIdmapshift is introduced in https://review.openstack.org/#/c/95279/\n\nIdmapshift is a simple utility used to properly set up ownership\nof filesystems used by containers running in user namespaced\nenvironments. It is used by Nova when spawning containers when\nuser namespaces is enabled.\n\nPyPI - https://pypi.python.org/pypi/IDMapShift\nGithub - https://github.com/ramielrowe/idmapshift\n\nChange-Id: I0b4129ac3f4109f1d74d9b63781eb76330fdc5b6\n'}, {'number': 3, 'created': '2014-06-09 21:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/1ac34cd3fa02a4545f655852a729fc6bd4b94315', 'message': 'Add idmapshift for Nova\n\nIdmapshift is introduced in https://review.openstack.org/#/c/95279/\n\nIdmapshift is a simple utility used to properly set up ownership\nof filesystems used by containers running in user namespaced\nenvironments. It is used by Nova when spawning containers when\nuser namespaces is enabled.\n\nPyPI - https://pypi.python.org/pypi/IDMapShift\nGithub - https://github.com/ramielrowe/idmapshift\n\nChange-Id: I0b4129ac3f4109f1d74d9b63781eb76330fdc5b6\n'}, {'number': 4, 'created': '2014-06-10 17:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/227d2643be913c68da1b4b02a38d89fa33484d2e', 'message': 'Add IDMapShift for Nova\n\nIDMapShift is introduced in https://review.openstack.org/#/c/95279/\n\nIdmapshift is a simple utility used to properly set up ownership\nof filesystems used by containers running in user namespaced\nenvironments. It is used by Nova when spawning containers when\nuser namespaces is enabled.\n\nPyPI - https://pypi.python.org/pypi/IDMapShift\nGithub - https://github.com/ramielrowe/idmapshift\n\nChange-Id: I0b4129ac3f4109f1d74d9b63781eb76330fdc5b6\n'}, {'number': 5, 'created': '2014-06-10 23:13:25.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3329258dbdd5240e9650ea0f76f424b95f3fdf95', 'message': 'Add IDMapShift for Nova\n\nIDMapShift is introduced in https://review.openstack.org/#/c/95279/\n\nIdmapshift is a simple utility used to properly set up ownership\nof filesystems used by containers running in user namespaced\nenvironments. It is used by Nova when spawning containers when\nuser namespaces is enabled.\n\nPyPI - https://pypi.python.org/pypi/IDMapShift\nGithub - https://github.com/ramielrowe/idmapshift\n\nChange-Id: I0b4129ac3f4109f1d74d9b63781eb76330fdc5b6\n'}]",2,98888,3329258dbdd5240e9650ea0f76f424b95f3fdf95,29,6,5,5387,,,0,"Add IDMapShift for Nova

IDMapShift is introduced in https://review.openstack.org/#/c/95279/

Idmapshift is a simple utility used to properly set up ownership
of filesystems used by containers running in user namespaced
environments. It is used by Nova when spawning containers when
user namespaces is enabled.

PyPI - https://pypi.python.org/pypi/IDMapShift
Github - https://github.com/ramielrowe/idmapshift

Change-Id: I0b4129ac3f4109f1d74d9b63781eb76330fdc5b6
",git fetch https://review.opendev.org/openstack/requirements refs/changes/88/98888/3 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,5b32b1ce9323b7384a66064ab54cb6cade929aa8,,idmapshift==0.0.1,,1,0
openstack%2Fmurano~master~I8221bc3aa063ecb53e210adf7a2222c92da1c049,openstack/murano,master,I8221bc3aa063ecb53e210adf7a2222c92da1c049,Add openstack libs to config checker,MERGED,2014-08-14 11:52:51.000000000,2014-08-14 14:40:24.000000000,2014-08-14 14:40:23.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}]","[{'number': 1, 'created': '2014-08-14 11:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0d8558d29eced1ed14b0b7c0b9a2285423cae5af', 'message': 'Add openstack libs to config checker\n\nSome parameters were ommitted in murano sample config file\nThis patch adds config params from openstack to config checker\n\nCloses-Bug: #1356787\nChange-Id: I8221bc3aa063ecb53e210adf7a2222c92da1c049\n'}, {'number': 2, 'created': '2014-08-14 12:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/2aae27b0db1bf7fdf6bf9843b7d930e11ae827d4', 'message': 'Add oslo messaging to config checker\n\nSome parameters were omitted in murano sample config file\nThis patch adds config params from openstack to config checker\n\nCloses-Bug: #1356787\nChange-Id: I8221bc3aa063ecb53e210adf7a2222c92da1c049\n'}, {'number': 3, 'created': '2014-08-14 12:20:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/979862d3223ad1bd33189bbb7c078cfdfa5c4c61', 'message': 'Add oslo messaging to config checker\n\nSome parameters were omitted in murano sample config file\nThis patch adds config params from openstack to config checker\n\nCloses-Bug: #1356787\nChange-Id: I8221bc3aa063ecb53e210adf7a2222c92da1c049\n'}, {'number': 4, 'created': '2014-08-14 12:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/4eebebf99490e76a69967a91b95b70be72cd8153', 'message': 'Add openstack libs to config checker\n\nSome parameters were omitted in murano sample config file\nThis patch adds config params from openstack to config checker\n\nCloses-Bug: #1356787\nChange-Id: I8221bc3aa063ecb53e210adf7a2222c92da1c049\n'}, {'number': 5, 'created': '2014-08-14 12:35:27.000000000', 'files': ['tools/config/oslo.config.generator.rc', 'etc/murano/murano.conf.sample'], 'web_link': 'https://opendev.org/openstack/murano/commit/865ed9bef9db907d93e517742153da5da38d9cc1', 'message': 'Add openstack libs to config checker\n\nSome parameters were ommitted in murano sample config file\n\nThis patch adds config params from openstack to config checker\n\nCloses-Bug: #1356787\nChange-Id: I8221bc3aa063ecb53e210adf7a2222c92da1c049\n'}]",0,114212,865ed9bef9db907d93e517742153da5da38d9cc1,27,7,5,7549,,,0,"Add openstack libs to config checker

Some parameters were ommitted in murano sample config file

This patch adds config params from openstack to config checker

Closes-Bug: #1356787
Change-Id: I8221bc3aa063ecb53e210adf7a2222c92da1c049
",git fetch https://review.opendev.org/openstack/murano refs/changes/12/114212/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/config/oslo.config.generator.rc', 'etc/murano/murano.conf.sample']",2,0d8558d29eced1ed14b0b7c0b9a2285423cae5af,bug/1356787,"# Options defined in oslo.messaging # # Use durable queues in amqp. (boolean value) # Deprecated group/name - [DEFAULT]/rabbit_durable_queues #amqp_durable_queues=false # Auto-delete queues in amqp. (boolean value) #amqp_auto_delete=false # Size of RPC connection pool. (integer value) #rpc_conn_pool_size=30 # Modules of exceptions that are permitted to be recreated # upon receiving exception data from an rpc call. (list value) #allowed_rpc_exception_modules=oslo.messaging.exceptions,nova.exception,cinder.exception,exceptions # Qpid broker hostname. (string value) #qpid_hostname=localhost # Qpid broker port. (integer value) #qpid_port=5672 # Qpid HA cluster host:port pairs. (list value) #qpid_hosts=$qpid_hostname:$qpid_port # Username for Qpid connection. (string value) #qpid_username= # Password for Qpid connection. (string value) #qpid_password= # Space separated list of SASL mechanisms to use for auth. # (string value) #qpid_sasl_mechanisms= # Seconds between connection keepalive heartbeats. (integer # value) #qpid_heartbeat=60 # Transport to use, either 'tcp' or 'ssl'. (string value) #qpid_protocol=tcp # Whether to disable the Nagle algorithm. (boolean value) #qpid_tcp_nodelay=true # The qpid topology version to use. Version 1 is what was # originally used by impl_qpid. Version 2 includes some # backwards-incompatible changes that allow broker federation # to work. Users should update to version 2 when they are # able to take everything down, as it requires a clean break. # (integer value) #qpid_topology_version=1 # SSL version to use (valid only if SSL enabled). valid values # are TLSv1, SSLv23 and SSLv3. SSLv2 may be available on some # distributions. (string value) #kombu_ssl_version= # SSL key file (valid only if SSL enabled). (string value) #kombu_ssl_keyfile= # SSL cert file (valid only if SSL enabled). (string value) #kombu_ssl_certfile= # SSL certification authority file (valid only if SSL # enabled). (string value) #kombu_ssl_ca_certs= # How long to wait before reconnecting in response to an AMQP # consumer cancel notification. (floating point value) #kombu_reconnect_delay=1.0 # The RabbitMQ broker address where a single node is used. # (string value) #rabbit_host=localhost # The RabbitMQ broker port where a single node is used. # (integer value) #rabbit_port=5672 # RabbitMQ HA cluster host:port pairs. (list value) #rabbit_hosts=$rabbit_host:$rabbit_port # Connect over SSL for RabbitMQ. (boolean value) #rabbit_use_ssl=false # The RabbitMQ userid. (string value) #rabbit_userid=guest # The RabbitMQ password. (string value) #rabbit_password=guest # the RabbitMQ login method (string value) #rabbit_login_method=AMQPLAIN # The RabbitMQ virtual host. (string value) #rabbit_virtual_host=/ # How frequently to retry connecting with RabbitMQ. (integer # value) #rabbit_retry_interval=1 # How long to backoff for between retries when connecting to # RabbitMQ. (integer value) #rabbit_retry_backoff=2 # Maximum number of RabbitMQ connection retries. Default is 0 # (infinite retry count). (integer value) #rabbit_max_retries=0 # Use HA queues in RabbitMQ (x-ha-policy: all). If you change # this option, you must wipe the RabbitMQ database. (boolean # value) #rabbit_ha_queues=false # If passed, use a fake RabbitMQ provider. (boolean value) #fake_rabbit=false # ZeroMQ bind address. Should be a wildcard (*), an ethernet # interface, or IP. The ""host"" option should point or resolve # to this address. (string value) #rpc_zmq_bind_address=* # MatchMaker driver. (string value) #rpc_zmq_matchmaker=oslo.messaging._drivers.matchmaker.MatchMakerLocalhost # ZeroMQ receiver listening port. (integer value) #rpc_zmq_port=9501 # Number of ZeroMQ contexts, defaults to 1. (integer value) #rpc_zmq_contexts=1 # Maximum number of ingress messages to locally buffer per # topic. Default is unlimited. (integer value) #rpc_zmq_topic_backlog=<None> # Directory for holding IPC sockets. (string value) #rpc_zmq_ipc_dir=/var/run/openstack # Name of this node. Must be a valid hostname, FQDN, or IP # address. Must match ""host"" option, if running Nova. (string # value) #rpc_zmq_host=murano # Seconds to wait before a cast expires (TTL). Only supported # by impl_zmq. (integer value) #rpc_cast_timeout=30 # Heartbeat frequency. (integer value) #matchmaker_heartbeat_freq=300 # Heartbeat time-to-live. (integer value) #matchmaker_heartbeat_ttl=600 # Host to locate redis. (string value) #host=127.0.0.1 # Use this port to connect to redis host. (integer value) #port=6379 # Password for Redis server (optional). (string value) #password=<None> # Size of RPC greenthread pool. (integer value) #rpc_thread_pool_size=64 # Driver or drivers to handle sending notifications. (multi # valued) #notification_driver= # AMQP topic used for OpenStack notifications. (list value) # Deprecated group/name - [rpc_notifier2]/topics #notification_topics=notifications # Seconds to wait for a response from a call. (integer value) #rpc_response_timeout=60 # A URL representing the messaging driver to use and its full # configuration. If not set, we fall back to the rpc_backend # option and driver specific configuration. (string value) #transport_url=<None> # The messaging driver to use, defaults to rabbit. Other # drivers include qpid and zmq. (string value) #rpc_backend=rabbit # The default exchange under which topics are scoped. May be # overridden by an exchange name specified in the # transport_url option. (string value) #control_exchange=openstack #[keystone_authtoken] # # Options defined in keystoneclient.middleware.auth_token # # Prefix to prepend at the beginning of the path. Deprecated, # use identity_uri. (string value) #auth_admin_prefix= # Host providing the admin Identity API endpoint. Deprecated, # use identity_uri. (string value) #auth_host=127.0.0.1 # Port of the admin Identity API endpoint. Deprecated, use # identity_uri. (integer value) #auth_port=35357 # Protocol of the admin Identity API endpoint (http or https). # Deprecated, use identity_uri. (string value) #auth_protocol=https # Complete public Identity API endpoint (string value) #auth_uri=<None> # Complete admin Identity API endpoint. This should specify # the unversioned root endpoint e.g. https://localhost:35357/ # (string value) #identity_uri=<None> # API version of the admin Identity API endpoint (string # value) #auth_version=<None> # Do not handle authorization requests within the middleware, # but delegate the authorization decision to downstream WSGI # components (boolean value) #delay_auth_decision=false # Request timeout value for communicating with Identity API # server. (boolean value) #http_connect_timeout=<None> # How many times are we trying to reconnect when communicating # with Identity API Server. (integer value) #http_request_max_retries=3 # This option is deprecated and may be removed in a future # release. Single shared secret with the Keystone # configuration used for bootstrapping a Keystone # installation, or otherwise bypassing the normal # authentication process. This option should not be used, use # `admin_user` and `admin_password` instead. (string value) #admin_token=<None> # Keystone account username (string value) #admin_user=<None> # Keystone account password (string value) #admin_password=<None> # Keystone service account tenant name to validate user tokens # (string value) #admin_tenant_name=admin # Env key for the swift cache (string value) #cache=<None> # Required if Keystone server requires client certificate # (string value) #certfile=<None> # Required if Keystone server requires client certificate # (string value) #keyfile=<None> # A PEM encoded Certificate Authority to use when verifying # HTTPs connections. Defaults to system CAs. (string value) #cafile=<None> # Verify HTTPS connections. (boolean value) #insecure=false # Directory used to cache files related to PKI tokens (string # value) #signing_dir=<None> # Optionally specify a list of memcached server(s) to use for # caching. If left undefined, tokens will instead be cached # in-process. (list value) # Deprecated group/name - [DEFAULT]/memcache_servers #memcached_servers=<None> # In order to prevent excessive effort spent validating # tokens, the middleware caches previously-seen tokens for a # configurable duration (in seconds). Set to -1 to disable # caching completely. (integer value) #token_cache_time=300 # Determines the frequency at which the list of revoked tokens # is retrieved from the Identity service (in seconds). A high # number of revocation events combined with a low cache # duration may significantly reduce performance. (integer # value) #revocation_cache_time=10 # (optional) if defined, indicate whether token data should be # authenticated or authenticated and encrypted. Acceptable # values are MAC or ENCRYPT. If MAC, token data is # authenticated (with HMAC) in the cache. If ENCRYPT, token # data is encrypted and authenticated in the cache. If the # value is not one of these options or empty, auth_token will # raise an exception on initialization. (string value) #memcache_security_strategy=<None> # (optional, mandatory if memcache_security_strategy is # defined) this string is used for key derivation. (string # value) #memcache_secret_key=<None> # (optional) indicate whether to set the X-Service-Catalog # header. If False, middleware will not ask for service # catalog on token validation and will not set the X-Service- # Catalog header. (boolean value) #include_service_catalog=true # Used to control the use and type of token binding. Can be # set to: ""disabled"" to not check token binding. ""permissive"" # (default) to validate binding information if the bind type # is of a form known to the server and ignore it if not. # ""strict"" like ""permissive"" but if the bind type is unknown # the token will be rejected. ""required"" any form of token # binding is needed to be allowed. Finally the name of a # binding method that must be present in tokens. (string # value) #enforce_token_bind=permissive # If true, the revocation list will be checked for cached # tokens. This requires that PKI tokens are configured on the # Keystone server. (boolean value) #check_revocations_for_cached=false # Hash algorithms to use for hashing PKI tokens. This may be a # single algorithm or multiple. The algorithms are those # supported by Python standard hashlib.new(). The hashes will # be tried in the order given, so put the preferred one first # for performance. The result of the first hash will be stored # in the cache. This will typically be set to multiple values # only while migrating from a less secure algorithm to a more # secure one. Once all the old tokens are expired this option # should be set to a single value for better performance. # (list value) #hash_algorithms=md5 [matchmaker_ring] # # Options defined in oslo.messaging # # Matchmaker ring file (JSON). (string value) # Deprecated group/name - [DEFAULT]/matchmaker_ringfile #ringfile=/etc/oslo/matchmaker_ring.json ",,362,0
openstack%2Fmagnetodb~master~Ia1ab1995e19d13b93e7429bbb7f46432210f7308,openstack/magnetodb,master,Ia1ab1995e19d13b93e7429bbb7f46432210f7308,Adds configuration guide,MERGED,2014-07-21 19:02:56.000000000,2014-08-14 14:37:11.000000000,2014-08-14 14:37:11.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8491}, {'_account_id': 8601}, {'_account_id': 8863}, {'_account_id': 10676}, {'_account_id': 11006}]","[{'number': 1, 'created': '2014-07-21 19:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/b969004e17b6026cd53111d241eb5c7b1a01026e', 'message': 'Adds configuration guide\n\nChange-Id: Ia1ab1995e19d13b93e7429bbb7f46432210f7308\nImplements: bp magnetodb-documentation\n'}, {'number': 2, 'created': '2014-07-21 19:08:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/fa4e3867dd29b62312531dc379ed6c20ddae431e', 'message': 'Adds configuration guide\n\nChange-Id: Ia1ab1995e19d13b93e7429bbb7f46432210f7308\nImplements: bp magnetodb-documentation\n'}, {'number': 3, 'created': '2014-08-13 18:53:28.000000000', 'files': ['doc/source/index.rst', 'doc/source/configuration_guide.rst'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/bc10f74ae5e1af75642b13d79f04192feb448793', 'message': 'Adds configuration guide\n\nChange-Id: Ia1ab1995e19d13b93e7429bbb7f46432210f7308\nImplements: bp magnetodb-documentation\n'}]",1,108471,bc10f74ae5e1af75642b13d79f04192feb448793,25,7,3,10665,,,0,"Adds configuration guide

Change-Id: Ia1ab1995e19d13b93e7429bbb7f46432210f7308
Implements: bp magnetodb-documentation
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/71/108471/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/configuration_guide.rst']",2,b969004e17b6026cd53111d241eb5c7b1a01026e,bp/magnetodb-documentation,"=================== Configuration guide =================== --------------------- Configuring MagnetoDB --------------------- Once MagnetoDB is installed, it is configured via configuration files (etc/magnetodb/magnetodb-api-server.conf, etc/magnetodb/magnetodb-api.conf), a PasteDeploy configuration file (etc/magnetodb/api-paste.ini). By default, MagnetoDB starts a service on port 8480 (you can change bind port and host in `magnetodb-api-server.conf`). Also you can run MagnetoDB with gunicorn (multithread). Use configs *-gunicorn* Starting and Stopping MagnetoDB =============================== Start MagnetoDB services using the command:: $ magnetodb-api-server --config-file /etc/magnetodb/magnetodb-api-server.conf For start MagnetoDB in gunicorn multithread mode use command:: $ magnetodb-api-server-gunicorn --config-file /etc/magnetodb/magnetodb-api-server-gunicorn.conf Also you can specify number of workers in magnetodb-api-server-gunicorn.conf (example magnetodb_api_workers = 4). Invoking these commands starts up wsgi.Server instance (the primary/public API interface). Stop the process using Control-C. Configuration Files =================== The MagnetoDB configuration files are an `ini` file format based on Paste, a common system used to configure Python WSGI based applications. The PasteDeploy configuration entries (WSGI pipeline definitions) can be provided in a separate `api-paste.ini` file, while general and driver-specific configuration parameters are in the primary configuration file `magnetodb-api.conf`. The api-paste.ini configuration file is organized into the following sections: [pipeline:main] is used when you need apply a number of filters. It takes one configuration key pipeline (plus any global configuration overrides you want). pipeline is a list of filters ended by an application. Two main filters are ec2authtoken and tokenauth: [filter:ec2authtoken] - check EC2 credentials in request headers (for DynamoDB API) - auth_uri: complete public Identity API endpoint (string value) for checking EC2 credentials (http://127.0.0.1:5000/v3) [filter:tokenauth] - checks the validity of the token in Keystone from the service user ( usually “magnetodb”). For this action role should be “admin”: - auth_host: host providing the admin Identity API endpoint (string value) - auth_port: port of the admin Identity API endpoint (integer value) - auth_protocol: protocol of the admin Identity API endpoint(http or https) - admin_tenant_name: Keystone service account tenant name to validate user tokens (string value) - admin_user: Keystone account username (string value) - admin_password: Keystone account password (string value) - auth_version: API version of the admin Identity API endpoint (string value) - admin_token: single shared secret with the Keystone configuration used for bootstrapping a Keystone installation, or otherwise bypassing the normal authentication process (string value) - signing_dir: directory used to cache files related to PKI tokens (string value) Note: signing_dir is configurable, but the default behavior of the authtoken middleware should be sufficient. It will create a temporary directory in the home directory for the user the MagnetoDB process is running as. .conf file ---------- The magnetodb-api.conf configuration file is organized into the following sections: | DEFAULT (logging configuration) | RPC Configuration Options | Notification System Options | Storage Manager Config [DEFAULT] ````````` - verbose: show more verbose log output (sets INFO log level output) <boolean value> - debug: show debugging output in logs (sets DEBUG log level output) <boolean value> - log_file: path to log file <string value> - use_syslog: use Syslog for logging <boolean value> - syslog_log_facility: Syslog facility to receive log lines <string value> - logging_exception_prefix: format exception prefix <string value> [RPC Configuration Options] ``````````````````````````` - rpc_backend: the messaging module to use (kombu by default) - rpc_thread_pool_size: size of rpc thread pool - rpc_conn_pool_size: size of RPC connection pool - rpc_response_timeout: seconds to wait for a response from call or multicall - rpc_cast_timeout: seconds to wait before a cast expires (only supported by impl_zmq) - allowed_rpc_exception_modules: modules of exceptions that are permitted to be recreated upon receiving exception data from an rpc call (neutron.openstack.common.exception, nova.exception) - control_exchange: AMQP exchange to connect to if using RabbitMQ or QPID - fake_rabbit: if passed, use a fake RabbitMQ provider Configuration options if sending notifications via kombu rpc (these are the defaults): - kombu_ssl_version: SSL version to use (valid only if SSL enabled) - kombu_ssl_keyfile: SSL key file (valid only if SSL enabled) - kombu_ssl_certfile: SSL cert file (valid only if SSL enabled) - kombu_ssl_ca_certs: SSL certification authority file (valid only if SSL enabled) - rabbit_host: IP address of the RabbitMQ installation - rabbit_password: password of the RabbitMQ server - rabbit_port: port where RabbitMQ server is running/listening - rabbit_hosts: RabbitMQ single or HA cluster (host:port pairs i.e: host1:5672, host2:5672) rabbit_hosts is defaulted to '$rabbit_host:$rabbit_port' - rabbit_userid: user ID used for RabbitMQ connections - rabbit_virtual_host: location of a virtual RabbitMQ installation. - rabbit_max_retries: maximum retries with trying to connect to RabbitMQ (the default of 0 implies an infinite retry count) - rabbit_retry_interval: RabbitMQ connection retry interval - rabbit_ha_queues: use HA queues in RabbitMQ (x-ha-policy: all). You need to wipe RabbitMQ database when changing this option (boolean value) QPID (rpc_backend=neutron.openstack.common.rpc.impl_qpid): - qpid_hostname: Qpid broker hostname - qpid_port: Qpid broker port - qpid_hosts: Qpid single or HA cluster (host:port pairs i.e: host1:5672, host2:5672) qpid_hosts is defaulted to '$qpid_hostname:$qpid_port' - qpid_username: username for qpid connection - qpid_password: password for qpid connection - qpid_sasl_mechanisms: space separated list of SASL mechanisms to use for auth - qpid_heartbeat: seconds between connection keepalive heartbeats - qpid_protocol: transport to use, either 'tcp' or 'ssl' - qpid_tcp_nodelay: disable Nagle algorithm ZMQ (rpc_backend=neutron.openstack.common.rpc.impl_zmq): - rpc_zmq_bind_address: ZeroMQ bind address. Should be a wildcard (*), an ethernet interface, or IP. The ""host"" option should point or resolve to this address. [Notification System Options] ````````````````````````````` Notifications can be sent when tables are created, or deleted, or data items are inserted/deleted/updated/retrieved. There are three methods of sending notifications: logging (via the log_file directive), rpc (via a message queue) and noop (no notifications sent, the default): <magnetodb property> - notification_service: together with default_publisher_id, this becomes the publisher_id (for example: magnetodb.myhost.com) <notification engine property> - notification_driver: magnetodb.openstack.common.notifier.no_op_notifier (do nothing driver) - notification_driver = magnetodb.openstack.common.notifier.log_notifier (logging driver) - notification_driver = magnetodb.openstack.common.notifier.rpc_notifier (RPC driver) - default_notification_level: default_notification_level is used to form actual topic name(s) or to set logging level - default_publisher_id: default_publisher_id is a part of the notification payload - notification_topics: defined in rpc_notifier, can be comma separated values. The actual topic names will be %s.%(default_notification_level)s Note: notification_driver can be defined multiple times. [Storage Manager Config] ```````````````````````` Storage manager config it is a simple string from the point of view of oslo.config. But this string should be a well-formed JSON which is a map of object specifications for object instantiation. Each element of this map is object specification and it is JSON of tne next format:: { ""type"": ""<factory method or class object name>"", ""args"": [<position arguments for object initialization >], ""kwargs"": {<keyword arguments map for object initialization>} } Each of these objects will be created and added to result context (map of object name to object). You can specify name of object in context as argument value to initialize another object in context using ""@"" prefix. For example if you define context like:: { ""cluster_params"": { ""type"": ""cassandra.cluster.Cluster"", ""kwargs"": { ""contact_points"": [""localhost""], ""control_connection_timeout"": 60, ""max_schema_agreement_wait"": 300 } }, ""cluster_handler"": { ""type"": ""magnetodb.common.cassandra.cluster_handler.ClusterHandler"", ""kwargs"": { ""cluster_params"": ""@cluster_params"", ""query_timeout"": 60, ""concurrent_queries"": 100 } } } Object with name “cluster_params” will be created at the beginning and then this object will be used for initialization of object with name ""cluster_handler"". Also you can escape you ""@"" using ""@@"" if you need to specify string which starts with @, not a link to another object from context. cassandra_connection: - type: <factory method or class object name> - args: <position arguments for object initialization > - kwargs: <keyword arguments map for object initialization> - in_buffer_size - out_buffer_size - cql_version: if a specific version of CQL should be used, this may be set to that string version. Otherwise, the highest CQL version supported by the server will be automatically used. - protocol_version: the version of the native protocol to use (with Cassandra 2.0+ you should use protocol version 2). - keyspace - compression: controls compression for communications between the driver and Cassandra. If left as the default of True, either lz4 or snappy compression may be used, depending on what is supported by both the driver and Cassandra. If both are fully supported, lz4 will be preferred. You may also set this to ‘snappy’ or ‘lz4’ to request that specific compression type. Setting this to False disables compression. - compressor - decompressor - ssl_options: a optional dict which will be used as kwargs for ssl.wrap_socket() when new sockets are created. This should be used when client encryption is enabled in Cassandra. By default, a ca_certs value should be supplied (the value should be a string pointing to the location of the CA certs file), and you probably want to specify ssl_version as ssl.PROTOCOL_TLSv1 to match Cassandra’s default protocol. - last_error - in_flight - is_defunct - is_closed - lock - is_control_connection cluster_params: - type: <factory method or class object name> - args: <position arguments for object initialization > - kwargs: <keyword arguments map for object initialization> - connection_class - Cassandra connection class. - contact_points - port: the server-side port to open connections to (defaults to 9042). - compression: controls compression for communications between the driver and Cassandra. If left as the default of True, either lz4 or snappy compression may be used, depending on what is supported by both the driver and Cassandra. If both are fully supported, lz4 will be preferred. You may also set this to ‘snappy’ or ‘lz4’ to request that specific compression type. Setting this to False disables compression. - auth_provider: when `protocol_version`_ is 2 or higher, this should be an instance of a subclass of `AuthProvider`_, such as `PlainTextAuthProvider`_. When not using authentication, this should be left as None. - load_balancing_policy: an instance of `policies.LoadBalancingPolicy`_ or one of its subclasses. Defaults to `RoundRobinPolicy`_. - reconnection_policy: an instance of `policies.ReconnectionPolicy`_. Defaults to an instance of `ExponentialReconnectionPolicy`_ with a base delay of one second and a max delay of ten minutes. - default_retry_policy: a default `policies.RetryPolicy`_ instance to use for all `Statement`_ objects which do not have a `retry_policy`_ explicitly set. - conviction_policy_factory: a factory function which creates instances of `policies.ConvictionPolicy`_. Defaults to `policies.SimpleConvictionPolicy`_ ; - metrics_enabled: whether or not metric collection is enabled. If enabled, `cluster_metrics`_ will be an instance of `Metrics`_. - connection_class: this determines what event loop system will be used for managing I/O with Cassandra. These are the current options: - `cassandra.io.asyncorereactor.AsyncoreConnection`_ - `cassandra.io.libevreactor.LibevConnection`_ - cassandra.io.libevreactor.GeventConnection (requires monkey-patching) - cassandra.io.libevreactor.TwistedConnection By default, AsyncoreConnection will be used, which uses the asyncore module in the Python standard library. The performance is slightly worse than with libev, but it is supported on a wider range of systems. If libev is installed, LibevConnection will be used instead. If gevent monkey-patching of the standard library is detected, GeventConnection will be used automatically. - ssl_options: a optional dict which will be used as kwargs for ssl.wrap_socket() when new sockets are created. This should be used when client encryption is enabled in Cassandra. By default, a ca_certs value should be supplied (the value should be a string pointing to the location of the CA certs file), and you probably want to specify ssl_version as ssl.PROTOCOL_TLSv1 to match Cassandra’s default protocol. - sockopts: an optional list of tuples which will be used as arguments to socket.setsockopt() for all created sockets. - cql_version: if a specific version of CQL should be used, this may be set to that string version. Otherwise, the highest CQL version supported by the server will be automatically used. - protocol_version: the version of the native protocol to use (with Cassandra 2.0+ you should use protocol version 2). - executor_threads - max_schema_agreement_wait: the maximum duration (in seconds) that the driver will wait for schema agreement across the cluster. Defaults to ten seconds. - control_connection_timeout: a timeout, in seconds, for queries made by the control connection, such as querying the current schema and information about nodes in the cluster. If set to None, there will be no timeout for these queries. cluster_handler: - type: <factory method or class object name> - args: <position arguments for object initialization > - kwargs: <keyword arguments map for object initialization> - cluster - Cluster object - query_timeout - concurrent_queries table_info_repo: - type: <factory method or class object name> - args: <position arguments for object initialization > - kwargs: <keyword arguments map for object initialization> - cluster_handler storage_driver: - type: <factory method or class object name> - args: <position arguments for object initialization > - kwargs: <keyword arguments map for object initialization> - cluster_handler - table_info_repo - default_keyspace_opts storage_manager: - type: <factory method or class object name> - args: <position arguments for object initialization > - kwargs: <keyword arguments map for object initialization> - storage_driver - table_info_repo - concurrent_tasks .. _protocol_version: http://datastax.github. io/python-driver/api/cassandra/cluster.html#cassandra. cluster.Cluster.protocol_version .. _AuthProvider: http://datastax.github. io/python-driver/api/cassandra/auth.html#cassandra. auth.AuthProvider .. _PlainTextAuthProvider: http://datastax.github. io/python-driver/api/cassandra/auth.html#cassandra. auth.PlainTextAuthProvider .. _policies.LoadBalancingPolicy: http://datastax.github. io/python-driver/api/cassandra/policies.html#cassandra. policies.LoadBalancingPolicy .. _RoundRobinPolicy: http://datastax.github. io/python-driver/api/cassandra/policies.html#cassandra. policies.RoundRobinPolicy .. _policies.ReconnectionPolicy: http://datastax.github. io/python-driver/api/cassandra/policies.html#cassandra. policies.ReconnectionPolicy .. _ExponentialReconnectionPolicy: http://datastax.github. io/python-driver/api/cassandra/policies.html#cassandra. policies.ExponentialReconnectionPolicy .. _policies.RetryPolicy: http://datastax.github. io/python-driver/api/cassandra/policies.html#cassandra. policies.RetryPolicy .. _Statement: http://datastax.github. io/python-driver/api/cassandra/query.html#cassandra. query.Statement .. _retry_policy: http://datastax.github. io/python-driver/api/cassandra/query.html#cassandra. query.Statement.retry_policy .. _policies.ConvictionPolicy: http://datastax.github. io/python-driver/api/cassandra/policies.html#cassandra. policies.ConvictionPolicy .. _policies.SimpleConvictionPolicy: http://datastax.github. io/python-driver/api/cassandra/policies.html#cassandra. policies.SimpleConvictionPolicy .. _cluster_metrics: http://datastax.github. io/python-driver/api/cassandra/cluster.html#cassandra. cluster.Cluster.metrics .. _Metrics: http://datastax.github. io/python-driver/api/cassandra/metrics.html#cassandra. metrics.Metrics .. _cassandra.io.asyncorereactor.AsyncoreConnection: http://datastax.github. io/python-driver/api/cassandra/io/asyncorereactor.html#cassandra. io.asyncorereactor.AsyncoreConnection .. _cassandra.io.libevreactor.LibevConnection: http://datastax.github. io/python-driver/api/cassandra/io/libevreactor.html#cassandra.io.libevreactor.LibevConnection Default storage manager config `````````````````````````````` :: storage_manager_config = { ""cassandra_connection"": { ""type"": ""eval"", ""args"": [ ""importutils.import_class('magnetodb.common.cassandra.io.eventletreactor.EventletConnection')"" ] }, ""cluster_params"": { ""type"": ""dict"", ""kwargs"": { ""connection_class"": ""@cassandra_connection"", ""contact_points"": [""localhost""], ""control_connection_timeout"": 60, ""max_schema_agreement_wait"": 300 } }, ""cluster_handler"": { ""type"": ""magnetodb.common.cassandra.cluster_handler.ClusterHandler"", ""kwargs"": { ""cluster_params"": ""@cluster_params"", ""query_timeout"": 60, ""concurrent_queries"": 100 } }, ""table_info_repo"": { ""type"": ""magnetodb.storage.table_info_repo.cassandra_impl.CassandraTableInfoRepository"", ""kwargs"": { ""cluster_handler"": ""@cluster_handler"" } }, ""storage_driver"": { ""type"": ""magnetodb.storage.driver.cassandra.cassandra_impl.CassandraStorageDriver"", ""kwargs"": { ""cluster_handler"": ""@cluster_handler"", ""table_info_repo"": ""@table_info_repo"", ""default_keyspace_opts"": { ""replication"": { ""replication_factor"": 3, ""class"": ""SimpleStrategy"" } } } }, ""storage_manager"": { ""type"": ""magnetodb.storage.manager.async_simple_impl.AsyncSimpleStorageManager"", ""kwargs"": { ""storage_driver"": ""@storage_driver"", ""table_info_repo"": ""@table_info_repo"", ""concurrent_tasks"": 1000 } } } ",,435,0
openstack%2Fkeystone~master~I0f713d7eeb80264a80abda63c20ab0ca7fee94cb,openstack/keystone,master,I0f713d7eeb80264a80abda63c20ab0ca7fee94cb,Do not overwrite token expires with lower resolution,ABANDONED,2014-08-14 02:46:13.000000000,2014-08-14 14:26:21.000000000,,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-08-14 02:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/01a90e77f699c247ce11bc8d538051556370cebb', 'message': 'Do not overwrite token expires with lower resolution\n\nIf a token has expires data in the token body, do not overwrite the\nexpires data with potentially (depending on db engine and version\nof db engine) lower resolution data.\n\nChange-Id: I0f713d7eeb80264a80abda63c20ab0ca7fee94cb\nbp: non-persistent-tokens\n'}, {'number': 2, 'created': '2014-08-14 02:55:14.000000000', 'files': ['keystone/token/providers/common.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d6b6d565ac41735617609337ba75d89a35f3feea', 'message': 'Do not overwrite token expires with lower resolution\n\nIf a token has expires data in the token body, do not overwrite the\nexpires data with potentially (depending on db engine and version\nof db engine) lower resolution data.\n\nChange-Id: I0f713d7eeb80264a80abda63c20ab0ca7fee94cb\nbp: non-persistent-tokens\n'}]",0,114103,d6b6d565ac41735617609337ba75d89a35f3feea,8,3,2,2903,,,0,"Do not overwrite token expires with lower resolution

If a token has expires data in the token body, do not overwrite the
expires data with potentially (depending on db engine and version
of db engine) lower resolution data.

Change-Id: I0f713d7eeb80264a80abda63c20ab0ca7fee94cb
bp: non-persistent-tokens
",git fetch https://review.opendev.org/openstack/keystone refs/changes/03/114103/2 && git format-patch -1 --stdout FETCH_HEAD,['keystone/token/providers/common.py'],1,01a90e77f699c247ce11bc8d538051556370cebb,bp/non-persistent-tokens," token_data = token_ref.get('token_data') if token_data: # Try V2 expires location try: token_data['access']['token']['expires'] except KeyError: # Try V3 expires location try: token_data['token']['expires_at'] except KeyError: # No expires data, either use token_ref['expires'] if # exists or fall through to the default_expire_time. No # exception should be raised here. pass # NOTE(morganfainberg): The value of 'expires' in the token body # is more likely to have proper microsecond resolution whereas # token_ref['expires'] will vary depending on the db engine, # version of db engine when the initial table was created, etc. # If for some reason the token does not have expires where expected # fall back to the token_ref['expires'] to ensure we maintain # consistent behavior. try: expires = token_ref['token_data']['access']['token']['expires'] except KeyError: expires = token_ref['expires'] expires=expires,"," expires=token_ref['expires'],",29,1
openstack%2Fkeystone~master~I5db47340ebffbb2a2752f128efb8aafd1ffef857,openstack/keystone,master,I5db47340ebffbb2a2752f128efb8aafd1ffef857,Convert (for mysql) revocation events expires_at to varchar,ABANDONED,2014-08-14 02:46:13.000000000,2014-08-14 14:23:48.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-14 02:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/38269c33d4373551ab376a4d2953cf40b6fba9a3', 'message': 'Convert (for mysql) revocation events expires_at to varchar\n\nDue to limited resolution of MySQL DATETIME type (in many cases and\nby default even in cases where it is supported) subsecond resolution\nwill be trimmed off.\n\nThis fix will convert (for MySQL only) the expires_at column in\nrevocation event table. The new expires at column is backed by\na varchar(26) and automatically converts from Datetime objects\nto ISO8660 (with subseconds) on process of param bind. On process\nof result value, the ISO8660 string is converted to a normalized\nDatetime object.\n\nChange-Id: I5db47340ebffbb2a2752f128efb8aafd1ffef857\nbp: non-persistent-tokens\n'}, {'number': 2, 'created': '2014-08-14 02:58:06.000000000', 'files': ['keystone/common/sql/core.py', 'keystone/contrib/revoke/migrate_repo/versions/002_switch_expires_column_type.py', 'keystone/contrib/revoke/model.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/aeeda3b977592c9e69e9114fa0f90ada71db9fe9', 'message': 'Convert (for mysql) revocation events expires_at to varchar\n\nDue to limited resolution of MySQL DATETIME type (in many cases and\nby default even in cases where it is supported) subsecond resolution\nwill be trimmed off.\n\nThis fix will convert (for MySQL only) the expires_at column in\nrevocation event table. The new expires at column is backed by\na varchar(26) and automatically converts from Datetime objects\nto ISO8660 (with subseconds) on process of param bind. On process\nof result value, the ISO8660 string is converted to a normalized\nDatetime object.\n\nChange-Id: I5db47340ebffbb2a2752f128efb8aafd1ffef857\nbp: non-persistent-tokens\n'}]",0,114104,aeeda3b977592c9e69e9114fa0f90ada71db9fe9,6,1,2,2903,,,0,"Convert (for mysql) revocation events expires_at to varchar

Due to limited resolution of MySQL DATETIME type (in many cases and
by default even in cases where it is supported) subsecond resolution
will be trimmed off.

This fix will convert (for MySQL only) the expires_at column in
revocation event table. The new expires at column is backed by
a varchar(26) and automatically converts from Datetime objects
to ISO8660 (with subseconds) on process of param bind. On process
of result value, the ISO8660 string is converted to a normalized
Datetime object.

Change-Id: I5db47340ebffbb2a2752f128efb8aafd1ffef857
bp: non-persistent-tokens
",git fetch https://review.opendev.org/openstack/keystone refs/changes/04/114104/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/core.py', 'keystone/contrib/revoke/migrate_repo/versions/002_switch_expires_column_type.py', 'keystone/contrib/revoke/model.py']",3,38269c33d4373551ab376a4d2953cf40b6fba9a3,bp/non-persistent-tokens,, if self.expires_at is not None: # Trim off the expiration time because MySQL timestamps are only # accurate to the second. self.expires_at = self.expires_at.replace(microsecond=0) # Trim off the microseconds because the revocation event only has # expirations accurate to the second. token_expires_at = token_expires_at.replace(microsecond=0) # Trim off the microseconds because the revocation event only has # expirations accurate to the second. token_expires_at = token_expires_at.replace(microsecond=0) ,75,13
openstack%2Ftraining-guides~master~I6e52c521b9a5f61fa42b644a60c49bf20c2e7cc3,openstack/training-guides,master,I6e52c521b9a5f61fa42b644a60c49bf20c2e7cc3,labs: osbash CLI default changes,MERGED,2014-08-14 12:25:16.000000000,2014-08-14 14:21:00.000000000,2014-08-14 14:20:59.000000000,"[{'_account_id': 3}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-08-14 12:25:16.000000000', 'files': ['labs/osbash.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/0b4863c7b3353f947d6cbfbf9d8882a4e7bfb88f', 'message': 'labs: osbash CLI default changes\n\nThis patch changes the default behavior of osbash in order to improve\nuseability and better protect user data:\n\nIf the user asks for a cluster, the script no longer asks whether to use\na matching base disk (the prompt was added before the basedisk command\nthat allows re-building a base disk if needed).\n\nIf an existing base disk is used, VMs already attached to that disk are\nno longer removed wholesale. They are removed only if and when they are\nabout to be replaced by a new VM of the same name. Among other things,\nthis will allow us to rebuild some nodes without affecting others.\n\nChange-Id: I6e52c521b9a5f61fa42b644a60c49bf20c2e7cc3\nImplements: blueprint openstack-training-labs\n'}]",1,114222,0b4863c7b3353f947d6cbfbf9d8882a4e7bfb88f,7,2,1,11109,,,0,"labs: osbash CLI default changes

This patch changes the default behavior of osbash in order to improve
useability and better protect user data:

If the user asks for a cluster, the script no longer asks whether to use
a matching base disk (the prompt was added before the basedisk command
that allows re-building a base disk if needed).

If an existing base disk is used, VMs already attached to that disk are
no longer removed wholesale. They are removed only if and when they are
about to be replaced by a new VM of the same name. Among other things,
this will allow us to rebuild some nodes without affecting others.

Change-Id: I6e52c521b9a5f61fa42b644a60c49bf20c2e7cc3
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/22/114222/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/osbash.sh'],1,0b4863c7b3353f947d6cbfbf9d8882a4e7bfb88f,bp/openstack-training-labs," if [ ""$CMD"" = basedisk -a -f ""$BASE_DISK"" ]; then if ! yes_or_no ""Keep this base disk?""; then # Remove users of base disk echo >&2 ""Unregistering and removing all disks attached to"" \ ""base disk path."" disk_delete_child_vms ""$BASE_DISK"" echo >&2 ""Unregistering old base disk."" echo >&2 ""Removing old base disk."" else echo >&2 ""Nothing to do. Exiting."" exitecho ""Using base disk $BASE_DISK"" "," # Remove users of base disk echo >&2 ""Unregistering and removing all disks attached to base disk path"" disk_delete_child_vms ""$BASE_DISK"" if [ -f ""$BASE_DISK"" ]; then if ! yes_or_no ""Re-use this base disk?""; then echo >&2 ""Unregistering old base disk"" echo >&2 ""Removing old base disk""",13,8
openstack%2Ftraining-guides~master~I4c85f81c1540ff50a8a690dc170871fc56667f7d,openstack/training-guides,master,I4c85f81c1540ff50a8a690dc170871fc56667f7d,labs: rudimentary verification of installed services,MERGED,2014-08-14 08:28:59.000000000,2014-08-14 14:12:10.000000000,2014-08-14 14:06:46.000000000,"[{'_account_id': 3}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-08-14 08:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/cb64f097e2d5a95919c7303805048e616dadc469', 'message': 'labs: rudimentary verification of installed services\n\nThe current scripts make no effort to verify that the installed\nservices are configured correctly.\n\nWith this patch, some basic configuration errors will at least leave\ntraces in the script log files.\n\nChange-Id: I4c85f81c1540ff50a8a690dc170871fc56667f7d\nImplements: blueprint openstack-training-labs\n'}, {'number': 2, 'created': '2014-08-14 13:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/4ce403eff91fe1172500d0d1c6aa668cd5124504', 'message': 'labs: rudimentary verification of installed services\n\nThe current scripts make no effort to verify that the installed\nservices are configured correctly.\n\nWith this patch, some basic configuration errors will at least leave\ntraces in the script log files.\n\nChange-Id: I4c85f81c1540ff50a8a690dc170871fc56667f7d\nImplements: blueprint openstack-training-labs\n'}, {'number': 3, 'created': '2014-08-14 13:26:33.000000000', 'files': ['labs/scripts/setup_cinder_controller.sh', 'labs/scripts/setup_nova_controller.sh', 'labs/scripts/setup_glance.sh', 'labs/scripts/setup_keystone.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/89ebaf0eb813183f045ba8ebf09cbe6d4b5ad1bf', 'message': 'labs: rudimentary verification of installed services\n\nThe current scripts make no effort to verify that the installed\nservices are configured correctly.\n\nWith this patch, some basic configuration errors will at least leave\ntraces in the script log files.\n\nChange-Id: I4c85f81c1540ff50a8a690dc170871fc56667f7d\nCo-Authored-By: Pranav Salunke <dguitarbite@gmail.com>\nImplements: blueprint openstack-training-labs\n'}]",0,114163,89ebaf0eb813183f045ba8ebf09cbe6d4b5ad1bf,19,2,3,11109,,,0,"labs: rudimentary verification of installed services

The current scripts make no effort to verify that the installed
services are configured correctly.

With this patch, some basic configuration errors will at least leave
traces in the script log files.

Change-Id: I4c85f81c1540ff50a8a690dc170871fc56667f7d
Co-Authored-By: Pranav Salunke <dguitarbite@gmail.com>
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/63/114163/3 && git format-patch -1 --stdout FETCH_HEAD,"['labs/scripts/setup_cinder_controller.sh', 'labs/scripts/setup_nova_controller.sh', 'labs/scripts/setup_glance.sh', 'labs/scripts/setup_keystone.sh']",4,cb64f097e2d5a95919c7303805048e616dadc469,bp/openstack-training-labs," #------------------------------------------------------------------------------ # Verify the Identity Service installation #------------------------------------------------------------------------------ echo ""Verifying keystone installation."" # From this point on, we are going to use keystone for authentication unset OS_SERVICE_TOKEN OS_SERVICE_ENDPOINT # Load keystone credentials source ""$CONFIG_DIR/labs-openstackrc.sh"" # The output of the following commands can be used to verify or debug the # service. echo ""keystone token-get"" keystone token-get echo ""keystone user-list"" keystone user-list echo ""keystone user-role-list --user $ADMIN_USER_NAME --tenant $ADMIN_TENANT_NAME"" keystone user-role-list --user ""$ADMIN_USER_NAME"" --tenant ""$ADMIN_TENANT_NAME""",,59,0
openstack%2Fmurano-dashboard~master~I0868f5cc7056f43d9216b378f5a2e66d932fa34b,openstack/murano-dashboard,master,I0868f5cc7056f43d9216b378f5a2e66d932fa34b,Fixed issue with is_public=False default value,MERGED,2014-08-14 12:05:09.000000000,2014-08-14 14:04:13.000000000,2014-08-14 14:04:13.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 9048}, {'_account_id': 10063}, {'_account_id': 11098}]","[{'number': 1, 'created': '2014-08-14 12:05:09.000000000', 'files': ['muranodashboard/tests/functional/sanity_check.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/2d38053c129d1b41ba509b3ff58d2d6b934e7834', 'message': 'Fixed issue with is_public=False default value\n\nWe merged commit https://review.openstack.org/#/c/109153/ and now we need\nto change tests for dashboard to avoid fails.\n\nChange-Id: I0868f5cc7056f43d9216b378f5a2e66d932fa34b\nCloses-Bug: #1356848\n'}]",0,114215,2d38053c129d1b41ba509b3ff58d2d6b934e7834,11,9,1,7227,,,0,"Fixed issue with is_public=False default value

We merged commit https://review.openstack.org/#/c/109153/ and now we need
to change tests for dashboard to avoid fails.

Change-Id: I0868f5cc7056f43d9216b378f5a2e66d932fa34b
Closes-Bug: #1356848
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/15/114215/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/tests/functional/sanity_check.py'],1,2d38053c129d1b41ba509b3ff58d2d6b934e7834,," self.check_package_parameter('PostgreSQL', 'Public', 'True') self.check_package_parameter('PostgreSQL', 'Public', 'False')"," self.check_package_parameter('PostgreSQL', 'Public', 'False') self.check_package_parameter('PostgreSQL', 'Public', 'True')",2,2
openstack%2Fnova~master~Ie93175602dbced361d76abbe35a7767a96d9e68e,openstack/nova,master,Ie93175602dbced361d76abbe35a7767a96d9e68e,Backport v3 api unittest into v2 api for attach_interface extension,MERGED,2014-08-11 06:22:32.000000000,2014-08-14 14:03:20.000000000,2014-08-14 11:53:52.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-11 06:22:32.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_attach_interfaces.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/260f5c6f508e58874ca4d448ff7b79f8117be28d', 'message': 'Backport v3 api unittest into v2 api for attach_interface extension\n\nOn most APIs, the unit test coverage of v3 is better than the one of v2.\nThis patch ports v3 attach_interface API tests to v2 tests for improving\nv2 attach_interface API tests\n\nChange-Id: Ie93175602dbced361d76abbe35a7767a96d9e68e\n'}]",0,113175,260f5c6f508e58874ca4d448ff7b79f8117be28d,22,10,1,5754,,,0,"Backport v3 api unittest into v2 api for attach_interface extension

On most APIs, the unit test coverage of v3 is better than the one of v2.
This patch ports v3 attach_interface API tests to v2 tests for improving
v2 attach_interface API tests

Change-Id: Ie93175602dbced361d76abbe35a7767a96d9e68e
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/113175/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/contrib/test_attach_interfaces.py'],1,260f5c6f508e58874ca4d448ff7b79f8117be28d,bp/v2-on-v3-api," @mock.patch.object(compute_api.API, 'get', side_effect=exception.InstanceNotFound(instance_id='')) def _test_instance_not_found(self, url, func, params, mock_get, method='GET'): req = webob.Request.blank(url) req.method = method req.headers['content-type'] = 'application/json' req.environ['nova.context'] = self.context self.assertRaises(exc.HTTPNotFound, func, req, *params) def test_show_instance_not_found(self): attachments = attach_interfaces.InterfaceAttachmentController() self._test_instance_not_found('/v2/fake/os-interfaces/fake', attachments.show, ('fake', 'fake')) def test_index_instance_not_found(self): attachments = attach_interfaces.InterfaceAttachmentController() self._test_instance_not_found('/v2/fake/os-interfaces', attachments.index, ('fake', )) def test_delete_instance_not_found(self): attachments = attach_interfaces.InterfaceAttachmentController() self._test_instance_not_found('/v2/fake/os-interfaces/fake', attachments.delete, ('fake', 'fake'), method='DELETE') def test_create_instance_not_found(self): attachments = attach_interfaces.InterfaceAttachmentController() self._test_instance_not_found('/v2/fake/os-interfaces', attachments.create, ('fake', {'interfaceAttachment': {}}), 'POST') "," class InterfaceAttachTestsWithMock(test.NoDBTestCase): def setUp(self): super(InterfaceAttachTestsWithMock, self).setUp() self.flags(auth_strategy=None, group='neutron') self.flags(url='http://anyhost/', group='neutron') self.flags(url_timeout=30, group='neutron') self.context = context.get_admin_context() ",33,9
openstack%2Fnova~master~Ie8ff7b444c739a933595f60b2154c0848e164a21,openstack/nova,master,Ie8ff7b444c739a933595f60b2154c0848e164a21,resize failed with vcdriver,ABANDONED,2014-08-13 11:08:21.000000000,2014-08-14 13:57:36.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 7730}, {'_account_id': 8027}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-13 11:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8783221cafd537848f0e7ce0a9f5b7afb13eaa03', 'message': 'resize failed with vcdriver\n\nget_host_ip_addr() method is not implemented in\nvmware vcdriver which breaks the resize operation.\nThis patch fixes this issue.\n\nChange-Id: Ie8ff7b444c739a933595f60b2154c0848e164a21\nCloses-bug:#1356280\n'}, {'number': 2, 'created': '2014-08-14 03:24:41.000000000', 'files': ['nova/virt/vmwareapi/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2dde67d66518b0c94aaf2789970739dc5257a7b9', 'message': 'resize failed with vcdriver\n\nget_host_ip_addr() method is not implemented in\nvmware vcdriver which breaks the resize operation.\nThis patch fixes this issue.\n\nChange-Id: Ie8ff7b444c739a933595f60b2154c0848e164a21\nCloses-bug:#1356280\n'}]",0,113849,2dde67d66518b0c94aaf2789970739dc5257a7b9,19,9,2,10487,,,0,"resize failed with vcdriver

get_host_ip_addr() method is not implemented in
vmware vcdriver which breaks the resize operation.
This patch fixes this issue.

Change-Id: Ie8ff7b444c739a933595f60b2154c0848e164a21
Closes-bug:#1356280
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/113849/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/driver.py'],1,8783221cafd537848f0e7ce0a9f5b7afb13eaa03,bug/1356280, @staticmethod def get_host_ip_addr(): return CONF.my_ip ,,4,0
openstack%2Ffuel-library~master~If2cf35ac8195baf37cda50564b70ba3db836ccea,openstack/fuel-library,master,If2cf35ac8195baf37cda50564b70ba3db836ccea,Add iops fact and add it to astute,MERGED,2014-08-13 15:10:41.000000000,2014-08-14 13:55:13.000000000,2014-08-14 13:37:35.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9705}]","[{'number': 1, 'created': '2014-08-13 15:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6abe5b17de704ceebd4d4631d269634447b2386e', 'message': 'Add iops fact and add it to astute\n\nAstute needs to know how many nodes can\nbe provisioned at a time, based on IOPS.\n\nChange-Id: If2cf35ac8195baf37cda50564b70ba3db836ccea\nPartial-Bug: #1355347\n'}, {'number': 2, 'created': '2014-08-13 15:57:49.000000000', 'files': ['deployment/puppet/nailgun/templates/astuted.conf.erb', 'deployment/puppet/nailgun/lib/facter/iops.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/26b55bc341cb99bf9bfb9e1888693dded8663760', 'message': 'Add iops fact and add it to astute\n\nAstute needs to know how many nodes can\nbe provisioned at a time, based on IOPS.\n\nChange-Id: If2cf35ac8195baf37cda50564b70ba3db836ccea\nPartial-Bug: #1355347\n'}]",3,113924,26b55bc341cb99bf9bfb9e1888693dded8663760,20,7,2,7195,,,0,"Add iops fact and add it to astute

Astute needs to know how many nodes can
be provisioned at a time, based on IOPS.

Change-Id: If2cf35ac8195baf37cda50564b70ba3db836ccea
Partial-Bug: #1355347
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/24/113924/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/nailgun/templates/astuted.conf.erb', 'deployment/puppet/nailgun/lib/facter/iops.rb']",2,6abe5b17de704ceebd4d4631d269634447b2386e,iops,"require 'facter' # Requires sysstat package on Ubuntu and CentOS # Fact iops totals tps values from iostat Facter.add('iops') do confine :kernel => :linux str = Facter::Util::Resolution.exec(""iostat | grep -v 'dm-' | grep sda"" \ "" | awk '{print $2}'"") iops = 0 str.split(""\n"").each do |iops_val| iops = iops + iops_val.to_i end iops end ",,16,0
openstack%2Fneutron~master~I547cfa80cf83b0340b459279df9283443562326b,openstack/neutron,master,I547cfa80cf83b0340b459279df9283443562326b,Predictable field and filter ordering,MERGED,2014-08-06 10:10:43.000000000,2014-08-14 13:52:41.000000000,2014-08-14 13:52:40.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6620}, {'_account_id': 6635}, {'_account_id': 6637}, {'_account_id': 6638}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-06 10:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2c6e70ee69a7c8bc6fbfbd143ed7dcfa0341c368', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple\nneutron.tests.unit.test_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_filters_with_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are four parts to this fix:\n1. Refactor Controller _field_attributes code to ensure order is\nmaintained.\n2. Update the APIv2TestCase _do_field_list function to construct field list in the same\norder as the controller constructs its list.\n3. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n4. Use assertItemsEqual in filters unit test to ignore order of returned\nfilters.\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}, {'number': 2, 'created': '2014-08-06 10:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/50b92dd72c2277d74edeb73238e5f078d6264bfa', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple\nneutron.tests.unit.test_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_filters_with_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are four parts to this fix:\n1. Refactor Controller _field_attributes code to ensure order is\nmaintained.\n2. Update the APIv2TestCase _do_field_list function to construct field list in the same\norder as the controller constructs its list.\n3. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n4. Use assertItemsEqual in filters unit test to ignore order of returned\nfilters.\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}, {'number': 3, 'created': '2014-08-06 12:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a4d6dcbcea1902650a121fee5be4a25e20cdd58d', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple\nneutron.tests.unit.test_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_filters_with_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are four parts to this fix:\n1. Refactor Controller _field_attributes code to ensure order is\nmaintained.\n2. Update the APIv2TestCase _do_field_list function to construct field list in the same\norder as the controller constructs its list.\n3. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n4. Use _sort_dict_lists to sort values before assertion in test_attr_info_with_convert_list_to\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}, {'number': 4, 'created': '2014-08-06 13:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dbe18bb3c4d6d42ce29a6c96b5ed68f6d07f8b6f', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple\nneutron.tests.unit.test_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_filters_with_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are four parts to this fix:\n1. Refactor Controller _field_attributes code to ensure order is\nmaintained.\n2. Update the APIv2TestCase _do_field_list function to construct field list in the same\norder as the controller constructs its list.\n3. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n4. Use _sort_dict_lists to sort values before assertion in test_attr_info_with_convert_list_to\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}, {'number': 5, 'created': '2014-08-06 13:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/987b2d27565c3d1da0900f6b9cea0bf576db7ce7', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple\nneutron.tests.unit.test_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_filters_with_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are four parts to this fix:\n1. Refactor Controller _field_attributes code to ensure order is\nmaintained.\n2. Update the APIv2TestCase _do_field_list function to construct field list in the same\norder as the controller constructs its list.\n3. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n4. Use _sort_dict_lists to sort values before assertion in test_attr_info_with_convert_list_to\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}, {'number': 6, 'created': '2014-08-06 15:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c3867fc86c4efe3402c902623f8507701d2f210', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple\nneutron.tests.unit.test_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_filters_with_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are four parts to this fix:\n1. Refactor Controller _field_attributes code to ensure order is\nmaintained.\n2. Update the APIv2TestCase _do_field_list function to construct field list in the same\norder as the controller constructs its list.\n3. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n4. Use _sort_dict_lists to sort values before assertion in test_attr_info_with_convert_list_to\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}, {'number': 7, 'created': '2014-08-07 15:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/139b24a1d58e71779b9a244e9d99d31b4ef4d032', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple\nneutron.tests.unit.test_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_filters_with_fields\nneutron.tests.unit.test_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are four parts to this fix:\n1. Refactor Controller _field_attributes code to ensure order is\nmaintained.\n2. Update the APIv2TestCase _do_field_list function to construct field list in the same\norder as the controller constructs its list.\n3. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n4. Use new sort_dict_lists function to sort values before assertion in test_attr_info_with_convert_list_to\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}, {'number': 8, 'created': '2014-08-08 13:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4619323e44e1c3d3801d60e8a5f5848efd6085ee', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\ntest_api_v2.APIv2TestCase.test_fields\ntest_api_v2.APIv2TestCase.test_fields_multiple\ntest_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\ntest_api_v2.APIv2TestCase.test_filters_with_fields\ntest_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are four parts to this fix:\n1. Refactor Controller _field_attributes code to ensure order is\nmaintained.\n2. Update the APIv2TestCase _do_field_list function to construct\nfield list in the same order as the controller constructs its list.\n3. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n4. Use new assertOrderedEqual function to sort values before assertion\nin test_attr_info_with_convert_list_to\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}, {'number': 9, 'created': '2014-08-08 14:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c98999fc513206d9abd35ae32e129c69b7d7a44', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\ntest_api_v2.APIv2TestCase.test_fields\ntest_api_v2.APIv2TestCase.test_fields_multiple\ntest_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\ntest_api_v2.APIv2TestCase.test_filters_with_fields\ntest_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are four parts to this fix:\n1. Refactor Controller _field_attributes code to ensure order is\nmaintained.\n2. Update the APIv2TestCase _do_field_list function to construct\nfield list in the same order as the controller constructs its list.\n3. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n4. Use new assertOrderedEqual function to sort values before assertion\nin test_attr_info_with_convert_list_to\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}, {'number': 10, 'created': '2014-08-11 09:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f4bc95e2933206a4c161160beee63dc42d0d49ec', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\ntest_api_v2.APIv2TestCase.test_fields\ntest_api_v2.APIv2TestCase.test_fields_multiple\ntest_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\ntest_api_v2.APIv2TestCase.test_filters_with_fields\ntest_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are 3 parts to this fix:\n1. Update the APIv2TestCase _do_field_list function to construct\nfield list in the same order as the controller constructs its list.\n2. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n3. Use new assertOrderedEqual function to sort values before assertion\nin test_attr_info_with_convert_list_to\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}, {'number': 11, 'created': '2014-08-11 16:33:52.000000000', 'files': ['neutron/tests/unit/test_api_v2.py', 'neutron/tests/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f103ce48ca60e12952be7aa6d5183f64ef826370', 'message': 'Predictable field and filter ordering\n\nThis fixes the fields and filters units tests that break with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an\nunpredictable output order. Values in kvp strings are being stored as\nsets underpinned by dicts when converted, leading to unpredictable\nordering of values when read.\n\nDiscovered with PYTHONHASHSEED = 2455351445 on these tests:\ntest_api_v2.APIv2TestCase.test_fields\ntest_api_v2.APIv2TestCase.test_fields_multiple\ntest_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to\ntest_api_v2.APIv2TestCase.test_filters_with_fields\ntest_api_v2.APIv2TestCase.test_fields_multiple_with_empty\n\nThere are 3 parts to this fix:\n1. Update the APIv2TestCase _do_field_list function to construct\nfield list in the same order as the controller constructs its list.\n2. Ensure the APIv2TestCase _get_collection_kwargs maintains order\nthroughout.\n3. Use new assertOrderedEqual function to sort values before assertion\nin test_attr_info_with_convert_list_to\n\nChange-Id: I547cfa80cf83b0340b459279df9283443562326b\nPartial-bug: #1348818\n'}]",27,112258,f103ce48ca60e12952be7aa6d5183f64ef826370,191,31,11,6637,,,0,"Predictable field and filter ordering

This fixes the fields and filters units tests that break with a
randomized PYTHONHASHSEED (see the bug report).

The RESOURCE_ATTRIBUTE_MAP is stored as a dict leading to an
unpredictable output order. Values in kvp strings are being stored as
sets underpinned by dicts when converted, leading to unpredictable
ordering of values when read.

Discovered with PYTHONHASHSEED = 2455351445 on these tests:
test_api_v2.APIv2TestCase.test_fields
test_api_v2.APIv2TestCase.test_fields_multiple
test_api_v2.FiltersTestCase.test_attr_info_with_convert_list_to
test_api_v2.APIv2TestCase.test_filters_with_fields
test_api_v2.APIv2TestCase.test_fields_multiple_with_empty

There are 3 parts to this fix:
1. Update the APIv2TestCase _do_field_list function to construct
field list in the same order as the controller constructs its list.
2. Ensure the APIv2TestCase _get_collection_kwargs maintains order
throughout.
3. Use new assertOrderedEqual function to sort values before assertion
in test_attr_info_with_convert_list_to

Change-Id: I547cfa80cf83b0340b459279df9283443562326b
Partial-bug: #1348818
",git fetch https://review.opendev.org/openstack/neutron refs/changes/58/112258/8 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/v2/base.py', 'neutron/tests/unit/test_api_v2.py']",2,2c6e70ee69a7c8bc6fbfbd143ed7dcfa0341c368,bug/1348818,"import collections if info.get('required_by_policy')] for (name, info) in attr_info.items(): if info.get('primary_key'): policy_attrs.append(name) args_dict = collections.OrderedDict((arg, mock.ANY) self.assertItemsEqual(expect_val, actual_val)"," if info.get('required_by_policy') or info.get('primary_key')] args_dict = dict((arg, mock.ANY) self.assertEqual(actual_val, expect_val)",21,5
openstack%2Ftrove~master~Idaa46b67096c1fbbacdf730c06c823aaf3e1e255,openstack/trove,master,Idaa46b67096c1fbbacdf730c06c823aaf3e1e255,Adjusted audit logging for taskmanager module,MERGED,2014-07-18 14:08:56.000000000,2014-08-14 13:51:10.000000000,2014-08-14 13:51:10.000000000,"[{'_account_id': 3}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}, {'_account_id': 10215}, {'_account_id': 10266}]","[{'number': 1, 'created': '2014-07-18 14:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/97d6cd5bb2536a39c238ec4819b9305c4a434ad5', 'message': 'Adjusted audit logging for taskmanager module\n\nThe taskmanager module audit log messages are unclear, some debug\nmessages are supposed to be info and vice versa.\n\nChanged logging of various messages to conform to standard.\n\nChange-Id: Idaa46b67096c1fbbacdf730c06c823aaf3e1e255\nPartial-Bug: #1324206\n'}, {'number': 2, 'created': '2014-07-18 15:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/54ae6f9b60404cd3ff25eb79db61cd3fef776903', 'message': 'Adjusted audit logging for taskmanager module\n\nThe taskmanager module audit log messages are unclear, some debug\nmessages are supposed to be info and vice versa.\n\nChanged logging of various messages to conform to standard.\n\nChange-Id: Idaa46b67096c1fbbacdf730c06c823aaf3e1e255\nPartial-Bug: #1324206\n'}, {'number': 3, 'created': '2014-07-21 19:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/addbe5748bcd44817a0970e90cff31de3f59a24c', 'message': 'Adjusted audit logging for taskmanager module\n\nThe taskmanager module audit log messages are unclear, some debug\nmessages are supposed to be info and vice versa.\n\nChanged logging of various messages to conform to standard.\n\nChange-Id: Idaa46b67096c1fbbacdf730c06c823aaf3e1e255\nPartial-Bug: #1324206\n'}, {'number': 4, 'created': '2014-07-22 21:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ba004c0aa1548fcf12b2228fb221d2d2aaff22bd', 'message': 'Adjusted audit logging for taskmanager module\n\nThe taskmanager module audit log messages are unclear, some debug\nmessages are supposed to be info and vice versa.\n\nChanged logging of various messages to conform to standard.\n\nChange-Id: Idaa46b67096c1fbbacdf730c06c823aaf3e1e255\nPartial-Bug: #1324206\n'}, {'number': 5, 'created': '2014-08-12 18:51:08.000000000', 'files': ['trove/taskmanager/api.py', 'trove/taskmanager/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/b5fc1a5519713f400335d592d0cf71379330e438', 'message': 'Adjusted audit logging for taskmanager module\n\nThe taskmanager module audit log messages are unclear, some debug\nmessages are supposed to be info and vice versa.\n\nChanged logging of various messages to conform to standard.\n\nChange-Id: Idaa46b67096c1fbbacdf730c06c823aaf3e1e255\nPartial-Bug: #1324206\n'}]",42,108020,b5fc1a5519713f400335d592d0cf71379330e438,65,9,5,10266,,,0,"Adjusted audit logging for taskmanager module

The taskmanager module audit log messages are unclear, some debug
messages are supposed to be info and vice versa.

Changed logging of various messages to conform to standard.

Change-Id: Idaa46b67096c1fbbacdf730c06c823aaf3e1e255
Partial-Bug: #1324206
",git fetch https://review.opendev.org/openstack/trove refs/changes/20/108020/5 && git format-patch -1 --stdout FETCH_HEAD,"['trove/taskmanager/api.py', 'trove/taskmanager/models.py']",2,97d6cd5bb2536a39c238ec4819b9305c4a434ad5,bug/1324206-taskmanager," LOG.info(_(""Creating instance %s."") % self.id) LOG.info(_(""Created instance %s successfully."") % self.id) LOG.error(_(""Failed to create instance %s. "" ""Timeout waiting for instance to become active. "" ""No usage create-event was sent."") % self.id) LOG.exception(_(""Failed to send usage create-event for "" ""instance %s."") % self.id) LOG.debug(""Begin _create_server_volume for id: %s"" % self.id) LOG.debug(""End _create_server_volume for id: %s"" % self.id) LOG.debug(""End _create_server_volume for id: %s"" % self.id) LOG.debug(""Begin _create_server_volume_heat for id: %s"" % self.id) raise TroveError(""Failed to utf-8 encode Heat template."") raise TroveError(""Failed to obtain Heat stack status. "" ""Timeout occurred."") raise TroveError(""Failed to create Heat stack."") raise TroveError(""Failed to provision Heat base instance."") raise TroveError(""Failed to provision Heat data volume."") msg = _(""Error occurred during Heat stack creation for "" ""instance %s."") % self.id LOG.debug(""End _create_server_volume_heat for id: %s"" % self.id) LOG.debug(""Begin _create_server_volume_individually for id: %s"" % msg = _(""Failed to create volume for instance %s"") % self.id LOG.debug(""End _create_server_volume_individually for id: %s"" % msg = _(""Failed to create volume for instance %s"") % self.id LOG.debug(""Begin _create_volume for id: %s"" % self.id) LOG.debug(""End _create_volume for id: %s"" % self.id) ""for instance %(id)s"" % LOG.debug(""Polling for ip addresses: $%s "" % server.addresses) LOG.error(_(""Failed to create DNS entry for instance "" ""%(instance)s. Server status was "" ""%(status)s)."") % LOG.debug(_(""Creating dns entry..."")) raise TroveError(""Failed to create DNS entry for instance %s. "" ""No IP available."" % self.id) err_msg = _(""Failed to create security group rules for instance "" ""%(instance_id)s: Invalid port format - "" msg = err_msg % {'instance_id': self.id, 'from': from_port, 'to': to_port} LOG.debug(""Begin _delete_resources for instance %s"" % self.id) # Poll until the server is gone. LOG.error(_(""Server %(server_id)s entered ERROR status "" ""when deleting instance %(instance_id)s!"") % LOG.exception(_(""Failed to delete instance %(instance_id)s: "" ""Timeout deleting compute server %(server_id)s"") % {'instance_id': self.id, 'server_id': server_id}) LOG.debug(""End _delete_resources for instance %s"" % self.id) LOG.info(_(""Resizing volume for instance %(instance_id)s from "" ""%(old_size)s GB to %(new_size)s GB."") % {'instance_id': self.id, 'old_size': self.volume_size, 'new_size': new_size}) LOG.info(_(""Resized volume for instance %s successfully."") % self.id) LOG.info(_(""Resizing instance %(instance_id)s from flavor "" ""%(old_flavor)s to %(new_flavor)s."") % {'instance_id': self.id, 'old_flavor': old_flavor['id'], 'new_flavor': new_flavor['id']}) LOG.info(_(""Resized instance %s successfully."") % self.id) LOG.info(""Initiating migration with host %s."" % host) LOG.info(""Initiated migration with host %s successfully."" % host) LOG.info(_(""Initiating backup for instance %s."") % self.id) LOG.info(_(""Initiated backup for instance %s successfully."") % self.id) LOG.info(_(""Rebooting instance %s."") % self.id) LOG.info(_(""Rebooted instance %s successfully."") % self.id) LOG.info(_(""Restarting datastore on instance %s."") % self.id) LOG.info(_(""Restarted datastore on instance %s successfully."") % self.id) except GuestError: LOG.error(_(""Failed to restart datastore on instance %s."") % LOG.debug(""Datastore restart completed on instance %s."" % self.id) LOG.info(""Updating datastore configurations on instance %s."" % self.id) LOG.info(_(""Updated datastore configurations on instance %s "" ""successfully."") % self.id) except GuestError: LOG.error(_(""Failed to update datastore configurations "" ""on instance %s."") % self.id) LOG.info(_(""Removing configuration group %(config_id)s from "" ""instance %(instance_id)s."") % {'config_id': configuration_id, 'instance_id': self.id}) LOG.info(_(""Removed configuration group %(config_id)s from "" ""instance %(instance_id)s successfully."") % {'config_id': configuration_id, 'instance_id': self.id}) LOG.debug(""Deleting files with prefix: %(cont)s/%(prefix)s"" % {'cont': cont, 'prefix': prefix}) LOG.debug(""Deleting file: %(cont)s/%(name)s"" % {'cont': cont, 'name': name}) LOG.debug(""Deleting file: %(cont)s/%(filename)s"" % {'cont': cont, 'filename': filename}) LOG.info(_(""Deleting backup %s."") % backup_id) LOG.exception(_(""Error occurred when deleting from swift. "" raise TroveError(""Failed to delete swift object for backup %s."" % backup_id) LOG.info(_(""Deleted backup %s successfully."") % backup_id) LOG.debug(""Begin _resize_active_volume for id: %(id)s"" % { LOG.debug(""End _resize_active_volume for id: %(id)s"" % { msg = _(""Failed to resize instance %(id)s volume for server "" ""%(server_id)s. The instance must be in state %(state)s "" ""not %(inst_state)s."") % { 'server_id': self.instance.server.id, LOG.debug(""Begin resize method _perform_nova_action instance: %s"" % LOG.debug(""End resize method _perform_nova_action instance: %s"" %"," LOG.debug(""begin create_instance for id: %s"" % self.id) LOG.error(_(""Timeout for service changing to active. "" ""No usage create-event sent."")) LOG.exception(_(""Error during create-event call."")) LOG.debug(""end create_instance for id: %s"" % self.id) LOG.debug(""begin _create_server_volume for id: %s"" % self.id) LOG.debug(""end _create_server_volume for id: %s"" % self.id) LOG.debug(""end _create_server_volume for id: %s"" % self.id) LOG.debug(""begin _create_server_volume_heat for id: %s"" % self.id) LOG.error(_(""heat template ascii encode issue"")) raise TroveError(""heat template ascii encode issue"") LOG.error(_(""Timeout during stack status tracing"")) raise TroveError(""Timeout occurred in tracking stack status"") raise TroveError(""Heat Stack Create Failed."") raise TroveError(""Heat Resource Provisioning Failed."") raise TroveError(""Heat Resource Provisioning Failed."") msg = ""Error during creating stack for instance %s"" % self.id LOG.debug(msg) LOG.debug(""end _create_server_volume_heat for id: %s"" % self.id) LOG.debug(""begin _create_server_volume_individually for id: %s"" % msg = _(""Error creating server for instance %s"") % self.id LOG.debug(""end _create_server_volume_individually for id: %s"" % msg = _(""Error provisioning volume for instance: %s"") % self.id LOG.info(""Entering create_volume"") LOG.debug(""begin _create_volume for id: %s"" % self.id) LOG.debug(""end _create_volume for id: %s"" % self.id) ""for id: %(id)s"" % LOG.info(_(""Entering guest_prepare"")) LOG.info(_(""Polling for ip addresses: $%s "") % server.addresses) LOG.error(_(""Instance IP not available, "" ""instance (%(instance)s): "" ""server had status (%(status)s)."") % LOG.info(_(""Creating dns entry..."")) raise TroveError('Error creating DNS. No IP available.') err_msg = _(""Error creating security group rules."" "" Invalid port format. "" msg = err_msg % {'from': from_port, 'to': to_port} LOG.debug(""begin _delete_resources for id: %s"" % self.id) # Poll until the server is gone. LOG.error(_(""Server %(server_id)s got into ERROR status "" ""during delete of instance %(instance_id)s!"") % LOG.exception(_(""Timout during nova server delete of server: %s"") % server_id) LOG.debug(""end _delete_resources for id: %s"" % self.id) LOG.debug(""begin resize_volume for instance: %s"" % self.id) LOG.debug(""end resize_volume for instance: %s"" % self.id) LOG.debug(""Calling migrate with host(%s)..."" % host) LOG.debug(""Calling create_backup %s "" % self.id) LOG.debug(""Rebooting instance %s"" % self.id) LOG.debug(""Successfully rebooted instance %s"" % self.id) LOG.debug(""Restarting datastore on instance %s "" % self.id) LOG.debug(""Restarting datastore successful %s "" % self.id) except GuestError: LOG.error(_(""Failure to restart datastore for instance %s."") % LOG.debug(""Restarting complete on instance %s "" % self.id) LOG.debug(""Updating configuration overrides on instance %s"" % self.id) LOG.debug(""Configuration overrides update successful."") except GuestError: LOG.error(_(""Failed to update configuration overrides."")) LOG.debug(""Unassigning the configuration from the instance %s"" % self.id) LOG.debug(""Unassigning the configuration id %s"" % self.configuration.id) LOG.info(_(""Deleting files with prefix: %(cont)s/%(prefix)s"") % {'cont': cont, 'prefix': prefix}) LOG.info(_(""Deleting file: %(cont)s/%(name)s"") % {'cont': cont, 'name': name}) LOG.info(_(""Deleting file: %(cont)s/%(filename)s"") % {'cont': cont, 'filename': filename}) LOG.exception(_(""Exception deleting from swift. "" raise TroveError(""Failed to delete swift objects"") LOG.debug(""begin _resize_active_volume for id: %(id)s"" % { LOG.debug(""end _resize_active_volume for id: %(id)s"" % { msg = _(""Volume resize failed for instance %(id)s. The instance "" ""must be in state %(state)s not %(inst_state)s."") % { LOG.debug(""begin resize method _perform_nova_action instance: %s"" % LOG.debug(""end resize method _perform_nova_action instance: %s"" %",105,80
openstack%2Fmagnetodb~master~Idf061639911f60e0a992e95f69f9dabc565208c1,openstack/magnetodb,master,Idf061639911f60e0a992e95f69f9dabc565208c1,Fixed API for atomic counters,ABANDONED,2014-05-15 04:24:55.000000000,2014-08-14 13:44:28.000000000,,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8414}, {'_account_id': 8491}, {'_account_id': 8601}]","[{'number': 1, 'created': '2014-05-15 04:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/3bae1058e3f619027d42af67100e12b8777fcab5', 'message': '1) fix API for atomic counter,\n2) add support at storage level\n3) add support in delete and create table at cassandra driver level\n\n TODO:\n Add support for Update and Get Atomic counter values at cassandra driver level\n\nChange-Id: Idf061639911f60e0a992e95f69f9dabc565208c1\n'}, {'number': 2, 'created': '2014-05-15 10:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/58ace7a36c11db99b71735904e5c09965fae6429', 'message': 'Fixed API for atomic counters\n\nChanges:\n1) fixed API for atomic counter,\n2) added support at storage level\n3) added support in delete and create table at cassandra driver level\n4) added counters support to devstack integration\n\nTODO:\nAdd support for Update and Get Atomic counter values at cassandra driver level\n\nChange-Id: Idf061639911f60e0a992e95f69f9dabc565208c1\n'}, {'number': 3, 'created': '2014-05-15 13:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/18ac7356bd8b0d502972ca00b9164c3a8f22d6ae', 'message': 'Fixed API for atomic counters\n\nChanges:\n1) fixed API for atomic counter,\n2) added support at storage level\n3) added counters support to devstack integration\n4) added atomic counters operations at cassandra driver level\n\nChange-Id: Idf061639911f60e0a992e95f69f9dabc565208c1\n'}, {'number': 4, 'created': '2014-05-16 15:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/9232144e36ab07ea1f92de57d0ba4ba21df0bfd1', 'message': 'Fixed API for atomic counters\n\nChanges:\n1) fixed API for atomic counter,\n2) added support at storage level\n3) added counters support to devstack integration\n4) added atomic counters operations at cassandra driver level\n\nChange-Id: Idf061639911f60e0a992e95f69f9dabc565208c1\n'}, {'number': 5, 'created': '2014-05-16 16:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/cab3e2d55e797394788e42333749a9f097604b32', 'message': 'Fixed API for atomic counters\n\nChanges:\n1) fixed API for atomic counter,\n2) added support at storage level\n3) added counters support to devstack integration\n4) added atomic counters operations at cassandra driver level\n\nChange-Id: Idf061639911f60e0a992e95f69f9dabc565208c1\n'}, {'number': 6, 'created': '2014-05-16 17:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/eeb7bcfd6b49dfa3c403536f1d271724f9f0521f', 'message': 'Fixed API for atomic counters\n\nChanges:\n1) fixed API for atomic counter,\n2) added support at storage level\n3) added counters support to devstack integration\n4) added atomic counters operations at cassandra driver level\n\nChange-Id: Idf061639911f60e0a992e95f69f9dabc565208c1\n'}, {'number': 7, 'created': '2014-05-16 17:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/4e03e38d79743e52d9addc83f9f0c3a193302e5d', 'message': 'Fixed API for atomic counters\n\nChanges:\n1) fixed API for atomic counter,\n2) added support at storage level\n3) added counters support to devstack integration\n4) added atomic counters operations at cassandra driver level\n\nChange-Id: Idf061639911f60e0a992e95f69f9dabc565208c1\n'}, {'number': 8, 'created': '2014-05-16 17:57:39.000000000', 'files': ['magnetodb/tests/unittests/storage/impl/test_cassandra_impl.py', 'magnetodb/storage/__init__.py', 'magnetodb/tests/unittests/api/openstack/v1/test_get_counter_item.py', 'magnetodb/api/openstack/v1/get_counter_item.py', 'magnetodb/storage/models.py', 'magnetodb/storage/driver/__init__.py', 'magnetodb/api/openstack/v1/create_table.py', 'magnetodb/api/openstack/v1/update_counter_item.py', 'magnetodb/api/wsgi.py', 'magnetodb/storage/driver/cassandra/cassandra_impl.py', 'magnetodb/storage/table_info_repo/cassandra_impl.py', 'magnetodb/api/openstack/v1/parser.py', 'magnetodb/storage/manager/simple_impl.py', 'contrib/devstack/lib/magnetodb', 'magnetodb/tests/unittests/api/openstack/v1/test_update_counter_item.py', 'magnetodb/storage/manager/__init__.py', 'contrib/cql_samples.txt', 'magnetodb/tests/unittests/api/openstack/v1/test_create_table.py'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/ad927cd449ac4dfb2bcad62866090987d263c8c7', 'message': 'Fixed API for atomic counters\n\nChanges:\n1) fixed API for atomic counter,\n2) added support at storage level\n3) added counters support to devstack integration\n4) added atomic counters operations at cassandra driver level\n\nChange-Id: Idf061639911f60e0a992e95f69f9dabc565208c1\n'}]",7,93654,ad927cd449ac4dfb2bcad62866090987d263c8c7,31,5,8,8601,,,0,"Fixed API for atomic counters

Changes:
1) fixed API for atomic counter,
2) added support at storage level
3) added counters support to devstack integration
4) added atomic counters operations at cassandra driver level

Change-Id: Idf061639911f60e0a992e95f69f9dabc565208c1
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/54/93654/8 && git format-patch -1 --stdout FETCH_HEAD,"['magnetodb/storage/__init__.py', 'magnetodb/tests/unittests/api/openstack/v1/test_get_counter_item.py', 'magnetodb/api/openstack/v1/get_counter_item.py', 'magnetodb/storage/models.py', 'magnetodb/storage/driver/__init__.py', 'magnetodb/api/openstack/v1/create_table.py', 'magnetodb/api/openstack/v1/update_counter_item.py', 'magnetodb/api/wsgi.py', 'magnetodb/storage/driver/cassandra/cassandra_impl.py', 'magnetodb/storage/table_info_repo/cassandra_impl.py', 'magnetodb/api/openstack/v1/parser.py', 'magnetodb/storage/manager/simple_impl.py', 'magnetodb/tests/unittests/api/openstack/v1/test_update_counter_item.py', 'magnetodb/storage/manager/__init__.py', 'contrib/cql_samples.txt', 'magnetodb/tests/unittests/api/openstack/v1/test_create_table.py']",16,3bae1058e3f619027d42af67100e12b8777fcab5,bp/atomic-counters-api-backend," ""counter_attributes"": [""PostsCount""] 'counter_attributes': ['PostsCount'],"," ""counters"": [""PostsCount""] 'counters': ['PostsCount'],",294,76
openstack%2Fmagnetodb~master~I3b4a8b95eeef4d2aac91215ee6601423ab62cc83,openstack/magnetodb,master,I3b4a8b95eeef4d2aac91215ee6601423ab62cc83,Draft version of atomic counters API,ABANDONED,2014-05-14 18:42:32.000000000,2014-08-14 13:44:15.000000000,,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8601}]","[{'number': 1, 'created': '2014-05-14 18:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/adb9796ff72affba16f0224f7fc7e8387fa594a0', 'message': 'Draft version of atomic counters API\n\nAll back-end operations for counters are dummy now.\n\nChange-Id: I3b4a8b95eeef4d2aac91215ee6601423ab62cc83\nImplements: blueprint atomic-counters\n'}, {'number': 2, 'created': '2014-05-15 04:24:55.000000000', 'files': ['magnetodb/api/wsgi.py', 'magnetodb/api/openstack/v1/parser.py', 'magnetodb/tests/unittests/api/openstack/v1/test_get_counters.py', 'magnetodb/tests/unittests/api/openstack/v1/test_update_counters.py', 'magnetodb/api/openstack/v1/get_counters.py', 'magnetodb/api/openstack/v1/update_counters.py', 'magnetodb/tests/unittests/api/openstack/v1/test_create_table.py', 'magnetodb/api/openstack/v1/create_table.py'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/06abc93c47c8ca486ea25b07be49a57a7db0836b', 'message': 'Draft version of atomic counters API\n\nAll back-end operations for counters are dummy now.\n\nChange-Id: I3b4a8b95eeef4d2aac91215ee6601423ab62cc83\nImplements: blueprint atomic-counters\n'}]",0,93619,06abc93c47c8ca486ea25b07be49a57a7db0836b,11,3,2,8414,,,0,"Draft version of atomic counters API

All back-end operations for counters are dummy now.

Change-Id: I3b4a8b95eeef4d2aac91215ee6601423ab62cc83
Implements: blueprint atomic-counters
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/19/93619/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnetodb/api/wsgi.py', 'magnetodb/api/openstack/v1/parser.py', 'magnetodb/tests/unittests/api/openstack/v1/test_get_counters.py', 'magnetodb/tests/unittests/api/openstack/v1/test_update_counters.py', 'magnetodb/api/openstack/v1/get_counters.py', 'magnetodb/api/openstack/v1/update_counters.py', 'magnetodb/tests/unittests/api/openstack/v1/test_create_table.py', 'magnetodb/api/openstack/v1/create_table.py']",8,adb9796ff72affba16f0224f7fc7e8387fa594a0,bp/atomic-counters," parser.Props.TABLE_NAME: parser.Types.TABLE_NAME, parser.Props.COUNTERS: { ""type"": ""array"", ""items"": { ""type"": ""string"", ""pattern"": parser.ATTRIBUTE_NAME_PATTERN } }, #parse counters counters = parser.Parser.parse_counters( body.get(parser.Props.COUNTERS)) # creating counters table if counters: # storage.create_counters(req.context, table_name, counters) pass if counters: table_def = result[parser.Props.TABLE_DESCRIPTION] table_def[parser.Props.COUNTERS] = counters ", parser.Props.TABLE_NAME: parser.Types.TABLE_NAME,416,1
openstack%2Fmagnetodb~master~I55de8fd3871a275d2a64387a9e3fed953a342678,openstack/magnetodb,master,I55de8fd3871a275d2a64387a9e3fed953a342678,(WIP) Added hacking,ABANDONED,2014-06-06 11:18:52.000000000,2014-08-14 13:41:15.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-06 11:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/ad7f8c76ebcd4165841ed8a1fd3367fd019b0de4', 'message': 'Added hacking\n\nhttp://docs.openstack.org/developer/hacking/readme.html\n\nChange-Id: I55de8fd3871a275d2a64387a9e3fed953a342678\n'}, {'number': 2, 'created': '2014-06-06 11:40:38.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/f52be7f6da975b6eda5e956a5da21a5040046c70', 'message': '(WIP) Added hacking\n\nhttp://docs.openstack.org/developer/hacking/readme.html\n\nChange-Id: I55de8fd3871a275d2a64387a9e3fed953a342678'}]",0,98375,f52be7f6da975b6eda5e956a5da21a5040046c70,6,1,2,8188,,,0,"(WIP) Added hacking

http://docs.openstack.org/developer/hacking/readme.html

Change-Id: I55de8fd3871a275d2a64387a9e3fed953a342678",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/75/98375/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ad7f8c76ebcd4165841ed8a1fd3367fd019b0de4,add-hacking,hacking,"flake8==2.0pep8==1.4.6,==1.5.6",1,2
openstack%2Fdesignate~master~Ia513705f75e70e38c6ba8574bf6a4d446a360df7,openstack/designate,master,Ia513705f75e70e38c6ba8574bf6a4d446a360df7,Added docs for zone transfers,ABANDONED,2014-07-18 14:02:58.000000000,2014-08-14 13:34:23.000000000,,"[{'_account_id': 3}, {'_account_id': 741}]","[{'number': 1, 'created': '2014-07-18 14:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/af9f513d6b1c8d34a7538227ec811cee16bbac8c', 'message': 'Added docs for zone transfers\n\nChange-Id: Ia513705f75e70e38c6ba8574bf6a4d446a360df7\nPartially-implements: blueprint zone-migration-between-tenants\n'}, {'number': 2, 'created': '2014-07-21 10:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/89fe90736f30c6ee892b2b9aa67a9385a98470a5', 'message': 'Added docs for zone transfers\n\nChange-Id: Ia513705f75e70e38c6ba8574bf6a4d446a360df7\nPartially-implements: blueprint zone-migration-between-tenants\n'}, {'number': 3, 'created': '2014-07-21 10:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/f1781ba412051d2e79bce31f2939afb19430623c', 'message': 'Added docs for zone transfers\n\nChange-Id: Ia513705f75e70e38c6ba8574bf6a4d446a360df7\nPartially-implements: blueprint zone-migration-between-tenants\n'}, {'number': 4, 'created': '2014-07-21 13:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/5bdaa4ed8cd7540e3e0f8d9a42d9c38fd03e56b0', 'message': 'Added docs for zone transfers\n\nChange-Id: Ia513705f75e70e38c6ba8574bf6a4d446a360df7\nPartially-implements: blueprint zone-migration-between-tenants\n'}, {'number': 5, 'created': '2014-07-24 17:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/bc99f6866e0eb5bea8967694b5fe506b1955985a', 'message': 'Added docs for zone transfers\n\nChange-Id: Ia513705f75e70e38c6ba8574bf6a4d446a360df7\nPartially-implements: blueprint zone-migration-between-tenants\n'}, {'number': 6, 'created': '2014-07-24 19:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e78f24535b3c22ad302490a64251de4491019fd3', 'message': 'Added docs for zone transfers\n\nChange-Id: Ia513705f75e70e38c6ba8574bf6a4d446a360df7\nPartially-implements: blueprint zone-migration-between-tenants\n'}, {'number': 7, 'created': '2014-07-24 19:50:38.000000000', 'files': ['doc/source/rest/v2/zones.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/1e8f0c9bf772d660a0f1345227a977ef7a3c9dd3', 'message': 'Added docs for zone transfers\n\nChange-Id: Ia513705f75e70e38c6ba8574bf6a4d446a360df7\nPartially-implements: blueprint zone-migration-between-tenants\n'}]",2,108016,1e8f0c9bf772d660a0f1345227a977ef7a3c9dd3,21,2,7,8099,,,0,"Added docs for zone transfers

Change-Id: Ia513705f75e70e38c6ba8574bf6a4d446a360df7
Partially-implements: blueprint zone-migration-between-tenants
",git fetch https://review.opendev.org/openstack/designate refs/changes/16/108016/6 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/rest/v2/zones.rst'],1,af9f513d6b1c8d34a7538227ec811cee16bbac8c,bp/zone-migration-between-tenants," To import a zonefile, set the Content-type to**text/dns**. The **zoneextractor.py**tool in the**contrib**folder can generate zonefiles that are suitable for Designate (without any**$INCLUDE**statements for To export a zone in zonefile format, set the**Accept**header to**text/dns**. Transfer Zone ------------- Create Zone Transfer Request ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ .. http:post:: /zones/(uuid:id)/tasks/transfer_requests To initiate a transfer the original owner must create a transfer request. This will return two items that are required to continue: * key: a password that is used to validate the transfer * id: ID of the request. Both of these should be communicated out of band (email / IM / etc) to the intended recipient There is an option of limiting the transfer to a single project. If that is required, the person initiating the transfer will need the Project ID. This will also allow the targeted project to see the transfer in their list of requests. A non-targeted request will not show in a list operation, apart from the owning projects request. An targeted request will only show in the targets and owners lists. An un-targeted request can be viewed by any authenticated user. **Example Request** .. sourcecode:: http POST /v2/zones/6b78734a-aef1-45cd-9708-8eb3c2d26ff8/tasks/transfer_requests HTTP/1.1 Host: 127.0.0.1:9001 Accept: application/json Content-Type: application/json { ""transfer_request"":{ ""target_project_id"": ""123456"", ""description"": ""Transfer qa.dev.example.com. to QA Team"" } } **Example Response** .. sourcecode:: http HTTP/1.1 201 Created Content-Type: application/json { ""transfer_request"": { ""created_at"": ""2014-07-17T20:34:40.882579"", ""description"": null, ""id"": ""f2ad17b5-807a-423f-a991-e06236c247be"", ""key"": ""9Z2R50Y0"", ""project_id"": ""1"", ""status"": ""ACTIVE"", ""target_project_id"": ""123456"", ""updated_at"": null, ""zone_id"": ""6b78734a-aef1-45cd-9708-8eb3c2d26ff8"", ""zone_name"": ""qa.dev.example.com."", ""links"": { ""self"": ""http://127.0.0.1:9001/v2/zones/tasks/transfer_requests/f2ad17b5-807a-423f-a991-e06236c247be"" } } } :form description: UTF-8 text field :form target_project_id: Optional field to only allow a single tenant to accept the transfer request List Zone Transfer Requests ^^^^^^^^^^^^^^^^^^^^^^^^^^^ .. http:get:: /zones/tasks/transfer_requests List all transfer requests that the requesting project have created, or are targeted to that project The detail shown will differ, based on who the requester is. **Example Request** .. sourcecode:: http GET /zones/tasks/transfer_requests HTTP/1.1 Host: 127.0.0.1:9001 Accept: application/json **Example Response** .. sourcecode:: http HTTP/1.1 200 OK Content-Type: application/json { ""transfer_requests"": [ { ""created_at"": ""2014-07-17T20:34:40.882579"", ""description"": ""This was created by the requesting project"", ""id"": ""f2ad17b5-807a-423f-a991-e06236c247be"", ""key"": ""9Z2R50Y0"", ""project_id"": ""1"", ""status"": ""ACTIVE"", ""target_project_id"": ""123456"", ""updated_at"": null, ""zone_id"": ""6b78734a-aef1-45cd-9708-8eb3c2d26ff8"", ""zone_name"": ""qa.dev.example.com."", ""links"": { ""self"": ""http://127.0.0.1:9001/v2/zones/tasks/transfer_requests/f2ad17b5-807a-423f-a991-e06236c247be"" } }, { ""description"": ""This is scoped to the requesting project"", ""id"": ""efd2d720-b0c4-43d4-99f7-d9b53e08860d"", ""zone_id"": ""2c4d5e37-f823-4bee-9859-031cb44f80e7"", ""zone_name"": ""subdomain.example.com."", ""status"": ""ACTIVE"", ""links"": { ""self"": ""http://127.0.0.1:9001/v2/zones/tasks/transfer_requests/efd2d720-b0c4-43d4-99f7-d9b53e08860d"" } } ], ""links"": { ""self"": ""http://127.0.0.1:9001/v2/zones/tasks/transfer_requests"" } } View a Transfer Request ^^^^^^^^^^^^^^^^^^^^^^^ .. http:get:: /zones/tasks/transfer_requests/(uuid:id) Show details about a request. This allows a user to view a transfer request before accepting it **Example Request** .. sourcecode:: http GET /v2/zones/tasks/transfer_requests/f2ad17b5-807a-423f-a991-e06236c247be HTTP/1.1 Host: 127.0.0.1:9001 Accept: application/json **Example Response** .. sourcecode:: http HTTP/1.1 200 OK Content-Type: application/json { ""transfer_request"":{ ""description"": ""This is scoped to the requesting project"", ""id"": ""efd2d720-b0c4-43d4-99f7-d9b53e08860d"", ""zone_id"": ""2c4d5e37-f823-4bee-9859-031cb44f80e7"", ""zone_name"": ""subdomain.example.com."", ""status"": ""ACTIVE"", ""links"": { ""self"": ""http://127.0.0.1:9001/v2/zones/tasks/transfer_requests/efd2d720-b0c4-43d4-99f7-d9b53e08860d"" } } } Accept a Transfer Request ^^^^^^^^^^^^^^^^^^^^^^^^^ .. http:post:: /zones/tasks/transfer_accepts Accept a zone transfer request. This is called by the project that will own the zone (i.e. the project that will maintain the zone) Once the API returns ""Complete"" the zone has been transfered to the new project **Example Request** .. sourcecode:: http POST /v2/zones/tasks/transfer_accept HTTP/1.1 Host: 127.0.0.1:9001 Accept: application/json Content-Type: application/json { ""transfer_accept"":{ ""key"":""9Z2R50Y0"", ""zone_transfer_request_id"":""f2ad17b5-807a-423f-a991-e06236c247be"" } } **Example Response** .. sourcecode:: http HTTP/1.1 201 Created Content-Type: application/json { ""transfer_accept"": { ""id"": ""581891d5-99f5-49e1-86c3-eec0f44d66fd"", ""links"": { ""self"": ""http://127.0.0.1:9001/v2/zones/tasks/transfer_accepts/581891d5-99f5-49e1-86c3-eec0f44d66fd"", ""zone"": ""http://127.0.0.1:9001/v2/zones/6b78734a-aef1-45cd-9708-8eb3c2d26ff8"" }, ""status"": ""COMPLETE"" } } "," To import a zonefile, set the Content-type to **text/dns**. The **zoneextractor.py** tool in the **contrib** folder can generate zonefiles that are suitable for Designate (without any **$INCLUDE** statements for To export a zone in zonefile format, set the **Accept** header to **text/dns**.",214,4
openstack%2Fnova~master~I8211cb31a7a890f86cdd818767b3d5e8cfd5bbed,openstack/nova,master,I8211cb31a7a890f86cdd818767b3d5e8cfd5bbed,libvirt: make guestfs methods always return list of tuples,MERGED,2014-08-04 12:00:35.000000000,2014-08-14 13:28:31.000000000,2014-08-14 13:28:28.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9796}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-04 12:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/435c09bd244f22f4e1795d8a949f850b60e6216f', 'message': ""libvirt: make guestfs method always return list of tuples\n\nguestfs.GuestFS supports parameter python_return_dict with default\nFalse in 1.22, see http://libguestfs.org/guestfs-release-notes.1.html\nThis indicates that your program wants to receive Python dicts for\nmethods in the API that return list of tuples. In a future version of\nlibguestfs, its default value will be True, and this will break the\ncode, to avoid this, we'd better force  python_return_dict as False.\nSee http://libguestfs.org/guestfs-python.3.html\n\nThis commit makes method inspect_get_mountpoints always return list\nof tuples.\n\nChange-Id: I8211cb31a7a890f86cdd818767b3d5e8cfd5bbed\n""}, {'number': 2, 'created': '2014-08-04 12:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10067646109555047bbbe36d44d02c12994c99b6', 'message': ""libvirt: make guestfs method always return list of tuples\n\nguestfs.GuestFS supports parameter python_return_dict with default\nFalse in 1.22, see http://libguestfs.org/guestfs-release-notes.1.html\nThis indicates that your program wants to receive Python dicts for\nmethods in the API that return list of tuples. In a future version of\nlibguestfs, its default value will be True, and this will break the\ncode, to avoid this, we'd better force  python_return_dict as False.\nSee http://libguestfs.org/guestfs-python.3.html\n\nThis commit makes method inspect_get_mountpoints always return list\nof tuples.\n\nChange-Id: I8211cb31a7a890f86cdd818767b3d5e8cfd5bbed\n""}, {'number': 3, 'created': '2014-08-04 12:58:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/564fd408136d4fc1e2cad964e63492f2bd408569', 'message': ""libvirt: make guestfs method always return list of tuples\n\nguestfs.GuestFS supports parameter python_return_dict with default\nFalse in 1.22, see http://libguestfs.org/guestfs-release-notes.1.html\nThis indicates that your program wants to receive Python dicts for\nmethods in the API that return list of tuples. In a future version of\nlibguestfs, its default value will be True, and this will break the\ncode, to avoid this, we'd better force  python_return_dict as False.\nSee http://libguestfs.org/guestfs-python.3.html\n\nThis commit makes method inspect_get_mountpoints always return list\nof tuples.\n\nChange-Id: I8211cb31a7a890f86cdd818767b3d5e8cfd5bbed\n""}, {'number': 4, 'created': '2014-08-05 02:04:26.000000000', 'files': ['nova/tests/virt/disk/vfs/fakeguestfs.py', 'nova/tests/virt/disk/vfs/test_guestfs.py', 'nova/virt/disk/vfs/guestfs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a8c8af82600e2905b558588e615b2e512adc7e7e', 'message': ""libvirt: make guestfs methods always return list of tuples\n\nguestfs.GuestFS supports parameter python_return_dict with default\nFalse in 1.22 (backported in 1.20). This indicates that your program\nwants to receive Python dicts for methods in the API that return list\nof tuples. See http://libguestfs.org/guestfs-release-notes.1.html\nIn a future version of libguestfs, its default value will be True,\nthen that will break the code, to avoid this, we'd better force\npython_return_dict as False. See http://libguestfs.org/guestfs-python.3.html\n\nThis commit makes method inspect_get_mountpoints always return list\nof tuples.\n\nChange-Id: I8211cb31a7a890f86cdd818767b3d5e8cfd5bbed\n""}]",4,111699,a8c8af82600e2905b558588e615b2e512adc7e7e,37,10,4,9796,,,0,"libvirt: make guestfs methods always return list of tuples

guestfs.GuestFS supports parameter python_return_dict with default
False in 1.22 (backported in 1.20). This indicates that your program
wants to receive Python dicts for methods in the API that return list
of tuples. See http://libguestfs.org/guestfs-release-notes.1.html
In a future version of libguestfs, its default value will be True,
then that will break the code, to avoid this, we'd better force
python_return_dict as False. See http://libguestfs.org/guestfs-python.3.html

This commit makes method inspect_get_mountpoints always return list
of tuples.

Change-Id: I8211cb31a7a890f86cdd818767b3d5e8cfd5bbed
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/111699/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/disk/vfs/fakeguestfs.py', 'nova/tests/virt/disk/vfs/test_guestfs.py', 'nova/virt/disk/vfs/guestfs.py']",3,435c09bd244f22f4e1795d8a949f850b60e6216f,return_dic_guestfs," self.handle = tpool.Proxy( guestfs.GuestFS(python_return_dict=False, close_on_exit=False)) except TypeError as e: if 'close_on_exit' in str(e) or 'python_return_dict' in str(e): # NOTE(gcb) python_return_dict was added in libguestfs 1.22", self.handle = tpool.Proxy(guestfs.GuestFS(close_on_exit=False)) except TypeError as e: if 'close_on_exit' in str(e):,26,5
openstack%2Ftraining-guides~master~I231fc4e32ed71edf10987a462714bb9d230647d1,openstack/training-guides,master,I231fc4e32ed71edf10987a462714bb9d230647d1,labs: increase RAM allocation for controller node,MERGED,2014-08-14 08:18:05.000000000,2014-08-14 13:20:49.000000000,2014-08-14 13:20:49.000000000,"[{'_account_id': 3}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-08-14 08:18:05.000000000', 'files': ['labs/config/config.controller'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/cc699cf93f06c09f35254d7baa5ce79180794eba', 'message': 'labs: increase RAM allocation for controller node\n\nThe controller node is running most of the services. It slows to a\ncrawl once all of them are installed.\n\nThis patch gives the controller node 1024 MB of RAM (instead of the\ncurrent default: 512 MB).\n\nChange-Id: I231fc4e32ed71edf10987a462714bb9d230647d1\nImplements: blueprint openstack-training-labs\n'}]",0,114159,cc699cf93f06c09f35254d7baa5ce79180794eba,7,2,1,11109,,,0,"labs: increase RAM allocation for controller node

The controller node is running most of the services. It slows to a
crawl once all of them are installed.

This patch gives the controller node 1024 MB of RAM (instead of the
current default: 512 MB).

Change-Id: I231fc4e32ed71edf10987a462714bb9d230647d1
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/59/114159/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/config/config.controller'],1,cc699cf93f06c09f35254d7baa5ce79180794eba,bp/openstack-training-labs, # Controller is running most of the services; it needs more than 512 MB RAM VM_MEM=1024,,3,0
openstack%2Ftraining-guides~master~Id9fa80766dca7953f82cd75d671ebbf4e29e7ba9,openstack/training-guides,master,Id9fa80766dca7953f82cd75d671ebbf4e29e7ba9,labs: fix cinder endpoints,MERGED,2014-08-14 08:11:55.000000000,2014-08-14 13:20:04.000000000,2014-08-14 13:20:04.000000000,"[{'_account_id': 3}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-08-14 08:11:55.000000000', 'files': ['labs/scripts/setup_cinder_controller.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/cc16bc7d032cd5695c81661d80fae1035b474d7a', 'message': 'labs: fix cinder endpoints\n\nAdds ""%(tenant_id)s"" strings to cinder endpoints to make them work.\n\nAlso registers v2 service and endpoints.\n\nChange-Id: Id9fa80766dca7953f82cd75d671ebbf4e29e7ba9\nImplements: blueprint openstack-training-labs\n'}]",0,114158,cc16bc7d032cd5695c81661d80fae1035b474d7a,7,2,1,11109,,,0,"labs: fix cinder endpoints

Adds ""%(tenant_id)s"" strings to cinder endpoints to make them work.

Also registers v2 service and endpoints.

Change-Id: Id9fa80766dca7953f82cd75d671ebbf4e29e7ba9
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/58/114158/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/scripts/setup_cinder_controller.sh'],1,cc16bc7d032cd5695c81661d80fae1035b474d7a,bp/openstack-training-labs," --publicurl 'http://controller-api:8776/v1/%(tenant_id)s' \ --adminurl 'http://controller-mgmt:8776/v1/%(tenant_id)s' \ --internalurl 'http://controller-mgmt:8776/v1/%(tenant_id)s' keystone service-create \ --name cinderv2 \ --type volumev2 \ --description ""OpenStack Block Storage v2"" cinder_v2_service_id=$(keystone service-list | awk '/ volumev2 / {print $2}') keystone endpoint-create \ --service-id ""$cinder_v2_service_id"" \ --publicurl 'http://controller-api:8776/v2/%(tenant_id)s' \ --adminurl 'http://controller-mgmt:8776/v2/%(tenant_id)s' \ --internalurl 'http://controller-mgmt:8776/v2/%(tenant_id)s'"," --publicurl ""http://controller-api:8776/v1"" \ --adminurl ""http://controller-mgmt:8776/v1"" \ --internalurl ""http://controller-mgmt:8776/v1""",15,3
openstack%2Fdevstack~master~I9e154f7fdf814b4bd21a9d4cf82e46ec3db2f1ca,openstack/devstack,master,I9e154f7fdf814b4bd21a9d4cf82e46ec3db2f1ca,Remove AUTHORS,MERGED,2014-08-07 05:08:15.000000000,2014-08-14 13:12:32.000000000,2014-08-14 13:12:31.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 67}, {'_account_id': 112}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-07 05:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8e0bea79350f455460f25eec8e847361aab628ed', 'message': ""Update AUTHORS\n\nI'm not sure AUTHORS is really even relevant in the days of git.\nRegenerate it from:\n\n $ git log --format='%aN <%aE>' | sort -f | uniq > AUTHORS\n\nIf people are unhappy with the output for themselves, they should\nupdate .mailmap.\n\nChange-Id: I9e154f7fdf814b4bd21a9d4cf82e46ec3db2f1ca\n""}, {'number': 2, 'created': '2014-08-07 08:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7f7d55000a05ae2b1f5860eaa8adb71094a116ee', 'message': ""Update AUTHORS\n\nI'm not sure AUTHORS is really even relevant in the days of git.\nRegenerate it from:\n\n $ git log --format='%aN <%aE>' | sort -f | uniq > AUTHORS\n\nIf people are unhappy with the output for themselves, they should\nupdate .mailmap.\n\nChange-Id: I9e154f7fdf814b4bd21a9d4cf82e46ec3db2f1ca\n""}, {'number': 3, 'created': '2014-08-14 03:53:59.000000000', 'files': ['.mailmap', 'AUTHORS'], 'web_link': 'https://opendev.org/openstack/devstack/commit/27fc42d2bc39a21e70c913b0e92d249583cbfc62', 'message': ""Remove AUTHORS\n\nAUTHORS isn't really relevant in the days of git.  devstack has no\nformal release where it would make sense to auto-generate an AUTHORS\nfile either.\n\nIf you really want to see who contributes, you can run\n\n $ git log --format='%aN <%aE>' | sort -f | uniq > AUTHORS\n\nChange-Id: I9e154f7fdf814b4bd21a9d4cf82e46ec3db2f1ca\n""}]",0,112476,27fc42d2bc39a21e70c913b0e92d249583cbfc62,26,11,3,7118,,,0,"Remove AUTHORS

AUTHORS isn't really relevant in the days of git.  devstack has no
formal release where it would make sense to auto-generate an AUTHORS
file either.

If you really want to see who contributes, you can run

 $ git log --format='%aN <%aE>' | sort -f | uniq > AUTHORS

Change-Id: I9e154f7fdf814b4bd21a9d4cf82e46ec3db2f1ca
",git fetch https://review.opendev.org/openstack/devstack refs/changes/76/112476/1 && git format-patch -1 --stdout FETCH_HEAD,"['.mailmap', 'AUTHORS']",2,8e0bea79350f455460f25eec8e847361aab628ed,authors,"Aaron Rosen <aaronorosen@gmail.com>Adalberto Medeiros <adalbas@linux.vnet.ibm.com> Adam Gandelman <adam.gandelman@canonical.com>Adam Gandelman <adamg@ubuntu.com> Adam Spiers <aspiers@suse.com> Adam Young <ayoung@redhat.com> Akihiro Motoki <motoki@da.jp.nec.com>Alan Pevec <apevec@redhat.com> Alessio Ababilov <ilovegnulinux@gmail.com> Alexander Gordeev <agordeev@mirantis.com> Alex Gaynor <alex.gaynor@gmail.com> Alex Rudenko <alexei.rudenko@gmail.com> Alvaro Lopez Ortega <alvaro@gnu.org> AmalaBasha <amala.alungal@RACKSPACE.COM> Ana Krivokapic <akrivoka@redhat.com> Anant Patil <anant.patil@hp.com> Andrea Frittoli <andrea.frittoli@hp.com> Andrea Frittoli <frittoli@hp.com> Andrew Bogott <abogott@wikimedia.org> Andrew Laski <alaski@gmail.com>Andrew Melton <andrew.melton@rackspace.com> Andy Chong <andycjw@gmail.com>Angus Salkeld <asalkeld@redhat.com> Anita Kuno <anteaya@anteaya.info> anju Tiwari <anjutiwari5@gmail.com>Arata Notsu <notsu@virtualtech.jp> Armando Migliaccio <amigliaccio@internap.com> Armando Migliaccio <amigliaccio@nicira.com> armando-migliaccio <amigliaccio@nicira.com> armando-migliaccio <armamig@gmail.com>Arnaud Legendre <arnaudleg@gmail.com> Attila Fazekas <afazekas@redhat.com> av-mido <avasilyev@midokura.jp> Baodong (Robert) Li <baoli@cisco.com> Bartosz Górski <bartosz.gorski@ntti3.com> Ben Andrews <andrewsben@gmail.com> Ben Nemec <bnemec@redhat.com> Ben Nemec <bnemec@us.ibm.com> Ben Nemec <openstack@nemebean.com> Bob Ball <bob.ball@citrix.com> Bob Kukura <rkukura@redhat.com> Bob Melander <bob.melander@gmail.com> Boris Pavlovic <boris@pavlovic.me>Brad P. Crochet <brad@redhat.com> Brad Topol <btopol@us.ibm.com> Brant Knudson <bknudson@us.ibm.com> Brett Campbell <invsblduck@gmail.com> Brian Haley <brian.haley@hp.com> Brian Waldon <bcwaldon@gmail.com> Chmouel Boudjnah <chmouel.boudjnah@rackspace.co.uk>Chmouel Boudjnah <chmouel@enovance.com> Chmouel Boudjnah <launchpad@chmouel.com> Chris Behrens <cbehrens@codestud.com> Chris Buccella <buccella@linux.vnet.ibm.com> Chris Dent <chdent@redhat.com> Chris Krelle <nobodycam@gmail.com> Christian Berendt <berendt@b1-systems.de> Chris Yeoh <cyeoh@au1.ibm.com> Chuck Short <chuck.short@canonical.com> Clark Boylan <clark.boylan@gmail.com> Clint Byrum <clint@fewbar.com> cloudnull <kevin.carter@rackspace.com> Cody A.W. Somerville <cody.somerville@hp.com> Cyril Roelandt <cyril.roelandt@enovance.com> Dane LeBlanc <leblancd@cisco.com> Daniel Jones <jonesld@us.ibm.com> Daniel Kuffner <dkuffner@chilicat.net> Daniel P. Berrange <berrange@redhat.com> Daniel Salinas <imsplitbit@gmail.com>Dan Smith <danms@us.ibm.com> Dan Smith <dansmith@redhat.com> Dan Wendlandt <dan@nicira.com> Darragh O'Reilly <dara2002-openstack@yahoo.com> Davanum Srinivas <davanum@gmail.com> Davanum Srinivas <dims@linux.vnet.ibm.com> Dave Lapsley <dlapsley@nicira.com> Dave Tucker <dave@dtucker.co.uk> Davide Guerri <davide.guerri@hp.com> David Kranz <david.kranz@qrclab.com> David Kranz <dkranz@redhat.com> David Ripton <dripton@redhat.com> David Shrewsbury <shrewsbury.dave@gmail.com> Dean Troyer <dt-github@xr7.org>debo <ddutta@gmail.com> Deepak Garg <deepak.garg@citrix.com> Denis Egorenko <degorenko@mirantis.com> Denis Makogon <dmakogon@mirantis.com> DennyZhang <denny@unitedstack.com> Derek Morton <derek.morton25@gmail.com> Derrick J. Wippler <thrawn01@gmail.com> Devananda van der Veen <devananda.vdv@gmail.com>Dina Belova <dbelova@mirantis.com> Dirk Mueller <dirk@dmllr.de> Dmitriy Budnik <dmitriy.budnik@gmail.com> dmitriybudnik <dmitriy.budnik@gmail.com> Dmitry Tantsur <dtantsur@redhat.com> Dolph Mathews <dolph.mathews@gmail.com> Don Dugger <donald.d.dugger@intel.com> Doug Hellmann <doug.hellmann@dreamhost.com> Ed Balduf <ebalduf@fusionio.com> Ed Cranford <ed.cranford@rackspace.com>Elena Ezhova <eezhova@mirantis.com> Emanuele Rocca <ema@linux.it> Emilien Macchi <emilien.macchi@enovance.com> Émilien Macchi <emilien.macchi@enovance.com>Eric Brown <browne@vmware.com> Eric Harney <eharney@redhat.com> Eric Windisch <eric@cloudscaling.com> Eric Windisch <ewindisch@docker.com> Euan Harris <euan.harris@citrix.com> Eugene Nikanorov <enikanorov@mirantis.com> Everett Toews <everett.toews@gmail.com> Evgeniy Afonichev <eafonichev@mirantis.com> ewindisch <eric@cloudscaling.com> Flaper Fesp <flaper87@gmail.com> Flavio Fernandes <ffernand@redhat.com> Flavio Percoco <flaper87@gmail.com> Florent Flament <florent.flament-ext@cloudwatt.com> Franck Yelles <franck110@gmail.com> ftersin <ftersin@cloudscaling.com> fujioka yuuichi <fujioka-yuuichi@zx.mxh.nes.nec.co.jp> fumihiko kakuma <kakuma@valinux.co.jp> Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>Gael Chamoulaud <gchamoul@redhat.com> galstrom21 <jshepher@rackspace.com>Gary Kotton <gkotton@vmware.com> Georges Dubus <georges.dubus@numergy.com> Geronimo Orozco <geronimo.orozco@intel.com> Ghe Rivero <ghe@debian.org> Gilles Dubreuil <gilles@redhat.com> Giulio Fidente <gfidente@redhat.com> Gonéri Le Bouder <goneri.lebouder@enovance.com> Gordon Chung <chungg@ca.ibm.com> gordon chung <gord@live.ca> Greg Lucas <glucas@tesora.com> Guangyu Suo <guangyu@unitedstack.com> guillaume pernot <gpernot@praksys.org> Haiwei Xu <xu-haiwei@mxw.nes.nec.co.jp> Harshada Mangesh Kakad <harshada.kakad@izeltech.com> hartsocks <hartsocks@vmware.com> Hemanth Ravi <hemanth.ravi@oneconvergence.com>Henry Gessau <gessau@cisco.com> Hirofumi Ichihara <ichihara.hirofumi@lab.ntt.co.jp>Ian Wienand <iwienand@redhat.com> Ihar Hrachyshka <ihrachys@redhat.com> Ilya Kharin <akscram@gmail.com> Isaku Yamahata <isaku.yamahata@intel.com> Isaku Yamahata <yamahata@valinux.co.jp> Ivar Lazzaro <ivar@embrane.com> IWAMOTO Toshihiro <iwamoto@valinux.co.jp>jakedahn <jake@ansolabs.com> Jakub Libosvar <libosvar@redhat.com> Jakub Ruzicka <jruzicka@redhat.com> James Chapman <james.p.chapman@intel.com>James E. Blair <jeblair@hp.com> James E. Blair <jeblair@openstack.org> James Kyle <james@jameskyle.org> Jamie Lennox <jamielennox@redhat.com> Jamie Lennox <jlennox@redhat.com>Jason Dillaman <dillaman@redhat.com> Jason Dunsmore <jasondunsmore@gmail.com> Jason Kölker <jason@koelker.net> Jay Lau <liugya@cn.ibm.com>Jeff Peeler <jpeeler@redhat.com> Jenkins <jenkins@review.openstack.org> Jeremy Stanley <fungi@yuggoth.org> Jérôme Gallard <jerome.david.gallard@gmail.com>Jiajun Liu <jiajun@unitedstack.com> jiajun xu <jiajun.xu@intel.com> Jianing Yang <jianingy@unitedstack.com>Jim Rollenhagen <jim@jimrollenhagen.com> Joe Gordon <joe.gordon0@gmail.com> Joe Heck <heckj@mac.com> Joe H. Rahme <joe.hakim.rahme@enovance.com> Joe Mills <joe@midokura.com> joequant <joequant@gmail.com>John Dunning <jrd@redhat.com> John Eckersberg <jeckersb@redhat.com> John Garbutt <john.garbutt@citrix.com> John Griffith <john.griffith@solidfire.com> john-griffith <john.griffith@solidfire.com> John H. Tran <jhtran@att.com>Jonathan Michalon <michalon@igbmc.fr> Jordan Pittier <jordan.pittier@gmail.com> JordanP <jordan.pittier@cloudwatt.com> JordanP <jordan.pittier-ext@cloudwatt.com> JordanP <jordan.pittier@gmail.com> Jorge Valderrama Romero <jorge.valderrama@stackops.com>Juan Manuel Olle <juan.m.olle@intel.com> Julien Danjou <julien@danjou.info> Julien Vey <julien.vey@numergy.com> Julie Pichon <jpichon@redhat.com> JUN JIE NAN <nanjj@cn.ibm.com> Jun Wu <quark@lihdd.net> Justin Santa Barbara <justin@fathomdb.com>Kaitlin Farr <kaitlin.farr@jhuapl.edu> Kashyap Chamarthy <kchamart@redhat.com> Ken'ichi Ohmichi <oomichi@mxs.nes.nec.co.jp>Kevin Benton <blak111@gmail.com> Kevin Benton <kevin.benton@bigswitch.com> Kevin L. Mitchell <kevin.mitchell@rackspace.com> Kevin Lyda <kevin@ie.suberic.net> Kiall Mac Innes <kiall@hp.com>Kieran Spear <kispear@gmail.com> KIYOHIRO ADACHI <adachi@mxs.nes.nec.co.jp> Kui Shi <skuicloud@gmail.com> Kyle Mestery <kmestery@cisco.com> Lianhao Lu <lianhao.lu@intel.com> lokesh <lokesh.s@hp.com> Longgeek <longgeek@thstack.com> long-wang <long.wang@bj.cs2c.com.cn> Lorin Hochstein <lorin@nimbisservices.com> Lucas Alvares Gomes <lucasagomes@gmail.com> Luigi Toscano <ltoscano@redhat.com> Malini Kamalambal <malini.kamalambal@rackspace.com> Mark McClain <mark.mcclain@dreamhost.com> Mark McClain <mmcclain@yahoo-inc.com> Mark McLoughlin <markmc@redhat.com> Martin Vidner <mvidner@suse.cz> Maru Newby <marun@redhat.com> Maru Newby <mnewby@internap.com> Masayuki Igawa <igawa@mxs.nes.nec.co.jp> Mate Lakat <mate.lakat@citrix.com> Mathieu Gagné <mgagne@iweb.com> mathieu-rohon <mathieu.rohon@gmail.com> mathrock <nathanael.i.burton.work@gmail.com> Mat Lowery <mlowery@ebaysf.com> Matthew Oliver <matt@oliver.net.au> Matthew Treinish <mtreinish@kortar.org> Matthew Treinish <treinish@linux.vnet.ibm.com> Matthieu Huin <mhu@enovance.com>Matt Odden <mrodden@us.ibm.com> Matt Riedemann <mriedem@us.ibm.com> Mauro S. M. Rodrigues <maurosr@linux.vnet.ibm.com> Mehdi Abaakouk <mehdi.abaakouk@enovance.com> Michael Basnight <mbasnight@gmail.com> Michael Still <mikal@stillhq.com> Mike Perez <thingee@gmail.com> Min Li <limin.marcus@gmail.com> Mohammad Banikazemi <mb@us.ibm.com> Monty Taylor <mordred@inaugust.com> Morgan Fainberg <m@metacloud.com> Morgan Fainberg <morgan.fainberg@gmail.com> MORITA Kazutaka <morita.kazutaka@gmail.com> Nachi Ueno <nachi@ntti3.com> Nachi Ueno <nachi@nttmcl.com> Nadya Privalova <nprivalova@mirantis.com> Nathan Kinder <nkinder@redhat.com> Newell Jensen <newell.jensen@gmail.com> Nicolas Simonds <nic@metacloud.com> Nikhil Manchanda <SlickNik@gmail.com> Nikola Dipanov <ndipanov@redhat.com> Nikolay Sobolevskiy <nsobolevsky@mirantis.com> Nobuto MURATA <nobuto@ubuntu.com> Noorul Islam K M <noorul@noorul.com> Obulapathi N Challa <obulpathi@gmail.com> Oleg Bondarev <obondarev@mirantis.com>Pádraig Brady <pbrady@redhat.com> Paul Czarkowski <paul@paulcz.net> Paul Linchpiner <autokarmaru@gmail.com> Paul Michali <pcm@cisco.com> Peter Feiner <peter@gridcentric.ca> Peter Portante <peter.portante@redhat.com> Piyush Masrani <pmasrani@vmware.com> Rabi Mishra <ramishra@redhat.com> Radoslaw Smigielski <radoslaw.smigielski@gmail.com> Rafael Folco <rfolco@br.ibm.com> rahmu <joe.hakim.rahme@enovance.com> Ralf Haferkamp <rhafer@suse.de> Ramakrishnan G <rameshg87@gmail.com> Ravi Chunduru <ravivsn@gmail.com> Renuka Apte <renuka.apte@citrix.com> Robbie Harwood (frozencemetery) <rharwood@redhat.com> Rob Crittenden <rcritten@redhat.com> Robert Collins <rbtcollins@hp.com> Robert Collins <robertc@robertcollins.net> Robert Myers <robert.myers@rackspace.com> Roey Chen <roeyc@mellanox.com> Roger Luethi <rl@patchworkscience.org> Rohit Karajgi <rohit.karajgi@nttdata.com> Roman Bogorodskiy <rbogorodskiy@mirantis.com> Roman Gorodeckij <holms@holms.lt> Roman Prykhodchenko <me@romcheg.me> Roman Prykhodchenko <rprikhodchenko@mirantis.com> ronak <ronak.malav.shah@gmail.com> root <root@localhost.localdomain> root <root@stack.(none)> root <root@STACK.(none)> Ruby Loo <rloo@yahoo-inc.com>Ryan Hsu <rhsu@vmware.com> Ryan McNair <rdmcnair@us.ibm.com> Ryota MIBU <r-mibu@cq.jp.nec.com> Ryu Ishimoto <ryu@midokura.com> Sabari Kumar Murugesan <smurugesan@vmware.com> Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com> Salvatore Orlando <salv.orlando@gmail.com> Sam Alba <sam.alba@gmail.com> Sam Hague <shague@gmail.com> Samuel Merritt <sam@swiftstack.com> Sascha Peilicke <saschpe@mailbox.org> Sascha Peilicke <saschpe@suse.de> sbauza <sbauza@free.fr> sbauza <sylvain.bauza@bull.net> Scott Moser <smoser@brickies.net>Sean Dague <sean@dague.net> Sean Dague <sean.dague@samsung.com> Sean Gallagher <sean@torandu.com> Sean M. Collins <sean_collins2@cable.comcast.com> Sébastien Han <sebastien.han@enovance.com> Sergey Kraynev <skraynev@mirantis.com> Sergey Lukjanov <slukjanov@mirantis.com> Sergey Skripnick <sskripnick@mirantis.com> shalini khandelwal <shalini.khandelwal@globallogic.com> Shane Wang <shane.wang@intel.com> Shashank Hegde <shashank@aristanetworks.com> Shengjie Min <shengjie_min@dell.com> Shiv Haris <sharis@brocade.com> Shweta P <shpadubi@cisco.com> Simon Pasquier <simon.pasquier@bull.net> Sirushti Murugesan <sirushtim@gmail.com> sleepsonthefloor <sleepsonthefloor@gmail.com> Solly Ross <sross@redhat.com> Soren Hansen <Soren.Hansen@ril.com> Sphoorti Joglekar <sphoorti.joglekar@gmail.com> Sreeram Yerrapragada <syerrapragada@vmware.com> sridhargaddam <sridhar.gaddam@enovance.com> stack <aguzikova@mirantis.com> Stanislaw Pitucha <stanislaw.pitucha@hp.com> Stef T <stelford@internap.com> Stephan Renatus <s.renatus@cloudbau.de> Stephen Ma <stephen.ma@hp.com> Stephen Mulcahy <stephen.mulcahy@hp.com> Steve Baker <sbaker@redhat.com> Steve Baker <steve@stevebaker.org> Steve Kowalik <steven@wedontsleep.org> Steve Martinelli <stevemar@ca.ibm.com> Steven Dake <sdake@redhat.com> Steven Hardy <shardy@redhat.com> Sudarshan Acharya <info@sacharya.com> sukhdev <sukhdev@aristanetworks.com>Sunil Thaha <sthaha@redhat.com> Surya Prabhakar <surya_prabhakar@dell.com> Sushil Kumar <sushil.kumar2@globallogic.com> Takaaki Suzuki <suzuki@midokura.com> Tal Kain <tal.kain@ravellosystems.com> tanlin <lin.tan@intel.com> termie <github@anarkystic.com> Terry Wilson <twilson@redhat.com> Thang Pham <thang.g.pham@gmail.com>Thomas Bechtold <tbechtold@suse.com> Thomas Maddox <thomas.maddox@rackspace.com> Tiago Mello <tmello@linux.vnet.ibm.com> Tim Miller <tim.miller.0@gmail.com> Todd Willey <todd@rubidine.com>Tomoe Sugihara <tomoe@midokura.com>Vadim Rovachev <vrovachev@mirantis.com> Victor Sergeyev <vsergeyev@mirantis.com> Vincent Hou <sbhou@cn.ibm.com>vishvananda <vishvananda@gmail.com> Walter A. Boring IV <walter.boring@hp.com> William Marshall <wcmarsha@us.ibm.com> YAMAMOTO Takashi <yamamoto@valinux.co.jp>Yong Sheng Gong <gongysh@unitedstack.com> Yoshihiro Kaneko <ykaneko0929@gmail.com> Yuiko Takada <takada-yuiko@mxn.nes.nec.co.jp> Yunhong, Jiang <yunhong.jiang@intel.com> Yun Mao <yunmao@gmail.com> Yuriy Zveryanskyy <yzveryanskyy@mirantis.com> Yves-Gwenael Bourhis <yves-gwenael.bourhis@cloudwatt.com> Zang MingJie <zealot0630@gmail.com> zhang-hare <zhuadl@cn.ibm.com> Zhang Hua <zhuadl@cn.ibm.com> zhang-jinnan <ben.os@99cloud.net> Zhenguo Niu <Niu.ZGlinux@gmail.com> zhhuabj <zhhuabj@cn.ibm.com> Zhi Kun Liu <zhikunli@cn.ibm.com> ZhiQiang Fan <aji.zqfan@gmail.com> ZhiQiang Fan <zhiqiang.fan@huawei.com>Ziad Sawalha <github@highbridgellc.com>",Doug hellmann <doug.hellmann@dreamhost.com> Eddie Hebert <edhebert@gmail.com>Eric Windisch <ewindisch@cloudscaling.com>Isaku Yamahata <yamahata@private.email.ne.jp>Joe Gordon <jogo@cloudscaling.com>Sean Dague <sdague@linux.vnet.ibm.com>Yun Mao <yunmao@gmail.com>Zhenguo Niu <niu.zglinux@gmail.com>,380,8
openstack%2Fpython-saharaclient~master~Id05745fbc6623394ef4d1e4fd9e9549fd1ffc3cb,openstack/python-saharaclient,master,Id05745fbc6623394ef4d1e4fd9e9549fd1ffc3cb,Updated from global requirements,MERGED,2014-08-13 23:24:33.000000000,2014-08-14 13:12:30.000000000,2014-08-14 13:12:29.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-08-13 23:24:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/1625d6851efbb3545b5915b4a87ef4948e405534', 'message': 'Updated from global requirements\n\nChange-Id: Id05745fbc6623394ef4d1e4fd9e9549fd1ffc3cb\n'}]",0,114072,1625d6851efbb3545b5915b4a87ef4948e405534,15,3,1,11131,,,0,"Updated from global requirements

Change-Id: Id05745fbc6623394ef4d1e4fd9e9549fd1ffc3cb
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/72/114072/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1625d6851efbb3545b5915b4a87ef4948e405534,openstack/requirements,requests>=1.2.1,requests>=1.1,1,1
openstack%2Fpython-designateclient~master~I01c685e1d51c8b0cee4deaa5b13d10943af24a9a,openstack/python-designateclient,master,I01c685e1d51c8b0cee4deaa5b13d10943af24a9a,Updated from global requirements,MERGED,2014-08-13 23:24:12.000000000,2014-08-14 13:10:52.000000000,2014-08-14 13:10:52.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-08-13 23:24:12.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/edbc00aed7adb9c7daf35398b9c66840f1bb3e7d', 'message': 'Updated from global requirements\n\nChange-Id: I01c685e1d51c8b0cee4deaa5b13d10943af24a9a\n'}]",0,114066,edbc00aed7adb9c7daf35398b9c66840f1bb3e7d,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: I01c685e1d51c8b0cee4deaa5b13d10943af24a9a
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/66/114066/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,edbc00aed7adb9c7daf35398b9c66840f1bb3e7d,openstack/requirements,requests>=1.2.1,requests>=1.1,1,1
openstack%2Fnova~master~I2c71df9adb68c12f4be0648cae98d10e53787ace,openstack/nova,master,I2c71df9adb68c12f4be0648cae98d10e53787ace,VMware: Update DSRecord tuple with more fields,ABANDONED,2014-04-19 00:17:56.000000000,2014-08-14 13:08:42.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 7575}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-19 00:17:56.000000000', 'files': ['nova/tests/virt/vmwareapi/test_vm_util_datastore_selection.py', 'nova/virt/vmwareapi/vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fc28ecd80df0bea3c7919abd5d4c81cadb172e45', 'message': ""VMware: Update DSRecord tuple with more fields\n\nThis patch adds two new fields 'accessible' & 'type' to the DSRecord tuple.\nAccessible defines a state where the Datastore is reachable to the compute host.\nType defines the type of datastore e.g VMFS, VSAN etc.\n\nChange-Id: I2c71df9adb68c12f4be0648cae98d10e53787ace\n""}]",2,88738,fc28ecd80df0bea3c7919abd5d4c81cadb172e45,17,9,1,7575,,,0,"VMware: Update DSRecord tuple with more fields

This patch adds two new fields 'accessible' & 'type' to the DSRecord tuple.
Accessible defines a state where the Datastore is reachable to the compute host.
Type defines the type of datastore e.g VMFS, VSAN etc.

Change-Id: I2c71df9adb68c12f4be0648cae98d10e53787ace
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/88738/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/vmwareapi/test_vm_util_datastore_selection.py', 'nova/virt/vmwareapi/vm_util.py']",2,fc28ecd80df0bea3c7919abd5d4c81cadb172e45,refactor_datastore_usage," 'DSRecord', ['datastore', 'name', 'capacity', 'freespace', 'type', 'accessible']) freespace=propdict['summary.freeSpace'], type=ds_type, accessible=propdict.get('summary.accessible')) best_match = DSRecord(datastore=None, name=None, capacity=None, freespace=None, type=None, accessible=False)"," 'DSRecord', ['datastore', 'name', 'capacity', 'freespace']) freespace=propdict['summary.freeSpace']) best_match = DSRecord(datastore=None, name=None, capacity=None, freespace=0)",25,16
openstack%2Fsahara~master~If13bf9e91cbb8c7ba6cdb4df10c542af001054d2,openstack/sahara,master,If13bf9e91cbb8c7ba6cdb4df10c542af001054d2,Fixed Exception failures caused by i18n,MERGED,2014-08-11 09:02:59.000000000,2014-08-14 13:05:07.000000000,2014-08-14 13:05:06.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-08-11 09:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f78254874fcae339d27b65610143e6f2483fb3bd', 'message': 'Fixed Exception failures caused by i18n\n\nChange-Id: If13bf9e91cbb8c7ba6cdb4df10c542af001054d2\nCloses-bug: #1355065\n'}, {'number': 2, 'created': '2014-08-11 10:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c4d248783ce07632091a27ee7cc6c22c773161a6', 'message': 'Fixed Exception failures caused by i18n\n\nChange-Id: If13bf9e91cbb8c7ba6cdb4df10c542af001054d2\nCloses-bug: #1355065\n'}, {'number': 3, 'created': '2014-08-12 08:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/adf6c135f6ec2a805f9d8b73524aa03fe2a1965b', 'message': 'Fixed Exception failures caused by i18n\n\nChange-Id: If13bf9e91cbb8c7ba6cdb4df10c542af001054d2\nCloses-bug: #1355065\n'}, {'number': 4, 'created': '2014-08-12 13:29:13.000000000', 'files': ['sahara/exceptions.py', 'sahara/tests/integration/tests/base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/ce316d6a7f3dfc5d680899116ce12a17e786695b', 'message': 'Fixed Exception failures caused by i18n\n\nChange-Id: If13bf9e91cbb8c7ba6cdb4df10c542af001054d2\nCloses-bug: #1355065\n'}]",13,113196,ce316d6a7f3dfc5d680899116ce12a17e786695b,45,10,4,12039,,,0,"Fixed Exception failures caused by i18n

Change-Id: If13bf9e91cbb8c7ba6cdb4df10c542af001054d2
Closes-bug: #1355065
",git fetch https://review.opendev.org/openstack/sahara refs/changes/96/113196/3 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/exceptions.py', 'sahara/tests/integration/tests/base.py']",2,f78254874fcae339d27b65610143e6f2483fb3bd,bug/1355065, 'on cluster node: ' + six.text_type(e) '\nTelnet has failed: ' + six.text_type(e) + 'to cluster node: ' + six.text_type(e) print(message + six.text_type(exception)), 'on cluster node: ' + str(e) '\nTelnet has failed: ' + str(e) + 'to cluster node: ' + str(e) print(message + str(exception)),8,7
openstack%2Frequirements~master~Ib047a1e079b68a7d99afe4188355ea51b96a3441,openstack/requirements,master,Ib047a1e079b68a7d99afe4188355ea51b96a3441,Add tooz to requirements,MERGED,2014-05-13 14:15:03.000000000,2014-08-14 12:33:02.000000000,2014-08-14 12:33:02.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2750}, {'_account_id': 3012}, {'_account_id': 6786}, {'_account_id': 8871}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-05-13 14:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/352a103d8b8f8c78c82c73353354c39fa9560542', 'message': 'Add tooz to requirements\n\nTooz is a library for helping to coordinate\ndistributed systems (which openstack is) and useful\nfor doing group membership, locking, and providing\nother capabilities for the various openstack projects.\n\nIt is being worked on by evonance and others and has\njust released a 0.1 version.\n\nChange-Id: Ib047a1e079b68a7d99afe4188355ea51b96a3441\n'}, {'number': 2, 'created': '2014-08-14 09:05:44.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e5cb0b079509111adf6df20dd2a7383f8edaaadf', 'message': 'Add tooz to requirements\n\nTooz is a library for helping to coordinate\ndistributed systems (which openstack is) and useful\nfor doing group membership, locking, and providing\nother capabilities for the various openstack projects.\n\nChange-Id: Ib047a1e079b68a7d99afe4188355ea51b96a3441\n'}]",0,93443,e5cb0b079509111adf6df20dd2a7383f8edaaadf,32,8,2,1297,,,0,"Add tooz to requirements

Tooz is a library for helping to coordinate
distributed systems (which openstack is) and useful
for doing group membership, locking, and providing
other capabilities for the various openstack projects.

Change-Id: Ib047a1e079b68a7d99afe4188355ea51b96a3441
",git fetch https://review.opendev.org/openstack/requirements refs/changes/43/93443/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,352a103d8b8f8c78c82c73353354c39fa9560542,93443,tooz>=0.1 # Apache-2.0,,1,0
openstack%2Fopenstack-doc-tools~master~I85071fe0e96c8787f14f9f9eb0b3c123e22e0c75,openstack/openstack-doc-tools,master,I85071fe0e96c8787f14f9f9eb0b3c123e22e0c75,jsoncheck: use ValueError to pass errors to outside callers,MERGED,2014-08-11 08:38:22.000000000,2014-08-14 12:32:27.000000000,2014-08-14 12:32:27.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-11 08:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/d3b1665cb4cec669a2a59ad8f5626a6f8dabe145', 'message': 'jsoncheck: use ValueError to pass errors to outside callers\n\nWith this patch, errors that need to be passed back to external callers\nare raised in ValueError.\n\nThe message indicating that a file has been successfully reformatted is\nstill directly printed for the CLI interface of jsoncheck. External\ncallers can choose to have that message printed by setting verbose=True.\n\nblueprint modularize-doctest\nChange-Id: I85071fe0e96c8787f14f9f9eb0b3c123e22e0c75\n'}, {'number': 2, 'created': '2014-08-12 08:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/731875985fda4d2bfeebef1dce8da0201b274ba1', 'message': 'jsoncheck: use ValueError to pass errors to outside callers\n\nWith this patch, errors that need to be passed back to external callers\nare raised in ValueError.\n\nThe message indicating that a file has been successfully reformatted is\nstill directly printed for the CLI interface of jsoncheck. External\ncallers can choose to have that message printed by setting verbose=True.\n\nblueprint modularize-doctest\nChange-Id: I85071fe0e96c8787f14f9f9eb0b3c123e22e0c75\n'}, {'number': 3, 'created': '2014-08-13 08:16:31.000000000', 'files': ['os_doc_tools/jsoncheck.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/eeadcf46dd528945485e36ff8c277bb4604ce02f', 'message': 'jsoncheck: use ValueError to pass errors to outside callers\n\nWith this patch, errors that need to be passed back to external callers\nare raised in ValueError.\n\nThe message indicating that a file has been successfully reformatted is\nstill directly printed for the CLI interface of jsoncheck. External\ncallers can choose to have that message printed by setting verbose=True.\n\nblueprint modularize-doctest\nChange-Id: I85071fe0e96c8787f14f9f9eb0b3c123e22e0c75\n'}]",10,113193,eeadcf46dd528945485e36ff8c277bb4604ce02f,23,5,3,11109,,,0,"jsoncheck: use ValueError to pass errors to outside callers

With this patch, errors that need to be passed back to external callers
are raised in ValueError.

The message indicating that a file has been successfully reformatted is
still directly printed for the CLI interface of jsoncheck. External
callers can choose to have that message printed by setting verbose=True.

blueprint modularize-doctest
Change-Id: I85071fe0e96c8787f14f9f9eb0b3c123e22e0c75
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/93/113193/2 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/jsoncheck.py'],1,d3b1665cb4cec669a2a59ad8f5626a6f8dabe145,bp/modularize-doctest,"def check_syntax(path, verbose=False): _process_file(path, None, verbose) def check_formatting(path, verbose=False): _process_file(path, 'check', verbose) def fix_formatting(path, verbose=False): _process_file(path, 'fix', verbose)def _process_file(path, formatting=None, verbose=False): Raises ValueError if JSON syntax is invalid or reformatting needed. raise ValueError(err) else: if formatting in ('check', 'fix'): if (verbose): print(""%s\n%s"" % (path, _indent_note(""Reformatted""))) else: raise ValueError(""Reformatting needed"") elif formatting != None: try: _process_file(path, args.formatting, verbose=True) except ValueError as err: print(""%s\n%s"" % (path, _indent_note(str(err))))","def check_syntax(path): _process_file(path) def check_formatting(path): _process_file(path, formatting='check') def fix_formatting(path): _process_file(path, formatting='fix')def _process_file(path, formatting=None): print(""%s\n%s"" % (path, _indent_note(str(err)))) else: if formatting in (None, 'check', 'fix'): errstr = ""Reformatted"" else: errstr = ""Reformatting needed"" print(""%s\n%s"" % (path, _indent_note(errstr))) else: _process_file(path, args.formatting)",20,14
openstack%2Fnova~master~Iff61763908d7b8ee994b835751577e3c597025de,openstack/nova,master,Iff61763908d7b8ee994b835751577e3c597025de,Add GlusterFS backend to libvirt,ABANDONED,2014-06-03 08:11:51.000000000,2014-08-14 12:17:30.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8163}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-03 08:11:51.000000000', 'files': ['nova/tests/virt/libvirt/test_imagebackend.py', 'nova/tests/virt/libvirt/fake_libvirt_utils.py', 'nova/compute/manager.py', 'nova/virt/libvirt/utils.py', 'nova/virt/libvirt/imagebackend.py', 'nova/virt/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7b017e5abccf81a69adc474fa425df7af1030f37', 'message': 'Add GlusterFS backend to libvirt\n\nThis patch set introduces changes needed to store\nephemeral volumes on GlusterFS.\n\nChange-Id: Iff61763908d7b8ee994b835751577e3c597025de\nBP: glusterfs-image-backend\n'}]",9,97427,7b017e5abccf81a69adc474fa425df7af1030f37,19,12,1,6938,,,0,"Add GlusterFS backend to libvirt

This patch set introduces changes needed to store
ephemeral volumes on GlusterFS.

Change-Id: Iff61763908d7b8ee994b835751577e3c597025de
BP: glusterfs-image-backend
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/97427/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_imagebackend.py', 'nova/compute/manager.py', 'nova/tests/virt/libvirt/fake_libvirt_utils.py', 'nova/virt/libvirt/utils.py', 'nova/virt/libvirt/imagebackend.py', 'nova/virt/images.py']",6,7b017e5abccf81a69adc474fa425df7af1030f37,bp/glusterfs-image-backend,"def qemu_img_info(path, force_info=False): if not force_info: return imageutils.QemuImgInfo()",def qemu_img_info(path): return imageutils.QemuImgInfo(),174,4
openstack%2Ffuel-main~stable%2F5.0~I814ee8caabe02884c9e8558af93de0e2e49b3b93,openstack/fuel-main,stable/5.0,I814ee8caabe02884c9e8558af93de0e2e49b3b93,Change dependency for ceph restart tests to be dependent on test groups,MERGED,2014-08-14 06:47:08.000000000,2014-08-14 12:17:15.000000000,2014-08-14 12:17:15.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-08-14 06:47:08.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_restart.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fd58828f404e4298ed338e8f44c6a326cebd31de', 'message': 'Change dependency for ceph restart tests\nto be dependent on test groups\n\nChange-Id: I814ee8caabe02884c9e8558af93de0e2e49b3b93\nCloses-Bug: #1356453\n'}]",0,114140,fd58828f404e4298ed338e8f44c6a326cebd31de,9,5,1,10136,,,0,"Change dependency for ceph restart tests
to be dependent on test groups

Change-Id: I814ee8caabe02884c9e8558af93de0e2e49b3b93
Closes-Bug: #1356453
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/40/114140/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_restart.py'],1,fd58828f404e4298ed338e8f44c6a326cebd31de,," @test(depends_on_groups=['ceph_multinode_with_cinder'], @test(depends_on_groups=['ceph_ha'],","from fuelweb_test.tests.test_ceph import CephCompactWithCinder from fuelweb_test.tests.test_ceph import CephHA @test(depends_on=[CephCompactWithCinder.ceph_multinode_with_cinder], @test(depends_on=[CephHA.ceph_ha],",2,4
openstack%2Ffuel-main~master~I814ee8caabe02884c9e8558af93de0e2e49b3b93,openstack/fuel-main,master,I814ee8caabe02884c9e8558af93de0e2e49b3b93,Change dependency for ceph restart tests to be dependent on test groups,MERGED,2014-08-13 16:08:56.000000000,2014-08-14 12:16:20.000000000,2014-08-14 12:16:20.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-08-13 16:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/dc160bb7329998b22316c253be267bb7d000305b', 'message': 'Change dependency for ceph restart tests\nto be dependent on test groups\n\nChange-Id: I814ee8caabe02884c9e8558af93de0e2e49b3b93\nCloses-Bug: #1356453\n'}, {'number': 2, 'created': '2014-08-13 16:13:26.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_restart.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/41592e4c014182c99f313959a6514e2d90f04e6e', 'message': 'Change dependency for ceph restart tests\nto be dependent on test groups\n\nChange-Id: I814ee8caabe02884c9e8558af93de0e2e49b3b93\nCloses-Bug: #1356453\n'}]",0,113949,41592e4c014182c99f313959a6514e2d90f04e6e,16,5,2,10136,,,0,"Change dependency for ceph restart tests
to be dependent on test groups

Change-Id: I814ee8caabe02884c9e8558af93de0e2e49b3b93
Closes-Bug: #1356453
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/49/113949/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_restart.py'],1,dc160bb7329998b22316c253be267bb7d000305b,fixDoubleRun," @test(depends_on_groups=['ceph_multinode_with_cinder'], @test(depends_on_groups=['ceph_ha'],","from fuelweb_test.tests.test_ceph import CephCompactWithCinder from fuelweb_test.tests.test_ceph import CephHA @test(depends_on=[CephCompactWithCinder.ceph_multinode_with_cinder], @test(depends_on=[CephHA.ceph_ha],",2,4
openstack%2Fkeystone~master~I80773e30b7d7cd19856b4337cc339fc4a7f549a5,openstack/keystone,master,I80773e30b7d7cd19856b4337cc339fc4a7f549a5,Deleting project with allow_subtree_delete LDAP,ABANDONED,2013-11-01 12:55:01.000000000,2014-08-14 12:08:11.000000000,,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 2166}, {'_account_id': 5046}, {'_account_id': 5575}, {'_account_id': 6482}, {'_account_id': 8533}]","[{'number': 1, 'created': '2013-11-01 12:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9dc05d9e6de4f825bcd5bd274eb802d3afb9db80', 'message': 'Deleting project with allow_subtree_delete LDAP parameter parameter\nbug 1247032\n\nChange-Id: I80773e30b7d7cd19856b4337cc339fc4a7f549a5\n'}, {'number': 2, 'created': '2013-11-01 14:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a17da8ae802a353c338f6b648c4d559a74d81bb7', 'message': 'Deleting project with allow_subtree_delete LDAP\nbug 1247032\n\nChange-Id: I80773e30b7d7cd19856b4337cc339fc4a7f549a5\n'}, {'number': 3, 'created': '2013-11-04 13:34:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4ce2d8d37315296616332bce7f8b1012f2c6a9af', 'message': 'Deleting project with allow_subtree_delete LDAP\nbug 1247032\n\nChange-Id: I80773e30b7d7cd19856b4337cc339fc4a7f549a5\n'}, {'number': 4, 'created': '2013-11-13 09:45:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/eeedc390940482e6cbf092c446ec48dbc730b87b', 'message': 'Deleting project with allow_subtree_delete LDAP\nbug 1247032\n\nChange-Id: I80773e30b7d7cd19856b4337cc339fc4a7f549a5\n'}, {'number': 5, 'created': '2013-11-13 09:54:48.000000000', 'files': ['keystone/assignment/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1a24980f1a37500f30d580ab32ba71e233537c12', 'message': 'Deleting project with allow_subtree_delete LDAP\n\nThe problem occurs in Havana configured with LDAP and\nallow_subtree_delete = True in keystone.conf.\n\nWhen you try to delete an existing project:\n\ncurl -X DELETE --insecure -H ""X-Auth-Token:the_token""\nhttps://localhost:35357/v3/projects/project_id\n\nKeystone log raises an exception like:\n\nWARNING keystone.common.wsgi [-] Could not find project, <built-in\nfunction id>\n\nCloses-Bug: #1247032\n\nChange-Id: I80773e30b7d7cd19856b4337cc339fc4a7f549a5\n'}]",6,54919,1a24980f1a37500f30d580ab32ba71e233537c12,38,7,5,8533,,,0,"Deleting project with allow_subtree_delete LDAP

The problem occurs in Havana configured with LDAP and
allow_subtree_delete = True in keystone.conf.

When you try to delete an existing project:

curl -X DELETE --insecure -H ""X-Auth-Token:the_token""
https://localhost:35357/v3/projects/project_id

Keystone log raises an exception like:

WARNING keystone.common.wsgi [-] Could not find project, <built-in
function id>

Closes-Bug: #1247032

Change-Id: I80773e30b7d7cd19856b4337cc339fc4a7f549a5
",git fetch https://review.opendev.org/openstack/keystone refs/changes/19/54919/2 && git format-patch -1 --stdout FETCH_HEAD,['keystone/assignment/backends/ldap.py'],1,9dc05d9e6de4f825bcd5bd274eb802d3afb9db80,master, self.project.deleteTree(tenant_id), self.project.deleteTree(id),1,1
openstack%2Fkeystone~master~I686e40e42371f6e2cea55110554456a33939799c,openstack/keystone,master,I686e40e42371f6e2cea55110554456a33939799c,Role NoneType object has no attribute setdefault,MERGED,2013-11-04 13:34:18.000000000,2014-08-14 12:07:57.000000000,2013-11-22 20:51:31.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 91}, {'_account_id': 994}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5575}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8533}]","[{'number': 1, 'created': '2013-11-04 13:34:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/df68f1af2979c56fc57f89006cde872caa6b9e53', 'message': 'Role NoneType object has no attribute setdefault\nbug 1247830\n\nChange-Id: I686e40e42371f6e2cea55110554456a33939799c\n'}, {'number': 2, 'created': '2013-11-13 09:45:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ca603f46a7d0d6d2e358b1d768a4d83343f24256', 'message': 'Role NoneType object has no attribute setdefault\n\nHavana Keystone configured with LDAP.\n\nWhen you try to update a role using the API:\n\ncurl -X PATCH --insecure -H ""X-Auth-Token:the_token"" -H\n""Content-type:\napplication/json"" -d \'{""role"": {""name"": ""the new name""}}\'\nhttps://localhost:35357/v3/roles/role_id\n\nKeystone server raises an error:\n\n{""error"": {""message"": ""An unexpected error prevented the server from\nfulfilling your request. \'NoneType\' object has no attribute\n\'setdefault\'"", ""code"": 500, ""title"": ""Internal Server Error""}}\n\nThe role information is updated, but keystone server raises that\nerror.\n\nCloses-Bug: #1247830\n\nChange-Id: I686e40e42371f6e2cea55110554456a33939799c\n'}, {'number': 3, 'created': '2013-11-19 14:30:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/97fbfb93e04e670e5f24ad251842d213f85400aa', 'message': 'Role NoneType object has no attribute setdefault\n\nHavana Keystone configured with LDAP.\n\nWhen you try to update a role using the API:\n\ncurl -X PATCH --insecure -H ""X-Auth-Token:the_token"" -H\n""Content-type:\napplication/json"" -d \'{""role"": {""name"": ""the new name""}}\'\nhttps://localhost:35357/v3/roles/role_id\n\nKeystone server raises an error:\n\n{""error"": {""message"": ""An unexpected error prevented the server from\nfulfilling your request. \'NoneType\' object has no attribute\n\'setdefault\'"", ""code"": 500, ""title"": ""Internal Server Error""}}\n\nThe role information is updated, but keystone server raises that\nerror.\n\nCloses-Bug: #1247830\n\nChange-Id: I686e40e42371f6e2cea55110554456a33939799c\n'}, {'number': 4, 'created': '2013-11-20 19:56:07.000000000', 'files': ['keystone/tests/test_backend.py', 'keystone/assignment/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/24da79bded4385e62265f43977efdcd2237f83d3', 'message': 'Role NoneType object has no attribute setdefault\n\nHavana Keystone configured with LDAP.\n\nWhen you try to update a role using the API:\n\ncurl -X PATCH --insecure -H ""X-Auth-Token:the_token"" -H\n""Content-type:\napplication/json"" -d \'{""role"": {""name"": ""the new name""}}\'\nhttps://localhost:35357/v3/roles/role_id\n\nKeystone server raises an error:\n\n{""error"": {""message"": ""An unexpected error prevented the server from\nfulfilling your request. \'NoneType\' object has no attribute\n\'setdefault\'"", ""code"": 500, ""title"": ""Internal Server Error""}}\n\nThe role information is updated, but keystone server raises that\nerror.\n\nCloses-Bug: #1247830\n\nChange-Id: I686e40e42371f6e2cea55110554456a33939799c\n'}]",7,55141,24da79bded4385e62265f43977efdcd2237f83d3,35,12,4,8533,,,0,"Role NoneType object has no attribute setdefault

Havana Keystone configured with LDAP.

When you try to update a role using the API:

curl -X PATCH --insecure -H ""X-Auth-Token:the_token"" -H
""Content-type:
application/json"" -d '{""role"": {""name"": ""the new name""}}'
https://localhost:35357/v3/roles/role_id

Keystone server raises an error:

{""error"": {""message"": ""An unexpected error prevented the server from
fulfilling your request. 'NoneType' object has no attribute
'setdefault'"", ""code"": 500, ""title"": ""Internal Server Error""}}

The role information is updated, but keystone server raises that
error.

Closes-Bug: #1247830

Change-Id: I686e40e42371f6e2cea55110554456a33939799c
",git fetch https://review.opendev.org/openstack/keystone refs/changes/41/55141/4 && git format-patch -1 --stdout FETCH_HEAD,['keystone/assignment/backends/ldap.py'],1,df68f1af2979c56fc57f89006cde872caa6b9e53,b56227," return self.role.update(role_id, role)"," self.role.update(role_id, role)",1,1
openstack%2Fkeystone~master~Iaf1f90332358cdfbdf50acdc017a87b9ac9c9adb,openstack/keystone,master,Iaf1f90332358cdfbdf50acdc017a87b9ac9c9adb,Delete role not implemented on LDAP backend,ABANDONED,2013-11-08 09:23:49.000000000,2014-08-14 12:07:19.000000000,,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 2166}, {'_account_id': 5046}, {'_account_id': 5575}, {'_account_id': 7244}, {'_account_id': 8533}]","[{'number': 1, 'created': '2013-11-08 09:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fb96742a7e0192acdf73a832cd83d5715ac5b594', 'message': 'Delete role not implemented on LDAP backend\nCloses-Bug: #1248952\n\nChange-Id: Iaf1f90332358cdfbdf50acdc017a87b9ac9c9adb\n'}, {'number': 2, 'created': '2013-11-08 10:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ef15620f568786d2f1c12b4e0cfff709059bbea2', 'message': 'Delete role not implemented on LDAP backend\nCloses-Bug: #1248952\n\nChange-Id: Iaf1f90332358cdfbdf50acdc017a87b9ac9c9adb\n'}, {'number': 3, 'created': '2013-11-08 12:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d8e48e0aaf29971816e9aaefe1c5f01189a49ed7', 'message': 'Delete role not implemented on LDAP backend\nCloses-Bug: #1248952\n\nChange-Id: Iaf1f90332358cdfbdf50acdc017a87b9ac9c9adb\n'}, {'number': 4, 'created': '2013-11-13 12:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4e5ced6bf9ce50670fbcb5b7569eb87fafc8a100', 'message': 'Delete role not implemented on LDAP backend\nCloses-Bug: #1248952\n\nChange-Id: Iaf1f90332358cdfbdf50acdc017a87b9ac9c9adb\n'}, {'number': 5, 'created': '2013-11-13 12:55:58.000000000', 'files': ['keystone/assignment/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/260feb08e593c267384f3f2472b08171f59fc9bb', 'message': 'Delete role not implemented on LDAP backend\n\nDelete role action is not implemented on the assignment LDAP backend in\nHavana release. Otherwise, other role functions are implemented.\n\nWhen you try:\n\ncurl -X DELETE --insecure -H ""X-Auth-Token:the_token""\nhttps://localhost:35357/v3/roles/role_id\n\nKeystone raises warning message: ""The action you have requested has not\nbeen implemented.""\n\nThe problem is ""assignment/ldap"" backend is not implementing\nlist_role_assignments function, so python search up in the hierachy and\narrives to assignment/core.py list_role_assignments fucntion and raises\nthe NotimplementedException.\n\nCloses-Bug: #1248952\n\nChange-Id: Iaf1f90332358cdfbdf50acdc017a87b9ac9c9adb\n'}]",8,55638,260feb08e593c267384f3f2472b08171f59fc9bb,29,7,5,8533,,,0,"Delete role not implemented on LDAP backend

Delete role action is not implemented on the assignment LDAP backend in
Havana release. Otherwise, other role functions are implemented.

When you try:

curl -X DELETE --insecure -H ""X-Auth-Token:the_token""
https://localhost:35357/v3/roles/role_id

Keystone raises warning message: ""The action you have requested has not
been implemented.""

The problem is ""assignment/ldap"" backend is not implementing
list_role_assignments function, so python search up in the hierachy and
arrives to assignment/core.py list_role_assignments fucntion and raises
the NotimplementedException.

Closes-Bug: #1248952

Change-Id: Iaf1f90332358cdfbdf50acdc017a87b9ac9c9adb
",git fetch https://review.opendev.org/openstack/keystone refs/changes/38/55638/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/assignment/backends/ldap.py'],1,fb96742a7e0192acdf73a832cd83d5715ac5b594,master," return self.role.list_role_assignments() def list_role_assignments(): conn = self.get_connection() query = '(objectClass=%s)' % self.object_class replaceArg1 = self.DEFAULT_OU[:2].upper() + self.DEFAULT_OU[2:] + "","" raiz = self.tree_dn.replace(replaceArg1, """") try: objects = conn.search_s(raiz, ldap.SCOPE_SUBTREE, query) except ldap.NO_SUCH_OBJECT: return [] assignment_list = [] prj = ProjectApi(CONF) default_ou_project = prj.DEFAULT_OU[:2].upper() + prj.DEFAULT_OU[2:] for object_dn, attrs in objects: if self.member_attribute in attrs: role_id = self._dn_to_id(object_dn) tenant_id = ldap.dn.str2dn(object_dn)[1][0][1] user_dns = attrs[self.member_attribute] for user_dn in user_dns: user_id = self._dn_to_id(user_dn) if default_ou_project in user_dn: assignment_list.append({'group_id': user_id, 'project_id': tenant_id, 'role_id': role_id}) else: assignment_list.append({'user_id': user_id, 'project_id': tenant_id, 'role_id': role_id}) return assignment_list", raise exception.NotImplemented(),30,1
openstack%2Fkeystone~master~I1fb247b538e6a11085a18f0103cb8508d58e664f,openstack/keystone,master,I1fb247b538e6a11085a18f0103cb8508d58e664f,LDAP Assignment does not support grant v3 API,MERGED,2013-11-18 14:08:31.000000000,2014-08-14 12:06:35.000000000,2014-01-21 08:36:54.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 91}, {'_account_id': 994}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 5575}, {'_account_id': 6486}, {'_account_id': 8533}]","[{'number': 1, 'created': '2013-11-18 14:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cf0813e1b96d8de51b97d45eaba9926f494381b7', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs, for example, role grant CRUD. This patch imeplements Role Grant\nCRUD for V3 Assignment API. Also, several test cases, related to\n1221805 and 1101287 bugs, have been developed.\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\nPartial-Bug: #1221805\n'}, {'number': 2, 'created': '2013-11-19 09:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/da85311a4114fbc406b205c0ddb642de23e2dc5f', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs, for example, role grant CRUD. This patch imeplements Role Grant\nCRUD for V3 Assignment API. Also, several test cases, related to\n1221805 and 1101287 bugs, have been developed.\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\nPartial-Bug: #1221805\n'}, {'number': 3, 'created': '2013-11-19 12:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/40f7f664181ec6a2428652d346b0e3611697403e', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs, for example, role grant CRUD. This patch imeplements Role Grant\nCRUD for V3 Assignment API. Also, several test cases, related to\n1221805 and 1101287 bugs, have been developed.\n\nCloses-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 4, 'created': '2013-11-19 13:54:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1cea5deb4e525710b8560849eacec74225397cfd', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs, for example, role grant CRUD. This patch imeplements Role Grant\nCRUD for V3 Assignment API. Also, several test cases, related to\n1221805 and 1101287 bugs, have been developed.\n\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 5, 'created': '2013-11-21 08:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/51c5d7b1982002407ead43cbab73be1a1b529cf8', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs, for example, role grant CRUD. This patch implements Role Grant\nCRUD for V3 Assignment API.\n\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 6, 'created': '2013-11-21 09:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5cc8e32ad7d9b9eef7845e317d8c413b4f3e44b3', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs, for example, role grant CRUD. This patch implements Role Grant\nCRUD for V3 Assignment API.\n\nCloses-Bug: #1248952\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 7, 'created': '2013-11-22 10:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ce9d54066b045606cc48906de1618626a0dda651', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs. This patch implements Role Grant CRUD for V3 Assignment API:\n\n- Role Grant CRUD\n  + create_grant\n  + get_grant\n  + delete_grant\n  + update_grant\n\n- GET /role_assignments\n  + list_role_assignments\n\nCloses-Bug: #1248952\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 8, 'created': '2013-12-04 09:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/04c39973c6d67eefa74939965fe2c4e1d91e03de', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs. This patch implements Role Grant CRUD for V3 Assignment API:\n\n- Role Grant CRUD\n  + create_grant\n  + get_grant\n  + delete_grant\n  + update_grant\n\n- GET /role_assignments\n  + list_role_assignments\n\nCloses-Bug: #1248952\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 9, 'created': '2013-12-04 12:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8d26fb537d8d929e4eef6b0334cbdbc168d4005f', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs. This patch implements Role Grant CRUD for V3 Assignment API:\n\n- Role Grant CRUD\n  + create_grant\n  + get_grant\n  + delete_grant\n  + update_grant\n\n- GET /role_assignments\n  + list_role_assignments\n\nCloses-Bug: #1248952\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 10, 'created': '2013-12-04 14:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4f654b1f7607d4b441f8ab0db87b489fec42a7b1', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs. This patch implements Role Grant CRUD for V3 Assignment API:\n\n- Role Grant CRUD\n  + create_grant\n  + get_grant\n  + delete_grant\n  + update_grant\n\n- GET /role_assignments\n  + list_role_assignments\n\nCloses-Bug: #1248952\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 11, 'created': '2013-12-04 15:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cfc38c887aa7d46e9e3ac7b12b424934f094b498', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs. This patch implements Role Grant CRUD for V3 Assignment API:\n\n- Role Grant CRUD\n  + create_grant\n  + get_grant\n  + delete_grant\n  + update_grant\n\n- GET /role_assignments\n  + list_role_assignments\n\nCloses-Bug: #1248952\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 12, 'created': '2014-01-13 10:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ccdf447a58d9322b711187fda39d09a9de0ee7b3', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs. This patch implements Role Grant CRUD for V3 Assignment API:\n\n- Role Grant CRUD\n  + create_grant\n  + get_grant\n  + delete_grant\n  + update_grant\n\n- GET /role_assignments\n  + list_role_assignments\n\nCloses-Bug: #1248952\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 13, 'created': '2014-01-16 23:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f421920ee03b1fd8e5df1c960a69617859b4bc07', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs. This patch implements Role Grant CRUD for V3 Assignment API:\n\n- Role Grant CRUD\n  + create_grant\n  + get_grant\n  + delete_grant\n  + update_grant\n\n- GET /role_assignments\n  + list_role_assignments\n\nCloses-Bug: #1248952\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 14, 'created': '2014-01-17 18:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f83474197ddb6e5868746319c3d60ca45354c5db', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs. This patch implements Role Grant CRUD for V3 Assignment API:\n\n- Role Grant CRUD\n  + create_grant\n  + get_grant\n  + delete_grant\n  + update_grant\n\n- GET /role_assignments\n  + list_role_assignments\n\nCloses-Bug: #1248952\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}, {'number': 15, 'created': '2014-01-18 15:19:06.000000000', 'files': ['keystone/tests/test_backend_ldap.py', 'keystone/assignment/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/829a2349312c2c294df22c55c76fb0b0afda200f', 'message': 'LDAP Assignment does not support grant v3 API\n\nThe LDAP assignment backend is missing support for several of the v3\nAPIs. This patch implements Role Grant CRUD for V3 Assignment API:\n\n- Role Grant CRUD\n  + create_grant\n  + get_grant\n  + delete_grant\n  + update_grant\n\n- GET /role_assignments\n  + list_role_assignments\n\nCloses-Bug: #1248952\nPartial-Bug: #1101287\nPartial-Bug: #1221805\n\nChange-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f\n'}]",36,56940,829a2349312c2c294df22c55c76fb0b0afda200f,70,9,15,8533,,,0,"LDAP Assignment does not support grant v3 API

The LDAP assignment backend is missing support for several of the v3
APIs. This patch implements Role Grant CRUD for V3 Assignment API:

- Role Grant CRUD
  + create_grant
  + get_grant
  + delete_grant
  + update_grant

- GET /role_assignments
  + list_role_assignments

Closes-Bug: #1248952
Partial-Bug: #1101287
Partial-Bug: #1221805

Change-Id: I1fb247b538e6a11085a18f0103cb8508d58e664f
",git fetch https://review.opendev.org/openstack/keystone refs/changes/40/56940/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_backend_ldap.py', 'keystone/assignment/backends/ldap.py']",2,cf0813e1b96d8de51b97d45eaba9926f494381b7,bp/revocation-events," def _get_roles_for_just_group_and_project(group_id, tenant_id): self.identity_api.get_group(group_id) self.get_project(tenant_id) group_dn = self.group._id_to_dn(group_id) # NOTE(marcos-fermin-lobo): In tests performed on the memory, for # functions such as ""self.role.get_role_assignments, it returns # the key ""CN"" or ""OU"" in uppercase. # The group_dn var has ""CN"" and ""OU"" in lowercase. # For this reason it has been necessary to use the function # ""upper()"" on IF sentence. return [self.role._dn_to_id(a.role_dn) for a in self.role.get_role_assignments (self.project._id_to_dn(tenant_id)) if a.user_dn.upper() == group_dn.upper()] if group_id is None and user_id is None: if tenant_id is None: return {} if user_id is None: metadata_ref = _get_roles_for_just_group_and_project(group_id, tenant_id) else: metadata_ref = _get_roles_for_just_user_and_project(user_id, tenant_id) def add_role_to_group_and_project(self, group_id, tenant_id, role_id): self.identity_api.get_group(group_id) self.get_project(tenant_id) self.get_role(role_id) group_dn = self.group._id_to_dn(group_id) role_dn = self._subrole_id_to_dn(role_id, tenant_id) self.role.add_user(role_id, role_dn, group_dn, group_id, tenant_id) tenant_dn = self.project._id_to_dn(tenant_id) return GroupRoleAssociation(group_dn=group_dn, role_dn=role_dn, tenant_dn=tenant_dn) def remove_role_from_group_and_project(self, group_id, tenant_id, role_id): role_dn = self._subrole_id_to_dn(role_id, tenant_id) return self.role.delete_user(role_dn, self.group._id_to_dn(group_id), self.project._id_to_dn(tenant_id), group_id, role_id) self.get_role(role_id) if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) if project_id and inherited_to_projects: msg = _('Inherited roles can only be assigned to domains') raise exception.Conflict(type='role grant', details=msg) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} if user_id is None: metadata_ref['roles'] = self.add_role_to_group_and_project( group_id, project_id, role_id) else: metadata_ref['roles'] = self.add_role_to_user_and_project( user_id, project_id, role_id) role_ref = self.get_role(role_id) if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} role_ids = set(self._roles_from_role_dicts( metadata_ref.get('roles', []), inherited_to_projects)) if role_id not in role_ids: raise exception.RoleNotFound(role_id=role_id) return role_ref if user_id: self.identity_api.get_user(user_id) if group_id: self.identity_api.get_group(group_id) self.get_role(role_id) if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} try: if user_id is None: metadata_ref['roles'] = self.remove_role_from_group_and_project( group_id, project_id, role_id) else: metadata_ref['roles'] = self.remove_role_from_user_and_project( user_id, project_id, role_id) except KeyError: raise exception.RoleNotFound(role_id=role_id) if domain_id: self.get_domain(domain_id) if project_id: self.get_project(project_id) try: metadata_ref = self._get_metadata(user_id, project_id, domain_id, group_id) except exception.MetadataNotFound: metadata_ref = {} return [self.get_role(x) for x in self._roles_from_role_dicts(metadata_ref.get('roles', []), inherited_to_projects)]"," if tenant_id is None or user_id is None: metadata_ref = _get_roles_for_just_user_and_project(user_id, tenant_id) raise exception.NotImplemented() raise exception.NotImplemented() raise exception.NotImplemented() raise exception.NotImplemented()",288,12
openstack%2Fnova~master~I4a5413f9d90d2e581044885a440a46bf3d76598f,openstack/nova,master,I4a5413f9d90d2e581044885a440a46bf3d76598f,Change assertTrue(isinstance()) by optimal assert,MERGED,2014-01-17 13:54:53.000000000,2014-08-14 12:06:22.000000000,2014-02-13 11:11:04.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1779}, {'_account_id': 8533}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-17 13:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2749bbb7d9250e246ba164d2fe03321aa9ef8dfe', 'message': 'Change assertTrue(isinstance()) by optimal assert\n\nSome of tests use different method of assertTrue(isinstance(A, B)) or\nassertEqual(type(A), B). The correct way is to use assertIsInstance(A,\nB) provided by testtools.\n\nChange-Id: I4a5413f9d90d2e581044885a440a46bf3d76598f\nCloses-Bug: #1268480\n'}, {'number': 2, 'created': '2014-01-17 14:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f516668743c45909016a8b87ac40e53c4ff81903', 'message': 'Change assertTrue(isinstance()) by optimal assert\n\nSome of tests use different method of assertTrue(isinstance(A, B)) or\nassertEqual(type(A), B). The correct way is to use assertIsInstance(A,\nB) provided by testtools.\n\nChange-Id: I4a5413f9d90d2e581044885a440a46bf3d76598f\nCloses-Bug: #1268480\n'}, {'number': 3, 'created': '2014-01-20 08:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe3ebd9e2fb0371106714e113382b315e029d012', 'message': 'Change assertTrue(isinstance()) by optimal assert\n\nSome of tests use different method of assertTrue(isinstance(A, B)) or\nassertEqual(type(A), B). The correct way is to use assertIsInstance(A,\nB) provided by testtools.\n\nChange-Id: I4a5413f9d90d2e581044885a440a46bf3d76598f\nCloses-Bug: #1268480\n'}, {'number': 4, 'created': '2014-02-07 14:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b84ea658b3467ff660e6a6e87ddffeab1eda63a8', 'message': 'Change assertTrue(isinstance()) by optimal assert\n\nSome of tests use different method of assertTrue(isinstance(A, B)) or\nassertEqual(type(A), B). The correct way is to use assertIsInstance(A,\nB) provided by testtools.\n\nChange-Id: I4a5413f9d90d2e581044885a440a46bf3d76598f\nCloses-Bug: #1268480\n'}, {'number': 5, 'created': '2014-02-11 13:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c71699d4ca32062fbe595d0c07dff6e907d2fe7', 'message': 'Change assertTrue(isinstance()) by optimal assert\n\nSome of tests use different method of assertTrue(isinstance(A, B)) or\nassertEqual(type(A), B). The correct way is to use assertIsInstance(A,\nB) provided by testtools.\n\nChange-Id: I4a5413f9d90d2e581044885a440a46bf3d76598f\nCloses-Bug: #1268480\n'}, {'number': 6, 'created': '2014-02-12 14:10:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/504c25baa4452466cfdbde2a71fc0bace1bb49f0', 'message': 'Change assertTrue(isinstance()) by optimal assert\n\nSome of tests use different method of assertTrue(isinstance(A, B)) or\nassertEqual(type(A), B). The correct way is to use assertIsInstance(A,\nB) provided by testtools.\n\nChange-Id: I4a5413f9d90d2e581044885a440a46bf3d76598f\nCloses-Bug: #1268480\n'}, {'number': 7, 'created': '2014-02-12 15:20:54.000000000', 'files': ['nova/tests/test_availability_zones.py', 'nova/tests/scheduler/test_scheduler_utils.py', 'nova/tests/virt/xenapi/test_vmops.py', 'nova/tests/db/test_migrations.py', 'nova/tests/pci/test_pci_request.py', 'nova/tests/virt/libvirt/test_libvirt.py', 'nova/tests/compute/test_compute_mgr.py', 'nova/hacking/checks.py', 'nova/tests/virt/libvirt/test_libvirt_config.py', 'nova/tests/test_hacking.py', 'nova/tests/virt/baremetal/test_volume_driver.py', 'nova/tests/virt/test_virt_drivers.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/d5e8f1af673dcf9e0bb543dcd9e4910c2bdd2384', 'message': 'Change assertTrue(isinstance()) by optimal assert\n\nSome of tests use different method of assertTrue(isinstance(A, B)) or\nassertEqual(type(A), B). The correct way is to use assertIsInstance(A,\nB) provided by testtools.\n\nChange-Id: I4a5413f9d90d2e581044885a440a46bf3d76598f\nCloses-Bug: #1268480\n'}]",18,67464,d5e8f1af673dcf9e0bb543dcd9e4910c2bdd2384,64,5,7,8533,,,0,"Change assertTrue(isinstance()) by optimal assert

Some of tests use different method of assertTrue(isinstance(A, B)) or
assertEqual(type(A), B). The correct way is to use assertIsInstance(A,
B) provided by testtools.

Change-Id: I4a5413f9d90d2e581044885a440a46bf3d76598f
Closes-Bug: #1268480
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/67464/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_mgr.py', 'nova/tests/test_availability_zones.py', 'nova/tests/scheduler/test_scheduler_utils.py', 'nova/tests/virt/xenapi/test_vmops.py', 'nova/tests/virt/baremetal/test_volume_driver.py', 'nova/tests/db/test_migrations.py', 'nova/tests/pci/test_pci_request.py', 'nova/tests/virt/test_virt_drivers.py']",8,2749bbb7d9250e246ba164d2fe03321aa9ef8dfe,master," self.assertIsInstance(host_status['hypervisor_version'], int)"," self.assertTrue(isinstance(host_status['hypervisor_version'], int))",19,19
openstack%2Fsahara~master~I5cda2b38be6532b13ccc7f31b6ea8ecf38c2247c,openstack/sahara,master,I5cda2b38be6532b13ccc7f31b6ea8ecf38c2247c,Fix scale up cluster on CDH plugin with vanilla image,MERGED,2014-08-07 14:29:09.000000000,2014-08-14 11:55:18.000000000,2014-08-14 11:55:17.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-08-07 14:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/bd953428ac73741d627b083cff7ed8a43f5db6d2', 'message': 'Fix scale up cluster on CDH plugin with vanilla image\n\nChange-Id: I5cda2b38be6532b13ccc7f31b6ea8ecf38c2247c\nCloses-bug: #1354022\n'}, {'number': 2, 'created': '2014-08-08 14:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7b30cae57d26a4748d2d31b7520607de3a360aeb', 'message': 'Fix scale up cluster on CDH plugin with vanilla image\n\nChange-Id: I5cda2b38be6532b13ccc7f31b6ea8ecf38c2247c\nCloses-bug: #1354022\n'}, {'number': 3, 'created': '2014-08-11 13:30:33.000000000', 'files': ['sahara/plugins/cdh/deploy.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/8809ca0ebe083e542878c3cde2f9fdfd0e2fd6b1', 'message': 'Fix scale up cluster on CDH plugin with vanilla image\n\nChange-Id: I5cda2b38be6532b13ccc7f31b6ea8ecf38c2247c\nCloses-bug: #1354022\n'}]",2,112590,8809ca0ebe083e542878c3cde2f9fdfd0e2fd6b1,46,8,3,7710,,,0,"Fix scale up cluster on CDH plugin with vanilla image

Change-Id: I5cda2b38be6532b13ccc7f31b6ea8ecf38c2247c
Closes-bug: #1354022
",git fetch https://review.opendev.org/openstack/sahara refs/changes/90/112590/2 && git format-patch -1 --stdout FETCH_HEAD,['sahara/plugins/cdh/deploy.py'],1,bd953428ac73741d627b083cff7ed8a43f5db6d2,fix-cdh-it, if len(instances) == 0: return if not cmd.is_pre_installed_cdh(instances[0].remote()):, if not cmd.is_pre_installed_cdh(pu.get_manager(cluster).remote()):,4,1
openstack%2Fsahara~master~Iefa529ec63599ec15fea4393811556e276ccc3e8,openstack/sahara,master,Iefa529ec63599ec15fea4393811556e276ccc3e8,Imported Translations from Transifex,MERGED,2014-08-14 06:10:40.000000000,2014-08-14 11:54:52.000000000,2014-08-14 11:54:51.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-08-14 06:10:40.000000000', 'files': ['sahara/locale/en_GB/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara-log-info.pot', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara-log-error.pot', 'sahara/locale/vi_VN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/te_IN/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/ja/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/sahara-log-warning.pot', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/ko_KR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/sahara-log-critical.pot', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-info.po'], 'web_link': 'https://opendev.org/openstack/sahara/commit/5dbe2a34abecda77afbe53361382138b18334e78', 'message': 'Imported Translations from Transifex\n\nChange-Id: Iefa529ec63599ec15fea4393811556e276ccc3e8\n'}]",0,114134,5dbe2a34abecda77afbe53361382138b18334e78,10,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Iefa529ec63599ec15fea4393811556e276ccc3e8
",git fetch https://review.opendev.org/openstack/sahara refs/changes/34/114134/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/locale/en_GB/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara-log-info.pot', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara-log-error.pot', 'sahara/locale/vi_VN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/te_IN/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/ja/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-critical.po', 'sahara/locale/sahara-log-warning.pot', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/ko_KR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/sahara-log-critical.pot', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-info.po']",36,5dbe2a34abecda77afbe53361382138b18334e78,transifex/translations,"""POT-Creation-Date: 2014-08-14 06:10+0000\n""#: sahara/api/middleware/auth_valid.py:54#: sahara/plugins/base.py:106 #, python-format msgid ""Plugin '%(plugin_name)s' loaded %(entry_point)s"" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:69 #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:314 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:304 msgid ""Install of Hadoop stack successful."" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:176 msgid ""Provisioning Cluster via Ambari Server: {0} ..."" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:245 msgid ""Using \""{0}\"" as admin user for scaling of cluster"" msgstr """" #: sahara/plugins/hdp/ambariplugin.py:328 #, python-format msgid ""AmbariPlugin: decommission_nodes called for HDP version = %s"" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:69 msgid ""{0}: Installing rpm's ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:81 msgid ""{0}: Unable to install rpm's from repo, checking for local install."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:91 msgid ""{0}: Installing swift integration ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:99 msgid """" ""{0}: Unable to install swift integration from source, checking for local rpm."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:126 msgid ""{0}: Installing ambari-server ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:130 msgid ""Running Ambari Server setup ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:156 msgid ""Starting Ambari ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:180 msgid ""{0}: Installing Ambari Agent ..."" msgstr """" #: sahara/plugins/hdp/hadoopserver.py:192 msgid ""{0}: Starting Ambari Agent ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:296 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:286 msgid ""Installing required Hadoop services ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:352 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:347 msgid ""Finalizing Ambari cluster state."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:369 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:364 msgid ""Starting Hadoop services ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:370 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:365 #, python-format msgid """" ""Cluster name: %(cluster_name)s, Ambari server address: %(server_address)s"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:391 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:386 msgid ""Successfully started Hadoop cluster '{0}'."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:418 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:413 msgid ""Successfully changed state of Hadoop components "" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:446 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:441 msgid ""Starting Hadoop components while scaling up"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:447 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:442 #, python-format msgid ""Cluster name %(cluster_name)s, Ambari server ip %(ip)s"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:503 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:498 msgid ""Waiting for all Ambari agents to register with server ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:516 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:511 #, python-format msgid ""Registered Hosts: %(current_number)s of %(final_number)s"" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:525 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:520 msgid ""Waiting to connect to ambari server ..."" msgstr """" #: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:607 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:708#: sahara/plugins/hdp/versions/version_2_0_6/services.py:916 msgid ""Creating Hue ini property tree from configuration named {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1016 #, python-format msgid ""Merging configuration properties: %(source)s -> %(destination)s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1060 msgid ""Installing Hue on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1065 msgid ""Setting Hue configuration on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1071 msgid ""Uninstalling Shell, if it is installed on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1080 msgid ""Creating initial Hue user on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1085 msgid ""(Re)starting Hue on {0}"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1176 msgid """" ""Missing HDFS client from Hue node... adding it since it is required for Hue"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/services.py:1182 msgid """" ""Missing HIVE client from Hue node... adding it since it is required for "" ""Beeswax and HCatalog"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:637 msgid ""AmbariClient: decommission post request succeeded!"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:655 #, python-format msgid """" ""AmbariClient: number of hosts waiting for decommisioning to complete = %s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:664 #, python-format msgid ""AmbariClient: decommission status request ok, result = %s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:674 #, python-format msgid ""AmbariClient: node = %(node)s is now in adminState = %(admin_state)s"" msgstr """" #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:682 msgid ""AmbariClient: sleeping for 5 seconds"" msgstr """" #: sahara/plugins/spark/config_helper.py:221 #: sahara/plugins/vanilla/v1_2_1/config_helper.py:227 #, python-format msgid ""Applying config: %s"" msgstr """" #: sahara/plugins/spark/plugin.py:111 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:127 #, python-format msgid ""Hadoop services in cluster %s have been started"" msgstr """" #: sahara/plugins/spark/plugin.py:123 #, python-format msgid ""Spark service at '%s' has been started"" msgstr """" #: sahara/plugins/spark/plugin.py:126 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:157 #, python-format msgid ""Cluster %s has been started successfully"" msgstr """" #: sahara/plugins/spark/plugin.py:379 #, python-format msgid ""Spark master service at '%s' has been restarted"" msgstr """" #: sahara/plugins/vanilla/hadoop2/config.py:300 msgid """" ""Node group awareness is not implemented in YARN yet so "" ""enable_hypervisor_awareness set to False explicitly"" msgstr """" #: sahara/plugins/vanilla/hadoop2/run_scripts.py:147 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:165 #, python-format msgid ""Waiting %s datanodes to start up"" msgstr """" #: sahara/plugins/vanilla/hadoop2/run_scripts.py:152 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:170 #, python-format msgid ""Datanodes on cluster %s has been started"" msgstr """" #: sahara/plugins/vanilla/hadoop2/run_scripts.py:160 #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:178 #, python-format msgid ""Stop waiting datanodes on cluster %s since it has been deleted"" msgstr """" #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:138 #, python-format msgid ""Oozie service at '%s' has been started"" msgstr """" #: sahara/plugins/vanilla/v1_2_1/versionhandler.py:153 #, python-format msgid ""Hive Metastore server at %s has been started"" msgstr """" #: sahara/service/direct_engine.py:281#: sahara/service/direct_engine.py:293#: sahara/service/direct_engine.py:301","""POT-Creation-Date: 2014-08-08 06:10+0000\n""#: sahara/middleware/auth_valid.py:54#: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:592 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:691#: sahara/service/direct_engine.py:280#: sahara/service/direct_engine.py:292#: sahara/service/direct_engine.py:300",5376,147
openstack%2Fsahara~master~I67edfc5009aac754e736d4a68622cebfb95ca8d7,openstack/sahara,master,I67edfc5009aac754e736d4a68622cebfb95ca8d7,Updated from global requirements,MERGED,2014-08-13 23:24:41.000000000,2014-08-14 11:54:45.000000000,2014-08-14 11:54:45.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-08-13 23:24:41.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/e5209c29c49bb3d2525102afe031263b547ae9f8', 'message': 'Updated from global requirements\n\nChange-Id: I67edfc5009aac754e736d4a68622cebfb95ca8d7\n'}]",0,114074,e5209c29c49bb3d2525102afe031263b547ae9f8,10,3,1,11131,,,0,"Updated from global requirements

Change-Id: I67edfc5009aac754e736d4a68622cebfb95ca8d7
",git fetch https://review.opendev.org/openstack/sahara refs/changes/74/114074/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e5209c29c49bb3d2525102afe031263b547ae9f8,openstack/requirements,oslo.utils>=0.1.1 # Apache-2.0requests>=1.2.1,oslo.utils>=0.1.1requests>=1.1,2,2
openstack%2Fheat~master~I0636b0d14f0169117fe96df7a4360b1349f7b12d,openstack/heat,master,I0636b0d14f0169117fe96df7a4360b1349f7b12d,Show correct error messages,MERGED,2014-07-22 07:42:05.000000000,2014-08-14 11:54:25.000000000,2014-08-14 11:54:24.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 6348}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 6610}, {'_account_id': 7193}, {'_account_id': 7230}, {'_account_id': 7239}, {'_account_id': 8289}, {'_account_id': 8537}, {'_account_id': 8871}, {'_account_id': 9165}, {'_account_id': 9542}, {'_account_id': 11599}, {'_account_id': 12259}, {'_account_id': 12321}]","[{'number': 1, 'created': '2014-07-22 07:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d44304b069f805e68b1bf7afa772e9d0dcb5e056', 'message': 'Show correct error messages\n\nWhen a ResourceFailure exception raised in heat/engine/parser.py,\nthe error message is not correctly printed. This patch fixes it.\n\nChange-Id: I0636b0d14f0169117fe96df7a4360b1349f7b12d\n'}, {'number': 2, 'created': '2014-07-25 09:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9645e9ef14aca64323236a819f09a53cd5863b71', 'message': 'Show correct error messages\n\nWhen a ResourceFailure exception raised in heat/engine/stack.py,\nthe error message is not correctly printed. This patch fixes it.\n\nChange-Id: I0636b0d14f0169117fe96df7a4360b1349f7b12d\n'}, {'number': 3, 'created': '2014-07-28 00:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/715a1c0dd1aad738d5b60d31f976794e62f9c827', 'message': 'Show correct error messages\n\nWhen a ResourceFailure exception raised in heat/engine/stack.py,\nthe error message is not correctly printed. This patch fixes it.\n\nChange-Id: I0636b0d14f0169117fe96df7a4360b1349f7b12d\n'}, {'number': 4, 'created': '2014-08-06 06:16:36.000000000', 'files': ['heat/engine/stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b51da48780bf81dc611483a3a99857f8858b3f86', 'message': 'Show correct error messages\n\nWhen a ResourceFailure exception raised in heat/engine/stack.py,\nthe error message is not correctly printed. This patch fixes it.\n\nChange-Id: I0636b0d14f0169117fe96df7a4360b1349f7b12d\n'}]",6,108603,b51da48780bf81dc611483a3a99857f8858b3f86,66,17,4,6348,,,0,"Show correct error messages

When a ResourceFailure exception raised in heat/engine/stack.py,
the error message is not correctly printed. This patch fixes it.

Change-Id: I0636b0d14f0169117fe96df7a4360b1349f7b12d
",git fetch https://review.opendev.org/openstack/heat refs/changes/03/108603/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/parser.py'],1,d44304b069f805e68b1bf7afa772e9d0dcb5e056,show_error_message, LOG.exception(_('create: %s') % ex), LOG.exception(_('create')),1,1
openstack%2Ftempest~master~I671b2262ea5ed5bf7d78149cf88f2894b6bf6508,openstack/tempest,master,I671b2262ea5ed5bf7d78149cf88f2894b6bf6508,Stop leaking identity resources in teardown_all(),MERGED,2014-03-12 11:04:01.000000000,2014-08-14 11:54:17.000000000,2014-08-14 11:54:16.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 7139}, {'_account_id': 7227}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-03-12 11:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d7361f4627d5b18410b0ef0a76c258dd06340721', 'message': 'Stop leaking identity resources\n\nteardown_all() tries to delete all resources. But if an exception\nhappens, the rest of resources are remained and it seems to happen\nfrequently.\nThis commit fixes it.\n\nPartially Implements: blueprint stop-leaking\nChange-Id: I671b2262ea5ed5bf7d78149cf88f2894b6bf6508\n'}, {'number': 2, 'created': '2014-03-12 11:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c78f20e4f684da6e7cffae01b833af3b4c699e02', 'message': 'Stop leaking identity resources\n\nteardown_all() tries to delete all resources. But if an exception\nhappens, the rest of resources are remained and it seems to happen\nfrequently.\nThis commit fixes it.\n\nPartially Implements: blueprint stop-leaking\nChange-Id: I671b2262ea5ed5bf7d78149cf88f2894b6bf6508\n'}, {'number': 3, 'created': '2014-03-12 11:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f15aa0f8ec3c83bc5835d8feaca45292dbb743fa', 'message': 'Stop leaking identity resources\n\nteardown_all() tries to delete all resources. But if an exception\nhappens, the rest of resources are remained and it seems to happen\nfrequently.\nThis commit fixes it.\n\nPartially Implements: blueprint stop-leaking\nChange-Id: I671b2262ea5ed5bf7d78149cf88f2894b6bf6508\n'}, {'number': 4, 'created': '2014-03-14 03:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5152202b5ea97e63b2ca7f4f05261d97e2874ae5', 'message': 'Stop leaking identity resources\n\nteardown_all() tries to delete all resources. But if an exception\nhappens, the rest of resources are remained and it seems to happen\nfrequently.\nThis commit fixes it.\n\nPartially Implements: blueprint stop-leaking\nChange-Id: I671b2262ea5ed5bf7d78149cf88f2894b6bf6508\n'}, {'number': 5, 'created': '2014-03-14 03:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/44b60b8ac94456b23b45a454159821c48d215d0a', 'message': 'Stop leaking identity resources\n\nteardown_all() tries to delete all resources. But if an exception\nhappens, the rest of resources are remained and it seems to happen\nfrequently.\nThis commit fixes it.\n\nPartially Implements: blueprint stop-leaking\nChange-Id: I671b2262ea5ed5bf7d78149cf88f2894b6bf6508\n'}, {'number': 6, 'created': '2014-03-14 23:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ff8571336b29b8882f243cbd6a83120132694bb4', 'message': 'Stop leaking identity resources\n\nteardown_all() tries to delete all resources. But if an exception\nhappens, the rest of resources are remained and it seems to happen\nfrequently.\nThis commit fixes it.\n\nPartially Implements: blueprint stop-leaking\nChange-Id: I671b2262ea5ed5bf7d78149cf88f2894b6bf6508\n'}, {'number': 7, 'created': '2014-03-19 09:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3a8815a0afa0dda1608dfcafa54af35b02f65b9c', 'message': 'Stop leaking identity resources in teardown_all()\n\nteardown_all() tries to delete all resources. But if an exception\nhappens, the rest of resources are remained and it seems to happen\nfrequently.\nThis commit fixes it.\n\nPartially Implements: blueprint stop-leaking\nChange-Id: I671b2262ea5ed5bf7d78149cf88f2894b6bf6508\n'}, {'number': 8, 'created': '2014-08-06 06:31:07.000000000', 'files': ['tempest/api/identity/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/630a3fabd15e93b993ecc57f49c7e7494d9a1d2e', 'message': 'Stop leaking identity resources in teardown_all()\n\nteardown_all() tries to delete all resources. But if an exception\nhappens, the rest of resources are remained and it seems to happen\nfrequently.\nThis commit fixes it.\n\nPartially Implements: blueprint stop-leaking\nChange-Id: I671b2262ea5ed5bf7d78149cf88f2894b6bf6508\n'}]",7,79902,630a3fabd15e93b993ecc57f49c7e7494d9a1d2e,83,13,8,5689,,,0,"Stop leaking identity resources in teardown_all()

teardown_all() tries to delete all resources. But if an exception
happens, the rest of resources are remained and it seems to happen
frequently.
This commit fixes it.

Partially Implements: blueprint stop-leaking
Change-Id: I671b2262ea5ed5bf7d78149cf88f2894b6bf6508
",git fetch https://review.opendev.org/openstack/tempest refs/changes/02/79902/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/identity/base.py'],1,d7361f4627d5b18410b0ef0a76c258dd06340721,bp/stop-leaking," del_pairs =\ [{'func': self.client.delete_user, 'ids': self.users}, {'func': self.client.delete_tenant, 'ids': self.tenants}, {'func': self.client.delete_role, 'ids': self.roles}, {'func': self.client.delete_user, 'ids': self.v3_users}, {'func': self.client.delete_role, 'ids': self.v3_roles}] if self.projects: del_pairs.append({'func': self.client.delete_project, 'ids': self.projects}) for pair in del_pairs: for thing in pair['ids']: try: pair['func'](thing['id']) except Exception: pass", for user in self.users: self.client.delete_user(user['id']) for tenant in self.tenants: self.client.delete_tenant(tenant['id']) for role in self.roles: self.client.delete_role(role['id']) for v3_user in self.v3_users: self.client.delete_user(v3_user['id']) for v3_project in self.projects: self.client.delete_project(v3_project['id']) for v3_role in self.v3_roles: self.client.delete_role(v3_role['id']),16,12
openstack%2Fheat~master~I68446dd652186191d19551032a634aee03f9e637,openstack/heat,master,I68446dd652186191d19551032a634aee03f9e637,Fix typos in comments and help strings,MERGED,2014-08-12 14:19:22.000000000,2014-08-14 11:54:09.000000000,2014-08-14 11:54:08.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 6610}, {'_account_id': 7193}, {'_account_id': 7239}, {'_account_id': 8289}, {'_account_id': 8537}, {'_account_id': 9542}, {'_account_id': 12259}, {'_account_id': 12573}]","[{'number': 1, 'created': '2014-08-12 14:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6e200aa0783ba8989422963e0c9829e277c6a543', 'message': 'Fix typos in comments and help strings\n\nChange-Id: I68446dd652186191d19551032a634aee03f9e637\n'}, {'number': 2, 'created': '2014-08-13 09:55:01.000000000', 'files': ['doc/source/getting_started/on_devstack.rst', 'heat/engine/resources/server.py', 'heat/engine/resources/volume.py', 'bin/heat-keystone-setup', 'heat/tests/test_api_aws.py', 'heat/engine/signal_responder.py', 'heat/engine/service.py', 'doc/source/template_guide/contrib.rst', 'heat/engine/resources/software_config/multi_part.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9ed313a8be01dd0df461c92168e283817e5be5d6', 'message': 'Fix typos in comments and help strings\n\nChange-Id: I68446dd652186191d19551032a634aee03f9e637\n'}]",3,113534,9ed313a8be01dd0df461c92168e283817e5be5d6,20,10,2,12573,,,0,"Fix typos in comments and help strings

Change-Id: I68446dd652186191d19551032a634aee03f9e637
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/113534/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/getting_started/on_devstack.rst', 'heat/engine/resources/server.py', 'heat/engine/resources/volume.py', 'bin/heat-keystone-setup', 'heat/tests/test_api_aws.py', 'heat/tests/test_watch.py', 'heat/engine/signal_responder.py', 'heat/engine/service.py', 'doc/source/template_guide/contrib.rst', 'heat/engine/resources/software_config/multi_part.py']",10,6e200aa0783ba8989422963e0c9829e277c6a543,or," _('Parts belonging to this message.'),"," _('Parts belonging to this messsage.'),",12,12
openstack%2Ftaskflow~master~I69e370a733e44c45c62177008838c259fd9c9a7c,openstack/taskflow,master,I69e370a733e44c45c62177008838c259fd9c9a7c,Allow a jobs posted book to be none by default,MERGED,2014-07-15 01:50:00.000000000,2014-08-14 11:54:05.000000000,2014-08-14 11:54:04.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 6648}, {'_account_id': 8122}, {'_account_id': 8340}, {'_account_id': 9608}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-07-15 01:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dd842c282ce6f65dd79547bbec37304b25776ec8', 'message': 'Allow a jobs posted book to be none by default\n\nNot all users of jobs and jobboards are using the\nassociated book that accompanies a job, instead they\nare fine with just using the name and the details\nthat can be provided for usage in their application.\n\nExample: http://review.openstack.org/#/c/91763/\n\nTo allow the optional usage of books with jobs (which\nis already supported) by default set the book to none\nand allow it to be provided on a as needed basis.\n\nChange-Id: I69e370a733e44c45c62177008838c259fd9c9a7c\n'}, {'number': 2, 'created': '2014-07-15 01:50:44.000000000', 'files': ['taskflow/jobs/jobboard.py', 'taskflow/jobs/backends/impl_zookeeper.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/52b43f3e2f808602848aa9c56dbb8adadcd36a98', 'message': 'Allow a jobs posted book to be none by default\n\nNot all users of jobs and jobboards are using the\nassociated book that accompanies a job, instead they\nare fine with just using the name and the details\nthat can be provided for usage in their application.\n\nExample: http://review.openstack.org/#/c/91763/\n\nTo allow the optional usage of books with jobs (which\nis already supported) by default set the book to none\nand allow it to be provided on a as needed basis.\n\nChange-Id: I69e370a733e44c45c62177008838c259fd9c9a7c\n'}]",0,106915,52b43f3e2f808602848aa9c56dbb8adadcd36a98,26,7,2,1297,,,0,"Allow a jobs posted book to be none by default

Not all users of jobs and jobboards are using the
associated book that accompanies a job, instead they
are fine with just using the name and the details
that can be provided for usage in their application.

Example: http://review.openstack.org/#/c/91763/

To allow the optional usage of books with jobs (which
is already supported) by default set the book to none
and allow it to be provided on a as needed basis.

Change-Id: I69e370a733e44c45c62177008838c259fd9c9a7c
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/15/106915/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/jobs/jobboard.py', 'taskflow/jobs/backends/impl_zookeeper.py']",2,dd842c282ce6f65dd79547bbec37304b25776ec8,," def post(self, name, book=None, details=None):"," def post(self, name, book, details=None):",6,6
openstack%2Fheat~master~I5788fb4618fef0d1c3e39cc98094bb2813e842c5,openstack/heat,master,I5788fb4618fef0d1c3e39cc98094bb2813e842c5,Implement barbican client plugin,MERGED,2014-06-09 04:32:29.000000000,2014-08-14 11:53:48.000000000,2014-08-14 11:53:48.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-09 04:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e3cded3400db30f20bd533cf95814e2b540c31bf', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 2, 'created': '2014-06-09 22:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/411581e8a3317a44011b426282e1cd7c876f13ec', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 3, 'created': '2014-06-10 02:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a1d7832108c986c3e6184a175333b66573bd2eb0', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 4, 'created': '2014-06-10 05:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4fdf504e44ec299ecbc4b1c8ce69599e576681dd', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 5, 'created': '2014-06-16 00:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0e8959c51263c1394247414c5060f1447295d869', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 6, 'created': '2014-06-16 05:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3f7940662f6eb8f21d576cb668dafab365db1ee8', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 7, 'created': '2014-06-17 05:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bb0b181d3082634a3bbec6db1e97e346e497052d', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 8, 'created': '2014-06-17 23:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/07d7879db31ed31aecdb607ad68254ee257914e3', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 9, 'created': '2014-06-18 00:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/867e2ca63200e9315293e4df1e0d1bcc6468c751', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 10, 'created': '2014-06-20 03:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7e08c3242cf4eef69b28cf13c1fb6fcf93c0024a', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 11, 'created': '2014-06-23 00:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d66698a205634c781179b1218e055e8e996fc37e', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 12, 'created': '2014-06-23 22:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/22ad11e9e1e34431f21171c23f07b0153c211f45', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 13, 'created': '2014-06-26 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ff6e86e6f7435e2265d6351a788a52e4fad55efb', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 14, 'created': '2014-06-27 06:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0a51a944eb82fd84c8a7e48e8c870399aae8b4c9', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 15, 'created': '2014-06-30 02:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c9ada931cf9b9ccaa850aad9db83c61132c3b9b8', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 16, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1c6041367274eb6da038450fe29d74c2080ea688', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5'}, {'number': 17, 'created': '2014-06-30 22:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/44492a5454e9795422c941b20ab6e0bd5b5d6a98', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nTestClient has been removed; it had limited practical value since it mocked all\nof the internal calls of the method it was testing.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 18, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/13ceae878b38623ea03f024916787bb46031c56d', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 19, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c4328ca78438c9fe46c196e445fecfc9f05c4002', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 20, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c9b0cc96ab3126acdacd03e23213aa40aef53109', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 21, 'created': '2014-07-06 22:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a44afead4a0aa0cc972a6ebf26fb136ff0f372cf', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 22, 'created': '2014-07-07 01:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/43af6fc815e18df1e14107a808c6a74ecde2af96', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 23, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d2640955312980f5e04675be9a794596f6c6b4cc', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 24, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/54f930f0d8abe144b48ba6c1cb10b9a92cda2217', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 25, 'created': '2014-07-08 21:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0b50dacf064f60b0712ca6e4d170bed0f23465b6', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 26, 'created': '2014-07-17 02:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c9fa5beb02ce9914026717683a9838962bb46ecc', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 27, 'created': '2014-07-18 02:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/97e19d5fec979465cff826c762fb56bc3cf6b786', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 28, 'created': '2014-07-21 17:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cc226cd36dcfcf1bd9946afe75e0c8684b528a5a', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 29, 'created': '2014-07-21 17:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6186c464dafb6fa35d32c9f7e179b12cb06b09a3', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 30, 'created': '2014-07-25 16:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a7700fe6b0e5551c4c36344fc8b159424f0d6c51', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 31, 'created': '2014-07-28 02:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/42d4ea86f308f0b9a3808b564b9dc94a15da0fa0', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 32, 'created': '2014-07-28 22:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/936cb90d931459c5b4a9b091cadf8b5b2740b99c', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 33, 'created': '2014-07-29 20:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ffc4e6e6197c12a51a9fa60ab5bd897119ad6d76', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 34, 'created': '2014-07-29 21:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/10fa561460bf0d424ca5f9c37b9290a3ae9891b6', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 35, 'created': '2014-07-30 21:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ca2f06f135821da87f8f42f616e5417ffb929777', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 36, 'created': '2014-07-30 22:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ed579df40085c04c44f317aa0070550d74d9c050', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 37, 'created': '2014-07-31 02:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b55bfc9eb8381e68fdfcbc7e1ed27ccb1565e26a', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 38, 'created': '2014-07-31 03:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/36b029eb609541623af8806c55833599c531b3a2', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 39, 'created': '2014-07-31 17:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/219c77d5b5f58ecf3b7b6bb3f30c5de40d208865', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 40, 'created': '2014-07-31 22:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9af828a82fd29471ba7c677f1267e4e12ed9ca37', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 41, 'created': '2014-08-07 16:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e8a8f9695b3ab8419acd6fb9dc0a5dd2d91b5aa8', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 42, 'created': '2014-08-11 20:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7e83790c82989c9e0eb0d77860db893ad449349d', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 43, 'created': '2014-08-11 22:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eb1bcbcdaa13103588ab650a2c3375e3c908706b', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}, {'number': 44, 'created': '2014-08-14 01:18:48.000000000', 'files': ['contrib/heat_barbican/README.md', 'contrib/heat_barbican/heat_barbican/tests/test_order.py', 'contrib/heat_barbican/heat_barbican/client.py', 'contrib/heat_barbican/heat_barbican/tests/__init__.py', 'contrib/heat_barbican/heat_barbican/resources/order.py', 'contrib/heat_barbican/setup.py', 'contrib/heat_barbican/heat_barbican/resources/secret.py', 'contrib/heat_barbican/heat_barbican/tests/test_secret.py', 'contrib/heat_barbican/heat_barbican/__init__.py', 'contrib/heat_barbican/setup.cfg', 'contrib/heat_barbican/requirements.txt', 'contrib/heat_barbican/heat_barbican/resources/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/fd191b7e4846c22eac7e9961d1ee637de30cf2b6', 'message': 'Implement barbican client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nBarbican is not an integrated project so the plugin is not registered\nif barbicanclient cannot be imported.\n\nThe code which prevented client errors in _resolve_attribute from being raised\nhas been removed. This will prevent invalid attribute values from being\nmemoized.\n\nThe base package has been renamed to heat_barbican since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package barbican might clash with\nthe actual Barbican project.\n\nChange-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5\n'}]",4,98684,fd191b7e4846c22eac7e9961d1ee637de30cf2b6,162,17,44,4571,,,0,"Implement barbican client plugin

This moves the client creation code out of a Clients subclass into
its own client plugin.

Barbican is not an integrated project so the plugin is not registered
if barbicanclient cannot be imported.

The code which prevented client errors in _resolve_attribute from being raised
has been removed. This will prevent invalid attribute values from being
memoized.

The base package has been renamed to heat_barbican since stevedore
is used for client plugin loading and the base package will be
installed by setuptools, the package barbican might clash with
the actual Barbican project.

Change-Id: I5788fb4618fef0d1c3e39cc98094bb2813e842c5
",git fetch https://review.opendev.org/openstack/heat refs/changes/84/98684/44 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/barbican/barbican/resources/order.py', 'contrib/barbican/barbican/resources/secret.py', 'contrib/barbican/barbican/client.py']",3,e3cded3400db30f20bd533cf95814e2b540c31bf,bp/client-plugins,from heat.engine.clients import client_pluginclass BarbicanClientPlugin(client_plugin.ClientPlugin): def _create(self): keystone_client = self.clients('keystone').client client = barbican_client.Client(auth_plugin=auth_plugin) return client def client_mapping(): if not barbican_client: return {} return {'barbican': BarbicanClientPlugin},"from heat.engine import clients as heat_clientsclass Clients(heat_clients.OpenStackClients): def __init__(self, context): super(Clients, self).__init__(context) self._barbican = None def barbican(self): if self._barbican: return self._barbican keystone_client = self.keystone().client self._barbican = barbican_client.Client(auth_plugin=auth_plugin) return self._barbican",21,22
openstack%2Fheat~master~Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad,openstack/heat,master,Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad,Implement marconi client plugin,MERGED,2014-06-09 04:32:29.000000000,2014-08-14 11:53:45.000000000,2014-08-14 11:53:45.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 12437}]","[{'number': 1, 'created': '2014-06-09 04:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/89424521f63c05856ead8ae433817a47fa2bef59', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 2, 'created': '2014-06-09 22:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/32fe2b02d28a500f2edbf02a46caa12f0f27f2ab', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 3, 'created': '2014-06-10 02:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9b6a0516b69badec26684c0e00cd125abfebdd7b', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 4, 'created': '2014-06-10 05:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c32d7237998e25d1f4bd5e237c35d2a49aec7247', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 5, 'created': '2014-06-16 00:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ca22ddbf20fd4dca3b99a1691884a1661cfd2e9e', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 6, 'created': '2014-06-16 05:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4800b6d3eb2ebc4da4ee9f8df2244796ddc88a77', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 7, 'created': '2014-06-17 05:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/707d4cc69012e278d8cdd02298183b094a3d397d', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 8, 'created': '2014-06-17 23:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ffdad087777a9d5f7c65d2486d3699bbe86c0623', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 9, 'created': '2014-06-18 00:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dd7ba82ec66cdd53adfb4eadf7aa83badc270816', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 10, 'created': '2014-06-20 03:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/608e91dd945b076f7796f6d01a97cc85271d0463', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 11, 'created': '2014-06-23 00:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b00824c42703e1d0570bfb9d0e7b5ff4820f57ce', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 12, 'created': '2014-06-23 22:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/58feff00abf85e24b38471909b3d82749c3ea6c4', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 13, 'created': '2014-06-26 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a55a7861c51e6ac582ab4c5f3b2ded795b6ae6ec', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 14, 'created': '2014-06-27 06:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ac23ae27a4fd52e4c0fc08804705a2a8e68e1c15', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nMarconi is not an integrated project so the plugin is not registered\nif marconiclient cannot be imported.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 15, 'created': '2014-06-30 02:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1167d396f2d7c14b69f7cf14a887116ac7fa0ba1', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 16, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e81e2db0d0cc9d17c9888c655027a9f2cf8ee701', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad'}, {'number': 17, 'created': '2014-06-30 22:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/194f8c956e7709a4c657d7c4ad57def82dfdd9cd', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 18, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b48baf2d499a04968ee67843d4fa369d24cfa7f2', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 19, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e51d2ce629c11d08f61c79fb23652e18dfb71be', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 20, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d2c5243b609867996fc98a701628b91c1a4236e6', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 21, 'created': '2014-07-06 22:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/21b2615711986fce4bcb95a4c12730f262cba3ec', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 22, 'created': '2014-07-07 01:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2f7b2ac9749e012eb35e2d487a6c9996d778c6e1', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 23, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ca9b2c3dd6f5eee36b0c58c7517a03e6225c244d', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 24, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c209b5af006acf4f2bd58ad7c1f16866c48b3238', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 25, 'created': '2014-07-08 21:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ae549588ddc1581fca7fad3f5411e88a9dbed73a', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 26, 'created': '2014-07-17 02:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/22af85358d1f8ba881bbba8f88fc2d247fc3130d', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 27, 'created': '2014-07-18 02:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3d212036c7bd2dfdbbdb6fb094f6faec61d505dc', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 28, 'created': '2014-07-21 17:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fd43cda306bb7b92e767d11a7b1a205e41d1bacd', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 29, 'created': '2014-07-21 17:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5a05416263e413a09a2d90f4c7d9e655ea433746', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 30, 'created': '2014-07-24 23:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fbe382d58596a0453a04d26ed33876642e9cf57d', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 31, 'created': '2014-07-28 02:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1597fb83bce3c674181e9a45207601f8336bbfea', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 32, 'created': '2014-07-28 22:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8f7998dee9ef3bfdf95b2a8f852bdeea65b76ca1', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 33, 'created': '2014-07-29 20:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2a6ccca5c9139cd146b02171fe51661685ed6221', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 34, 'created': '2014-07-29 21:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9c6b7bce36d1b24f2e1f8b6033dacdf500f97bac', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 35, 'created': '2014-07-30 21:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/997a04adb605b2d3ce2ed60b35d37025c3404c08', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 36, 'created': '2014-07-30 22:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/db6795b141f0d7539da8602921a3be1efd784c31', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 37, 'created': '2014-07-31 02:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/70321c1406e89709054b2ca586eeb1edfb69e160', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 38, 'created': '2014-07-31 03:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a669d5bc75f25e7e638799dbae46c14e5ad459e2', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 39, 'created': '2014-07-31 17:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/71043a7a7c05d4280157bed5dab9b3e1b1ac5833', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 40, 'created': '2014-07-31 22:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b208ed74557f3f552c0b914c3d46f0a4c5fd04fa', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 41, 'created': '2014-08-07 16:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9f4e910d9a9fcf9326dc434bb6a63808f39a3706', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 42, 'created': '2014-08-11 20:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6d0f9128dccee3b4d45fbb909261156e2e984254', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 43, 'created': '2014-08-11 22:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2f34b57d847601276a6664d3450a5cf94a6ce4fe', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}, {'number': 44, 'created': '2014-08-14 01:18:48.000000000', 'files': ['contrib/heat_marconi/heat_marconi/__init__.py', 'contrib/heat_marconi/README.md', 'contrib/heat_marconi/heat_marconi/resources/__init__.py', 'contrib/heat_marconi/setup.cfg', 'contrib/heat_marconi/heat_marconi/client.py', 'contrib/heat_marconi/requirements.txt', 'contrib/heat_marconi/heat_marconi/resources/queue.py', 'contrib/heat_marconi/heat_marconi/tests/__init__.py', 'contrib/heat_marconi/heat_marconi/tests/test_queue.py', 'contrib/heat_marconi/setup.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/23893088f1220bc73cfcc4f6844d9bab189a308b', 'message': 'Implement marconi client plugin\n\nThis moves the client creation code out of a Clients subclass into\nits own client plugin.\n\nThe base package has been renamed to heat_marconi since stevedore\nis used for client plugin loading and the base package will be\ninstalled by setuptools, the package marconi might clash with\nthe actual marconi project.\n\nChange-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad\n'}]",5,98683,23893088f1220bc73cfcc4f6844d9bab189a308b,166,19,44,4571,,,0,"Implement marconi client plugin

This moves the client creation code out of a Clients subclass into
its own client plugin.

The base package has been renamed to heat_marconi since stevedore
is used for client plugin loading and the base package will be
installed by setuptools, the package marconi might clash with
the actual marconi project.

Change-Id: Ie824d961fcfa9dafd72cc40ccf207d1c1e0501ad
",git fetch https://review.opendev.org/openstack/heat refs/changes/83/98683/10 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/marconi/marconi/resources/queue.py', 'contrib/marconi/marconi/client.py']",2,89424521f63c05856ead8ae433817a47fa2bef59,bp/client-plugins,"from heat.engine.clients import client_plugin class MarconiClientPlugin(client_plugin.ClientPlugin): def _create(self): 'os_service_type': 'queuing', endpoint = self.url_for(service_type='queuing') client = marconiclient.Client(url=endpoint, conf=conf) return client def client_mapping(): if not marconiclient: return {} return {'marconi': MarconiClientPlugin}","""""""Client Library for Marconi Resources."""""" from heat.engine import clients class Clients(clients.OpenStackClients): """"""Convenience class to create and cache client instances."""""" def __init__(self, context): super(Clients, self).__init__(context) self._marconi = None def marconi(self, service_type=""queuing""): if self._marconi: return self._marconi 'os_service_type': service_type, endpoint = self.url_for(service_type=service_type) self._marconi = marconiclient.Client(url=endpoint, conf=conf) return self._marconi",15,19
openstack%2Fheat~master~I312de40064cc00896dba1835117ff67003e57938,openstack/heat,master,I312de40064cc00896dba1835117ff67003e57938,Port rackspace clients to client plugins,MERGED,2014-06-09 04:32:29.000000000,2014-08-14 11:53:42.000000000,2014-08-14 11:53:41.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-06-09 04:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fb1fb706e9606d45bb466a0bc189f9916938768d', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 2, 'created': '2014-06-09 22:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/30ac8238d0eafb6ab7581875951ee4d842a7157e', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 3, 'created': '2014-06-10 02:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1695890b69230152d606341eff317eb510a70766', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 4, 'created': '2014-06-10 05:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/513d365c5b273db06ccf77787fb8a0219841eea3', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 5, 'created': '2014-06-16 00:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d15ee0cd39464b08c75699f450238369a4e08020', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 6, 'created': '2014-06-16 05:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/08d3f6bec9ec7e09657eada7c134d0caa33461fc', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 7, 'created': '2014-06-17 05:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6373f48f82bba32b0eb18c60184bdcc452820632', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 8, 'created': '2014-06-17 23:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f16db1165ab2c6c3bc3073904e1d8900d832fe24', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 9, 'created': '2014-06-18 00:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4a3afd6416dc69c6e2b001da25e698c3268698d4', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 10, 'created': '2014-06-20 03:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0195e0db4afa58059858087933b86d9caf0e4356', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 11, 'created': '2014-06-23 00:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/542c3906db663590c1d9d3b6ad9d2567fe71b310', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 12, 'created': '2014-06-23 22:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/440b52fbf970d1fe74df3ae573ad9c9c4ad4fba0', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 13, 'created': '2014-06-26 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e684adc4e8d2f6199d17f8f47f5b7846ab7ed01d', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 14, 'created': '2014-06-27 06:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d749b28193dce4d1f365a30ad1b4821f0971407e', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nas long as the rackspace package is found in the configured plugin_dirs.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 15, 'created': '2014-06-30 02:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/207e9494ed281c6a9b045c1904a4979e69abf2d7', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 16, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/276a95273d4b385c3f369b3eac3dcced94b70872', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 17, 'created': '2014-06-30 22:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/352abf85f4d87d4bb3a876b36956aa6cfbe0c39c', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 18, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7d3457df3c1d966d32816810c68a70be95e2d068', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 19, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/846dd3984ee892293865e9514b838cf6bdd7f842', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 20, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d30fc8abdd7a65cf45e37dc1defc178442e89619', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 21, 'created': '2014-07-06 22:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e30e6e9c86bcf385f0133bf0319fda7f164da1c4', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 22, 'created': '2014-07-07 01:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8163a32ac4ca212bb93a26886b68766bfd9aeb7c', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 23, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dc3d633be7265e227266f966d509d143e97dcc62', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 24, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2e9b800a143e59086acbf4f06ad24eb16b34cc71', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 25, 'created': '2014-07-08 21:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3ea879808540c296347c77dda51e16e231a98cdb', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 26, 'created': '2014-07-17 02:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a178f1f58ca867e960e2b439204b041659e2114b', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 27, 'created': '2014-07-18 02:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/904d67d621612bac74998a01646bb1b1cb102a9e', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 28, 'created': '2014-07-21 17:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/55f1f584a089315d94c10523c7397cda0f14e383', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 29, 'created': '2014-07-21 17:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c6b8d5f5b1d5607de2414022dbfad47a396cbbe6', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 30, 'created': '2014-07-24 23:15:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6c086d733a8c9b16940e6a59186ad1932955f1b3', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 31, 'created': '2014-07-28 02:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e5e5cfb897b6b2285dbcd8cb1cc4a35475c9ce98', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 32, 'created': '2014-07-28 21:58:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/476ed605106e3b8cb367d60128ad79bbe7f6252c', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 33, 'created': '2014-07-29 20:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/38b051f4627307cd974a63bd79b69421acfeb7ee', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 34, 'created': '2014-07-29 21:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b037f952988da5de56c81cbcfaa98ac526dc2e95', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 35, 'created': '2014-07-30 21:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/919f6e6640da022c02313818b144d026d0f04866', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 36, 'created': '2014-07-30 21:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e87ddb1ee746234829a0c64337bce333271bfb6b', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 37, 'created': '2014-07-31 02:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ad7c1476e240513956e9ca81333c45742b6e5bbf', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 38, 'created': '2014-07-31 03:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/498f75c56601c290fb60aa7d0465d730054a381c', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 39, 'created': '2014-07-31 17:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bf740aeae215b5ec82e995e3a42fcbe31d0d5026', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 40, 'created': '2014-07-31 22:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a8a440e89b316c0efca5b9ab86ec2e5b4d608f76', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 41, 'created': '2014-08-07 16:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4d6905ff4a5f8045d232e4061979f736c3e868fb', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 42, 'created': '2014-08-11 19:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/013cf87519a6db673aebe4ce440b6d283e413663', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 43, 'created': '2014-08-11 22:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/09daf20749100267e2c18de363b1e8d47335fb18', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}, {'number': 44, 'created': '2014-08-14 01:18:48.000000000', 'files': ['contrib/rackspace/rackspace/tests/test_cloud_loadbalancer.py', 'contrib/rackspace/rackspace/tests/test_rackspace_clients.py', 'contrib/rackspace/rackspace/resources/cloud_loadbalancer.py', 'contrib/rackspace/rackspace/tests/test_cloudnetworks.py', 'contrib/rackspace/setup.cfg', 'contrib/rackspace/rackspace/tests/test_auto_scale.py', 'contrib/rackspace/rackspace/resources/cloudnetworks.py', 'contrib/rackspace/rackspace/resources/auto_scale.py', 'contrib/rackspace/rackspace/tests/test_rackspace_cloud_server.py', 'contrib/rackspace/rackspace/clients.py', 'contrib/rackspace/rackspace/resources/cloud_dns.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/1a44187fdf7c2c18fbabb96ca0c49983e303ad89', 'message': 'Port rackspace clients to client plugins\n\nThis change converts the rackspace client code to be contributed\nvia client plugins. This is the last change required for all in-tree\nclients to be contributed via plugins.\n\nA RackspaceTest base class which adds the rackspace directory\nto the client plugins path which ensures any rackspace variants\nare loaded. Plugin loading precedence is used to ensure rackspace\nversions will override core plugins with the same name.\n\nThe nova plugin will fallback to returning the core nova client\nso that CloudServersTest will run even when pyrax is not installed.\n\nThe cloud_backed configuration option will no longer have any effect\non whether rackspace clients will be loaded. Instead they will be loaded\nby stevedore via the setup.cfg heat.clients entry point.\n\nChange-Id: I312de40064cc00896dba1835117ff67003e57938\n'}]",13,98687,1a44187fdf7c2c18fbabb96ca0c49983e303ad89,160,17,44,4571,,,0,"Port rackspace clients to client plugins

This change converts the rackspace client code to be contributed
via client plugins. This is the last change required for all in-tree
clients to be contributed via plugins.

A RackspaceTest base class which adds the rackspace directory
to the client plugins path which ensures any rackspace variants
are loaded. Plugin loading precedence is used to ensure rackspace
versions will override core plugins with the same name.

The nova plugin will fallback to returning the core nova client
so that CloudServersTest will run even when pyrax is not installed.

The cloud_backed configuration option will no longer have any effect
on whether rackspace clients will be loaded. Instead they will be loaded
by stevedore via the setup.cfg heat.clients entry point.

Change-Id: I312de40064cc00896dba1835117ff67003e57938
",git fetch https://review.opendev.org/openstack/heat refs/changes/87/98687/5 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/rackspace/rackspace/tests/test_cloud_loadbalancer.py', 'contrib/rackspace/rackspace/tests/test_cloudnetworks.py', 'contrib/rackspace/rackspace/tests/test_auto_scale.py', 'contrib/rackspace/rackspace/resources/auto_scale.py', 'contrib/rackspace/rackspace/tests/test_rackspace_dns.py', 'contrib/rackspace/rackspace/clients.py', 'contrib/rackspace/rackspace/resources/cloud_dns.py', 'contrib/rackspace/rackspace/tests/test_rackspace_clients.py', 'contrib/rackspace/rackspace/resources/cloud_loadbalancer.py', 'contrib/rackspace/rackspace/resources/cloudnetworks.py', 'contrib/rackspace/rackspace/tests/test_rackspace.py', 'contrib/rackspace/rackspace/tests/test_rackspace_cloud_server.py']",12,fb1fb706e9606d45bb466a0bc189f9916938768d,bp/client-plugins,from .test_rackspace import RackspaceTest # noqaclass CloudServersTest(RackspaceTest):,from heat.tests.common import HeatTestCaseclass CloudServersTest(HeatTestCase):,208,95
openstack%2Ffuel-main~master~I3f729156b967e6bbcff7f1f733a671801477a2dd,openstack/fuel-main,master,I3f729156b967e6bbcff7f1f733a671801477a2dd,Remove premature authentication tries from HTTPClient class,MERGED,2014-08-13 15:16:32.000000000,2014-08-14 11:39:29.000000000,2014-08-14 11:39:28.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-08-13 15:16:32.000000000', 'files': ['fuelweb_test/helpers/http.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b65ef8093f95cc02cf63218e2a6ebb061d49e903', 'message': 'Remove premature authentication tries from HTTPClient class\n\nHTTPClient class is created in the very beginning of CI tests,\nwhen no environment exists. This is caused delays for about 5\nminutes while keystone is trying to authenticate at start of\nevery system test.\n\nChange-Id: I3f729156b967e6bbcff7f1f733a671801477a2dd\nCloses-Bug: #1356418\n'}]",0,113926,b65ef8093f95cc02cf63218e2a6ebb061d49e903,12,7,1,11969,,,0,"Remove premature authentication tries from HTTPClient class

HTTPClient class is created in the very beginning of CI tests,
when no environment exists. This is caused delays for about 5
minutes while keystone is trying to authenticate at start of
every system test.

Change-Id: I3f729156b967e6bbcff7f1f733a671801477a2dd
Closes-Bug: #1356418
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/26/113926/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/http.py'],1,b65ef8093f95cc02cf63218e2a6ebb061d49e903,bug/1356418,, self.authenticate(),0,1
openstack%2Fopenstacksdk~master~I69f81fac0fd69597d42424c105a9a55d388ef211,openstack/openstacksdk,master,I69f81fac0fd69597d42424c105a9a55d388ef211,compute/v2 image resource,MERGED,2014-08-08 21:36:28.000000000,2014-08-14 11:34:50.000000000,2014-08-14 11:34:50.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-08 21:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b908a4fe2f469d1fc161c3d3f981beb2255adcb9', 'message': 'compute/v2 image resource\n\nChange-Id: I69f81fac0fd69597d42424c105a9a55d388ef211\n'}, {'number': 2, 'created': '2014-08-11 18:19:48.000000000', 'files': ['openstack/tests/compute/v2/test_image.py', 'openstack/compute/v2/image.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9bdf3fbfae491f19ecc3f2083c49c902bad4dfe8', 'message': 'compute/v2 image resource\n\nChange-Id: I69f81fac0fd69597d42424c105a9a55d388ef211\n'}]",1,113030,9bdf3fbfae491f19ecc3f2083c49c902bad4dfe8,14,3,2,8736,,,0,"compute/v2 image resource

Change-Id: I69f81fac0fd69597d42424c105a9a55d388ef211
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/30/113030/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/compute/v2/test_image.py', 'openstack/compute/v2/image.py']",2,b908a4fe2f469d1fc161c3d3f981beb2255adcb9,image,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack.compute import compute_service from openstack import resource class Image(resource.Resource): resource_key = 'image' resources_key = 'images' base_path = '/images' service = compute_service.ComputeService() # capabilities allow_create = True allow_retrieve = True allow_update = True allow_delete = True allow_list = True # Properties created = resource.prop('created') links = resource.prop('links') metadata = resource.prop('metadata', type=dict) minDisk = resource.prop('minDisk', type=int) minRam = resource.prop('minRam', type=int) name = resource.prop('name') progress = resource.prop('progress', type=int) status = resource.prop('status') updated = resource.prop('updated') ",,96,0
openstack%2Fopenstacksdk~master~I53164b8e0811c8fbb3781f2070a1a2126fb47e50,openstack/openstacksdk,master,I53164b8e0811c8fbb3781f2070a1a2126fb47e50,network/v2 security_group_rule resource,MERGED,2014-07-31 19:23:23.000000000,2014-08-14 11:32:46.000000000,2014-08-14 11:32:45.000000000,"[{'_account_id': 3}, {'_account_id': 7191}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-07-31 19:23:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/20377800e365267ae8f06edb7d81e8273dd6e659', 'message': 'network/v2 security_group_rule resource\n\nChange-Id: I53164b8e0811c8fbb3781f2070a1a2126fb47e50\n'}, {'number': 2, 'created': '2014-08-01 16:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4ccdad752166eff3b749e46f98eb1e60b1265f31', 'message': 'network/v2 security_group_rule resource\n\nChange-Id: I53164b8e0811c8fbb3781f2070a1a2126fb47e50\n'}, {'number': 3, 'created': '2014-08-05 11:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ed2c3b0b9bd0e8e6b5647efaee80f24db299656b', 'message': 'network/v2 security_group_rule resource\n\nChange-Id: I53164b8e0811c8fbb3781f2070a1a2126fb47e50\n'}, {'number': 4, 'created': '2014-08-05 11:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/241f073088f03625235b537b4d7467bf15655fd8', 'message': 'network/v2 security_group_rule resource\n\nChange-Id: I53164b8e0811c8fbb3781f2070a1a2126fb47e50\n'}, {'number': 5, 'created': '2014-08-07 18:08:27.000000000', 'files': ['openstack/network/v2/security_group_rule.py', 'openstack/tests/network/v2/test_security_group_rule.py', 'openstack/network/v2/security_group.py', 'openstack/tests/network/v2/test_security_group.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ab70cc4c43ce8399654f312be0bd9c976f532b24', 'message': 'network/v2 security_group_rule resource\n\nChange-Id: I53164b8e0811c8fbb3781f2070a1a2126fb47e50\n'}]",4,111047,ab70cc4c43ce8399654f312be0bd9c976f532b24,28,4,5,8736,,,0,"network/v2 security_group_rule resource

Change-Id: I53164b8e0811c8fbb3781f2070a1a2126fb47e50
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/47/111047/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/network/v2/security_group_rule.py', 'openstack/tests/network/v2/test_security_group_rule.py']",2,20377800e365267ae8f06edb7d81e8273dd6e659,security_group_rule,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testtools from openstack.network.v2 import security_group_rule IDENTIFIER = 'IDENTIFIER' EXAMPLE = { 'direction': '1', 'ethertype': '2', 'id': IDENTIFIER, 'port_range_max': '4', 'port_range_min': '5', 'tenant_id': '6', 'protocol': '7', 'remote_group_id': '8', 'remote_ip_prefix': '9', 'security_group_id': '10', } class TestSecurityGroupRule(testtools.TestCase): def test_basic(self): sot = security_group_rule.SecurityGroupRule() self.assertEqual('security_group_rule', sot.resource_key) self.assertEqual('security_group_rules', sot.resources_key) self.assertEqual('/v2.0/security-group-rules', sot.base_path) self.assertEqual('network', sot.service.service_type) self.assertTrue(sot.allow_create) self.assertTrue(sot.allow_retrieve) self.assertTrue(sot.allow_update) self.assertTrue(sot.allow_delete) self.assertTrue(sot.allow_list) def test_make_it(self): sot = security_group_rule.SecurityGroupRule(EXAMPLE) self.assertEqual(EXAMPLE['direction'], sot.direction) self.assertEqual(EXAMPLE['ethertype'], sot.ethertype) self.assertEqual(EXAMPLE['id'], sot.id) self.assertEqual(EXAMPLE['port_range_max'], sot.port_range_max) self.assertEqual(EXAMPLE['port_range_min'], sot.port_range_min) self.assertEqual(EXAMPLE['tenant_id'], sot.project_id) self.assertEqual(EXAMPLE['protocol'], sot.protocol) self.assertEqual(EXAMPLE['remote_group_id'], sot.remote_group_id) self.assertEqual(EXAMPLE['remote_ip_prefix'], sot.remote_ip_prefix) self.assertEqual(EXAMPLE['security_group_id'], sot.security_group_id) ",,96,0
openstack%2Fheat~master~I1c91aee20f72dc2a5a049e67de1d6d7cbabda241,openstack/heat,master,I1c91aee20f72dc2a5a049e67de1d6d7cbabda241,Use setuptools to install contrib plugins,MERGED,2014-06-30 02:30:31.000000000,2014-08-14 11:31:02.000000000,2014-08-14 11:31:01.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6610}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7404}]","[{'number': 1, 'created': '2014-06-30 02:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/524a3d256c96837ebea71d20c0fd2fe8fd74a838', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 2, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/86f107277699115375e3c407e020eb7db5ffd6ed', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 3, 'created': '2014-06-30 22:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/166b5b71dcc5fe893152eb571785e1b5e07d91e1', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 4, 'created': '2014-07-01 07:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3f4d5502dc7ae64d8189a67c02133ed9c478c739', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies an entry_points\nentry to install the contrib plugin source into the ""heat.resources""\nnamespace.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nCo-Authored-by: Steven Baker <sbaker@redhat.com>\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 5, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7c29e3845317de0a3459230b7392cc87a4f3f2da', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 6, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/593fd768530ce1cea6e10f8a5a38f0c79becd538', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 7, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cd6c8fb7652d96603adaf1ddd1cbc21f825d7d78', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 8, 'created': '2014-07-06 22:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9938b40443e00be3fe9427978ae881d1bc5cdc56', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 9, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e7cf1a55bbbbb08d2cdcdfca10c8d1ae41d5e273', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 10, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eb626a7b9f1db0d0b932a8bc7235f579cb8fbb31', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 11, 'created': '2014-07-08 21:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2b745752f72d59b43745bbdedfec64dac047ba1f', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 12, 'created': '2014-07-17 02:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d342cc2ee20fb1a1b0c95665e7ac6f6729fd8f83', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 13, 'created': '2014-07-18 02:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9d19d6f69d85b97d3d6e26359934f5be24483844', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 14, 'created': '2014-07-21 17:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9320544d0b0564af86f5068b0162b0fb4a302dc9', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 15, 'created': '2014-07-21 17:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4b177112d60422e7ac7a9391a3e52093603cef2f', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 16, 'created': '2014-07-24 23:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e92b132b77ad5cb4123f8dce8a7afbbd78bd8355', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 17, 'created': '2014-07-28 02:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ca12fcee03bc83a707d386e29c9c6f01f283da4a', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 18, 'created': '2014-07-28 21:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/37b0e0eb43d611de231e3087edb07c4be8c49551', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 19, 'created': '2014-07-28 21:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2939fc41fe5ecfe9151a1d444917ee650a594e52', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 20, 'created': '2014-07-29 20:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8816abc1c4422c0fda93a769b688369e8213fd35', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 21, 'created': '2014-07-29 21:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/829a365e515b40d7ac38cef0d2d1ed6350078b2b', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 22, 'created': '2014-07-30 21:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7a6abfe706dc871f665671f5a7c3b4051af58600', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 23, 'created': '2014-07-31 17:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a3fa2cae5d2b576ca97f46a7d0f709912130e3c0', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 24, 'created': '2014-07-31 22:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c13c91cf7a697e24531bc577aa6d213fa466d2cc', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 25, 'created': '2014-08-07 16:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/639b3dd4455b3fdf10fbc9ee4179a77b12a824a1', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 26, 'created': '2014-08-11 17:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4331c8a5ec996c8fa2e532823ebae72512136794', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 27, 'created': '2014-08-11 22:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fea5875ef065607ce0247de4fa4732005474c772', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}, {'number': 28, 'created': '2014-08-14 01:18:48.000000000', 'files': ['contrib/docker/docker/README.md', 'contrib/marconi/setup.cfg', 'contrib/extraroute/setup.cfg', 'contrib/barbican/setup.cfg', '.gitignore', 'contrib/heat_keystoneclient_v2/setup.cfg', 'contrib/marconi/setup.py', 'contrib/docker/setup.cfg', 'contrib/heat_keystoneclient_v2/README.md', 'contrib/barbican/README.md', 'contrib/docker/setup.py', 'doc/source/conf.py', 'contrib/barbican/setup.py', 'contrib/marconi/README.md', 'contrib/rackspace/README.md', 'contrib/nova_flavor/setup.py', 'contrib/extraroute/setup.py', 'contrib/nova_flavor/setup.cfg', 'contrib/nova_flavor/README.md', 'contrib/rackspace/setup.cfg', 'contrib/heat_keystoneclient_v2/setup.py', 'contrib/docker/README.md', 'contrib/rackspace/setup.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0eb93cbf3399a59d3227dd6d3a9a90b4dae8588f', 'message': 'Use setuptools to install contrib plugins\n\nThis change creates a pbr setup.cfg and specifies a data_files\nentry to install the contrib plugin source into the /usr/lib/heat\nplugin directory.\n\nThis change also temporarily disables docs building for contrib\nresoures until the transition to stevedore is fully complete.\n\nChange-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241\n'}]",13,103441,0eb93cbf3399a59d3227dd6d3a9a90b4dae8588f,108,17,28,4571,,,0,"Use setuptools to install contrib plugins

This change creates a pbr setup.cfg and specifies a data_files
entry to install the contrib plugin source into the /usr/lib/heat
plugin directory.

This change also temporarily disables docs building for contrib
resoures until the transition to stevedore is fully complete.

Change-Id: I1c91aee20f72dc2a5a049e67de1d6d7cbabda241
",git fetch https://review.opendev.org/openstack/heat refs/changes/41/103441/6 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/docker/docker/README.md', 'contrib/marconi/setup.cfg', 'contrib/extraroute/setup.cfg', 'contrib/barbican/setup.cfg', '.gitignore', 'contrib/heat_keystoneclient_v2/setup.cfg', 'contrib/marconi/setup.py', 'contrib/docker/setup.cfg', 'contrib/heat_keystoneclient_v2/README.md', 'contrib/barbican/README.md', 'contrib/docker/setup.py', 'contrib/barbican/setup.py', 'contrib/marconi/README.md', 'contrib/rackspace/README.md', 'contrib/nova_flavor/setup.py', 'contrib/extraroute/setup.py', 'contrib/nova_flavor/setup.cfg', 'contrib/nova_flavor/README.md', 'contrib/rackspace/setup.cfg', 'contrib/heat_keystoneclient_v2/setup.py', 'contrib/docker/README.md', 'contrib/rackspace/setup.py']",22,524a3d256c96837ebea71d20c0fd2fe8fd74a838,bp/client-plugins,"#!/usr/bin/env python # Copyright (c) 2013 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # THIS FILE IS MANAGED BY THE GLOBAL REQUIREMENTS REPO - DO NOT EDIT import setuptools # In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass setuptools.setup( setup_requires=['pbr'], pbr=True) ",,462,43
openstack%2Fswift~master~I4b2c6e947241c987779a385fdff270d037470a57,openstack/swift,master,I4b2c6e947241c987779a385fdff270d037470a57,Catch permissions errors when writing StatsD packets,MERGED,2014-08-11 06:54:57.000000000,2014-08-14 11:30:59.000000000,2014-08-14 11:30:58.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 2696}, {'_account_id': 7233}, {'_account_id': 7847}]","[{'number': 1, 'created': '2014-08-11 06:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7d479ee40d40e7791b2bca310363c195aab5888d', 'message': 'Catch permissions errors when writing StatsD packets\n\nFixes Bug: #1183152\n\nChange-Id: I4b2c6e947241c987779a385fdff270d037470a57\n'}, {'number': 2, 'created': '2014-08-11 15:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c38a11c60eab2373e80fc77e57641faedfc454af', 'message': 'Catch permissions errors when writing StatsD packets\n\nCloses Bug: 1183152\n\nChange-Id: I4b2c6e947241c987779a385fdff270d037470a57\n'}, {'number': 3, 'created': '2014-08-12 18:28:41.000000000', 'files': ['swift/common/utils.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/1bc4fe891a359c626ebc8049403d4d72a75b6be7', 'message': 'Catch permissions errors when writing StatsD packets\n\nCloses-Bug: #1183152\n\nChange-Id: I4b2c6e947241c987779a385fdff270d037470a57\n'}]",7,113180,1bc4fe891a359c626ebc8049403d4d72a75b6be7,30,6,3,330,,,0,"Catch permissions errors when writing StatsD packets

Closes-Bug: #1183152

Change-Id: I4b2c6e947241c987779a385fdff270d037470a57
",git fetch https://review.opendev.org/openstack/swift refs/changes/80/113180/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'test/unit/common/test_utils.py']",2,7d479ee40d40e7791b2bca310363c195aab5888d,bug/1183152," def __init__(self, sendto_errno=None): self.sendto_errno = sendto_errno if self.sendto_errno: raise socket.error(self.sendto_errno, 'test errno %s' % self.sendto_errno) def test_no_exception_when_cant_send_udp_packet(self): logger = utils.get_logger({'log_statsd_host': 'some.host.com'}) statsd_client = logger.logger.statsd_client mock_socket = MockUdpSocket(sendto_errno=errno.EPERM) statsd_client._open_socket = lambda *_: mock_socket logger.increment('tunafish') # if we got to this point, no error was thrown ", def __init__(self):,21,2
openstack%2Fpuppet-neutron~master~Ifb4b5acccdce0be63e763b4d837eb452827cd6d4,openstack/puppet-neutron,master,Ifb4b5acccdce0be63e763b4d837eb452827cd6d4,Makes ca_file parameter optional when use_ssl => true,MERGED,2014-08-12 23:05:59.000000000,2014-08-14 11:25:11.000000000,2014-08-14 11:25:10.000000000,"[{'_account_id': 3}, {'_account_id': 6994}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-08-12 23:05:59.000000000', 'files': ['spec/classes/neutron_init_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/70ef4af1e7c5b42a4ebabdbd6d2f69623c8861f5', 'message': 'Makes ca_file parameter optional when use_ssl => true\n\nThe ca_file parameter should not be required when use_ssl => true.  Rather,\nuse_ssl must be true when ca_file is specified.\n\nChange-Id: Ifb4b5acccdce0be63e763b4d837eb452827cd6d4\nCloses-Bug: 1356089\n'}]",0,113673,70ef4af1e7c5b42a4ebabdbd6d2f69623c8861f5,10,3,1,9060,,,0,"Makes ca_file parameter optional when use_ssl => true

The ca_file parameter should not be required when use_ssl => true.  Rather,
use_ssl must be true when ca_file is specified.

Change-Id: Ifb4b5acccdce0be63e763b4d837eb452827cd6d4
Closes-Bug: 1356089
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/73/113673/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_init_spec.rb', 'manifests/init.pp']",2,70ef4af1e7c5b42a4ebabdbd6d2f69623c8861f5,bug/1356089, if $ca_file and !$use_ssl { fail('The ca_file parameter requires that use_ssl to be set to true') } } if $ca_file { neutron_config { 'DEFAULT/ssl_ca_file' : value => $ca_file; } } else { neutron_config { 'DEFAULT/ssl_ca_file' : ensure => absent; }, if !$ca_file { fail('The ca_file parameter is required when use_ssl is set to true') } 'DEFAULT/ssl_ca_file' : value => $ca_file;,35,4
openstack%2Fhorizon~master~I697217adcd0035b4cba493e4af1dbab36479dedc,openstack/horizon,master,I697217adcd0035b4cba493e4af1dbab36479dedc,Add option to prevent duplicate instance names,ABANDONED,2014-02-06 20:46:46.000000000,2014-08-14 11:10:05.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 6610}, {'_account_id': 6966}, {'_account_id': 9275}, {'_account_id': 9313}, {'_account_id': 9317}, {'_account_id': 9498}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9659}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-02-06 20:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8f1d3d723342c76b4d5ddef6fc3f9deb3ff8a869', 'message': 'Disallow duplicate instance names when launching or updating instances\n\nFixes the issue where duplicate names within the same project may be picked for\nnew instances that are being launched, or for existing instances that are being\nupdated.\n\nChange-Id: I697217adcd0035b4cba493e4af1dbab36479dedc\nCloses-Bug: 1275934\n'}, {'number': 2, 'created': '2014-02-06 21:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2163ba0613cb08436d839520d87a4e0ed6a69427', 'message': 'Disallow duplicate instance names when launching or updating instances\n\nFixes the issue where duplicate names within the same project may be picked for\nnew instances that are being launched, or for existing instances that are being\nupdated.\n\nIn the special case where multiple instances are being launched at the same\ntime (count > 1) the instance id is appended to the given name to ensure\nuniqueness. Therefore, in this case the duplicate name check would not be\nrequired.\n\nChange-Id: I697217adcd0035b4cba493e4af1dbab36479dedc\nCloses-Bug: 1275934\n'}, {'number': 3, 'created': '2014-02-06 21:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/94f6d1f91c1b47df3aa9a1a7d389200d39ca00cb', 'message': 'Disallow duplicate instance names during launch or update\n\nFixes the issue where duplicate names within the same project may be\npicked for new instances that are being launched, or for existing\ninstances that are being updated.\n\nIn the special case where multiple instances are being launched at\nthe same time (count > 1) the instance id is appended to the given\nname to ensure uniqueness. Therefore, in this case the duplicate\nname check would not be required.\n\nChange-Id: I697217adcd0035b4cba493e4af1dbab36479dedc\nCloses-Bug: 1275934\n'}, {'number': 4, 'created': '2014-02-07 21:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c6c8bbcd7419f7f07d800de7f7369527a3a31551', 'message': 'Disallow duplicate instance names during launch or update\n\nFixes the issue where duplicate names within the same project may be\npicked for new instances that are being launched, or for existing\ninstances that are being updated.\n\nIn the special case where multiple instances are being launched at\nthe same time (count > 1) the instance id is appended to the given\nname to ensure uniqueness. Therefore, in this case the duplicate\nname check would not be required.\n\nThe duplicate name check is case insensitive. Proper error messages\nare displayed for the case where the exact name already exists, and\nfor the case where the same name with different case already exists.\n\nChange-Id: I697217adcd0035b4cba493e4af1dbab36479dedc\nCloses-Bug: 1275934\n'}, {'number': 5, 'created': '2014-03-04 00:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ec911dff73adc53350b91b4d1e04860a98e13f3c', 'message': 'Add option to prevent duplicate instance names\n\nAdds a local settings option to turn on/off instance name uniqueness\nwithin projects. The settings property is set in local_settings.py\nand is called ENFORCE_UNIQUE_PROJECT_INSTANCE_NAME. By default it is\nset to false, which means duplicate names are allowed.\n\nIf set to True, duplicate names within a project may not be used for\nnew instances that are being launched, or for existing instances\nthat are being updated. In the special case where multiple instances\nare being launched at the same time (count > 1) the instance id is\ncurrently appended to the given name to ensure uniqueness. As a\nresult, in this case the duplicate name check would not be required.\n\nDuplicate name check is case insensitive (as in other modals like\nCreate Flavor or Create Volume Type). Proper error messages are\ndisplayed for the case where the exact name already exists, and for\nthe case where the same name with different case already exists.\n\nChange-Id: I697217adcd0035b4cba493e4af1dbab36479dedc\nCloses-Bug: 1275934\n'}, {'number': 6, 'created': '2014-03-04 19:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5fddc516c6044aed23e6afea55c48c322c6534b6', 'message': 'Add option to prevent duplicate instance names\n\nAdds a local settings option to turn on/off instance name uniqueness\nwithin projects. The settings property is set in local_settings.py\nand is called ENFORCE_UNIQUE_PROJECT_INSTANCE_NAME. By default it is\nset to false, which means duplicate names are allowed.\n\nIf set to True, duplicate names within a project may not be used for\nnew instances that are being launched, or for existing instances\nthat are being updated. In the special case where multiple instances\nare being launched at the same time (count > 1) the instance id is\ncurrently appended to the given name to ensure uniqueness. As a\nresult, in this case the duplicate name check would not be required.\n\nDuplicate name check is case insensitive (as in other modals like\nCreate Flavor or Create Volume Type). Proper error messages are\ndisplayed for the case where the exact name already exists, and for\nthe case where the same name with different case already exists.\n\nChange-Id: I697217adcd0035b4cba493e4af1dbab36479dedc\nCloses-Bug: 1275934'}, {'number': 7, 'created': '2014-03-04 20:01:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2e4cf69d44926559fe8654933faee9bf71776b39', 'message': 'Add option to prevent duplicate instance names\n\nAdds a local settings option to turn on/off instance name uniqueness\nwithin projects. The settings property is set in local_settings.py\nand is called ENFORCE_UNIQUE_PROJECT_INSTANCE_NAME. By default it is\nset to false, which means duplicate names are allowed.\n\nIf set to True, duplicate names within a project may not be used for\nnew instances that are being launched, or for existing instances\nthat are being updated. In the special case where multiple instances\nare being launched at the same time (count > 1) the instance id is\ncurrently appended to the given name to ensure uniqueness. As a\nresult, in this case the duplicate name check would not be required.\n\nDuplicate name check is case insensitive (as in other modals like\nCreate Flavor or Create Volume Type). Proper error messages are\ndisplayed for the case where the exact name already exists, and for\nthe case where the same name with different case already exists.\n\nChange-Id: I697217adcd0035b4cba493e4af1dbab36479dedc\nCloses-Bug: 1275934'}, {'number': 8, 'created': '2014-03-04 20:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/305f595f1af949d07cd74a3ee29a2ba96be6eecf', 'message': 'Add option to prevent duplicate instance names\n\nAdds a local settings option to turn on/off instance name uniqueness\nwithin projects. The settings property is set in local_settings.py\nand is called ENFORCE_UNIQUE_PROJECT_INSTANCE_NAME. By default it is\nset to false, which means duplicate names are allowed.\n\nIf set to True, duplicate names within a project may not be used for\nnew instances that are being launched, or for existing instances\nthat are being updated. In the special case where multiple instances\nare being launched at the same time (count > 1) the instance id is\ncurrently appended to the given name to ensure uniqueness. As a\nresult, in this case the duplicate name check would not be required.\n\nDuplicate name check is case insensitive (as in other modals like\nCreate Flavor or Create Volume Type). Proper error messages are\ndisplayed for the case where the exact name already exists, and for\nthe case where the same name with different case already exists.\n\nChange-Id: I697217adcd0035b4cba493e4af1dbab36479dedc\nCloses-Bug: 1275934'}, {'number': 9, 'created': '2014-03-07 21:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4f6a55f06e24bdf78691873cee1a546797ff0457', 'message': 'Add option to prevent duplicate instance names\n\nAdds a local settings option to turn on/off instance name uniqueness\nwithin projects. The settings property is set in local_settings.py\nand is called ENFORCE_UNIQUE_PROJECT_INSTANCE_NAME. By default it is\nset to false, which means duplicate names are allowed.\n\nIf set to True, duplicate names within a project may not be used for\nnew instances that are being launched, or for existing instances\nthat are being updated. In the special case where multiple instances\nare being launched at the same time (count > 1) the instance id is\ncurrently appended to the given name to ensure uniqueness. As a\nresult, in this case the duplicate name check would not be required.\n\nDuplicate name check is case insensitive (as in other modals like\nCreate Flavor or Create Volume Type).\n\nChange-Id: I697217adcd0035b4cba493e4af1dbab36479dedc\nCloses-Bug: 1275934\n'}, {'number': 10, 'created': '2014-03-12 17:34:40.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/workflows/update_instance.py', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'doc/source/topics/settings.rst', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/local/local_settings.py.example'], 'web_link': 'https://opendev.org/openstack/horizon/commit/31ce60f2284ec3e450ed1c3b47d0d8f8edeb921f', 'message': 'Add option to prevent duplicate instance names\n\nAdds a local settings option to turn on/off instance name uniqueness\nwithin projects. The settings property is set in local_settings.py\nand is called ENFORCE_UNIQUE_PROJECT_INSTANCE_NAME. By default it is\nset to false, which means duplicate names are allowed.\n\nIf set to True, duplicate names within a project may not be used for\nnew instances that are being launched, or for existing instances\nthat are being updated. In the special case where multiple instances\nare being launched at the same time (count > 1) the instance id is\ncurrently appended to the given name to ensure uniqueness. As a\nresult, in this case the duplicate name check would not be required.\n\nDuplicate name check is case insensitive (as in other modals like\nCreate Flavor or Create Volume Type).\n\nChange-Id: I697217adcd0035b4cba493e4af1dbab36479dedc\nCloses-Bug: 1275934\n'}]",29,71649,31ce60f2284ec3e450ed1c3b47d0d8f8edeb921f,95,13,10,9498,,,0,"Add option to prevent duplicate instance names

Adds a local settings option to turn on/off instance name uniqueness
within projects. The settings property is set in local_settings.py
and is called ENFORCE_UNIQUE_PROJECT_INSTANCE_NAME. By default it is
set to false, which means duplicate names are allowed.

If set to True, duplicate names within a project may not be used for
new instances that are being launched, or for existing instances
that are being updated. In the special case where multiple instances
are being launched at the same time (count > 1) the instance id is
currently appended to the given name to ensure uniqueness. As a
result, in this case the duplicate name check would not be required.

Duplicate name check is case insensitive (as in other modals like
Create Flavor or Create Volume Type).

Change-Id: I697217adcd0035b4cba493e4af1dbab36479dedc
Closes-Bug: 1275934
",git fetch https://review.opendev.org/openstack/horizon refs/changes/49/71649/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/instances/workflows/update_instance.py', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'openstack_dashboard/dashboards/project/instances/tests.py']",3,8f1d3d723342c76b4d5ddef6fc3f9deb3ff8a869,bug/1275934," api.nova: ('server_get', 'server_update', 'server_list'), api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) @test.create_stubs({api.nova: ('server_get', 'server_list'), api.network: ('security_group_list', 'server_security_groups',)}) def test_instance_update_post_duplicate_name_exception(self): server = self.servers.first() server2 = self.servers.list()[1] secgroups = self.security_groups.list()[:3] server_groups = [secgroups[0], secgroups[1]] wanted_groups = [secgroups[0].id, secgroups[1].id] api.nova.server_get(IsA(http.HttpRequest), server.id).AndReturn(server) api.network.security_group_list(IsA(http.HttpRequest)) \ .AndReturn(secgroups) api.network.server_security_groups(IsA(http.HttpRequest), server.id).AndReturn(server_groups) api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) self.mox.ReplayAll() res = self._instance_update_post(server.id, server2.name, wanted_groups) self.assertFormErrors(res, 1, 'The name &quot;' + server2.name + '&quot; is already used by another instance.') api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) 'server_create', 'server_list',), # ensure name uniqueness server.name + '_new', api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) 'name': server.name + '_new', 'server_create', 'server_list',), # ensure name uniqueness server.name + '_new', api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) 'name': server.name + '_new', 'tenant_absolute_limits', 'server_list',), # ensure name uniqueness server.name + '_new', api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) 'name': server.name + '_new', 'tenant_absolute_limits', 'server_list',), api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) # ensure name uniqueness 'name': server.name + '_new', 'server_create', 'server_list',), # ensure name uniqueness server.name + '_new', api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) 'name': server.name + '_new', 'availability_zone_list', 'server_list',), api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) # ensure name uniqueness 'name': server.name + '_new', 'availability_zone_list', 'server_list',), api.network: ('security_group_list',), cinder: ('volume_list', 'volume_snapshot_list',), quotas: ('tenant_quota_usages',)}) def test_launch_form_instance_duplicate_name_error(self): flavor = self.flavors.first() image = self.images.first() keypair = self.keypairs.first() server = self.servers.first() volume = self.volumes.first() sec_group = self.security_groups.first() avail_zone = self.availability_zones.first() customization_script = 'user data' device_name = u'vda' volume_choice = ""%s:vol"" % volume.id quota_usages = self.quota_usages.first() api.nova.extension_supported('BlockDeviceMappingV2Boot', IsA(http.HttpRequest)) \ .AndReturn(True) api.nova.flavor_list(IsA(http.HttpRequest)) \ .AndReturn(self.flavors.list()) api.nova.keypair_list(IsA(http.HttpRequest)) \ .AndReturn(self.keypairs.list()) api.network.security_group_list(IsA(http.HttpRequest)) \ .AndReturn(self.security_groups.list()) api.nova.availability_zone_list(IsA(http.HttpRequest)) \ .AndReturn(self.availability_zones.list()) api.glance.image_list_detailed(IsA(http.HttpRequest), filters={'is_public': True, 'status': 'active'}) \ .AndReturn([self.images.list(), False]) api.glance.image_list_detailed(IsA(http.HttpRequest), filters={'property-owner_id': self.tenant.id, 'status': 'active'}) \ .AndReturn([[], False]) api.neutron.network_list(IsA(http.HttpRequest), tenant_id=self.tenant.id, shared=False) \ .AndReturn(self.networks.list()[:1]) api.neutron.network_list(IsA(http.HttpRequest), shared=True) \ .AndReturn(self.networks.list()[1:]) # TODO(absubram): Remove if clause and create separate # test stubs for when profile_support is being used. # Additionally ensure those are always run even in default setting if api.neutron.is_port_profiles_supported(): policy_profiles = self.policy_profiles.list() api.neutron.profile_list(IsA(http.HttpRequest), 'policy').AndReturn(policy_profiles) cinder.volume_list(IsA(http.HttpRequest)) \ .AndReturn(self.volumes.list()) cinder.volume_snapshot_list(IsA(http.HttpRequest)).AndReturn([]) api.nova.flavor_list(IsA(http.HttpRequest)) \ .AndReturn(self.flavors.list()) api.nova.tenant_absolute_limits(IsA(http.HttpRequest)) \ .AndReturn(self.limits['absolute']) quotas.tenant_quota_usages(IsA(http.HttpRequest)) \ .AndReturn(quota_usages) api.nova.flavor_list(IsA(http.HttpRequest)) \ .AndReturn(self.flavors.list()) api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) self.mox.ReplayAll() form_data = {'flavor': flavor.id, 'source_type': 'image_id', 'image_id': image.id, 'availability_zone': avail_zone.zoneName, 'keypair': keypair.name, 'name': server.name, 'customization_script': customization_script, 'project_id': self.tenants.first().id, 'user_id': self.user.id, 'groups': sec_group.name, 'volume_type': 'volume_id', 'volume_id': volume_choice, 'device_name': device_name, 'count': 1} url = reverse('horizon:project:instances:launch') res = self.client.post(url, form_data) self.assertFormErrors(res, 1, 'The name &quot;' + server.name + '&quot; is already used by another instance.') @test.create_stubs({api.glance: ('image_list_detailed',), api.neutron: ('network_list', 'profile_list',), api.nova: ('extension_supported', 'flavor_list', 'keypair_list', 'tenant_absolute_limits', 'availability_zone_list', 'server_list',), api.nova.server_list(IsA(http.HttpRequest)) \ .AndReturn([self.servers.list(), False]) # ensure name uniqueness 'name': server.name + '_new',"," api.nova: ('server_get', 'server_update'), 'server_create',), server.name, 'name': server.name, 'server_create',), server.name, 'name': server.name, 'tenant_absolute_limits',), server.name, 'name': server.name, 'tenant_absolute_limits',), 'name': server.name, 'server_create',), server.name, 'name': server.name, 'availability_zone_list',), 'name': server.name, 'availability_zone_list',), 'name': server.name,",219,19
openstack%2Fhorizon~master~If09f0306e62fe93bc2b59e078a7b7cecb799c959,openstack/horizon,master,If09f0306e62fe93bc2b59e078a7b7cecb799c959,Fix progress indicators in Resize Instance modal,ABANDONED,2014-03-08 00:55:11.000000000,2014-08-14 11:06:55.000000000,,"[{'_account_id': 3}, {'_account_id': 4978}, {'_account_id': 9498}, {'_account_id': 9576}, {'_account_id': 10697}]","[{'number': 1, 'created': '2014-03-08 00:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/950e3f5466d1b9eb81338fd81ed92357c2a35c3b', 'message': 'Fix progress indicators in Resize Instance modal\n\nProgress indicators in Resize Instance do not currently show correct\nvalues, as they account for the resource quota of the current instance\nin both blue and green sections. This patch fixes the issue by\naccounting that resource quota in the green section only.\n\nChange-Id: If09f0306e62fe93bc2b59e078a7b7cecb799c959\nCloses-Bug: #1288954\n'}, {'number': 2, 'created': '2014-03-08 00:57:18.000000000', 'files': ['horizon/static/horizon/js/horizon.quota.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0eb369caaf55272cbee17d7479c6ee1875bc82bb', 'message': 'Fix progress indicators in Resize Instance modal\n\nProgress indicators in Resize Instance do not currently show correct\nvalues, as they account for the resource quota of the current instance\nin both blue and green sections. This patch fixes the issue by\naccounting that resource quota in the green section only.\n\nChange-Id: If09f0306e62fe93bc2b59e078a7b7cecb799c959\nCloses-Bug: #1288954\n'}]",1,79112,0eb369caaf55272cbee17d7479c6ee1875bc82bb,17,5,2,9498,,,0,"Fix progress indicators in Resize Instance modal

Progress indicators in Resize Instance do not currently show correct
values, as they account for the resource quota of the current instance
in both blue and green sections. This patch fixes the issue by
accounting that resource quota in the green section only.

Change-Id: If09f0306e62fe93bc2b59e078a7b7cecb799c959
Closes-Bug: #1288954
",git fetch https://review.opendev.org/openstack/horizon refs/changes/12/79112/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.quota.js'],1,950e3f5466d1b9eb81338fd81ed92357c2a35c3b,Bug1288954," old_flavor: null, // The flavor object of the old flavor on the form. new_flavor: null, // The flavor object of the new flavor on the form. this.getOldFlavor(); the new flavor. // Returns the flavor object for the old flavor in the form. getOldFlavor: function() { if(this.is_flavor_quota) { this.old_flavor = $.grep(this.flavors, function(flavor) { return flavor.name === $(""#id_old_flavor_name"").val(); })[0]; } else { this.old_flavor = null; } return this.old_flavor; }, // Returns the flavor object for the new flavor in the form. getNewFlavor: function() { if(this.is_flavor_quota) { this.new_flavor = $.grep(this.flavors, function(flavor) { this.new_flavor = null; } return this.new_flavor; new flavor on the form select element. this.getNewFlavor(); if (this.new_flavor) { var name = horizon.utils.truncate(this.new_flavor.name, 14, true); var vcpus = horizon.utils.humanizeNumbers(this.new_flavor.vcpus); var disk = horizon.utils.humanizeNumbers(this.new_flavor.disk); var ephemeral = horizon.utils.humanizeNumbers(this.new_flavor[""OS-FLV-EXT-DATA:ephemeral""]); var disk_total = this.new_flavor.disk + this.new_flavor[""OS-FLV-EXT-DATA:ephemeral""]; var ram = horizon.utils.humanizeNumbers(this.new_flavor.ram); else { $(""#flavor_name"").html(""""); $(""#flavor_vcpus"").html(""""); $(""#flavor_disk"").html(""""); $(""#flavor_ephemeral"").html(""""); $(""#flavor_disk_total"").html(""""); $(""#flavor_ram"").html(""""); } this.getNewFlavor(); } else if (progress_stat === 'instances') { } else if (scope.new_flavor === undefined) { update_amount = scope.old_flavor[progress_stat]; } else { update_amount = scope.new_flavor[progress_stat] * instance_count; var progress_stat = progress_element.attr('id').match(/^quota_(.+)/)[1]; var quota_used; if (progress_stat === 'instances') { quota_used = parseInt(progress_element.attr('data-quota-used'), 10) - 1; } else { quota_used = parseInt(progress_element.attr('data-quota-used'), 10) - (this.old_flavor === undefined ? 0 : this.old_flavor[progress_stat]); } var progress_stat = progress_element.attr('id').match(/^quota_(.+)/)[1]; var quota_used; if (progress_stat === 'instances') { quota_used = parseInt(progress_element.attr('data-quota-used'), 10) - (scope.old_flavor === undefined ? 0 : 1); } else { quota_used = parseInt(progress_element.attr('data-quota-used'), 10) - (scope.old_flavor === undefined ? 0 : scope.old_flavor[progress_stat]); }"," selected_flavor: null, // The flavor object of the current selected flavor on the form. the selected flavor. // Returns the flavor object for the selected flavor in the form. getSelectedFlavor: function() { if(this.is_flavor_quota) { this.selected_flavor = $.grep(this.flavors, function(flavor) { this.selected_flavor = null; } return this.selected_flavor; selected flavor on the form select element. this.getSelectedFlavor(); if (this.selected_flavor) { var name = horizon.utils.truncate(this.selected_flavor.name, 14, true); var vcpus = horizon.utils.humanizeNumbers(this.selected_flavor.vcpus); var disk = horizon.utils.humanizeNumbers(this.selected_flavor.disk); var ephemeral = horizon.utils.humanizeNumbers(this.selected_flavor[""OS-FLV-EXT-DATA:ephemeral""]); var disk_total = this.selected_flavor.disk + this.selected_flavor[""OS-FLV-EXT-DATA:ephemeral""]; var ram = horizon.utils.humanizeNumbers(this.selected_flavor.ram); this.getSelectedFlavor(); } else if(progress_stat === 'instances') { } else if (scope.selected_flavor) { update_amount = (scope.selected_flavor[progress_stat] * instance_count); var quota_used = parseInt(progress_element.attr('data-quota-used'), 10); var quota_used = parseInt(progress_element.attr('data-quota-used'), 10);",64,22
openstack%2Ftripleo-image-elements~master~I59de4e88d9343e093a95436432e2e4d68f425d06,openstack/tripleo-image-elements,master,I59de4e88d9343e093a95436432e2e4d68f425d06,Custom policy for ssh-keygen failure,MERGED,2014-07-16 05:28:12.000000000,2014-08-14 11:05:47.000000000,2014-08-14 11:05:47.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-07-16 05:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/31600ff891b7b570edf9afa778dab9b6d418fd99', 'message': 'WIP: Custom policy for ssh-keygen failure\n\nThis patch contains a custom policy to allow ssh-keygen to write to\n/tmp. This action is blocked by SELinux. The custom policy is needed\nuntil the upstream SELinux policy is updated for Fedora or nova is\nmodified to call ssh-keygen to write out to a different directory.\n\nBug: 1284485\nChange-Id: I59de4e88d9343e093a95436432e2e4d68f425d06\n'}, {'number': 2, 'created': '2014-07-16 18:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/18b1b813e1ad2f14035dce29b592bc7772089d2f', 'message': 'WIP: Custom policy for ssh-keygen failure\n\nThis patch contains a custom policy to allow ssh-keygen to write to\n/tmp. This action is blocked by SELinux. The custom policy is needed\nuntil the upstream SELinux policy is updated for Fedora or nova is\nmodified to call ssh-keygen to write out to a different directory.\n\nBug: 1284485\nChange-Id: I59de4e88d9343e093a95436432e2e4d68f425d06\n'}, {'number': 3, 'created': '2014-07-31 21:19:55.000000000', 'files': ['elements/selinux/custom-policies/tripleo-selinux-ssh.te'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/77d89ebad41d50458ec178cb94fa75d7e8cb3ae2', 'message': 'Custom policy for ssh-keygen failure\n\nThis patch contains a custom policy to allow ssh-keygen to write to\n/tmp. This action is blocked by SELinux. The custom policy is needed\nuntil the upstream SELinux policy is updated for Fedora or nova is\nmodified to call ssh-keygen to write out to a different directory.\n\nPartial-Bug: 1284485\nChange-Id: I59de4e88d9343e093a95436432e2e4d68f425d06\n'}]",1,107233,77d89ebad41d50458ec178cb94fa75d7e8cb3ae2,30,5,3,7471,,,0,"Custom policy for ssh-keygen failure

This patch contains a custom policy to allow ssh-keygen to write to
/tmp. This action is blocked by SELinux. The custom policy is needed
until the upstream SELinux policy is updated for Fedora or nova is
modified to call ssh-keygen to write out to a different directory.

Partial-Bug: 1284485
Change-Id: I59de4e88d9343e093a95436432e2e4d68f425d06
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/33/107233/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/selinux/custom-policies/bug1284485-ssh-keygen.te'],1,31600ff891b7b570edf9afa778dab9b6d418fd99,bug/1284485, module ssh-keygen 1.0; require { type ssh_keygen_t; type init_tmp_t; class file open; } #============= ssh_keygen_t ============== allow ssh_keygen_t init_tmp_t:file open; ,,11,0
openstack%2Ftripleo-image-elements~master~I51d2afbd89c4f632920eca6d2d1698665ccf4e21,openstack/tripleo-image-elements,master,I51d2afbd89c4f632920eca6d2d1698665ccf4e21,Custom policy for nova-api tmpfs errors,MERGED,2014-07-16 17:45:52.000000000,2014-08-14 11:02:51.000000000,2014-08-14 11:02:51.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-07-16 17:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5fe00b9c3c9697b6be2742187673c66fb0ed1dbc', 'message': 'WIP: Custom policy for nova-api tmpfs errors\n\nThis policy fixes an issue whereby nova-api is unable to use tmpfs,\n/dev/shm, when SELinux is running in enforcing mode.\n\nBug: 1342863\nChange-Id: I51d2afbd89c4f632920eca6d2d1698665ccf4e21\n'}, {'number': 2, 'created': '2014-08-01 02:44:47.000000000', 'files': ['elements/selinux/custom-policies/tripleo-selinux-nova.te'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6ef091157378a94993f9f7719f3fd05ed62c0e72', 'message': 'Custom policy for nova-api tmpfs errors\n\nThis policy fixes an issue whereby nova-api is unable to use tmpfs,\n/dev/shm, when SELinux is running in enforcing mode.\n\nPartial-Bug: 1342863\nChange-Id: I51d2afbd89c4f632920eca6d2d1698665ccf4e21\n'}]",4,107447,6ef091157378a94993f9f7719f3fd05ed62c0e72,29,5,2,7471,,,0,"Custom policy for nova-api tmpfs errors

This policy fixes an issue whereby nova-api is unable to use tmpfs,
/dev/shm, when SELinux is running in enforcing mode.

Partial-Bug: 1342863
Change-Id: I51d2afbd89c4f632920eca6d2d1698665ccf4e21
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/47/107447/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/selinux/custom-policies/bug1342863-nova-api.te'],1,5fe00b9c3c9697b6be2742187673c66fb0ed1dbc,bug/1342863, module bug1342863-nova-api 1.0; require { type tmpfs_t; type nova_api_t; class dir { write remove_name search add_name }; class file { write getattr link read create unlink open }; class filesystem getattr; } #============= nova_api_t ============== allow nova_api_t tmpfs_t:dir { write remove_name search add_name }; allow nova_api_t tmpfs_t:file { getattr unlink }; allow nova_api_t tmpfs_t:file { read write create open link }; allow nova_api_t tmpfs_t:filesystem getattr; ,,17,0
openstack%2Ffuel-web~master~I7b12cc537cf1e82f21cbac039e3480928cd24873,openstack/fuel-web,master,I7b12cc537cf1e82f21cbac039e3480928cd24873,fuel_upgrade: run KillSupervisord hook in 5.0.1,MERGED,2014-08-14 08:27:11.000000000,2014-08-14 11:01:50.000000000,2014-08-14 11:01:50.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8789}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 10959}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-08-14 08:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/38751b040ffad1dd19aa90ebfc65c9b2309a9dee', 'message': ""fuel_upgrade: run KillSupervisord hook in 5.0.1\n\nSince we didn't backport a supervisor fix to 5.0.1, we should run our\nhook during upgrading from 5.0.1 too.\n\nChange-Id: I7b12cc537cf1e82f21cbac039e3480928cd24873\nImplements: upgrade-to-5-1\n""}, {'number': 2, 'created': '2014-08-14 09:47:02.000000000', 'files': ['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_pre_upgrade_hooks.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/pre_upgrade_hooks/from_5_0_to_any_kill_supervisord.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fbb63e9538b3c4ea521839db4fc91257e7c06df2', 'message': ""fuel_upgrade: run KillSupervisord hook in 5.0.1\n\nSince we didn't backport a supervisor fix to 5.0.1, we should run our\nhook during upgrading from 5.0.1 too.\n\nChange-Id: I7b12cc537cf1e82f21cbac039e3480928cd24873\nImplements: upgrade-to-5-1\n""}]",0,114161,fbb63e9538b3c4ea521839db4fc91257e7c06df2,22,8,2,10391,,,0,"fuel_upgrade: run KillSupervisord hook in 5.0.1

Since we didn't backport a supervisor fix to 5.0.1, we should run our
hook during upgrading from 5.0.1 too.

Change-Id: I7b12cc537cf1e82f21cbac039e3480928cd24873
Implements: upgrade-to-5-1
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/61/114161/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_pre_upgrade_hooks.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/pre_upgrade_hooks/from_5_0_to_any_kill_supervisord.py']",2,38751b040ffad1dd19aa90ebfc65c9b2309a9dee,fix_kill_supervisord_hook," return self.config.from_version in ('5.0', '5.0.1')"," return self.config.from_version in ('5.0', )",4,1
openstack%2Fglance~master~I425de4975a4468495a000e408e8d7cf94b646912,openstack/glance,master,I425de4975a4468495a000e408e8d7cf94b646912,Fix bad indentation in glance,MERGED,2014-08-13 14:56:26.000000000,2014-08-14 10:47:18.000000000,2014-08-14 10:47:18.000000000,"[{'_account_id': 3}, {'_account_id': 6549}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9064}, {'_account_id': 9236}]","[{'number': 1, 'created': '2014-08-13 14:56:26.000000000', 'files': ['glance/registry/api/v2/__init__.py', 'glance/registry/api/v1/__init__.py', 'glance/domain/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/9e9d49c4abe1796b720358ebfb6f8d65002a30f7', 'message': 'Fix bad indentation in glance\n\nFix for bad indentation warnings from pylint.\n\nCloses-Bug: #1356406\n\nChange-Id: I425de4975a4468495a000e408e8d7cf94b646912\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>\n'}]",0,113918,9e9d49c4abe1796b720358ebfb6f8d65002a30f7,15,6,1,9064,,,0,"Fix bad indentation in glance

Fix for bad indentation warnings from pylint.

Closes-Bug: #1356406

Change-Id: I425de4975a4468495a000e408e8d7cf94b646912
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>
",git fetch https://review.opendev.org/openstack/glance refs/changes/18/113918/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/registry/api/v2/__init__.py', 'glance/registry/api/v1/__init__.py', 'glance/domain/__init__.py']",3,9e9d49c4abe1796b720358ebfb6f8d65002a30f7,bug/1356406," valid_transitions = { 'pending': ['processing', 'failure'], 'processing': ['success', 'failure'], 'success': [], 'failure': [], } if new_status in valid_transitions[cur_status]: return True else: return False"," valid_transitions = { 'pending': ['processing', 'failure'], 'processing': ['success', 'failure'], 'success': [], 'failure': [], } if new_status in valid_transitions[cur_status]: return True else: return False",70,70
openstack%2Fpbr~master~Ieaeca592b6ba26c5da50dcad3fb6e7551431d50e,openstack/pbr,master,Ieaeca592b6ba26c5da50dcad3fb6e7551431d50e,Handle more local dev version cases,MERGED,2014-08-14 00:58:56.000000000,2014-08-14 10:47:06.000000000,2014-08-14 10:47:06.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4190}, {'_account_id': 4395}]","[{'number': 1, 'created': '2014-08-14 00:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/797b58dcf2c9c09bbbff6dcb8fecb33200a450d2', 'message': 'Handle single short sha versions\n\nIn some repos where there are no tags yet, the version comes out\nas a single short sha. Handle that.\n\nChange-Id: Ieaeca592b6ba26c5da50dcad3fb6e7551431d50e\n'}, {'number': 2, 'created': '2014-08-14 01:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/aa0a12c3c461c1e56b7175ed086f7ac2a1f962e4', 'message': 'Handle single short sha versions\n\nIn some repos where there are no tags yet, the version comes out\nas a single short sha. Handle that.\n\nChange-Id: Ieaeca592b6ba26c5da50dcad3fb6e7551431d50e\n'}, {'number': 3, 'created': '2014-08-14 04:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/268856d6a753ade637e95a04a305683c71629272', 'message': 'Handle more local dev version cases\n\nDue to an oversight in testing (the tests for local dev versions were all running with PBR_VERSION in the environment) we did not handle enough variety of local development versions.\n\nSpecific new cases we now handle:\n - untagged trees - where git describe returns just the sha\n - tags with versions with less than two components (e.g. 1)\n\nChange-Id: Ieaeca592b6ba26c5da50dcad3fb6e7551431d50e\nCo-Authored-By: Robert Collins <rbtcollins@hp.com>\n'}, {'number': 4, 'created': '2014-08-14 04:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/e97689ef895c2931a8b9d6e6562dfa23f60fa389', 'message': 'Handle more local dev version cases\n\nDue to an oversight in testing (the tests for local dev versions were all\nrunning with PBR_VERSION in the environment) we did not handle enough\nvariety of local development versions.\n\nSpecific new cases we now handle:\n - untagged trees - where git describe returns just the sha\n - tags with versions with less than two components (e.g. 1)\n\nChange-Id: Ieaeca592b6ba26c5da50dcad3fb6e7551431d50e\nCo-Authored-By: Robert Collins <rbtcollins@hp.com>\n'}, {'number': 5, 'created': '2014-08-14 04:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/5886db087f8015bfb0e98b04ee956ef43a0507ab', 'message': 'Handle more local dev version cases\n\nDue to an oversight in testing (the tests for local dev versions were all\nrunning with PBR_VERSION in the environment) we did not handle enough\nvariety of local development versions.\n\nSpecific new cases we now handle:\n - untagged trees - where git describe returns just the sha\n - tags with versions with less than two components (e.g. 1)\n\nChange-Id: Ieaeca592b6ba26c5da50dcad3fb6e7551431d50e\nCo-Authored-By: Robert Collins <rbtcollins@hp.com>\n'}, {'number': 6, 'created': '2014-08-14 04:58:29.000000000', 'files': ['pbr/tests/test_version.py', 'pbr/packaging.py', 'pbr/tests/testpackage/pbr_testpackage/__init__.py', 'pbr/tests/base.py', 'pbr/tests/test_packaging.py', 'pbr/tests/testpackage/setup.cfg', 'pbr/version.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/1758998881ef5e3c81a76910755ce1e33688b9e0', 'message': 'Handle more local dev version cases\n\nDue to an oversight in testing (the tests for local dev versions were\nall running with PBR_VERSION in the environment) we did not handle\nenough variety of local development versions.\n\nSpecific new cases we now handle:\n - untagged trees - where git describe returns just the sha\n - tags with versions with less than two components (e.g. 1)\n\nChange-Id: Ieaeca592b6ba26c5da50dcad3fb6e7551431d50e\nCo-Authored-By: Robert Collins <rbtcollins@hp.com>\n'}]",0,114093,1758998881ef5e3c81a76910755ce1e33688b9e0,21,5,6,2,,,0,"Handle more local dev version cases

Due to an oversight in testing (the tests for local dev versions were
all running with PBR_VERSION in the environment) we did not handle
enough variety of local development versions.

Specific new cases we now handle:
 - untagged trees - where git describe returns just the sha
 - tags with versions with less than two components (e.g. 1)

Change-Id: Ieaeca592b6ba26c5da50dcad3fb6e7551431d50e
Co-Authored-By: Robert Collins <rbtcollins@hp.com>
",git fetch https://review.opendev.org/openstack/pbr refs/changes/93/114093/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/version.py'],1,797b58dcf2c9c09bbbff6dcb8fecb33200a450d2,bp/pbr-semver, # Fake a parseable version in the case of a single git sha version if len(components) == 1 and len(components[0]) == 7: components = ['0'] * 4 + ['g' + components[0]],,3,0
openstack%2Fsahara-extra~master~Iff684b2bb688c44ab7f9f49fcb326dfdba787284,openstack/sahara-extra,master,Iff684b2bb688c44ab7f9f49fcb326dfdba787284,Remove edp-examples,MERGED,2014-08-07 17:11:49.000000000,2014-08-14 10:42:55.000000000,2014-08-14 10:42:54.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 8091}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-08-07 17:11:49.000000000', 'files': ['edp-examples/pig-job/input', 'edp-examples/README.rst', 'edp-examples/pig-job/expected_output', 'edp-examples/edp-wordcount/src/WordCount.java', 'edp-examples/edp-wordcount/wordcount/workflow.xml', 'edp-examples/pig-job/example.pig', 'edp-examples/edp-wordcount/README.rst', 'edp-examples/pig-job/README.rst', 'edp-examples/pig-job/udf.jar', 'edp-examples/edp-wordcount/src/NOTICE.txt', 'edp-examples/edp-wordcount/wordcount/lib/edp-java.jar', 'edp-examples/edp-wordcount/wordcount/job.properties'], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/6f67ebb9cbcf7fb813752bdf86f6ac4b0ae5d0df', 'message': 'Remove edp-examples\n\nThe EDP examples will be moved to the sahara repo and removed from\nsahara-extra.\n\nPartial-implements: blueprint edp-move-examples\nChange-Id: Iff684b2bb688c44ab7f9f49fcb326dfdba787284\n'}]",0,112625,6f67ebb9cbcf7fb813752bdf86f6ac4b0ae5d0df,15,4,1,8091,,,0,"Remove edp-examples

The EDP examples will be moved to the sahara repo and removed from
sahara-extra.

Partial-implements: blueprint edp-move-examples
Change-Id: Iff684b2bb688c44ab7f9f49fcb326dfdba787284
",git fetch https://review.opendev.org/openstack/sahara-extra refs/changes/25/112625/1 && git format-patch -1 --stdout FETCH_HEAD,"['edp-examples/pig-job/input', 'edp-examples/README.rst', 'edp-examples/pig-job/expected_output', 'edp-examples/edp-wordcount/src/WordCount.java', 'edp-examples/edp-wordcount/wordcount/workflow.xml', 'edp-examples/pig-job/example.pig', 'edp-examples/edp-wordcount/README.rst', 'edp-examples/pig-job/README.rst', 'edp-examples/pig-job/udf.jar', 'edp-examples/edp-wordcount/src/NOTICE.txt', 'edp-examples/edp-wordcount/wordcount/lib/edp-java.jar', 'edp-examples/edp-wordcount/wordcount/job.properties']",12,6f67ebb9cbcf7fb813752bdf86f6ac4b0ae5d0df,bp/edp-move-examples,,"# # Licensed to the Apache Software Foundation (ASF) under one # or more contributor license agreements. See the NOTICE file # distributed with this work for additional information # regarding copyright ownership. The ASF licenses this file # to you under the Apache License, Version 2.0 (the # ""License""); you may not use this file except in compliance # with the License. You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # nameNode=hdfs://1.2.3.4:8020 jobTracker=1.2.3.4:8021 queueName=default oozie.wf.application.path=${nameNode}/user/${user.name}/wordcount ",1,267
openstack%2Fsahara-image-elements~master~Ibf87bcf196cd5e2a30ae3ec13bfdc8858fc0239a,openstack/sahara-image-elements,master,Ibf87bcf196cd5e2a30ae3ec13bfdc8858fc0239a,Fixed parameters parsing after -d,MERGED,2014-08-12 23:52:22.000000000,2014-08-14 10:33:56.000000000,2014-08-14 10:33:55.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7604}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-08-12 23:52:22.000000000', 'files': ['diskimage-create/diskimage-create.sh'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/0df557c4268219505faa29cd614a05257d19a57f', 'message': ""Fixed parameters parsing after -d\n\n-d doesn't have param but it had pattern as opt with parameter\n\nChange-Id: Ibf87bcf196cd5e2a30ae3ec13bfdc8858fc0239a\n""}]",0,113708,0df557c4268219505faa29cd614a05257d19a57f,24,8,1,8411,,,0,"Fixed parameters parsing after -d

-d doesn't have param but it had pattern as opt with parameter

Change-Id: Ibf87bcf196cd5e2a30ae3ec13bfdc8858fc0239a
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/08/113708/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage-create/diskimage-create.sh'],1,0df557c4268219505faa29cd614a05257d19a57f,,"while getopts ""p:i:v:dm"" opt; do","while getopts ""p:i:v:d:m"" opt; do",1,1
openstack%2Fneutron~master~Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f,openstack/neutron,master,Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f,Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint,MERGED,2014-07-08 14:38:19.000000000,2014-08-14 10:28:45.000000000,2014-08-14 10:28:43.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 8124}, {'_account_id': 9008}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-07-08 14:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/14f4ce488fe53cca0c4cfcaf2a9afc0938f08647', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}, {'number': 2, 'created': '2014-07-09 10:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1521650ae12d1eac76b51d5914e50e929f29eaf3', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}, {'number': 3, 'created': '2014-07-09 13:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69ccaecab59f73e964abdb94dacbc33dbbb9d21f', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}, {'number': 4, 'created': '2014-07-16 08:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55487042ec942cdee88044f032e5fabde18dde6a', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}, {'number': 5, 'created': '2014-07-24 09:49:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c5560a2987d183c1db5faed88fd2963683c9f7ae', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}, {'number': 6, 'created': '2014-07-24 10:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ba3f15e471dba6ef94b2208940cc2a8510769622', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}, {'number': 7, 'created': '2014-07-29 07:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d22539c459cf94b6f221377eac357a2ea5c22c0b', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}, {'number': 8, 'created': '2014-07-29 13:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cde8958854bd21ea73f704f9b2b597864f0da178', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}, {'number': 9, 'created': '2014-07-30 08:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3510869bbe1a5f29de622b3dcf6de408f77182c4', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}, {'number': 10, 'created': '2014-07-31 12:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9bdc6270c5ced8afef41bee7cac5dc844fe237d9', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}, {'number': 11, 'created': '2014-08-13 14:51:54.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/4eba2f05c2f4_correct_vxlan_endpoint_primary_key.py', 'neutron/tests/unit/ml2/test_type_vxlan.py', 'neutron/plugins/ml2/drivers/type_vxlan.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/tests/unit/ml2/test_type_gre.py', 'neutron/plugins/ml2/drivers/type_gre.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc4965080ce83db50b71255d6a0f972b9be67b1b', 'message': ""Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint\n\nSELECT FOR UPDATE expression, which is triggered with the use of the\nSQLAlchemy Query object's with_lockmode('update') method, is\ndetrimental to performance and scalability of the database\nperformance code in Neutron due to the lock contention it produces.\n\nSELECT FOR UPDATE can be entirely avoided in add_endpoint methods\nwith the use of single-shot SELECT and INSERT expressions and the\ncorrection of VxlanEndpoint primary key: indeed previously it was not\npossible to create multiple endpoints with the same ip, now the model\nprimary key constraint ensures it.\n\nChange-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f\nPartial-Bug: #1330562\n""}]",19,105472,bc4965080ce83db50b71255d6a0f972b9be67b1b,278,34,11,8124,,,0,"Remove SELECT FOR UPDATE use in ML2 tunnel driver add_endpoint

SELECT FOR UPDATE expression, which is triggered with the use of the
SQLAlchemy Query object's with_lockmode('update') method, is
detrimental to performance and scalability of the database
performance code in Neutron due to the lock contention it produces.

SELECT FOR UPDATE can be entirely avoided in add_endpoint methods
with the use of single-shot SELECT and INSERT expressions and the
correction of VxlanEndpoint primary key: indeed previously it was not
possible to create multiple endpoints with the same ip, now the model
primary key constraint ensures it.

Change-Id: Id69fbc15c8f51b4b275cd742312e6ff6802d8c0f
Partial-Bug: #1330562
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/105472/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/4eba2f05c2f4_correct_vxlan_endpoint_primary_key.py', 'neutron/tests/unit/ml2/test_type_vxlan.py', 'neutron/plugins/ml2/drivers/type_vxlan.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/plugins/ml2/drivers/type_gre.py', 'neutron/tests/unit/ml2/test_type_gre.py']",6,14f4ce488fe53cca0c4cfcaf2a9afc0938f08647,bug/1330562,"import mock def test_add_same_endpoints(self): self.driver.add_endpoint(TUNNEL_IP_ONE) with mock.patch.object(type_gre.LOG, 'warning') as log_warn: self.driver.add_endpoint(TUNNEL_IP_ONE) log_warn.assert_called_once_with(mock.ANY, TUNNEL_IP_ONE) ",,109,22
openstack%2Fhorizon~master~I0fdf625938e74a31883024a57ba580680f235670,openstack/horizon,master,I0fdf625938e74a31883024a57ba580680f235670,Updated from global requirements,MERGED,2014-08-13 23:18:58.000000000,2014-08-14 10:28:36.000000000,2014-08-14 10:28:35.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-08-13 23:18:58.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/180982cb21b24ce345cdd930546aa3a090f1a700', 'message': 'Updated from global requirements\n\nChange-Id: I0fdf625938e74a31883024a57ba580680f235670\n'}]",0,114056,180982cb21b24ce345cdd930546aa3a090f1a700,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: I0fdf625938e74a31883024a57ba580680f235670
",git fetch https://review.opendev.org/openstack/horizon refs/changes/56/114056/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,180982cb21b24ce345cdd930546aa3a090f1a700,openstack/requirements,"Django>=1.4.2,<1.7","Django>=1.4,<1.7",1,1
openstack%2Fhorizon~master~I9296ad4e68a74a645e2f68cd08b621000fc1aa51,openstack/horizon,master,I9296ad4e68a74a645e2f68cd08b621000fc1aa51,Imported Translations from Transifex,MERGED,2014-08-14 06:03:08.000000000,2014-08-14 10:28:28.000000000,2014-08-14 10:28:27.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-08-14 06:03:08.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/ru/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'horizon/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d065caebeeadb19718e86a2c3ac1e4f7abdd5ce2', 'message': 'Imported Translations from Transifex\n\nChange-Id: I9296ad4e68a74a645e2f68cd08b621000fc1aa51\n'}]",0,114128,d065caebeeadb19718e86a2c3ac1e4f7abdd5ce2,8,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I9296ad4e68a74a645e2f68cd08b621000fc1aa51
",git fetch https://review.opendev.org/openstack/horizon refs/changes/28/114128/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/ru/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'horizon/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",18,d065caebeeadb19718e86a2c3ac1e4f7abdd5ce2,transifex/translations,"""POT-Creation-Date: 2014-08-13 03:25-0500\n"" ""PO-Revision-Date: 2014-08-13 06:12+0000\n""#: dashboards/admin/volumes/snapshots/tables.py:58 #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:10#: dashboards/admin/volumes/snapshots/forms.py:24#: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:15#: dashboards/admin/volumes/templates/volumes/snapshots/_update_status.html:29#: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:12#: dashboards/admin/volumes/templates/volumes/snapshots/_update_status.html:18#: dashboards/admin/volumes/snapshots/tables.py:63#: dashboards/admin/volumes/snapshots/forms.py:33 #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:18#: dashboards/admin/volumes/panel.py:21 dashboards/admin/volumes/tabs.py:34#: dashboards/admin/volumes/tabs.py:71 #: dashboards/admin/volumes/snapshots/tables.py:68#: dashboards/admin/volumes/snapshots/tables.py:64#: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:33#: dashboards/admin/volumes/snapshots/tabs.py:23#: dashboards/admin/volumes/tabs.py:48 dashboards/admin/volumes/tabs.py:94 #: dashboards/admin/volumes/snapshots/tables.py:51#: dashboards/admin/volumes/tabs.py:65#: dashboards/admin/volumes/tabs.py:86 dashboards/project/volumes/tabs.py:88 #: dashboards/project/volumes/volumes/forms.py:187 msgid ""Unable to retrieve volume snapshots."" msgstr ""Unable to retrieve volume snapshots."" #: dashboards/admin/volumes/snapshots/forms.py:25 #: dashboards/admin/volumes/volumes/forms.py:55 msgid ""Creating"" msgstr """" #: dashboards/admin/volumes/snapshots/forms.py:26 #: dashboards/admin/volumes/volumes/forms.py:56 #: dashboards/project/instances/tables.py:759 msgid ""Deleting"" msgstr ""Deleting"" #: dashboards/admin/volumes/snapshots/forms.py:27 #: dashboards/admin/volumes/volumes/forms.py:58 #: dashboards/project/instances/tables.py:710 msgid ""Error"" msgstr ""Error"" #: dashboards/admin/volumes/snapshots/forms.py:28 msgid ""Error_Deleting"" msgstr """" #: dashboards/admin/volumes/snapshots/forms.py:43 #, python-format msgid ""Successfully updated volume snapshot status: \""%s\""."" msgstr """" #: dashboards/admin/volumes/snapshots/forms.py:48 msgid ""Unable to update volume snapshot status."" msgstr """" #: dashboards/admin/volumes/snapshots/tables.py:29 #: dashboards/admin/volumes/templates/volumes/snapshots/_update_status.html:28 #: dashboards/admin/volumes/templates/volumes/volumes/_update_status.html:28 msgid ""Update Status"" msgstr """" #: dashboards/admin/volumes/snapshots/tables.py:61 #: dashboards/project/volumes/backups/tables.py:120 #: dashboards/project/volumes/snapshots/tables.py:132 #: dashboards/project/volumes/volumes/forms.py:41 #: dashboards/project/volumes/volumes/forms.py:489 #: dashboards/project/volumes/volumes/forms.py:511 msgid ""Volume Name"" msgstr ""Volume Name"" #: dashboards/admin/volumes/snapshots/views.py:44 #: dashboards/project/volumes/snapshots/views.py:42 msgid ""Unable to retrieve volume snapshot."" msgstr ""Unable to retrieve volume snapshot."" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:4 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:4 msgid ""Volume Snapshot Overview"" msgstr ""Volume Snapshot Overview"" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:7 #: dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:6 #: dashboards/project/database_backups/templates/database_backups/details.html:15 #: dashboards/project/databases/templates/databases/_detail_overview.html:6 #: dashboards/project/images/templates/images/images/_detail_overview.html:6 #: dashboards/project/instances/templates/instances/_detail_overview.html:7 #: dashboards/project/instances/workflows/update_instance.py:119 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:6 #: dashboards/project/stacks/templates/stacks/_resource_overview.html:6 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:7 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:7 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:7 msgid ""Info"" msgstr ""Info"" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:20 #: dashboards/project/instances/templates/instances/_detail_overview.html:138 #: dashboards/project/instances/workflows/create_instance.py:98 #: dashboards/project/instances/workflows/create_instance.py:336 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:20 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:20 #: dashboards/project/volumes/volumes/forms.py:205 #: dashboards/project/volumes/volumes/tables.py:59 #: dashboards/project/volumes/volumes/tables.py:352 msgid ""Volume"" msgstr ""Volume"" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:30 #: dashboards/project/databases/templates/databases/_detail_overview.html:23 #: dashboards/project/images/templates/images/images/_detail_overview.html:41 #: dashboards/project/instances/templates/instances/_detail_overview.html:43 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:31 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:34 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:24 msgid ""Specs"" msgstr ""Specs"" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:34 #: dashboards/project/database_backups/templates/database_backups/details.html:35 #: dashboards/project/instances/templates/instances/_detail_overview.html:53 #: dashboards/project/instances/templates/instances/_detail_overview.html:56 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:11 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:12 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:13 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:35 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:38 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:28 #: dashboards/project/volumes/templates/volumes/volumes/_extend_limits.html:10 #: dashboards/project/volumes/templates/volumes/volumes/_extend_limits.html:11 #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:10 #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:11 msgid ""GB"" msgstr ""GB"" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:35 #: dashboards/project/data_processing/cluster_templates/workflows/create.py:81 #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:27 #: dashboards/project/data_processing/jobs/workflows/launch.py:407 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:292 #: dashboards/project/database_backups/tables.py:141 #: dashboards/project/database_backups/templates/database_backups/details.html:36 #: dashboards/project/databases/tables.py:266 #: dashboards/project/databases/templates/databases/_detail_overview.html:34 #: dashboards/project/images/templates/images/images/_detail_overview.html:25 #: dashboards/project/instances/templates/instances/_detail_overview.html:18 #: dashboards/project/instances/templates/instances/_detail_overview.html:36 #: dashboards/project/stacks/tables.py:89 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:22 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:36 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:39 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:29 msgid ""Created"" msgstr ""Created"" #: dashboards/admin/volumes/templates/volumes/snapshots/_update_status.html:9 #: dashboards/admin/volumes/templates/volumes/snapshots/update_status.html:3 #: dashboards/admin/volumes/templates/volumes/snapshots/update_status.html:6 msgid ""Update Volume Snapshot Status"" msgstr """" #: dashboards/admin/volumes/templates/volumes/snapshots/_update_status.html:19 msgid """" ""\n"" "" The status of a volume snapshot is normally managed automatically. In some circumstances\n"" "" an administrator may need to explicitly update the status value. This is equivalent to\n"" "" the <tt>cinder snapshot-reset-state</tt> command.\n"" "" "" msgstr """" #: dashboards/admin/volumes/volumes/views.py:61#: dashboards/project/volumes/volumes/views.py:210#: dashboards/project/volumes/volumes/views.py:101 #: dashboards/project/volumes/volumes/views.py:144 #: dashboards/project/volumes/volumes/views.py:193#: dashboards/project/volumes/volumes/views.py:135#: dashboards/project/volumes/volumes/views.py:162","""POT-Creation-Date: 2014-08-12 22:17-0500\n"" ""PO-Revision-Date: 2014-08-13 03:17+0000\n""#: dashboards/admin/volumes/panel.py:21 dashboards/admin/volumes/tabs.py:29#: dashboards/admin/volumes/tabs.py:43#: dashboards/admin/volumes/tabs.py:60#: dashboards/admin/volumes/templates/volumes/volumes/_update_status.html:28 msgid ""Update Status"" msgstr """" #: dashboards/admin/volumes/volumes/forms.py:55 msgid ""Creating"" msgstr """" #: dashboards/admin/volumes/volumes/forms.py:56 #: dashboards/project/instances/tables.py:759 msgid ""Deleting"" msgstr ""Deleting"" #: dashboards/admin/volumes/volumes/forms.py:58 #: dashboards/project/instances/tables.py:710 msgid ""Error"" msgstr ""Error"" #: dashboards/admin/volumes/volumes/views.py:58#: dashboards/project/data_processing/cluster_templates/workflows/create.py:81 #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:27 #: dashboards/project/data_processing/jobs/workflows/launch.py:407 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:292 #: dashboards/project/database_backups/tables.py:141 #: dashboards/project/database_backups/templates/database_backups/details.html:36 #: dashboards/project/databases/tables.py:266 #: dashboards/project/databases/templates/databases/_detail_overview.html:34 #: dashboards/project/images/templates/images/images/_detail_overview.html:25 #: dashboards/project/instances/templates/instances/_detail_overview.html:18 #: dashboards/project/instances/templates/instances/_detail_overview.html:36 #: dashboards/project/stacks/tables.py:89 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:22 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:36 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:39 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:29 msgid ""Created"" msgstr ""Created"" #: dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:6 #: dashboards/project/database_backups/templates/database_backups/details.html:15 #: dashboards/project/databases/templates/databases/_detail_overview.html:6 #: dashboards/project/images/templates/images/images/_detail_overview.html:6 #: dashboards/project/instances/templates/instances/_detail_overview.html:7 #: dashboards/project/instances/workflows/update_instance.py:119 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:6 #: dashboards/project/stacks/templates/stacks/_resource_overview.html:6 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:7 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:7 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:7 msgid ""Info"" msgstr ""Info"" #: dashboards/project/database_backups/templates/database_backups/details.html:35 #: dashboards/project/instances/templates/instances/_detail_overview.html:53 #: dashboards/project/instances/templates/instances/_detail_overview.html:56 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:11 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:12 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:13 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:35 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:38 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:28 #: dashboards/project/volumes/templates/volumes/volumes/_extend_limits.html:10 #: dashboards/project/volumes/templates/volumes/volumes/_extend_limits.html:11 #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:10 #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:11 msgid ""GB"" msgstr ""GB"" #: dashboards/project/databases/templates/databases/_detail_overview.html:23 #: dashboards/project/images/templates/images/images/_detail_overview.html:41 #: dashboards/project/instances/templates/instances/_detail_overview.html:43 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:31 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:34 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:24 msgid ""Specs"" msgstr ""Specs"" #: dashboards/project/instances/templates/instances/_detail_overview.html:138 #: dashboards/project/instances/workflows/create_instance.py:98 #: dashboards/project/instances/workflows/create_instance.py:336 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:20 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:20 #: dashboards/project/volumes/volumes/forms.py:205 #: dashboards/project/volumes/volumes/tables.py:59 #: dashboards/project/volumes/volumes/tables.py:352 msgid ""Volume"" msgstr ""Volume"" #: dashboards/project/volumes/tabs.py:88 #: dashboards/project/volumes/volumes/forms.py:187 msgid ""Unable to retrieve volume snapshots."" msgstr ""Unable to retrieve volume snapshots."" #: dashboards/project/volumes/backups/tables.py:120 #: dashboards/project/volumes/snapshots/tables.py:132 #: dashboards/project/volumes/volumes/forms.py:41 #: dashboards/project/volumes/volumes/forms.py:489 #: dashboards/project/volumes/volumes/forms.py:511 msgid ""Volume Name"" msgstr ""Volume Name"" #: dashboards/project/volumes/snapshots/views.py:42 msgid ""Unable to retrieve volume snapshot."" msgstr ""Unable to retrieve volume snapshot."" #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:4 msgid ""Volume Snapshot Overview"" msgstr ""Volume Snapshot Overview"" #: dashboards/project/volumes/volumes/views.py:207#: dashboards/project/volumes/volumes/views.py:98 #: dashboards/project/volumes/volumes/views.py:141 #: dashboards/project/volumes/volumes/views.py:190#: dashboards/project/volumes/volumes/views.py:132#: dashboards/project/volumes/volumes/views.py:159",2917,2003
openstack%2Fnova~master~Ic7fa319674594f4470b6eafd3e07e7c467b99477,openstack/nova,master,Ic7fa319674594f4470b6eafd3e07e7c467b99477,"Merge unit tests of ""create a flavor"" API",MERGED,2014-07-31 02:35:59.000000000,2014-08-14 10:28:04.000000000,2014-08-14 10:28:02.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-31 02:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/337e4168524f8c214276b6c4059c04e1f7277f90', 'message': 'Merge BadRequest tests of ""create a flavor"" API\n\nIn test_flavor_manage, there are BadRequest tests of ""create a flavor"".\nMost parts of them are duplicated.\nThis patch merges them for the readability and clarifying their purposes.\n\nChange-Id: Ic7fa319674594f4470b6eafd3e07e7c467b99477\n'}, {'number': 2, 'created': '2014-08-11 05:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c3e9fd7ffd16d3de4da94f239ec0e15d971730f', 'message': 'Merge BadRequest tests of ""create a flavor"" API\n\nIn test_flavor_manage, there are BadRequest tests of ""create a flavor"".\nMost parts of them are duplicated.\nThis patch merges them for the readability and clarifying their purposes.\n\nChange-Id: Ic7fa319674594f4470b6eafd3e07e7c467b99477\n'}, {'number': 3, 'created': '2014-08-11 05:58:22.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_flavor_manage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d20ce98a602c0215ca5acd14fd68ae3841f4e480', 'message': 'Merge unit tests of ""create a flavor"" API\n\nIn test_flavor_manage, there are success/bad_request tests of\n""create a flavor"". Most parts of them are duplicated.\nThis patch merges them for the readability and clarifying their\npurposes.\n\nChange-Id: Ic7fa319674594f4470b6eafd3e07e7c467b99477\n'}]",0,110835,d20ce98a602c0215ca5acd14fd68ae3841f4e480,47,12,3,6167,,,0,"Merge unit tests of ""create a flavor"" API

In test_flavor_manage, there are success/bad_request tests of
""create a flavor"". Most parts of them are duplicated.
This patch merges them for the readability and clarifying their
purposes.

Change-Id: Ic7fa319674594f4470b6eafd3e07e7c467b99477
",git fetch https://review.opendev.org/openstack/nova refs/changes/35/110835/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/contrib/test_flavor_manage.py'],1,337e4168524f8c214276b6c4059c04e1f7277f90,bp/v2-on-v3-api," def _create_flavor_bad_request_case(self, body): url = '/v2/fake/flavors' req = webob.Request.blank(url) req.headers['Content-Type'] = 'application/json' req.method = 'POST' req.body = jsonutils.dumps(body) res = req.get_response(self.app) self.assertEqual(res.status_code, 400) def test_create_invalid_name(self): body = { self._create_flavor_bad_request_case(body) body = { self._create_flavor_bad_request_case(body) body = { self._create_flavor_bad_request_case(body) body = { self._create_flavor_bad_request_case(body) body = {} self._create_flavor_bad_request_case(body) body = { self._create_flavor_bad_request_case(body) body = { self._create_flavor_bad_request_case(body) body = { self._create_flavor_bad_request_case(body) body = { self._create_flavor_bad_request_case(body)"," def test_create_invalid_name(self): expected = { url = '/v2/fake/flavors' req = webob.Request.blank(url) req.headers['Content-Type'] = 'application/json' req.method = 'POST' req.body = jsonutils.dumps(expected) res = req.get_response(self.app) self.assertEqual(res.status_code, 400) request_dict = { url = '/v2/fake/flavors' req = webob.Request.blank(url) req.headers['Content-Type'] = 'application/json' req.method = 'POST' req.body = jsonutils.dumps(request_dict) res = req.get_response(self.app) self.assertEqual(res.status_code, 400) expected = { url = '/v2/fake/flavors' req = webob.Request.blank(url) req.headers['Content-Type'] = 'application/json' req.method = 'POST' req.body = jsonutils.dumps(expected) res = req.get_response(self.app) self.assertEqual(res.status_int, 400) self.stubs.UnsetAll() expected = { url = '/v2/fake/flavors' req = webob.Request.blank(url) req.headers['Content-Type'] = 'application/json' req.method = 'POST' req.body = jsonutils.dumps(expected) res = req.get_response(self.app) self.assertEqual(res.status_code, 400) self.stubs.UnsetAll() expected = {} url = '/v2/fake/flavors' req = webob.Request.blank(url) req.headers['Content-Type'] = 'application/json' req.method = 'POST' req.body = jsonutils.dumps(expected) res = req.get_response(self.app) self.assertEqual(res.status_code, 400) self.stubs.UnsetAll() expected = { url = '/v2/fake/flavors' req = webob.Request.blank(url) req.headers['Content-Type'] = 'application/json' req.method = 'POST' req.body = jsonutils.dumps(expected) res = req.get_response(self.app) self.assertEqual(res.status_code, 400) self.stubs.UnsetAll() expected = { url = '/v2/fake/flavors' req = webob.Request.blank(url) req.headers['Content-Type'] = 'application/json' req.method = 'POST' req.body = jsonutils.dumps(expected) res = req.get_response(self.app) self.assertEqual(res.status_code, 400) self.stubs.UnsetAll() expected = { url = '/v2/fake/flavors' req = webob.Request.blank(url) req.headers['Content-Type'] = 'application/json' req.method = 'POST' req.body = jsonutils.dumps(expected) res = req.get_response(self.app) self.assertEqual(res.status_code, 400) self.stubs.UnsetAll() expected = { url = '/v2/fake/flavors' req = webob.Request.blank(url) req.headers['Content-Type'] = 'application/json' req.method = 'POST' req.body = jsonutils.dumps(expected) res = req.get_response(self.app) self.assertEqual(res.status_code, 400)",29,88
openstack%2Frally~master~I4e2dd58629f3c07b9928a95879056a79382fcf8b,openstack/rally,master,I4e2dd58629f3c07b9928a95879056a79382fcf8b,Do not assume networks should be assigned,MERGED,2014-08-09 20:55:46.000000000,2014-08-14 10:24:43.000000000,2014-08-14 10:24:43.000000000,"[{'_account_id': 3}, {'_account_id': 1525}, {'_account_id': 4428}, {'_account_id': 6124}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9601}]","[{'number': 1, 'created': '2014-08-09 20:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/badef0c33d3d6312e8bc5f1d92e009fa2c9e6814', 'message': 'Do not assume networks should be assigned\n\nThere are several places within the Nova benchark scenarios where we\nare assuming networks should be assigned. This breaks a variety of\ndifferent deployments. Instead of always assigning a network, do so\nbased on whether a new scenario argument of auto_assign_nic=True.\n\nChange-Id: I4e2dd58629f3c07b9928a95879056a79382fcf8b\nCloses-Bug: #1353622\n'}, {'number': 2, 'created': '2014-08-09 20:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4049447d819a79db5cf4ce2a0cfb1d60632a172b', 'message': 'Do not assume networks should be assigned\n\nThere are several places within the Nova benchark scenarios where we\nare assuming networks should be assigned. This breaks a variety of\ndifferent deployments. Instead of always assigning a network, do so\nbased on whether a new scenario argument of auto_assign_nic=True.\n\nChange-Id: I4e2dd58629f3c07b9928a95879056a79382fcf8b\nCloses-Bug: #1353622\n'}, {'number': 3, 'created': '2014-08-10 17:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e796051f8ff9fec5b8ffb2bd50bb12be21a382c6', 'message': 'Do not assume networks should be assigned\n\nThere are several places within the Nova benchark scenarios where we\nare assuming networks should be assigned. This breaks a variety of\ndifferent deployments. Instead of always assigning a network, do so\nbased on whether a new scenario argument of auto_assign_nic=True.\n\nChange-Id: I4e2dd58629f3c07b9928a95879056a79382fcf8b\nCloses-Bug: #1353622\n'}, {'number': 4, 'created': '2014-08-11 02:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1044fdc85a0a2f34f3c2996f5b2e93d33b8676a7', 'message': 'Do not assume networks should be assigned\n\nThere are several places within the Nova benchark scenarios where we\nare assuming networks should be assigned. This breaks a variety of\ndifferent deployments. Instead of always assigning a network, do so\nbased on whether a new scenario argument of auto_assign_nic=True.\n\nChange-Id: I4e2dd58629f3c07b9928a95879056a79382fcf8b\nCloses-Bug: #1353622\n'}, {'number': 5, 'created': '2014-08-13 19:25:17.000000000', 'files': ['rally/benchmark/scenarios/nova/utils.py', 'tests/benchmark/scenarios/nova/test_utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'rally-scenarios/rally.yaml', 'tests/benchmark/scenarios/nova/test_servers.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/103d7cc346cfb82fa27d2097591f6f7938ff1ae6', 'message': 'Do not assume networks should be assigned\n\nThere are several places within the Nova benchark scenarios where we\nare assuming networks should be assigned. This breaks a variety of\ndifferent deployments. Instead of always assigning a network, do so\nbased on whether a new scenario argument of auto_assign_nic=True.\n\nChange-Id: I4e2dd58629f3c07b9928a95879056a79382fcf8b\nCloses-Bug: #1353622\n'}]",7,113096,103d7cc346cfb82fa27d2097591f6f7938ff1ae6,45,7,5,1525,,,0,"Do not assume networks should be assigned

There are several places within the Nova benchark scenarios where we
are assuming networks should be assigned. This breaks a variety of
different deployments. Instead of always assigning a network, do so
based on whether a new scenario argument of auto_assign_nic=True.

Change-Id: I4e2dd58629f3c07b9928a95879056a79382fcf8b
Closes-Bug: #1353622
",git fetch https://review.opendev.org/openstack/rally refs/changes/96/113096/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/nova/utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'tests/benchmark/scenarios/nova/test_servers.py']",3,badef0c33d3d6312e8bc5f1d92e009fa2c9e6814,bug/1353622," def _prepare_boot(self, mock_osclients, nic=None, assert_nic=False): def _verify_boot_server(self, mock_osclients, nic=None, assert_nic=False): scenario._boot_server.assert_called_once_with(""name"", ""img"", 0, False,"," def _prepare_boot(self, mock_osclients, mock_choice=None, nic=None, assert_nic=False): mock_choice.return_value = nova.networks.create('net-2') @mock.patch(""rally.benchmark.scenarios.nova.servers.random.choice"") def _verify_boot_server(self, mock_choice, mock_osclients, nic=None, assert_nic=False): mock_choice=mock_choice, scenario._boot_server.assert_called_once_with(""name"", ""img"", 0, @mock.patch(""rally.benchmark.scenarios.nova.servers.NovaServers.clients"") @mock.patch(""rally.benchmark.runners.base.osclients"") def test_boot_server_random_nic(self, mock_osclients, mock_nova_clients): self._verify_boot_server(mock_osclients=mock_osclients, nic=None, assert_nic=True) @mock.patch(""rally.benchmark.scenarios.nova.servers.NovaServers.clients"") @mock.patch(""rally.benchmark.runners.base.osclients"") @mock.patch(""rally.benchmark.scenarios.nova.servers.random.choice"") def test_boot_server_from_volume_random_nic(self, mock_choice, mock_osclients, mock_nova_clients): scenario, kwargs, expected_kwargs = self._prepare_boot( mock_osclients=mock_osclients, mock_choice=mock_choice, nic=None, assert_nic=True) fake_volume = fakes.FakeVolumeManager().create() fake_volume.id = ""volume_id"" scenario._create_volume = mock.MagicMock(return_value=fake_volume) scenario.boot_server_from_volume(""img"", 0, 5, **kwargs) scenario._create_volume.assert_called_once_with(5, imageRef=""img"") scenario._boot_server.assert_called_once_with( ""name"", ""img"", 0, block_device_mapping={""vda"": ""volume_id:::1""}, **expected_kwargs) ",25,65
openstack%2Ffuel-web~stable%2F5.0~Ie9a778dae178368cc2fabe182b870abf2c2f4a4b,openstack/fuel-web,stable/5.0,Ie9a778dae178368cc2fabe182b870abf2c2f4a4b,[5.0.1] vCenter validation,ABANDONED,2014-08-14 06:55:14.000000000,2014-08-14 10:14:57.000000000,,"[{'_account_id': 3}, {'_account_id': 8766}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-14 06:55:14.000000000', 'files': ['nailgun/static/templates/dialogs/display_changes.html', 'nailgun/static/i18n/translation.json', 'nailgun/static/js/views/cluster_page_tabs/settings_tab.js', 'nailgun/static/js/views/dialogs.js', 'nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/css/styles.less', 'nailgun/static/js/models.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/327a039dec3dab094a445a94990848bc88015a38', 'message': '[5.0.1] vCenter validation\n\nRelated-Bug:#1314613\n\nChange-Id: Ie9a778dae178368cc2fabe182b870abf2c2f4a4b\n'}]",0,114143,327a039dec3dab094a445a94990848bc88015a38,8,3,1,8766,,,0,"[5.0.1] vCenter validation

Related-Bug:#1314613

Change-Id: Ie9a778dae178368cc2fabe182b870abf2c2f4a4b
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/43/114143/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/templates/dialogs/display_changes.html', 'nailgun/static/i18n/translation.json', 'nailgun/static/js/views/cluster_page_tabs/settings_tab.js', 'nailgun/static/js/views/dialogs.js', 'nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/css/styles.less', 'nailgun/static/js/models.js']",7,327a039dec3dab094a445a94990848bc88015a38,bug/1314613, if (!setting.disabled && setting.regex && setting.regex.source) {, if (setting.regex && setting.regex.source) {,28,11
openstack%2Fpuppet-cinder~stable%2Ficehouse~Idcad78c78405c17518b8f4fe75e9954107b386f9,openstack/puppet-cinder,stable/icehouse,Idcad78c78405c17518b8f4fe75e9954107b386f9,volume/iscsi: Fix typo and use real default iscsi_helper in tests,MERGED,2014-08-13 20:43:29.000000000,2014-08-14 10:09:11.000000000,2014-08-14 10:09:11.000000000,"[{'_account_id': 3}, {'_account_id': 6994}, {'_account_id': 7155}]","[{'number': 1, 'created': '2014-08-13 20:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/f774aed104d8d2e450dde043f7ae1daa4ec9c680', 'message': ""volume/iscsi: Fix typo and use real default iscsi_helper in tests\n\nThe default value for iscsi_helper isn't correctly configured in\nvolume::iscsi. This commit fix also a typo in the params class.\n\nCloses-Bug: 1341091\nChange-Id: Idcad78c78405c17518b8f4fe75e9954107b386f9\n(cherry picked from commit 0e076dec1111c4573db59f524ddb36f5f36566e6)\n""}, {'number': 2, 'created': '2014-08-13 20:43:34.000000000', 'files': ['spec/classes/cinder_volume_iscsi_spec.rb', 'manifests/volume/iscsi.pp', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/b5b45a2eec88ab63d78c5ecf0d9c29539b8af464', 'message': ""volume/iscsi: Fix typo and use real default iscsi_helper in tests\n\nThe default value for iscsi_helper isn't correctly configured in\nvolume::iscsi. This commit fix also a typo in the params class.\n\nCloses-Bug: 1341091\nChange-Id: Idcad78c78405c17518b8f4fe75e9954107b386f9\n(cherry picked from commit 0e076dec1111c4573db59f524ddb36f5f36566e6)\n""}]",0,114021,b5b45a2eec88ab63d78c5ecf0d9c29539b8af464,9,3,2,7822,,,0,"volume/iscsi: Fix typo and use real default iscsi_helper in tests

The default value for iscsi_helper isn't correctly configured in
volume::iscsi. This commit fix also a typo in the params class.

Closes-Bug: 1341091
Change-Id: Idcad78c78405c17518b8f4fe75e9954107b386f9
(cherry picked from commit 0e076dec1111c4573db59f524ddb36f5f36566e6)
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/21/114021/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/cinder_volume_iscsi_spec.rb', 'manifests/params.pp', 'manifests/volume/iscsi.pp']",3,f774aed104d8d2e450dde043f7ae1daa4ec9c680,," $iscsi_helper = $::cinder::params::iscsi_helper, include cinder::params "," $iscsi_helper = $cinder::params::iscsi_helper,",19,15
openstack%2Frequirements~master~Ica40e995cdb1906fefceb8b3b4e581d9f6fb37ee,openstack/requirements,master,Ica40e995cdb1906fefceb8b3b4e581d9f6fb37ee,Remove d-g from projects.txt,ABANDONED,2014-08-12 20:38:39.000000000,2014-08-14 10:07:35.000000000,,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-12 20:38:39.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/2de9ab5165a1935f7483b60df46ba3a74c2a14ab', 'message': ""Remove d-g from projects.txt\n\nCurrently we don't have gate-requirements jobs on d-g and so it\nshouldn't be included to the projects.txt, because it breaks post job\nthat propose requirements updates to all projects specified in\nprojects.txt (bashate that isn't in the global reqs has been added to\nreqs of d-g).\n\nChange-Id: Ica40e995cdb1906fefceb8b3b4e581d9f6fb37ee\n""}]",0,113643,2de9ab5165a1935f7483b60df46ba3a74c2a14ab,9,3,1,6786,,,0,"Remove d-g from projects.txt

Currently we don't have gate-requirements jobs on d-g and so it
shouldn't be included to the projects.txt, because it breaks post job
that propose requirements updates to all projects specified in
projects.txt (bashate that isn't in the global reqs has been added to
reqs of d-g).

Change-Id: Ica40e995cdb1906fefceb8b3b4e581d9f6fb37ee
",git fetch https://review.opendev.org/openstack/requirements refs/changes/43/113643/1 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,2de9ab5165a1935f7483b60df46ba3a74c2a14ab,,,openstack-infra/devstack-gate,0,1
openstack%2Ffuel-library~master~I759f1330c670923f5b1bad846eff922a8bb25868,openstack/fuel-library,master,I759f1330c670923f5b1bad846eff922a8bb25868,Add authorization by service token to the rescheduling script,MERGED,2014-07-24 15:59:33.000000000,2014-08-14 10:02:39.000000000,2014-08-14 10:02:38.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7604}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-07-24 15:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f80b327dfddb327ce7a9c4f647f410f975fbdab7', 'message': 'Add authorization by service token to the rescheduling script\n\nCloses-bug: #1311749\nCloses-bug: #1322221\n\nChange-Id: I759f1330c670923f5b1bad846eff922a8bb25868\n'}, {'number': 2, 'created': '2014-07-24 16:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/13e7fd7e974d9185fabdf01d2c75aa31b588f8a6', 'message': 'Add authorization by service token to the rescheduling script\n\nCloses-bug: #1311749\nCloses-bug: #1322221\n\nChange-Id: I759f1330c670923f5b1bad846eff922a8bb25868\n'}, {'number': 3, 'created': '2014-07-24 16:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e205a3098697a1d34c9435263b0b4e1ef3af322f', 'message': 'Add authorization by service token to the rescheduling script\n\nCloses-bug: #1311749\nCloses-bug: #1322221\n\nChange-Id: I759f1330c670923f5b1bad846eff922a8bb25868\n'}, {'number': 4, 'created': '2014-07-25 12:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c69c6ad99081b8f373b1c37ead4e3fc578f9248f', 'message': 'Add authorization by service token to the rescheduling script\n\nCloses-bug: #1311749\nCloses-bug: #1322221\n\nChange-Id: I759f1330c670923f5b1bad846eff922a8bb25868\n'}, {'number': 5, 'created': '2014-08-11 09:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/572f02727fd73f30e37854b900faafd3025b94b6', 'message': 'Add authorization by service token to the rescheduling script\n\nCloses-bug: #1311749\nCloses-bug: #1322221\n\nChange-Id: I759f1330c670923f5b1bad846eff922a8bb25868\n'}, {'number': 6, 'created': '2014-08-12 10:32:40.000000000', 'files': ['deployment/puppet/neutron/files/q-agent-cleanup.py', 'deployment/puppet/neutron/files/ocf/neutron-agent-dhcp', 'deployment/puppet/neutron/files/ocf/neutron-agent-l3'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7dd02c88691dbd9074b93ecdd266ecb379a62672', 'message': 'Add authorization by service token to the rescheduling script\n\nCloses-bug: #1275652\nCloses-bug: #1322221\n\nChange-Id: I759f1330c670923f5b1bad846eff922a8bb25868'}]",0,109332,7dd02c88691dbd9074b93ecdd266ecb379a62672,53,7,6,7468,,,0,"Add authorization by service token to the rescheduling script

Closes-bug: #1275652
Closes-bug: #1322221

Change-Id: I759f1330c670923f5b1bad846eff922a8bb25868",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/32/109332/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/neutron/files/q-agent-cleanup.py'],1,f80b327dfddb327ce7a9c4f647f410f975fbdab7,bug/1311749,"import random import stringfrom keystoneclient.apiclient.exceptions import NotFound as ks_NotFound LOG_NAME = 'q-agent-cleanup'PORT_ID_PART_LEN = 11 TMP_USER_NAME = 'tmp_neutron_admin' def __del__(self): if self._keystone and self._keystone.username: try: self._keystone.users.delete(self._keystone.users.find(username=self._keystone.username)) except: # if we get exception while cleaning temporary account -- nothing harm pass def generate_random_passwd(self, length=13): chars = string.ascii_letters + string.digits + '!@#$%^&*()' random.seed = (os.urandom(1024)) return ''.join(random.choice(chars) for i in range(length)) ret_count = self.options.get('retries', 1) while True: if ret_count <= 0: a_token = self.options.get('auth-token') a_url = self.options.get('admin-auth-url') if a_token and a_url: self.log.debug(""Authentication by predefined token."") #auth_url=self.auth_config['OS_AUTH_URL'] ks = ks_client.Client( token=a_token, endpoint=a_url, ) # find or create temporary rescheduling-admin user with random password tmp_passwd = self.generate_random_passwd() service_tenant = ks.tenants.find(name='services') auth_url = ks.endpoints.find( service_id=ks.services.find(type='identity').id ).internalurl try: user = ks.users.find(username=TMP_USER_NAME) ks.users.delete(user) except ks_NotFound: # user not found, it's OK pass user = ks.users.create(TMP_USER_NAME, tmp_passwd, tenant_id=service_tenant.id) ks.roles.add_user_role(user, ks.roles.find(name='admin'), service_tenant) # authenticate tmp user user self._keystone = ks_client.Client( username=user.username, password=tmp_passwd, tenant_id=user.tenantId, auth_url=auth_url, ) else: self._keystone = ks_client.Client( username=self.auth_config['OS_USERNAME'], password=self.auth_config['OS_PASSWORD'], tenant_name=self.auth_config['OS_TENANT_NAME'], auth_url=self.auth_config['OS_AUTH_URL'], ) errmsg = str(e.message).strip() # str() need, because keystone may use int as message in exception self.log.info("">>> Can't connect to {0}, wait for server ready..."".format(self.auth_config['OS_AUTH_URL'])) time.sleep(self.options.sleep) #self.log.debug(""Auth_token: '{0}'"".format(self._token)) endpoint_url=self.keystone.endpoints.find( service_id=self.keystone.services.find(type='network').id ).adminurl, if ret_count <= 0: errmsg = str(e.message).strip() self.log.info(""Can't connect to {0}, wait for server ready..."".format(self.keystone.service_catalog.url_for(service_type='network'))) time.sleep(self.options.sleep) self.log.error(""ERROR (rc={0}) while execution {1}"".format(rc, ' '.join(cmd))) cmd.extend([ns, 'ip', 'l', 'show']) self.log.error(""ERROR (rc={0}) while execution {1}"".format(rc, ' '.join(cmd))) self.log.error(""ERROR (rc={0}) while execution {1}"".format(rc, ' '.join(cmd))) parser.add_argument(""-t"", ""--auth-token"", dest=""auth-token"", default=None, help=""Authenticating token (instead username/passwd)"", metavar=""TOKEN"") parser.add_argument(""-u"", ""--admin-auth-url"", dest=""admin-auth-url"", default=None, help=""Authenticating URL (admin)"", metavar=""URL"")"," LOG_NAME='q-agent-cleanup'PORT_ID_PART_LEN=11 ret_count = self.options.get('retries',1) while True: if ret_count <= 0 : self._keystone = ks_client.Client( username=self.auth_config['OS_USERNAME'], password=self.auth_config['OS_PASSWORD'], tenant_name=self.auth_config['OS_TENANT_NAME'], auth_url=self.auth_config['OS_AUTH_URL'], ) errmsg = e.message.strip() self.log.info("">>> Can't connect to {0}, wait for server ready..."".format(self.auth_config['OS_AUTH_URL'])) time.sleep(self.options.sleep) endpoint_url=self.keystone.service_catalog.url_for(service_type='network'), if ret_count <= 0 : errmsg = e.message.strip() self.log.info(""Can't connect to {0}, wait for server ready..."".format(self.keystone.service_catalog.url_for(service_type='network'))) time.sleep(self.options.sleep) self.log.error(""ERROR (rc={0}) while execution {1}"".format(rc,' '.join(cmd))) cmd.extend([ns,'ip','l','show']) self.log.error(""ERROR (rc={0}) while execution {1}"".format(rc,' '.join(cmd))) self.log.error(""ERROR (rc={0}) while execution {1}"".format(rc,' '.join(cmd))) #todo: kill processes in given namespaces if self.options.get('list-agents'): self._list_agents(agent) return 0 # parser.add_argument(""--cleanup-ns"", dest=""cleanup-ns"", action=""store_true"", default=False, # help=""cleanup namespaces for given agents"") # parser.add_argument(""--remove-agent"", dest=""remove-agent"", action=""store_true"", default=False, # help=""cleanup namespaces for given agents"") # parser.add_argument(""--list"", dest=""list-agents"", action=""store_true"", default=False, # help=""list agents and some additional information"")",77,33
openstack%2Fmurano~master~Ic7352042e9e1b48d227a8b572ae8ae91798c7487,openstack/murano,master,Ic7352042e9e1b48d227a8b572ae8ae91798c7487,Fix the concurrency issue agent queue creation and VM agent,MERGED,2014-07-28 15:46:29.000000000,2014-08-14 09:55:37.000000000,2014-08-14 09:55:37.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-07-28 15:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/de522c9ee5234d116ffcf252eb0265332e60d0f6', 'message': 'Fix the concurrency issue agent queue creation and VM agent\n\nThis fix moves queue creation code to initialize section in order to\nhave a queue created before Murano agent on the spawned VM will try to use it.\n\nChange-Id: Ic7352042e9e1b48d227a8b572ae8ae91798c7487\nCloses-Bug: #1349472\n'}, {'number': 2, 'created': '2014-07-28 23:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/92ba41f1375eecc635e4faeaf5163a9cd5f3b179', 'message': 'Fix the concurrency issue agent queue creation and VM agent\n\nThis fix moves queue creation code to initialize section in order to\nhave a queue created before Murano agent on the spawned VM will try to use it.\n\nChange-Id: Ic7352042e9e1b48d227a8b572ae8ae91798c7487\nCloses-Bug: #1349472\n'}, {'number': 3, 'created': '2014-07-29 01:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c4b3d30f51c21b4d1b7e8a3d4bfe0f1b2a4133c3', 'message': 'Fix the concurrency issue agent queue creation and VM agent\n\nThis fix moves queue creation code to initialize section in order to\nhave a queue created before Murano agent on the spawned VM will try to use it.\n\nChange-Id: Ic7352042e9e1b48d227a8b572ae8ae91798c7487\nCloses-Bug: #1349472\n'}, {'number': 4, 'created': '2014-07-29 14:18:35.000000000', 'files': ['meta/io.murano/Classes/resources/Instance.yaml', 'murano/engine/system/agent.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/999512756d11e1182677ed8d29cc210e55651a0e', 'message': 'Fix the concurrency issue agent queue creation and VM agent\n\nThis fix moves queue creation code to initialize section in order to\nhave a queue created before Murano agent on the spawned VM will try to use it.\n\nChange-Id: Ic7352042e9e1b48d227a8b572ae8ae91798c7487\nCloses-Bug: #1349472\n'}]",0,110030,999512756d11e1182677ed8d29cc210e55651a0e,30,6,4,8443,,,0,"Fix the concurrency issue agent queue creation and VM agent

This fix moves queue creation code to initialize section in order to
have a queue created before Murano agent on the spawned VM will try to use it.

Change-Id: Ic7352042e9e1b48d227a8b572ae8ae91798c7487
Closes-Bug: #1349472
",git fetch https://review.opendev.org/openstack/murano refs/changes/30/110030/3 && git format-patch -1 --stdout FETCH_HEAD,['murano/engine/system/agent.py'],1,de522c9ee5234d116ffcf252eb0265332e60d0f6,bug/1349472," with common.create_rmq_client() as client: client.declare(self._queue, enable_ha=True, ttl=86400000)"," client.declare(self._queue, enable_ha=True, ttl=86400000)",2,1
openstack%2Fmurano~master~Iee3c39b7c4965d5b8015d458afb78c324dfd2826,openstack/murano,master,Iee3c39b7c4965d5b8015d458afb78c324dfd2826,Reduce number of API requests during deploy,MERGED,2014-08-12 23:10:55.000000000,2014-08-14 09:50:48.000000000,2014-08-14 09:50:48.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-08-12 23:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/455968b0be94f145961b30172af6880f35770be6', 'message': 'Reduce number of API requests during deploy\n\nFor every class name, a request is made to the API server to retrieve\nthe package to which it belongs. This is unnecessary, since a package\ncontains a list of the classes it owns. This patch adds a second cache\nto PackageClassLoader that maps class names to the package, and reduces\nthe number of calls for the io.murano classes to 1.\n\nA further improvenment (not yet made) is to not try to request system\nclasses (inbuilt ones) from the API at all.\n\nChange-Id: Iee3c39b7c4965d5b8015d458afb78c324dfd2826\n'}, {'number': 2, 'created': '2014-08-13 15:24:37.000000000', 'files': ['meta/io.murano/Classes/system/NetworkExplorer.yaml', 'meta/io.murano/Classes/system/AgentListener.yaml', 'meta/io.murano/Classes/system/Agent.yaml', 'murano/engine/package_class_loader.py', 'meta/io.murano/Classes/system/Resources.yaml', 'meta/io.murano/Classes/system/HeatStack.yaml', 'meta/io.murano/manifest.yaml', 'meta/io.murano/Classes/system/InstanceReportNotifier.yaml', 'meta/io.murano/Classes/system/StatusReporter.yaml'], 'web_link': 'https://opendev.org/openstack/murano/commit/c49a36d269a28dbacb897638a787981312bec8ac', 'message': 'Reduce number of API requests during deploy\n\nFor every class name, a request is made to the API server to retrieve\nthe package to which it belongs. This is unnecessary, since a package\ncontains a list of the classes it owns. This patch adds a second cache\nto PackageClassLoader that maps class names to the package, and reduces\nthe number of calls for the io.murano classes to 1.\n\nThe second improvement is to add blank YAML definitions for system\nclasses (the function definitions are in python code) which allows\nthe engine to cache those, too.\n\nChange-Id: Iee3c39b7c4965d5b8015d458afb78c324dfd2826\n'}]",0,113676,c49a36d269a28dbacb897638a787981312bec8ac,17,6,2,10063,,,0,"Reduce number of API requests during deploy

For every class name, a request is made to the API server to retrieve
the package to which it belongs. This is unnecessary, since a package
contains a list of the classes it owns. This patch adds a second cache
to PackageClassLoader that maps class names to the package, and reduces
the number of calls for the io.murano classes to 1.

The second improvement is to add blank YAML definitions for system
classes (the function definitions are in python code) which allows
the engine to cache those, too.

Change-Id: Iee3c39b7c4965d5b8015d458afb78c324dfd2826
",git fetch https://review.opendev.org/openstack/murano refs/changes/76/113676/2 && git format-patch -1 --stdout FETCH_HEAD,['murano/engine/package_class_loader.py'],1,455968b0be94f145961b30172af6880f35770be6,bugs/1334352," self._class_packages = {} def _get_package_for(self, class_name): package = self._class_packages.get(class_name, None) if package is None: package = self.package_loader.get_package_by_class(class_name) if package is not None: for cn in package.classes: self._class_packages[cn] = package return package package = self._get_package_for(name) app_pkg = self._get_package_for(class_name)", self._packages_cache = {} package = self.package_loader.get_package_by_class(name) app_pkg = self.package_loader.get_package_by_class(class_name),12,3
openstack%2Fmurano~master~I565caaae21925c48f2a0adea18036239cac91c77,openstack/murano,master,I565caaae21925c48f2a0adea18036239cac91c77,Allow murano-agent to be disabled,MERGED,2014-07-25 23:07:55.000000000,2014-08-14 09:49:18.000000000,2014-08-14 09:49:18.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-07-25 23:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f4cc817e1e3fe4e7f0240fd8829e51ade6a98f9d', 'message': ""Allow murano-agent to be disabled\n\nIn some circumstances murano-agent isn't required (e.g. in\nenvironments where heat SW config is capable alone of performing\nconfiguration). In this case it's not necessary to have the\nadditional overhead of rabbitMQ connections for the AgentListener\nthat will never receive a message.\n\nPatch adds a config option 'disable_murano_agent' that no-ops\nAgentLister.start() and raises an exception on Agent._send()\n\nChange-Id: I565caaae21925c48f2a0adea18036239cac91c77\nImplements: blueprint disable-murano-agent\n""}, {'number': 2, 'created': '2014-07-28 16:05:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/9ec0172c6955efd8f8b0a844150d175f42a546ec', 'message': ""Allow murano-agent to be disabled\n\nIn some circumstances murano-agent isn't required (e.g. in\nenvironments where heat SW config is capable alone of performing\nconfiguration). In this case it's not necessary to have the\nadditional overhead of rabbitMQ connections for the AgentListener\nthat will never receive a message.\n\nPatch adds a config option 'disable_murano_agent' that no-ops\nAgentLister.start() and raises an exception on Agent._send()\n\nChange-Id: I565caaae21925c48f2a0adea18036239cac91c77\nImplements: blueprint disable-murano-agent\n""}, {'number': 3, 'created': '2014-08-04 14:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f0b2f8e9b44bcb5cc4dde0227ebaf66121b5c181', 'message': ""Allow murano-agent to be disabled\n\nIn some circumstances murano-agent isn't required (e.g. in\nenvironments where heat SW config is capable alone of performing\nconfiguration). In this case it's not necessary to have the\nadditional overhead of rabbitMQ connections for the AgentListener\nthat will never receive a message.\n\nPatch adds a config option 'disable_murano_agent' that no-ops\nAgentLister.start() and raises an exception on Agent._send()\n\nChange-Id: I565caaae21925c48f2a0adea18036239cac91c77\nImplements: blueprint disable-murano-agent\n""}, {'number': 4, 'created': '2014-08-08 14:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/96edcaa9035cdfefe6e792d16db74dc883a0e43d', 'message': ""Allow murano-agent to be disabled\n\nIn some circumstances murano-agent isn't required (e.g. in\nenvironments where heat SW config is capable alone of performing\nconfiguration). In this case it's not necessary to have the\nadditional overhead of rabbitMQ connections for the AgentListener\nthat will never receive a message.\n\nPatch adds a config option 'disable_murano_agent' that no-ops\nAgentLister.start() and raises an exception on Agent._send()\n\nChange-Id: I565caaae21925c48f2a0adea18036239cac91c77\nImplements: blueprint disable-murano-agent\n""}, {'number': 5, 'created': '2014-08-12 15:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f8118d6ddf9b9a9ff79c3708f6796d87e45f9e67', 'message': ""Allow murano-agent to be disabled\n\nIn some circumstances murano-agent isn't required (e.g. in\nenvironments where heat SW config is capable alone of performing\nconfiguration). In this case it's not necessary to have the\nadditional overhead of rabbitMQ connections for the AgentListener\nthat will never receive a message.\n\nPatch adds a config option 'disable_murano_agent' that no-ops\nAgentLister.start() and raises an exception on Agent._send()\n\nChange-Id: I565caaae21925c48f2a0adea18036239cac91c77\nImplements: blueprint disable-murano-agent\n""}, {'number': 6, 'created': '2014-08-13 14:06:01.000000000', 'files': ['murano/tests/dsl/meta/AgentListenerTests.yaml', 'murano/common/config.py', 'murano/engine/system/agent.py', 'murano/tests/dsl/meta/AgentTests.yaml', 'murano/engine/system/agent_listener.py', 'etc/murano/murano.conf.sample', 'murano/tests/dsl/test_agent.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/e2bea76426cb1026b26f0fd932a8a01d942436e5', 'message': ""Allow murano-agent to be disabled\n\nIn some circumstances murano-agent isn't required (e.g. in\nenvironments where heat SW config is capable alone of performing\nconfiguration). In this case it's not necessary to have the\nadditional overhead of rabbitMQ connections for the AgentListener\nthat will never receive a message.\n\nPatch adds a config option 'disable_murano_agent' that no-ops\nAgentLister.start() and raises an exception on Agent._send()\n\nChange-Id: I565caaae21925c48f2a0adea18036239cac91c77\nImplements: blueprint disable-murano-agent\n""}]",2,109769,e2bea76426cb1026b26f0fd932a8a01d942436e5,48,7,6,10063,,,0,"Allow murano-agent to be disabled

In some circumstances murano-agent isn't required (e.g. in
environments where heat SW config is capable alone of performing
configuration). In this case it's not necessary to have the
additional overhead of rabbitMQ connections for the AgentListener
that will never receive a message.

Patch adds a config option 'disable_murano_agent' that no-ops
AgentLister.start() and raises an exception on Agent._send()

Change-Id: I565caaae21925c48f2a0adea18036239cac91c77
Implements: blueprint disable-murano-agent
",git fetch https://review.opendev.org/openstack/murano refs/changes/69/109769/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/common/config.py', 'murano/engine/system/agent.py', 'murano/engine/system/agent_listener.py', 'etc/murano/murano.conf.sample']",4,f4cc817e1e3fe4e7f0240fd8829e51ade6a98f9d,bp/disable-murano-agent,[engine] # Disallow the use of murano-agent #disable_murano_agent = False ,,44,0
openstack%2Ftempest~master~I04ae0cf942d12c4504b2df504a8c940575b90b69,openstack/tempest,master,I04ae0cf942d12c4504b2df504a8c940575b90b69,orchestration add volume backup/restore scenario test,ABANDONED,2014-04-24 16:50:37.000000000,2014-08-14 09:47:21.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 5196}, {'_account_id': 5292}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6796}, {'_account_id': 7193}, {'_account_id': 7350}, {'_account_id': 7872}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9542}, {'_account_id': 10090}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-24 16:50:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e300c736fe8df0f49d8a32ba28f0ae61380d31a3', 'message': 'orchestration add volume backup/restore API test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 2, 'created': '2014-05-07 11:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e0e95ec742595060c152da64831d3adf98ee42cf', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 3, 'created': '2014-05-07 11:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/38004b4eb66e12907a300e13728787c09957f05d', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 4, 'created': '2014-05-20 15:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3bfb286b3375b80c81e9e323a27b96fa42a77bc8', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 5, 'created': '2014-05-23 14:22:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/98b782d3dce43b3bce226143c1e03829cadfd349', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 6, 'created': '2014-05-23 14:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/73081bb1fc8f5ed3f22db872f182b95a38c8c8cf', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 7, 'created': '2014-06-02 09:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aae8c4b9568e263e4e1a88552fe6e6fb36ef4ae0', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 8, 'created': '2014-06-19 12:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/698c166fc1739f8245592bcad7b3d0560cfeab73', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 9, 'created': '2014-06-19 14:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0280209421587e7ef5449002f7ccb578ff92dd39', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 10, 'created': '2014-06-19 14:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/62115467f83c6d73547c40402b0f61d67f04607a', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 11, 'created': '2014-06-27 09:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4ff5d4c4ac7ba7de753432e1596cab235803b56b', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 12, 'created': '2014-06-30 20:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e868d96bd29c7c180204a3b9bc8e476a9d99a11a', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 13, 'created': '2014-07-01 09:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b120e95e25faec8e3336cfa0ce566929ab263899', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 14, 'created': '2014-07-03 18:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2a2f3544ef37c91eff1f740d6e68953d4cbe7ce2', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 15, 'created': '2014-07-07 20:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3f198e869067d1bd4d235ac5ead7798ca3023171', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 16, 'created': '2014-07-08 10:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ac2287f722249b8eb69fafea526e1a0228d86376', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}, {'number': 17, 'created': '2014-07-09 17:05:47.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/scenario/orchestration/test_volumes_delete_snapshot.yaml', 'etc/tempest.conf.sample', 'tempest/config.py', 'tempest/scenario/orchestration/test_volumes.py', 'tempest/scenario/orchestration/test_volumes_create_from_backup.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4ceb24d5ef22e6f3fb1947b5d9cb8fd79f7fdf80', 'message': 'orchestration add volume backup/restore scenario test\n\nAdds a more comprehensive test for the cinder volume resources:\n- Creates a stack with a volume, and writes data to it\n- Deletes the stack with the volume deletion policy set to\n  ""snapshot"" (which really means backup) the volume\n- Create a new stack with a volume created from the backup\n- Prove the data written in the first stack is still present\n\nNote this test also aims to provide coverage of volume attachment\nresources, e.g so we would catch any bugs like bug #1311533 in\nfuture.\n\nChange-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69\nRelated-Bug: #1311533\n'}]",38,90143,4ceb24d5ef22e6f3fb1947b5d9cb8fd79f7fdf80,195,21,17,4328,,,0,"orchestration add volume backup/restore scenario test

Adds a more comprehensive test for the cinder volume resources:
- Creates a stack with a volume, and writes data to it
- Deletes the stack with the volume deletion policy set to
  ""snapshot"" (which really means backup) the volume
- Create a new stack with a volume created from the backup
- Prove the data written in the first stack is still present

Note this test also aims to provide coverage of volume attachment
resources, e.g so we would catch any bugs like bug #1311533 in
future.

Change-Id: I04ae0cf942d12c4504b2df504a8c940575b90b69
Related-Bug: #1311533
",git fetch https://review.opendev.org/openstack/tempest refs/changes/43/90143/8 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/orchestration/stacks/test_volumes.py', 'tempest/api/orchestration/stacks/templates/cinder_delete_snapshot.yaml', 'tempest/api/orchestration/base.py', 'tempest/api/orchestration/stacks/templates/cinder_create_from_backup.yaml']",4,e300c736fe8df0f49d8a32ba28f0ae61380d31a3,bug/1311533,"heat_template_version: 2013-05-23 parameters: key_name: type: string description: keypair to enable SSH access to the instance. instance_type: type: string description: Type of the instance to be created. default: m1.small image_id: type: string description: ID of the image to use for the instance to be created. timeout: type: number description: Stack creation timeout dev_name: type: string description: Expected device name for volume default: vdb rescan_timeout: type: number description: Max number of seconds to wait for volume after rescan default: 10 backup_id: type: string description: backup_id to create volume from resources: volume: type: OS::Cinder::Volume properties: backup_id: { get_param: backup_id } description: a descriptive description volume_attachment: type: OS::Cinder::VolumeAttachment properties: volume_id: { get_resource: volume } instance_uuid: { get_resource: instance } instance: type: OS::Nova::Server properties: image: { get_param: image_id } flavor: { get_param: instance_type } key_name: { get_param: key_name } user_data_format: RAW user_data: str_replace: template: | #!/bin/sh # Trigger rescan to ensure we see the attached volume for i in /sys/class/scsi_host/*; do echo ""- - -"" > $i/scan; done # Wait for the rescan as the volume doesn't appear immediately for i in $(seq 1 rescan_timeout) do grep -q dev_name /proc/partitions && break sleep 1 done if grep -q dev_name /proc/partitions then mount /dev/dev_name /mnt TESTDATA=$(cat /mnt/testfile) curl -X PUT -H 'Content-Type:' --data-binary '{""Status"": ""SUCCESS"", ""Reason"": ""Test Complete"", ""Data"": ""Volume Data:'$TESTDATA'"", ""UniqueId"": ""instance1""}' ""wc_url"" else curl -X PUT -H 'Content-Type:' --data-binary '{""Status"": ""FAILURE"", ""Reason"": ""Test Failed"", ""Data"": ""Expected device dev_name not found."", ""UniqueId"": ""instance1""}' ""wc_url"" fi params: wc_url: { get_resource: wait_handle } dev_name: { get_param: dev_name } rescan_timeout: { get_param: rescan_timeout } wait_handle: type: OS::Heat::UpdateWaitConditionHandle wait_condition: type: AWS::CloudFormation::WaitCondition properties: Count: 1 Handle: { get_resource: wait_handle } Timeout: { get_param: timeout } outputs: status: description: status value: { get_attr: ['volume', 'status'] } size: description: size value: { get_attr: ['volume', 'size'] } display_description: description: display_description value: { get_attr: ['volume', 'display_description'] } volume_id: value: { get_resource: volume } testfile_data: description: Contents of /mnt/testfile from the mounted volume value: { get_attr: ['wait_condition', 'Data'] } ",,306,4
openstack%2Fopenstack-manuals~master~I82d5438fcf8d249856eeac1f4e323b6e9b212435,openstack/openstack-manuals,master,I82d5438fcf8d249856eeac1f4e323b6e9b212435,Remove duplicate footer,MERGED,2014-08-14 08:51:25.000000000,2014-08-14 09:20:50.000000000,2014-08-14 09:20:50.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-14 08:51:25.000000000', 'files': ['www/trunk/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c1ed605042ba294f9007786469353c139c796527', 'message': 'Remove duplicate footer\n\nhttp://docs.openstack.org/trunk/ has a duplicate footer, remove it.\n\nChange-Id: I82d5438fcf8d249856eeac1f4e323b6e9b212435\n'}]",0,114169,c1ed605042ba294f9007786469353c139c796527,9,4,1,6547,,,0,"Remove duplicate footer

http://docs.openstack.org/trunk/ has a duplicate footer, remove it.

Change-Id: I82d5438fcf8d249856eeac1f4e323b6e9b212435
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/69/114169/1 && git format-patch -1 --stdout FETCH_HEAD,['www/trunk/index.html'],1,c1ed605042ba294f9007786469353c139c796527,fix-footer,,"<div class=""container""> <div id=""footer""> <hr/> <p> Documentation treated like code, powered by the community - interested? Here's <a href=""http://wiki.openstack.org/Documentation/HowTo""> how to contribute </a> . </p> <p> The OpenStack project is provided under the Apache 2.0 license. Openstack.org is powered by <a href=""http://www.rackspacecloud.com/""> Rackspace Cloud Computing </a> . </p> </div> </div>",0,19
openstack%2Foslo-incubator~master~I8926ff3157f86ea2a28f558420dbb27f0a09746c,openstack/oslo-incubator,master,I8926ff3157f86ea2a28f558420dbb27f0a09746c,Set python hash seed to 0 in tox.ini,MERGED,2014-08-13 23:11:44.000000000,2014-08-14 09:00:36.000000000,2014-08-14 09:00:36.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-08-13 23:11:44.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/ebbdcad9d23e6fd7e2e9328a0ef270f369a08c86', 'message': ""Set python hash seed to 0 in tox.ini\n\nNew tox (>=1.7.0) sets a random python hash seed by default. This is\ngenerally good for testing because it will help keep projects working\nregardless of the hash seed, but incubator unittests don't currently\npass with a random hash seed so set it to the python default seed.\n\nThis change will allow us to use new tox again and remove the\nrestriction on tox<=1.6.1 to run unittests.\n\nRedundant setenvs for specific test envs are removed to prevent them\nfrom overriding the PYTHONHASHSEED value.\n\nNote this change will need to be backported to the stable branches to\nkeep unittests there working with new tox as well.\n\nChange-Id: I8926ff3157f86ea2a28f558420dbb27f0a09746c\n""}]",0,114052,ebbdcad9d23e6fd7e2e9328a0ef270f369a08c86,8,3,1,4146,,,0,"Set python hash seed to 0 in tox.ini

New tox (>=1.7.0) sets a random python hash seed by default. This is
generally good for testing because it will help keep projects working
regardless of the hash seed, but incubator unittests don't currently
pass with a random hash seed so set it to the python default seed.

This change will allow us to use new tox again and remove the
restriction on tox<=1.6.1 to run unittests.

Redundant setenvs for specific test envs are removed to prevent them
from overriding the PYTHONHASHSEED value.

Note this change will need to be backported to the stable branches to
keep unittests there working with new tox as well.

Change-Id: I8926ff3157f86ea2a28f558420dbb27f0a09746c
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/52/114052/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ebbdcad9d23e6fd7e2e9328a0ef270f369a08c86,set-hash-seed, PYTHONHASHSEED=0,setenv = VIRTUAL_ENV={envdir}setenv = VIRTUAL_ENV={envdir}setenv = PYTHONHASHSEED=0,1,3
openstack%2Ftripleo-specs~master~I437157099f9e44b91ab99557ec51b4c18dbe63e4,openstack/tripleo-specs,master,I437157099f9e44b91ab99557ec51b4c18dbe63e4,Keystone setup as part of Overcloud Heat template,ABANDONED,2014-08-05 11:34:58.000000000,2014-08-14 08:57:52.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 7585}, {'_account_id': 8042}, {'_account_id': 9712}]","[{'number': 1, 'created': '2014-08-05 11:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/1cba9d47797745bdf93c596b833ff6bfb3405c6f', 'message': 'Keystone init & setup endpoints as part of Overcloud Heat template\n\nThis spec covers a transformation for having init keystone\noperations as part of heat stack-create process. Including\nall the necesary operations for making the change backwards\ncompatible.\n\nChange-Id: I437157099f9e44b91ab99557ec51b4c18dbe63e4\n'}, {'number': 2, 'created': '2014-08-05 14:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/31fee1ef78df1025d04980ec4ec5705649aee4c9', 'message': 'Keystone init & setup endpoints as part of Overcloud Heat template\n\nThis spec covers a transformation for having init keystone\noperations as part of heat stack-create process. Including\nall the necesary operations for making the change backwards\ncompatible.\n\nChange-Id: I437157099f9e44b91ab99557ec51b4c18dbe63e4\n'}, {'number': 3, 'created': '2014-08-05 14:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/f5bcde9a75f4ab823b48979c252e81aaaabe4990', 'message': 'Keystone setup as part of Overcloud Heat template\n\nThis spec covers a transformation for having init keystone\noperations as part of heat stack-create process. Including\nall the necesary operations for making the change backwards\ncompatible.\n\nChange-Id: I437157099f9e44b91ab99557ec51b4c18dbe63e4\n'}, {'number': 4, 'created': '2014-08-08 07:13:19.000000000', 'files': ['specs/juno/tripleo-juno-keystone-setup-inside-template.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/d6b7b53047a542adcb7abea01175fd28f51eda72', 'message': 'Keystone setup as part of Overcloud Heat template\n\nThis spec covers a transformation for having init keystone\noperations as part of heat stack-create process. Including\nall the necesary operations for making the change backwards\ncompatible.\n\nChange-Id: I437157099f9e44b91ab99557ec51b4c18dbe63e4\n'}]",28,111985,d6b7b53047a542adcb7abea01175fd28f51eda72,28,6,4,7585,,,0,"Keystone setup as part of Overcloud Heat template

This spec covers a transformation for having init keystone
operations as part of heat stack-create process. Including
all the necesary operations for making the change backwards
compatible.

Change-Id: I437157099f9e44b91ab99557ec51b4c18dbe63e4
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/85/111985/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/tripleo-juno-keystone-setup-inside-template.rst'],1,1cba9d47797745bdf93c596b833ff6bfb3405c6f,master,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================================================================== Keystone init and setup endpoints as part of Overcloud Heat Template ==================================================================== https://blueprints.launchpad.net/tripleo/+spec/tripleo-juno-keystone-setup-inside-template Make the keystone-init and setup-endpoints part of Heat template deployment Problem Description =================== 1. Having setup-endpoints as separate operation after heat-stack-create makes it problematic for the UI. UI doesn't have temporary storage for passwords that needs to be passed to keystone after the deployment. 2. The most probable future is that the service passwords will be generated inside Heat, so they will not be accessible to the outside world, which means we have to do the init-keystone and setup-endpoints as part of heat stack-create. (passwords would have to be in stack output in raw format, to be accessible to the outside world, which is very bad idea not only because of security reasons) Proposed Change =============== 1. Delete or make optional code for pki init https://github.com/openstack/os-cloud-config/blob/master/os_cloud_config/keystone.py#L46 Certificates are now passed via parameters, so this code is obsolete. 2. Make sure init code starting in here https://github.com/openstack/tripleo-incubator/blob/master/scripts/devtest_overcloud.sh#L415, namely init-keystone, setup-endpoints and keystone role-create, does not create duplicate content when running twice. This way we can temporarily have both ways of init. 3. Creating image element with os-cloud-config 4. Making os-cloud-config available on the Controller node so it's callable from the Template 5. Add software config as after create hook to the Heat template for Controller running init-keystone, setup-endpoints and keystone role-create. Making sure it is running just on one controller node. 6. Delete init-keystone, setup-endpoints and keystone role-create code from https://github.com/openstack/tripleo-incubator/blob/master/scripts/devtest_overcloud.sh#L415 Alternatives ------------ None Security Impact --------------- None Other End User Impact --------------------- None Performance Impact ------------------ This means more logic putted into heat stack-create. Thought it's really just few keystone API calls which will have negligible effect on the performance. Other Deployer Impact --------------------- None Developer Impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: lsmola Work Items ---------- tripleo-incubator ^^^^^^^^^^^^^^^^^ * Making os-cloud-config available on the Controller node so it's callable from the Template. * Delete init-keystone, setup-endpoints and keystone role-create code from https://github.com/openstack/tripleo-incubator/blob/master/scripts/devtest_overcloud.sh#L415 os-cloud-config ^^^^^^^^^^^^^^^ * Delete or make optional code for pki init https://github.com/openstack/os-cloud-config/blob/master/os_cloud_config/keystone.py#L46 Certificates are now passed via parameters, so this code is obsolete. * Make sure init code starting in here https://github.com/openstack/tripleo-incubator/blob/master/scripts/devtest_overcloud.sh#L415, namely init-keystone, setup-endpoints and keystone role-create, does not create duplicate content when running twice. This way we can temporarily have both ways of init. tripleo-image-elements ^^^^^^^^^^^^^^^^^^^^^^ * Creating image element with os-cloud-config. tripleo-heat-templates ^^^^^^^^^^^^^^^^^^^^^^ * Add software config as after create hook to the Heat template for Controller running init-keystone, setup-endpoints and keystone role-create. Making sure it is running just on one controller node. Dependencies ============ None Testing ======= The test if Overcloud is initialized correctly is already done by deploying testing VMs in devtest_overcloud script. Documentation Impact ==================== None References ========== None ",,125,0
openstack%2Fmurano~master~I390806b7e2d09f18ab3c496178406e1a3fc8d899,openstack/murano,master,I390806b7e2d09f18ab3c496178406e1a3fc8d899,Default is_public to false,MERGED,2014-07-23 23:40:30.000000000,2014-08-14 08:56:32.000000000,2014-08-14 08:56:32.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-07-23 23:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/dcb1ae26527a287718525fb8d6072f12b660e040', 'message': 'Default is_public to false\n\nSets is_public=false in the database model, adds is_public querystring\nto API and policy check for it. Will need corresponding client change.\n\nRelies on changes in https://review.openstack.org/#/c/109151/ (mainly\nfor unit test refactoring).\n\nChange-Id: I390806b7e2d09f18ab3c496178406e1a3fc8d899\nCloses-Bug: #1331243\n'}, {'number': 2, 'created': '2014-07-28 21:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/6655779a7ab693d366b85e0339cc7068d1d01cb4', 'message': 'Default is_public to false\n\nSets is_public=false in the database model, adds is_public querystring\nto API and policy check for it. Will need corresponding client change.\n\nRelies on changes in https://review.openstack.org/#/c/109151/ (mainly\nfor unit test refactoring).\n\nChange-Id: I390806b7e2d09f18ab3c496178406e1a3fc8d899\nCloses-Bug: #1331243\n'}, {'number': 3, 'created': '2014-07-28 21:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/d14d9e757ce752e9a4a0978d57dfed32692c9dad', 'message': 'Default is_public to false\n\nSets is_public=false in the database model, adds is_public querystring\nto API and policy check for it. Will need corresponding client change.\n\nRelies on changes in https://review.openstack.org/#/c/109151/ (mainly\nfor unit test refactoring).\n\nChange-Id: I390806b7e2d09f18ab3c496178406e1a3fc8d899\nCloses-Bug: #1331243\n'}, {'number': 4, 'created': '2014-07-29 15:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/511438cc85a5cbbbd49ab249d6062848211f878e', 'message': 'Default is_public to false\n\nSets is_public=false in the database model, adds is_public querystring\nto API and policy check for it. Will need corresponding client change.\n\nDoes not include an alembic migration because altering columns is\napparently difficult, and removing/adding does more damage than good.\nNew objects should have is_public set to False by the db model.\n\nRelies on changes in https://review.openstack.org/#/c/109151/ (mainly\nfor unit test refactoring).\n\nChange-Id: I390806b7e2d09f18ab3c496178406e1a3fc8d899\nCloses-Bug: #1331243\n'}, {'number': 5, 'created': '2014-07-31 16:01:59.000000000', 'files': ['murano/tests/unit/api/v1/test_catalog.py', 'murano/api/v1/catalog.py', 'murano/db/models.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/f5daa12347268a53fafae08cff285a76b3abdf93', 'message': 'Default is_public to false\n\nSets is_public=false in the database model, adds is_public querystring\nto API and policy check for it. Will need corresponding client change.\n\nDoes not include an alembic migration because altering columns is\napparently difficult, and removing/adding does more damage than good.\nNew objects should have is_public set to False by the db model.\n\nRelies on changes in https://review.openstack.org/#/c/109151/ (mainly\nfor unit test refactoring).\n\nChange-Id: I390806b7e2d09f18ab3c496178406e1a3fc8d899\nCloses-Bug: #1331243\n'}]",2,109153,f5daa12347268a53fafae08cff285a76b3abdf93,40,6,5,10063,,,0,"Default is_public to false

Sets is_public=false in the database model, adds is_public querystring
to API and policy check for it. Will need corresponding client change.

Does not include an alembic migration because altering columns is
apparently difficult, and removing/adding does more damage than good.
New objects should have is_public set to False by the db model.

Relies on changes in https://review.openstack.org/#/c/109151/ (mainly
for unit test refactoring).

Change-Id: I390806b7e2d09f18ab3c496178406e1a3fc8d899
Closes-Bug: #1331243
",git fetch https://review.opendev.org/openstack/murano refs/changes/53/109153/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/api/v1/catalog.py', 'murano/db/models.py', 'murano/db/migration/alembic_migrations/versions/2ecbc21b2d64_package_is_public_default_false.py', 'murano/tests/api/v1/test_catalog.py']",4,dcb1ae26527a287718525fb8d6072f12b660e040,bug/1331243,"import cgi import cStringIOimport os import webob def _test_package(self): return pkg, package def test_load_package_with_supplier_info(self): self._set_policy_rules( {'get_package': '@'} ) package_from_dir, package = self._test_package() self.expect_policy_check('get_package', {'package_id': saved_package.id}) def test_add_public_unauthorized(self): policy.set_rules({ 'upload_package': '@', 'publicize_package': 'role:is_admin or is_admin:True' }) self.expect_policy_check('upload_package') self.expect_policy_check('publicize_image') self.expect_policy_check('upload_package') self.expect_policy_check('publicize_image') file_obj_str = cStringIO.StringIO(""This is some dummy data"") file_obj = mock.MagicMock(cgi.FieldStorage) file_obj.file = file_obj_str package_from_dir, package_metadata = self._test_package() body = '''\ --BOUNDARY Content-Disposition: form-data; name=""ziparchive"" Content-Type: text/plain: This is a fake zip archive --BOUNDARY Content-Disposition: form-data; name=""metadata""; filename=""test.json"" Content-Type: application/json %s --BOUNDARY--''' % package_metadata with mock.patch('murano.packages.load_utils.load_from_file') as lff: lff.return_value = package_from_dir req = self._post('/catalog/packages', body, content_type='multipart/form-data; ; boundary=BOUNDARY', params={""is_public"": ""true""}) res = req.get_response(self.api) # Nobody has access to upload public images self.assertEquals(403, res.status_code) self.is_admin = True req = self._post('/catalog/packages', body, content_type='multipart/form-data; ; boundary=BOUNDARY', params={""is_public"": ""true""}) res = req.get_response(self.api) ","import os @mock.patch.object(policy, 'check') def test_load_package_with_supplier_info(self, mock_policy_check):",111,4
openstack%2Fironic~master~I756f78bd8d8976a638169ee9db712a95dc664b58,openstack/ironic,master,I756f78bd8d8976a638169ee9db712a95dc664b58,Use valid exception in start_shellinabox_console,MERGED,2014-08-13 15:43:40.000000000,2014-08-14 08:49:36.000000000,2014-08-14 08:49:35.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 7711}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-08-13 15:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/667c9bed5e467ef8b37d68bc8179fdb8036e677f', 'message': 'Use valid exceptions in start_shellinabox_console\n\nReplaces non-existing exceptions exception.ProcessExecutionError\nand exception.UnknownArgumentError with the correct exceptions\nfrom processutils.\n\nAdds a unit test that checks for this.\n\nChange-Id: I756f78bd8d8976a638169ee9db712a95dc664b58\nCloses-Bug: #1356408\n'}, {'number': 2, 'created': '2014-08-13 16:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2f7b2501f38203503fd95b8672f84b45bd04771c', 'message': ""Use valid exception in start_shellinabox_console\n\nReplace non-existing exception exception.ProcessExecutionError\nwith the correct exception from processutils.\n\nRemove non-existing exception exception.UnknownArgumentError\nbecause it was meant to be processutils.UnknownArgumentError\nhich isn't needed since it is only raised if there are\nunknown arguments in kwargs, which there aren't in this case\n(only 'check_exit_code' is there.)\n\nAdds a unit test that checks for the ProcessExecutionError\nexception.\n\nChange-Id: I756f78bd8d8976a638169ee9db712a95dc664b58\nCloses-Bug: #1356408\n""}, {'number': 3, 'created': '2014-08-13 16:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a8b035d476399507cbf44f9a21f97a496c3d524b', 'message': ""Use valid exception in start_shellinabox_console\n\nReplace non-existing exception exception.ProcessExecutionError\nwith the correct exception from processutils.\n\nRemove non-existing exception exception.UnknownArgumentError\nbecause it was meant to be processutils.UnknownArgumentError\nwhich isn't needed since it is only raised if there are\nunknown arguments in kwargs, which there aren't in this case\n(only 'check_exit_code' is there.)\n\nAdds a unit test that checks for the ProcessExecutionError\nexception.\n\nChange-Id: I756f78bd8d8976a638169ee9db712a95dc664b58\nCloses-Bug: #1356408\n""}, {'number': 4, 'created': '2014-08-13 22:10:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6c951ea1dc22afb96543c31c8a165f1c25d95516', 'message': ""Use valid exception in start_shellinabox_console\n\nReplace non-existing exception exception.ProcessExecutionError\nwith the correct exception from processutils.\n\nRemove non-existing exception exception.UnknownArgumentError\nbecause it was meant to be processutils.UnknownArgumentError\nhich isn't needed since it is only raised if there are\nunknown arguments in kwargs, which there aren't in this case\n(only 'check_exit_code' is there.)\n\nAdds a unit test that checks for the ProcessExecutionError\nexception.\n\nChange-Id: I756f78bd8d8976a638169ee9db712a95dc664b58\nCloses-Bug: #1356408\n""}, {'number': 5, 'created': '2014-08-13 22:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bc137537b8db1b3bf5a2386a68d0113413fd8a03', 'message': ""Use valid exception in start_shellinabox_console\n\nReplace non-existing exception exception.ProcessExecutionError\nwith the correct exception from processutils.\n\nRemove non-existing exception exception.UnknownArgumentError\nbecause it was meant to be processutils.UnknownArgumentError\nwhich isn't needed since it is only raised if there are\nunknown arguments in kwargs, which there aren't in this case\n(only 'check_exit_code' is there.)\n\nAdds a unit test that checks for the ProcessExecutionError\nexception.\n\nChange-Id: I756f78bd8d8976a638169ee9db712a95dc664b58\nCloses-Bug: #1356408\n""}, {'number': 6, 'created': '2014-08-13 23:37:06.000000000', 'files': ['ironic/drivers/modules/console_utils.py', 'ironic/tests/drivers/test_console_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1b526e1f4836327350a97b4a9569b2f4a2a6f6c9', 'message': ""Use valid exception in start_shellinabox_console\n\nReplace non-existing exception exception.ProcessExecutionError\nwith the correct exception from processutils.\n\nRemove non-existing exception exception.UnknownArgumentError\nbecause it was meant to be processutils.UnknownArgumentError\nwhich isn't needed since it is only raised if there are\nunknown arguments in kwargs, which there aren't in this case\n(only 'check_exit_code' is there.)\n\nAdds a unit test that checks for the ProcessExecutionError\nexception.\n\nChange-Id: I756f78bd8d8976a638169ee9db712a95dc664b58\nCloses-Bug: #1356408\n""}]",2,113939,1b526e1f4836327350a97b4a9569b2f4a2a6f6c9,26,6,6,6618,,,0,"Use valid exception in start_shellinabox_console

Replace non-existing exception exception.ProcessExecutionError
with the correct exception from processutils.

Remove non-existing exception exception.UnknownArgumentError
because it was meant to be processutils.UnknownArgumentError
which isn't needed since it is only raised if there are
unknown arguments in kwargs, which there aren't in this case
(only 'check_exit_code' is there.)

Adds a unit test that checks for the ProcessExecutionError
exception.

Change-Id: I756f78bd8d8976a638169ee9db712a95dc664b58
Closes-Bug: #1356408
",git fetch https://review.opendev.org/openstack/ironic refs/changes/39/113939/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/console_utils.py', 'ironic/tests/drivers/test_console_utils.py']",2,667c9bed5e467ef8b37d68bc8179fdb8036e677f,bug/1267693-console,"from ironic.openstack.common import processutils @mock.patch.object(subprocess, 'Popen', autospec=True) @mock.patch.object(utils, 'execute') def test_start_shellinabox_console_fail_oldpid(self, mock_execute, mock_popen): mock_execute.side_effect = processutils.ProcessExecutionError() mock_popen.return_value.poll.return_value = 1 mock_popen.return_value.communicate.return_value = ('output', 'error') pid_file = console_utils._get_console_pid_file(self.info['uuid']) f = open(pid_file, 'w') f.write('2345') f.close() self.assertTrue(os.path.exists(pid_file)) self.assertRaises(exception.ConsoleSubprocessFailed, console_utils.start_shellinabox_console, self.info['uuid'], self.info['port'], 'ls&') self.assertFalse(os.path.exists(pid_file)) mock_execute.assert_called_once_with('kill', '2345', check_exit_code=[0, 99]) mock_popen.assert_called_once_with(mock.ANY, stdout=subprocess.PIPE, stderr=subprocess.PIPE) mock_popen.return_value.poll.assert_called_once_with()",,33,1
openstack%2Fmanila~master~I23557b768c53de0fb56c8dbbfe63f6baa5831ec5,openstack/manila,master,I23557b768c53de0fb56c8dbbfe63f6baa5831ec5,Fix bad indentation in manila,MERGED,2014-08-13 18:58:02.000000000,2014-08-14 08:35:06.000000000,2014-08-14 08:35:05.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 8851}, {'_account_id': 9064}]","[{'number': 1, 'created': '2014-08-13 18:58:02.000000000', 'files': ['manila/tests/fake_network.py', 'manila/share/drivers/netapp/cluster_mode.py', 'manila/tests/api/contrib/test_services.py', 'manila/tests/api/contrib/test_share_actions.py', 'manila/tests/test_migrations.py', 'manila/share/drivers/generic.py', 'manila/share/configuration.py', 'manila/share/drivers/netapp/driver.py', 'manila/tests/test_share_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/2c950c49432f8a2d0a607eebaad4401a414b3349', 'message': 'Fix bad indentation in manila\n\nCloses-Bug: #1356524\n\nChange-Id: I23557b768c53de0fb56c8dbbfe63f6baa5831ec5\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>\n'}]",0,113995,2c950c49432f8a2d0a607eebaad4401a414b3349,15,4,1,9064,,,0,"Fix bad indentation in manila

Closes-Bug: #1356524

Change-Id: I23557b768c53de0fb56c8dbbfe63f6baa5831ec5
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>
",git fetch https://review.opendev.org/openstack/manila refs/changes/95/113995/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/fake_network.py', 'manila/share/drivers/netapp/cluster_mode.py', 'manila/tests/api/contrib/test_services.py', 'manila/tests/api/contrib/test_share_actions.py', 'manila/tests/test_migrations.py', 'manila/share/drivers/generic.py', 'manila/share/configuration.py', 'manila/share/drivers/netapp/driver.py', 'manila/tests/test_share_glusterfs.py']",9,2c950c49432f8a2d0a607eebaad4401a414b3349,bug/1356524, raise exception.ProcessExecutionError(stderr='testvol'), raise exception.ProcessExecutionError(stderr='testvol'),41,41
openstack%2Fopenstack-doc-tools~master~Ib11f1a7aefd41a595eeb810d0c7d2fbf75d51c85,openstack/openstack-doc-tools,master,Ib11f1a7aefd41a595eeb810d0c7d2fbf75d51c85,Handle exceptions of handle_options,MERGED,2014-08-12 16:44:56.000000000,2014-08-14 08:32:38.000000000,2014-08-14 08:32:37.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-12 16:44:56.000000000', 'files': ['os_doc_tools/doctest.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/3d088cdbb7f2d8b8a67b4546d7293677aa8c17cf', 'message': 'Handle exceptions of handle_options\n\nFor example if the specified configuration file is not available the\nexception should be handled correctly.\n\nChange-Id: Ib11f1a7aefd41a595eeb810d0c7d2fbf75d51c85\n'}]",0,113584,3d088cdbb7f2d8b8a67b4546d7293677aa8c17cf,9,2,1,167,,,0,"Handle exceptions of handle_options

For example if the specified configuration file is not available the
exception should be handled correctly.

Change-Id: Ib11f1a7aefd41a595eeb810d0c7d2fbf75d51c85
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/84/113584/1 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/doctest.py'],1,3d088cdbb7f2d8b8a67b4546d7293677aa8c17cf,handle_options_exception, try: handle_options() except cfg.Error as e: print(e) return 1, handle_options(),5,2
openstack%2Fopenstack-manuals~master~I2f0c61006ef8885e157eb2b800080407f2bae393,openstack/openstack-manuals,master,I2f0c61006ef8885e157eb2b800080407f2bae393,Use a static site generator to generate content in www,MERGED,2014-08-06 08:41:14.000000000,2014-08-14 08:23:50.000000000,2014-08-14 08:23:49.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-06 08:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3617cf4a8fd767642636e617885fd370d942bc4a', 'message': ""WIP: Use a static site generator to generate index pages\n\nThis is just a demonstration how we could generate our index pages\nusing the static site generator Wok (http://wok.mythmon.com/).\n\nTo generate the index page of http://docs.openstack.org first install\nWok with 'pip install wok'. Then run 'wok' inside the 'www' directory.\nThe output will be available in the directory 'output'.\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n""}, {'number': 2, 'created': '2014-08-09 08:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/20264bf675e473d6cf87a40fb0c7b085f6f0312d', 'message': 'WIP: Use a static site generator to generate index pages\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 3, 'created': '2014-08-09 08:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/aa9f1875dc525b2bf1a5472e1dfb01ae66ec5233', 'message': 'WIP: Use a static site generator to generate index pages\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 4, 'created': '2014-08-09 09:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0253e4ec6940e3f7a7ce86b0abae3fde8d16b3e3', 'message': 'WIP: Use a static site generator to generate index pages\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 5, 'created': '2014-08-09 12:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/de097d8287b56b2eae8ae9483a5b268898215b04', 'message': 'WIP: Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 6, 'created': '2014-08-09 12:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/71a47d4f2d92acef200fc503a837b8020f896237', 'message': 'WIP: Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 7, 'created': '2014-08-09 14:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/61b34d41b26845e0889379f9c85f274c08e4f9da', 'message': 'WIP: Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 8, 'created': '2014-08-09 14:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2db04ee0f2c2b45a16e1c1b522aa19094fcf8ea9', 'message': 'Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 9, 'created': '2014-08-09 15:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/183accaee6bf0bda9f638bcb0ab844086060cadf', 'message': 'Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 10, 'created': '2014-08-09 15:40:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7170a14266aae3a1c0af8a112e935d047e26139b', 'message': 'Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 11, 'created': '2014-08-11 07:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/18461b0de0cbbe0da17774235e243edfe947ecbb', 'message': 'Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 12, 'created': '2014-08-11 07:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bff2e7bebb9080c793a32c5cb2f30f67f3d5bcc8', 'message': 'Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 13, 'created': '2014-08-11 07:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9c9471db2c26f648c00278915ccf2e2a1780593e', 'message': 'Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 14, 'created': '2014-08-11 07:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0e8fcd746f4a2ecb8e294bf151cf14da530f54f8', 'message': 'Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 15, 'created': '2014-08-11 16:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/836e886634bd35d6ac1f42446dfd5b4d24838400', 'message': 'Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 16, 'created': '2014-08-11 20:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b300cf4f6cf1e88275314da3f0411b0a7b1dc088', 'message': 'Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}, {'number': 17, 'created': '2014-08-14 08:02:29.000000000', 'files': ['www/static/common/images/search-icon.png', 'www/static/common/jquery/treeview/jquery.treeview.js', 'test-requirements.txt', 'www/static/common/jquery/treeview/jquery.treeview.css', 'www/static/sitemap.xml', 'www/trunk/index.html', 'www/developer/language-bindings.html', 'www/static/common/jquery/jquery-ui-1.8.2.custom.min.js', 'www/static/common/jquery/theme-redmond/images/ui-anim_basic_16x16.gif', 'www/static/common/jquery/theme-redmond/images/ui-bg_inset-hard_100_fcfdfd_1x100.png', 'www/static/common/images/loading.gif', 'www/static/common/images/openstack-manual.png', 'www/static/common/jquery/theme-redmond/images/ui-bg_glass_95_fef1ec_1x400.png', 'www/static/common/jquery/jquery.cookie.js', 'www/static/common/css/positioning.css', 'www/templates/script_header.tmpl', 'www/templates/base.tmpl', 'www/draft-i18n-manuals.html', 'www/static/common/images/paperclip.gif', 'www/static/common/images/highlighter.png', 'www/static/common/jquery/theme-redmond/images/ui-bg_inset-hard_100_f5f8f9_1x100.png', 'www/templates/default.tmpl', 'www/templates/header.tmpl', 'www/static/common/jquery/theme-redmond/images/ui-icons_2e83ff_256x240.png', 'www/static/common/jquery/jquery.hoverIntent.minified.js', 'www/templates/css.tmpl', 'www/templates/footer.tmpl', 'www/static/common/jquery/treeview/images/treeview-famfamfam-line.gif', 'www/static/common/jquery/treeview/images/treeview-famfamfam.gif', 'www/static/common/jquery/theme-redmond/images/ui-icons_6da8d5_256x240.png', 'www/static/common/jquery/treeview/images/page_white_text.png', 'www/static/common/jquery/treeview/jquery.treeview.pack.js', 'www/static/common/jquery/treeview/images/plus.gif', 'www/static/common/jquery/treeview/images/folder.gif', 'www/templates/navigation.tmpl', 'www/static/common/jquery/treeview/images/minus.gif', 'www/static/common/jquery/treeview/images/file.gif', 'www/static/common/images/compute-admin.png', 'www/static/common/jquery/jTweetsAnywhere/jquery.jtweetsanywhere-1.2.1.css', 'www/static/common/jquery/theme-redmond/jquery-ui-1.8.2.custom.css', 'www/static/common/main.js', 'www/static/common/images/page_white_text.png', 'www/static/common/jquery/theme-redmond/images/ui-bg_glass_85_dfeffc_1x400.png', 'www/static/common/jquery/theme-redmond/images/ui-icons_cd0a0a_256x240.png', 'www/static/common/images/compute-dev-guide.png', 'www/static/common/css/main-landing.css', 'www/arch/index.html', 'www/static/common/images/header-bg.gif', 'www/static/.htaccess', 'www/static/common/jquery/jTweetsAnywhere/jquery.jtweetsanywhere-1.2.1.min.js', 'www/static/common/css/homepage.css', 'www/fr/index.html', 'www/static/common/jquery/treeview/images/folder-closed.gif', 'www/static/common/images/openstack-logo.png', 'www/icehouse/index.html', 'www/static/common/images/small-manual.png', 'www/static/common/jquery/theme-redmond/images/ui-bg_flat_0_aaaaaa_40x100.png', 'www/static/common/css/docblitz.css', 'www/ja/index.html', 'www/static/common/jquery/theme-redmond/images/ui-icons_469bdd_256x240.png', 'www/api/api-ref-guides.html', 'www/static/common/jquery/treeview/images/folder-closed2.gif', 'www/static/common/images/previous-arrow.png', 'tools/www-generator.py', 'www/static/common/jquery/treeview/images/folder2.gif', 'www/static/common/jquery/treeview/images/treeview-gray.gif', 'www/sec/index.html', 'www/de/index.html', 'www/static/common/images/openstack-arch-guide-team.png', 'www/static/common/css/homepage-updated.css', 'www/static/common/images/openstack-security-guide-team.jpg', 'www/static/robots.txt', 'www/static/common/jquery/treeview/images/treeview-default.gif', 'www/grizzly/index.html', 'www/static/common/images/highlight-blue.gif', 'www/static/common/jquery/theme-redmond/images/ui-icons_f9bd01_256x240.png', 'www/static/common/jquery/theme-redmond/images/ui-bg_glass_75_d0e5f5_1x400.png', 'www/static/common/images/storage-admin.png', 'www/static/common/images/storage-dev-guide.png', 'www/templates/script_search.tmpl', 'www/static/common/jquery/treeview/images/treeview-red-line.gif', 'www/static/common/images/OpenStackOpsGuide.jpg', 'www/static/common/jquery/theme-redmond/images/ui-bg_gloss-wave_55_5c9ccc_500x100.png', 'www/static/common/images/highlight-yellow.gif', 'www/static/common/images/large-manual.png', 'www/static/common/jquery/treeview/images/treeview-gray-line.gif', 'www/static/common/jquery/theme-redmond/images/ui-bg_flat_55_fbec88_40x100.png', 'www/static/favicon.ico', 'www/static/common/jquery/treeview/images/treeview-black-line.gif', 'www/static/common/jquery/theme-redmond/images/ui-icons_d8e7f3_256x240.png', 'www/static/common/jquery/treeview/images/treeview-default-line.gif', 'www/developer/openstack-projects.html', 'tox.ini', 'www/static/common/jquery/treeview/images/treeview-red.gif', 'www/static/common/images/book_open.png', 'www/static/common/jquery/theme-redmond/images/ui-icons_217bc0_256x240.png', 'www/templates/dropdown_releases_and_languages.tmpl', 'www/www-index.html', 'www/static/common/images/sidebar.png', '.gitignore', 'www/static/common/jquery/treeview/jquery.treeview.async.js', 'www/static/common/jquery/treeview/images/treeview-black.gif', 'www/ops/index.html', 'www/static/common/images/breadcrumb-arrow.png', 'www/static/common/images/toc-icon.png', 'www/static/common/jquery/jTweetsAnywhere/license.txt', 'www/templates/script_footer.tmpl', 'www/static/common/jquery/treeview/jquery.treeview.min.js', 'www/static/common/css/new-homepage.css', 'www/static/common/images/arch-guide-cover.png', 'www/static/common/images/showHideTreeIcons.png', 'www/index.html', 'www/static/common/images/selection-arrow.png', 'www/static/common/images/openstack-security-guide.jpg', 'www/havana/index.html', 'www/static/common/images/oreilly-openstack-ops-guide.png', 'www/static/common/jquery/jquery-1.4.2.min.js', 'www/static/common/images/next-arrow.png', 'www/static/common/jquery/jTweetsAnywhere/jquery.jtweetsanywhere-1.2.1.js', 'www/static/common/images/note.png', 'tools/README-USE-openstack-doc-tools.txt'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/40b657f993c57f580e7860e2921ee6d993bbbe89', 'message': 'Use a static site generator to generate content in www\n\nChange-Id: I2f0c61006ef8885e157eb2b800080407f2bae393\n'}]",5,112239,40b657f993c57f580e7860e2921ee6d993bbbe89,84,5,17,167,,,0,"Use a static site generator to generate content in www

Change-Id: I2f0c61006ef8885e157eb2b800080407f2bae393
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/112239/17 && git format-patch -1 --stdout FETCH_HEAD,"['www/templates/base.html', 'www/templates/header_content.html', 'www/templates/footer.html', 'www/templates/navigation.html', 'www/config', 'www/content/home.mkd', 'www/templates/script_footer.html', 'www/templates/default.html', 'www/templates/links_css.html', 'www/templates/script_header.html', 'www/templates/header.html']",11,3617cf4a8fd767642636e617885fd370d942bc4a,website_generator,"<div class=""span-5""> <h1 id=""logo""> <a href=""/"">OpenStack</a> </h1> </div> ",,463,0
openstack%2Fsecurity-doc~master~I28fdb67a9103e3263944a3b22a44cfc16917473e,openstack/security-doc,master,I28fdb67a9103e3263944a3b22a44cfc16917473e,"Improve ""Hardening the virtualization layer""",MERGED,2014-08-10 18:11:08.000000000,2014-08-14 08:18:19.000000000,2014-08-14 08:18:19.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2807}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-10 18:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/bae81e9756f65d7a880759ea189e89ad4c00c947', 'message': 'Improve ""Hardening the virtualization layer""\n\nUse variablelist to follow conventions for markup, improve paragraph\nas proposed in bug report for clarity.\n\nChange-Id: I28fdb67a9103e3263944a3b22a44cfc16917473e\nCloses-Bug: #1342862\n'}, {'number': 2, 'created': '2014-08-10 18:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/252ff43c8cee0c6f1945a09f4d350acb5c817f69', 'message': 'Improve ""Hardening the virtualization layer""\n\nUse variablelist to follow conventions for markup, improve paragraph\nas proposed in bug report for clarity.\n\nClarify a sentence about SELinux.\n\nChange-Id: I28fdb67a9103e3263944a3b22a44cfc16917473e\nCloses-Bug: #1342862\nCloses-Bug: #1342829\n'}, {'number': 3, 'created': '2014-08-10 18:20:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/e03feb4e72a8804b8fb1cb8475a596e122eaa2a0', 'message': 'Improve ""Hardening the virtualization layer""\n\nVarious edits as suggested in bug reports:\n* Use variablelist to follow conventions for markup, improve paragraph\n  for clarity.\n* Clarify a sentence about SELinux.\n* Improve CFLAGS recommendation.\n* Reword QEMU recommendation.\n\nChange-Id: I28fdb67a9103e3263944a3b22a44cfc16917473e\nCloses-Bug: #1342862\nCloses-Bug: #1342829\nCloses-Bug: #1342826\nCloses-Bug: #1342432\n'}, {'number': 4, 'created': '2014-08-11 11:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/01cf314f838e15719790eb873f221273c1da880d', 'message': 'Improve ""Hardening the virtualization layer""\n\nVarious edits as suggested in bug reports:\n* Use variablelist to follow conventions for markup, improve paragraph\n  for clarity.\n* Clarify a sentence about SELinux.\n* Improve CFLAGS recommendation.\n* Reword QEMU recommendation.\n\nChange-Id: I28fdb67a9103e3263944a3b22a44cfc16917473e\nCloses-Bug: #1342862\nCloses-Bug: #1342829\nCloses-Bug: #1342826\nCloses-Bug: #1342432\n'}, {'number': 5, 'created': '2014-08-12 05:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/0fae2bf1de37d500a410503f2b21d90437c1431a', 'message': 'Improve ""Hardening the virtualization layer""\n\nVarious edits as suggested in bug reports:\n* Use variablelist to follow conventions for markup, improve paragraph\n  for clarity.\n* Clarify a sentence about SELinux.\n* Improve CFLAGS recommendation.\n* Reword QEMU recommendation.\n\nChange-Id: I28fdb67a9103e3263944a3b22a44cfc16917473e\nCloses-Bug: #1342862\nCloses-Bug: #1342829\nCloses-Bug: #1342826\nCloses-Bug: #1342432\n'}, {'number': 6, 'created': '2014-08-14 08:03:02.000000000', 'files': ['security-guide/section_hardening-the-virtualization-layers.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/733e5a8ca50a12c55be046b84b9e8db3bda2ad14', 'message': 'Improve ""Hardening the virtualization layer""\n\nVarious edits as suggested in bug reports:\n* Use variablelist to follow conventions for markup, improve paragraph\n  for clarity.\n* Clarify a sentence about SELinux.\n* Improve CFLAGS recommendation.\n* Reword QEMU recommendation.\n\nChange-Id: I28fdb67a9103e3263944a3b22a44cfc16917473e\nCloses-Bug: #1342862\nCloses-Bug: #1342829\nCloses-Bug: #1342826\nCloses-Bug: #1342432\n'}]",11,113142,733e5a8ca50a12c55be046b84b9e8db3bda2ad14,34,4,6,6547,,,0,"Improve ""Hardening the virtualization layer""

Various edits as suggested in bug reports:
* Use variablelist to follow conventions for markup, improve paragraph
  for clarity.
* Clarify a sentence about SELinux.
* Improve CFLAGS recommendation.
* Reword QEMU recommendation.

Change-Id: I28fdb67a9103e3263944a3b22a44cfc16917473e
Closes-Bug: #1342862
Closes-Bug: #1342829
Closes-Bug: #1342826
Closes-Bug: #1342432
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/42/113142/5 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/section_hardening-the-virtualization-layers.xml'],1,bae81e9756f65d7a880759ea189e89ad4c00c947,bug/1342862," vectors: </para> <variablelist> <varlistentry> <term>Hypervisor threats</term> <listitem> <para> When a compromised application running within a virtual machine attacks the hypervisor to access underlying resources. For example, when a virtual machine is able to access the hypervisor OS, physical devices, or other applications. This threat vector represents considerable risk as a compromise on a hypervisor can infect the physical hardware as well as exposing other virtual machines and network segments. </para> </listitem> </varlistentry> <varlistentry> <term>Virtual Machine (multi-tenant) threats</term> <listitem> <para> A compromised application running within a VM attacks the hypervisor to access/control another virtual machine and its resources. This is a threat vector unique to virtualization and represents considerable risk as a multitude of virtual machine file images could be compromised due to vulnerability in a single application. This virtual network attack is a major concern as the administrative techniques for protecting real networks do not directly apply to the virtual environment. </para> </listitem> </varlistentry> </variablelist>"," vectors:</para> <itemizedlist><listitem> <para><emphasis role=""bold"">Hypervisor threats</emphasis> A compromised application running within a virtual machine attacks the hypervisor to access underlying resources. For example, the host OS, applications, or devices within the physical machine. This is a threat vector unique to virtualization and represents considerable risk as the underlying real machine can be compromised due to vulnerability in a single virtual application.</para> </listitem> <listitem> <para><emphasis role=""bold"">Virtual Machine (multi-tenant) threats</emphasis> A compromised application running within a VM attacks the hypervisor to access/control another virtual machine and its resources. This is a threat vector unique to virtualization and represents considerable risk as a multitude of virtual machine file images could be compromised due to vulnerability in a single application. This virtual network attack is a major concern as the administrative techniques for protecting real networks do not directly apply to the virtual environment.</para> </listitem> </itemizedlist>",36,25
openstack%2Fneutron~master~I0f245cb3e209ad5a37d0c098524830eea689b62c,openstack/neutron,master,I0f245cb3e209ad5a37d0c098524830eea689b62c,Convert vsctl call to ovsdb WIP - DO NOT MERGE,ABANDONED,2014-08-11 04:25:58.000000000,2014-08-14 08:16:34.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5756}, {'_account_id': 8788}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10387}, {'_account_id': 12444}]","[{'number': 1, 'created': '2014-08-11 04:25:58.000000000', 'files': ['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/plugins/ryu/agent/ryu_neutron_agent.py', 'neutron/agent/linux/ovs_lib.py', 'neutron/agent/linux/interface.py', 'neutron/agent/ovs_cleanup_util.py', 'neutron/common/utils.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/ibm/agent/sdnve_neutron_agent.py', 'neutron/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c3312ce91be7bb605953b1d855df7bec8a652c0e', 'message': ""Convert vsctl call to ovsdb WIP - DO NOT MERGE\n\nThis is very much a work in progress. And I'm in the middle of a\nrefactor, but I thought I'd throw this up here a) for backup\npurposes and b) so people can comment on the general structure.\n\nTo play with it, make sure to have devstack\n  chmod a+rwx /var/run/openvswitch/db.sock.\nwhen restarting openvswitch. Yes, permissions are a thing we'll have\nto work out.\n\nThough tempest tests ran, when running devstack vif_plugging is still\nfailing. Lots of work to do on safety, exceptions, testing, etc.\n\nImplements: blueprint vsctl-to-ovsdb\n\nChange-Id: I0f245cb3e209ad5a37d0c098524830eea689b62c\n""}]",11,113162,c3312ce91be7bb605953b1d855df7bec8a652c0e,20,15,1,5756,,,0,"Convert vsctl call to ovsdb WIP - DO NOT MERGE

This is very much a work in progress. And I'm in the middle of a
refactor, but I thought I'd throw this up here a) for backup
purposes and b) so people can comment on the general structure.

To play with it, make sure to have devstack
  chmod a+rwx /var/run/openvswitch/db.sock.
when restarting openvswitch. Yes, permissions are a thing we'll have
to work out.

Though tempest tests ran, when running devstack vif_plugging is still
failing. Lots of work to do on safety, exceptions, testing, etc.

Implements: blueprint vsctl-to-ovsdb

Change-Id: I0f245cb3e209ad5a37d0c098524830eea689b62c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/113162/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/plugins/ryu/agent/ryu_neutron_agent.py', 'neutron/agent/linux/ovs_lib.py', 'neutron/agent/linux/interface.py', 'neutron/agent/ovs_cleanup_util.py', 'neutron/common/utils.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/ibm/agent/sdnve_neutron_agent.py', 'neutron/common/exceptions.py']",9,c3312ce91be7bb605953b1d855df7bec8a652c0e,bp/vsctl-to-ovsdb," class RetryTimeoutError(NeutronException): message = _(""Retry timeout limit of %(timeout)d seconds reached"")",,618,290
openstack%2Fopenstack-doc-tools~master~Ic7a496ee16efffc7ae41f657a07af998436ea12e,openstack/openstack-doc-tools,master,Ic7a496ee16efffc7ae41f657a07af998436ea12e,A virtual building and testing environment using Vagrant,MERGED,2014-05-08 16:07:48.000000000,2014-08-14 08:15:36.000000000,2014-08-14 08:15:36.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7472}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-05-08 16:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/b388b8c6ec6b039dadffab60d9599c86cb91221f', 'message': 'an initial virtual building and testing environment using Vagrant\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\n'}, {'number': 2, 'created': '2014-05-08 16:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/790a53a9f7c6922b3e7117814f13747b0668cfc0', 'message': 'an virtual building and testing environment using Vagrant\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\n'}, {'number': 3, 'created': '2014-05-08 18:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/f8a171c59d6f23ede92be749de429e56c250147b', 'message': 'a virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\n'}, {'number': 4, 'created': '2014-05-09 10:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/af927cff91afff141eb94d872bacc195cf2ef1ff', 'message': 'a virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}, {'number': 5, 'created': '2014-05-09 12:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/c18b836ec85c3ce2196c9984fb7789a98a20deac', 'message': 'a virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}, {'number': 6, 'created': '2014-05-14 07:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/624f3b500c4856fe0c4f680807c7a3b4c767f15b', 'message': 'a virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}, {'number': 7, 'created': '2014-05-14 07:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/961b5e3f1bcc24c00a6aefcef48e0da4bbe0ce5f', 'message': 'a virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}, {'number': 8, 'created': '2014-05-14 07:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/44eb9595ba6a721475e8a50e8c26d09fc981689d', 'message': 'a virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}, {'number': 9, 'created': '2014-05-14 08:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/aa8c97c9523a48187353aae229cea614fdaa87dc', 'message': 'a virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}, {'number': 10, 'created': '2014-05-23 10:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/8be7c8766779985cdeafa672076f9c6a100ccb16', 'message': 'a virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}, {'number': 11, 'created': '2014-06-03 12:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/69bf051a011b1ca12af21001f30beca3523433c4', 'message': 'A virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}, {'number': 12, 'created': '2014-08-11 12:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/de805f2f6c56b170d8817e4dd8264de6cafb8f76', 'message': 'A virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}, {'number': 13, 'created': '2014-08-11 12:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/befb16712ed24eed9710ce1799fad6b3c53c5297', 'message': 'A virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}, {'number': 14, 'created': '2014-08-11 16:46:02.000000000', 'files': ['RELEASE_NOTES.rst', 'build_environment/README.md', 'build_environment/Vagrantfile.box', 'build_environment/files/nginx.default', '.gitignore', 'build_environment/files/fetch.sh', 'build_environment/Vagrantfile', 'build_environment/bin/package.sh', 'build_environment/files/playbook.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/051d7dbc691a7d84d6a54f0a69ccb1b505e0b349', 'message': 'A virtual building and testing environment using Vagrant\n\nThis patch provides all necessary files and configurations to\nbuild a Vagrantbox that can be used as building and testing\nenvironment for all OpenStack manuals and documentations. It\nincludes the repositories like openstack-manuals. Tox, Maven\nand all needed dependencies by Maven are already\ninstalled/fetched.\n\nChange-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e\nCloses-Bug: #1317849\n'}]",12,92867,051d7dbc691a7d84d6a54f0a69ccb1b505e0b349,92,7,14,167,,,0,"A virtual building and testing environment using Vagrant

This patch provides all necessary files and configurations to
build a Vagrantbox that can be used as building and testing
environment for all OpenStack manuals and documentations. It
includes the repositories like openstack-manuals. Tox, Maven
and all needed dependencies by Maven are already
installed/fetched.

Change-Id: Ic7a496ee16efffc7ae41f657a07af998436ea12e
Closes-Bug: #1317849
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/67/92867/11 && git format-patch -1 --stdout FETCH_HEAD,"['build_environment/files/default', 'build_environment/files/build.sh', 'build_environment/Vagrantfile', 'build_environment/files/fetch.sh', 'build_environment/files/pull.sh', 'build_environment/files/playbook.yaml']",6,b388b8c6ec6b039dadffab60d9599c86cb91221f,bug/1317849,--- - hosts: all sudo: True tasks: - apt: name={{ item }} state=present with_items: - git - git-review - maven - nginx - python-tox - copy: src=default dest=/etc/nginx/sites-available/default notify: restart nginx - service: name=nginx enabled=yes state=started - copy: src=build.sh dest=/usr/local/bin/build.sh mode=0755 - copy: src=fetch.sh dest=/usr/local/bin/fetch.sh mode=0755 - copy: src=pull.sh dest=/usr/local/bin/pull.sh mode=0755 - lineinfile: dest=/etc/environment regexp='^JAVA_HOME=' line='JAVA_HOME=/usr/lib/jvm/default-java' sudo: True - git: repo=https://github.com/openstack/{{ item }} dest=/opt/working/{{ item }} with_items: - api-site - compute-api - database-api - identity-api - image-api - netconn-api - object-api - openstack-doc-tools - openstack-manuals - volume-api sudo: False - command: /usr/local/bin/fetch.sh sudo: False handlers: - name: restart nginx service: name=nginx state=restarted ,,129,0
openstack%2Fopenstack-doc-tools~master~Ic1528bd9d386660090fe4fae4908bf663f314db2,openstack/openstack-doc-tools,master,Ic1528bd9d386660090fe4fae4908bf663f314db2,Add a link to the static index of generated WWW pages,MERGED,2014-08-12 10:16:01.000000000,2014-08-14 08:14:13.000000000,2014-08-14 08:14:13.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-12 10:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/01a31f47c67543bf04870e12aadfed19b4626eaf', 'message': 'Add a link to the static index of generated WWW pages\n\nChange-Id: Ic1528bd9d386660090fe4fae4908bf663f314db2\n'}, {'number': 2, 'created': '2014-08-12 11:38:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/263a874d24b331992f5aa69cb6e7a36c3422a02a', 'message': 'Add a link to the static index of generated WWW pages\n\nChange-Id: Ic1528bd9d386660090fe4fae4908bf663f314db2\n'}, {'number': 3, 'created': '2014-08-12 16:16:34.000000000', 'files': ['os_doc_tools/doctest.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/5979d8093d328030bb0c072f6c7dedb120adc411', 'message': 'Add a link to the static index of generated WWW pages\n\nChange-Id: Ic1528bd9d386660090fe4fae4908bf663f314db2\n'}]",1,113476,5979d8093d328030bb0c072f6c7dedb120adc411,17,2,3,167,,,0,"Add a link to the static index of generated WWW pages

Change-Id: Ic1528bd9d386660090fe4fae4908bf663f314db2
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/76/113476/3 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/doctest.py'],1,01a31f47c67543bf04870e12aadfed19b4626eaf,add_www_index," index_file.write('<br/>\n' index_file.write('<a href=""www-index.html"">list of generated WWW pages</a>\n'",,2,0
openstack%2Fopenstack-doc-tools~master~Ic28ba9251ecb47967de2e7b6816788828e3bbb14,openstack/openstack-doc-tools,master,Ic28ba9251ecb47967de2e7b6816788828e3bbb14,Remove publish_www and simplify www_touched,MERGED,2014-08-11 19:23:29.000000000,2014-08-14 08:14:08.000000000,2014-08-14 08:14:07.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-11 19:23:29.000000000', 'files': ['os_doc_tools/doctest.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/b654d61d16fcc24b54d2039a8c88cc1f5061e8df', 'message': ""Remove publish_www and simplify www_touched\n\nBecause of I2f0c61006ef8885e157eb2b800080407f2bae393 it is not\nlonger necessary to publish the files inside the www directory.\n\nBecause of the removal of publish_www it's now only necessary\nto check if only files inside the www directory are changed.\n\nChange-Id: Ic28ba9251ecb47967de2e7b6816788828e3bbb14\n""}]",0,113352,b654d61d16fcc24b54d2039a8c88cc1f5061e8df,14,3,1,167,,,0,"Remove publish_www and simplify www_touched

Because of I2f0c61006ef8885e157eb2b800080407f2bae393 it is not
longer necessary to publish the files inside the www directory.

Because of the removal of publish_www it's now only necessary
to check if only files inside the www directory are changed.

Change-Id: Ic28ba9251ecb47967de2e7b6816788828e3bbb14
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/52/113352/1 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/doctest.py'],1,b654d61d16fcc24b54d2039a8c88cc1f5061e8df,remove_www_publish,"def www_touched(): """"""Check whether files in www directory are touched."""""" return www_changed and not other_changed if not CONF.force and www_touched():","def www_touched(check_only_www): """"""Check whether files in www directory are touched. If check_only_www is True: Check that only files in www are touched. Otherwise check that files in www are touched. """""" if check_only_www: return www_changed and not other_changed return www_changeddef publish_www(): """"""Copy www files."""""" publish_path = get_publish_path() www_path = os.path.join(publish_path, 'www') shutil.rmtree(www_path, ignore_errors=True) source = os.path.join(get_gitroot(), 'www') shutil.copytree(source, www_path) # Do not publish www directory if we build for external # publishing if (CONF.check_build and (www_touched(False) and not CONF.publish)): publish_www() if not CONF.force and www_touched(True):",4,27
openstack%2Fpython-keystoneclient~master~Id6d47e59e96b7b42c04cecdd53c13a887f60c75b,openstack/python-keystoneclient,master,Id6d47e59e96b7b42c04cecdd53c13a887f60c75b,Allow registering individual plugin CONF options,MERGED,2014-08-12 10:23:52.000000000,2014-08-14 08:09:37.000000000,2014-08-14 08:09:36.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-08-12 10:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/24545777144a378acfc8c58f818e133549565252', 'message': 'Allow registering indeividual plugin CONF options\n\nGive plugins some more flexibility in registering there own CONF\noptions.\n\nChange-Id: Id6d47e59e96b7b42c04cecdd53c13a887f60c75b\n'}, {'number': 2, 'created': '2014-08-13 07:19:08.000000000', 'files': ['keystoneclient/auth/base.py', 'keystoneclient/auth/conf.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/feaafdc651bf967b6d181cc384bf583152246956', 'message': 'Allow registering individual plugin CONF options\n\nGive plugins some more flexibility in registering there own CONF\noptions.\n\nChange-Id: Id6d47e59e96b7b42c04cecdd53c13a887f60c75b\n'}]",1,113478,feaafdc651bf967b6d181cc384bf583152246956,11,3,2,7191,,,0,"Allow registering individual plugin CONF options

Give plugins some more flexibility in registering there own CONF
options.

Change-Id: Id6d47e59e96b7b42c04cecdd53c13a887f60c75b
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/78/113478/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/auth/base.py', 'keystoneclient/auth/conf.py']",2,24545777144a378acfc8c58f818e133549565252,cli-plugins," plugin_class.register_conf_options(conf, group) return plugin_class.load_from_conf_options(conf, group, **kwargs)"," plugin_opts = plugin_class.get_options() conf.register_opts(plugin_opts, group=group) for opt in plugin_opts: val = conf[group][opt.dest] if val is not None: val = opt.type(val) kwargs.setdefault(opt.dest, val) return plugin_class.load_from_options(**kwargs)",33,10
openstack%2Fpython-keystoneclient~master~I3dd5a8ed183d843246b1add3dfbf591ba4e2f94c,openstack/python-keystoneclient,master,I3dd5a8ed183d843246b1add3dfbf591ba4e2f94c,Individual plugin CLI registering,MERGED,2014-08-07 11:44:32.000000000,2014-08-14 08:08:44.000000000,2014-08-14 08:08:43.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 9101}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-08-07 11:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e973ad74cc52514f700b94fcc07c970bdc09b500', 'message': 'Individual plugin CLI registering\n\nSplit the functions that load the auth plugins from CLI so that they can\nbe used on a specific plugin. The intention here is to be able to turn\nthe existing authentication options in shells into a new auth plugin and\nhave that be loadable rather than maintain separate paths through the\nshells.\n\nChange-Id: I3dd5a8ed183d843246b1add3dfbf591ba4e2f94c\n'}, {'number': 2, 'created': '2014-08-07 22:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/735f7fcf00b88302f54b77c4ddc961ffe2bbf489', 'message': 'Individual plugin CLI registering\n\nSplit the functions that load the auth plugins from CLI so that they can\nbe used on a specific plugin. The intention here is to be able to turn\nthe existing authentication options in shells into a new auth plugin and\nhave that be loadable rather than maintain separate paths through the\nshells.\n\nChange-Id: I3dd5a8ed183d843246b1add3dfbf591ba4e2f94c\n'}, {'number': 3, 'created': '2014-08-07 22:21:30.000000000', 'files': ['keystoneclient/auth/base.py', 'keystoneclient/auth/cli.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/8f1605e30a0a563f5a9018b80c73aaabf6f5228d', 'message': 'Individual plugin CLI registering\n\nSplit the functions that load the auth plugins from CLI so that they can\nbe used on a specific plugin. The intention here is to be able to turn\nthe existing authentication options in shells into a new auth plugin and\nhave that be loadable rather than maintain separate paths through the\nshells.\n\nChange-Id: I3dd5a8ed183d843246b1add3dfbf591ba4e2f94c\n'}]",2,112563,8f1605e30a0a563f5a9018b80c73aaabf6f5228d,29,11,3,7191,,,0,"Individual plugin CLI registering

Split the functions that load the auth plugins from CLI so that they can
be used on a specific plugin. The intention here is to be able to turn
the existing authentication options in shells into a new auth plugin and
have that be loadable rather than maintain separate paths through the
shells.

Change-Id: I3dd5a8ed183d843246b1add3dfbf591ba4e2f94c
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/63/112563/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/auth/cli.py', 'keystoneclient/auth/__init__.py']",2,e973ad74cc52514f700b94fcc07c970bdc09b500,cli-plugins," 'load_plugin_from_argparse_arguments', 'register_plugin_argparse_arguments',",,51,25
openstack%2Fcongress~master~I5481f34bf8a1e95ab82bf2629e09c5bd80203fe1,openstack/congress,master,I5481f34bf8a1e95ab82bf2629e09c5bd80203fe1,Make datasources configurable,ABANDONED,2014-08-12 17:48:44.000000000,2014-08-14 08:05:26.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-08-12 17:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/803e37a683ad6a6e4d460b4ca0daa5db28539e66', 'message': ""Make datasources configurable\n\nThis patch makes the openstack datasources configurable outside of the\ncode. Eventually this will be removed and we'll be doing this via the\ncongress api.\n\nChange-Id: I5481f34bf8a1e95ab82bf2629e09c5bd80203fe1\nCloses-bug: 1355958\n""}, {'number': 2, 'created': '2014-08-12 17:52:17.000000000', 'files': ['congress/common/config.py', 'etc/congress.conf.sample', 'congress/tests/test_config.py', 'congress/datasources/neutron_driver.py', 'congress/datasources/settings.py', 'congress/datasources/nova_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/0ed9ed9d8a37cffa6962ca5b68d6a30402ee4f26', 'message': ""Make datasources configurable\n\nThis patch makes the openstack datasources configurable outside of the\ncode. Eventually this will be removed and we'll be doing this via the\ncongress api.\n\nChange-Id: I5481f34bf8a1e95ab82bf2629e09c5bd80203fe1\nCloses-bug: 1355958\n""}]",0,113600,0ed9ed9d8a37cffa6962ca5b68d6a30402ee4f26,8,4,2,4395,,,0,"Make datasources configurable

This patch makes the openstack datasources configurable outside of the
code. Eventually this will be removed and we'll be doing this via the
congress api.

Change-Id: I5481f34bf8a1e95ab82bf2629e09c5bd80203fe1
Closes-bug: 1355958
",git fetch https://review.opendev.org/openstack/congress refs/changes/00/113600/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/common/config.py', 'congress/tests/test_config.py', 'congress/datasources/neutron_driver.py', 'congress/datasources/settings.py', 'congress/datasources/nova_driver.py']",5,803e37a683ad6a6e4d460b4ca0daa5db28539e66,bug/1355958,from oslo.config import cfg d['username'] = cfg.CONF.os_username d['api_key'] = cfg.CONF.os_password d['auth_url'] = cfg.CONF.os_auth_url d['project_id'] = cfg.CONF.os_tenant_name,"from congress.datasources.settings import OS_USERNAME, \ OS_PASSWORD, OS_AUTH_URL, OS_TENANT_NAME USERNAME = OS_USERNAME PASSWORD = OS_PASSWORD AUTH_URL = OS_AUTH_URL TENANT_NAME = OS_TENANT_NAME d['username'] = self.USERNAME d['api_key'] = self.PASSWORD d['auth_url'] = self.AUTH_URL d['project_id'] = self.TENANT_NAME",25,42
openstack%2Fopenstack-manuals~master~Iecf16d2be386a3d933c089f5ef9e73e378a32555,openstack/openstack-manuals,master,Iecf16d2be386a3d933c089f5ef9e73e378a32555,Reformat overlong lines,MERGED,2014-08-12 18:46:42.000000000,2014-08-14 08:00:51.000000000,2014-08-14 08:00:50.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-12 18:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ac3a08d2a0e67c17266262bc0a429fe6fbe4dbd8', 'message': 'Hot Guide: Reformat overlong lines\n\nReformat some overlong lines in the source file.\n\nChange-Id: Iecf16d2be386a3d933c089f5ef9e73e378a32555\n'}, {'number': 2, 'created': '2014-08-13 06:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/05bd0858d9b88e6eea63c42feebf5326a8ddacec', 'message': 'Hot Guide: Reformat overlong lines\n\nReformat some overlong lines in the source file.\n\nChange-Id: Iecf16d2be386a3d933c089f5ef9e73e378a32555\n'}, {'number': 3, 'created': '2014-08-13 12:04:29.000000000', 'files': ['doc/admin-guide-cloud/roadmap.rst', 'doc/user-guide/roadmap.rst', 'doc/cli-reference/roadmap.rst', 'doc/hot-guide/source/hot_spec.rst', 'doc/hot-guide/source/hot_guide.rst', 'doc/user-guide-admin/roadmap.rst', 'doc/image-guide/roadmap.rst', 'doc/install-guide/roadmap.rst', 'doc/cli-reference/generated/README.rst', 'doc/config-reference/roadmap.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1bda86a0b8e8ec604046da8f625a8e6b14a1b76f', 'message': 'Reformat overlong lines\n\nReformat some overlong lines in the source files.\n\nNow doc8 -e .rst doc passes.\n\nChange-Id: Iecf16d2be386a3d933c089f5ef9e73e378a32555\n'}]",0,113611,1bda86a0b8e8ec604046da8f625a8e6b14a1b76f,14,3,3,6547,,,0,"Reformat overlong lines

Reformat some overlong lines in the source files.

Now doc8 -e .rst doc passes.

Change-Id: Iecf16d2be386a3d933c089f5ef9e73e378a32555
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/11/113611/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/hot-guide/source/hot_spec.rst'],1,ac3a08d2a0e67c17266262bc0a429fe6fbe4dbd8,bp/heat-templates," The *resource_facade* function allows a provider template to retrieve data about its resource facade in the parent template. (A provider template is used to provide a custom definition of a resource - the facade - in the form of a Heat template. The resource's properties are passed to the provider template as its parameters, but other resource data can be included using this function.) The syntax of the *resource_facade* function is as follows::","The *resource_facade* function allows a provider template to retrieve data about its resource facade in the parent template. (A provider template is used to provide a custom definition of a resource - the facade - in the form of a Heat template. The resource's properties are passed to the provider template as its parameters, but other resource data can be included using this function.) The syntax of the *resource_facade* function is as follows::",8,3
openstack%2Fopenstack-manuals~master~Iffd51c0ca648b208b5b6381d6ced919eaf914e55,openstack/openstack-manuals,master,Iffd51c0ca648b208b5b6381d6ced919eaf914e55,Remove trailing whitespace from txt files,MERGED,2014-08-13 12:21:20.000000000,2014-08-14 07:59:16.000000000,2014-08-14 07:59:15.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-13 12:21:20.000000000', 'files': ['doc/install-guide/samples/account-server.conf.txt', 'doc/install-guide/samples/network-interfaces.conf.txt', 'doc/install-guide/samples/container-server-1.conf.txt', 'doc/install-guide/samples/container-server.conf.txt', 'doc/install-guide/samples/object-server.conf.txt', 'doc/install-guide/samples/object-server-1.conf.txt', 'doc/install-guide/samples/account-server-1.conf.txt'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/699a879342fd1364e258b8ed68d87771ef466b2c', 'message': 'Remove trailing whitespace from txt files\n\nNow doc -e .txt doc passes.\n\nChange-Id: Iffd51c0ca648b208b5b6381d6ced919eaf914e55\n'}]",0,113864,699a879342fd1364e258b8ed68d87771ef466b2c,8,3,1,6547,,,0,"Remove trailing whitespace from txt files

Now doc -e .txt doc passes.

Change-Id: Iffd51c0ca648b208b5b6381d6ced919eaf914e55
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/64/113864/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/samples/account-server.conf.txt', 'doc/install-guide/samples/network-interfaces.conf.txt', 'doc/install-guide/samples/container-server-1.conf.txt', 'doc/install-guide/samples/container-server.conf.txt', 'doc/install-guide/samples/object-server.conf.txt', 'doc/install-guide/samples/object-server-1.conf.txt', 'doc/install-guide/samples/account-server-1.conf.txt']",7,699a879342fd1364e258b8ed68d87771ef466b2c,txt-whitespace,, ,41,43
openstack%2Fdocs-specs~master~If6b31ba87dff9dc7b550b147aa16e3da88c1e057,openstack/docs-specs,master,If6b31ba87dff9dc7b550b147aa16e3da88c1e057,Cleanup README.rst,MERGED,2014-08-13 16:14:17.000000000,2014-08-14 07:56:08.000000000,2014-08-14 07:56:07.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-13 16:14:17.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/6c9b1ba135ca764fca81aef0b1367731e1b980ab', 'message': 'Cleanup README.rst\n\nWrap long lines, remove extra whitespace.\n\nNow passes doc8.\n\nChange-Id: If6b31ba87dff9dc7b550b147aa16e3da88c1e057\n'}]",0,113952,6c9b1ba135ca764fca81aef0b1367731e1b980ab,8,3,1,6547,,,0,"Cleanup README.rst

Wrap long lines, remove extra whitespace.

Now passes doc8.

Change-Id: If6b31ba87dff9dc7b550b147aa16e3da88c1e057
",git fetch https://review.opendev.org/openstack/docs-specs refs/changes/52/113952/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,6c9b1ba135ca764fca81aef0b1367731e1b980ab,doc8-README,"This git repository is used to hold approved design specifications for additions to the OpenStack Documentation program. Reviews of the specs are done in gerrit, using a similar workflow to how we review and merge changes to the docs and supporting tools.You can find an example spec in `doc/source/specs/template.rst`.For docs, blueprints are required for larger, coordinated projects but not for small fixes. It's a judgement call for whether you need a spec, so feel free to ask in theblueprint in Launchpad (and the spec links to Launchpad).","This git repository is used to hold approved design specifications for additions to the OpenStack Documentation program. Reviews of the specs are done in gerrit, using a similar workflow to how we review and merge changes to the docs and supporting tools.You can find an example spec in `doc/source/specs/template.rst`. For docs, blueprints are required for larger, coordinated projects but not for small fixes. It's a judgement call for whether you need a spec, so feel free to ask in theblueprint in Launchpad (and the spec links to Launchpad). ",9,7
openstack%2Fnova~master~Ia83cf1b77a7a185a195286234d7f943d0ca7537f,openstack/nova,master,Ia83cf1b77a7a185a195286234d7f943d0ca7537f,"Merge BadRequest tests of ""get console output"" API",MERGED,2014-07-31 14:42:22.000000000,2014-08-14 07:55:04.000000000,2014-08-14 03:50:04.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 9847}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-31 14:42:22.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_console_output.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/45b51d973d92a515982d3b715efb618daab7d538', 'message': 'Merge BadRequest tests of ""get console output"" API\n\nIn test_console_output, there are BadRequest tests of ""get console output"".\nMost parts of them are duplicated.\nThis patch merges them for the readability and clarifying their purposes.\n\nChange-Id: Ia83cf1b77a7a185a195286234d7f943d0ca7537f\n'}]",0,110981,45b51d973d92a515982d3b715efb618daab7d538,39,11,1,6167,,,0,"Merge BadRequest tests of ""get console output"" API

In test_console_output, there are BadRequest tests of ""get console output"".
Most parts of them are duplicated.
This patch merges them for the readability and clarifying their purposes.

Change-Id: Ia83cf1b77a7a185a195286234d7f943d0ca7537f
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/110981/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/contrib/test_console_output.py'],1,45b51d973d92a515982d3b715efb618daab7d538,," def _get_console_output_bad_request_case(self, body): def test_get_console_output_with_non_integer_length(self): body = {'os-getConsoleOutput': {'length': 'NaN'}} self._get_console_output_bad_request_case(body) def test_get_text_console_bad_body(self): body = {} self._get_console_output_bad_request_case(body) def test_get_console_output_with_length_as_float(self): body = {'os-getConsoleOutput': {'length': 2.5}} self._get_console_output_bad_request_case(body) "," def test_get_console_output_with_non_integer_length(self): body = {'os-getConsoleOutput': {'length': 'NaN'}} req = webob.Request.blank('/v2/fake/servers/1/action') req.method = ""POST"" req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" res = req.get_response(self.app) self.assertEqual(res.status_int, 400) def test_get_text_console_bad_body(self): body = {} def test_get_console_output_with_length_as_float(self): body = {'os-getConsoleOutput': {'length': 2.5}} req = webob.Request.blank('/v2/fake/servers/1/action') req.method = ""POST"" req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" res = req.get_response(self.app) self.assertEqual(res.status_int, 400) ",13,21
openstack%2Fos-cloud-config~master~Ia0b7ecf2eed93e8dfe16ce71a221a5e0c1209c3d,openstack/os-cloud-config,master,Ia0b7ecf2eed93e8dfe16ce71a221a5e0c1209c3d,Updated from global requirements,MERGED,2014-07-12 23:06:03.000000000,2014-08-14 07:47:21.000000000,2014-08-14 07:47:21.000000000,"[{'_account_id': 3}, {'_account_id': 8041}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 9369}, {'_account_id': 9712}]","[{'number': 1, 'created': '2014-07-12 23:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/c260daba1db6cf93bc6fa1aee093dfae7d9948f4', 'message': 'Updated from global requirements\n\nChange-Id: Ia0b7ecf2eed93e8dfe16ce71a221a5e0c1209c3d\n'}, {'number': 2, 'created': '2014-07-28 19:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/e0978e540933b3cc4d491edc484a4d09f2ed1c92', 'message': 'Updated from global requirements\n\nChange-Id: Ia0b7ecf2eed93e8dfe16ce71a221a5e0c1209c3d\n'}, {'number': 3, 'created': '2014-08-02 20:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/85d7f86910b108a0932a4aa43ad537cb2d0c0e0a', 'message': 'Updated from global requirements\n\nChange-Id: Ia0b7ecf2eed93e8dfe16ce71a221a5e0c1209c3d\n'}, {'number': 4, 'created': '2014-08-04 03:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/cf734a8827ba87c12e4626ed4a5d2e5db6f62f5c', 'message': 'Updated from global requirements\n\nChange-Id: Ia0b7ecf2eed93e8dfe16ce71a221a5e0c1209c3d\n'}, {'number': 5, 'created': '2014-08-13 23:23:45.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/672880d7c0c6bcba9b15eb03aa47cf64f72d66df', 'message': 'Updated from global requirements\n\nChange-Id: Ia0b7ecf2eed93e8dfe16ce71a221a5e0c1209c3d\n'}]",0,106589,672880d7c0c6bcba9b15eb03aa47cf64f72d66df,41,6,5,11131,,,0,"Updated from global requirements

Change-Id: Ia0b7ecf2eed93e8dfe16ce71a221a5e0c1209c3d
",git fetch https://review.opendev.org/openstack/os-cloud-config refs/changes/89/106589/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c260daba1db6cf93bc6fa1aee093dfae7d9948f4,openstack/requirements,oslo.config>=1.4.0.0a2,oslo.config>=1.2.1,1,1
openstack%2Fmurano-dashboard~master~I279d1c41ad95946af33b79a3a2b22a7c047bb76c,openstack/murano-dashboard,master,I279d1c41ad95946af33b79a3a2b22a7c047bb76c,Update Image selection in functional test,MERGED,2014-08-08 08:03:55.000000000,2014-08-14 07:40:07.000000000,2014-08-14 07:40:07.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-08-08 08:03:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ce17f1f4048fc5a54ef258d7af3f0d1bc945449e', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 2, 'created': '2014-08-08 15:17:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/7103a75a12427991912ca91515ac89fb53ede8d5', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 3, 'created': '2014-08-08 15:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/7932a9c2363e3e2dd7d3876049d425d7ff0e910e', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 4, 'created': '2014-08-11 08:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/397069d6acf32dd693d1075b91c0296c02cfe9d4', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 5, 'created': '2014-08-12 11:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/b9c70f32e45477e844ae0c651029e03be80fb83f', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 6, 'created': '2014-08-12 13:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/5f5fc9fb0005ae3d4fb107bd940a808fcaa4d4cb', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 7, 'created': '2014-08-12 13:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/1c52435b46d0610e196f46716f8bb48796f8df78', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 8, 'created': '2014-08-12 14:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/45a1629a6863f8a2f79202aa24927256c6536985', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 9, 'created': '2014-08-12 16:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/01df90a425e79f6591371e2fb8b7d6fa82217bf2', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nSome other changes are made:\n\n* Use expected conditions before click to the element\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 10, 'created': '2014-08-12 18:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/17d3239a1f204fad5880bce094ffc0275c822615', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nSome other changes are made:\n\n* Use expected conditions before click to the element\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 11, 'created': '2014-08-13 08:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/557ac245427d76c62769dcccb2393556938037ad', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nSome other changes are made:\n\n* Use expected conditions before click to the element\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 12, 'created': '2014-08-13 09:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/d4ecdd726b5053f0811cebaf69baf9a44853c92b', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nSome other changes are made:\n\n* Use expected conditions before click to the element\n* Add wait for page loading after navigation\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 13, 'created': '2014-08-13 10:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ee621d15f5f5538afc1635ad46380a9c44718b60', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nSome other changes are made:\n\n* Use expected conditions before click to the element\n* Add wait for page loading after navigation\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 14, 'created': '2014-08-13 11:17:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/02ff5e6244a0f563b92de6bcc61489d26a2c11d1', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nSome other changes are made:\n\n* Use expected conditions before click to the element\n* Add wait for page loading after navigation\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 15, 'created': '2014-08-13 11:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/4d52e2869ad5d0971d9ce434a145753bedbde213', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nSome other changes are made:\n\n* Use expected conditions before click to the element\n* Add wait for page loading after navigation\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}, {'number': 16, 'created': '2014-08-13 13:49:14.000000000', 'files': ['muranodashboard/tests/functional/sanity_check.py', 'muranodashboard/tests/functional/consts.py', 'muranodashboard/tests/functional/base.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/b1a51b2be21253ee5c85d15c60accc71ca4f1b15', 'message': 'Update Image selection in functional test\n\n* Get name by id\n* Add delay before element selection\n\nSome other changes are made:\n\n* Use expected conditions before click to the element\n* Add wait for page loading after navigation\n\nChange-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c\n'}]",0,112785,b1a51b2be21253ee5c85d15c60accc71ca4f1b15,113,5,16,7549,,,0,"Update Image selection in functional test

* Get name by id
* Add delay before element selection

Some other changes are made:

* Use expected conditions before click to the element
* Add wait for page loading after navigation

Change-Id: I279d1c41ad95946af33b79a3a2b22a7c047bb76c
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/85/112785/16 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/tests/functional/sanity_check.py', 'muranodashboard/tests/functional/base.py']",2,ce17f1f4048fc5a54ef258d7af3f0d1bc945449e,update_func_tests," time.sleep(1) ""//select[contains(@name, '{0}')]/option[@value='{1}']"". self.select_from_list('image', self.image.id) self.select_from_list('type', 'linux')"," ""//select[@name='{0}']/option[text()='{1}']"". self.select_from_list('image', self.image.name) self.select_from_list('type', 'Generic Linux')",8,7
openstack%2Fnova~master~Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035,openstack/nova,master,Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035,Port images and image_metadata for V2.1 on V3 framework,ABANDONED,2014-03-30 13:51:42.000000000,2014-08-14 07:38:36.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8163}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-03-30 13:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a97a5e2213183025b698f1edabd762dd3342cb4', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 2, 'created': '2014-03-31 11:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/281da63b92f20f06d18a84e8bab0fc85ddc1ef76', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 3, 'created': '2014-04-01 05:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f8eaca926c407108cedccf15ea3576329450e34', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 4, 'created': '2014-04-02 00:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ca5bb595c4764ac53850fd654c4c2a18c5943ce', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 5, 'created': '2014-04-02 05:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd095cf7b5de511b06083f8db99e2122b5e5cc3a', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 6, 'created': '2014-04-02 13:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea74bbc584295762d9cd41097068074f36fcd7c0', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 7, 'created': '2014-04-03 02:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f47e90447e479649e5b03d8f93523352c692e669', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 8, 'created': '2014-04-03 03:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aef14a23a94450d78c297a6a3c69010ffe767c0a', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 9, 'created': '2014-04-05 15:37:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f478970a3fb4b85557df70854aeb1c8e37017963', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 10, 'created': '2014-04-05 17:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/410b13795d0b9067307923a9360e5fb357dde501', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 11, 'created': '2014-04-08 06:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae1b70ea1f02106b1f2de2c92f1e6373edc00ab8', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 12, 'created': '2014-04-15 06:51:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/04285fa906d812abc653059fc3893b6a3c22597a', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}, {'number': 13, 'created': '2014-04-22 04:44:31.000000000', 'files': ['nova/api/openstack/compute/plugins/v2/images.py', 'nova/tests/api/openstack/compute/plugins/v2/test_images.py', 'nova/tests/api/openstack/compute/plugins/v2/__init__.py', 'nova/tests/api/openstack/compute/plugins/v2/test_image_metadata.py', 'nova/api/openstack/compute/plugins/v2/image_metadata.py', 'setup.cfg', 'nova/api/openstack/compute/plugins/v2/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9d68c1b4cd5a2d43d45111453e17f53855fd56d6', 'message': 'Port images and image_metadata for V2.1 on V3 framework\n\nPort the images and image_metadata from V2 to V2.1 (using\nthe V3 framework).\n\nTODO:\n- input validation\n- should probably just inherit off V2 tests\n  and then add any additional tests required related\n  to input validation\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035\n'}]",16,84008,9d68c1b4cd5a2d43d45111453e17f53855fd56d6,108,11,13,5292,,,0,"Port images and image_metadata for V2.1 on V3 framework

Port the images and image_metadata from V2 to V2.1 (using
the V3 framework).

TODO:
- input validation
- should probably just inherit off V2 tests
  and then add any additional tests required related
  to input validation

Partially implements blueprint v2-on-v3-api

Change-Id: Ib1d036e58b64dd5fb296d0aafdf89ac4e9ba4035
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/84008/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v2/images.py', 'nova/tests/api/openstack/compute/plugins/v2/test_images.py', 'nova/tests/api/openstack/compute/plugins/v2/__init__.py', 'nova/tests/api/openstack/compute/plugins/v2/test_image_metadata.py', 'nova/api/openstack/compute/plugins/v2/image_metadata.py', 'setup.cfg', 'nova/api/openstack/compute/plugins/v2/__init__.py']",7,9a97a5e2213183025b698f1edabd762dd3342cb4,bp/v2-on-v3-api,,,1675,0
openstack%2Fkeystone~master~I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2,openstack/keystone,master,I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2,Do not require method attribute on plugins,MERGED,2014-07-18 01:41:32.000000000,2014-08-14 06:56:22.000000000,2014-08-14 06:56:21.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 8871}, {'_account_id': 8978}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-07-18 01:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9534a637749531af4e8af9d6df43b79aa82609f2', 'message': 'Do not require method attribute on plugins\n\nCloses-Bug: #1343709\n\nChange-Id: I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2\n'}, {'number': 2, 'created': '2014-07-18 14:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b9a02cf62153bb6f062ad48e31056cf14bc1bbc6', 'message': 'Do not require method attribute on plugins\n\nCloses-Bug: #1343709\n\nChange-Id: I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2\n'}, {'number': 3, 'created': '2014-07-18 15:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4ca44c24d0e1b65b89309f9e369abe381dd5becd', 'message': 'Do not require method attribute on plugins\n\nCloses-Bug: #1343709\n\nChange-Id: I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2\n'}, {'number': 4, 'created': '2014-07-18 21:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e2a5411aa13f437c18d7d4f5776bb79fb55db172', 'message': 'Do not require method attribute on plugins\n\nRemoves the condition that an authentication plugin knows the ""method"" name that is going to be used to call it. This condition prevents different mechanisms like ""kerberos"" and ""saml"" from using the same backend plugin.  \n\nThe client should not know how the server is enforcing the Kerberos authentication,  mod_auth_kerb or embedded Kerberos,  but the mod_auth_kerb implementation needs to use the same implementation as an X509 implementation.\n\n\n\n\nCloses-Bug: #1343709\n\nChange-Id: I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2'}, {'number': 5, 'created': '2014-07-18 21:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/16d368afddee7d44c52749d9c079d6fb5bb3a0ac', 'message': 'Do not require method attribute on plugins\n\nRemoves the condition that an authentication plugin knows \nthe ""method"" name that is going to be used to call it. This \ncondition prevents different mechanisms like ""kerberos"" and \n""saml"" from using the same backend plugin.  \n\nThe client should not know how the server is enforcing the \nKerberos authentication,  mod_auth_kerb or embedded Kerberos, \nbut the mod_auth_kerb implementation needs to use the same \nimplementation as an X509 implementation.\n\n\nCloses-Bug: #1343709\nChange-Id: I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2\n'}, {'number': 6, 'created': '2014-07-18 21:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/83f5c4851293840030ab4f7b4c453c07f0c78d61', 'message': 'Do not require method attribute on plugins\n\nRemoves the condition that an authentication plugin knows the ""method""\nname that is going to be used to call it. This condition prevents\ndifferent mechanisms like ""kerberos"" and ""saml"" from using the same\nbackend plugin.  \n\nThe client should not know how the server is enforcing the Kerberos\nauthentication,  mod_auth_kerb or embedded Kerberos,  but the\nmod_auth_kerb implementation needs to use the same implementation as an\nX509 implementation.\n\n\n\n\nCloses-Bug: #1343709\n\nChange-Id: I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2'}, {'number': 7, 'created': '2014-08-13 16:23:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2a9da2aa76e9ab714c40eb8f88ab64b84f47112a', 'message': 'Do not require method attribute on plugins\n\nRemoves the condition that an authentication plugin knows the ""method""\nname that is going to be used to call it. This condition prevents\ndifferent mechanisms like ""kerberos"" and ""saml"" from using the same\nbackend plugin.\n\nThe client should not know how the server is enforcing the Kerberos\nauthentication,  mod_auth_kerb or embedded Kerberos,  but the\nmod_auth_kerb implementation needs to use the same implementation as an\nX509 implementation.\n\n\n\n\nCloses-Bug: #1343709\n\nChange-Id: I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2'}, {'number': 8, 'created': '2014-08-14 02:52:47.000000000', 'files': ['keystone/auth/controllers.py', 'keystone/tests/test_auth_plugin.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1a610dcc25cb95b1013c40dbf8d70136ac36fa3a', 'message': 'Do not require method attribute on plugins\n\nRemoves the condition that an authentication plugin knows the ""method""\nname that is going to be used to call it. This condition prevents\ndifferent mechanisms like ""kerberos"" and ""saml"" from using the same\nbackend plugin.\n\nThe client should not know how the server is enforcing the Kerberos\nauthentication,  mod_auth_kerb or embedded Kerberos,  but the\nmod_auth_kerb implementation needs to use the same implementation as an\nX509 implementation.\n\nCloses-Bug: #1343709\n\nChange-Id: I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2\n'}]",3,107873,1a610dcc25cb95b1013c40dbf8d70136ac36fa3a,51,9,8,2218,,,0,"Do not require method attribute on plugins

Removes the condition that an authentication plugin knows the ""method""
name that is going to be used to call it. This condition prevents
different mechanisms like ""kerberos"" and ""saml"" from using the same
backend plugin.

The client should not know how the server is enforcing the Kerberos
authentication,  mod_auth_kerb or embedded Kerberos,  but the
mod_auth_kerb implementation needs to use the same implementation as an
X509 implementation.

Closes-Bug: #1343709

Change-Id: I6c7d44d3809e5e88cc50c50b6df6f3a154df7ab2
",git fetch https://review.opendev.org/openstack/keystone refs/changes/73/107873/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/auth/controllers.py', 'keystone/tests/test_auth_plugin.py']",2,9534a637749531af4e8af9d6df43b79aa82609f2,bug/1343709,," def test_mismatched_auth_method_and_plugin_attribute(self): test_opt = config.cfg.StrOpt('test') def clear_and_unregister_opt(): # NOTE(morganfainberg): Reset is required before unregistering # arguments or ArgsAlreadyParsedError is raised. config.CONF.reset() config.CONF.unregister_opt(test_opt, 'auth') self.addCleanup(clear_and_unregister_opt) # Guarantee we register the option we expect to unregister in cleanup config.CONF.register_opt(test_opt, 'auth') self.config_fixture.config(group='auth', methods=['test']) self.config_fixture.config( group='auth', test='keystone.tests.test_auth_plugin.MismatchedAuthPlugin') self.clear_auth_plugin_registry() self.assertRaises(ValueError, auth.controllers.load_auth_methods)",4,33
openstack%2Fneutron~master~Id3a6fe145058f690e107bfe7023980ede61cff90,openstack/neutron,master,Id3a6fe145058f690e107bfe7023980ede61cff90,Fix KeyError during sync_routers,MERGED,2014-08-12 16:28:11.000000000,2014-08-14 06:49:57.000000000,2014-08-14 02:09:30.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10692}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-08-12 16:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa9a878916b23baa0de7ba7df8dda3d0d694d39a', 'message': 'Fix KeyError during sync_routers\n\nMethod sync_routers is used by the L3 agent to query\nrouters it knows about. Routers and GW ports lists\nare populated in two different times, which means that\nthey can be interleaved by a delete request which\nresults in gateway ports being missing in one of the\ntwo data structures.\n\nThis patch takes care of the race condition.\n\nCloses-bug: #1355409\n\nChange-Id: Id3a6fe145058f690e107bfe7023980ede61cff90\n'}, {'number': 2, 'created': '2014-08-12 19:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ccf123aadb78d20e7230fa7e01af507856c529e', 'message': 'Fix KeyError during sync_routers\n\nMethod sync_routers is used by the L3 agent to query\nrouters it knows about. Routers and GW ports lists\nare populated in two different times, which means that\nthey can be interleaved by a delete request which\nresults in gateway ports being missing in one of the\ntwo data structures.\n\nThis patch takes care of the race condition.\n\nCloses-bug: #1355409\n\nChange-Id: Id3a6fe145058f690e107bfe7023980ede61cff90\n'}, {'number': 3, 'created': '2014-08-12 19:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58e4501ff9348d6e36f45e7c930eeffc7b212e5b', 'message': 'Fix KeyError during sync_routers\n\nMethod sync_routers is used by the L3 agent to query\nrouters it knows about. Routers and GW ports lists\nare populated in two different times, which means that\nthey can be interleaved by a delete request which\nresults in gateway ports being missing in one of the\ntwo data structures.\n\nThis patch takes care of the race condition.\n\nCloses-bug: #1355409\n\nChange-Id: Id3a6fe145058f690e107bfe7023980ede61cff90\n'}, {'number': 4, 'created': '2014-08-13 14:13:20.000000000', 'files': ['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/db/l3_gwmode_db.py', 'neutron/db/l3_dvr_db.py', 'neutron/tests/unit/test_extension_ext_gw_mode.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/aee5344db7972e2e12ed056c2e6467f7952aec3f', 'message': 'Fix KeyError during sync_routers\n\nMethod sync_routers is used by the L3 agent to query\nrouters it knows about. Routers and GW ports lists\nare populated in two different times, which means that\nthey can be interleaved by a delete request which\nresults in gateway ports being missing in one of the\ntwo data structures.\n\nThis patch takes care of the race condition.\n\nCloses-bug: #1355409\n\nChange-Id: Id3a6fe145058f690e107bfe7023980ede61cff90\n'}]",4,113580,aee5344db7972e2e12ed056c2e6467f7952aec3f,79,22,4,748,,,0,"Fix KeyError during sync_routers

Method sync_routers is used by the L3 agent to query
routers it knows about. Routers and GW ports lists
are populated in two different times, which means that
they can be interleaved by a delete request which
results in gateway ports being missing in one of the
two data structures.

This patch takes care of the race condition.

Closes-bug: #1355409

Change-Id: Id3a6fe145058f690e107bfe7023980ede61cff90
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/113580/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_dvr_db.py', 'neutron/db/l3_db.py']",2,aa9a878916b23baa0de7ba7df8dda3d0d694d39a,bug/1355409," # Ensure we deal with missing gw ports if gw_port_id and gw_ports.get(gw_port_id): # NOTE(armando-migliaccio): between get_routers and get_sync_gw_ports # gw ports may get deleted, which means that router_dicts may contain # ports that gw_ports does not; we should rebuild router_dicts, instead # of forcing the callee to check for missing gw_ports", if gw_port_id:,8,2
openstack%2Fsecurity-doc~master~I2046734641549fb998ce8428f18f7cf5788ee0ed,openstack/security-doc,master,I2046734641549fb998ce8428f18f7cf5788ee0ed,Imported Translations from Transifex,MERGED,2014-08-14 06:04:52.000000000,2014-08-14 06:42:40.000000000,2014-08-14 06:42:40.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-14 06:04:52.000000000', 'files': ['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/3b374019338282e7b288aa7d3fe262f034071538', 'message': 'Imported Translations from Transifex\n\nChange-Id: I2046734641549fb998ce8428f18f7cf5788ee0ed\n'}]",0,114129,3b374019338282e7b288aa7d3fe262f034071538,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I2046734641549fb998ce8428f18f7cf5788ee0ed
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/29/114129/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po']",2,3b374019338282e7b288aa7d3fe262f034071538,transifex/translations,"""POT-Creation-Date: 2014-08-13 12:36+0000\n"" ""PO-Revision-Date: 2014-08-13 12:37+0000\n""#: ./security-guide/section_hardening-the-virtualization-layers.xml310(None) #: ./security-guide/section_hardening-the-virtualization-layers.xml314(None)#: ./security-guide/section_hardening-the-virtualization-layers.xml118(para) msgid """" ""Additionally, ensure iptables has the default policy filtering network "" ""traffic, and consider examining the existing rule set to understand each "" ""rule and determine if the policy needs to be expanded upon."" msgstr """" #: ./security-guide/section_hardening-the-virtualization-layers.xml124(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml125(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml138(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml149(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml150(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml159(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml168(term)#: ./security-guide/section_hardening-the-virtualization-layers.xml170(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml180(term)#: ./security-guide/section_hardening-the-virtualization-layers.xml182(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml188(term)#: ./security-guide/section_hardening-the-virtualization-layers.xml190(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml197(term)#: ./security-guide/section_hardening-the-virtualization-layers.xml199(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml205(term)#: ./security-guide/section_hardening-the-virtualization-layers.xml207(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml215(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml222(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml226(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml235(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml238(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml243(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml244(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml258(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml259(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml270(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml275(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml285(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml298(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml318(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml327(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml328(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml339(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml348(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml353(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml354(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml358(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml366(emphasis)#: ./security-guide/section_hardening-the-virtualization-layers.xml367(emphasis)#: ./security-guide/section_hardening-the-virtualization-layers.xml372(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml373(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml376(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml377(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml380(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml381(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml384(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml385(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml388(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml389(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml392(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml393(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml396(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml397(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml400(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml401(para)#: ./security-guide/section_security-services-for-instances.xml89(title)#: ./security-guide/section_security-services-for-instances.xml157(title)#: ./security-guide/section_security-services-for-instances.xml59(title)#: ./security-guide/section_security-services-for-instances.xml60(para)#: ./security-guide/section_security-services-for-instances.xml71(title)#: ./security-guide/section_security-services-for-instances.xml72(para)#: ./security-guide/section_security-services-for-instances.xml75(title)#: ./security-guide/section_security-services-for-instances.xml76(para)#: ./security-guide/section_security-services-for-instances.xml79(title)#: ./security-guide/section_security-services-for-instances.xml80(para)#: ./security-guide/section_security-services-for-instances.xml83(title)#: ./security-guide/section_security-services-for-instances.xml84(para)#: ./security-guide/section_security-services-for-instances.xml85(para)#: ./security-guide/section_security-services-for-instances.xml90(para)#: ./security-guide/section_security-services-for-instances.xml92(title)#: ./security-guide/section_security-services-for-instances.xml93(para)#: ./security-guide/section_security-services-for-instances.xml101(para)#: ./security-guide/section_security-services-for-instances.xml108(para)#: ./security-guide/section_security-services-for-instances.xml109(para)#: ./security-guide/section_security-services-for-instances.xml110(para)#: ./security-guide/section_security-services-for-instances.xml146(para)#: ./security-guide/section_security-services-for-instances.xml147(para)#: ./security-guide/section_security-services-for-instances.xml150(title)#: ./security-guide/section_security-services-for-instances.xml151(para)#: ./security-guide/section_security-services-for-instances.xml152(para)#: ./security-guide/section_security-services-for-instances.xml153(para)#: ./security-guide/section_security-services-for-instances.xml158(para)#: ./security-guide/section_security-services-for-instances.xml168(para)#: ./security-guide/section_security-services-for-instances.xml169(para)#: ./security-guide/section_security-services-for-instances.xml170(para)#: ./security-guide/section_security-services-for-instances.xml171(para)#: ./security-guide/section_security-services-for-instances.xml172(para)#: ./security-guide/section_security-services-for-instances.xml175(title)#: ./security-guide/section_security-services-for-instances.xml176(para)#: ./security-guide/section_security-services-for-instances.xml178(para)#: ./security-guide/section_security-services-for-instances.xml181(para)#: ./security-guide/section_security-services-for-instances.xml184(para)#: ./security-guide/section_security-services-for-instances.xml187(para)#: ./security-guide/section_security-services-for-instances.xml192(title)#: ./security-guide/section_security-services-for-instances.xml193(para)#: ./security-guide/section_security-services-for-instances.xml195(para) #: ./security-guide/section_security-services-for-instances.xml205(title)#: ./security-guide/section_security-services-for-instances.xml198(para)#: ./security-guide/section_security-services-for-instances.xml201(para) #: ./security-guide/section_security-services-for-instances.xml218(title)#: ./security-guide/section_security-services-for-instances.xml206(para)#: ./security-guide/section_security-services-for-instances.xml214(title)#: ./security-guide/section_security-services-for-instances.xml215(para)#: ./security-guide/section_security-services-for-instances.xml219(para)#: ./security-guide/section_security-services-for-instances.xml221(para)#: ./security-guide/section_security-services-for-instances.xml222(para)#: ./security-guide/section_security-services-for-instances.xml223(para)","""POT-Creation-Date: 2014-08-12 03:05+0000\n"" ""PO-Revision-Date: 2014-08-12 00:38+0000\n""#: ./security-guide/section_hardening-the-virtualization-layers.xml305(None) #: ./security-guide/section_hardening-the-virtualization-layers.xml309(None)#: ./security-guide/section_hardening-the-virtualization-layers.xml119(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml120(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml133(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml144(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml145(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml154(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml163(term)#: ./security-guide/section_hardening-the-virtualization-layers.xml165(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml175(term)#: ./security-guide/section_hardening-the-virtualization-layers.xml177(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml183(term)#: ./security-guide/section_hardening-the-virtualization-layers.xml185(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml192(term)#: ./security-guide/section_hardening-the-virtualization-layers.xml194(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml200(term)#: ./security-guide/section_hardening-the-virtualization-layers.xml202(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml210(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml217(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml221(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml230(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml233(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml238(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml239(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml253(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml254(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml265(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml270(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml280(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml293(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml313(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml322(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml323(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml334(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml343(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml348(title)#: ./security-guide/section_hardening-the-virtualization-layers.xml349(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml353(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml361(emphasis)#: ./security-guide/section_hardening-the-virtualization-layers.xml362(emphasis)#: ./security-guide/section_hardening-the-virtualization-layers.xml367(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml368(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml371(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml372(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml375(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml376(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml379(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml380(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml383(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml384(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml387(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml388(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml391(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml392(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml395(para)#: ./security-guide/section_hardening-the-virtualization-layers.xml396(para)#: ./security-guide/section_security-services-for-instances.xml90(title)#: ./security-guide/section_security-services-for-instances.xml158(title)#: ./security-guide/section_security-services-for-instances.xml57(emphasis) msgid ""Tenant Driven Whole Host Reservation"" msgstr ""テナントによるホスト全体予約"" #: ./security-guide/section_security-services-for-instances.xml58(para) msgid """" ""There currently exists a <link "" ""href=\""https://blueprints.launchpad.net/nova/+spec/whole-host-"" ""allocation\"">blueprint for whole host reservation</link> - This would allow "" ""a tenant to exclusively reserve hosts for only it's instances, incurring "" ""extra costs."" msgstr ""現在、<link href=\""https://blueprints.launchpad.net/nova/+spec/whole-host-allocation\"">ホスト全体予約のブループリント</link>が公開されています。これによって効率面の負担はありますが、テナントは抱えるインスタンスのみのためにホストを確保できます。"" #: ./security-guide/section_security-services-for-instances.xml60(title)#: ./security-guide/section_security-services-for-instances.xml61(para)#: ./security-guide/section_security-services-for-instances.xml72(title)#: ./security-guide/section_security-services-for-instances.xml73(para)#: ./security-guide/section_security-services-for-instances.xml76(title)#: ./security-guide/section_security-services-for-instances.xml77(para)#: ./security-guide/section_security-services-for-instances.xml80(title)#: ./security-guide/section_security-services-for-instances.xml81(para)#: ./security-guide/section_security-services-for-instances.xml84(title)#: ./security-guide/section_security-services-for-instances.xml85(para)#: ./security-guide/section_security-services-for-instances.xml86(para)#: ./security-guide/section_security-services-for-instances.xml91(para)#: ./security-guide/section_security-services-for-instances.xml93(title)#: ./security-guide/section_security-services-for-instances.xml94(para)#: ./security-guide/section_security-services-for-instances.xml102(para)#: ./security-guide/section_security-services-for-instances.xml109(para)#: ./security-guide/section_security-services-for-instances.xml110(para)#: ./security-guide/section_security-services-for-instances.xml111(para)#: ./security-guide/section_security-services-for-instances.xml147(para)#: ./security-guide/section_security-services-for-instances.xml148(para)#: ./security-guide/section_security-services-for-instances.xml151(title)#: ./security-guide/section_security-services-for-instances.xml152(para)#: ./security-guide/section_security-services-for-instances.xml153(para)#: ./security-guide/section_security-services-for-instances.xml154(para)#: ./security-guide/section_security-services-for-instances.xml159(para)#: ./security-guide/section_security-services-for-instances.xml169(para)#: ./security-guide/section_security-services-for-instances.xml170(para)#: ./security-guide/section_security-services-for-instances.xml171(para)#: ./security-guide/section_security-services-for-instances.xml172(para)#: ./security-guide/section_security-services-for-instances.xml173(para)#: ./security-guide/section_security-services-for-instances.xml176(title)#: ./security-guide/section_security-services-for-instances.xml177(para)#: ./security-guide/section_security-services-for-instances.xml179(para)#: ./security-guide/section_security-services-for-instances.xml182(para)#: ./security-guide/section_security-services-for-instances.xml185(para)#: ./security-guide/section_security-services-for-instances.xml188(para)#: ./security-guide/section_security-services-for-instances.xml193(title)#: ./security-guide/section_security-services-for-instances.xml194(para)#: ./security-guide/section_security-services-for-instances.xml196(para) #: ./security-guide/section_security-services-for-instances.xml206(title)#: ./security-guide/section_security-services-for-instances.xml199(para)#: ./security-guide/section_security-services-for-instances.xml202(para) #: ./security-guide/section_security-services-for-instances.xml219(title)#: ./security-guide/section_security-services-for-instances.xml207(para)#: ./security-guide/section_security-services-for-instances.xml215(title)#: ./security-guide/section_security-services-for-instances.xml216(para)#: ./security-guide/section_security-services-for-instances.xml220(para)#: ./security-guide/section_security-services-for-instances.xml222(para)#: ./security-guide/section_security-services-for-instances.xml223(para)#: ./security-guide/section_security-services-for-instances.xml224(para)",229,239
openstack%2Fneutron~master~I825b25080cbf054462318fc01248692b9e0e4ecb,openstack/neutron,master,I825b25080cbf054462318fc01248692b9e0e4ecb,Fix PortNotFound exception during sync_routers,MERGED,2014-08-12 05:48:13.000000000,2014-08-14 06:40:58.000000000,2014-08-14 01:13:34.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-12 05:48:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9b3c205c2c6c6adf4feec09d1767a85939086982', 'message': 'Fix PortNotFound exception during sync_routers\n\nThis trace is observed when an L3 agent invokes\nsync_routers right about the same time a port\ninterface is removed from a router.\n\nRelated-bug: #1355409\n\nChange-Id: I825b25080cbf054462318fc01248692b9e0e4ecb\n'}, {'number': 2, 'created': '2014-08-12 17:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/06b0fb31d6dea343fcf8e2fd09ac39fdbff78981', 'message': 'Fix PortNotFound exception during sync_routers\n\nThis trace is observed when an L3 agent invokes\nsync_routers right about the same time a port\ninterface is removed from a router.\n\nRelated-bug: #1355409\n\nChange-Id: I825b25080cbf054462318fc01248692b9e0e4ecb\n'}, {'number': 3, 'created': '2014-08-13 01:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66b92db5ad3d82fde1219b576ac6aae3d40cf7b0', 'message': 'Fix PortNotFound exception during sync_routers\n\nThis trace is observed when an L3 agent invokes\nsync_routers right about the same time a port\ninterface is removed from a router.\n\nRelated-bug: #1355409\n\nChange-Id: I825b25080cbf054462318fc01248692b9e0e4ecb\n'}, {'number': 4, 'created': '2014-08-13 05:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7be38bed94878d6c3aebfec48bab49ac9d72e19b', 'message': 'Fix PortNotFound exception during sync_routers\n\nThis trace is observed when an L3 agent invokes\nsync_routers right about the same time a port\ninterface is removed from a router.\n\nRelated-bug: #1355409\n\nChange-Id: I825b25080cbf054462318fc01248692b9e0e4ecb\n'}, {'number': 5, 'created': '2014-08-13 14:04:39.000000000', 'files': ['neutron/tests/unit/test_l3_plugin.py', 'neutron/db/l3_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2affc39d3ad2d30c54e3373249446f61ee59f881', 'message': 'Fix PortNotFound exception during sync_routers\n\nThis trace is observed when an L3 agent invokes\nsync_routers right about the same time a port\ninterface is removed from a router.\n\nRelated-bug: #1355409\n\nChange-Id: I825b25080cbf054462318fc01248692b9e0e4ecb\n'}]",12,113441,2affc39d3ad2d30c54e3373249446f61ee59f881,112,26,5,748,,,0,"Fix PortNotFound exception during sync_routers

This trace is observed when an L3 agent invokes
sync_routers right about the same time a port
interface is removed from a router.

Related-bug: #1355409

Change-Id: I825b25080cbf054462318fc01248692b9e0e4ecb
",git fetch https://review.opendev.org/openstack/neutron refs/changes/41/113441/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_rpc_base.py'],1,9b3c205c2c6c6adf4feec09d1767a85939086982,bug/1355409,"from neutron.common import exceptions try: self.plugin.update_port(context, port['id'], {'port': {portbindings.HOST_ID: host}}) except exceptions.PortNotFound: LOG.debug(""Port %(port)s for router %(router)s deleted."" % {""port"": port['id'], ""router"": router_id})"," self.plugin.update_port(context, port['id'], {'port': {portbindings.HOST_ID: host}})",7,2
openstack%2Fopenstack-manuals~master~I33f4acd72d3812048bc15d28f38f789b5db4d1e8,openstack/openstack-manuals,master,I33f4acd72d3812048bc15d28f38f789b5db4d1e8,Added missing close bracket in the Telemetry documentation,MERGED,2014-08-13 22:08:51.000000000,2014-08-14 06:26:13.000000000,2014-08-14 06:26:12.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6772}, {'_account_id': 8103}]","[{'number': 1, 'created': '2014-08-13 22:08:51.000000000', 'files': ['doc/common/section_getstart_telemetry.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4a3f250c2c4d9c8da214e5da315a7ad5399def3d', 'message': 'Added missing close bracket in the Telemetry documentation\n\nChange-Id: I33f4acd72d3812048bc15d28f38f789b5db4d1e8\n'}]",0,114045,4a3f250c2c4d9c8da214e5da315a7ad5399def3d,9,4,1,9191,,,0,"Added missing close bracket in the Telemetry documentation

Change-Id: I33f4acd72d3812048bc15d28f38f789b5db4d1e8
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/45/114045/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/section_getstart_telemetry.xml'],1,4a3f250c2c4d9c8da214e5da315a7ad5399def3d,rdo/close-bracket, >ceilometer-collector</systemitem>)</term>, >ceilometer-collector</systemitem></term>,1,1
openstack%2Fnova~master~I397de1a45d785915e3558e8e2ec39123f1912e39,openstack/nova,master,I397de1a45d785915e3558e8e2ec39123f1912e39,upgrade websockify module to resolve novncproxy zombie processes bug,ABANDONED,2014-05-22 06:38:28.000000000,2014-08-14 06:05:59.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8021}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9608}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-22 06:38:28.000000000', 'files': ['requirements.txt', 'nova/console/websocketproxy.py', 'nova/cmd/novncproxy.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/82a710bf0d0e507634075711acdc639682b54f97', 'message': 'upgrade websockify module to resolve novncproxy zombie processes bug\n\ncurrently novncproxy will leave zombie processes due to some bug in\nwebsockify module. This bug had been fixed in websockify since version\n0.6.0, we need upgrade websockify module to fix this bug in novncproxy.\nBesides, websockify 0.6.0 support python logging module, so I enabled\nlog for novncproxy service too.\n\nRelated-Bug: 1048703\n\nChange-Id: I397de1a45d785915e3558e8e2ec39123f1912e39\n'}]",0,94778,82a710bf0d0e507634075711acdc639682b54f97,12,8,1,2967,,,0,"upgrade websockify module to resolve novncproxy zombie processes bug

currently novncproxy will leave zombie processes due to some bug in
websockify module. This bug had been fixed in websockify since version
0.6.0, we need upgrade websockify module to fix this bug in novncproxy.
Besides, websockify 0.6.0 support python logging module, so I enabled
log for novncproxy service too.

Related-Bug: 1048703

Change-Id: I397de1a45d785915e3558e8e2ec39123f1912e39
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/94778/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'nova/console/websocketproxy.py', 'nova/cmd/novncproxy.py']",3,82a710bf0d0e507634075711acdc639682b54f97,bug/1048703,"from nova.openstack.common import log as logging logging.setup(""nova"")"," no_parent=True,",13,9
openstack%2Fnova~master~Ia2d395eac5bc14f1c88dbdd8660fd7349a20f467,openstack/nova,master,Ia2d395eac5bc14f1c88dbdd8660fd7349a20f467,Add a setup-hook that generates the config sample,ABANDONED,2014-04-16 09:50:47.000000000,2014-08-14 06:05:01.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 1955}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7808}, {'_account_id': 8163}, {'_account_id': 8910}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-16 09:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cdb169df4f24e45a3b167ef61996b1f332e546ac', 'message': ""Add a setup-hook that generates the config sample\n\nAdd a hook that will generate the sample configuration file and include\nit to the extra_files when creating the tarball.\n\nThe hook won't try to re-generate the file if it already exists and\nwon't prevent the command (sdist) to fail if there is an error during\nthe generation (e.g. running it without the requirements installed).\n\nChange-Id: Ia2d395eac5bc14f1c88dbdd8660fd7349a20f467\nCloses-bug: #1301519\n""}, {'number': 2, 'created': '2014-04-16 09:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc69bdbf93ac4a005c81af321d189e6c1da7bd22', 'message': ""Add a setup-hook that generates the config sample\n\nAdd a hook that will generate the sample configuration file and include\nit to the extra_files when creating the tarball.\n\nThe hook won't try to re-generate the file if it already exists and\nwon't prevent the command (sdist) to fail if there is an error during\nthe generation (e.g. running it without the requirements installed).\n\nChange-Id: Ia2d395eac5bc14f1c88dbdd8660fd7349a20f467\nCloses-bug: #1301519\n""}, {'number': 3, 'created': '2014-04-16 15:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ddf1979c6eeed5282fe9153771f67d14757de55a', 'message': ""Add a setup-hook that generates the config sample\n\nAdd a hook that will generate the sample configuration file and include\nit to the extra_files when running the sdist command. It won't do\nanything for all the other commands.\n\nThe hook won't fail if the generation of the file fails to prevent the\ncommand from failing if not all the requirements are available.\n\nChange-Id: Ia2d395eac5bc14f1c88dbdd8660fd7349a20f467\nCloses-bug: #1301519\n""}, {'number': 4, 'created': '2014-04-17 08:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d4ffcf21914cf2add12b361800274e899073a4b', 'message': ""Add a setup-hook that generates the config sample\n\nAdd a hook that will generate the sample configuration file and include\nit to the extra_files when running the sdist command. It won't do\nanything for all the other commands.\n\nThe hook won't fail if the generation of the file fails to prevent the\ncommand from failing if not all the requirements are available.\n\nChange-Id: Ia2d395eac5bc14f1c88dbdd8660fd7349a20f467\nCloses-bug: #1301519\n""}, {'number': 5, 'created': '2014-04-18 12:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b6123636d1045710f739453c48b192c11eadbcc', 'message': ""Add a setup-hook that generates the config sample\n\nAdd a hook that will generate the sample configuration file and include\nit to the extra_files when running the sdist command. It won't do\nanything for all the other commands.\n\nThe hook won't fail if the generation of the file fails to prevent the\ncommand from failing if not all the requirements are available.\n\nChange-Id: Ia2d395eac5bc14f1c88dbdd8660fd7349a20f467\nCloses-bug: #1301519\n""}, {'number': 6, 'created': '2014-04-26 19:26:26.000000000', 'files': ['tools/config/generate_sample.sh', 'nova/setup_hooks.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/nova/commit/183c8ae758dbdf69bb438ffc92b726c847acb021', 'message': ""Add a setup-hook that generates the config sample\n\nAdd a hook that will generate the sample configuration file and include\nit to the extra_files when running the sdist command. It won't do\nanything for all the other commands.\n\nThe hook won't fail if the generation of the file fails to prevent the\ncommand from failing if not all the requirements are available.\n\nChange-Id: Ia2d395eac5bc14f1c88dbdd8660fd7349a20f467\nCloses-bug: #1301519\n""}]",8,87896,183c8ae758dbdf69bb438ffc92b726c847acb021,89,15,6,7808,,,0,"Add a setup-hook that generates the config sample

Add a hook that will generate the sample configuration file and include
it to the extra_files when running the sdist command. It won't do
anything for all the other commands.

The hook won't fail if the generation of the file fails to prevent the
command from failing if not all the requirements are available.

Change-Id: Ia2d395eac5bc14f1c88dbdd8660fd7349a20f467
Closes-bug: #1301519
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/87896/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/pbr_hook.py', 'tools/config/generate_sample.sh', 'setup.cfg']",3,cdb169df4f24e45a3b167ef61996b1f332e546ac,xqueralt_generate_config_setup, nova.pbr_hook.config_hook,,47,0
openstack%2Fnova~master~Iaacf5d5c836dc345cb8f5660305b5563827818ce,openstack/nova,master,Iaacf5d5c836dc345cb8f5660305b5563827818ce,Add node manager to read power/temperature of compute node,ABANDONED,2014-01-09 08:00:06.000000000,2014-08-14 06:01:44.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 4458}, {'_account_id': 4491}, {'_account_id': 4992}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11235}]","[{'number': 1, 'created': '2014-01-09 08:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1df0f53b8d35beb43cfc5a07ab3a31987bb5a275', 'message': 'Add node manager to read power/temperature of compute node\n\nThe patch implements the Intel node manager by using IPMI command to\nread power/temperature of compute node. It will be used in power and\ntemperature monitor plugin.\n\nThis is part of the blueprint utilization-aware-scheduling.\n\nChange-Id: Iaacf5d5c836dc345cb8f5660305b5563827818ce\n'}, {'number': 2, 'created': '2014-02-26 07:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/82de46032e92bf4a83cca436f31efbeed1d8ca4f', 'message': 'Add node manager to read power/temperature of compute node\n\nThe patch implements the Intel node manager by using IPMI command to\nread power/temperature of compute node. It will be used in power and\ntemperature monitor plugin.\n\nThis is part of the blueprint utilization-aware-scheduling.\n\nChange-Id: Iaacf5d5c836dc345cb8f5660305b5563827818ce\n'}, {'number': 3, 'created': '2014-05-14 07:54:33.000000000', 'files': ['nova/compute/monitors/nodemanager/node_manager.py', 'nova/compute/monitors/nodemanager/__init__.py', 'nova/exception.py', 'nova/tests/compute/monitors/test_node_manager.py', 'nova/compute/monitors/nodemanager/nm_common.py', 'nova/compute/monitors/nodemanager/nm_exception.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2bcc4c0f358f9661278b249a52cffb82fcf343f5', 'message': 'Add node manager to read power/temperature of compute node\n\nThe patch implements the Intel node manager by using IPMI command to\nread power/temperature of compute node. It will be used in power and\ntemperature monitor plugin.\n\nImplements: blueprint add-useful-metrics\n\nChange-Id: Iaacf5d5c836dc345cb8f5660305b5563827818ce\n'}]",13,65631,2bcc4c0f358f9661278b249a52cffb82fcf343f5,131,12,3,7642,,,0,"Add node manager to read power/temperature of compute node

The patch implements the Intel node manager by using IPMI command to
read power/temperature of compute node. It will be used in power and
temperature monitor plugin.

Implements: blueprint add-useful-metrics

Change-Id: Iaacf5d5c836dc345cb8f5660305b5563827818ce
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/65631/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/monitors/nodemanager/__init__.py', 'nova/compute/monitors/nodemanager/node_manager.py', 'nova/tests/compute/monitors/test_node_manager.py', 'nova/compute/monitors/nodemanager/nm_common.py', 'nova/compute/monitors/nodemanager/nm_exception.py']",5,1df0f53b8d35beb43cfc5a07ab3a31987bb5a275,bp/add-useful-metrics,"# Copyright 2013 Intel Corporation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # @author: Fengqian Gao, Intel Corporation. class NodeManagerException(Exception): pass class IPMIException(Exception): pass ",,387,0
openstack%2Fnova~master~I0da6ee49e678446fcdf0a84efc35a3c53dc9b4c4,openstack/nova,master,I0da6ee49e678446fcdf0a84efc35a3c53dc9b4c4,Added temperature monitor for compute node,ABANDONED,2013-12-30 08:12:42.000000000,2014-08-14 06:00:00.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 4458}, {'_account_id': 4491}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11235}]","[{'number': 1, 'created': '2013-12-30 08:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80b6c2b719bfc6fe9f4a37adee67b29010795335', 'message': 'Added temperature monitor for compute node\n\nThe patch defines the temperature monitor plugin to collect the\ntemperature metrics for the compute node. It uses IPMI command to\nread temperature from Intel Node Manager.\n\nThis is part of the blueprint utilization-aware-scheduling.\n\nChange-Id: I0da6ee49e678446fcdf0a84efc35a3c53dc9b4c4\n'}, {'number': 2, 'created': '2014-01-02 05:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f8ba55cc609506e2a32da836935f339fd50b37c6', 'message': 'Added temperature monitor for compute node\n\nThe patch defines the temperature monitor plugin to collect the\ntemperature metrics for the compute node. It uses IPMI command to\nread temperature from Intel Node Manager.\n\nThis is part of the blueprint utilization-aware-scheduling.\n\nChange-Id: I0da6ee49e678446fcdf0a84efc35a3c53dc9b4c4\n'}, {'number': 3, 'created': '2014-01-09 08:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65ea08b529f5656069a9427b8b31e1b5e49a1382', 'message': 'Added temperature monitor for compute node\n\nThe patch defines the temperature monitor plugin to collect the\ntemperature metrics for the compute node. It uses IPMI command to\nread temperature from Intel Node Manager.\n\nThis is part of the blueprint utilization-aware-scheduling.\n\nChange-Id: I0da6ee49e678446fcdf0a84efc35a3c53dc9b4c4\n'}, {'number': 4, 'created': '2014-02-26 07:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c395fe8fbabf762e44df11c8964ebf615b51949', 'message': 'Added temperature monitor for compute node\n\nThe patch defines the temperature monitor plugin to collect the\ntemperature metrics for the compute node. It uses IPMI command to\nread temperature from Intel Node Manager.\n\nThis is part of the blueprint utilization-aware-scheduling.\n\nChange-Id: I0da6ee49e678446fcdf0a84efc35a3c53dc9b4c4\n'}, {'number': 5, 'created': '2014-05-14 07:54:33.000000000', 'files': ['nova/compute/monitors/temperature_monitor.py', 'nova/compute/monitors/nodemanager/temperature_monitor.py', 'nova/tests/compute/monitors/test_temperature_monitor.py', 'nova/tests/compute/monitors/test_monitors.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3040878b99399dc87fe65a9102565ef5d1e4fab3', 'message': 'Added temperature monitor for compute node\n\nThe patch defines the temperature monitor plugin to collect the\ntemperature metrics for the compute node. It uses IPMI command to\nread temperature from Intel Node Manager.\n\nImplements: blueprint add-useful-metrics\n\nChange-Id: I0da6ee49e678446fcdf0a84efc35a3c53dc9b4c4\n'}]",15,64403,3040878b99399dc87fe65a9102565ef5d1e4fab3,48,12,5,7642,,,0,"Added temperature monitor for compute node

The patch defines the temperature monitor plugin to collect the
temperature metrics for the compute node. It uses IPMI command to
read temperature from Intel Node Manager.

Implements: blueprint add-useful-metrics

Change-Id: I0da6ee49e678446fcdf0a84efc35a3c53dc9b4c4
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/64403/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/monitors/nodemanager/__init__.py', 'nova/compute/monitors/nodemanager/node_manager.py', 'nova/compute/monitors/temperature_monitor.py', 'nova/compute/monitors/nodemanager/temperature_monitor.py', 'nova/tests/compute/monitors/test_temperature_monitor.py', 'nova/compute/monitors/nodemanager/node_manager_common.py', 'nova/compute/monitors/nodemanager/node_manager_exception.py', 'nova/tests/compute/monitors/test_monitors.py']",8,80b6c2b719bfc6fe9f4a37adee67b29010795335,bp/add-useful-metrics," self.assertIn('NodeManagerTemperatureMonitor', self.class_map)",,527,0
openstack%2Fnova~master~I686674f9b8ac3ab7e02afa65e562789478d8faa6,openstack/nova,master,I686674f9b8ac3ab7e02afa65e562789478d8faa6,Added power monitor for compute node,ABANDONED,2013-12-30 08:12:43.000000000,2014-08-14 05:59:27.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 4458}, {'_account_id': 4491}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11235}]","[{'number': 1, 'created': '2013-12-30 08:12:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2da1bcd9598ba2dfd233532720daec707e5424eb', 'message': 'Added power monitor for compute node\n\nThe patch defines the power monitor plugin to collect the\npower metrics for the compute node. It uses IPMI command to\nread power from Intel Node Manager.\n\nThis is part of the blueprint utilization-aware-scheduling.\n\nChange-Id: I686674f9b8ac3ab7e02afa65e562789478d8faa6\n'}, {'number': 2, 'created': '2014-01-02 05:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3ce4ae859b4e245e93b57b0b0ea693f18e4c438', 'message': 'Added power monitor for compute node\n\nThe patch defines the power monitor plugin to collect the\npower metrics for the compute node. It uses IPMI command to\nread power from Intel Node Manager.\n\nThis is part of the blueprint utilization-aware-scheduling.\n\nChange-Id: I686674f9b8ac3ab7e02afa65e562789478d8faa6\n'}, {'number': 3, 'created': '2014-01-09 08:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9c14cdbf0d8d6858046f981e41a55b953250c91', 'message': 'Added power monitor for compute node\n\nThe patch defines the power monitor plugin to collect the\npower metrics for the compute node. It uses IPMI command to\nread power from Intel Node Manager.\n\nThis is part of the blueprint utilization-aware-scheduling.\n\nChange-Id: I686674f9b8ac3ab7e02afa65e562789478d8faa6\n'}, {'number': 4, 'created': '2014-02-26 07:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed4659bc2cda2ae3d5fde2d2610b86d180e3480a', 'message': 'Added power monitor for compute node\n\nThe patch defines the power monitor plugin to collect the\npower metrics for the compute node. It uses IPMI command to\nread power from Intel Node Manager.\n\nThis is part of the blueprint utilization-aware-scheduling.\n\nChange-Id: I686674f9b8ac3ab7e02afa65e562789478d8faa6\n'}, {'number': 5, 'created': '2014-05-14 07:54:33.000000000', 'files': ['nova/compute/monitors/power_monitor.py', 'nova/tests/compute/monitors/test_power_monitor.py', 'nova/compute/monitors/nodemanager/power_monitor.py', 'nova/tests/compute/monitors/test_monitors.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4ba75d938ef23f291c9ad5d6148b648d9c37d723', 'message': 'Added power monitor for compute node\n\nThe patch defines the power monitor plugin to collect the\npower metrics for the compute node. It uses IPMI command to\nread power from Intel Node Manager.\n\nImplements: blueprint add-useful-metrics\n\nChange-Id: I686674f9b8ac3ab7e02afa65e562789478d8faa6\n'}]",1,64404,4ba75d938ef23f291c9ad5d6148b648d9c37d723,46,12,5,7642,,,0,"Added power monitor for compute node

The patch defines the power monitor plugin to collect the
power metrics for the compute node. It uses IPMI command to
read power from Intel Node Manager.

Implements: blueprint add-useful-metrics

Change-Id: I686674f9b8ac3ab7e02afa65e562789478d8faa6
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/64404/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/monitors/power_monitor.py', 'nova/tests/compute/monitors/test_power_monitor.py', 'nova/compute/monitors/nodemanager/power_monitor.py', 'nova/tests/compute/monitors/test_monitors.py']",4,2da1bcd9598ba2dfd233532720daec707e5424eb,bp/add-useful-metrics," self.assertIn('NodeManagerPowerMonitor', self.class_map)",,200,0
openstack%2Fnova~master~I9adfebf04427e0d09b37606390745974cbfe75ee,openstack/nova,master,I9adfebf04427e0d09b37606390745974cbfe75ee,Do not use __builtin__ in python3,ABANDONED,2014-06-12 01:15:15.000000000,2014-08-14 05:53:44.000000000,,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2835}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9008}, {'_account_id': 9323}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-12 01:15:15.000000000', 'files': ['nova/virt/hyperv/pathutils.py', 'nova/tests/virt/xenapi/test_vm_utils.py', 'nova/tests/test_versions.py', 'nova/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4f2c46e8b939b0eb55c3e65ec9c20c725f885fc2', 'message': 'Do not use __builtin__ in python3\n\n__builtin__ does not exist in Python 3, use\nsix.moves.builtins instead.\n\nChange-Id: I9adfebf04427e0d09b37606390745974cbfe75ee\ncloses-bug: #1290234\n'}]",1,99525,4f2c46e8b939b0eb55c3e65ec9c20c725f885fc2,38,12,1,9323,,,0,"Do not use __builtin__ in python3

__builtin__ does not exist in Python 3, use
six.moves.builtins instead.

Change-Id: I9adfebf04427e0d09b37606390745974cbfe75ee
closes-bug: #1290234
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/99525/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/pathutils.py', 'nova/tests/virt/xenapi/test_vm_utils.py', 'nova/tests/test_versions.py', 'nova/tests/test_utils.py']",4,4f2c46e8b939b0eb55c3e65ec9c20c725f885fc2,bug/1290234,import six.moves.builtins as __builtin__,import __builtin__,4,4
openstack%2Fopenstacksdk~master~I8e1fb76b5d48216a75462dd921631afd71dc8c7d,openstack/openstacksdk,master,I8e1fb76b5d48216a75462dd921631afd71dc8c7d,identity/v2 tenant resource,MERGED,2014-08-13 04:40:28.000000000,2014-08-14 05:42:29.000000000,2014-08-14 05:42:29.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-13 04:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/61c2b7d564323938e4d3d24a576b23b5d9a9da46', 'message': 'identity/v2 tenant resource\n\nChange-Id: I8e1fb76b5d48216a75462dd921631afd71dc8c7d\n'}, {'number': 2, 'created': '2014-08-13 07:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a9150ce71ab50c0bd5f56653bc2c3095897dbd28', 'message': 'identity/v2 tenant resource\n\nChange-Id: I8e1fb76b5d48216a75462dd921631afd71dc8c7d\n'}, {'number': 3, 'created': '2014-08-14 00:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/630b5ab53ef873fe2a210209e6c8de95a80de05b', 'message': 'identity/v2 tenant resource\n\nChange-Id: I8e1fb76b5d48216a75462dd921631afd71dc8c7d\n'}, {'number': 4, 'created': '2014-08-14 05:19:04.000000000', 'files': ['openstack/tests/identity/v2/test_tenant.py', 'openstack/identity/v2/tenant.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a39786e0f76279173f6146abdc4f5966974c2998', 'message': 'identity/v2 tenant resource\n\nChange-Id: I8e1fb76b5d48216a75462dd921631afd71dc8c7d\n'}]",2,113768,a39786e0f76279173f6146abdc4f5966974c2998,18,3,4,7191,,,0,"identity/v2 tenant resource

Change-Id: I8e1fb76b5d48216a75462dd921631afd71dc8c7d
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/68/113768/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/identity/v2/test_tenant.py', 'openstack/identity/v2/tenant.py']",2,61c2b7d564323938e4d3d24a576b23b5d9a9da46,user,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack.identity import identity_service from openstack import resource class Tenant(resource.Resource): resource_key = 'tenant' resources_key = 'tenants' base_path = '/tenants' service = identity_service.AdminService() # capabilities allow_create = True allow_retrieve = True allow_update = True allow_delete = True allow_list = True # Properties description = resource.prop('description') enabled = resource.prop('enabled') name = resource.prop('name') ",,78,0
openstack%2Fneutron~master~I48286cda23d9737ddd90251dc0d1db1c310e7784,openstack/neutron,master,I48286cda23d9737ddd90251dc0d1db1c310e7784,VPNaaS: Cisco fix validation for GW IP,MERGED,2014-08-13 02:16:09.000000000,2014-08-14 05:42:01.000000000,2014-08-14 04:31:25.000000000,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 490}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6995}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10692}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-13 02:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ff093e387890d555567df0df359a6c83b8d2bf1', 'message': ""VPNaaS: Cisco fix validation for GW IP\n\nThe validation to check that the router has a GW IP\nfor the Cisco service driver was trying to directly\nthe gw_port information, which is not available, as\nthe validator only has a dict of the vpn_service info.\n\nModified validator to get the router object (not a\ndict representation), using the vpn_service's router_id\nand then check the attributes for the router directly.\n\nChange-Id: I48286cda23d9737ddd90251dc0d1db1c310e7784\nCloses-Bug: 1356127\n""}, {'number': 2, 'created': '2014-08-13 12:55:58.000000000', 'files': ['neutron/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron/services/vpn/service_drivers/cisco_validator.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7370b3df04a9f5dddb3bddc9bf6f8b1f3c205d72', 'message': ""VPNaaS: Cisco fix validation for GW IP\n\nThe validation to check that the router has a GW IP\nfor the Cisco service driver was trying to directly\nget the gw_port information, which is not available, as\nthe validator only has a dict of the vpn_service info.\n\nModified validator to get the router object (not a\ndict representation), using the vpn_service's router_id\nand then check the attributes for the router directly.\n\nChange-Id: I48286cda23d9737ddd90251dc0d1db1c310e7784\nCloses-Bug: 1356127\n""}]",1,113751,7370b3df04a9f5dddb3bddc9bf6f8b1f3c205d72,43,21,2,6659,,,0,"VPNaaS: Cisco fix validation for GW IP

The validation to check that the router has a GW IP
for the Cisco service driver was trying to directly
get the gw_port information, which is not available, as
the validator only has a dict of the vpn_service info.

Modified validator to get the router object (not a
dict representation), using the vpn_service's router_id
and then check the attributes for the router directly.

Change-Id: I48286cda23d9737ddd90251dc0d1db1c310e7784
Closes-Bug: 1356127
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/113751/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron/services/vpn/service_drivers/cisco_validator.py']",2,2ff093e387890d555567df0df359a6c83b8d2bf1,bug/1356127," def validate_public_ip_present(self, router): gw_port = router.gw_port router = self.l3_plugin._get_router(context, vpn_service['router_id']) self.validate_public_ip_present(router) LOG.debug(""IPSec connection validated for Cisco CSR"")"," def validate_public_ip_present(self, vpn_service): gw_port = vpn_service.router.gw_port self.validate_public_ip_present(vpn_service) LOG.debug(""IPSec connection %s validated for Cisco CSR"", ipsec_sitecon['id'])",16,12
openstack%2Fdevstack~master~Ia4665ea78f0bafeaa2b2284a6d3de4474ea195e9,openstack/devstack,master,Ia4665ea78f0bafeaa2b2284a6d3de4474ea195e9,Exact match rhel6,MERGED,2014-08-04 04:16:24.000000000,2014-08-14 04:40:55.000000000,2014-08-14 04:40:54.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 6962}, {'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 9932}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-04 04:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3c9bccc7187ee3f4b6964755c93b8bf60c317a0f', 'message': ""Exact match rhel6\n\nWith rhel6 & rhel7 having a common prefix, use an exact match to make\nsure we don't mix them up.  This is breaking Centos7.\n\nChange-Id: Ia4665ea78f0bafeaa2b2284a6d3de4474ea195e9\n""}, {'number': 2, 'created': '2014-08-05 01:33:32.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a36167e38146c9bc328718458a4d7413b920f79f', 'message': ""Exact match rhel6\n\nWith rhel6 & rhel7 having a common prefix, use an exact match to make\nsure we don't mix them up.  This is breaking Centos7.\n\nChange-Id: Ia4665ea78f0bafeaa2b2284a6d3de4474ea195e9\n""}]",2,111637,a36167e38146c9bc328718458a4d7413b920f79f,29,11,2,7118,,,0,"Exact match rhel6

With rhel6 & rhel7 having a common prefix, use an exact match to make
sure we don't mix them up.  This is breaking Centos7.

Change-Id: Ia4665ea78f0bafeaa2b2284a6d3de4474ea195e9
",git fetch https://review.opendev.org/openstack/devstack refs/changes/37/111637/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,3c9bccc7187ee3f4b6964755c93b8bf60c317a0f,rackspace-pip-remove,"if [[ is_fedora && $DISTRO == ""rhel6"" ]]; thenif [[ is_fedora && $DISTRO == ""rhel6"" ]]; then",if [[ is_fedora && $DISTRO =~ (rhel) ]]; thenif [[ is_fedora && $DISTRO =~ (rhel) ]]; then,2,2
openstack%2Fmonasca-agent~master~I1224d7bd7ef8ef426f68c963ee9794e401e0a7f8,openstack/monasca-agent,master,I1224d7bd7ef8ef426f68c963ee9794e401e0a7f8,Change mode of requirement files,MERGED,2014-08-13 07:27:33.000000000,2014-08-14 04:39:26.000000000,2014-08-14 04:39:26.000000000,"[{'_account_id': 3}, {'_account_id': 2419}]","[{'number': 1, 'created': '2014-08-13 07:27:33.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/caad7a33881729318bdeccbaf2929d7d2b3320a6', 'message': 'Change mode of requirement files\n\nIt is not necessary that the requirement files are executable.\n\nChange-Id: I1224d7bd7ef8ef426f68c963ee9794e401e0a7f8\n'}]",0,113793,caad7a33881729318bdeccbaf2929d7d2b3320a6,11,2,1,167,,,0,"Change mode of requirement files

It is not necessary that the requirement files are executable.

Change-Id: I1224d7bd7ef8ef426f68c963ee9794e401e0a7f8
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/93/113793/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,caad7a33881729318bdeccbaf2929d7d2b3320a6,fix_mode,,,0,0
openstack%2Fheat~master~Ic8120022a1f9117c783f6422069f94614bcbb3c6,openstack/heat,master,Ic8120022a1f9117c783f6422069f94614bcbb3c6,Move nova_utils functions to nova client plugin,MERGED,2014-06-23 00:44:30.000000000,2014-08-14 04:31:35.000000000,2014-08-14 04:31:34.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6610}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 7761}, {'_account_id': 8289}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-23 00:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ac61dd31f63ddca5c3f08039b258accd170aad52', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 2, 'created': '2014-06-23 22:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d6127d4af77df28a57218366d5b3775cd5b8aab4', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 3, 'created': '2014-06-26 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b0dd23601d59e4f503e2ea4a4ba545883e330c94', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 4, 'created': '2014-06-27 06:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0d267b56c2d64d05f9eb7ff0d843c8d4480aab80', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 5, 'created': '2014-06-30 02:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3149c8c87bf476536614740fd36497c69601c74c', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 6, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ead8d01a07247d881473bb0f55d1b44c5620b051', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 7, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0e4dccbd933e3bc193355ea83a307f717fad3a6d', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 8, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3964d9fdb5d5736d8d3947efb3a4c2f2faa94fc5', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 9, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/676a25c1dea999b277c91ce1ddfdd0814500b144', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 10, 'created': '2014-07-06 22:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ed27e4c45f78320d46fe4287aa189e3960ff8ad6', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 11, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fa1de94288f278c7e5299f5209d6e86d6fbe5527', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 12, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4ec6f7926ad866bf2d4d424c736b40785054440c', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 13, 'created': '2014-07-08 21:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b97a2b0edb85331d0923416dbb6d8950df6ab12d', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 14, 'created': '2014-07-17 02:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2c3d166ab6cbcdf5ac1172f35bd7d289a83d9994', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 15, 'created': '2014-07-18 02:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cb577a0b1aa4df0294ed292c8d2e55a5812ff3da', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 16, 'created': '2014-07-21 17:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/06918dde977b58fd67f527decc9f49d879d92f80', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 17, 'created': '2014-07-21 17:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0f1107a36587e392f3011c386e79b57f66a98662', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 18, 'created': '2014-07-24 22:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/08f7cabc5fa486cb26e3a9e00fae01d2edea4219', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 19, 'created': '2014-07-28 02:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ae03e72a40f18d5eb17d78d95834419a267d9e8d', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 20, 'created': '2014-07-28 21:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/77fd0854b955b637b310f1a13d3f2c8eac41d8ff', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 21, 'created': '2014-07-29 20:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d2a741d936aef0a5827a6efaf146f88310313afd', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 22, 'created': '2014-07-29 21:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6847c325ec0433434bf0a72bd650ec52a1b002e1', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 23, 'created': '2014-07-30 21:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a218e694737433fd425e82026c6069611e7da56c', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 24, 'created': '2014-07-31 17:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0c2d1b0bcae01c16f489171e31b6f211bb89836a', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 25, 'created': '2014-07-31 22:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b6705383a8bc4c350d1720d595df476cedcc5e58', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 26, 'created': '2014-08-05 15:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bee045408dca5ca25931461d1120a48beb9e2cbd', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 27, 'created': '2014-08-11 17:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/432c084e2e201d907eefe241be531acbac238eca', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 28, 'created': '2014-08-11 22:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cdb43ed683cad8bd7a2f54b8eed8f53a4ea02225', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 29, 'created': '2014-08-13 21:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/27beb6981d1543fa542c34b2d65c17f6120e19dd', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}, {'number': 30, 'created': '2014-08-14 01:18:48.000000000', 'files': ['heat/tests/test_os_database.py', 'heat/tests/test_instance.py', 'heat/tests/test_neutron_autoscaling.py', 'heat/engine/resources/instance.py', 'heat/tests/test_engine_service.py', 'heat/engine/resources/nova_utils.py', 'heat/engine/resources/os_database.py', 'heat/engine/resources/server.py', 'heat/tests/test_nova_client.py', 'heat/engine/clients/os/nova.py', 'heat/engine/resources/neutron/loadbalancer.py', 'heat/tests/test_server.py', 'heat/tests/test_server_tags.py', 'heat/tests/test_instance_network.py', 'contrib/rackspace/rackspace/resources/cloud_server.py', 'heat/engine/resources/loadbalancer.py', 'heat/engine/resources/nova_keypair.py', 'heat/tests/test_nokey.py', 'heat/engine/clients/os/trove.py', 'heat/tests/test_nova_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/60e6eeb075ce22116e63dd6d99c322b143fe7c66', 'message': 'Move nova_utils functions to nova client plugin\n\nAll uses of nova_utils functions have been migrated to using\nthe nova client plugin version.\n\nExisting functions now have a deprecation warning which is\nsuppressed during nova_utils unit tests.\n\nnova_utils.get_flavor_id was being called with the trove\nclient, so there is now a dedicated trove plugin method\nget_flavor_id.\n\nChange-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6\n'}]",13,101782,60e6eeb075ce22116e63dd6d99c322b143fe7c66,135,20,30,4571,,,0,"Move nova_utils functions to nova client plugin

All uses of nova_utils functions have been migrated to using
the nova client plugin version.

Existing functions now have a deprecation warning which is
suppressed during nova_utils unit tests.

nova_utils.get_flavor_id was being called with the trove
client, so there is now a dedicated trove plugin method
get_flavor_id.

Change-Id: Ic8120022a1f9117c783f6422069f94614bcbb3c6
",git fetch https://review.opendev.org/openstack/heat refs/changes/82/101782/16 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_os_database.py', 'heat/tests/test_instance.py', 'heat/tests/test_neutron_autoscaling.py', 'heat/engine/resources/instance.py', 'heat/tests/test_engine_service.py', 'heat/engine/resources/nova_utils.py', 'heat/engine/resources/os_database.py', 'heat/engine/resources/server.py', 'heat/tests/test_nova_client.py', 'heat/engine/clients/os/nova.py', 'heat/engine/resources/neutron/loadbalancer.py', 'heat/tests/test_server.py', 'heat/tests/test_server_tags.py', 'heat/tests/test_instance_network.py', 'contrib/rackspace/rackspace/resources/cloud_server.py', 'heat/engine/resources/loadbalancer.py', 'heat/engine/resources/nova_keypair.py', 'heat/tests/test_nokey.py', 'heat/tests/test_nova_utils.py']",19,ac61dd31f63ddca5c3f08039b258accd170aad52,bp/client-plugins," self.mock_warnings = mock.patch( 'heat.engine.resources.nova_utils.warnings') self.mock_warnings.start() self.addCleanup(self.mock_warnings.stop) def setUp(self): super(NovaUtilsRefreshServerTests, self).setUp() self.mock_warnings = mock.patch( 'heat.engine.resources.nova_utils.warnings') self.mock_warnings.start() self.addCleanup(self.mock_warnings.stop) self.mock_warnings = mock.patch( 'heat.engine.resources.nova_utils.warnings') self.mock_warnings.start() self.addCleanup(self.mock_warnings.stop) def setUp(self): super(NovaUtilsMetadataTests, self).setUp() self.mock_warnings = mock.patch( 'heat.engine.resources.nova_utils.warnings') self.mock_warnings.start() self.addCleanup(self.mock_warnings.stop) ",,742,143
openstack%2Fnova~master~I6c3ff35f6e90fbed8b1fd727eb3b0b0ee140abc4,openstack/nova,master,I6c3ff35f6e90fbed8b1fd727eb3b0b0ee140abc4,Drop instance_group_metadata from the database,MERGED,2014-08-11 19:33:24.000000000,2014-08-14 03:57:59.000000000,2014-08-13 23:15:28.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-11 19:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53bc0ec2a3f216cca90969e19a21b002000ff145', 'message': 'Drop instance_group_metadata from the database\n\nThis completes the instance_group metadataectomy started in the previous\npatch. Per recent discussions, this decouples the code change from the\nactual schema change, allowing them to (potentially) be run at different\ntimes.\n\nChange-Id: I6c3ff35f6e90fbed8b1fd727eb3b0b0ee140abc4\n'}, {'number': 2, 'created': '2014-08-11 21:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ca90c7b1266e94ff5ac41e4f58cfb9818ef376c', 'message': 'Drop instance_group_metadata from the database\n\nThis completes the instance_group metadataectomy started in the previous\npatch. Per recent discussions, this decouples the code change from the\nactual schema change, allowing them to (potentially) be run at different\ntimes.\n\nChange-Id: I6c3ff35f6e90fbed8b1fd727eb3b0b0ee140abc4\n'}, {'number': 3, 'created': '2014-08-11 22:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4624c5872cc4b98b3c3a8e88d4093670104498a5', 'message': 'Drop instance_group_metadata from the database\n\nThis completes the instance_group metadataectomy started in the previous\npatch. Per recent discussions, this decouples the code change from the\nactual schema change, allowing them to (potentially) be run at different\ntimes.\n\nChange-Id: I6c3ff35f6e90fbed8b1fd727eb3b0b0ee140abc4\n'}, {'number': 4, 'created': '2014-08-12 15:48:34.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/250_remove_instance_groups_metadata.py', 'nova/tests/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aeee162ea3611d9128e78d0589215864c8f48c06', 'message': 'Drop instance_group_metadata from the database\n\nThis completes the instance_group metadataectomy started in the previous\npatch. Per recent discussions, this decouples the code change from the\nactual schema change, allowing them to (potentially) be run at different\ntimes.\n\nChange-Id: I6c3ff35f6e90fbed8b1fd727eb3b0b0ee140abc4\n'}]",3,113355,aeee162ea3611d9128e78d0589215864c8f48c06,47,12,4,4393,,,0,"Drop instance_group_metadata from the database

This completes the instance_group metadataectomy started in the previous
patch. Per recent discussions, this decouples the code change from the
actual schema change, allowing them to (potentially) be run at different
times.

Change-Id: I6c3ff35f6e90fbed8b1fd727eb3b0b0ee140abc4
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/113355/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/versions/250_remove_instance_groups_metadata.py', 'nova/tests/db/test_migrations.py']",2,53bc0ec2a3f216cca90969e19a21b002000ff145,remove-sg-metadata," def _check_250(self, engine, data): self.assertTableNotExists(engine, 'instance_group_metadata') self.assertTableNotExists(engine, 'shadow_instance_group_metadata') def _post_downgrade_250(self, engine): oslodbutils.get_table(engine, 'instance_group_metadata') oslodbutils.get_table(engine, 'shadow_instance_group_metadata') ",,70,0
openstack%2Fironic~master~Ib5ac15100214b351607e1c17aa663fa4c123bc7a,openstack/ironic,master,Ib5ac15100214b351607e1c17aa663fa4c123bc7a,Remove objectify decorator from dbapi.update_* methods,MERGED,2014-08-13 16:41:11.000000000,2014-08-14 03:51:40.000000000,2014-08-14 03:51:39.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 8106}]","[{'number': 1, 'created': '2014-08-13 16:41:11.000000000', 'files': ['ironic/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/488f5a19c3a2cc99706011d9751af296e88c87fe', 'message': ""Remove objectify decorator from dbapi.update_* methods\n\nThis patch removes the objectify decorator from the update_chassis,\nupdate_port and update_node dbapi's methods. The problem with the\nobjectify decorator is that dbapi methods doesn't get the context,\nso when forming the RPC object using the decorator we can't store the\ncontext within the object (which is what we want to do to have consistent\nobject interfaces).\n\nAlso there are no parts of the code that is expecting the returned RPC\nobject from the dbapi.update_*() methods so we can just simply get ride\nof the decorator.\n\nPartial-Bug: 1314732\nChange-Id: Ib5ac15100214b351607e1c17aa663fa4c123bc7a\n""}]",0,113968,488f5a19c3a2cc99706011d9751af296e88c87fe,9,3,1,6773,,,0,"Remove objectify decorator from dbapi.update_* methods

This patch removes the objectify decorator from the update_chassis,
update_port and update_node dbapi's methods. The problem with the
objectify decorator is that dbapi methods doesn't get the context,
so when forming the RPC object using the decorator we can't store the
context within the object (which is what we want to do to have consistent
object interfaces).

Also there are no parts of the code that is expecting the returned RPC
object from the dbapi.update_*() methods so we can just simply get ride
of the decorator.

Partial-Bug: 1314732
Change-Id: Ib5ac15100214b351607e1c17aa663fa4c123bc7a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/68/113968/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/db/sqlalchemy/api.py'],1,488f5a19c3a2cc99706011d9751af296e88c87fe,bug/1314732,, @objects.objectify(objects.Node) @objects.objectify(objects.Port) @objects.objectify(objects.Chassis),0,3
openstack%2Fceilometer~master~I2f696a5894ce7722114a2da054b42d9ffac56b83,openstack/ceilometer,master,I2f696a5894ce7722114a2da054b42d9ffac56b83,Issue one SQL statement per execute() call,MERGED,2014-08-13 01:35:23.000000000,2014-08-14 03:50:27.000000000,2014-08-14 03:50:26.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7729}]","[{'number': 1, 'created': '2014-08-13 01:35:23.000000000', 'files': ['ceilometer/storage/sqlalchemy/migrate_repo/versions/003_set_utf8_charset.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/676f9cba78035fe50e58316007c6ae71394145d4', 'message': ""Issue one SQL statement per execute() call\n\nSome sqlalchemy drivers only support a single SQL statement per\nexecute() call.  It isn't 100% clear from the sqlalchemy docs, but the\nsqlalchemy author confirmed that this is the intention.\n\nChange-Id: I2f696a5894ce7722114a2da054b42d9ffac56b83\n""}]",0,113743,676f9cba78035fe50e58316007c6ae71394145d4,9,4,1,11279,,,0,"Issue one SQL statement per execute() call

Some sqlalchemy drivers only support a single SQL statement per
execute() call.  It isn't 100% clear from the sqlalchemy docs, but the
sqlalchemy author confirmed that this is the intention.

Change-Id: I2f696a5894ce7722114a2da054b42d9ffac56b83
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/43/113743/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/storage/sqlalchemy/migrate_repo/versions/003_set_utf8_charset.py'],1,676f9cba78035fe50e58316007c6ae71394145d4,separate-sql," migrate_engine.execute(""SET foreign_key_checks = 0"") migrate_engine.execute( ""ALTER TABLE %s CONVERT TO CHARACTER SET utf8"" % table) migrate_engine.execute(""SET foreign_key_checks = 1"") migrate_engine.execute( ""ALTER DATABASE %s DEFAULT CHARACTER SET utf8"" % migrate_engine.url.database) migrate_engine.execute(""SET foreign_key_checks = 0"") migrate_engine.execute( ""ALTER TABLE %s CONVERT TO CHARACTER SET latin1"" % table) migrate_engine.execute(""SET foreign_key_checks = 1"") migrate_engine.execute( ""ALTER DATABASE %s DEFAULT CHARACTER SET latin1"" % migrate_engine.url.database)"," sql = ""SET foreign_key_checks = 0;"" sql += ""ALTER TABLE %s CONVERT TO CHARACTER SET utf8;"" % table sql += ""SET foreign_key_checks = 1;"" sql += (""ALTER DATABASE %s DEFAULT CHARACTER SET utf8;"" % migrate_engine.url.database) migrate_engine.execute(sql) sql = ""SET foreign_key_checks = 0;"" sql += ""ALTER TABLE %s CONVERT TO CHARACTER SET latin1;"" % table sql += ""SET foreign_key_checks = 1;"" sql += (""ALTER DATABASE %s DEFAULT CHARACTER SET latin1;"" % migrate_engine.url.database) migrate_engine.execute(sql)",14,12
openstack%2Fnova~master~I86ed6cd3316dd4da5e1b10b36a3ddba3739316d3,openstack/nova,master,I86ed6cd3316dd4da5e1b10b36a3ddba3739316d3,Added hacking check for jsonutils,MERGED,2014-08-01 14:38:53.000000000,2014-08-14 03:23:28.000000000,2014-08-13 21:38:14.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9656}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11069}]","[{'number': 1, 'created': '2014-08-01 14:38:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1e70bef1296c400dd1955f7feb94ffb1be85d51', 'message': 'Added hacking check for jsonutils\n\nChange-Id: I86ed6cd3316dd4da5e1b10b36a3ddba3739316d3\n'}, {'number': 2, 'created': '2014-08-01 14:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86541ed3472db4cdde14bc51ed24f0e8001b61ff', 'message': ""Added hacking check for jsonutils\n\njsonutils provides some additional features in comparison to pure json\nor simplejson modules. For example, on Python 2.6, it automatically\nswitches to simplejson that provides significant performance boost.\n\nSo let's enforce usage of the module in replacement to stdlib json.\n\nChange-Id: I86ed6cd3316dd4da5e1b10b36a3ddba3739316d3\n""}, {'number': 3, 'created': '2014-08-03 15:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f8973ece27b6530522b66bd5e8df2f04a170143', 'message': ""Added hacking check for jsonutils\n\njsonutils provides some additional features in comparison to pure json\nor simplejson modules. For example, on Python 2.6, it automatically\nswitches to simplejson that provides significant performance boost.\n\nSo let's enforce usage of the module in replacement to stdlib json.\n\nChange-Id: I86ed6cd3316dd4da5e1b10b36a3ddba3739316d3\n""}, {'number': 4, 'created': '2014-08-12 14:02:11.000000000', 'files': ['nova/hacking/checks.py', 'nova/tests/test_hacking.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/243879f5c51fc45f03491bcb78765945ddf76be8', 'message': ""Added hacking check for jsonutils\n\njsonutils provides some additional features in comparison to pure json\nor simplejson modules. For example, on Python 2.6, it automatically\nswitches to simplejson that provides significant performance boost.\n\nSo let's enforce usage of the module in replacement to stdlib json.\n\nChange-Id: I86ed6cd3316dd4da5e1b10b36a3ddba3739316d3\n""}]",8,111296,243879f5c51fc45f03491bcb78765945ddf76be8,43,11,4,9656,,,0,"Added hacking check for jsonutils

jsonutils provides some additional features in comparison to pure json
or simplejson modules. For example, on Python 2.6, it automatically
switches to simplejson that provides significant performance boost.

So let's enforce usage of the module in replacement to stdlib json.

Change-Id: I86ed6cd3316dd4da5e1b10b36a3ddba3739316d3
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/111296/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/hacking/checks.py'],1,c1e70bef1296c400dd1955f7feb94ffb1be85d51,bug/1329496,"def use_jsonutils(logical_line, filename): if ""plugins/xenserver"" in filename: return msg = ""N323: jsonutils.%(fun)s must be used instead of json.%(fun)s"" json_funcs = ['dump', 'dumps', 'load', 'loads'] for f in json_funcs: pos = logical_line.find('json.%s' % f) if pos != -1: yield (pos, msg % {'fun': f}) register(use_jsonutils)",,14,0
openstack%2Fdevstack-gate~master~Ib0a88e6f944e5722a300bf95cdfff77c9bd324e5,openstack/devstack-gate,master,Ib0a88e6f944e5722a300bf95cdfff77c9bd324e5,[DO NOT MERGE] test full tempest run on f20,ABANDONED,2014-08-08 00:35:12.000000000,2014-08-14 03:12:14.000000000,,"[{'_account_id': 3}, {'_account_id': 5803}, {'_account_id': 7118}]","[{'number': 1, 'created': '2014-08-08 00:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/259210f224a261828bf5fc2d2801b634f1869c42', 'message': '[DO NOT MERGE] test full tempest run on f20\n\nhttps://review.openstack.org/#/c/112670/ proposes a full tempest run\nfor f20; this is to test it in production before we commit it\n\nChange-Id: Ib0a88e6f944e5722a300bf95cdfff77c9bd324e5\n'}, {'number': 2, 'created': '2014-08-13 09:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fdc6f1586d7ba6dd35f3e7f5ee096af7fc649dbb', 'message': '[DO NOT MERGE] test full tempest run on f20\n\nhttps://review.openstack.org/#/c/112670/ proposes a full tempest run\nfor f20; this is to test it in production before we commit it\n\nChange-Id: Ib0a88e6f944e5722a300bf95cdfff77c9bd324e5\n'}, {'number': 3, 'created': '2014-08-14 01:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/e15d91ad497622149b5425f5a099f1b493fd4d7c', 'message': '[DO NOT MERGE] test full tempest run on f20\n\nhttps://review.openstack.org/#/c/112670/ proposes a full tempest run\nfor f20; this is to test it in production before we commit it\n\nChange-Id: Ib0a88e6f944e5722a300bf95cdfff77c9bd324e5\n'}, {'number': 4, 'created': '2014-08-14 02:16:59.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/1a8dfef1b67e581d52ed9d8a324f95e57ee16b24', 'message': '[DO NOT MERGE] test full tempest run on f20\n\nhttps://review.openstack.org/#/c/112670/ proposes a full tempest run\nfor f20; this is to test it in production before we commit it\n\nChange-Id: Ib0a88e6f944e5722a300bf95cdfff77c9bd324e5\n'}]",0,112739,1a8dfef1b67e581d52ed9d8a324f95e57ee16b24,17,3,4,7118,,,0,"[DO NOT MERGE] test full tempest run on f20

https://review.openstack.org/#/c/112670/ proposes a full tempest run
for f20; this is to test it in production before we commit it

Change-Id: Ib0a88e6f944e5722a300bf95cdfff77c9bd324e5
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/39/112739/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,259210f224a261828bf5fc2d2801b634f1869c42,f20-full-tempest," # fake test for confirming https://review.openstack.org/112670 if lsb_release -i 2>/dev/null | grep -iq ""fedora""; then DEVSTACK_GATE_SMOKE_SERIAL=0 DEVSTACK_GATE_TEMPEST_FULL=1 fi ",,6,0
openstack%2Fkeystone~master~Id0fd31f8b270eca95b579391477e19198d6e6f57,openstack/keystone,master,Id0fd31f8b270eca95b579391477e19198d6e6f57,DO NOT MERGE - DEBUGGING CHECK SPECIFIC FAILURE,ABANDONED,2014-08-12 22:42:12.000000000,2014-08-14 02:59:26.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}]","[{'number': 1, 'created': '2014-08-12 22:42:12.000000000', 'files': ['keystone/tests/test_auth.py', 'keystone/models/token_model.py', 'keystone/middleware/core.py', 'keystone/auth/plugins/token.py', 'keystone/contrib/revoke/model.py', 'keystone/tests/unit/token/test_token_model.py', 'keystone/common/wsgi.py', 'keystone/tests/test_token_bind.py', 'keystone/token/controllers.py', 'keystone/tests/test_content_types.py', 'keystone/common/authorization.py', 'keystone/common/controller.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d024703f3e3d98802fdfbc5e1a1c9989b0ecc411', 'message': 'DO NOT MERGE - DEBUGGING CHECK SPECIFIC FAILURE\n\nTHIS IS A DUPLICATE OF THE FIX FOR AUTHCONTEXT MIDDLEWARE,\nDO NOT MERGE THIS, IT HAS ADDED DEBUGGING ON THE REVOCATION\nEVENTS TO HELP TRACK DOWN ISSUES PASSING TEMPEST THAT ARE\nNOT SHOWING UP LOCALLY.\n\nAuthContextMiddleware and the fall-through in the controller base\n_build_policy_check_credentials now utilizes the KeystoneToken\nmodel and uses token_provider_api instead of token_api.\n\nIn support of this change, the token auth plugin, the auth_context\nbuilder, token bind check, and token controller have all been updated\nto utilize the KeystoneToken model. Support for the federation data\nhas been added to the KeystoneToken model so that it can be used\nin the auth context and associated code.\n\nAssociated tests that passed a raw token_ref to methods that now\nexpect the KeystoneToken model have been updated. This includes an\nupdate to the revocation model to guard against users without domain\ndata (the federated user case).\n\nChange-Id: Id0fd31f8b270eca95b579391477e19198d6e6f57\n'}]",0,113670,d024703f3e3d98802fdfbc5e1a1c9989b0ecc411,7,3,1,2903,,,0,"DO NOT MERGE - DEBUGGING CHECK SPECIFIC FAILURE

THIS IS A DUPLICATE OF THE FIX FOR AUTHCONTEXT MIDDLEWARE,
DO NOT MERGE THIS, IT HAS ADDED DEBUGGING ON THE REVOCATION
EVENTS TO HELP TRACK DOWN ISSUES PASSING TEMPEST THAT ARE
NOT SHOWING UP LOCALLY.

AuthContextMiddleware and the fall-through in the controller base
_build_policy_check_credentials now utilizes the KeystoneToken
model and uses token_provider_api instead of token_api.

In support of this change, the token auth plugin, the auth_context
builder, token bind check, and token controller have all been updated
to utilize the KeystoneToken model. Support for the federation data
has been added to the KeystoneToken model so that it can be used
in the auth context and associated code.

Associated tests that passed a raw token_ref to methods that now
expect the KeystoneToken model have been updated. This includes an
update to the revocation model to guard against users without domain
data (the federated user case).

Change-Id: Id0fd31f8b270eca95b579391477e19198d6e6f57
",git fetch https://review.opendev.org/openstack/keystone refs/changes/70/113670/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_auth.py', 'keystone/models/token_model.py', 'keystone/middleware/core.py', 'keystone/auth/plugins/token.py', 'keystone/contrib/revoke/model.py', 'keystone/tests/unit/token/test_token_model.py', 'keystone/common/wsgi.py', 'keystone/tests/test_token_bind.py', 'keystone/token/controllers.py', 'keystone/tests/test_content_types.py', 'keystone/common/authorization.py', 'keystone/common/controller.py']",12,d024703f3e3d98802fdfbc5e1a1c9989b0ecc411,bp/non-persistent-tokens,"from keystone.models import token_model # There is no current auth context, build it from the incoming token. # TODO(morganfainberg): Collapse this logic with AuthContextMiddleware # in sane manner as this just mirrors the logic in AuthContextMiddleware token_ref = token_model.KeystoneToken( token_id=context['token_id'], token_data=self.token_provider_api.validate_token( context['token_id'])) # NOTE(jamielennox): whilst this maybe shouldn't be within this # function it would otherwise need to reload the token_ref from # backing store. wsgi.validate_token_bind(context, token_ref) auth_context = authorization.token_to_auth_context(token_ref)"," # now build the auth context from the incoming auth token # TODO(ayoung): These two functions return the token in different # formats. However, the call # to get_token hits the caching layer, and does not validate the # token. This should be reduced to one call if not CONF.token.revoke_by_id: self.token_api.token_provider_api.validate_token( context['token_id']) token_ref = self.token_api.get_token(context['token_id']) # NOTE(jamielennox): whilst this maybe shouldn't be within this function # it would otherwise need to reload the token_ref from backing store. wsgi.validate_token_bind(context, token_ref) auth_context = authorization.token_to_auth_context(token_ref['token_data'])",275,200
openstack%2Ftempest~master~I3c3d9810ef865451ab07acf3600d4fed3420d301,openstack/tempest,master,I3c3d9810ef865451ab07acf3600d4fed3420d301,Heat neutron loadbalancer scenario test,ABANDONED,2013-12-04 21:18:28.000000000,2014-08-14 02:52:31.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 4571}, {'_account_id': 6072}, {'_account_id': 6577}, {'_account_id': 8328}]","[{'number': 1, 'created': '2013-12-04 21:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0be1540cd2e32a73f21da01ec3757089fc5aacda', 'message': 'Heat neutron loadbalancer scenario test\n\nThis test start two instances with fake HTTP servers and\nneutron loadbalancer.\nThen we try connect to each servers separately. After that\nuse vip address for testing balancing.\n\nChange-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301\n'}, {'number': 2, 'created': '2013-12-05 10:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4849371cb49acca62c667ffbb89896362744a79c', 'message': 'Heat neutron loadbalancer scenario test\n\nThis test start two instances with fake HTTP servers and\nneutron loadbalancer.\nThen we try connect to each servers separately. After that\nuse vip address for testing balancing.\n\nThis test give ability for testing neutron loadbalancer resources.\n\nChange-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301\n'}, {'number': 3, 'created': '2013-12-05 12:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9170d4389155649af3f513db191bba124b97493e', 'message': 'Heat neutron loadbalancer scenario test\n\nThis test start two instances with fake HTTP servers and\nneutron loadbalancer.\nThen we try connect to each servers separately. After that\nuse vip address for testing balancing.\n\nThis test give ability for testing neutron loadbalancer resources.\n\nChange-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301\n'}, {'number': 4, 'created': '2013-12-06 13:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5500871cb20bb4062e9ea955cc4cdeb573932bcd', 'message': 'Heat neutron loadbalancer scenario test\n\nThis test start two instances with fake HTTP servers and\nneutron loadbalancerm, that has FloatinfIP connected with vip.\nThen we try connect to each servers separately. After that\nuse vip and floating IP address for testing balancing.\n\nThis test give ability for testing neutron loadbalancer resources.\n\nChange-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301\n'}, {'number': 5, 'created': '2013-12-06 14:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/093b18b09c9934a8e28f7586b79ced1cf88e7d5e', 'message': 'Heat neutron loadbalancer scenario test\n\nThis test start two instances with fake HTTP servers and\nneutron loadbalancerm, that has FloatinfIP connected with vip.\nThen we try connect to each servers separately. After that\nuse vip and floating IP address for testing balancing.\n\nThis test give ability for testing neutron loadbalancer resources.\n\nChange-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301\n'}, {'number': 6, 'created': '2013-12-06 14:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/09bbc3dea701951265ff235b106ddd398a0e8f40', 'message': 'Heat neutron loadbalancer scenario test\n\nThis test start two instances with fake HTTP servers and\nneutron loadbalancerm, that has FloatinfIP connected with vip.\nThen we try connect to each servers separately. After that\nuse vip and floating IP address for testing balancing.\n\nThis test give ability for testing neutron loadbalancer resources.\n\nChange-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301\n'}, {'number': 10, 'created': '2013-12-11 08:42:25.000000000', 'files': ['tempest/scenario/orchestration/test_loadbalancer.yaml', 'tempest/scenario/orchestration/test_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b5da0494ff445b3e6227a2b554a1afdb75162383', 'message': 'Heat neutron loadbalancer scenario test\n\nThis test start two instances with fake HTTP servers and\nneutron loadbalancerm, that has FloatinfIP connected with vip.\nThen we try connect to each servers separately. After that\nuse vip and floating IP address for testing balancing.\n\nThis test give ability for testing neutron loadbalancer resources.\n\nChange-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301\n'}, {'number': 8, 'created': '2013-12-11 08:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2e71144212c9a65dce7153db9c1a9d3b43bd2b1b', 'message': 'Heat neutron loadbalancer scenario test\n\nThis test start two instances with fake HTTP servers and\nneutron loadbalancerm, that has FloatinfIP connected with vip.\nThen we try connect to each servers separately. After that\nuse vip and floating IP address for testing balancing.\n\nThis test give ability for testing neutron loadbalancer resources.\n\nChange-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301\n'}, {'number': 9, 'created': '2013-12-11 08:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a4cbc1fa629dd5b0dac6a51fc23e77e2ab607fec', 'message': 'Heat neutron loadbalancer scenario test\n\nThis test start two instances with fake HTTP servers and\nneutron loadbalancerm, that has FloatinfIP connected with vip.\nThen we try connect to each servers separately. After that\nuse vip and floating IP address for testing balancing.\n\nThis test give ability for testing neutron loadbalancer resources.\n\nChange-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301\n'}, {'number': 7, 'created': '2013-12-11 08:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e3b453f9a8df50b7e8534ce5ec744be1f8dcb288', 'message': 'Heat neutron loadbalancer scenario test\n\nThis test start two instances with fake HTTP servers and\nneutron loadbalancerm, that has FloatinfIP connected with vip.\nThen we try connect to each servers separately. After that\nuse vip and floating IP address for testing balancing.\n\nThis test give ability for testing neutron loadbalancer resources.\n\nChange-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301\n'}]",6,60078,b5da0494ff445b3e6227a2b554a1afdb75162383,87,8,10,6577,,,0,"Heat neutron loadbalancer scenario test

This test start two instances with fake HTTP servers and
neutron loadbalancerm, that has FloatinfIP connected with vip.
Then we try connect to each servers separately. After that
use vip and floating IP address for testing balancing.

This test give ability for testing neutron loadbalancer resources.

Change-Id: I3c3d9810ef865451ab07acf3600d4fed3420d301
",git fetch https://review.opendev.org/openstack/tempest refs/changes/78/60078/10 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/orchestration/test_loadbalancer.yaml', 'tempest/scenario/orchestration/test_loadbalancer.py']",2,0be1540cd2e32a73f21da01ec3757089fc5aacda,60078,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import time import urllib from tempest.scenario import manager from tempest.test import attr from tempest.test import call_until_true from tempest.test import services class LoadBalancingTest(manager.OrchestrationScenarioTest): def setUp(self): super(LoadBalancingTest, self).setUp() if not self.config.orchestration.image_ref: raise self.skipException(""No image available to test"") self.client = self.orchestration_client def tearDown(self): super(LoadBalancingTest, self).tearDown() self.client.stacks.delete(stack_id=self.stack_identifier) def assign_keypair(self): self.stack_name = self._stack_rand_name() if self.config.orchestration.keypair_name: self.keypair_name = self.config.orchestration.keypair_name else: self.keypair = self.create_keypair() self.keypair_name = self.keypair.id def launch_stack(self): net = self._get_default_network() self.parameters = { 'key_name': self.keypair_name, 'flavor': self.config.orchestration.instance_type, 'image': self.config.orchestration.image_ref, 'private_subnet_id': net['subnets'][0] } # create the stack self.template = self._load_template(__file__, 'test_loadbalancer.yaml') self.client.stacks.create( stack_name=self.stack_name, template=self.template, parameters=self.parameters) self.stack = self.client.stacks.get(self.stack_name) self.stack_identifier = '%s/%s' % (self.stack_name, self.stack.id) # if a keypair was set, do not delete the stack on exit to allow # for manual post-mortums if not self.config.orchestration.keypair_name: self.set_resource('stack', self.stack) @attr(type='slow') @services('orchestration', 'compute', 'network') def test_balancing(self): self.assign_keypair() self.launch_stack() sid = self.stack_identifier timeout = self.config.orchestration.build_timeout interval = 10 self.assertEqual('CREATE', self.stack.action) # wait for create to complete. self.status_timeout(self.client.stacks, sid, 'COMPLETE', error_status='FAILED') self.stack.get() self.assertEqual('CREATE_COMPLETE', self.stack.stack_status) # the resource SmokeServerGroup is implemented as a nested # stack, so servers can be counted by counting the resources # inside that nested stack server1_id = \ self.client.resources.get(sid, 'server1').physical_resource_id server2_id = \ self.client.resources.get(sid, 'server2').physical_resource_id pool_id = \ self.client.resources.get(sid, 'TestPool').physical_resource_id vip_id = self.network_client.show_pool(pool_id)['pool']['vip_id'] vip = self.network_client.show_vip(vip_id)['vip']['address'] serv_ip1 = \ self.compute_client.servers.get(server1_id).networks['private'][0] serv_ip2 = \ self.compute_client.servers.get(server2_id).networks['private'][0] def check_connect(check_ip): try: urllib.urlopen(""http://{0}/"".format(check_ip)) return True except IOError: return False def collect_reponses(ip): resp = [] for count in range(10): time.sleep(1.5) print ""res:"" + str(count) resp.append(urllib.urlopen(""http://{0}/"".format(ip)).read()) return resp while not check_connect(serv_ip1): time.sleep(10) responses1 = collect_reponses(serv_ip1) self.assertEqual(len(responses1), responses1.count('server1\n')) responses2 = collect_reponses(serv_ip2) self.assertEqual(len(responses2), responses2.count('server2\n')) responses3 = collect_reponses(vip) self.assertEqual( len(responses3), responses3.count('server1\n') + responses3.count('server2\n')) self.assertEqual(responses3, 5*['server1\n', 'server2\n']) ",,202,0
openstack%2Fmonasca-agent~master~Ibca521b49549432a3f27c53ac77bb8bf54b09fc3,openstack/monasca-agent,master,Ibca521b49549432a3f27c53ac77bb8bf54b09fc3,Additional documentation updates,MERGED,2014-08-13 21:30:16.000000000,2014-08-14 02:23:36.000000000,2014-08-14 02:23:35.000000000,"[{'_account_id': 3}, {'_account_id': 2419}]","[{'number': 1, 'created': '2014-08-13 21:30:16.000000000', 'files': ['monasca-agent_arch.graffle', 'monasca-agent_arch.png', 'monsetup/main.py', 'README.md'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/caac3eb3dc11a30954fb4adbdbe0bcd175e757ae', 'message': 'Additional documentation updates\n\nChange-Id: Ibca521b49549432a3f27c53ac77bb8bf54b09fc3\n'}]",0,114036,caac3eb3dc11a30954fb4adbdbe0bcd175e757ae,7,2,1,12108,,,0,"Additional documentation updates

Change-Id: Ibca521b49549432a3f27c53ac77bb8bf54b09fc3
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/36/114036/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca-agent_arch.graffle', 'monasca-agent_arch.png', 'monsetup/main.py', 'README.md']",4,caac3eb3dc11a30954fb4adbdbe0bcd175e757ae,monasca/update-documentation,"**Table of Contents** *generated with [DocToc](http://doctoc.herokuapp.com/)* - [monasca-setup (Recommended)](#monasca-setup-recommended) - [Explanation of monasca-setup command-line parameters:](#explanation-of-monasca-setup-command-line-parameters) - [Manual Configuration of the Agent](#manual-configuration-of-the-agent) - [Manual Configuration of Plugins](#manual-configuration-of-plugins)- [Troubleshooting](#troubleshooting) - [System Dimensions](#system-dimensions) - [OpenStack Dimensions](#openstack-dimensions) - [System Checks](#system-checks)- [Plugin Checks](#plugin-checks) - [Developing New Checks](#developing-new-checks) - [AgentCheck Interface](#agentcheck-interface) - [ServicesCheck interface](#servicescheck-interface) - [Sending Metrics](#sending-metrics) - [Plugin Configuration](#plugin-configuration) - [init_config](#init_config) - [instances](#instances) - [Plugin Documentation](#plugin-documentation) - [Nagios Checks](#nagios-checks) - [Host Alive Checks](#host-alive-checks) - [Process Checks](#process-checks) - [Http Endpoint Checks](#http-endpoint-checks) - [MySQL Checks](#mysql-checks) - [ZooKeeper Checks](#zookeeper-checks) - [Kafka Checks](#kafka-checks) - [RabbitMQ Checks](#rabbitmq-checks) - [OpenStack Monitoring](#openstack-monitoring) - [Nova Checks](#nova-checks) - [Nova Processes Monitored](#nova-processes-monitored) - [Example Nova Metrics](#example-nova-metrics) - [Swift Checks](#swift-checks) - [Swift Processes Monitored](#swift-processes-monitored) - [Example Swift Metrics](#example-swift-metrics) - [Glance Checks](#glance-checks) - [Glance Processes Monitored](#glance-processes-monitored) - [Example Glance Metrics](#example-glance-metrics) - [Cinder Checks](#cinder-checks) - [Cinder Processes Monitored](#cinder-processes-monitored) - [Example Cinder Metrics](#example-cinder-metrics) - [Neutron Checks](#neutron-checks) - [Neutron Processes Monitored](#neutron-processes-monitored) - [Example Neutron Metrics](#example-neutron-metrics) - [Keystone Checks](#keystone-checks) - [Keystone Processes Monitored](#keystone-processes-monitored) - [Example Keystone Metrics](#example-keystone-metrics) - [Ceilometer Checks](#ceilometer-checks) - [Ceilometer Processes Monitored](#ceilometer-processes-monitored) - [Example Ceilometer Metrics](#example-ceilometer-metrics) - [Statsd](#statsd) - [Log Parsing](#log-parsing)* Process checks. The Monasca Agent can check a process and return several metrics on the process such as number of instances, memory, io and threads.* OpenStack metrics. The agent can perform checks on OpenStack processes. * The Agent can automatically detect and setup checks on certain processes and resources.This section describes the overall architecture of the Monasca Agent. The agent consists of the supervisor, collector, forwarder and statsd daemon.The flow of the agent application goes like this: * The collector runs based on a configurable interval and collects the base system metrics such as cpu or disk utilization as well as any metrics from additional configured plugins such as mySQL or Kafka. * The statsd daemon allows users to send statsd type messages to the agent at any time. These messages are flushed periodically to the forwarder. * The forwarder, is a Tornado web server application that takes the metrics from the collector and statsd daemon, normalizes the metric names and forwards them on to the Monasca-API. * Once sent to the Monasca-API, the metrics continue through the Monasca pipeline and end up in the Metrics Database. * The collector then waits for the configured interval and restarts the collection process.* Statsd Daemon (monasca-statsd): Statsd daemon. * Monasca Setup (monasca-setup)| Supervisor | supervisord | Runs as root, launches all other processes as the ""monasca-agent"" user. This process manages the lifecycle of the Collector, Forwarder and Statsd Daemon. It allows Start, Stop and Restart of all the agent processes together. | | Collector | monasca-collector | Gathers system & application metrics on a configurable interval and sends them to the Forwarder process. | | Forwarder | monasca-forwarder | Gathers data from the collector and statsd and submits it to Monasca API over SSL (tcp/17123) | | Statsd Daemon | monasca-statsd | Statsd engine capable of handling dimensions associated with metrics submitted by a client that supports them. Also supports metrics from the standard statsd client. (udp/8125) | | Monasca Setup | monasca-setup | The monasca-setup script collects command-line arguments and configures the and starts the agent. the Monasca Setup program can also auto-detect and configure certain agent plugins | | Agent Checks | checks.d/*.py | Python-based user-configured checks. These checks can be for other applications or services to verify functionality or gather statistics on things such as messages processed, etc. Each additional agent check must be configured using a yaml file for a specific plugin that provides the additional functionality located in the conf.d directory. | The Agent includes the ""monasca-setup"" script, that can be used for automatically configuring the agent to generate metrics that are sent to the API. It creates the agent.conf file locate in /etc/monasca/agent directory. It also sets up additional checks based on what is running locally on that machine. For instance, if this is a compute node, the agent will setup checks to monitor the Nova processes and setup a http_status check on the nova-api. It can also detect other servers such as mySQL and Kafka and setup checks for them as well. A metric is identified by a name and dimensions. The fields required in a metric are name, timestamp, and value. A metric can also have 0..n dimensions. Some standard dimensions are sent with all metrics that are sent by the agent. Reference the section on [Dimensions](#dimensions) for more details. The [monasca-alarm-manager](**https://github.com/hpcloud-mon/monasca-alarm-manager**) is a utility that is under development that can be used for configuring a default set of alarms when monitoring a OpenStack deployment.The Monasca agent has a script, called ""monasca-setup"", that should be used to automatically configure the Agent to send metrics to a Monasca API. This script will create the agent.conf configuration file as well as any plugin configuration yaml files needed to monitor the processes on the local machine. The mon-setup script will auto-detect certain applications and OpenStack processes that are running on the machine. The agent configuration files are located in /etc/monasca/agent. The plugin configuration files are located in located in /etc/monasca/agent/conf.d.TBD * To start the agent daemon: * To stop the agent daemon: * To restart the agent daemon if it is already running:# Troubleshooting* '.' is used to hierarchially group. This is done for compatabilty with Graphite as Graphite assumes a '.' as a delimiter. * '_' is used to separate words in long names that are not meant to be hierarchal. ### System Dimensions Dimensions are a dictionary of (key, value) pairs that can be used to describe metrics. Dimensions are supplied to the API by the Agent.### OpenStack Dimensions| tenant_name | The tenant name of the owner of an OpenStack resource. | | # System ChecksThis section documents the system metrics that are sent by the Agent. This section includes checks by the network plugin as these are considered more system level checks.| cpu.idle_perc | | Percentage of time the CPU is idle when no I/O requests are in progress | | cpu.wait_perc | | Percentage of time the CPU is idle AND there is at least one I/O request in progress | | cpu.stolen_perc | | Percentage of stolen CPU time, i.e. the time spent in other OS contexts when running in a virtualized environment | | cpu.system_perc | | Percentage of time the CPU is used at the system level | | cpu.user_perc | | Percentage of time the CPU is used at the user level | | disk.free_inodes | device | The number of inodes that are free on a device | | disk.used_inodes | device | The number of inodes that are used on a device | | disk.total_inodes | device | The total number of inodes that are available on a device | | disk.used_kbytes | device | The number of kilobytes of disk space that are used on a device | | disk.total_kbytes | device | The total number of kilobytes of disk space that are available on a device | | disk.free_kbytes | device | The number of kilobytes of disk space that are free on a device| | io.read_kbytes_sec | device | Kbytes/sec read by an io device | io.read_req_sec | device | Number of read requests/sec to an io device | io.write_kbytes_sec |device | Kbytes/sec written by an io device | io.write_req_sec | device | Number of write requests/sec to an io device | cpu.load_avg_1min | | The average system load over a 1 minute period | cpu.load_avg_5min | | The average system load over a 5 minute period | cpu.load_avg_15min | | The average system load over a 15 minute period | mem.free_mb | | Megabytes of free memory | mem.swap_free_perc | | Percentage of free swap memory that is free | mem.swap_free_mb | | Megabytes of free swap memory that is free | mem.swap_total_mb | | Megabytes of total physical swap memory | mem.swap_used_mb | | Megabytes of total swap memory used | mem.total_mb | | Total megabytes of memory | mem.usable_mb | | Total megabytes of usable memory | mem.usable_perc | | Percentage of total memory that is usable | mem.used_buffers | | Number of buffers being used by the kernel for block io | mem_used_cached | | Memory used for the page cache | mem.used_shared | | Memory shared between separate processes and typically used for inter-process communication | net.bytes_in | device | Number of network bytes received | net.bytes_out | device | Number of network bytes sent | net.packets_in | device | Number of network packets received | net.packets_out | device | Number of network packets sent | net.errors_in | device | Number of network errors on incoming network traffic | net.errors_out | device | Number of network errors on outgoing network traffic | collector.threads.count | service=monasca component=agent | Number of threads that the collector is consuming for this collection run | collector.emit.time | service=monasca component=agent | Amount of time that the collector took for sending the collected metrics to the Forwarder for this collection run | collector.collection.time | service=monasca component=agent | Amount of time that the collector took for this collection run # Plugin Checks Plugins are the way to extend the Monasca Agent. Plugins add additional functionality that allow the agent to perform checks on other applications, servers or services. ## Developing New Checks Developers can extend the functionality of the Agent by writing custom plugins. Plugins are written in Python according to the conventions described below. The plugin script is placed in /etc/monasca/agent/checks.d, and a YAML file containing the configuration for the plugin is placed in /etc/monasca/agent/conf.d. The YAML file must have the same stem name as the plugin script. ### AgentCheck Interface Most monasca-agent plugin code uses the AgentCheck interface. All custom checks inherit from the AgentCheck class found in monagent/collector/checks/__init__.py and require a check() method that takes one argument, instance, which is a dict specifying the configuration of the instance on behalf of the plugin being executed. The check() method is run once per instance defined in the check's configuration (discussed later). ### ServicesCheck interface Some monasca-agent plugins use the ServicesCheck class found in monagent/collector/services_checks.py. These require a _check() method that is similar to AgentCheck's check(), but instead of being called once per iteration in a linear fashion, it is run against a threadpool to allow concurrent instances to be checked. Also, _check() must return a tuple consisting of either Status.UP or 'Status.DOWN(frommonagent.collector.checks.services_checks`), plus a text description. The size of the threadpool is either 6 or the total number of instances, whichever is lower. This may be adjusted with the threads_count parameter in the plugin's init_config (see Plugin Configuration below). ### Sending Metrics Sending metrics in a check is easy, and is very similar to submitting metrics using a statsd client. The following methods are available: ``` self.gauge( ... ) # Sample a gauge metric self.increment( ... ) # Increment a counter metric self.decrement( ... ) # Decrement a counter metric self.histogram( ... ) # Sample a histogram metric self.rate( ... ) # Sample a point, with the rate calculated at the end of the check ``` All of these methods take the following arguments: * metric: The name of the metric * value: The value for the metric (defaults to 1 on increment, -1 on decrement) * dimensions: (optional) A list of dimensions (name:value pairs) to associate with this metric * hostname: (optional) A hostname to associate with this metric. Defaults to the current host * device_name: (optional) A device name to associate with this metric These methods may be called from anywhere within your check logic. At the end of your check function, all metrics that were submitted will be collected and flushed out with the other Agent metrics. As part of the parent class, you're given a logger at self.log>. The log handler will be checks.{name} where {name} is the stem filename of your plugin. Of course, when writing your plugin you should ensure that your code raises meaningful exceptions when unanticipated errors occur. ### Plugin Configuration Each plugin has a corresponding YAML configuration file with the same stem name as the plugin script file. The configuration file has the following structure: ``` init_config: key1: value1 key2: value2 instances: - username: john_smith password: 123456 - username: jane_smith password: 789012 ``` #### init_config In the init_config section you can specify an arbitrary number of global name:value pairs that will be available on every run of the check in self.init_config. #### instances The instances section is a list of instances that this check will be run against. Your actual check() method is run once per instance. The name:value pairs for each instance specify details about the instance that are necessary for the check. #### Plugin Documentation Your plugin should include an example YAML configuration file to be placed in /etc/monasca/agent/conf.d/ which has the name of the plugin YAML file plus the extension '.example', so the example configuration file for the process plugin would be at /etc/monasca/agent/conf.d/process.yaml.example. This file should include a set of example init_config and instances clauses that demonstrate how the plugin can be configured. ## Nagios Checks## Host Alive Checks## Process ChecksThe process checks return the following metrics: | Metric Name | Dimensions | Semantics | | ----------- | ---------- | --------- | | processes.mem.real | process_name | Amount of real memory a process is using | processes.mem.rss | process_name | Amount of rss memory a process is using | processes.io.read_count | process_name | Number of reads by a process | processes.io.write_count | process_name | Number of writes by a process | processes.io.read_bytes | process_name | Bytes read by a process | processes.io.write_bytes | process_name | Bytes written by a process | processes.threads | process_name | Number of threads a process is using | processes.cpu_perc | process_name | Percentage of cpu being consumed by a process | processes.vms | process_name | Amount of virtual memory a process is using | processes.open_file_decorators | process_name | Number of files being used by a process | processes.involuntary_ctx_switches | process_name | Number of involuntary context switches for a process | processes.voluntary_ctx_switches | process_name | Number of voluntary context switches for a process | processes.pid_count | process_name | Number of processes that exist with this process name ## Http Endpoint ChecksSample config: init_config: The http_status checks return the following metrics: | Metric Name | Dimensions | Semantics | | ----------- | ---------- | --------- | | http_status | url, detail | The status of the http endpoint call (0 = success, 1 = failure) | http_response_time | url | The response time of the http endpoint call ## MySQL Checks This section describes the mySQL check that can be performed by the Agent. The mySQL check requires a configuration file called mysql.yaml to be available in the agent conf.d configuration directory. Sample config: defaults_file: /root/.my.cnf server: localhost user: root ``` The mySQL checks return the following metrics: | Metric Name | Dimensions | Semantics | | ----------- | ---------- | --------- | | mysql.performance.questions | hostname, mode, service=mysql | | | mysql.performance.qcache_hits | hostname, mode, service=mysql | | | mysql.performance.open_files | hostname, mode, service=mysql | | | mysql.performance.created_tmp_tables | hostname, mode, service=mysql | | | mysql.performance.user_time | hostname, mode, service=mysql | | | mysql.performance.com_replace_select | hostname, mode, service=mysql | | | mysql.performance.kernel_time | hostname, mode, service=mysql | | | mysql.performance.com_insert | hostname, mode, service=mysql | | | mysql.performance.threads_connected | hostname, mode, service=mysql | | | mysql.performance.com_update_multi | hostname, mode, service=mysql | | | mysql.performance.table_locks_waited | hostname, mode, service=mysql | | | mysql.performance.com_insert_select | hostname, mode, service=mysql | | | mysql.performance.slow_queries | hostname, mode, service=mysql | | | mysql.performance.com_delete | hostname, mode, service=mysql | | | mysql.performance.com_select | hostname, mode, service=mysql | | | mysql.performance.queries | hostname, mode, service=mysql | | | mysql.performance.created_tmp_files | hostname, mode, service=mysql | | | mysql.performance.com_update | hostname, mode, service=mysql | | | mysql.performance.com_delete_multi | hostname, mode, service=mysql | | | mysql.performance.created_tmp_disk_tables | hostname, mode, service=mysql | | | mysql.innodb.mutex_spin_rounds | hostname, mode, service=mysql | | | mysql.innodb.current_row_locks | hostname, mode, service=mysql | | | mysql.innodb.mutex_os_waits | hostname, mode, service=mysql | | | mysql.innodb.buffer_pool_used | hostname, mode, service=mysql | | | mysql.innodb.data_writes | hostname, mode, service=mysql | | | mysql.innodb.data_reads | hostname, mode, service=mysql | | | mysql.innodb.row_lock_waits | hostname, mode, service=mysql | | | mysql.innodb.os_log_fsyncs | hostname, mode, service=mysql | | | mysql.innodb.buffer_pool_total | hostname, mode, service=mysql | | | mysql.innodb.row_lock_time | hostname, mode, service=mysql | | | mysql.innodb.mutex_spin_waits | hostname, mode, service=mysql | | | mysql.innodb.buffer_pool_free | hostname, mode, service=mysql | | | mysql.net.max_connections | hostname, mode, service=mysql | | | mysql.net.connections | hostname, mode, service=mysql | | ## ZooKeeper Checks This section describes the Zookeeper check that can be performed by the Agent. The Zookeeper check requires a configuration file called zk.yaml to be available in the agent conf.d configuration directory. Sample config: ``` init_config: instances: host: localhost port: 2181 timeout: 3 ``` The Zookeeper checks return the following metrics: | Metric Name | Dimensions | Semantics | | ----------- | ---------- | --------- | | zookeeper.latency.max | hostname, mode, service=zookeeper | | | zookeeper.latency.min | hostname, mode, service=zookeeper | | | zookeeper.latency.avg | hostname, mode, service=zookeeper | | | zookeeper.bytes_sent | hostname, mode, service=zookeeper | | | zookeeper.bytes_outstanding | hostname, mode, service=zookeeper | | | zookeeper.bytes_received | hostname, mode, service=zookeeper | | | zookeeper.connections | hostname, mode, service=zookeeper | | | zookeeper.nodes | hostname, mode, service=zookeeper | | | zookeeper.zxid.count | hostname, mode, service=zookeeper | | | zookeeper.zxid.epoch | hostname, mode, service=zookeeper | | ## Kafka Checks This section describes the Kafka check that can be performed by the Agent. The Kafka check requires a configuration file called kafka.yaml to be available in the agent conf.d configuration directory. Sample config: ``` init_config: instances: - consumer_groups: '1_alarm-state-transitions': 'alarm-state-transitions': ['3', '2', '1', '0'] '1_metrics': 'metrics': &id001 ['3', '2', '1', '0'] 'test': 'healthcheck': ['1', '0'] 'thresh-event': 'events': ['3', '2', '1', '0'] 'thresh-metric': 'metrics': *id001 kafka_connect_str: localhost:9092 zk_connect_str: localhost:2181 ``` The Kafka checks return the following metrics: | Metric Name | Dimensions | Semantics | | ----------- | ---------- | --------- | | TBD | | | ## RabbitMQ Checks TBD ## OpenStack Monitoring The `monasca-setup` script when run on a system that is running OpenStack services, configures the Agent to send the following list of metrics: * The setup program creates process checks for each process that is part of an OpenStack service. A few sample metrics from the process check are provided. For the complete list of process metrics, see the [Process Checks](#Process Checks) section. * Additionally, an http_status check will be setup on the api for the service, if there is one. PLEASE NOTE: The monasca-setup program will only install checks for OpenStack services it detects when it is run. If an additional service is added to a particular node or deleted, monasca-setup must be re-run to add monitoring for the additional service or remove the service that is no longer there. ### Nova Checks This section documents a *sampling* of the metrics generated by the checks setup automatically by the monasca-setup script for the OpenStack Nova service. The following nova processes are monitored, if they exist when the monasca-setup script is run: ##### Nova Processes Monitored * nova-compute * nova-conductor * nova-cert * nova-network * nova-scheduler * nova-novncproxy * nova-xvpncproxy * nova-consoleauth * nova-objectstore * nova-api ##### Example Nova Metrics | Component | Metric Name | Metric Type | Check Type | Dimensions | Plugin | Description | Notes | | --------- | ----------- | ----------- | ---------- | ---- | ------ | ----------- | ----- | | nova-compute | processes.process_pid_count | Gauge | Passive | service=nova, component=nova-compute | process | nova-compute process exists | This is only one of the process checks performed | | nova-api | processes.process_pid_count | Gauge | Passive | service=nova, component=nova-api | process | nova-api process pid count | This is only one of the process checks performed | | nova-api | http_status | Gauge | Active | service=nova, component=nova-api url=url_to_nova_api | http_status | nova-api http endpoint is alive | This check should be executed on multiple systems.| ### Swift Checks This section documents a sampling of the metrics generated by the checks setup automatically by the monasca-setup script for the OpenStack Swift service. The following swift processes are monitored, if they exist when the monasca-setup script is run: ##### Swift Processes Monitored * swift-container-updater * swift-account-auditor * swift-object-replicator * swift-container-replicator * swift-object-auditor * swift-container-auditor * swift-account-reaper * swift-container-sync * swift-account-replicator * swift-object-updater * swift-object-server * swift-account-server * swift-container-server * swift-proxy-server ##### Example Swift Metrics | Component | Metric Name | Metric Type | Check Type | Dimensions | Plugin | Description | Notes | | --------- | ----------- | ----------- | ---------- | ---- | ------ | ----------- | ----- | | swift-container-updater | processes.process_pid_count | Gauge | Passive | service=swift, component=swift-container-updater | process | swift-container-updater process exists | This is only one of the process checks performed | | swift-proxy-server | processes.process_pid_count | Gauge | Passive | service=swift, component=swift-proxy-server | process | swift-proxy-server process pid count | This is only one of the process checks performed | | swift-proxy-server | http_status | Gauge | Active | service=swift, component=swift-proxy-server url=url_to_swift_proxy_server | http_status | swift-proxy-server http endpoint is alive | This check should be executed on multiple systems.| ### Glance Checks This section documents a sampling of the metrics generated by the checks setup automatically by the monasca-setup script for the OpenStack Glance service. The following glance processes are monitored, if they exist when the monasca-setup script is run: ##### Glance Processes Monitored * glance-registry * glance-api ##### Example Glance Metrics | Component | Metric Name | Metric Type | Check Type | Dimensions | Plugin | Description | Notes | | --------- | ----------- | ----------- | ---------- | ---- | ------ | ----------- | ----- | | glance-registry | processes.process_pid_count | Gauge | Passive | service=glance, component=glance-registry | process | glance-registry process exists | This is only one of the process checks performed | | glance-api | processes.process_pid_count | Gauge | Passive | service=glance, component=glance-api | process | glance-api process pid count | This is only one of the process checks performed | | glance-api | http_status | Gauge | Active | service=glance, component=glance-api url=url_to_glance_api | http_status | glance-api http endpoint is alive | This check should be executed on multiple systems.| ### Cinder Checks This section documents a sampling of the metrics generated by the checks setup automatically by the monasca-setup script for the OpenStack Cinder service. The following cinder processes are monitored, if they exist when the monasca-setup script is run: ##### Cinder Processes Monitored * cinder-volume * cinder-scheduler * cinder-api ##### Example Cinder Metrics | Component | Metric Name | Metric Type | Check Type | Dimensions | Plugin | Description | Notes | | --------- | ----------- | ----------- | ---------- | ---- | ------ | ----------- | ----- | | cinder-volume | processes.process_pid_count | Gauge | Passive | service=cinder, component=cinder-volume | process | cinder-volume process exists | This is only one of the process checks performed | | cinder-api | processes.process_pid_count | Gauge | Passive | service=cinder, component=cinder-api | process | cinder-api process pid count | This is only one of the process checks performed | | cinder-api | http_status | Gauge | Active | service=cinder, component=cinder-api url=url_to_cinder_api | http_status | cinder-api http endpoint is alive | This check should be executed on multiple systems.| ### Neutron Checks This section documents a sampling of the metrics generated by the checks setup automatically by the monasca-setup script for the OpenStack Neutron service. The following neutron processes are monitored, if they exist when the monasca-setup script is run: ##### Neutron Processes Monitored * neutron-server * neutron-openvswitch-agent * neutron-rootwrap * neutron-dhcp-agent * neutron-vpn-agent * neutron-metadata-agent * neutron-metering-agent * neutron-ns-metadata-proxy ##### Example Neutron Metrics | Component | Metric Name | Metric Type | Check Type | Dimensions | Plugin | Description | Notes | | --------- | ----------- | ----------- | ---------- | ---- | ------ | ----------- | ----- | | neutron-server | processes.process_pid_count | Gauge | Passive | service=neutron, component=neutron-server | process | neutron-server process exists | This is only one of the process checks performed | | neutron-ns-metadata-proxy | processes.process_pid_count | Gauge | Passive | service=neutron, component=neutron-ns-metadata-proxy | process | neutron-ns-metadata-proxy process pid count | This is only one of the process checks performed | | neutron-ns-metadata-proxy | http_status | Gauge | Active | service=neutron, component=neutron-ns-metadata-proxy url=url_to_neutron_api | http_status | neutron-ns-metadata-proxy http endpoint is alive | This check should be executed on multiple systems.| ### Keystone Checks This section documents a sampling of the metrics generated by the checks setup automatically by the monasca-setup script for the OpenStack Keystone service. The following keystone processes are monitored, if they exist when the monasca-setup script is run: ##### Keystone Processes Monitored * keystone-all ##### Example Keystone Metrics | Component | Metric Name | Metric Type | Check Type | Dimensions | Plugin | Description | Notes | | --------- | ----------- | ----------- | ---------- | ---- | ------ | ----------- | ----- | | keystone-all | processes.process_pid_count | Gauge | Passive | service=keystone, component=keystone-all | process | keystone-all process pid count | This is only one of the process checks performed | | keystone-all | http_status | Gauge | Active | service=keystone, component=keystone-all url=url_to_keystone_api | http_status | keystone-all http endpoint is alive | This check should be executed on multiple systems.| ### Ceilometer Checks This section documents a sampling of the metrics generated by the checks setup automatically by the monasca-setup script for the OpenStack Ceilometer service. The following ceilometer processes are monitored, if they exist when the monasca-setup script is run: ##### Ceilometer Processes Monitored * ceilometer-agent-compute * ceilometer-agent-central * ceilometer-agent-notification * ceilometer-collector * ceilometer-alarm-notifier * ceilometer-alarm-evaluator * ceilometer-api ##### Example Ceilometer Metrics | Component | Metric Name | Metric Type | Check Type | Dimensions | Plugin | Description | Notes | | --------- | ----------- | ----------- | ---------- | ---- | ------ | ----------- | ----- | | ceilometer-agent-compute | processes.process_pid_count | Gauge | Passive | service=ceilometer, component=ceilometer-agent-compute | process | ceilometer-agent-compute process exists | This is only one of the process checks performed | | ceilometer-api | processes.process_pid_count | Gauge | Passive | service=ceilometer, component=ceilometer-api | process | ceilometer-api process pid count | This is only one of the process checks performed | | ceilometer-api | http_status | Gauge | Active | service=ceilometer, component=ceilometer-api url=url_to_ceilometer_api | http_status | ceilometer-api http endpoint is alive | This check should be executed on multiple systems.| # Statsd The Monasca Agent ships with a Statsd daemon implementation called monasca-statsd. A statsd client can be used to send metrics to the Forwarder via the Statsd daemon. monascastatsd will accept metrics submitted by functions in either the standard statsd Python client library, or the monasca-agent's [python-monasca-statsd Python client library](https://github.com/hpcloud-mon/python-monascastatsd). The advantage of using the python-monasca-statsd library is that it is possible to specify dimensions on submitted metrics. Dimensions are not handled by the standard statsd client. Statsd metrics are not bundled along with the metrics gathered by the Collector, but are flushed to the agent Forwarder on a separate schedule (every 10 seconds by default, rather than 15 seconds for Collector metrics). Here is an example of metrics submitted using the standard statsd Python client library. ``` import statsd statsd.increment('processed', 5) # Increment 'processed' metric by 5 statsd.timing('pipeline', 2468.34) # Pipeline took 2468.34 ms to execute statsd.gauge('gaugething', 3.14159265) # 'gauge' would be the preferred metric type for MonitoringThe [python-monasca-statsd](https://github.com/hpcloud-mon/python-monascastatsd) library provides a python based implementation of a statsd client but also adds the ability to add dimensions to the the statsd metrics for the client. Here are some examples of how code can be instrumented using calls to python-monascastatsd. ``` * Import the module once it's installed. from monascastatsd import monascastatsd * Optionally, configure the host and port if you're running Statsd on a non-standard port. monascastatsd.connect('localhost', 8125) * Increment a counter. monascastatsd.increment('page_views') With dimensions: monascastatsd.increment('page_views', 5, dimensions={'Hostname': 'prod.mysql.abccorp.com'}) * Record a gauge 50% of the time. monascastatsd.gauge('users_online', 91, sample_rate=0.5) With dimensions: monascastatsd.gauge('users_online', 91, dimensions={'Origin': 'Dev', 'Environment': 'Test'}) * Sample a histogram. monascastatsd.histogram('file.upload_size', 20456) With dimensions: monascastatsd.histogram('file.upload_size', 20456, sample_rate=0.5, dimensions={'Name': 'MyFile.pdf', 'Version': '1.0'}) * Time a function call. @monascastatsd.timed('page.render') def render_page(): # Render things ... ``` # Log Parsing TBD","**Table of Contents** - [Configuration Options](#configuration-options) - [Configuring Plugins](#configuring-plugins) - [monasca-setup](#monasca-setup) - [Configuration Options](#configuration-options-1)- [Trouble-shooting](#trouble-shooting) - [Dimensions](#dimensions) - [Dimensions](#dimensions-1) - [Checks](#checks) - [Nagios](#nagios) - [Statsd](#statsd) - [Log Parsing](#log-parsing) - [Host alive](#host-alive) - [Process exists](#process-exists) - [Http Endpoint checks](#http-endpoint-checks) - [MySQL](#mysql) - [RabbitMQ](#rabbitmq) - [Kafka](#kafka) - [Other](#other) - [OpenStack](#openstack) - [Nova](#nova) - [Swift](#swift) - [Glance](#glance) - [Cinder](#cinder) - [Neutron](#neutron) - [Keystone](#keystone) - [Seed Controller](#seed-controller) - [Developing New Checks](#developing-new-checks) - [AgentCheck Interface](#agentcheck-interface) - [ServicesCheck interface](#servicescheck-interface) - [Sending Metrics](#sending-metrics) - [Plugin Configuration](#plugin-configuration) - [init_config](#init_config) - [instances](#instances) - [Plugin Documentation](#plugin-documentation)* Process exists checks. The Monasca Agent can check if a process is up or down.This section describes the overall architecture of the Monasca Agent. * Agent * ChecksA metric is identified by a name and dimensions.* Statsd nDaemon (monasca-statsd): Statsd daemon.| Supervisor | supervisord | Runs as root, launches all other processes as the ""monasca-agent"" user | | Collector | monasca-collector | Gathers system & application metrics | | Monstatsd | monasca-statsd | Statsd engine capable of handling dimensions associated with metrics submitted by a client that supports them. Also supports metrics from the standard statsd client. (udp/8125) | | Forwarder | monasca-forwarder | Gathers data from statsd and submits it to Monasca API over SSL (tcp/17123) | | Agent Checks | checks.d/*.py | Python-based user-configured checks | The Agent includes the script ""monasca-setup"", that can be used for automatically configuring the agent to generate metrics that are sent to the API. It creates the agent.conf file locate in /etc/monasca/agent directory. It also sets up additional checks based on what is running locally on that machine. For instance, if this is a compute node, the agent will setup checks to monitor the Nova processes and setup a http_status check on the nova-api. It can also detect other servers such as mySQL and Kafka and setup checks for them as well. The [monasca-alarm-manager](**https://github.com/hpcloud-mon/monasca-alarm-manager**) is a utility that can be used for configuring a default set of alarms when monitoring a OpenStack deployment.The Monasca agent has a script, called ""monasca-setup"", that should be used to automatically configure the Agent to send metrics to a Monasca API. This script will create the agent.conf configuration file as well as any plugin configuration yaml files needed to monitor the processes on the local machine. The agent configuration files are located in /etc/monasca/agent. The plugin configuration files are located in located in /etc/monasca/agent/conf.d.To run the agent from the command-line, you will need to start at least 2 processes in order to send metrics. These are the collector and forwarder. If you have already installed the monasca-agent package and run the monasca-setup configuration script, run the following commands from the Linux command-line: * From a terminal window, use netcat to listen for metrics on a local port: nc -lk 8080 * From a second terminal window, launch the forwarder in the background: python ddagent.py & * From the second terminal window, launch the collector in the foreground: python agent.py foreground --use-local-forwarder * Metric payloads will start to appear in the first terminal window running netcat * To start the agent: * To stop the agent: * To restart the agent if it is already running:# Trouble-shooting* '.' is used to hierarchially group. This is done for compabilty with Graphite as Graphite assumes a '.' as a delimiter. * '_' is used to separate words in long names that are not meant to be hierarchial. ### Dimensions Dimensions are a dictionary of (key, value) pairs that can be used to describe metrics. Dimensions are supplied to the API by Agent.### Dimensions| tenant_id | The tenant/project ID of the owner of an OpenStack resource. | | # ChecksThis section documents the system metrics that are sent by the Agent.| system.cpu.idle_perc | | Percentage of time the CPU is idle when no I/O requests are in progress | | system.cpu.iowait_perc | | Percentage of time the CPU is idle AND there is at least one I/O request in progress | | system.cpu.stolen_perc | | Percentage of stolen CPU time, i.e. the time spent in other OS contexts when running in a virtualized environment | | system.cpu.system_perc | | Percentage of time the CPU is used at the system level | | system.cpu.user_perc | | Percentage of time the CPU is used at the user level | | system.disk.usage | device | | | system.mountpoint | | (OS dependent) The amount of disk space being used | system.inodes | device | | | system.mountpoint | | (OS dependent) inodes remaining in a filesystem | system.inodes_perc | device | | | system.mountpoint | | (OS dependent) Percentage of inodes remaining in a filesystem | system.io_read_kbytes_sec device | | Kbytes/sec read by an io device | system.io.read_req_sec | device | Number of read requests/sec to an io device | system.io.write_kbytes_sec |device | Kbytes/sec written by an io device | system.io.write_req_sec | device | Number of write requests/sec to an io device | system.cpu.load_avg_1min | | The average system load over a 1 minute period | system.cpu.load_avg_5min | | The average system load over a 5 minute period | system.cpu.load_avg_15min | | The average system load over a 15 minute period | system.mem.free_mb | | Megabytes of free memory | system.mem.swap_free_mb | | Megabytes of free swap memory that is free | system.mem.swap_total_mb | | Megabytes of total physical swap memory | system.mem.swap_used_mb | | Megabytes of total swap memory used | system.mem.total_mb | | Total megabytes of memory | system.mem.usable_mb | | Total megabytes of usable memory | system.mem.usable_perc | | Percentage of total memory that is usable | system.mem.used_buffers | | Number of buffers being used by the kernel for block io | system.mem_used_cached | | Memory used for the page cache | system.mem.used_shared | | Memory shared between separate processes and typically used for inter-process communication ## Nagios## Statsd The Agent ships with a Statsd daemon implementation called monstatsd. A statsd client can be used to send metrics to the Forwarder via the Statsd daemon. monstatsd will accept metrics submitted by functions in either the standard statsd Python client library, or monasca-agent's monstatsd-python Python client library. The advantage of using the monstatsd-python library is that it is possible to specify dimensions on submitted metrics. Dimensions are not handled by the standard statsd client. Statsd metrics are not bundled along with the metrics gathered by the Collector, but are flushed to the agent Forwarder on a separate schedule (every 10 seconds by default, rather than 15 seconds for Collector metrics). Here is an example of metrics submitted using the standard statsd Python client library. ``` import statsd statsd.increment('processed', 5) # Increment 'processed' metric by 5 statsd.timing('pipeline', 2468.34) # Pipeline took 2468.34 ms to execute statsd.gauge('gaugething', 3.14159265) # 'gauge' would be the preferred metric type for Monitoring ``` The monstatsd-python library provides client support for dimensions. Metrics submission to monstatsd using the monstatsd-python Python client library may look like this: ``` from monstatsd import statsd statsd.gauge('withdimensions', 6.283185, dimensions=['name1:value1', 'name2:value2']) ``` Here are some examples of how code can be instrumented using calls to monstatsd. ``` # Import the module once it's installed. from monstatsd import statsd # Optionally, configure the host and port if you're running Statsd on a # non-standard port. statsd.connect('localhost', 8125) # Increment a counter. statsd.increment('page.views') # Record a gauge 50% of the time. statsd.gauge('users.online', 123, sample_rate=0.5) # Sample a histogram. statsd.histogram('file.upload.size', 1234) # Time a function call. @statsd.timed('page.render') def render_page(): # Render things ... # Tag a metric. statsd.histogram('query.time', 10, dimensions = [""version:1""]) ``` ## Log Parsing TBD ## Host alive## Process exists ## Http Endpoint checksExample Output ``` ""metrics"" : [ [ ""http_status"", 1394833060, 0, { ""type"" : ""gauge"", ""hostname"" : ""agenthost.domain.net"", ""dimensions"" : [ ""url:http://192.168.0.254/healthcheck"", ""detail:\""* deadlocks: OK\\n* mysql-db: OK\\n* rabbitmq-api: OK\\n* rabbitmq-external: OK\\n* rabbitmq-internal: OK\\n\"""" ] } ], [ ""http_response_time"", 1394833060, 0.251352787017822, { ""type"" : ""gauge"", ""hostname"" : ""agenthost.domain.net"", ""dimensions"" : [ ""url:http://192.168.0.254/healthcheck"" ] } ], ], ``` ## MySQL ## RabbitMQ ## Kafka ## Other ## OpenStack The `monasca-setup` script when run on a system that is running OpenStack services configures the Agent to send the following list of metrics. ### Nova This section documents all the checks done for the OpenStack Nova service. | Component | Metric Name | Metric Type | Check Type | Unit | Plugin | Description | Notes | | --------- | ----------- | ----------- | ---------- | ---- | ------ | ----------- | ----- | | nova-api | nova.api.process_exists | Gauge | Passive | Binary | process | nova-api process exists | | nova-api | nova.api.http_status | Gauge | Passive | Binary | process | nova-api http endpoint is alive | This check should be executed on multiple systems.| | nova-compute | nova.compute.process_exists | Gauge | Passive | Binary | process | nova-api process exists | ### Swift ### Glance ### Cinder ### Neutron ### Keystone ### Seed Controller # Developing New Checks Developers can extend the functionality of the Agent by writing custom plugins. Plugins are written in Python according to the conventions described below. The plugin script is placed in /etc/monasca/agent/checks.d, and a YAML file containing the configuration for the plugin is placed in /etc/monasca/agent/conf.d. The YAML file must have the same stem name as the plugin script. ## AgentCheck Interface Most monasca-agent plugin code uses the AgentCheck interface. All custom checks inherit from the AgentCheck class found in monagent/collector/checks/__init__.py and require a check() method that takes one argument, instance, which is a dict specifying the configuration of the instance on behalf of the plugin being executed. The check() method is run once per instance defined in the check's configuration (discussed later). ## ServicesCheck interface Some monasca-agent plugins use the ServicesCheck class found in monagent/collector/services_checks.py. These require a _check() method that is similar to AgentCheck's check(), but instead of being called once per iteration in a linear fashion, it is run against a threadpool to allow concurrent instances to be checked. Also, _check() must return a tuple consisting of either Status.UP or 'Status.DOWN(frommonagent.collector.checks.services_checks`), plus a text description. The size of the threadpool is either 6 or the total number of instances, whichever is lower. This may be adjusted with the threads_count parameter in the plugin's init_config (see Plugin Configuration below). ## Sending Metrics Sending metrics in a check is easy, and is very similar to submitting metrics using a statsd client. The following methods are available: ``` self.gauge( ... ) # Sample a gauge metric self.increment( ... ) # Increment a counter metric self.decrement( ... ) # Decrement a counter metric self.histogram( ... ) # Sample a histogram metric self.rate( ... ) # Sample a point, with the rate calculated at the end of the check ``` All of these methods take the following arguments: * metric: The name of the metric * value: The value for the metric (defaults to 1 on increment, -1 on decrement) * dimensions: (optional) A list of dimensions (name:value pairs) to associate with this metric * hostname: (optional) A hostname to associate with this metric. Defaults to the current host * device_name: (optional) A device name to associate with this metric These methods may be called from anywhere within your check logic. At the end of your check function, all metrics that were submitted will be collected and flushed out with the other Agent metrics. As part of the parent class, you're given a logger at self.log>. The log handler will be checks.{name} where {name} is the stem filename of your plugin. Of course, when writing your plugin you should ensure that your code raises meaningful exceptions when unanticipated errors occur. ## Plugin Configuration Each plugin has a corresponding YAML configuration file with the same stem name as the plugin script file. The configuration file has the following structure: key1: value1 key2: value2 - username: john_smith password: 123456 - username: jane_smith password: 789012### init_config In the init_config section you can specify an arbitrary number of global name:value pairs that will be available on every run of the check in self.init_config. ### instances The instances section is a list of instances that this check will be run against. Your actual check() method is run once per instance. The name:value pairs for each instance specify details about the instance that are necessary for the check. ## Plugin Documentation Your plugin should include an example YAML configuration file to be placed in /etc/monasca/agent/conf.d/ which has the name of the plugin YAML file plus the extension '.example', so the example configuration file for the process plugin would be at /etc/monasca/agent/conf.d/process.yaml.example. This file should include a set of example init_config and instances clauses that demonstrate how the plugin can be configured.",2059,276
openstack%2Fopenstacksdk~master~Ie77f49ca6f8a307944d16a88edc4016b37ba760f,openstack/openstacksdk,master,Ie77f49ca6f8a307944d16a88edc4016b37ba760f,Updated from global requirements,MERGED,2014-08-13 23:25:24.000000000,2014-08-14 02:20:09.000000000,2014-08-14 02:20:08.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-13 23:25:24.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8edc2c9741580913b9379788e853b75b972d1382', 'message': 'Updated from global requirements\n\nChange-Id: Ie77f49ca6f8a307944d16a88edc4016b37ba760f\n'}]",0,114076,8edc2c9741580913b9379788e853b75b972d1382,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ie77f49ca6f8a307944d16a88edc4016b37ba760f
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/76/114076/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,8edc2c9741580913b9379788e853b75b972d1382,openstack/requirements,requests>=1.2.1,requests>=1.1,1,1
openstack%2Fopenstacksdk~master~I68c7c9e6a08dfe24cf031284a63e1dd8db8fbc27,openstack/openstacksdk,master,I68c7c9e6a08dfe24cf031284a63e1dd8db8fbc27,identity/v2 user resource,MERGED,2014-08-13 04:33:20.000000000,2014-08-14 01:57:40.000000000,2014-08-14 01:57:39.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-13 04:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8b2f28237af7020780c99602c00b31968acdc488', 'message': 'identity/v2 user resource\n\nChange-Id: I68c7c9e6a08dfe24cf031284a63e1dd8db8fbc27\n'}, {'number': 2, 'created': '2014-08-13 07:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/22af685b5dd93349a7ce2b9269eb1c02fc43ecc5', 'message': 'identity/v2 user resource\n\nChange-Id: I68c7c9e6a08dfe24cf031284a63e1dd8db8fbc27\n'}, {'number': 3, 'created': '2014-08-14 00:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8da5c66f7a78404559d349aa9e4b869230517884', 'message': 'identity/v2 user resource\n\nChange-Id: I68c7c9e6a08dfe24cf031284a63e1dd8db8fbc27\n'}, {'number': 4, 'created': '2014-08-14 01:25:10.000000000', 'files': ['openstack/identity/identity_service.py', 'openstack/tests/identity/test_identity_service.py', 'openstack/tests/identity/v2/test_user.py', 'openstack/identity/v2/__init__.py', 'openstack/identity/v2/user.py', 'openstack/identity/__init__.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2609db413bbeed6333e019837b2d636c0b402df8', 'message': 'identity/v2 user resource\n\nChange-Id: I68c7c9e6a08dfe24cf031284a63e1dd8db8fbc27\n'}]",4,113766,2609db413bbeed6333e019837b2d636c0b402df8,19,3,4,7191,,,0,"identity/v2 user resource

Change-Id: I68c7c9e6a08dfe24cf031284a63e1dd8db8fbc27
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/66/113766/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/identity/identity_service.py', 'openstack/tests/identity/v2/test_user.py', 'openstack/identity/v2/__init__.py', 'openstack/identity/v2/user.py', 'openstack/identity/__init__.py']",5,8b2f28237af7020780c99602c00b31968acdc488,user,,,108,0
openstack%2Fnova~master~I24d0cd442e8d9d89fac50e43fc97f7bb4a293c3d,openstack/nova,master,I24d0cd442e8d9d89fac50e43fc97f7bb4a293c3d,Consistently use jsonutils instead of specific implementation,MERGED,2014-06-12 21:03:46.000000000,2014-08-14 01:51:56.000000000,2014-08-13 21:38:01.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9656}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11650}]","[{'number': 1, 'created': '2014-06-12 21:03:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc0990a6e1c5cdb9e98b4987a9a01124a37e7f90', 'message': 'Consistently use jsonutils instead of specific implementation\n\njsonutils have several benefits in comparison to pure json\nimplementation, like enabling C boosted encoders and decoders for\nPython2.6 by using simplejson when available.\n\nChange-Id: I24d0cd442e8d9d89fac50e43fc97f7bb4a293c3d\nCloses-Bug: 1329496\n'}, {'number': 2, 'created': '2014-06-12 21:27:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/17c8c6763188ea1a64e351e35b8878a398a80973', 'message': 'Consistently use jsonutils instead of specific implementation\n\njsonutils have several benefits in comparison to pure json\nimplementation, like enabling C boosted encoders and decoders for\nPython2.6 by using simplejson when available.\n\nChange-Id: I24d0cd442e8d9d89fac50e43fc97f7bb4a293c3d\nCloses-Bug: 1329496\n'}, {'number': 3, 'created': '2014-06-16 07:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e45654906fb430a232e95de9649d5646a15d1751', 'message': 'Consistently use jsonutils instead of specific implementation\n\njsonutils have several benefits in comparison to pure json\nimplementation, like enabling C boosted encoders and decoders for\nPython2.6 by using simplejson when available.\n\nChange-Id: I24d0cd442e8d9d89fac50e43fc97f7bb4a293c3d\nCloses-Bug: 1329496\n'}, {'number': 4, 'created': '2014-06-23 20:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed855f1d9049debf0c492daa2da89cddc8750d15', 'message': 'Consistently use jsonutils instead of specific implementation\n\njsonutils have several benefits in comparison to pure json\nimplementation, like enabling C boosted encoders and decoders for\nPython2.6 by using simplejson when available.\n\nChange-Id: I24d0cd442e8d9d89fac50e43fc97f7bb4a293c3d\nCloses-Bug: 1329496\n'}, {'number': 5, 'created': '2014-08-01 14:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03e37836941e22f52618fb2bafb0d9ee2117654c', 'message': 'Consistently use jsonutils instead of specific implementation\n\njsonutils have several benefits in comparison to pure json\nimplementation, like enabling C boosted encoders and decoders for\nPython2.6 by using simplejson when available.\n\nChange-Id: I24d0cd442e8d9d89fac50e43fc97f7bb4a293c3d\nCloses-Bug: 1329496\n'}, {'number': 6, 'created': '2014-08-12 14:02:11.000000000', 'files': ['nova/virt/libvirt/imagecache.py', 'nova/api/openstack/compute/contrib/security_groups.py', 'nova/image/glance.py', 'nova/tests/api/test_auth.py', 'nova/virt/storage_users.py', 'nova/tests/test_metadata.py', 'nova/scheduler/scheduler_options.py', 'nova/tests/integrated/v3/test_console_auth_tokens.py', 'nova/tests/policy_fixture.py', 'nova/api/openstack/compute/plugins/v3/security_groups.py', 'nova/api/metadata/base.py', 'nova/tests/api/openstack/compute/contrib/test_server_external_events.py', 'nova/tests/virt/libvirt/test_imagecache.py', 'nova/tests/integrated/test_api_samples.py', 'nova/tests/api/openstack/compute/plugins/v3/test_server_external_events.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9f2658d8cf0b805560169d457ac83d10325f24f2', 'message': 'Consistently use jsonutils instead of specific implementation\n\njsonutils have several benefits in comparison to pure json\nimplementation, like enabling C boosted encoders and decoders for\nPython2.6 by using simplejson when available.\n\nChange-Id: I24d0cd442e8d9d89fac50e43fc97f7bb4a293c3d\nCloses-Bug: 1329496\n'}]",4,99763,9f2658d8cf0b805560169d457ac83d10325f24f2,99,14,6,9656,,,0,"Consistently use jsonutils instead of specific implementation

jsonutils have several benefits in comparison to pure json
implementation, like enabling C boosted encoders and decoders for
Python2.6 by using simplejson when available.

Change-Id: I24d0cd442e8d9d89fac50e43fc97f7bb4a293c3d
Closes-Bug: 1329496
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/99763/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/imagecache.py', 'nova/api/openstack/compute/contrib/security_groups.py', 'nova/image/glance.py', 'nova/tests/api/test_auth.py', 'nova/virt/storage_users.py', 'nova/tests/test_metadata.py', 'nova/scheduler/scheduler_options.py', 'nova/tests/integrated/v3/test_console_auth_tokens.py', 'nova/tests/policy_fixture.py', 'nova/api/openstack/compute/plugins/v3/security_groups.py', 'nova/api/metadata/base.py', 'nova/tests/api/openstack/compute/contrib/test_server_external_events.py', 'nova/tests/virt/libvirt/test_imagecache.py', 'nova/tests/integrated/test_api_samples.py', 'nova/tests/api/openstack/compute/plugins/v3/test_server_external_events.py']",15,bc0990a6e1c5cdb9e98b4987a9a01124a37e7f90,bug/1329496,from nova.openstack.common import jsonutils req.body = jsonutils.dumps(body),import json req.body = json.dumps(body),41,45
openstack%2Fheat~master~I2f749375ccd7ca917387ef96856b1fc248c8567b,openstack/heat,master,I2f749375ccd7ca917387ef96856b1fc248c8567b,Use new template for resource update reparse,MERGED,2014-08-13 01:32:49.000000000,2014-08-14 00:48:01.000000000,2014-08-14 00:47:59.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}]","[{'number': 1, 'created': '2014-08-13 01:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2450b218a3030db851d3454be347f41bded38d5d', 'message': 'Use new template for resource update reparse\n\nIf the stack-update is switching from pre-HOT to HOT then\nthe update will fail because the functions are resolved\nusing the pre-HOT template.\n\nThis change uses the new template for the reparse instead of the\nold one. It fixes the issue observed but any other effects are\nunknown.\n\nChange-Id: I2f749375ccd7ca917387ef96856b1fc248c8567b\nCloses-Bug: #1356097\n'}, {'number': 2, 'created': '2014-08-13 01:57:58.000000000', 'files': ['heat/engine/update.py', 'heat/tests/test_parser.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/afd538664f5041df1070e5e8b42b5bab979dc9f7', 'message': 'Use new template for resource update reparse\n\nIf the stack-update is switching from pre-HOT to HOT then\nthe update will fail because the functions are resolved\nusing the pre-HOT template.\n\nThis change uses the new template for the reparse instead of the\nold one. It fixes the issue observed but any other effects are\nunknown.\n\nChange-Id: I2f749375ccd7ca917387ef96856b1fc248c8567b\nCloses-Bug: #1356097\n'}]",0,113739,afd538664f5041df1070e5e8b42b5bab979dc9f7,20,4,2,4571,,,0,"Use new template for resource update reparse

If the stack-update is switching from pre-HOT to HOT then
the update will fail because the functions are resolved
using the pre-HOT template.

This change uses the new template for the reparse instead of the
old one. It fixes the issue observed but any other effects are
unknown.

Change-Id: I2f749375ccd7ca917387ef96856b1fc248c8567b
Closes-Bug: #1356097
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/113739/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/update.py'],1,2450b218a3030db851d3454be347f41bded38d5d,bug/1356097, # but with the template of the new stack (in case the update # is switching template implementations) self.new_stack.t), self.existing_stack.t),3,1
openstack%2Fheat~master~I4c08732d37ca9c1e15d13217ba257fff1bc2f518,openstack/heat,master,I4c08732d37ca9c1e15d13217ba257fff1bc2f518,test_parser.py remove some spurious Replay/Verify calls,MERGED,2014-08-13 09:15:24.000000000,2014-08-14 00:46:56.000000000,2014-08-14 00:46:55.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-08-13 09:15:24.000000000', 'files': ['heat/tests/test_parser.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0b86e0a0f7fb2039f9241240f9c42921f2c13f06', 'message': ""test_parser.py remove some spurious Replay/Verify calls\n\nThere are some Replay/Verify calls which don't do anything, so\nremove them, for the avoidance of perpetuating them in cut/paste\nfor new tests.\n\nChange-Id: I4c08732d37ca9c1e15d13217ba257fff1bc2f518\n""}]",0,113819,0b86e0a0f7fb2039f9241240f9c42921f2c13f06,16,7,1,4328,,,0,"test_parser.py remove some spurious Replay/Verify calls

There are some Replay/Verify calls which don't do anything, so
remove them, for the avoidance of perpetuating them in cut/paste
for new tests.

Change-Id: I4c08732d37ca9c1e15d13217ba257fff1bc2f518
",git fetch https://review.opendev.org/openstack/heat refs/changes/19/113819/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_parser.py'],1,0b86e0a0f7fb2039f9241240f9c42921f2c13f06,test_parser_cleanup,, self.m.ReplayAll() self.m.ReplayAll() self.m.VerifyAll() self.m.ReplayAll() self.m.VerifyAll() self.m.ReplayAll() self.m.VerifyAll() self.m.ReplayAll() self.m.VerifyAll() ,0,17
openstack%2Ftripleo-ci~master~I489a06223d37c01fc12edfbbfc268e35f6968b8c,openstack/tripleo-ci,master,I489a06223d37c01fc12edfbbfc268e35f6968b8c,Use baremetal_full to get the entire disk,MERGED,2014-07-23 13:58:46.000000000,2014-08-14 00:43:49.000000000,2014-08-14 00:43:49.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-07-23 13:58:46.000000000', 'files': ['heat-templates/testenv-workers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6dcb1ccefb7c5b03278515e80b0a6d74e3f3a2a1', 'message': ""Use baremetal_full to get the entire disk\n\nWe don't need a state partition for testenvs.\n\nChange-Id: I489a06223d37c01fc12edfbbfc268e35f6968b8c\n""}]",0,108997,6dcb1ccefb7c5b03278515e80b0a6d74e3f3a2a1,14,3,1,4190,,,0,"Use baremetal_full to get the entire disk

We don't need a state partition for testenvs.

Change-Id: I489a06223d37c01fc12edfbbfc268e35f6968b8c
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/97/108997/1 && git format-patch -1 --stdout FETCH_HEAD,['heat-templates/testenv-workers.yaml'],1,6dcb1ccefb7c5b03278515e80b0a6d74e3f3a2a1,, Default: baremetal_full, Default: baremetal,1,1
openstack%2Ftripleo-ci~master~I5d67cb28ffa6fc1a50f043993428daf3efc22f1e,openstack/tripleo-ci,master,I5d67cb28ffa6fc1a50f043993428daf3efc22f1e,Allow new virsh commands from ironic,MERGED,2014-07-29 22:55:25.000000000,2014-08-14 00:37:21.000000000,2014-08-14 00:37:20.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 6928}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-07-29 22:55:25.000000000', 'files': ['elements/testenv-worker/bin/ci_commands'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/80c920b64658e464bf4f6750ecbf9da635aec99a', 'message': 'Allow new virsh commands from ironic\n\nAs of I36b704e4d9daa902393b3f79405bf288d9ee0872 ironic has added\n2 new commands to the ssh driver.\n\nChange-Id: I5d67cb28ffa6fc1a50f043993428daf3efc22f1e\n'}]",0,110492,80c920b64658e464bf4f6750ecbf9da635aec99a,18,5,1,1926,,,0,"Allow new virsh commands from ironic

As of I36b704e4d9daa902393b3f79405bf288d9ee0872 ironic has added
2 new commands to the ssh driver.

Change-Id: I5d67cb28ffa6fc1a50f043993428daf3efc22f1e
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/92/110492/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/testenv-worker/bin/ci_commands'],1,80c920b64658e464bf4f6750ecbf9da635aec99a,virsh-commands," r""""""^/usr/bin/virsh( --connect qemu:///system)? (start|destroy|reset) ""?[a-z0-9_]+""?$"""""": run_command, r""""""^/usr/bin/virsh( --connect qemu:///system)? dumpxml [a-z0-9_]+ \| awk '[\w\\\/<>\(\){},.|=*;"" ]+' Q=""'"" RS=""\[<>\]"" \| head -1$"""""": run_command, r""""""^EDITOR=""sed -i '[\w\\\/<>\(\)|=*;"" ]+'"" /usr/bin/virsh( --connect qemu:///system)? edit ""?[a-z0-9_]+""?$"""""": run_command,"," r""""""^/usr/bin/virsh( --connect qemu:///system)? (start|destroy|reset) ""?[a-z0-9_]+""?$"""""": run_command",3,1
openstack%2Ftripleo-ci~master~I9e6474867aafb6d50605833f5e92b9ef229d4d8b,openstack/tripleo-ci,master,I9e6474867aafb6d50605833f5e92b9ef229d4d8b,Explicitly set NODE_ARCH to i386,MERGED,2014-07-11 11:48:25.000000000,2014-08-14 00:37:05.000000000,2014-08-14 00:37:05.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 6928}, {'_account_id': 7471}]","[{'number': 1, 'created': '2014-07-11 11:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8e0fe6669d1e4179df7c73ee2de509902a232d40', 'message': 'Remove explicitly setting NODE_ARCH\n\nInstead use the default set in tripleo-incubator, as is this will set TE\ndomains to be i386.\n\nChange-Id: I9e6474867aafb6d50605833f5e92b9ef229d4d8b\n'}, {'number': 2, 'created': '2014-07-11 12:17:43.000000000', 'files': ['elements/testenv-worker/bin/ensure-test-env'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7c84e2f939ad14630a4a60b3ba900b6fee872f63', 'message': 'Explicitly set NODE_ARCH to i386\n\nThis should cause us to require slightly less memory\non CI instances.\n\nChange-Id: I9e6474867aafb6d50605833f5e92b9ef229d4d8b\n'}]",0,106342,7c84e2f939ad14630a4a60b3ba900b6fee872f63,26,6,2,1926,,,0,"Explicitly set NODE_ARCH to i386

This should cause us to require slightly less memory
on CI instances.

Change-Id: I9e6474867aafb6d50605833f5e92b9ef229d4d8b
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/42/106342/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/testenv-worker/bin/ensure-test-env'],1,8e0fe6669d1e4179df7c73ee2de509902a232d40,te-fixes,,export NODE_ARCH=amd64,0,1
openstack%2Fswift~master~I5bc15bbd2968ab7bedcd7c0df10f2ec825537191,openstack/swift,master,I5bc15bbd2968ab7bedcd7c0df10f2ec825537191,Add POST and DELETE to tempurl default methods,MERGED,2014-07-11 18:43:42.000000000,2014-08-14 00:30:45.000000000,2014-08-14 00:30:45.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 8871}, {'_account_id': 10380}]","[{'number': 1, 'created': '2014-07-11 18:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/25a59b88dca9efa4ef3ae651c99f253e2446e73e', 'message': ""Add POST and DELETE to tempurl default methods\n\nThe tempurl middleware supports any configured HTTP methods, but the\ndefault set was only GET, PUT, and HEAD, so cluster operators had to\ntake action to enable POST and DELETE. This commit changes the\ndefaults to include POST and DELETE.\n\nNote that this doesn't affect any existing temporary URLs at all; the\nmethod is baked into the signature (temp_url_sig query param), so no\nnew access is granted to a holder of a temporary URL by this\nchange. It simply gives more flexibility to creators of temporary\nURLs.\n\nChange-Id: I5bc15bbd2968ab7bedcd7c0df10f2ec825537191\n""}, {'number': 2, 'created': '2014-07-11 18:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0c00f562d1656b92424ade0a8aa32f190d962de8', 'message': ""Add POST and DELETE to tempurl default methods\n\nThe tempurl middleware supports any configured HTTP methods, but the\ndefault set was only GET, PUT, and HEAD, so cluster operators had to\ntake action to enable POST and DELETE. This commit changes the\ndefaults to include POST and DELETE.\n\nNote that this doesn't affect any existing temporary URLs at all; the\nmethod is baked into the signature (temp_url_sig query param), so no\nnew access is granted to a holder of a temporary URL by this\nchange. It simply gives more flexibility to creators of temporary\nURLs.\n\nChange-Id: I5bc15bbd2968ab7bedcd7c0df10f2ec825537191\n""}, {'number': 3, 'created': '2014-08-07 11:30:10.000000000', 'files': ['swift/common/middleware/tempurl.py', 'etc/proxy-server.conf-sample', 'test/unit/common/middleware/test_tempurl.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/134e864fa132b4d29e8fed6c54526cf1777307b2', 'message': ""Add POST and DELETE to tempurl default methods\n\nThe tempurl middleware supports any configured HTTP methods, but the\ndefault set was only GET, PUT, and HEAD, so cluster operators had to\ntake action to enable POST and DELETE. This commit changes the\ndefaults to include POST and DELETE.\n\nNote that this doesn't affect any existing temporary URLs at all; the\nmethod is baked into the signature (temp_url_sig query param), so no\nnew access is granted to a holder of a temporary URL by this\nchange. It simply gives more flexibility to creators of temporary\nURLs.\n\nChange-Id: I5bc15bbd2968ab7bedcd7c0df10f2ec825537191\n""}]",0,106466,134e864fa132b4d29e8fed6c54526cf1777307b2,33,8,3,2622,,,0,"Add POST and DELETE to tempurl default methods

The tempurl middleware supports any configured HTTP methods, but the
default set was only GET, PUT, and HEAD, so cluster operators had to
take action to enable POST and DELETE. This commit changes the
defaults to include POST and DELETE.

Note that this doesn't affect any existing temporary URLs at all; the
method is baked into the signature (temp_url_sig query param), so no
new access is granted to a holder of a temporary URL by this
change. It simply gives more flexibility to creators of temporary
URLs.

Change-Id: I5bc15bbd2968ab7bedcd7c0df10f2ec825537191
",git fetch https://review.opendev.org/openstack/swift refs/changes/66/106466/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/tempurl.py', 'etc/proxy-server.conf-sample', 'test/unit/common/middleware/test_tempurl.py']",3,25a59b88dca9efa4ef3ae651c99f253e2446e73e,p-tempurl-methods-doc," def test_post_when_forbidden_by_config(self): self.tempurl.methods.remove('POST') def test_delete_when_forbidden_by_config(self): self.tempurl.methods.remove('DELETE') def test_delete_allowed(self): 'REQUEST_METHOD': 'POST', 'PATH_INFO': '/v1/a/c/o'}), 'a') self.assertEquals(self.tempurl._get_account({ 'REQUEST_METHOD': 'DELETE', 'PATH_INFO': '/v1/a/c/o'}), 'a') set(('GET', 'HEAD', 'PUT', 'POST', 'DELETE'))) tempurl.filter_factory({'methods': 'GET HEAD PUT DELETE BREW'}) set(('GET', 'HEAD', 'PUT', 'DELETE', 'BREW')))"," def test_post_not_allowed(self): def test_delete_not_allowed(self): def test_delete_allowed_with_conf(self): self.tempurl.methods.append('DELETE') 'REQUEST_METHOD': 'POST', 'PATH_INFO': '/v1/a/c/o'}), None) self.assertEquals(self.tempurl._get_account({ 'REQUEST_METHOD': 'DELETE', 'PATH_INFO': '/v1/a/c/o'}), None) set(('GET', 'HEAD', 'PUT'))) tempurl.filter_factory({'methods': 'GET HEAD PUT POST DELETE'}) set(('GET', 'HEAD', 'PUT', 'POST', 'DELETE')))",12,11
openstack%2Fopenstacksdk~master~Ia664b5d6e142a1c9f05134ccb5222451de9319a1,openstack/openstacksdk,master,Ia664b5d6e142a1c9f05134ccb5222451de9319a1,Fixes for telemetry,MERGED,2014-08-13 20:09:41.000000000,2014-08-14 00:18:18.000000000,2014-08-14 00:18:18.000000000,"[{'_account_id': 3}, {'_account_id': 8736}, {'_account_id': 12807}]","[{'number': 1, 'created': '2014-08-13 20:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/cf7082df0d76e79f3d6913b682fe3493f829e449', 'message': 'Fixes for telemetry\n\nIt could be my implementation, but I had to make these changes to\nget telemetry working.  Service type for me is metering.  If that\nis not always the case, maybe there should be the ability to\nsupply multiple types or override through some mapping.  Also,\nthe v2.0 url did not work for me.\n\nChange-Id: Ia664b5d6e142a1c9f05134ccb5222451de9319a1\n'}, {'number': 2, 'created': '2014-08-13 21:59:48.000000000', 'files': ['openstack/telemetry/v2/capabilities.py', 'openstack/telemetry/telemetry_service.py', 'openstack/tests/telemetry/v2/test_capabilities.py', 'openstack/tests/telemetry/test_telemetry_service.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0db56a456605ce5ffeffbbfcf5cdecd70fb3c756', 'message': 'Fixes for telemetry\n\nIt could be my implementation, but I had to make these changes to\nget telemetry working.  Service type for me is metering.  If that\nis not always the case, maybe there should be the ability to\nsupply multiple types or override through some mapping.  Also,\nthe v2.0 url did not work for me.\n\nChange-Id: Ia664b5d6e142a1c9f05134ccb5222451de9319a1\n'}]",0,114012,0db56a456605ce5ffeffbbfcf5cdecd70fb3c756,20,3,2,8736,,,0,"Fixes for telemetry

It could be my implementation, but I had to make these changes to
get telemetry working.  Service type for me is metering.  If that
is not always the case, maybe there should be the ability to
supply multiple types or override through some mapping.  Also,
the v2.0 url did not work for me.

Change-Id: Ia664b5d6e142a1c9f05134ccb5222451de9319a1
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/12/114012/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/telemetry/v2/capabilities.py', 'openstack/telemetry/telemetry_service.py']",2,cf7082df0d76e79f3d6913b682fe3493f829e449,telemetry_fixes," super(TelemetryService, self).__init__(service_type='metering')"," super(TelemetryService, self).__init__(service_type='telemetry')",2,2
openstack%2Fnova~master~I370c9e8d6a1b1f66e385f009f897816f2e705a36,openstack/nova,master,I370c9e8d6a1b1f66e385f009f897816f2e705a36,libvirt: parse disk backing chains from domain XML,MERGED,2014-06-13 18:31:01.000000000,2014-08-14 00:12:28.000000000,2014-08-13 20:46:34.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 4523}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 8574}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-13 18:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33efef4ed36b0854c43e287958600857ab0500b4', 'message': 'libvirt: parse disk backing chains from domain XML\n\nAdd support for parsing <backingStore> XML elements in the libvirt\ndomain XML description for disks.\n\nThis is being added to libvirt in order to support blockjob operations\nfor network-attached disks.\n\nChange-Id: I370c9e8d6a1b1f66e385f009f897816f2e705a36\n'}, {'number': 2, 'created': '2014-06-16 14:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60367c3d83600cdcbb9357c5c54e204e60f7c830', 'message': 'libvirt: parse disk backing chains from domain XML\n\nAdd support for parsing <backingStore> XML elements in the libvirt\ndomain XML description for disks.\n\nThis is being added to libvirt in order to support blockjob operations\nfor network-attached disks.\n\nChange-Id: I370c9e8d6a1b1f66e385f009f897816f2e705a36\n'}, {'number': 3, 'created': '2014-06-17 13:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/491830f7a345e52510eefcfeb2179ea8c5a361b7', 'message': 'libvirt: parse disk backing chains from domain XML\n\nAdd support for parsing <backingStore> XML elements in the libvirt\ndomain XML description for disks.\n\nThis is being added to libvirt in order to support blockjob operations\nfor network-attached disks.\n\nChange-Id: I370c9e8d6a1b1f66e385f009f897816f2e705a36\n'}, {'number': 4, 'created': '2014-06-18 15:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3bb130d472e679810f8f6a554dd7769035696518', 'message': 'libvirt: parse disk backing chains from domain XML\n\nAdd support for parsing <backingStore> XML elements in the libvirt\ndomain XML description for disks.\n\nThis is being added to libvirt in order to support blockjob operations\nfor network-attached disks.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I370c9e8d6a1b1f66e385f009f897816f2e705a36\n'}, {'number': 5, 'created': '2014-06-19 20:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/903746973ad3330cc20db80f3cfedcdaeb66dd7b', 'message': 'libvirt: parse disk backing chains from domain XML\n\nAdd support for parsing <backingStore> XML elements in the libvirt\ndomain XML description for disks.\n\nThis is being added to libvirt in order to support blockjob operations\nfor network-attached disks.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I370c9e8d6a1b1f66e385f009f897816f2e705a36\n'}, {'number': 6, 'created': '2014-06-20 14:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5363c76cf803d02670c89333dc2f9c56ce1cfe9', 'message': 'libvirt: parse disk backing chains from domain XML\n\nAdd support for parsing <backingStore> XML elements in the libvirt\ndomain XML description for disks.\n\nThis is being added to libvirt in order to support blockjob operations\nfor network-attached disks.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I370c9e8d6a1b1f66e385f009f897816f2e705a36\n'}, {'number': 7, 'created': '2014-07-22 19:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68cf691c097c01bf856d9f4042543835605dee58', 'message': 'libvirt: parse disk backing chains from domain XML\n\nAdd support for parsing <backingStore> XML elements in the libvirt\ndomain XML description for disks.\n\nThis is being added to libvirt in order to support blockjob operations\nfor network-attached disks.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I370c9e8d6a1b1f66e385f009f897816f2e705a36\n'}, {'number': 8, 'created': '2014-08-04 22:40:39.000000000', 'files': ['nova/virt/libvirt/config.py', 'nova/tests/virt/libvirt/test_config.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/49c3ac406503b5fd80fea896ff0eca4117c5f2ac', 'message': 'libvirt: parse disk backing chains from domain XML\n\nAdd support for parsing <backingStore> XML elements in the libvirt\ndomain XML description for disks.\n\nThis is being added to libvirt in order to support blockjob operations\nfor network-attached disks.\n\nImplements: blueprint libvirt-volume-snap-network-disk\n\nChange-Id: I370c9e8d6a1b1f66e385f009f897816f2e705a36\n'}]",13,99981,49c3ac406503b5fd80fea896ff0eca4117c5f2ac,99,13,8,4523,,,0,"libvirt: parse disk backing chains from domain XML

Add support for parsing <backingStore> XML elements in the libvirt
domain XML description for disks.

This is being added to libvirt in order to support blockjob operations
for network-attached disks.

Implements: blueprint libvirt-volume-snap-network-disk

Change-Id: I370c9e8d6a1b1f66e385f009f897816f2e705a36
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/99981/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/config.py', 'nova/tests/virt/libvirt/test_config.py']",2,33efef4ed36b0854c43e287958600857ab0500b4,bp/libvirt-volume-snap-network-disk,"class LibvirtConfigGuestDiskBackingStoreTest(LibvirtConfigBaseTest): def test_config_file_parse(self): xml = """"""<backingStore type='file'> <driver name='qemu' type='qcow2'/> <source file='/var/lib/libvirt/images/mid.qcow2'/> <backingStore type='file'> <driver name='qemu' type='qcow2'/> <source file='/var/lib/libvirt/images/base.qcow2'/> <backingStore/> </backingStore> </backingStore> """""" xmldoc = etree.fromstring(xml) obj = config.LibvirtConfigGuestDiskBackingStore() obj.parse_dom(xmldoc) self.assertEqual(obj.source_type, 'file') self.assertEqual(obj.backing_store.source_type, 'file') self.assertEqual(obj.backing_store.driver_name, 'qemu') self.assertIsNone(obj.backing_store.backing_store) def test_config_network_parse(self): xml = """"""<backingStore type='network' index='1'> <format type='qcow2'/> <source protocol='gluster' name='volume1/img1'> <host name='host1' port='24007'/> </source> <backingStore type='network' index='2'> <format type='qcow2'/> <source protocol='gluster' name='volume1/img2'> <host name='host1' port='24007'/> </source> <backingStore/> </backingStore> </backingStore> """""" xmldoc = etree.fromstring(xml) obj = config.LibvirtConfigGuestDiskBackingStore() obj.parse_dom(xmldoc) self.assertEqual(obj.source_type, 'network') self.assertEqual(obj.source_protocol, 'gluster') self.assertEqual(obj.source_name, 'volume1/img1') self.assertEqual(obj.index, '1') self.assertEqual(obj.backing_store.source_name, 'volume1/img2') self.assertEqual(obj.backing_store.index, '2') self.assertIsNone(obj.backing_store.backing_store) ",,98,3
openstack-attic%2Fvolume-api~master~I8abd1189c8948044047fa6cf19683c982f826c83,openstack-attic/volume-api,master,I8abd1189c8948044047fa6cf19683c982f826c83,Removes WADL from v1 Block Storage API,MERGED,2014-08-07 15:06:33.000000000,2014-08-14 00:04:17.000000000,2014-08-14 00:04:17.000000000,"[{'_account_id': 3}, {'_account_id': 2448}]","[{'number': 1, 'created': '2014-08-07 15:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/volume-api/commit/dc8414ec3f5819550e61eb82fb3f646029eef4b7', 'message': 'Removes WADL from v1 Block Storage API\n\nMoves generalized info to API Reference\nOther patch adds backup extension info to API Reference\n\nChange-Id: I8abd1189c8948044047fa6cf19683c982f826c83\n'}, {'number': 2, 'created': '2014-08-13 21:45:50.000000000', 'files': ['v2/bk_blockstorage_api_ref_v2.xml', 'v1/bk_blockstorage_api_ref_v1.xml'], 'web_link': 'https://opendev.org/openstack-attic/volume-api/commit/47653c6aa79b7901fd744ae60647678852c471d8', 'message': 'Removes WADL from v1 Block Storage API\n\nMoves generalized info to API Reference\nOther patch adds backup extension info to API Reference\n\nChange-Id: I8abd1189c8948044047fa6cf19683c982f826c83\n'}]",2,112605,47653c6aa79b7901fd744ae60647678852c471d8,13,2,2,964,,,0,"Removes WADL from v1 Block Storage API

Moves generalized info to API Reference
Other patch adds backup extension info to API Reference

Change-Id: I8abd1189c8948044047fa6cf19683c982f826c83
",git fetch https://review.opendev.org/openstack-attic/volume-api refs/changes/05/112605/2 && git format-patch -1 --stdout FETCH_HEAD,"['v2/bk_blockstorage_api_ref_v2.xml', 'v1/bk_blockstorage_api_ref_v1.xml']",2,dc8414ec3f5819550e61eb82fb3f646029eef4b7,extricate-wadl," <date>2014-08-05</date> <revdescription> <itemizedlist spacing=""compact""> <listitem> <para>Removes WADL references.</para> </listitem> </itemizedlist> </revdescription> </revision> <revision> <para>For information about Block Storage API operations, see <link xlink:href=""http://developer.openstack.org/api-ref-blockstorage-v1.html"" ><citetitle>Block Storage API v1 (CURRENT)</citetitle></link>.</para>"," <section xml:id=""Volumes""> <title>Volumes</title> <para>A volume is a detachable block storage device. You can think of it as a USB hard drive. It can only be attached to one instance at a time.</para> <para><?rax-fo keep-with-next?>When making an API call to create, list, or delete volume(s), the following status values are possible:</para> <itemizedlist spacing=""compact""> <listitem> <para>CREATING &ndash; The volume is being created.</para> </listitem> <listitem> <para>AVAILABLE &ndash; The volume is read to be attached to an instance.</para> </listitem> <listitem> <para>ATTACHING &ndash; The volume is attaching to an instance.</para> </listitem> <listitem> <para>IN-USE &ndash; The volume is attached to an instance.</para> </listitem> <listitem> <para>DELETING &ndash; The volume is being deleted.</para> </listitem> <listitem> <para>ERROR &ndash; An error has occurred with the volume.</para> </listitem> <listitem> <para>ERROR_DELETING &ndash; There was an error deleting the volume.</para> </listitem> </itemizedlist> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/volume-api/src/v1/volume-api-v1.wadl#volumes""> <wadl:method href=""createVolume""/> <wadl:method href=""getVolumesSimple""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/volume-api/src/v1/volume-api-v1.wadl#detail-volume""> <wadl:method href=""getVolumesDetail""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/volume-api/src/v1/volume-api-v1.wadl#volume_id""> <wadl:method href=""getVolume""/> <wadl:method href=""deleteVolume""/> </wadl:resource> </wadl:resources> </section> <section xml:id=""Snapshots""> <title>Snapshots</title> <para><?rax-fo keep-with-next?>A snapshot is a point in time copy of the data contained in a volume.</para> <para>When making an API call to create, list, or delete snapshot(s), the following status values are possible:</para> <itemizedlist spacing=""compact""> <listitem> <para>CREATING &ndash; The snapshot is being created.</para> </listitem> <listitem> <para>AVAILABLE &ndash; The snapshot is ready to be used.</para> </listitem> <listitem> <para>DELETING &ndash; The snapshot is being deleted.</para> </listitem> <listitem> <para>ERROR &ndash; An error occurred with the snapshot.</para> </listitem> <listitem> <para>ERROR_DELETING &ndash; There was an error deleting the snapshot.</para> </listitem> </itemizedlist> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/volume-api/src/v1/volume-api-v1.wadl#snapshots""/> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/volume-api/src/v1/volume-api-v1.wadl#detail-snapshots""/> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/volume-api/src/v1/volume-api-v1.wadl#snapshot_id"" /> </wadl:resources> </section> <section xml:id=""Volume_Types""> <title>Volume types</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/volume-api/src/v2/volume-api-v2.wadl#types""> <wadl:method href=""getVolumeTypes""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/volume-api/src/v2/volume-api-v2.wadl#volume_type_id""> <wadl:method href=""getVolumeType""/> </wadl:resource> </wadl:resources> </section> <section xml:id=""ext-os-quota-sets-cinder""> <title>Quota sets extension (os-quota-sets)</title> <para>Administrators only, depending on policy settings. View, update, and delete quotas for a tenant.</para> <wadl:resources href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/volume-api/src/v1/os-quota-sets.wadl"" xmlns:wadl=""http://wadl.dev.java.net/2009/02""/> </section>",17,386
openstack-attic%2Fnetconn-api~master~Ie28876acb2c8e0837a87dd475ef235f54dcf4c03,openstack-attic/netconn-api,master,Ie28876acb2c8e0837a87dd475ef235f54dcf4c03,Removes WADL references and replaces with links to API Ref,MERGED,2014-08-08 15:47:34.000000000,2014-08-14 00:02:06.000000000,2014-08-14 00:02:06.000000000,"[{'_account_id': 3}, {'_account_id': 2448}]","[{'number': 1, 'created': '2014-08-08 15:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/netconn-api/commit/f71c530e5b2de038b80626e5a3e78ee6b0554f02', 'message': 'Removes WADL references and replaces with links to API Ref\n\nChange-Id: Ie28876acb2c8e0837a87dd475ef235f54dcf4c03\n'}, {'number': 2, 'created': '2014-08-13 21:56:29.000000000', 'files': ['v2.0/section_neutron-ext-metering.xml', 'v2.0/ch_neutron_api_extensions.xml', 'v2.0/section_neutron-ext-lbaas.xml', 'v2.0/section_neutron-ext-provider-networks.xml', 'v2.0/section_neutron-ext-security-groups-rules.xml', 'v2.0/section_neutron-ext-agent-management.xml', 'v2.0/section_neutron-ext-extra-dhcp-options.xml', 'v2.0/section_neutron-ext-quotas.xml', 'v2.0/section_neutron-ext-external-networks.xml', 'v2.0/section_neutron-ext-allowed-address-pairs.xml', 'v2.0/section_neutron-ext-extra-routes.xml', 'v2.0/section_neutron-ext-agent-schedulers.xml', 'v2.0/section_neutron-ext-vpnaas.xml', 'v2.0/section_neutron-ext-external-gateways-modes.xml', 'v2.0/section_neutron-ext-fwaas.xml', 'v2.0/section_neutron-ext-provider-networks-multi.xml', 'v2.0/ch_neutron_api_operations.xml', 'v2.0/section_neutron-ext-layer3.xml', 'v2.0/section_neutron-ext-binding-ports.xml', 'v2.0/neutron-api-guide.xml', 'v2.0/section_neutron-ext-show-info.xml'], 'web_link': 'https://opendev.org/openstack-attic/netconn-api/commit/3825fdc3752f124b5951bacc91f36f1eb3b68970', 'message': 'Removes WADL references and replaces with links to API Ref\n\nChange-Id: Ie28876acb2c8e0837a87dd475ef235f54dcf4c03\n'}]",1,112951,3825fdc3752f124b5951bacc91f36f1eb3b68970,13,2,2,964,,,0,"Removes WADL references and replaces with links to API Ref

Change-Id: Ie28876acb2c8e0837a87dd475ef235f54dcf4c03
",git fetch https://review.opendev.org/openstack-attic/netconn-api refs/changes/51/112951/1 && git format-patch -1 --stdout FETCH_HEAD,"['v2.0/section_neutron-ext-metering.xml', 'v2.0/ch_neutron_api_extensions.xml', 'v2.0/section_neutron-ext-lbaas.xml', 'v2.0/section_neutron-ext-provider-networks.xml', 'v2.0/section_neutron-ext-security-groups-rules.xml', 'v2.0/section_neutron-ext-agent-management.xml', 'v2.0/section_neutron-ext-extra-dhcp-options.xml', 'v2.0/section_neutron-ext-quotas.xml', 'v2.0/section_neutron-ext-external-networks.xml', 'v2.0/section_neutron-ext-allowed-address-pairs.xml', 'v2.0/section_neutron-ext-extra-routes.xml', 'v2.0/section_neutron-ext-agent-schedulers.xml', 'v2.0/section_neutron-ext-vpnaas.xml', 'v2.0/section_neutron-ext-external-gateways-modes.xml', 'v2.0/section_neutron-ext-fwaas.xml', 'v2.0/section_neutron-ext-provider-networks-multi.xml', 'v2.0/ch_neutron_api_operations.xml', 'v2.0/section_neutron-ext-layer3.xml', 'v2.0/section_neutron-ext-binding-ports.xml', 'v2.0/neutron-api-guide.xml', 'v2.0/section_neutron-ext-show-info.xml']",21,f71c530e5b2de038b80626e5a3e78ee6b0554f02,remove-wadl-from,,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xlink=""http://www.w3.org/1999/xlink"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:svg=""http://www.w3.org/2000/svg"" xmlns:m=""http://www.w3.org/1998/Math/MathML"" xmlns:html=""http://www.w3.org/1999/xhtml"" xmlns:xsdxt=""http://docs.rackspacecloud.com/xsd-ext/v1.0"" xmlns:db=""http://docbook.org/ns/docbook"" version=""5.0"" xml:id=""retrieve_extensions""> <title>Get extension information</title> <para>List available extensions and show details for a specified extension.</para> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/netconn-api/src/os-networks.wadl#extensions""> <wadl:method href=""#listExtensions""/> </wadl:resource> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/netconn-api/src/os-networks.wadl#extension""> <wadl:method href=""#getExtension""/> </wadl:resource> </wadl:resources> </section> ",26,5915
openstack%2Fheat~master~I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110,openstack/heat,master,I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110,"Cinder, trove, ceilo use ignore_not_found etc",MERGED,2014-06-20 03:05:38.000000000,2014-08-13 23:58:58.000000000,2014-08-13 23:58:57.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6610}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7239}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 7761}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9165}, {'_account_id': 10487}, {'_account_id': 11599}, {'_account_id': 12437}]","[{'number': 1, 'created': '2014-06-20 03:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/25c027f428b2344c718286ced2f9fa0a1baf7e3f', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 2, 'created': '2014-06-23 00:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b9434e4a08856bbc657713d1e57c63e432107845', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 3, 'created': '2014-06-23 22:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/84ab74c65ef7c259505a2502ddac10774af726b5', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 4, 'created': '2014-06-26 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/38d2a900fbcf682c0026a4894ca91eff0489093a', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 5, 'created': '2014-06-27 06:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/63bf4d5ae8e5d96159b9fa96cfb9ede4b37336df', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 6, 'created': '2014-06-30 02:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/360c41620fd439c494fd34c76b465b0e93575c7b', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 7, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0b85a525598ebf6aeaa45e06f07d82fb9ce0cb9e', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 8, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c437e4195f6e98f380896901458227ca38d8d477', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 9, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b6ed9e653230c13f1436be12df625c5d10a31334', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 10, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7fd0ef6135ff7aeacd986a45eb6f1c8e68f37d54', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 11, 'created': '2014-07-06 22:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5b1df6ea63ebad79789c92ce1699b4ebbf885f7d', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 12, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8ff1daf99428b6e466887d4479161f2d546b3b34', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 13, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/23f05874cfc29726feda07056a45734178a7167f', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 14, 'created': '2014-07-08 21:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/54040dda7154eb01aec638b450e8bb7c7e680665', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 15, 'created': '2014-07-17 02:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5ab04323d928b29044bd4bcd820b118b950723bf', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 16, 'created': '2014-07-18 02:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9b6e4fa9fa596d2fceccd17f5681cdafac0db18c', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 17, 'created': '2014-07-21 17:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/afc857dc7d898b2face5cccb8740553db13b4947', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 18, 'created': '2014-07-21 17:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d5f26f82cb5d30ca9c2afc2a78fa23fbbca2d924', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 19, 'created': '2014-07-24 21:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/307eedc7df0c5ce897c7f332168303c1d670e60a', 'message': 'Cinder, trove, ceilo use ignore_not_found()\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 20, 'created': '2014-07-28 02:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bed8f4f2dd9e28df16a474e345d22f47dc3996e2', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 21, 'created': '2014-07-28 21:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6aa86c767c25938bba686d7430410572befe6f05', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 22, 'created': '2014-07-29 20:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/72aaa76dcae43a0110d7cae610ce71f0ee7deb89', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 23, 'created': '2014-07-29 21:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4bb44f1186e814eeb6ef07a15396f669ac373fe8', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 24, 'created': '2014-07-30 21:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/af1ac0e1fc5e03bf8b69a082dee2c25fe4137ad1', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 25, 'created': '2014-07-31 17:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/84c328f89c93b142644a3db0488f1ded15f605f3', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 26, 'created': '2014-07-31 22:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/94a5e615b6d3d3021f0f09189e16c1445c5862c4', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 27, 'created': '2014-08-05 15:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8e427dca9f51c4b49c9e78c60321a15dd1e749f3', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 28, 'created': '2014-08-11 16:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/68d35f04c959b6875c2790ae10b22a6bbe671253', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 29, 'created': '2014-08-11 22:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d50f42b584fe39bcf83102d195703fdca450e43f', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}, {'number': 30, 'created': '2014-08-13 21:43:39.000000000', 'files': ['heat/engine/resources/ceilometer/alarm.py', 'heat/engine/resources/os_database.py', 'heat/engine/resources/volume.py', 'heat/engine/clients/os/trove.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/20c347a7944f691eba2ab641bcd4e4ef9b0890d0', 'message': 'Cinder, trove, ceilo use ignore_not_found etc\n\nChange-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110\n'}]",0,101397,20c347a7944f691eba2ab641bcd4e4ef9b0890d0,135,25,30,4571,,,0,"Cinder, trove, ceilo use ignore_not_found etc

Change-Id: I7dc38cba8cb9a51fed616c7bb9c8eb58e897a110
",git fetch https://review.opendev.org/openstack/heat refs/changes/97/101397/30 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/ceilometer/alarm.py', 'heat/engine/resources/os_database.py', 'heat/engine/resources/volume.py', 'heat/tests/test_ceilometer_alarm.py']",4,25c027f428b2344c718286ced2f9fa0a1baf7e3f,bp/client-plugins, ceilometer.exc.HTTPNotFound()) ceilometer.exc.HTTPNotFound()), alarm.ceilometerclient_exc.HTTPNotFound()) alarm.ceilometerclient_exc.HTTPNotFound()),29,19
openstack%2Fironic~master~Ie7bc50a9804373c9c4f8850f4e2b201c1d01effb,openstack/ironic,master,Ie7bc50a9804373c9c4f8850f4e2b201c1d01effb,Driver merge review comments from 111425-2-3,MERGED,2014-08-13 02:14:02.000000000,2014-08-13 23:49:52.000000000,2014-08-13 23:49:52.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 6773}]","[{'number': 1, 'created': '2014-08-13 02:14:02.000000000', 'files': ['ironic/nova/virt/ironic/driver.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b97bb93455b6c3c124af328e54da983c89c9ee86', 'message': 'Driver merge review comments from 111425-2-3\n\nThis review contain fixes that addresses the review comments\nraised in https://review.openstack.org/#/c/111425 revisions 2 & 3.\nOnce these changes are merged here in Ironic, they will be\nproposed as updates to the patch series over in Nova.\n\nChange-Id: Ie7bc50a9804373c9c4f8850f4e2b201c1d01effb\n'}]",0,113750,b97bb93455b6c3c124af328e54da983c89c9ee86,11,4,1,8125,,,0,"Driver merge review comments from 111425-2-3

This review contain fixes that addresses the review comments
raised in https://review.openstack.org/#/c/111425 revisions 2 & 3.
Once these changes are merged here in Ironic, they will be
proposed as updates to the patch series over in Nova.

Change-Id: Ie7bc50a9804373c9c4f8850f4e2b201c1d01effb
",git fetch https://review.opendev.org/openstack/ironic refs/changes/50/113750/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/nova/virt/ironic/driver.py'],1,b97bb93455b6c3c124af328e54da983c89c9ee86,fixes-for-111425-3," self.firewall_driver = firewall.load_driver( default='nova.virt.firewall.NoopFirewallDriver') memory_kib = int(node.properties.get('memory_mb', 0)) * 1024 if memory_kib == 0: LOG.warn(_LW(""Warning, memory usage is 0 for "" ""%(instance)s on baremetal node %(node)s.""), {'instance': instance['uuid'], 'node': instance['node']}) num_cpu = node.properties.get('cpus', 0) if num_cpu == 0: LOG.warn(_LW(""Warning, number of cpus is 0 for "" ""%(instance)s on baremetal node %(node)s.""), {'instance': instance['uuid'], 'node': instance['node']}) 'num_cpu': num_cpu,","_FIREWALL_DRIVER = ""%s.%s"" % (firewall.__name__, firewall.NoopFirewallDriver.__name__) self.firewall_driver = firewall.load_driver(default=_FIREWALL_DRIVER) memory_kib = int(node.properties.get('memory_mb')) * 1024 'num_cpu': node.properties.get('cpus'), # TODO(nobodycam): check the current power state first. # TODO(nobodycam): check the current power state first.",17,8
openstack%2Fironic~master~Ic403ef47586922ef12c111aa191b0b181028d60d,openstack/ironic,master,Ic403ef47586922ef12c111aa191b0b181028d60d,Raise MissingParameterValue when validating glance info,MERGED,2014-07-21 18:07:10.000000000,2014-08-13 23:49:19.000000000,2014-08-13 23:49:19.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7763}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-07-21 18:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/36c3c791d409546dd681afa27479cd5182bdce18', 'message': 'Use _check_for_missing_params when validating glance info\n\nThere was duplicate code inside validate_glance_image function.\nMake use of the generic _check_for_missing_params and update the\ndocstring to add a new MissingParameterValue exception.\n\nChange-Id: Ic403ef47586922ef12c111aa191b0b181028d60d\n'}, {'number': 2, 'created': '2014-07-22 16:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ef48f87c47d95377c56d05a283a4c3a446777f51', 'message': 'Raise MissingParamenterValue when validating glance info\n\nMake use of the MissigParameterValue exception when validating the\nimage info from glance.\n\nChange-Id: Ic403ef47586922ef12c111aa191b0b181028d60d\n'}, {'number': 3, 'created': '2014-07-22 22:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/890b8d092fc84e5394962787463e66d2aeecbb40', 'message': 'Raise MissingParamenterValue when validating glance info\n\nMake use of the MissigParameterValue exception when validating the\nimage info from glance.\n\nChange-Id: Ic403ef47586922ef12c111aa191b0b181028d60d\n'}, {'number': 4, 'created': '2014-07-23 12:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2c8bcb877fb9c666779b4a58f82283f35462cdcb', 'message': 'Raise MissingParameterValue when validating glance info\n\nMake use of the MissigParameterValue exception when validating the\nimage info from glance.\n\nChange-Id: Ic403ef47586922ef12c111aa191b0b181028d60d\n'}, {'number': 5, 'created': '2014-08-07 06:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ff94bd704db30308f6ff7822538b6aacc3c893c9', 'message': 'Raise MissingParameterValue when validating glance info\n\nMake use of the MissigParameterValue exception when validating the\nimage info from glance.\n\nChange-Id: Ic403ef47586922ef12c111aa191b0b181028d60d\n'}, {'number': 6, 'created': '2014-08-12 11:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e84d2bf28dcd4773edd7abedeccb57dcf8eecf58', 'message': 'Raise MissingParameterValue when validating glance info\n\nMake use of the MissigParameterValue exception when validating the\nimage info from glance.\n\nChange-Id: Ic403ef47586922ef12c111aa191b0b181028d60d\n'}, {'number': 7, 'created': '2014-08-13 07:53:01.000000000', 'files': ['ironic/tests/drivers/test_pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/3d7d6832459cf5945079d57136462a4a6d1f4c59', 'message': 'Raise MissingParameterValue when validating glance info\n\nMake use of the MissigParameterValue exception when validating the\nimage info from glance.\n\nChange-Id: Ic403ef47586922ef12c111aa191b0b181028d60d\n'}]",1,108456,3d7d6832459cf5945079d57136462a4a6d1f4c59,56,10,7,1726,,,0,"Raise MissingParameterValue when validating glance info

Make use of the MissigParameterValue exception when validating the
image info from glance.

Change-Id: Ic403ef47586922ef12c111aa191b0b181028d60d
",git fetch https://review.opendev.org/openstack/ironic refs/changes/56/108456/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_pxe.py']",2,36c3c791d409546dd681afa27479cd5182bdce18,glance_missing," self.assertRaises(exception.MissingParameterValue,"," self.assertRaises(exception.InvalidParameterValue,",6,10
openstack%2Ftripleo-image-elements~master~I92818ef4324493f19207c10a73a0d6510795e9cc,openstack/tripleo-image-elements,master,I92818ef4324493f19207c10a73a0d6510795e9cc,"Revert ""Use pacemaker to run neutron l3 agent and metadata agent""",MERGED,2014-08-13 20:42:18.000000000,2014-08-13 23:45:03.000000000,2014-08-13 23:45:02.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-08-13 20:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1b80494d91cba7e2a19a044d815ceaff4ddd3e3a', 'message': 'Revert ""Use pacemaker to run neutron l3 agent and metadata agent""\n\nThis reverts commit 9ae3c52104a2098b2566fe77e5420ec93b5875f7.\n\nThere are three issues:\n - it doesn\'t work on Ubuntu\n - upgrading the images on a cloud with old heat templates will fail (it doesn\'t have sensible defaults)\n - upgrading an existing a/a cloud will cause 2/3rds of the networks to stop routing until their networks are rescheduled. \n\nWe need to fix all three things before landing this.\n\nChange-Id: I92818ef4324493f19207c10a73a0d6510795e9cc\n'}, {'number': 2, 'created': '2014-08-13 20:42:54.000000000', 'files': ['elements/neutron-network-node/element-deps', 'elements/neutron-network-node/os-refresh-config/post-configure.d/80-neutron-networking'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/fa0627569ded7673568d53e9a44af447d5feb3c5', 'message': 'Revert ""Use pacemaker to run neutron l3 agent and metadata agent""\n\nThis reverts commit 9ae3c52104a2098b2566fe77e5420ec93b5875f7.\n\nThere are three issues:\n - it doesn\'t work on Ubuntu\n - upgrading the images on a cloud with old heat templates will \n   fail (needed to permit upgrading heat to transition to HOT)\n - upgrading an existing a/a cloud will cause 2/3rds of the \n   networks to stop routing until their networks are rescheduled. \n\nWe need to fix all three things before landing this.\n\nChange-Id: I92818ef4324493f19207c10a73a0d6510795e9cc\n'}]",0,114019,fa0627569ded7673568d53e9a44af447d5feb3c5,12,4,2,4190,,,0,"Revert ""Use pacemaker to run neutron l3 agent and metadata agent""

This reverts commit 9ae3c52104a2098b2566fe77e5420ec93b5875f7.

There are three issues:
 - it doesn't work on Ubuntu
 - upgrading the images on a cloud with old heat templates will 
   fail (needed to permit upgrading heat to transition to HOT)
 - upgrading an existing a/a cloud will cause 2/3rds of the 
   networks to stop routing until their networks are rescheduled. 

We need to fix all three things before landing this.

Change-Id: I92818ef4324493f19207c10a73a0d6510795e9cc
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/19/114019/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/neutron-network-node/element-deps', 'elements/neutron-network-node/os-refresh-config/post-configure.d/80-neutron-networking']",2,1b80494d91cba7e2a19a044d815ceaff4ddd3e3a,pcmk-neutron2,os-svc-enable -n neutron-metadata-agent os-svc-enable -n neutron-l3-agent os-svc-restart -n neutron-metadata-agent os-svc-restart -n neutron-l3-agent,"# get resource class (systemd, upstart, lsb). It should be possible # to use 'service' class which is a wrapper for others but this doesn't work # as expected on Fedora - lrmd process segfaults if 'service' resource class # is used: https://bugzilla.redhat.com/show_bug.cgi?id=1117151 CLASS=$(dib-init-system) if [ ""$CLASS"" = ""sysv"" ]; then CLASS=lsb fi if os-is-bootstrap-host; then SERVICE_METADATA=$(map-services neutron-metadata-agent) SERVICE_AGENT=$(map-services neutron-l3-agent) if ! cibadmin --query --xpath ""//primitive[@id=\""$SERVICE_METADATA\""]""; then /usr/sbin/cibadmin -o resources -C -X "" <primitive class=\""$CLASS\"" id=\""$SERVICE_METADATA\"" type=\""$SERVICE_METADATA\""> <instance_attributes id=\""$SERVICE_METADATA-instance_attributes\""/> <operations> <op id=\""$SERVICE_METADATA-monitor-start-delay-10s\"" interval=\""30s\"" name=\""monitor\"" start-delay=\""10s\""/> </operations> </primitive>"" fi if ! cibadmin --query --xpath ""//primitive[@id=\""$SERVICE_AGENT\""]""; then /usr/sbin/cibadmin -o resources -C -X "" <primitive class=\""$CLASS\"" id=\""$SERVICE_AGENT\"" type=\""$SERVICE_AGENT\""> <instance_attributes id=\""$SERVICE_AGENT-instance_attributes\""/> <operations> <op id=\""$SERVICE_AGENT-monitor-start-delay-10s\"" interval=\""30s\"" name=\""monitor\"" start-delay=\""10s\""/> </operations> </primitive>"" fi fi",4,34
openstack%2Fsahara~master~Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e,openstack/sahara,master,Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e,Add translation support to plugin modules,MERGED,2014-07-17 14:28:56.000000000,2014-08-13 23:41:16.000000000,2014-08-13 23:41:15.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-07-17 14:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8cf6a788bd73a40e3a8a1c7192eb44a85ddda034', 'message': 'oslo.i18n implementation added\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 2, 'created': '2014-07-18 12:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4731f83246215d195b337d623313c74f6961fee2', 'message': 'oslo.i18n implementation added\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 3, 'created': '2014-07-18 13:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d236338ecd4c68bb450958b2da986cdff4f61724', 'message': 'oslo.i18n implementation added\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 4, 'created': '2014-07-18 14:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/247ab6a733baaaa39f457b253625c5c71449a422', 'message': 'oslo.i18n implementation added\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 5, 'created': '2014-07-18 14:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5dce8a7dffa31a77119b738441c20cfc1eee0ce5', 'message': 'oslo.i18n implementation added\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 6, 'created': '2014-07-21 10:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7076ffa69b8183b5a566bad7f1e90803db1ed3e9', 'message': 'oslo.i18n implementation added\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 7, 'created': '2014-07-21 13:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2b8998ff4a4d7ba5cfd8f0fd86804daf43be58f1', 'message': 'oslo.i18n implementation added\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 8, 'created': '2014-07-22 10:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b44e614f08d61b6531f5534b6d671b4f544ea2ae', 'message': 'Add translation support to plugin modules\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 9, 'created': '2014-07-23 12:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/bd3ad2fc827e55b7874b4811c431ce31d8fee44a', 'message': 'Add translation support to plugin modules\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 10, 'created': '2014-07-24 13:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d43fcee8177eee2425f988308f6dcb606e267819', 'message': 'Add translation support to plugin modules\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 11, 'created': '2014-07-25 10:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/91cfd52b4c88df2482bd8866af27ed59c3fd035c', 'message': 'Add translation support to plugin modules\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 12, 'created': '2014-07-28 11:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a86f07da4bbb5282e714587f5ecd9dfe8a807495', 'message': 'Add translation support to plugin modules\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 13, 'created': '2014-07-31 13:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/70c918818b538c788953b7722d6d9f8c5599cf6b', 'message': 'Add translation support to plugin modules\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 14, 'created': '2014-08-05 12:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/cde07c5def9cf18da5a2e91608e9e6ac3809da35', 'message': 'Add translation support to plugin modules\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 15, 'created': '2014-08-05 12:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/efc46af6ed2ce69ce8a5f77e3c71499fea8e85ea', 'message': 'Add translation support to plugin modules\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 16, 'created': '2014-08-11 09:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/075723845aa72ae2f19338a7ae3f13c9981fd439', 'message': 'Add translation support to plugin modules\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}, {'number': 17, 'created': '2014-08-12 13:18:42.000000000', 'files': ['sahara/plugins/vanilla/hadoop2/run_scripts.py', 'sahara/plugins/vanilla/hadoop2/scaling.py', 'sahara/plugins/base.py', 'sahara/plugins/hdp/hadoopserver.py', 'sahara/plugins/spark/config_helper.py', 'sahara/plugins/spark/scaling.py', 'sahara/plugins/hdp/configprovider.py', 'sahara/plugins/vanilla/v1_2_1/config_helper.py', 'sahara/plugins/provisioning.py', 'sahara/plugins/fake/plugin.py', 'sahara/plugins/vanilla/hadoop2/validation.py', 'sahara/plugins/general/exceptions.py', 'sahara/plugins/vanilla/hadoop2/config.py', 'sahara/plugins/hdp/versions/version_2_0_6/services.py', 'sahara/plugins/spark/plugin.py', 'sahara/plugins/general/utils.py', 'sahara/plugins/vanilla/v1_2_1/scaling.py', 'sahara/plugins/vanilla/plugin.py', 'sahara/plugins/hdp/versions/version_1_3_2/services.py', 'sahara/plugins/vanilla/v1_2_1/versionhandler.py', 'sahara/plugins/hdp/clusterspec.py', 'sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py', 'sahara/plugins/vanilla/hadoop2/config_helper.py', 'sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py', 'sahara/plugins/hdp/ambariplugin.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sahara/commit/6bc8ce78de796339d12818ed485c6406be08646d', 'message': 'Add translation support to plugin modules\n\nChanged modules:\n* sahara/plugins/base.py\n* sahara/plugins/general/exceptions.py\n* sahara/plugins/general/utils.py\n* sahara/plugins/hdp/ambariplugin.py\n* sahara/plugins/hdp/clusterspec.py\n* sahara/plugins/hdp/configprovider.py\n* sahara/plugins/hdp/hadoopserver.py\n* sahara/plugins/hdp/versions/version_1_3_2/services.py\n* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py\n* sahara/plugins/hdp/versions/version_2_0_6/services.py\n* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py\n* sahara/plugins/provisioning.py\n* sahara/plugins/spark/config_helper.py\n* sahara/plugins/spark/plugin.py\n* sahara/plugins/spark/scaling.py\n* sahara/plugins/vanilla/hadoop2/config.py\n* sahara/plugins/vanilla/hadoop2/config_helper.py\n* sahara/plugins/vanilla/hadoop2/run_scripts.py\n* sahara/plugins/vanilla/hadoop2/scaling.py\n* sahara/plugins/vanilla/hadoop2/validation.py\n* sahara/plugins/vanilla/plugin.py\n* sahara/plugins/vanilla/v1_2_1/config_helper.py\n* sahara/plugins/vanilla/v1_2_1/scaling.py\n* sahara/plugins/vanilla/v1_2_1/versionhandler.py\n\nChange-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e\n'}]",51,107718,6bc8ce78de796339d12818ed485c6406be08646d,115,11,17,12039,,,0,"Add translation support to plugin modules

Changed modules:
* sahara/plugins/base.py
* sahara/plugins/general/exceptions.py
* sahara/plugins/general/utils.py
* sahara/plugins/hdp/ambariplugin.py
* sahara/plugins/hdp/clusterspec.py
* sahara/plugins/hdp/configprovider.py
* sahara/plugins/hdp/hadoopserver.py
* sahara/plugins/hdp/versions/version_1_3_2/services.py
* sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py
* sahara/plugins/hdp/versions/version_2_0_6/services.py
* sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py
* sahara/plugins/provisioning.py
* sahara/plugins/spark/config_helper.py
* sahara/plugins/spark/plugin.py
* sahara/plugins/spark/scaling.py
* sahara/plugins/vanilla/hadoop2/config.py
* sahara/plugins/vanilla/hadoop2/config_helper.py
* sahara/plugins/vanilla/hadoop2/run_scripts.py
* sahara/plugins/vanilla/hadoop2/scaling.py
* sahara/plugins/vanilla/hadoop2/validation.py
* sahara/plugins/vanilla/plugin.py
* sahara/plugins/vanilla/v1_2_1/config_helper.py
* sahara/plugins/vanilla/v1_2_1/scaling.py
* sahara/plugins/vanilla/v1_2_1/versionhandler.py

Change-Id: Ia3dacd7ce5a77e8b51747d9c8e1a17fab266395e
",git fetch https://review.opendev.org/openstack/sahara refs/changes/18/107718/17 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/vanilla/hadoop2/run_scripts.py', 'sahara/plugins/vanilla/hadoop2/scaling.py', 'sahara/plugins/base.py', 'sahara/plugins/hdp/hadoopserver.py', 'sahara/plugins/spark/config_helper.py', 'sahara/plugins/spark/scaling.py', 'sahara/plugins/hdp/configprovider.py', 'sahara/plugins/vanilla/v1_2_1/config_helper.py', 'sahara/plugins/provisioning.py', 'sahara/plugins/vanilla/hadoop2/validation.py', 'sahara/plugins/general/exceptions.py', 'sahara/plugins/vanilla/hadoop2/config.py', 'sahara/plugins/hdp/versions/version_2_0_6/services.py', 'sahara/plugins/spark/plugin.py', 'sahara/plugins/general/utils.py', 'sahara/plugins/vanilla/v1_2_1/scaling.py', 'sahara/plugins/vanilla/plugin.py', 'sahara/plugins/hdp/versions/version_1_3_2/services.py', 'sahara/plugins/vanilla/v1_2_1/versionhandler.py', 'sahara/plugins/hdp/clusterspec.py', 'sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py', 'sahara/plugins/vanilla/hadoop2/config_helper.py', 'sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py', 'sahara/plugins/hdp/ambariplugin.py', 'tox.ini']",25,8cf6a788bd73a40e3a8a1c7192eb44a85ddda034,oslo.i18n,"import_exceptions = sahara.i18n._, sahara.i18n._LI, sahara.i18n._LW, sahara.i18n._LE, sahara.i18n._LC",,390,285
openstack%2Fdiskimage-builder~master~Ia8e0aed62bcf814bf85c86b54ff0837da49ae7dd,openstack/diskimage-builder,master,Ia8e0aed62bcf814bf85c86b54ff0837da49ae7dd,Don't try to install if packages is empty,MERGED,2014-07-15 11:46:05.000000000,2014-08-13 23:36:14.000000000,2014-08-13 23:36:13.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 6928}, {'_account_id': 8532}, {'_account_id': 9369}, {'_account_id': 10375}]","[{'number': 1, 'created': '2014-07-15 11:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/49640faeb6736d2bfe67804856259bb9300f6946', 'message': ""Don't try to install if packages is empty\n\nAfter running through pkg-map we could have no packages to install,\nif so, don't attempt to run a malformed command.\n\nChange-Id: Ia8e0aed62bcf814bf85c86b54ff0837da49ae7dd\n""}, {'number': 2, 'created': '2014-07-15 12:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/22cfe31b91327328363ce405e4483fd1f60548e0', 'message': ""Don't try to install if packages is empty\n\nAfter running through pkg-map we could have no packages to install,\nif so, don't attempt to run a malformed command.\n\nChange-Id: Ia8e0aed62bcf814bf85c86b54ff0837da49ae7dd\n""}, {'number': 3, 'created': '2014-07-16 10:20:52.000000000', 'files': ['elements/dpkg/bin/install-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/94a0947a60cc4f901f47e78f759eaffa63972854', 'message': ""Don't try to install if packages is empty\n\nAfter running through pkg-map we could have no packages to install,\nif so, don't attempt to run a malformed command.\n\nChange-Id: Ia8e0aed62bcf814bf85c86b54ff0837da49ae7dd\n""}]",0,107008,94a0947a60cc4f901f47e78f759eaffa63972854,37,8,3,215,,,0,"Don't try to install if packages is empty

After running through pkg-map we could have no packages to install,
if so, don't attempt to run a malformed command.

Change-Id: Ia8e0aed62bcf814bf85c86b54ff0837da49ae7dd
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/08/107008/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/dpkg/bin/install-packages', 'elements/yum/bin/install-packages']",2,49640faeb6736d2bfe67804856259bb9300f6946,master," if [ -z ""${PKGS}"" ]; then echo 'No packages need to be installed' else yum -y $ACTION $EXTRA_ARGS $PKGS fi", yum -y $ACTION $EXTRA_ARGS $PKGS,10,2
openstack%2Fdevstack~master~I6c2ce646070db0ed248665216071499a9b5567ab,openstack/devstack,master,I6c2ce646070db0ed248665216071499a9b5567ab,Allow to use flat providernet for public network,MERGED,2014-07-23 07:24:35.000000000,2014-08-13 23:17:07.000000000,2014-08-13 23:17:06.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 6854}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-23 07:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2f6ddd7c63158f15723c55089166b54a48b61ed2', 'message': 'Allow to use flat providernet for public network\n\nChange-Id: I6c2ce646070db0ed248665216071499a9b5567ab\n'}, {'number': 2, 'created': '2014-07-25 07:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/bf177ff109c61951842fadb609cfb52ed5c47020', 'message': 'Allow to use flat providernet for public network\n\nThe support of ancillary bridges (aka br-ex) is planned to be\ndropped for ofagent.  This commit prepares the deprecation by\nproviding devstack support for an alternative way to connect\npublic network.\n\nChange-Id: I6c2ce646070db0ed248665216071499a9b5567ab\n'}, {'number': 3, 'created': '2014-08-01 02:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6050fc4109f44ce4f8ff8313827e7cfe77519a7b', 'message': 'Allow to use flat providernet for public network\n\nThe support of ancillary bridges (aka br-ex) is planned to be\ndropped for ofagent.  This commit prepares the deprecation by\nproviding devstack support for an alternative way to connect\npublic network.\n\nChange-Id: I6c2ce646070db0ed248665216071499a9b5567ab\n'}, {'number': 4, 'created': '2014-08-01 02:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/df9551d47604d9ab3479c1de17ae9b7da197ec7a', 'message': 'Allow to use flat providernet for public network\n\nThe support of ancillary bridges (aka br-ex) is planned to be\ndropped for ofagent.  This commit prepares the deprecation by\nproviding devstack support for an alternative way to connect\npublic network.\n\nRelated to blueprint ofagent-port-monitor\nChange-Id: I6c2ce646070db0ed248665216071499a9b5567ab\n'}, {'number': 5, 'created': '2014-08-01 05:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/eddc1c479bf62fc67bfdcbfb63bae9385112d3dc', 'message': 'Allow to use flat providernet for public network\n\nThe support of ancillary bridges (aka br-ex) is planned to be\ndropped for ofagent.  This commit prepares the deprecation by\nproviding devstack support for an alternative way to connect\npublic network.\n\nRelated to blueprint ofagent-port-monitor\nChange-Id: I6c2ce646070db0ed248665216071499a9b5567ab\n'}, {'number': 6, 'created': '2014-08-01 05:27:29.000000000', 'files': ['lib/neutron', 'lib/neutron_plugins/ovs_base'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6a633fd024347aade777ecd6545fa3efde5a959c', 'message': 'Allow to use flat providernet for public network\n\nThe support of ancillary bridges (aka br-ex) is planned to be\ndropped for ofagent.  This commit prepares the deprecation by\nproviding devstack support for an alternative way to connect\npublic network.\n\nRelated to blueprint ofagent-port-monitor\nChange-Id: I6c2ce646070db0ed248665216071499a9b5567ab\n'}]",5,108910,6a633fd024347aade777ecd6545fa3efde5a959c,75,9,6,6854,,,0,"Allow to use flat providernet for public network

The support of ancillary bridges (aka br-ex) is planned to be
dropped for ofagent.  This commit prepares the deprecation by
providing devstack support for an alternative way to connect
public network.

Related to blueprint ofagent-port-monitor
Change-Id: I6c2ce646070db0ed248665216071499a9b5567ab
",git fetch https://review.opendev.org/openstack/devstack refs/changes/10/108910/5 && git format-patch -1 --stdout FETCH_HEAD,"['lib/neutron', 'lib/neutron_plugins/ovs_base']",2,2f6ddd7c63158f15723c55089166b54a48b61ed2,providernet," if [ ""$Q_USE_PROVIDERNET_FOR_PUBLIC"" = ""True"" ]; then iniset $Q_L3_CONF_FILE DEFAULT external_network_bridge """" else iniset $Q_L3_CONF_FILE DEFAULT external_network_bridge $PUBLIC_BRIDGE fi", iniset $Q_L3_CONF_FILE DEFAULT external_network_bridge $PUBLIC_BRIDGE,18,2
openstack%2Fglance~master~I23b3926a7671e0669315836da787ec88a812d67b,openstack/glance,master,I23b3926a7671e0669315836da787ec88a812d67b,Use @mock.patch.object instead of mock.MagicMock,MERGED,2014-07-31 15:45:43.000000000,2014-08-13 23:16:30.000000000,2014-08-13 23:16:29.000000000,"[{'_account_id': 3}, {'_account_id': 6549}, {'_account_id': 7763}, {'_account_id': 8127}, {'_account_id': 8759}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-07-31 15:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c4c7358377c21f6cdf7fd5ce5bb491f4dde04a2f', 'message': 'Use @mock.patch.object instead of mock.MagicMock\n\nSome unittests replace methods by mock objects, so they are leave mocked\nwhen unittest finished. It can cause a lot of issues, because when we\ntry to get access to these attributes in the next test, we get mock\nobject instead of real attribute. Use @mock.patch.object decorator to\nget attributes `unmocked` after test.\n\nChange-Id: I23b3926a7671e0669315836da787ec88a812d67b\n'}, {'number': 2, 'created': '2014-08-13 14:53:59.000000000', 'files': ['glance/tests/unit/test_manage.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/d8c657ab1c42e1ae8f55028bfab1e1826d6e9cbd', 'message': 'Use @mock.patch.object instead of mock.MagicMock\n\nSome unittests replace methods by mock objects, so they are leave mocked\nwhen unittest finished. It can cause a lot of issues, because when we\ntry to get access to these attributes in the next test, we get mock\nobject instead of real attribute. Use @mock.patch.object decorator to\nget attributes `unmocked` after test.\n\nChange-Id: I23b3926a7671e0669315836da787ec88a812d67b\n'}]",0,110999,d8c657ab1c42e1ae8f55028bfab1e1826d6e9cbd,16,6,2,7491,,,0,"Use @mock.patch.object instead of mock.MagicMock

Some unittests replace methods by mock objects, so they are leave mocked
when unittest finished. It can cause a lot of issues, because when we
try to get access to these attributes in the next test, we get mock
object instead of real attribute. Use @mock.patch.object decorator to
get attributes `unmocked` after test.

Change-Id: I23b3926a7671e0669315836da787ec88a812d67b
",git fetch https://review.opendev.org/openstack/glance refs/changes/99/110999/2 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/test_manage.py'],1,c4c7358377c21f6cdf7fd5ce5bb491f4dde04a2f,add_new_migration," @mock.patch.object(migration, 'db_version') def test_legacy_db_version(self, db_version): @mock.patch.object(migration, 'db_sync') def test_legacy_db_sync(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_legacy_db_upgrade(self, db_sync): @mock.patch.object(migration, 'db_version_control') def test_legacy_db_version_control(self, db_version_control): @mock.patch.object(migration, 'db_sync') def test_legacy_db_sync_version(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_legacy_db_upgrade_version(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_legacy_db_downgrade_version(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_legacy_db_sync_version_without_sanity_check(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_legacy_db_upgrade_version_without_sanity_check(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_legacy_db_downgrade_version_without_sanity_check(self, db_sync): @mock.patch.object(migration, 'db_version') def test_db_version(self, db_version): @mock.patch.object(migration, 'db_sync') def test_db_sync(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_db_upgrade(self, db_sync): @mock.patch.object(migration, 'db_version_control') def test_db_version_control(self, db_version_control): @mock.patch.object(migration, 'db_sync') def test_db_sync_version(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_db_upgrade_version(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_db_downgrade_version(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_db_sync_version_without_sanity_check(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_db_upgrade_version_without_sanity_check(self, db_sync): @mock.patch.object(migration, 'db_sync') def test_db_downgrade_version_without_sanity_check(self, db_sync):", def test_legacy_db_version(self): migration.db_version = mock.Mock() def test_legacy_db_sync(self): migration.db_sync = mock.Mock() def test_legacy_db_upgrade(self): migration.db_sync = mock.Mock() def test_legacy_db_version_control(self): migration.db_version_control = mock.Mock() def test_legacy_db_sync_version(self): migration.db_sync = mock.Mock() def test_legacy_db_upgrade_version(self): migration.db_sync = mock.Mock() def test_legacy_db_downgrade_version(self): migration.db_sync = mock.Mock() def test_legacy_db_sync_version_without_sanity_check(self): migration.db_sync = mock.Mock() def test_legacy_db_upgrade_version_without_sanity_check(self): migration.db_sync = mock.Mock() def test_legacy_db_downgrade_version_without_sanity_check(self): migration.db_sync = mock.Mock() def test_db_version(self): migration.db_version = mock.Mock() def test_db_sync(self): migration.db_sync = mock.Mock() def test_db_upgrade(self): migration.db_sync = mock.Mock() def test_db_version_control(self): migration.db_version_control = mock.Mock() def test_db_sync_version(self): migration.db_sync = mock.Mock() def test_db_upgrade_version(self): migration.db_sync = mock.Mock() def test_db_downgrade_version(self): migration.db_sync = mock.Mock() def test_db_sync_version_without_sanity_check(self): migration.db_sync = mock.Mock() def test_db_upgrade_version_without_sanity_check(self): migration.db_sync = mock.Mock() def test_db_downgrade_version_without_sanity_check(self): migration.db_sync = mock.Mock(),40,40
openstack%2Fneutron~master~I71dc194a5ced63b8549f8bffb82d22774d3da74b,openstack/neutron,master,I71dc194a5ced63b8549f8bffb82d22774d3da74b,Imported Translations from Transifex,MERGED,2014-08-08 06:04:17.000000000,2014-08-13 23:16:21.000000000,2014-08-13 23:16:20.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-08-08 06:04:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bfca2f4c2ba9054047dc83a2ed3590191787b332', 'message': 'Imported Translations from Transifex\n\nChange-Id: I71dc194a5ced63b8549f8bffb82d22774d3da74b\n'}, {'number': 2, 'created': '2014-08-09 06:04:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d91456ced7add45927064b9dfd3f844fc82ed88d', 'message': 'Imported Translations from Transifex\n\nChange-Id: I71dc194a5ced63b8549f8bffb82d22774d3da74b\n'}, {'number': 3, 'created': '2014-08-10 06:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48fa1eae038a6980662268e4c64c7db119683682', 'message': 'Imported Translations from Transifex\n\nChange-Id: I71dc194a5ced63b8549f8bffb82d22774d3da74b\n'}, {'number': 4, 'created': '2014-08-11 06:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1491a8f748faa0f452386f37b5bfce70b2f2220c', 'message': 'Imported Translations from Transifex\n\nChange-Id: I71dc194a5ced63b8549f8bffb82d22774d3da74b\n'}, {'number': 5, 'created': '2014-08-12 06:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78afe94e499343656eaafb7c492bbdd100a2e141', 'message': 'Imported Translations from Transifex\n\nChange-Id: I71dc194a5ced63b8549f8bffb82d22774d3da74b\n'}, {'number': 6, 'created': '2014-08-13 06:05:51.000000000', 'files': ['neutron/locale/neutron-log-error.pot', 'neutron/locale/de/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/te_IN/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/fr/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/te_IN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/en_AU/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/ja/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/en_AU/LC_MESSAGES/neutron-log-info.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a381d1b14d38b2c481963f2514bfb005c404b970', 'message': 'Imported Translations from Transifex\n\nChange-Id: I71dc194a5ced63b8549f8bffb82d22774d3da74b\n'}]",0,112761,a381d1b14d38b2c481963f2514bfb005c404b970,109,19,6,11131,,,0,"Imported Translations from Transifex

Change-Id: I71dc194a5ced63b8549f8bffb82d22774d3da74b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/112761/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/neutron-log-error.pot', 'neutron/locale/de/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/te_IN/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/fr/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/te_IN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/en_AU/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/ja/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-error.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/en_AU/LC_MESSAGES/neutron-log-info.po']",28,bfca2f4c2ba9054047dc83a2ed3590191787b332,transifex/translations,"""POT-Creation-Date: 2014-08-08 06:03+0000\n""#: neutron/openstack/common/periodic_task.py:126#: neutron/openstack/common/periodic_task.py:131 #: neutron/tests/unit/vmware/apiclient/test_api_eventlet_request.py:63 #, python-format msgid ""spawned: %d"" msgstr """" #: neutron/tests/unit/vmware/apiclient/test_api_eventlet_request.py:75 #, python-format msgid ""_handle_request called: %s"" msgstr """"","""POT-Creation-Date: 2014-07-21 06:06+0000\n""#: neutron/openstack/common/periodic_task.py:125#: neutron/openstack/common/periodic_task.py:130",587,377
openstack%2Fneutron~master~Iefbefa1ff300adad48ab9fc472d5eb1913fbe488,openstack/neutron,master,Iefbefa1ff300adad48ab9fc472d5eb1913fbe488,Fix 404 error fetching metadata when using DVR,MERGED,2014-08-06 18:34:15.000000000,2014-08-13 23:16:12.000000000,2014-08-13 23:16:11.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10692}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-06 18:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f34625698383641846130337dfad278bafb60a64', 'message': ""Fix 404 error fetching metadata when using DVR\n\nThe metadata agent was unable to find networks\nattached to the DVR router because it was only\nfiltering ports for 'centralized' routers.\n\nTo fix the issue, this patch expands the search\nfilters to include DVR router interfaces during\nthe network lookup operation.\n\nThe extra filter cause no evident performance\nloss while serving the request; a different\napproach would require to pass the router type\naround to narrow down the search filter, but it\nsounds like an overkill.\n\nCloses-bug: #1353271\n\nChange-Id: Iefbefa1ff300adad48ab9fc472d5eb1913fbe488\n""}, {'number': 2, 'created': '2014-08-12 19:26:40.000000000', 'files': ['neutron/agent/metadata/agent.py', 'neutron/tests/unit/test_metadata_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/338171c114743c0e03def04ef551231f0d9c93f8', 'message': ""Fix 404 error fetching metadata when using DVR\n\nThe metadata agent was unable to find networks\nattached to the DVR router because it was only\nfiltering ports for 'centralized' routers.\n\nTo fix the issue, this patch expands the search\nfilters to include DVR router interfaces during\nthe network lookup operation.\n\nThe extra filter cause no evident performance\nloss while serving the request; a different\napproach would require to pass the router type\naround to narrow down the search filter, but it\nsounds like an overkill.\n\nCloses-bug: #1353271\n\nChange-Id: Iefbefa1ff300adad48ab9fc472d5eb1913fbe488\n""}]",2,112376,338171c114743c0e03def04ef551231f0d9c93f8,44,22,2,748,,,0,"Fix 404 error fetching metadata when using DVR

The metadata agent was unable to find networks
attached to the DVR router because it was only
filtering ports for 'centralized' routers.

To fix the issue, this patch expands the search
filters to include DVR router interfaces during
the network lookup operation.

The extra filter cause no evident performance
loss while serving the request; a different
approach would require to pass the router type
around to narrow down the search filter, but it
sounds like an overkill.

Closes-bug: #1353271

Change-Id: Iefbefa1ff300adad48ab9fc472d5eb1913fbe488
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/112376/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/metadata/agent.py', 'neutron/tests/unit/test_metadata_agent.py']",2,f34625698383641846130337dfad278bafb60a64,bug/1353271,"def _get_router_device_owners(): return [ constants.DEVICE_OWNER_ROUTER_INTF, constants.DEVICE_OWNER_DVR_INTERFACE ] device_owner=_get_router_device_owners()) device_owner=_get_router_device_owners()) device_owner=_get_router_device_owners()", device_owner=constants.DEVICE_OWNER_ROUTER_INTF) device_owner=constants.DEVICE_OWNER_ROUTER_INTF) device_owner=constants.DEVICE_OWNER_ROUTER_INTF,12,4
openstack%2Fdevstack~master~I480167dcc008506ec2fe8c412db4114b74496e60,openstack/devstack,master,I480167dcc008506ec2fe8c412db4114b74496e60,Cleanup lib/ironic,MERGED,2014-08-06 01:28:36.000000000,2014-08-13 23:16:08.000000000,2014-08-13 23:16:08.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-06 01:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4d4b677de0108891db40c89b04705b7d3786979a', 'message': 'Cleanup lib/ironic\n\nThis moves around a bunch of functionality and attempts to isolate setup\nsteps into discrete functions (new or existing), making them easier to\nconsume from outside of Devstack (ie, Grenade).\n\nChange-Id: I480167dcc008506ec2fe8c412db4114b74496e60\n'}, {'number': 2, 'created': '2014-08-06 06:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4be52a9432dba6c935586cb1449894591c44eff4', 'message': 'Cleanup lib/ironic\n\nThis moves around a bunch of functionality and attempts to isolate setup\nsteps into discrete functions (new or existing), making them easier to\nconsume from outside of Devstack (ie, Grenade).\n\nChange-Id: I480167dcc008506ec2fe8c412db4114b74496e60\n'}, {'number': 3, 'created': '2014-08-06 19:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ba99b614776c6e06f2551c260259c44ef013c65e', 'message': 'Cleanup lib/ironic\n\nThis moves around a bunch of functionality and attempts to isolate setup\nsteps into discrete functions (new or existing), making them easier to\nconsume from outside of Devstack (ie, Grenade).\n\nChange-Id: I480167dcc008506ec2fe8c412db4114b74496e60\n'}, {'number': 4, 'created': '2014-08-06 23:48:35.000000000', 'files': ['lib/ironic', 'lib/nova_plugins/hypervisor-ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6d27148eb6b72ba829f0c9ecf0dd6cf280063787', 'message': 'Cleanup lib/ironic\n\nThis moves around a bunch of functionality and attempts to isolate setup\nsteps into discrete functions (new or existing), making them easier to\nconsume from outside of Devstack (ie, Grenade).\n\nChange-Id: I480167dcc008506ec2fe8c412db4114b74496e60\n'}]",0,112177,6d27148eb6b72ba829f0c9ecf0dd6cf280063787,37,6,4,1420,,,0,"Cleanup lib/ironic

This moves around a bunch of functionality and attempts to isolate setup
steps into discrete functions (new or existing), making them easier to
consume from outside of Devstack (ie, Grenade).

Change-Id: I480167dcc008506ec2fe8c412db4114b74496e60
",git fetch https://review.opendev.org/openstack/devstack refs/changes/77/112177/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ironic', 'extras.d/50-ironic.sh']",2,4d4b677de0108891db40c89b04705b7d3786979a,ironic_grenade," # make sure all needed service were enabled for srv in nova glance key neutron; do if ! is_service_enabled ""$srv""; then die $LINENO ""$srv should be enabled for Ironic."" fi done",,45,63
openstack%2Fheat~master~I63d578a9291d0fe08815d6a33323324432ae21cb,openstack/heat,master,I63d578a9291d0fe08815d6a33323324432ae21cb,Use Constraint stubs in common.py,MERGED,2014-07-31 01:37:03.000000000,2014-08-13 23:16:05.000000000,2014-08-13 23:16:04.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 7193}, {'_account_id': 7404}, {'_account_id': 8435}, {'_account_id': 9165}, {'_account_id': 11599}]","[{'number': 1, 'created': '2014-07-31 01:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/35720ae8dd4ece04b137391d53190b1f1b678e51', 'message': 'Use Constraint stubs in common.py\n\nDefine the stub_KeypairConstraint_validate() and\nstub_ImageConstraint_validate() funtions in tests/common.py,\nand migrate to use them.\n\nChange-Id: I63d578a9291d0fe08815d6a33323324432ae21cb\n'}, {'number': 2, 'created': '2014-07-31 01:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8c49b15d2e26f7daf1a0a0d83faf9d007103c8fd', 'message': 'Use Constraint stubs in common.py\n\nAfter defining the stub_KeypairConstraint_validate() and\nstub_ImageConstraint_validate() funtions in tests/common.py,\nthen migrate to use them.\n\nChange-Id: I63d578a9291d0fe08815d6a33323324432ae21cb\n'}, {'number': 3, 'created': '2014-08-05 02:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/74553c4321a03232a532bbc2e1cd24c911fcfcdd', 'message': 'Use Constraint stubs in common.py\n\nDefine the stub_KeypairConstraint_validate() and\nstub_ImageConstraint_validate() funtions in tests/common.py,\nand migrate to use them.\n\nChange-Id: I63d578a9291d0fe08815d6a33323324432ae21cb\n'}, {'number': 4, 'created': '2014-08-05 03:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/888091569425f174cc60515003769347ec9519c0', 'message': 'Use Constraint stubs in common.py\n\nDefine the stub_KeypairConstraint_validate() and\nstub_ImageConstraint_validate() funtions in tests/common.py,\nand migrate to use them.\n\nChange-Id: I63d578a9291d0fe08815d6a33323324432ae21cb\n'}, {'number': 5, 'created': '2014-08-06 04:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/58eb202ee71d1d423961c624b23a0b3ee842a724', 'message': 'Use Constraint stubs in common.py\n\nDefine the stub_KeypairConstraint_validate() and\nstub_ImageConstraint_validate() funtions in tests/common.py,\nand migrate to use them.\n\nChange-Id: I63d578a9291d0fe08815d6a33323324432ae21cb\n'}, {'number': 6, 'created': '2014-08-06 06:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f6cf2334e53f29e16ea069e589ca827ce1bc4558', 'message': 'Use Constraint stubs in common.py\n\nDefine the stub_KeypairConstraint_validate() and\nstub_ImageConstraint_validate() funtions in tests/common.py,\nand migrate to use them.\n\nChange-Id: I63d578a9291d0fe08815d6a33323324432ae21cb\n'}, {'number': 7, 'created': '2014-08-11 07:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9f558fc204b016853dacf8fac0cd6dfc73ea42ec', 'message': 'Use Constraint stubs in common.py\n\nMigrate to use functions: stub_KeypairConstraint_validate() and\nstub_ImageConstraint_validate() in tests/common.py which defined \nin patch I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093.\n\nChange-Id: I63d578a9291d0fe08815d6a33323324432ae21cb\n'}, {'number': 8, 'created': '2014-08-11 09:58:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2fec6411224e046add43026042ec9149e3d2ccb8', 'message': 'Use Constraint stubs in common.py\n\nMigrate to use functions: stub_KeypairConstraint_validate() and\nstub_ImageConstraint_validate() in tests/common.py which defined \nin patch I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093.\n\nChange-Id: I63d578a9291d0fe08815d6a33323324432ae21cb\n'}, {'number': 9, 'created': '2014-08-13 16:03:22.000000000', 'files': ['heat/tests/test_metadata_refresh.py', 'heat/tests/test_instance.py', 'heat/tests/test_neutron_autoscaling.py', 'heat/tests/test_volume.py', 'heat/tests/test_server.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/33b1cefe66e4a936c5cfa90bbba5dd8daa73e618', 'message': 'Use Constraint stubs in common.py\n\nMigrate to use functions: stub_KeypairConstraint_validate() and\nstub_ImageConstraint_validate() in tests/common.py which defined \nin patch I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093.\n\nChange-Id: I63d578a9291d0fe08815d6a33323324432ae21cb\n'}]",0,110830,33b1cefe66e4a936c5cfa90bbba5dd8daa73e618,34,7,9,8289,,,0,"Use Constraint stubs in common.py

Migrate to use functions: stub_KeypairConstraint_validate() and
stub_ImageConstraint_validate() in tests/common.py which defined 
in patch I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093.

Change-Id: I63d578a9291d0fe08815d6a33323324432ae21cb
",git fetch https://review.opendev.org/openstack/heat refs/changes/30/110830/8 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_metadata_refresh.py', 'heat/tests/test_instance.py', 'heat/tests/test_neutron_autoscaling.py', 'heat/tests/test_server.py', 'heat/tests/test_volume.py']",5,35720ae8dd4ece04b137391d53190b1f1b678e51,use_constraint_stub_in_common, self.stub_ImageConstraint_validate()," self.m.StubOutWithMock(glance.ImageConstraint, ""validate"") glance.ImageConstraint.validate( mox.IgnoreArg(), mox.IgnoreArg()).MultipleTimes().AndReturn(True)",19,40
openstack%2Fheat~master~I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093,openstack/heat,master,I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093,Add constraints to check whether image/keypair exists,MERGED,2014-04-25 07:45:49.000000000,2014-08-13 23:15:56.000000000,2014-08-13 23:15:55.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 6698}, {'_account_id': 6899}, {'_account_id': 7193}, {'_account_id': 7233}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8290}, {'_account_id': 8435}, {'_account_id': 8871}, {'_account_id': 9165}, {'_account_id': 11599}]","[{'number': 1, 'created': '2014-04-25 07:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0cb039030d45eba5984d49d73ba9dd61c1fd08cb', 'message': 'Add constraints to check whether image/keypair exists\n\nAdd constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image\nexists on ""AWS::AutoScaling::LaunchConfiguration"" resource.\n\nChange-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093\nCloses-Bug: #1312564\n'}, {'number': 2, 'created': '2014-04-26 06:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a393c4ecdce14a18fb599d234056f5ced207c13c', 'message': 'Add constraints to check whether image/keypair exists\n\nAdd constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image\nexists on ""AWS::AutoScaling::LaunchConfiguration"" resource.\n\nChange-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093\nCloses-Bug: #1312564\n'}, {'number': 3, 'created': '2014-05-28 08:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5aa8a6d2ebb34003fbc9e6eeedfd8204ea87141a', 'message': 'Add constraints to check whether image/keypair exists\n\nAdd constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image\nexists on ""AWS::AutoScaling::LaunchConfiguration"" resource.\n\nChange-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093\nCloses-Bug: #1312564\n'}, {'number': 4, 'created': '2014-05-31 07:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eb878e87a506e2e630a91f69a1dd2554d5c9e669', 'message': 'Add constraints to check whether image/keypair exists\n\nAdd constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image\nexists on ""AWS::AutoScaling::LaunchConfiguration"" resource.\n\nChange-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093\nCloses-Bug: #1312564\n'}, {'number': 5, 'created': '2014-07-30 10:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a609baf5ad07bf6254ca14b27cf5a924d2c41987', 'message': 'Add constraints to check whether image/keypair exists\n\nAdd constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image\nexists on ""AWS::AutoScaling::LaunchConfiguration"" resource.\n\nChange-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093\nCloses-Bug: #1312564\n'}, {'number': 6, 'created': '2014-08-05 01:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9d6dbfb5296ca59af43816198161512207b67f25', 'message': 'Add constraints to check whether image/keypair exists\n\nAdd constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image\nexists on ""AWS::AutoScaling::LaunchConfiguration"" resource.\n\nChange-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093\nCloses-Bug: #1312564\n'}, {'number': 7, 'created': '2014-08-05 03:18:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/81b832ac87d37da3412a63345a6250e0598e4615', 'message': 'Add constraints to check whether image/keypair exists\n\nAdd constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image\nexists on ""AWS::AutoScaling::LaunchConfiguration"" resource.\n\nChange-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093\nCloses-Bug: #1312564\n'}, {'number': 8, 'created': '2014-08-06 06:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3103a93a561012ea162f037f8883ece4f3a5218b', 'message': 'Add constraints to check whether image/keypair exists\n\nAdd constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image\nexists on ""AWS::AutoScaling::LaunchConfiguration"" resource.\n\nChange-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093\nCloses-Bug: #1312564\n'}, {'number': 9, 'created': '2014-08-11 09:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/87014b2c50c53a9bc65aae5005b57dd2318b05a8', 'message': 'Add constraints to check whether image/keypair exists\n\nAdd constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image\nexists on ""AWS::AutoScaling::LaunchConfiguration"" resource.\n\nChange-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093\nCloses-Bug: #1312564\n'}, {'number': 10, 'created': '2014-08-13 16:03:05.000000000', 'files': ['heat/engine/resources/autoscaling.py', 'heat/tests/common.py', 'heat/tests/test_autoscaling_update_policy.py', 'heat/tests/test_autoscaling.py', 'heat/tests/test_server_tags.py', 'heat/tests/test_instance_group.py', 'heat/tests/test_instance_group_update_policy.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7262d3a2c79c38391a93617cfbe69341d2221324', 'message': 'Add constraints to check whether image/keypair exists\n\nAdd constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image\nexists on ""AWS::AutoScaling::LaunchConfiguration"" resource.\n\nChange-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093\nCloses-Bug: #1312564\n'}]",18,90304,7262d3a2c79c38391a93617cfbe69341d2221324,84,13,10,8289,,,0,"Add constraints to check whether image/keypair exists

Add constraints for ""KeyName"" and ""ImageId"" to check whether keypair/image
exists on ""AWS::AutoScaling::LaunchConfiguration"" resource.

Change-Id: I23dc126e621f3cfa7ca86b3a1c27dd949d3f5093
Closes-Bug: #1312564
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/90304/9 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/autoscaling.py'],1,0cb039030d45eba5984d49d73ba9dd61c1fd08cb,bug/1312564," constraints=[ constraints.CustomConstraint('glance.image') ], _('Optional Nova keypair name.'), constraints=[ constraints.CustomConstraint('nova.keypair') ]", _('Optional Nova keypair name.'),7,1
openstack%2Fkeystone~master~Ie0f910cf3c647410e3a9b773fc4043622163b9e4,openstack/keystone,master,Ie0f910cf3c647410e3a9b773fc4043622163b9e4,Remove unnecessary declaration of CONF,MERGED,2014-08-13 15:23:05.000000000,2014-08-13 23:15:48.000000000,2014-08-13 23:15:46.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-08-13 15:23:05.000000000', 'files': ['keystone/contrib/access/core.py', 'keystone/tests/test_policy.py', 'keystone/tests/test_sql_livetest.py', 'keystone/common/environment/__init__.py', 'keystone/tests/test_keystoneclient_sql.py', 'keystone/contrib/s3/core.py', 'keystone/controllers.py', 'keystone/contrib/revoke/backends/sql.py', 'keystone/tests/test_exception.py', 'keystone/tests/test_revoke.py', 'keystone/contrib/ec2/core.py', 'keystone/contrib/federation/controllers.py', 'keystone/trust/controllers.py', 'keystone/contrib/example/core.py', 'keystone/tests/test_backend_federation_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0ce41999750ff3ab49e4d8876049028f31a6153a', 'message': 'Remove unnecessary declaration of CONF\n\nVarious files had unnecessary references to the keystone config\nfile. Remove those lines and the import statement.\n\nChange-Id: Ie0f910cf3c647410e3a9b773fc4043622163b9e4\n'}]",0,113930,0ce41999750ff3ab49e4d8876049028f31a6153a,14,7,1,6482,,,0,"Remove unnecessary declaration of CONF

Various files had unnecessary references to the keystone config
file. Remove those lines and the import statement.

Change-Id: Ie0f910cf3c647410e3a9b773fc4043622163b9e4
",git fetch https://review.opendev.org/openstack/keystone refs/changes/30/113930/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/contrib/access/core.py', 'keystone/tests/test_policy.py', 'keystone/tests/test_sql_livetest.py', 'keystone/common/environment/__init__.py', 'keystone/tests/test_keystoneclient_sql.py', 'keystone/contrib/s3/core.py', 'keystone/controllers.py', 'keystone/contrib/revoke/backends/sql.py', 'keystone/tests/test_exception.py', 'keystone/tests/test_revoke.py', 'keystone/contrib/ec2/core.py', 'keystone/contrib/federation/controllers.py', 'keystone/trust/controllers.py', 'keystone/contrib/example/core.py', 'keystone/tests/test_backend_federation_sql.py']",15,0ce41999750ff3ab49e4d8876049028f31a6153a,remove_useless_conf,,from keystone import configCONF = config.CONF ,0,47
openstack%2Frequirements~master~I43c65e68780c3f302485a1540e53afd14fd0d72a,openstack/requirements,master,I43c65e68780c3f302485a1540e53afd14fd0d72a,Rename bash8 to bashate (part 1),MERGED,2014-08-09 07:27:00.000000000,2014-08-13 23:15:24.000000000,2014-08-13 23:15:24.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-08-09 07:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/abcf88ce168654d4a46afe77307ffc4e6072e8b1', 'message': 'Add bashate\n\nbashate is now required by devstack-gate, add it here.\n\ndevstack-gate commit:\nhttps://review.openstack.org/#/c/101267/\n\nChange-Id: I43c65e68780c3f302485a1540e53afd14fd0d72a\n'}, {'number': 2, 'created': '2014-08-13 09:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/290218380532e6e917203d29c0ff86ed0b9b8067', 'message': 'Rename bash8 to bashate\n\nThe package has been renamed.\n\nAlso, use version >= 0.2 as required by devstack-gate\n\ndevstack-gate commit:\nhttps://review.openstack.org/#/c/101267/\n\nChange-Id: I43c65e68780c3f302485a1540e53afd14fd0d72a\n'}, {'number': 3, 'created': '2014-08-13 10:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/f99a969b4ea18b274770fa4b87dbb7abfa76f1be', 'message': 'Rename bash8 to bashate (part 1)\n\nThe package has been renamed. We need to add the new\npackage name to requirements, update all users, and then\nremove bash8.\n\nFor bashate use version >= 0.2 as required by devstack-gate\n\ndevstack-gate commit:\nhttps://review.openstack.org/#/c/101267/\n\nChange-Id: I43c65e68780c3f302485a1540e53afd14fd0d72a\n'}, {'number': 4, 'created': '2014-08-13 12:33:35.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f67f9695025fbb52ad7dca37d7ea6640daec790a', 'message': 'Rename bash8 to bashate (part 1)\n\nThe package has been renamed. We need to add the new\npackage name to requirements, update all users, and then\nremove bash8.\n\nFor bashate use version >= 0.2 as required by devstack-gate.\n\nLicence of bashate is Apache 2.0, add it as well.\n\ndevstack-gate commit:\nhttps://review.openstack.org/#/c/101267/\n\nChange-Id: I43c65e68780c3f302485a1540e53afd14fd0d72a\n'}]",2,113080,f67f9695025fbb52ad7dca37d7ea6640daec790a,40,8,4,6547,,,0,"Rename bash8 to bashate (part 1)

The package has been renamed. We need to add the new
package name to requirements, update all users, and then
remove bash8.

For bashate use version >= 0.2 as required by devstack-gate.

Licence of bashate is Apache 2.0, add it as well.

devstack-gate commit:
https://review.openstack.org/#/c/101267/

Change-Id: I43c65e68780c3f302485a1540e53afd14fd0d72a
",git fetch https://review.opendev.org/openstack/requirements refs/changes/80/113080/4 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,abcf88ce168654d4a46afe77307ffc4e6072e8b1,bashate,bashate>=0.2,,1,0
openstack%2Ftraining-guides~master~I10cb822d3b714c57d0876d7f3cc24961e6950588,openstack/training-guides,master,I10cb822d3b714c57d0876d7f3cc24961e6950588,labs: fix nova endpoints,MERGED,2014-08-13 17:30:05.000000000,2014-08-13 23:08:55.000000000,2014-08-13 23:08:55.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 9178}]","[{'number': 1, 'created': '2014-08-13 17:30:05.000000000', 'files': ['labs/scripts/setup_nova_controller.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/9317570325e71741aa57a7a226283196ec922074', 'message': 'labs: fix nova endpoints\n\nTurns out those rather peculiar ""%(tenant_id)s"" strings are necessary\nto make nova endpoints work.\n\nThis patch adds them.\n\nChange-Id: I10cb822d3b714c57d0876d7f3cc24961e6950588\n'}]",0,113976,9317570325e71741aa57a7a226283196ec922074,8,3,1,11109,,,0,"labs: fix nova endpoints

Turns out those rather peculiar ""%(tenant_id)s"" strings are necessary
to make nova endpoints work.

This patch adds them.

Change-Id: I10cb822d3b714c57d0876d7f3cc24961e6950588
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/76/113976/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/scripts/setup_nova_controller.sh'],1,9317570325e71741aa57a7a226283196ec922074,fix_nova_endpoints, --publicurl 'http://controller-api:8774/v2/%(tenant_id)s' \ --adminurl 'http://controller-mgmt:8774/v2/%(tenant_id)s' \ --internalurl 'http://controller-mgmt:8774/v2/%(tenant_id)s'," --publicurl ""http://controller-api:8774"" \ --adminurl ""http://controller-mgmt:8774"" \ --internalurl ""http://controller-mgmt:8774"" ",3,4
openstack%2Fironic~master~Ib99c48c2f80abaf42b08f36af942535d7c9ac5d1,openstack/ironic,master,Ib99c48c2f80abaf42b08f36af942535d7c9ac5d1,Allow Ironic URL from config file,MERGED,2014-07-08 20:56:14.000000000,2014-08-13 23:07:19.000000000,2014-08-13 23:07:19.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 8125}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-07-08 20:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d5705c54d6693efc3a701aa262966dd98835888d', 'message': ""Allow Ironic URL from config file\n\nCurrently when using username/password auth from configs with\nironic client, it's not possible to specify the ironic URL in\na config file. This commit makes that possible.\n\nChange-Id: Ib99c48c2f80abaf42b08f36af942535d7c9ac5d1\n""}, {'number': 2, 'created': '2014-07-09 14:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8a741c1268b24194025c8f627f2ac3dadbaaef64', 'message': ""Allow Ironic URL from config file\n\nCurrently when using username/password auth from configs with\nironic client, it's not possible to specify the ironic URL in\na config file. This commit makes that possible.\n\nChange-Id: Ib99c48c2f80abaf42b08f36af942535d7c9ac5d1\n""}, {'number': 3, 'created': '2014-07-11 13:56:35.000000000', 'files': ['ironic/nova/virt/ironic/client_wrapper.py', 'ironic/nova/tests/virt/ironic/test_client_wrapper.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/aa108b5430c5b796d49f0f28686df3f55fea2dde', 'message': ""Allow Ironic URL from config file\n\nCurrently when using username/password auth from configs with\nironic client, it's not possible to specify the ironic URL in\na config file. This commit makes that possible.\n\nChange-Id: Ib99c48c2f80abaf42b08f36af942535d7c9ac5d1\n""}]",0,105590,aa108b5430c5b796d49f0f28686df3f55fea2dde,44,7,3,10343,,,0,"Allow Ironic URL from config file

Currently when using username/password auth from configs with
ironic client, it's not possible to specify the ironic URL in
a config file. This commit makes that possible.

Change-Id: Ib99c48c2f80abaf42b08f36af942535d7c9ac5d1
",git fetch https://review.opendev.org/openstack/ironic refs/changes/90/105590/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic/nova/virt/ironic/client_wrapper.py'],1,d5705c54d6693efc3a701aa262966dd98835888d,fix-auth," 'os_endpoint_type': 'public', 'ironic_url': CONF.ironic.api_endpoint}", 'os_endpoint_type': 'public'},2,1
openstack%2Foslo.serialization~master~I9dd879914c7cb226c71e856914536318b416e488,openstack/oslo.serialization,master,I9dd879914c7cb226c71e856914536318b416e488,Specify namedtuple_as_object=False when using simplejson,MERGED,2014-08-13 17:19:46.000000000,2014-08-13 22:48:56.000000000,2014-08-13 22:48:55.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6854}, {'_account_id': 6928}, {'_account_id': 7448}]","[{'number': 1, 'created': '2014-08-13 17:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/fac32e865a072de47fc6de90705d97229a23d08d', 'message': 'Specify namedtuple_as_object=False when using simplejson\n\nThis makes namedtuple serialization consistent with non simplejson case.\n\nCloses-Bug: #1356173\nChange-Id: I9dd879914c7cb226c71e856914536318b416e488\n'}, {'number': 2, 'created': '2014-08-13 17:51:21.000000000', 'files': ['tests/test_jsonutils.py', 'oslo/serialization/jsonutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/c5b869462f9b1d1a56dd98cd66c7b5f4238334ae', 'message': 'Specify namedtuple_as_object=False when using simplejson\n\nThis makes namedtuple serialization consistent with non simplejson case.\n\nCloses-Bug: #1356173\nChange-Id: I9dd879914c7cb226c71e856914536318b416e488\n'}]",16,113973,c5b869462f9b1d1a56dd98cd66c7b5f4238334ae,20,6,2,6854,,,0,"Specify namedtuple_as_object=False when using simplejson

This makes namedtuple serialization consistent with non simplejson case.

Closes-Bug: #1356173
Change-Id: I9dd879914c7cb226c71e856914536318b416e488
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/73/113973/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_jsonutils.py', 'oslo/serialization/jsonutils.py']",2,fac32e865a072de47fc6de90705d97229a23d08d,bug/1356173,"is_simplejson = False is_simplejson = True if is_simplejson: return json.dumps(value, default=default, namedtuple_as_object=False, **kwargs) if is_simplejson: return json.dump(obj, fp, *args, namedtuple_as_object=False, **kwargs)",,24,2
openstack%2Fheat~master~I61fbe9556d9988fffd4afddf3fad5d2fa211475a,openstack/heat,master,I61fbe9556d9988fffd4afddf3fad5d2fa211475a,Remove function get_software_config,MERGED,2014-06-20 03:05:38.000000000,2014-08-13 22:47:15.000000000,2014-08-13 22:47:14.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 7761}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 12437}]","[{'number': 1, 'created': '2014-06-20 03:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/50ace49a1ab4db505287bd52f756d7534ac4778f', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 2, 'created': '2014-06-23 00:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cac499c374a3792b2b87f9bf9410f00f9f73c2d5', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 3, 'created': '2014-06-23 22:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/45d14e0aa6c004f52c71a86eb970cabe06ec21b4', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 4, 'created': '2014-06-26 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fad98a366524fb220016c7fc03568e665d0c9d1b', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 5, 'created': '2014-06-27 06:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1b7f7d78069b87f519326259eac1ee25e344cd08', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 6, 'created': '2014-06-30 02:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8a18f248fd6e7796f64bf41207c795deaf25e2e5', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 7, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d16a0e45fee0d1bcae1b7c5fdf63542334666c11', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 8, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2c47f1457d11adbc6dcd7b3a5331c9b7d860da31', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 9, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3dfc00ae648033a3692a6bc483725ec1e0253910', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 10, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2b1de7595923fa06ebc76ccb91a8d314e70434f1', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 11, 'created': '2014-07-06 22:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e48b963a592a7b3bf564641742dd7654d107de9b', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 12, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aa6234bd7b96fb1d8230c4597ada24f12e795ff0', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 13, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c84c9b70f34dd16e7c3e723f6f3b649674c59f69', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 14, 'created': '2014-07-08 21:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4b075544da852524b5156c829461e40fb38aad50', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 15, 'created': '2014-07-17 02:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2e7a5a87c68ada0f8ef305a5d9945af557f6bdce', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 16, 'created': '2014-07-18 02:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5e2fd72346e6553fe4ab4b7400edf5556dccbd6b', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 17, 'created': '2014-07-21 17:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c76e4b34b2785be21f4aa0234e3f04e29b096f8e', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 18, 'created': '2014-07-21 17:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5e1f61272ab59baf3f8db63ab5b21cacafb77b1e', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 19, 'created': '2014-07-24 20:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c72f7fd097456fce23e1c0f6671085c24ad9b005', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 20, 'created': '2014-07-28 02:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b9e338246bd7c1918db01d9ad33e17ea084f1e12', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 21, 'created': '2014-07-28 21:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/173675f60c63dce084272bef6e4cc825bd985d95', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 22, 'created': '2014-07-29 20:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8408374057b18fe02fe89f2ccdad8d960fddfe57', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 23, 'created': '2014-07-29 21:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/84025023d55f917d379ebccb5e636c0bd0810566', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 24, 'created': '2014-07-30 21:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d5efd14e57d9de10645047c1ea2dc2804719bc33', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 25, 'created': '2014-07-31 17:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aaec3e93e83c066fa8fabd84da72e8bc709c2ae5', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 26, 'created': '2014-07-31 22:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f5e66ec5e986f22ce184d5bdd9c37eb0a0d25e96', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 27, 'created': '2014-08-05 15:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/62c39c75f2abf44bde50e52f2cfa1405d6b941ea', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 28, 'created': '2014-08-11 16:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ba0384c7821ee42fd9fcbf705136aeb38237a87b', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 29, 'created': '2014-08-11 22:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/927435d850c7f7c48451f1d19fc0590407171cac', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}, {'number': 30, 'created': '2014-08-13 19:31:10.000000000', 'files': ['heat/engine/resources/software_config/software_config.py', 'heat/common/exception.py', 'heat/engine/resources/server.py', 'heat/tests/test_software_config.py', 'heat/tests/test_server.py', 'heat/engine/resources/software_config/software_deployment.py', 'heat/engine/resources/software_config/multi_part.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d825e2be115ad4e124ed80ff87182af5756f8638', 'message': ""Remove function get_software_config\n\nThis change removes the function get_software_config\nand replaces it with direct calls to heatclient.\n\nThis allows the heat client plugin's ignore_not_found handling\nto be used.\n\nThe SoftwareConfigMissing exception is also no longer required.\n\nChange-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a\n""}]",4,101396,d825e2be115ad4e124ed80ff87182af5756f8638,118,20,30,4571,,,0,"Remove function get_software_config

This change removes the function get_software_config
and replaces it with direct calls to heatclient.

This allows the heat client plugin's ignore_not_found handling
to be used.

The SoftwareConfigMissing exception is also no longer required.

Change-Id: I61fbe9556d9988fffd4afddf3fad5d2fa211475a
",git fetch https://review.opendev.org/openstack/heat refs/changes/96/101396/12 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/software_config/software_config.py', 'heat/common/exception.py', 'heat/engine/resources/server.py', 'heat/tests/test_software_config.py', 'heat/tests/test_server.py', 'heat/engine/resources/software_config/software_deployment.py', 'heat/engine/resources/software_config/multi_part.py']",7,50ace49a1ab4db505287bd52f756d7534ac4778f,bp/client-plugins, part = self.heat().software_configs.get(config).config except Exception: self.client_plugin().ignore_not_found(),"from heat.common import exception part = self.get_software_config(self.heat(), config) except exception.SoftwareConfigMissing: pass",37,80
openstack%2Fneutron~master~Ida6644f628d8a529f3f8a9294062cff4fb9a6e62,openstack/neutron,master,Ida6644f628d8a529f3f8a9294062cff4fb9a6e62,Adding support template as an extended attribute for subnet and router,ABANDONED,2014-08-05 01:49:31.000000000,2014-08-13 22:11:58.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7962}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10068}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-08-05 01:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6fe65c745c50036b9c1ff98d4f8cae5e272df900', 'message': 'Adding support template as an extended attribute for subnet and router\n\nChange-Id: Ida6644f628d8a529f3f8a9294062cff4fb9a6e62\nImplements: blueprint nuage-extension-for-templates\n'}, {'number': 2, 'created': '2014-08-05 02:11:52.000000000', 'files': ['neutron/plugins/nuage/plugin.py', 'neutron/plugins/nuage/extensions/nuage_router.py', 'neutron/plugins/nuage/extensions/nuage_subnet.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/38e6c7b6e83b011c7781fb50c17c4ed3093eb587', 'message': 'Adding support template as an extended attribute for subnet and router\n\nChange-Id: Ida6644f628d8a529f3f8a9294062cff4fb9a6e62\nImplements: blueprint nuage-extension-for-templates\n'}]",0,111883,38e6c7b6e83b011c7781fb50c17c4ed3093eb587,34,17,2,11784,,,0,"Adding support template as an extended attribute for subnet and router

Change-Id: Ida6644f628d8a529f3f8a9294062cff4fb9a6e62
Implements: blueprint nuage-extension-for-templates
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/111883/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/nuage/plugin.py', 'neutron/plugins/nuage/extensions/nuage_router.py', 'neutron/plugins/nuage/extensions/nuage_subnet.py']",3,6fe65c745c50036b9c1ff98d4f8cae5e272df900,bp/nuage-extension-for-templates," 'nuage_subnet_template': { 'allow_post': True, 'allow_put': False, 'is_visible': True, 'default': None, 'validate': {'type:uuid_or_none': None} },",,24,5
openstack%2Ftripleo-incubator~master~Ie2dbba83d98608e0ad9699c003ac179e67d6da97,openstack/tripleo-incubator,master,Ie2dbba83d98608e0ad9699c003ac179e67d6da97,Switch to only one top-level heading per doc,MERGED,2014-07-03 03:30:58.000000000,2014-08-13 22:03:42.000000000,2014-08-13 22:03:42.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 9369}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-07-03 03:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/47e859b5883725ec7b972a107d638e631e258fd0', 'message': 'Tweak heading levels\n\nSome of our docs have many top-level headings, leading to confusing\ntoctrees. Split this out into first/second level headings to make the\ntoctree easier to read.\n\nChange-Id: Ie2dbba83d98608e0ad9699c003ac179e67d6da97\n'}, {'number': 2, 'created': '2014-07-03 04:08:19.000000000', 'files': ['README.rst', 'doc/source/deploying.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/90acd67c8a5e8ef58456d5c5f7a09a62c1f4145a', 'message': ""Switch to only one top-level heading per doc\n\nSome of our docs have many top-level headings, leading to confusing\ntoctrees.\n\nTo fix this I've found all the top-level headings (except the first,\nwhich is the document title) and made them second-level headings, as\nwell as demoting all subheadings inside them.\n\nThe heading hierarchy is now:\n\n=====\n-----\n^^^^^\n~~~~~\n\nChange-Id: Ie2dbba83d98608e0ad9699c003ac179e67d6da97\n""}]",2,104434,90acd67c8a5e8ef58456d5c5f7a09a62c1f4145a,25,6,2,9453,,,0,"Switch to only one top-level heading per doc

Some of our docs have many top-level headings, leading to confusing
toctrees.

To fix this I've found all the top-level headings (except the first,
which is the document title) and made them second-level headings, as
well as demoting all subheadings inside them.

The heading hierarchy is now:

=====
-----
^^^^^
~~~~~

Change-Id: Ie2dbba83d98608e0ad9699c003ac179e67d6da97
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/34/104434/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'README.rst']",2,47e859b5883725ec7b972a107d638e631e258fd0,tidy_heading_levels,==================================Overview ======== ,,5,1
openstack%2Fnova~master~I73a166a48c0038743213e4feaa95834f9ebc8fbf,openstack/nova,master,I73a166a48c0038743213e4feaa95834f9ebc8fbf,VMware: Remove ds_util.build_datastore_path(),MERGED,2014-07-02 11:03:40.000000000,2014-08-13 21:59:16.000000000,2014-08-13 11:40:12.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 7400}, {'_account_id': 8027}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-02 11:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3dde2067ff96e0668af04b86ebb0183100dd1860', 'message': 'VMware: Use ds_util.build_datastore_path() in tests\n\nThis change has been split out of\nhttps://review.openstack.org/#/c/87002/, which was written by Shawn\nHartsock.\n\nTrivialFix\n\npartial blueprint vmware-spawn-refactor\n\nCo-authored-by: Shawn Hartsock <hartsocks@acm.org>\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 2, 'created': '2014-07-04 09:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2db175d246056af55baecf74bf1a717eb205acf1', 'message': 'VMware: Use ds_util.build_datastore_path() in tests\n\nThis change has been split out of\nhttps://review.openstack.org/#/c/87002/, which was written by Shawn\nHartsock.\n\nTrivialFix\n\npartial blueprint vmware-spawn-refactor\n\nCo-authored-by: Shawn Hartsock <hartsocks@acm.org>\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 3, 'created': '2014-07-04 09:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/693068588dabb9bbbad59c08784d02741ddb2fbc', 'message': 'VMware: Use ds_util.build_datastore_path() in tests\n\nThis change has been split out of\nhttps://review.openstack.org/#/c/87002/, which was written by Shawn\nHartsock.\n\nTrivialFix\n\npartial blueprint vmware-spawn-refactor\n\nCo-authored-by: Shawn Hartsock <hartsocks@acm.org>\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 4, 'created': '2014-07-04 10:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46146f5578bfa8a936cee8ddad9b76ad9d6e228a', 'message': 'VMware: Use ds_util.build_datastore_path() in tests\n\nThis change has been split out of\nhttps://review.openstack.org/#/c/87002/, which was written by Shawn\nHartsock.\n\nTrivialFix\n\npartial blueprint vmware-spawn-refactor\n\nCo-authored-by: Shawn Hartsock <hartsocks@acm.org>\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 5, 'created': '2014-07-04 13:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/852d6f2e72f16d7652bf9c90016c8fc7bf941be2', 'message': 'VMware: Use ds_util.build_datastore_path() in tests\n\nThis change has been split out of\nhttps://review.openstack.org/#/c/87002/, which was written by Shawn\nHartsock.\n\nTrivialFix\n\npartial blueprint vmware-spawn-refactor\n\nCo-authored-by: Shawn Hartsock <hartsocks@acm.org>\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 6, 'created': '2014-07-08 13:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/40c890567a8cd5b048ee4edbc65010037d97d0bd', 'message': 'VMware: Remove ds_util.build_datastore_path()\n\nConvert all remaining users of build_datastore_path to use the\nDatastorePath class, and remove build_datastore_path() and its tests.\n\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 7, 'created': '2014-07-10 08:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10d69b60e508c2435dd3dc2d17b7c6babf30a3b0', 'message': 'VMware: Remove ds_util.build_datastore_path()\n\nConvert all remaining users of build_datastore_path to use the\nDatastorePath class, and remove build_datastore_path() and its tests.\n\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 8, 'created': '2014-07-14 08:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c2221fbbecc3c914af6c6365e6ba320cffa392d', 'message': 'VMware: Remove ds_util.build_datastore_path()\n\nConvert all remaining users of build_datastore_path to use the\nDatastorePath class, and remove build_datastore_path() and its tests.\n\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 9, 'created': '2014-07-14 16:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6fd71c63ac70f6895c11ad81974e123916f7c041', 'message': 'VMware: Remove ds_util.build_datastore_path()\n\nConvert all remaining users of build_datastore_path to use the\nDatastorePath class, and remove build_datastore_path() and its tests.\n\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 10, 'created': '2014-07-17 11:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/215507efe15f24dea8f3ec7d3eaf6d90105c51a6', 'message': 'VMware: Remove ds_util.build_datastore_path()\n\nConvert all remaining users of build_datastore_path to use the\nDatastorePath class, and remove build_datastore_path() and its tests.\n\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 11, 'created': '2014-07-28 22:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30b0f1465e834aa7b5f6b7a861e866fbd6ca3f0a', 'message': 'VMware: Remove ds_util.build_datastore_path()\n\nConvert all remaining users of build_datastore_path to use the\nDatastorePath class, and remove build_datastore_path() and its tests.\n\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 12, 'created': '2014-08-04 13:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0eefbe8370549b8909a0cfc612ac06d53cc415a', 'message': 'VMware: Remove ds_util.build_datastore_path()\n\nConvert all remaining users of build_datastore_path to use the\nDatastorePath class, and remove build_datastore_path() and its tests.\n\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 13, 'created': '2014-08-07 13:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c33766ddf6f93cc07636d28799d100e30cac5047', 'message': 'VMware: Remove ds_util.build_datastore_path()\n\nConvert all remaining users of build_datastore_path to use the\nDatastorePath class, and remove build_datastore_path() and its tests.\n\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 14, 'created': '2014-08-08 13:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfb34d1a18416de697e67637994f80853f0edc46', 'message': 'VMware: Remove ds_util.build_datastore_path()\n\nConvert all remaining users of build_datastore_path to use the\nDatastorePath class, and remove build_datastore_path() and its tests.\n\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}, {'number': 15, 'created': '2014-08-08 17:26:04.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/virt/vmwareapi/ds_util.py', 'nova/tests/virt/vmwareapi/test_ds_util.py', 'nova/tests/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1498bf94e2617269be5be59556b89a24d56e3e86', 'message': 'VMware: Remove ds_util.build_datastore_path()\n\nConvert all remaining users of build_datastore_path to use the\nDatastorePath class, and remove build_datastore_path() and its tests.\n\nChange-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf\n'}]",0,104146,1498bf94e2617269be5be59556b89a24d56e3e86,188,18,15,9555,,,0,"VMware: Remove ds_util.build_datastore_path()

Convert all remaining users of build_datastore_path to use the
DatastorePath class, and remove build_datastore_path() and its tests.

Change-Id: I73a166a48c0038743213e4feaa95834f9ebc8fbf
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/104146/12 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/vmwareapi/test_driver_api.py'],1,3dde2067ff96e0668af04b86ebb0183100dd1860,bp/vmware-spawn-refactor," cache = (ds_util.build_datastore_path(self.ds, 'vmware_base/%s/%s.vmdk' % (self.fake_image_uuid, self.fake_image_uuid))) path = ds_util.build_datastore_path(self.ds, ('vmware_base/%s/%s.vmdk' % (self.fake_image_uuid, self.fake_image_uuid))) root = ds_util.build_datastore_path(self.ds, ('vmware_base/%s/%s.80.vmdk' % (self.fake_image_uuid, self.fake_image_uuid))) self.assertTrue(vmwareapi_fake.get_file(path)) path = ds_util.build_datastore_path(self.ds, ('vmware_base/%s/%s.iso' % (self.fake_image_uuid, self.fake_image_uuid))) self.assertTrue(vmwareapi_fake.get_file(path)) vmdk_file_path = ds_util.build_datastore_path(self.ds, ('%s/%s.vmdk' % (self.uuid, self.uuid))) vmdk_file_path = ds_util.build_datastore_path(self.ds, ('%s/%s.vmdk' % (self.uuid, self.uuid))) self.iso_path = ds_util.build_datastore_path(self.ds, ('vmware_base/%s/%s.iso' % (self.fake_image_uuid, self.fake_image_uuid))) ds_util.build_datastore_path(self.ds, 'vmware_base/%s/%s.iso' % (self.fake_image_uuid, self.fake_image_uuid)), ds_util.build_datastore_path(self.ds, 'fake-config-drive')] self.iso_path = ds_util.build_datastore_path( self.ds, 'fake-config-drive') root = ds_util.build_datastore_path(self.ds, ('vmware_base/%s/%s.80.vmdk' % ( self.fake_image_uuid, self.fake_image_uuid))) inst_path = ds_util.build_datastore_path(self.ds, ('%s/%s.vmdk' % (self.uuid, self.uuid))) rescue_file_path = ds_util.build_datastore_path(self.ds, ('%s-rescue/%s-rescue.vmdk' % (self.uuid, self.uuid))) return ds_util.build_datastore_path(data_store_name, ""%s/fake.iso"" % instance_uuid) inst_file_path = ds_util.build_datastore_path(self.ds, ('%s/%s.vmdk' % (self.uuid, self.uuid))) rescue_file_path = ds_util.build_datastore_path(self.ds, ('%s-rescue/%s-rescue.vmdk' % (self.uuid, self.uuid))) timestamp = ds_util.build_datastore_path(self.ds, ('vmware_base/%s/%s/' % (self.fake_image_uuid, self._get_timestamp_filename()))) ts_path = ds_util.build_datastore_path(self.ds, ('vmware_base/%s/%s/' % (self.fake_image_uuid, ts))) ds_util.build_datastore_path(self.ds, ""vmware_temp/%s-flat.vmdk"" % uuid_str), ds_util.build_datastore_path(self.ds, ""vmware_temp/%s.vmdk"" % uuid_str),"," cache = ('[%s] vmware_base/%s/%s.vmdk' % (self.ds, self.fake_image_uuid, self.fake_image_uuid)) file = '[%s] vmware_base/%s/%s.vmdk' % (self.ds, self.fake_image_uuid, self.fake_image_uuid) root = '[%s] vmware_base/%s/%s.80.vmdk' % (self.ds, self.fake_image_uuid, self.fake_image_uuid) self.assertTrue(vmwareapi_fake.get_file(file)) file = '[%s] vmware_base/%s/%s.iso' % (self.ds, self.fake_image_uuid, self.fake_image_uuid) self.assertTrue(vmwareapi_fake.get_file(file)) vmdk_file_path = '[%s] %s/%s.vmdk' % (self.ds, self.uuid, self.uuid) vmdk_file_path = '[%s] %s/%s.vmdk' % (self.ds, self.uuid, self.uuid) self.iso_path = ( '[%s] vmware_base/%s/%s.iso' % (self.ds, self.fake_image_uuid, self.fake_image_uuid)) '[%s] vmware_base/%s/%s.iso' % (self.ds, self.fake_image_uuid, self.fake_image_uuid), '[%s] fake-config-drive' % self.ds] self.iso_path = '[%s] fake-config-drive' % self.ds root = ('[%s] vmware_base/%s/%s.80.vmdk' % (self.ds, self.fake_image_uuid, self.fake_image_uuid)) inst_path = '[%s] %s/%s.vmdk' % (self.ds, self.uuid, self.uuid) rescue_file_path = '[%s] %s-rescue/%s-rescue.vmdk' % (self.ds, self.uuid, self.uuid) return ""[%s] %s/fake.iso"" % (data_store_name, instance_uuid) inst_file_path = '[%s] %s/%s.vmdk' % (self.ds, self.uuid, self.uuid) rescue_file_path = '[%s] %s-rescue/%s-rescue.vmdk' % (self.ds, self.uuid, self.uuid) timestamp = ('[%s] vmware_base/%s/%s/' % (self.ds, self.fake_image_uuid, self._get_timestamp_filename())) ts_path = ('[%s] vmware_base/%s/%s/' % (self.ds, self.fake_image_uuid, ts)) ""[%s] vmware_temp/%s-flat.vmdk"" % (self.ds, uuid_str), ""[%s] vmware_temp/%s.vmdk"" % (self.ds, uuid_str),",58,38
openstack%2Fneutron~master~If436a2c5c3a79fa28ee759a012f1f54734c2d818,openstack/neutron,master,If436a2c5c3a79fa28ee759a012f1f54734c2d818,Add comments to iptables rules to help debugging,ABANDONED,2014-05-20 05:41:50.000000000,2014-08-13 21:57:52.000000000,,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10184}, {'_account_id': 10192}]","[{'number': 1, 'created': '2014-05-20 05:41:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99b0a7572c4cab70f74b5ec35382714803c019a3', 'message': 'Add comments to iptables rules to help debugging\n\nAdds comments to some of the iptables rules generated\nby neutron to assist with debugging.\n\nPartial-Bug: #1265493\nChange-Id: If436a2c5c3a79fa28ee759a012f1f54734c2d818\n'}, {'number': 2, 'created': '2014-05-20 05:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/930c0878842877108c1f21e78c6dbfeac16e42b4', 'message': 'Add comments to iptables rules to help debugging\n\nAdds comments to some of the iptables rules generated\nby neutron to assist with debugging.\n\nPartial-Bug: #1265493\nChange-Id: If436a2c5c3a79fa28ee759a012f1f54734c2d818\n'}, {'number': 3, 'created': '2014-05-20 06:54:53.000000000', 'files': ['neutron/agent/linux/iptables_firewall.py', 'neutron/tests/unit/test_iptables_manager.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/tests/unit/test_iptables_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4766b38d704a057d770035b3b2728734619fd57d', 'message': 'Add comments to iptables rules to help debugging\n\nAdds comments to some of the iptables rules generated\nby neutron to assist with debugging.\n\nPartial-Bug: #1265493\nChange-Id: If436a2c5c3a79fa28ee759a012f1f54734c2d818\n'}]",4,94306,4766b38d704a057d770035b3b2728734619fd57d,44,14,3,7787,,,0,"Add comments to iptables rules to help debugging

Adds comments to some of the iptables rules generated
by neutron to assist with debugging.

Partial-Bug: #1265493
Change-Id: If436a2c5c3a79fa28ee759a012f1f54734c2d818
",git fetch https://review.opendev.org/openstack/neutron refs/changes/06/94306/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/iptables_firewall.py', 'neutron/tests/unit/test_iptables_manager.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/agent/common/config.py', 'neutron/tests/unit/test_iptables_firewall.py']",5,99b0a7572c4cab70f74b5ec35382714803c019a3,master," mock.call.add_rule( 'sg-fallback', '-j DROP', comment_key='unmatch_drop'), '-j $sg-chain', comment_key='vm_int_sg'), '-j $ifake_dev', comment_key='sg_to_vm_sg'), '-m state --state INVALID -j DROP', comment_key=None), mock.call.add_rule( 'ifake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), mock.call.add_rule( 'ifake_dev', '-j $sg-fallback', comment_key=None), '-j $sg-chain', comment_key='vm_int_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='sg_to_vm_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='input_to_sg'), '-s 10.0.0.1 -j RETURN', comment_key='pair_allow'), mock.call.add_rule( 'sfake_dev', '-j DROP', comment_key='pair_drop'), '-p udp -m udp --sport 68 --dport 67 -j RETURN', comment_key=None), mock.call.add_rule('ofake_dev', '-j $sfake_dev', comment_key=None), '-p udp -m udp --sport 67 --dport 68 -j DROP', comment_key=None), '-m state --state INVALID -j DROP', comment_key=None), mock.call.add_rule( 'ofake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), mock.call.add_rule( 'ofake_dev', '-j $sg-fallback', comment_key=None), ingress = mock.call.add_rule('ifake_dev', '-j RETURN', comment_key=None) ingress = mock.call.add_rule( 'ifake_dev', '-s %s -j RETURN' % prefix, comment_key=None) ingress = mock.call.add_rule( 'ifake_dev', '-p tcp -m tcp -j RETURN', comment_key=None) '-s %s -p tcp -m tcp -j RETURN' % prefix, comment_key=None) ingress = mock.call.add_rule('ifake_dev', '-p icmp -j RETURN', comment_key=None) 'ifake_dev', '-s %s -p icmp -j RETURN' % prefix, comment_key=None) '-p tcp -m tcp --dport 10 -j RETURN', comment_key=None) '-p tcp -m tcp -m multiport --dports 10:100 -j RETURN', comment_key=None) '-j RETURN' % prefix, comment_key=None) ingress = mock.call.add_rule( 'ifake_dev', '-p udp -m udp -j RETURN', comment_key=None) '-s %s -p udp -m udp -j RETURN' % prefix, comment_key=None) '-p udp -m udp --dport 10 -j RETURN', comment_key=None) '-p udp -m udp -m multiport --dports 10:100 -j RETURN', comment_key=None) '-j RETURN' % prefix, comment_key=None) egress = mock.call.add_rule('ofake_dev', '-j RETURN', comment_key=None) egress = mock.call.add_rule( 'ofake_dev', '-s %s -j RETURN' % prefix, comment_key=None) egress = mock.call.add_rule( 'ofake_dev', '-p tcp -m tcp -j RETURN', comment_key=None) '-s %s -p tcp -m tcp -j RETURN' % prefix, comment_key=None) egress = mock.call.add_rule('ofake_dev', '-p icmp -j RETURN', comment_key=None) 'ofake_dev', '-s %s -p icmp -j RETURN' % prefix, comment_key=None) '-s %s -p icmp --icmp-type 8 -j RETURN' % prefix, comment_key=None) '-s %s -p icmp --icmp-type echo-request -j RETURN' % prefix, comment_key=None) '-s %s -p icmp --icmp-type 8/0 -j RETURN' % prefix, comment_key=None) '-p tcp -m tcp --dport 10 -j RETURN', comment_key=None) '-p tcp -m tcp -m multiport --dports 10:100 -j RETURN', comment_key=None) '-j RETURN' % prefix, comment_key=None) egress = mock.call.add_rule( 'ofake_dev', '-p udp -m udp -j RETURN', comment_key=None) '-s %s -p udp -m udp -j RETURN' % prefix, comment_key=None) '-p udp -m udp --dport 10 -j RETURN', comment_key=None) '-p udp -m udp -m multiport --dports 10:100 -j RETURN', comment_key=None) '-j RETURN' % prefix, comment_key=None) ingress = mock.call.add_rule('ifake_dev', '-j RETURN', comment_key=None) ingress = mock.call.add_rule( 'ifake_dev', '-s %s -j RETURN' % prefix, comment_key=None) ingress = mock.call.add_rule( 'ifake_dev', '-p tcp -m tcp -j RETURN', comment_key=None) '-s %s -p tcp -m tcp -j RETURN' % prefix, comment_key=None) '-p tcp -m tcp --dport 10 -j RETURN', comment_key=None) ingress = mock.call.add_rule( 'ifake_dev', '-p icmpv6 -j RETURN', comment_key=None) 'ifake_dev', '-s %s -p icmpv6 -j RETURN' % prefix, comment_key=None) '-p tcp -m tcp -m multiport --dports 10:100 -j RETURN', comment_key=None) '-j RETURN' % prefix, comment_key=None) ingress = mock.call.add_rule( 'ifake_dev', '-p udp -m udp -j RETURN', comment_key=None) '-s %s -p udp -m udp -j RETURN' % prefix, comment_key=None) '-p udp -m udp --dport 10 -j RETURN', comment_key=None) '-p udp -m udp -m multiport --dports 10:100 -j RETURN', comment_key=None) '-j RETURN' % prefix, comment_key=None) egress = mock.call.add_rule('ofake_dev', '-j RETURN', comment_key=None) egress = mock.call.add_rule( 'ofake_dev', '-s %s -j RETURN' % prefix, comment_key=None) egress = mock.call.add_rule( 'ofake_dev', '-p tcp -m tcp -j RETURN', comment_key=None) '-s %s -p tcp -m tcp -j RETURN' % prefix, comment_key=None) egress = mock.call.add_rule( 'ofake_dev', '-p icmpv6 -j RETURN', comment_key=None) 'ofake_dev', '-s %s -p icmpv6 -j RETURN' % prefix, comment_key=None) '-s %s -p icmpv6 --icmpv6-type 8 -j RETURN' % prefix, comment_key=None) '-s %s -p icmpv6 --icmpv6-type echo-request -j RETURN' % prefix, comment_key=None) '-s %s -p icmpv6 --icmpv6-type 8/0 -j RETURN' % prefix, comment_key=None) '-p tcp -m tcp --dport 10 -j RETURN', comment_key=None) '-p tcp -m tcp -m multiport --dports 10:100 -j RETURN', comment_key=None) '-j RETURN' % prefix, comment_key=None) egress = mock.call.add_rule( 'ofake_dev', '-p udp -m udp -j RETURN', comment_key=None) '-s %s -p udp -m udp -j RETURN' % prefix, comment_key=None) '-p udp -m udp --dport 10 -j RETURN', comment_key=None) '-p udp -m udp -m multiport --dports 10:100 -j RETURN', comment_key=None) '-j RETURN' % prefix, comment_key=None) '-p udp -m udp --sport 68 --dport 67 -j RETURN', comment_key=None)] '-p icmpv6 -j RETURN', comment_key=None), '-j RETURN', comment_key=None)] mock.call.add_rule( 'sg-fallback', '-j DROP', comment_key='unmatch_drop'), '-j $sg-chain', comment_key='vm_int_sg'), '-j $ifake_dev', comment_key='sg_to_vm_sg'), icmp6_type, comment_key=None)) calls += [ mock.call.add_rule( 'ifake_dev', '-m state --state INVALID -j DROP', comment_key=None ), mock.call.add_rule( 'ifake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None ) ] calls += [mock.call.add_rule('ifake_dev', '-j $sg-fallback', comment_key=None), '-j $sg-chain', comment_key='vm_int_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='sg_to_vm_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='input_to_sg'), % prefix, comment_key='pair_allow'), mock.call.add_rule( 'sfake_dev', '-j DROP', comment_key='pair_drop')] calls.append(mock.call.add_rule('ofake_dev', '-j $sfake_dev', comment_key=None)) '-p udp -m udp --sport 67 --dport 68 -j DROP', comment_key=None)) '-p udp -m udp --sport 547 --dport 546 -j DROP', comment_key=None)) calls += [ mock.call.add_rule( 'ofake_dev', '-m state --state INVALID -j DROP', comment_key=None), mock.call.add_rule( 'ofake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), ] calls += [mock.call.add_rule('ofake_dev', '-j $sg-fallback', comment_key=None), mock.call.add_rule( 'sg-fallback', '-j DROP', comment_key='unmatch_drop'), '--physdev-is-bridged -j $sg-chain', comment_key='vm_int_sg'), '--physdev-is-bridged -j $ifake_dev', comment_key='sg_to_vm_sg'), '-m state --state INVALID -j DROP', comment_key=None), mock.call.add_rule( 'ifake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), mock.call.add_rule('ifake_dev', '-j RETURN', comment_key=None), mock.call.add_rule( 'ifake_dev', '-j $sg-fallback', comment_key=None), '--physdev-is-bridged -j $sg-chain', comment_key='vm_int_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='sg_to_vm_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='input_to_sg'), '-j RETURN', comment_key='pair_allow'), mock.call.add_rule( 'sfake_dev', '-j DROP', comment_key='pair_drop'), '-p udp -m udp --sport 68 --dport 67 -j RETURN', comment_key=None), mock.call.add_rule('ofake_dev', '-j $sfake_dev', comment_key=None), '-p udp -m udp --sport 67 --dport 68 -j DROP', comment_key=None), 'ofake_dev', '-m state --state INVALID -j DROP', comment_key=None), '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), mock.call.add_rule( 'ofake_dev', '-j $sg-fallback', comment_key=None), '--physdev-is-bridged -j $sg-chain', comment_key='vm_int_sg'), '--physdev-is-bridged -j $ifake_dev', comment_key='sg_to_vm_sg'), '-m state --state INVALID -j DROP', comment_key=None), '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), mock.call.add_rule( 'ifake_dev', '-j $sg-fallback', comment_key=None), '--physdev-is-bridged -j $sg-chain', comment_key='vm_int_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='sg_to_vm_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='input_to_sg'), '-j RETURN', comment_key='pair_allow'), mock.call.add_rule( 'sfake_dev', '-j DROP', comment_key='pair_drop'), '-p udp -m udp --sport 68 --dport 67 -j RETURN', comment_key=None), mock.call.add_rule('ofake_dev', '-j $sfake_dev', comment_key=None), '-p udp -m udp --sport 67 --dport 68 -j DROP', comment_key=None), '-m state --state INVALID -j DROP', comment_key=None), mock.call.add_rule( 'ofake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), mock.call.add_rule('ofake_dev', '-j RETURN', comment_key=None), mock.call.add_rule('ofake_dev', '-j $sg-fallback', comment_key=None), mock.call.add_rule( 'sg-fallback', '-j DROP', comment_key='unmatch_drop'), '-j $sg-chain', comment_key='vm_int_sg'), '-j $ifake_dev', comment_key='sg_to_vm_sg'), '-m state --state INVALID -j DROP', comment_key=None), mock.call.add_rule( 'ifake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), mock.call.add_rule('ifake_dev', '-j $sg-fallback', comment_key=None), '-j $sg-chain', comment_key='vm_int_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='sg_to_vm_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='input_to_sg'), '-j RETURN', comment_key='pair_allow'), '-j RETURN', comment_key='pair_allow'), mock.call.add_rule( 'sfake_dev', '-j DROP', comment_key='pair_drop'), '-p udp -m udp --sport 68 --dport 67 -j RETURN', comment_key=None), mock.call.add_rule('ofake_dev', '-j $sfake_dev', comment_key=None), '-p udp -m udp --sport 67 --dport 68 -j DROP', comment_key=None), '-m state --state INVALID -j DROP', comment_key=None), mock.call.add_rule( 'ofake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), mock.call.add_rule('ofake_dev', '-j $sg-fallback', comment_key=None), mock.call.add_rule( 'sg-fallback', '-j DROP', comment_key='unmatch_drop'), '-j $sg-chain', comment_key='vm_int_sg'), '-j $ifake_dev', comment_key='sg_to_vm_sg'), '-m state --state INVALID -j DROP', comment_key=None), mock.call.add_rule( 'ifake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), mock.call.add_rule('ifake_dev', '-j $sg-fallback', comment_key=None), '-j $sg-chain', comment_key='vm_int_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='sg_to_vm_sg'), '--physdev-is-bridged -j $ofake_dev', comment_key='input_to_sg'), '-m mac --mac-source ff:ff:ff:ff:ff:ff -j RETURN', comment_key='pair_allow'), mock.call.add_rule( 'sfake_dev', '-j DROP', comment_key='pair_drop'), '-p udp -m udp --sport 68 --dport 67 -j RETURN', comment_key=None), mock.call.add_rule('ofake_dev', '-j $sfake_dev', comment_key=None), '-p udp -m udp --sport 67 --dport 68 -j DROP', comment_key=None), '-m state --state INVALID -j DROP', comment_key=None), mock.call.add_rule( 'ofake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN', comment_key=None), mock.call.add_rule('ofake_dev', '-j $sg-fallback', comment_key=None),"," mock.call.add_rule('sg-fallback', '-j DROP'), '-j $sg-chain'), '-j $ifake_dev'), mock.call.add_rule( 'ifake_dev', '-m state --state INVALID -j DROP'), '-m state --state RELATED,ESTABLISHED -j RETURN'), mock.call.add_rule('ifake_dev', '-j $sg-fallback'), '-j $sg-chain'), '--physdev-is-bridged ' '-j $ofake_dev'), '--physdev-is-bridged ' '-j $ofake_dev'), '-s 10.0.0.1 -j RETURN'), mock.call.add_rule('sfake_dev', '-j DROP'), '-p udp -m udp --sport 68 --dport 67 -j RETURN'), mock.call.add_rule('ofake_dev', '-j $sfake_dev'), '-p udp -m udp --sport 67 --dport 68 -j DROP'), mock.call.add_rule( 'ofake_dev', '-m state --state INVALID -j DROP'), '-m state --state RELATED,ESTABLISHED -j RETURN'), mock.call.add_rule('ofake_dev', '-j $sg-fallback'), ingress = mock.call.add_rule('ifake_dev', '-j RETURN') ingress = mock.call.add_rule('ifake_dev', '-s %s -j RETURN' % prefix) ingress = mock.call.add_rule('ifake_dev', '-p tcp -m tcp -j RETURN') '-s %s -p tcp -m tcp -j RETURN' % prefix) ingress = mock.call.add_rule('ifake_dev', '-p icmp -j RETURN') 'ifake_dev', '-s %s -p icmp -j RETURN' % prefix) '-p tcp -m tcp --dport 10 -j RETURN') '-p tcp -m tcp -m multiport --dports 10:100 -j RETURN') '-j RETURN' % prefix) ingress = mock.call.add_rule('ifake_dev', '-p udp -m udp -j RETURN') '-s %s -p udp -m udp -j RETURN' % prefix) '-p udp -m udp --dport 10 -j RETURN') '-p udp -m udp -m multiport --dports 10:100 -j RETURN') '-j RETURN' % prefix) egress = mock.call.add_rule('ofake_dev', '-j RETURN') egress = mock.call.add_rule('ofake_dev', '-s %s -j RETURN' % prefix) egress = mock.call.add_rule('ofake_dev', '-p tcp -m tcp -j RETURN') '-s %s -p tcp -m tcp -j RETURN' % prefix) egress = mock.call.add_rule('ofake_dev', '-p icmp -j RETURN') 'ofake_dev', '-s %s -p icmp -j RETURN' % prefix) '-s %s -p icmp --icmp-type 8 -j RETURN' % prefix) '-s %s -p icmp --icmp-type echo-request -j RETURN' % prefix) '-s %s -p icmp --icmp-type 8/0 -j RETURN' % prefix) '-p tcp -m tcp --dport 10 -j RETURN') '-p tcp -m tcp -m multiport --dports 10:100 -j RETURN') '-j RETURN' % prefix) egress = mock.call.add_rule('ofake_dev', '-p udp -m udp -j RETURN') '-s %s -p udp -m udp -j RETURN' % prefix) '-p udp -m udp --dport 10 -j RETURN') '-p udp -m udp -m multiport --dports 10:100 -j RETURN') '-j RETURN' % prefix) ingress = mock.call.add_rule('ifake_dev', '-j RETURN') ingress = mock.call.add_rule('ifake_dev', '-s %s -j RETURN' % prefix) ingress = mock.call.add_rule('ifake_dev', '-p tcp -m tcp -j RETURN') '-s %s -p tcp -m tcp -j RETURN' % prefix) '-p tcp -m tcp --dport 10 -j RETURN') ingress = mock.call.add_rule('ifake_dev', '-p icmpv6 -j RETURN') 'ifake_dev', '-s %s -p icmpv6 -j RETURN' % prefix) '-p tcp -m tcp -m multiport --dports 10:100 -j RETURN') '-j RETURN' % prefix) ingress = mock.call.add_rule('ifake_dev', '-p udp -m udp -j RETURN') '-s %s -p udp -m udp -j RETURN' % prefix) '-p udp -m udp --dport 10 -j RETURN') '-p udp -m udp -m multiport --dports 10:100 -j RETURN') '-j RETURN' % prefix) egress = mock.call.add_rule('ofake_dev', '-j RETURN') egress = mock.call.add_rule('ofake_dev', '-s %s -j RETURN' % prefix) egress = mock.call.add_rule('ofake_dev', '-p tcp -m tcp -j RETURN') '-s %s -p tcp -m tcp -j RETURN' % prefix) egress = mock.call.add_rule('ofake_dev', '-p icmpv6 -j RETURN') 'ofake_dev', '-s %s -p icmpv6 -j RETURN' % prefix) '-s %s -p icmpv6 --icmpv6-type 8 -j RETURN' % prefix) '-s %s -p icmpv6 --icmpv6-type echo-request -j RETURN' % prefix) '-s %s -p icmpv6 --icmpv6-type 8/0 -j RETURN' % prefix) '-p tcp -m tcp --dport 10 -j RETURN') '-p tcp -m tcp -m multiport --dports 10:100 -j RETURN') '-j RETURN' % prefix) egress = mock.call.add_rule('ofake_dev', '-p udp -m udp -j RETURN') '-s %s -p udp -m udp -j RETURN' % prefix) '-p udp -m udp --dport 10 -j RETURN') '-p udp -m udp -m multiport --dports 10:100 -j RETURN') '-j RETURN' % prefix) '-p udp -m udp --sport 68 --dport 67 -j RETURN')] '-p icmpv6 -j RETURN'), '-j RETURN')] mock.call.add_rule('sg-fallback', '-j DROP'), '-j $sg-chain'), '-j $ifake_dev'), icmp6_type)) calls += [mock.call.add_rule('ifake_dev', '-m state --state INVALID -j DROP'), mock.call.add_rule( 'ifake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN')] calls += [mock.call.add_rule('ifake_dev', '-j $sg-fallback'), '-j $sg-chain'), '--physdev-is-bridged ' '-j $ofake_dev'), '--physdev-is-bridged ' '-j $ofake_dev'), % prefix), mock.call.add_rule('sfake_dev', '-j DROP')] calls.append(mock.call.add_rule('ofake_dev', '-j $sfake_dev')) '-p udp -m udp --sport 67 --dport 68 -j DROP')) '-p udp -m udp --sport 547 --dport 546 -j DROP')) calls += [mock.call.add_rule( 'ofake_dev', '-m state --state INVALID -j DROP'), mock.call.add_rule( 'ofake_dev', '-m state --state RELATED,ESTABLISHED -j RETURN')] calls += [mock.call.add_rule('ofake_dev', '-j $sg-fallback'), mock.call.add_rule('sg-fallback', '-j DROP'), '--physdev-is-bridged -j $sg-chain'), '--physdev-is-bridged -j $ifake_dev'), mock.call.add_rule( 'ifake_dev', '-m state --state INVALID -j DROP'), '-m state --state RELATED,ESTABLISHED -j RETURN'), mock.call.add_rule('ifake_dev', '-j RETURN'), mock.call.add_rule('ifake_dev', '-j $sg-fallback'), '--physdev-is-bridged -j $sg-chain'), '--physdev-is-bridged -j $ofake_dev'), '--physdev-is-bridged -j $ofake_dev'), '-j RETURN'), mock.call.add_rule('sfake_dev', '-j DROP'), '-p udp -m udp --sport 68 --dport 67 -j RETURN'), mock.call.add_rule('ofake_dev', '-j $sfake_dev'), '-p udp -m udp --sport 67 --dport 68 -j DROP'), 'ofake_dev', '-m state --state INVALID -j DROP'), '-m state --state RELATED,ESTABLISHED -j RETURN'), mock.call.add_rule('ofake_dev', '-j $sg-fallback'), '--physdev-is-bridged -j $sg-chain'), '--physdev-is-bridged -j $ifake_dev'), '-m state --state INVALID -j DROP'), '-m state --state RELATED,ESTABLISHED -j RETURN'), mock.call.add_rule('ifake_dev', '-j $sg-fallback'), '--physdev-is-bridged -j $sg-chain'), '--physdev-is-bridged -j $ofake_dev'), '--physdev-is-bridged -j $ofake_dev'), '-j RETURN'), mock.call.add_rule('sfake_dev', '-j DROP'), '-p udp -m udp --sport 68 --dport 67 -j RETURN'), mock.call.add_rule('ofake_dev', '-j $sfake_dev'), '-p udp -m udp --sport 67 --dport 68 -j DROP'), mock.call.add_rule( 'ofake_dev', '-m state --state INVALID -j DROP'), '-m state --state RELATED,ESTABLISHED -j RETURN'), mock.call.add_rule('ofake_dev', '-j RETURN'), mock.call.add_rule('ofake_dev', '-j $sg-fallback'), mock.call.add_rule('sg-fallback', '-j DROP'), '-j $sg-chain'), '-j $ifake_dev'), mock.call.add_rule( 'ifake_dev', '-m state --state INVALID -j DROP'), '-m state --state RELATED,ESTABLISHED -j RETURN'), mock.call.add_rule('ifake_dev', '-j $sg-fallback'), '-j $sg-chain'), '--physdev-is-bridged ' '-j $ofake_dev'), '--physdev-is-bridged ' '-j $ofake_dev'), '-j RETURN'), '-j RETURN'), mock.call.add_rule('sfake_dev', '-j DROP'), '-p udp -m udp --sport 68 --dport 67 -j RETURN'), mock.call.add_rule('ofake_dev', '-j $sfake_dev'), '-p udp -m udp --sport 67 --dport 68 -j DROP'), mock.call.add_rule( 'ofake_dev', '-m state --state INVALID -j DROP'), '-m state --state RELATED,ESTABLISHED -j RETURN'), mock.call.add_rule('ofake_dev', '-j $sg-fallback'), mock.call.add_rule('sg-fallback', '-j DROP'), '-j $sg-chain'), '-j $ifake_dev'), mock.call.add_rule( 'ifake_dev', '-m state --state INVALID -j DROP'), '-m state --state RELATED,ESTABLISHED -j RETURN'), mock.call.add_rule('ifake_dev', '-j $sg-fallback'), '-j $sg-chain'), '--physdev-is-bridged ' '-j $ofake_dev'), '--physdev-is-bridged ' '-j $ofake_dev'), '-m mac --mac-source ff:ff:ff:ff:ff:ff -j RETURN'), mock.call.add_rule('sfake_dev', '-j DROP'), '-p udp -m udp --sport 68 --dport 67 -j RETURN'), mock.call.add_rule('ofake_dev', '-j $sfake_dev'), '-p udp -m udp --sport 67 --dport 68 -j DROP'), mock.call.add_rule( 'ofake_dev', '-m state --state INVALID -j DROP'), '-m state --state RELATED,ESTABLISHED -j RETURN'), mock.call.add_rule('ofake_dev', '-j $sg-fallback'),",578,220
openstack%2Fmanila~master~I2657815f19bb81a5d5e26808e088b51eb631d5b1,openstack/manila,master,I2657815f19bb81a5d5e26808e088b51eb631d5b1,Modify smb config in CIFSHelper using SFTP,ABANDONED,2014-07-09 10:07:55.000000000,2014-08-13 21:54:17.000000000,,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7534}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-07-09 10:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6b41153451289f6a2c13d608f930c975ad2626c8', 'message': 'Modify smb config in CIFSHelper using SFTP\n\nChange-Id: I2657815f19bb81a5d5e26808e088b51eb631d5b1\n'}, {'number': 2, 'created': '2014-07-10 14:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a524a2c328c626d7ef1dedcf78f82a1f89b7f677', 'message': ""Modify smb config in CIFSHelper using SFTP\n\nAdd functional which changes smb config on remote side. So now it's not\nnecessary to store local config, then change it and move to remote server.\nAll changes go through sftp.\n\nAlso add posibility to log in using ssh keys instead of username/password.\n\nChange-Id: I2657815f19bb81a5d5e26808e088b51eb631d5b1\n""}, {'number': 3, 'created': '2014-08-06 07:54:42.000000000', 'files': ['manila/tests/test_share_generic.py', 'manila/share/drivers/generic.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/48cf91c8e1fd4aa46cea3ae21370b6a50412b4cd', 'message': ""Modify smb config in CIFSHelper using SFTP\n\nAdd functional which changes smb config on remote side. So now it's not\nnecessary to store local config, then change it and move to remote server.\nAll changes go through sftp.\n\nAlso add posibility to log in using ssh keys instead of username/password.\n\nChange-Id: I2657815f19bb81a5d5e26808e088b51eb631d5b1\n""}]",10,105689,48cf91c8e1fd4aa46cea3ae21370b6a50412b4cd,14,4,3,6529,,,0,"Modify smb config in CIFSHelper using SFTP

Add functional which changes smb config on remote side. So now it's not
necessary to store local config, then change it and move to remote server.
All changes go through sftp.

Also add posibility to log in using ssh keys instead of username/password.

Change-Id: I2657815f19bb81a5d5e26808e088b51eb631d5b1
",git fetch https://review.opendev.org/openstack/manila refs/changes/89/105689/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/test_share_generic.py', 'manila/share/drivers/generic.py']",2,6b41153451289f6a2c13d608f930c975ad2626c8,,"import paramiko def _get_sftp_connection(self, server): t = paramiko.Transport((str(server['ip']), 22)) t.connect(username=server[""username""], password=server['password']) server_sftp = paramiko.SFTPClient.from_transport(t) return server_sftp server_sftp = self._get_sftp_connection(server) server_sftp.put(local_config, self.config_path) server_sftp = self._get_sftp_connection(server) config = server_sftp.file(self.config_path) parser.readfp(config) self._update_remote_config(parser, self.config_path, server_sftp) server_sftp = self._get_sftp_connection(server) config = server_sftp.file(self.config_path) parser.readfp(config) self._update_remote_config(parser, self.config_path, server_sftp) server_sftp = self._get_sftp_connection(server) config = server_sftp.file(self.config_path) parser.readfp(config) self._update_remote_config(parser, self.config_path, server_sftp) server_sftp = self._get_sftp_connection(server) config = server_sftp.file(self.config_path) parser.readfp(config) self._update_remote_config(parser, self.config_path, server_sftp) with open(config, ""w"") as fp: parser.write(fp) def _update_remote_config(self, parser, config, server_sftp): """"""Check if new configuration is correct and save it to remote server"""""" #Check that configuration is correct with open(self.test_config, 'w') as fp: parser.write(fp) self._execute('testparm', '-s', self.test_config, check_exit_code=True) #save it with server_sftp.file(config, ""w"") as fp:"," def _get_local_config(self, share_network_id): local_config = self.local_configs.get(share_network_id, None) if local_config is None: local_config = self._create_local_config(share_network_id) return local_config self._write_remote_config(local_config, server) config = self._get_local_config(server['instance_id']) parser.read(config) self._update_config(parser, config) self._write_remote_config(config, server) config = self._get_local_config(server['instance_id']) parser.read(config) self._update_config(parser, config) self._write_remote_config(config, server) def _write_remote_config(self, config, server): with open(config, 'r') as f: cfg = ""'%s'"" % f.read() self._ssh_exec(server, ['echo %s > %s' % (cfg, self.config_path)]) config = self._get_local_config(server['instance_id']) parser.read(config) self._update_config(parser, config) self._write_remote_config(config, server) config = self._get_local_config(server['instance_id']) parser.read(config) self._update_config(parser, config) self._write_remote_config(config, server) with open(config, 'w') as fp:",59,55
openstack%2Fdevstack~master~Idf0914f55d72832a829ac99edf763ff51f71ca6c,openstack/devstack,master,Idf0914f55d72832a829ac99edf763ff51f71ca6c,Add MAINTAINERS.rst,MERGED,2014-08-07 05:03:33.000000000,2014-08-13 21:50:58.000000000,2014-08-13 21:50:58.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 67}, {'_account_id': 112}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 6854}, {'_account_id': 6962}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-07 05:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ed8775e737b74bf12cfed2209044300099fd6489', 'message': ""Add MAINTAINERS.rst\n\nAdd a MAINTAINERS.rst file with two goals\n\n1) to help seed initial reviews with relevant people.  Devstack by its\nnature attracts new contributors, so when they hit some obscure bug,\nthis will help them find out who to put on a review.\n\n2) core reviewers can't know everything about everything.  Having\nsomeone who has flagged themselves as interested in an area sign-off\noff on relevant changes can help move changes through.\n\nChange-Id: Idf0914f55d72832a829ac99edf763ff51f71ca6c\n""}, {'number': 2, 'created': '2014-08-11 02:03:34.000000000', 'files': ['MAINTAINERS.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f901dd0049d0fc6a885e5e076d272af155a0d5b4', 'message': ""Add MAINTAINERS.rst\n\nAdd a MAINTAINERS.rst file with two goals\n\n1) to help seed initial reviews with relevant people.  Devstack by its\nnature attracts new contributors, so when they hit some obscure bug,\nthis will help them find out who to put on a review.\n\n2) core reviewers can't know everything about everything.  Having\nsomeone who has flagged themselves as interested in an area sign-off\noff on relevant changes can help move changes through.\n\nChange-Id: Idf0914f55d72832a829ac99edf763ff51f71ca6c\n""}]",8,112473,f901dd0049d0fc6a885e5e076d272af155a0d5b4,27,12,2,7118,,,0,"Add MAINTAINERS.rst

Add a MAINTAINERS.rst file with two goals

1) to help seed initial reviews with relevant people.  Devstack by its
nature attracts new contributors, so when they hit some obscure bug,
this will help them find out who to put on a review.

2) core reviewers can't know everything about everything.  Having
someone who has flagged themselves as interested in an area sign-off
off on relevant changes can help move changes through.

Change-Id: Idf0914f55d72832a829ac99edf763ff51f71ca6c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/73/112473/1 && git format-patch -1 --stdout FETCH_HEAD,['MAINTAINERS.rst'],1,ed8775e737b74bf12cfed2209044300099fd6489,maintainers,MAINTAINERS =========== Overview -------- The following is a list of people known to have interests in particular areas or sub-systems of devstack. It is a rather general guide intended to help seed the initial reviewers list of a change. A +1 on a review from someone identified as being a maintainer of its affected area is a very positive flag to the core team for the veracity of the change. The ``devstack-core`` group can still be added to all reviews. Format ~~~~~~ The format of the file is the name of the maintainer and their gerrit-registered email. Maintainers ----------- .. contents:: :local: Fedora/CentOS/RHEL ~~~~~~~~~~~~~~~~~~ * Ian Wienand <iwienand@redhat.com> Xen ~~~ Cinder ~~~~~~ Neutron ~~~~~~~ nova-docker ~~~~~~~~~~~ tempest ~~~~~~~ ,,50,0
openstack%2Fdevstack~master~Ia79d12da3c2224366425be5f6927859181e18909,openstack/devstack,master,Ia79d12da3c2224366425be5f6927859181e18909,Disable in-band control for PUBLIC_BRIDGE,MERGED,2014-07-23 07:24:35.000000000,2014-08-13 21:47:25.000000000,2014-08-13 21:47:25.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 6854}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-23 07:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/cc0e7af47fddb777062746a3e8362ec5e0a4f430', 'message': 'Disable in-band for PUBLIC_BRIDGE\n\nWe use local port to communicate with VMs.\n\nChange-Id: Ia79d12da3c2224366425be5f6927859181e18909\n'}, {'number': 2, 'created': '2014-07-25 07:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ac90a899a6222ed24347700225d88011f22cf5ae', 'message': 'Disable in-band control for PUBLIC_BRIDGE\n\nBy default, Open vSwitch installs internal flows for in-band control\nto bridges with controller setting.  ""with controller setting"" part\nis false for openvswitch agent but can be true for ofagent.\nUnfortunately the internal flows are incompatible with our use of\nthe local port here to communicate with neutron router.  This commit\navoids the problem by disabling the in-band control functionality.\n\nChange-Id: Ia79d12da3c2224366425be5f6927859181e18909\n'}, {'number': 3, 'created': '2014-08-01 02:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8e6a7ff42f859daf33d47f12e2e478a707f5d0b5', 'message': 'Disable in-band control for PUBLIC_BRIDGE\n\nBy default, Open vSwitch installs internal flows for in-band control\nto bridges with controller setting.  ""with controller setting"" part\nis false for openvswitch agent but can be true for ofagent.\nUnfortunately the internal flows are incompatible with our use of\nthe local port here to communicate with neutron router.  This commit\navoids the problem by disabling the in-band control functionality.\n\nChange-Id: Ia79d12da3c2224366425be5f6927859181e18909\n'}, {'number': 4, 'created': '2014-08-01 02:35:58.000000000', 'files': ['lib/neutron'], 'web_link': 'https://opendev.org/openstack/devstack/commit/ea3dac9a3c57ee59270e3321d68b93f2734f24b0', 'message': 'Disable in-band control for PUBLIC_BRIDGE\n\nBy default, Open vSwitch installs internal flows for in-band control\nto bridges with controller setting.  ""with controller setting"" part\nis false for openvswitch agent but can be true for ofagent.\nUnfortunately the internal flows are incompatible with our use of\nthe local port here to communicate with neutron router.  This commit\navoids the problem by disabling the in-band control functionality.\n\nRelated to blueprint ofagent-port-monitor\nChange-Id: Ia79d12da3c2224366425be5f6927859181e18909\n'}]",0,108909,ea3dac9a3c57ee59270e3321d68b93f2734f24b0,79,9,4,6854,,,0,"Disable in-band control for PUBLIC_BRIDGE

By default, Open vSwitch installs internal flows for in-band control
to bridges with controller setting.  ""with controller setting"" part
is false for openvswitch agent but can be true for ofagent.
Unfortunately the internal flows are incompatible with our use of
the local port here to communicate with neutron router.  This commit
avoids the problem by disabling the in-band control functionality.

Related to blueprint ofagent-port-monitor
Change-Id: Ia79d12da3c2224366425be5f6927859181e18909
",git fetch https://review.opendev.org/openstack/devstack refs/changes/09/108909/4 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron'],1,cc0e7af47fddb777062746a3e8362ec5e0a4f430,providernet, # Disable in-band as we are going to use local port # to communicate with VMs sudo ovs-vsctl set Bridge $PUBLIC_BRIDGE other_config:disable-in-band=true,,3,0
openstack%2Fheat~master~I0f4c78df15d3d973394ccfa14178941d170c9944,openstack/heat,master,I0f4c78df15d3d973394ccfa14178941d170c9944,Move calculating new capacity to a function,MERGED,2014-06-11 20:38:11.000000000,2014-08-13 21:43:14.000000000,2014-08-13 21:43:13.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 6800}, {'_account_id': 7256}, {'_account_id': 7404}, {'_account_id': 8435}, {'_account_id': 10018}, {'_account_id': 10048}]","[{'number': 1, 'created': '2014-06-11 20:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/62283171a1184591359e2784e27b282e7d0b8e55', 'message': 'Move calculating new capacity to new function\n\nChange-Id: I0f4c78df15d3d973394ccfa14178941d170c9944\n'}, {'number': 2, 'created': '2014-06-11 21:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/523ece1487f30772a3f11d9d79ad0bede7e8af0e', 'message': 'This is part of the refactoring to fix the inheritance hierarchy of\nAutoScaleResourceGroup.  In this case, attempting to move some common\nfunctionality out of the inheritance hierarchy entirely (perhaps to\nthe heat/scaling module).\n\nCalculating the new capacity, taking min/max constraints into account,\nseems like some common functionality to any type of scaling.  Also,\nbounds checking was previously done in both handle_update and in adjust,\nand it seems like it could be done in just one place.\n\nChange-Id: I0f4c78df15d3d973394ccfa14178941d170c9944\n'}, {'number': 3, 'created': '2014-06-11 23:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4a9401afc5481e0bafd0e67d9cfe1535d780d991', 'message': 'This is part of the refactoring to fix the inheritance hierarchy of\nAutoScaleResourceGroup.  In this case, attempting to move some common\nfunctionality out of the inheritance hierarchy entirely (perhaps to\nthe heat/scaling module).\n\nCalculating the new capacity, taking min/max constraints into account,\nseems like some common functionality to any type of scaling.  Also,\nbounds checking was previously done in both handle_update and in adjust,\nand it seems like it could be done in just one place.\n\nChange-Id: I0f4c78df15d3d973394ccfa14178941d170c9944\n'}, {'number': 4, 'created': '2014-06-12 01:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e5fe30d22d3f366f3e9fa80d561a8c16dc6b5232', 'message': 'This is part of the refactoring to fix the \ninheritance hierarchy of AutoScaleResourceGroup.\nIn this case, attempting to move some common\nfunctionality out of the inheritance hierarchy\nentirely (perhaps to the heat/scaling module).\n\nCalculating the new capacity, taking min/max\nconstraints into account, seems like some common\nfunctionality to any type of scaling.  Also,\nbounds checking was previously done in both\nhandle_update and in adjust, and it seems like\nit could be done in just one place.\n\nChange-Id: I0f4c78df15d3d973394ccfa14178941d170c9944\n'}, {'number': 5, 'created': '2014-06-12 01:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cd6eb34bb0c9e7aac5b70193a329357a261adce1', 'message': 'Move calculating new capacity to a function\n\nThis is part of the refactoring to fix the \ninheritance hierarchy of AutoScaleResourceGroup.\nIn this case, attempting to move some common\nfunctionality out of the inheritance hierarchy\nentirely (perhaps to the heat/scaling module).\n\nCalculating the new capacity while taking\nmin/max constraints into account, seems like\nsome common functionality to any type of\nscaling.  This way, the extra bounds checking\nin handle_update can be eliminated as well.\n\nChange-Id: I0f4c78df15d3d973394ccfa14178941d170c9944\n'}, {'number': 6, 'created': '2014-07-02 20:33:48.000000000', 'files': ['heat/engine/resources/autoscaling.py', 'heat/tests/test_autoscaling.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7c3c8338c86b0f809352b58463bc2f0772429450', 'message': 'Move calculating new capacity to a function\n\nThis is part of the refactoring to fix the\ninheritance hierarchy of AutoScaleResourceGroup.\nIn this case, attempting to move some common\nfunctionality out of the inheritance hierarchy\nentirely (perhaps to the heat/scaling module).\n\nCalculating the new capacity while taking\nmin/max constraints into account, seems like\nsome common functionality to any type of\nscaling.  This way, the extra bounds checking\nin handle_update can be eliminated as well.\n\nChange-Id: I0f4c78df15d3d973394ccfa14178941d170c9944\n'}]",17,99470,7c3c8338c86b0f809352b58463bc2f0772429450,41,9,6,10048,,,0,"Move calculating new capacity to a function

This is part of the refactoring to fix the
inheritance hierarchy of AutoScaleResourceGroup.
In this case, attempting to move some common
functionality out of the inheritance hierarchy
entirely (perhaps to the heat/scaling module).

Calculating the new capacity while taking
min/max constraints into account, seems like
some common functionality to any type of
scaling.  This way, the extra bounds checking
in handle_update can be eliminated as well.

Change-Id: I0f4c78df15d3d973394ccfa14178941d170c9944
",git fetch https://review.opendev.org/openstack/heat refs/changes/70/99470/6 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/autoscaling.py', 'heat/tests/test_autoscaling.py']",2,62283171a1184591359e2784e27b282e7d0b8e55,new-capacity-refactor," self._stub_meta_expected(now, 'ExactCapacity : 1')"," self._stub_meta_expected(now, 'ExactCapacity : 2')",61,42
openstack%2Fnova~master~I040b2c87ad0a2be92f31264e293794d97c27c965,openstack/nova,master,I040b2c87ad0a2be92f31264e293794d97c27c965,Use v1 as default for cinder_catalog_info,MERGED,2014-08-08 16:35:13.000000000,2014-08-13 21:40:34.000000000,2014-08-13 21:40:31.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 360}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-08 16:35:13.000000000', 'files': ['nova/tests/test_cinder.py', 'nova/volume/cinder.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c55736d9fc941ae3f00a29e945b8881be7813e52', 'message': 'Use v1 as default for cinder_catalog_info\n\nIn c5402ef4fc509047d513a715a1c14e9b4ba9674f we recently\nadded support for the Cinder v2 client. This change modified\nthe default value of the cinder_catalog_info config such\nthat an end user who was previously using the Cinder V1\nAPI via the default config setting (by not setting it) would\nhave a broken Nova -> cinder configuration upon upgrade.\n\nWe should hold off on changing the default cinder_catalog_info\nfor one release to allow for proper deprecation.\n\nChange-Id: I040b2c87ad0a2be92f31264e293794d97c27c965\nCloses-bug: #1354499\n'}]",0,112970,c55736d9fc941ae3f00a29e945b8881be7813e52,42,13,1,360,,,0,"Use v1 as default for cinder_catalog_info

In c5402ef4fc509047d513a715a1c14e9b4ba9674f we recently
added support for the Cinder v2 client. This change modified
the default value of the cinder_catalog_info config such
that an end user who was previously using the Cinder V1
API via the default config setting (by not setting it) would
have a broken Nova -> cinder configuration upon upgrade.

We should hold off on changing the default cinder_catalog_info
for one release to allow for proper deprecation.

Change-Id: I040b2c87ad0a2be92f31264e293794d97c27c965
Closes-bug: #1354499
",git fetch https://review.opendev.org/openstack/nova refs/changes/70/112970/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_cinder.py', 'nova/volume/cinder.py']",2,c55736d9fc941ae3f00a29e945b8881be7813e52,cinder_catalog_info_default," default='volume:cinder:publicURL',"," default='volumev2:cinder:publicURL',",4,3
openstack%2Fkeystone~master~I3bb8eb2e1ae62753acadd34a539a6ece571e8913,openstack/keystone,master,I3bb8eb2e1ae62753acadd34a539a6ece571e8913,Remove _BaseFederationExtension,MERGED,2014-08-10 14:54:16.000000000,2014-08-13 21:40:27.000000000,2014-08-13 21:40:26.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-08-10 14:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c7de13932868e97cf06aa4d1f97e1c9bee88c28b', 'message': 'Remove __BaseFederationExtension.\n\nThis class is not needed at the moment as there is only one class that\ninherits from it.\n\nChange-Id: I3bb8eb2e1ae62753acadd34a539a6ece571e8913\n'}, {'number': 2, 'created': '2014-08-11 06:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ab9c22ce14b5ca052951a73d800185b0d2fa8247', 'message': 'Remove _BaseFederationExtension.\n\nThis class is not needed at the moment as there is only one class that\ninherits from it.\n\nChange-Id: I3bb8eb2e1ae62753acadd34a539a6ece571e8913\n'}, {'number': 3, 'created': '2014-08-13 18:31:21.000000000', 'files': ['keystone/contrib/federation/routers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0341cc116a7670e400351681ddee7d525f6cb0a3', 'message': 'Remove _BaseFederationExtension\n\nThis class is not needed at the moment as there is only one class that\ninherits from it.\n\nChange-Id: I3bb8eb2e1ae62753acadd34a539a6ece571e8913\n'}]",0,113136,0341cc116a7670e400351681ddee7d525f6cb0a3,25,9,3,8978,,,0,"Remove _BaseFederationExtension

This class is not needed at the moment as there is only one class that
inherits from it.

Change-Id: I3bb8eb2e1ae62753acadd34a539a6ece571e8913
",git fetch https://review.opendev.org/openstack/keystone refs/changes/36/113136/3 && git format-patch -1 --stdout FETCH_HEAD,['keystone/contrib/federation/routers.py'],1,c7de13932868e97cf06aa4d1f97e1c9bee88c28b,remove_base_router,"class FederationExtension(wsgi.ExtensionRouter): def _construct_url(self, suffix): return ""/OS-FEDERATION/%s"" % suffix ","class _BaseFederationExtension(wsgi.ExtensionRouter): """"""Base class for Federation Extension classes. All generic methods should be stored here so inheriting classes don't need to reimplement them. """""" def _construct_url(self, suffix): return ""/OS-FEDERATION/%s"" % suffix class FederationExtension(_BaseFederationExtension):",4,12
openstack%2Fzaqar~master~I512cce01e8280f4fcee6e6bd072d8af870b1c69b,openstack/zaqar,master,I512cce01e8280f4fcee6e6bd072d8af870b1c69b,Position Zaqar more as an SQS/SNS type service,ABANDONED,2014-08-13 18:45:03.000000000,2014-08-13 21:38:41.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-13 18:45:03.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b7a91e1f9813ccc2836c79e492054e970fea3d82', 'message': 'Position Zaqar more as an SQS/SNS type service\n\nThis patch modifies the developer doc intro so that it is clear we\nare not trying to replace oslo messaging, but that Zaqar provides\nsome neat features that can be used by other OS components to\nenable some interesting use cases.\n\nChange-Id: I512cce01e8280f4fcee6e6bd072d8af870b1c69b\n'}]",0,113990,b7a91e1f9813ccc2836c79e492054e970fea3d82,4,1,1,6427,,,0,"Position Zaqar more as an SQS/SNS type service

This patch modifies the developer doc intro so that it is clear we
are not trying to replace oslo messaging, but that Zaqar provides
some neat features that can be used by other OS components to
enable some interesting use cases.

Change-Id: I512cce01e8280f4fcee6e6bd072d8af870b1c69b
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/90/113990/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,b7a91e1f9813ccc2836c79e492054e970fea3d82,doc-rock-day,"Zaqar is a multi-tenant cloud messaging service. It combines the ideas pioneered by Amazon's SQS product with additional semantics to support event broadcasting. The service features a RESTful API, which developers can, for example, use to send messages between various components of their SaaS and mobile applications, by using a variety of communication patterns. Underlying this API is an efficient messaging engine designed with scalability and security in mind. Other OpenStack components can integrate with Zaqar to surface interesting events to end users and to communicate with guest agents that run in the ""over-cloud"" layer. Cloud operators can leverage Zaqar to provide equivalents of SQS and SNS to their customers.* Firewall-friendly, HTTP-based API with Keystone support * Multi-tenant queues based on Keystone project IDs","Zaqar is a multi-tenant cloud messaging and notification service for web and mobile developers. The service features a ReST API, which developers can use to send messages between various components of their SaaS and mobile applications, by using a variety of communication patterns. Underlying this API is an efficient messaging engine designed with scalability and security in mind. Other OpenStack components can integrate with Zaqar to surface events to end users and to communicate with guest agents that run in the ""over-cloud"" layer.* HTTP-based messaging API * Multi-tenant design based on Keystone project IDs",14,11
openstack%2Fdesignate~master~I798e0b91f2e515562188b5d14cd7ce2055bd64fb,openstack/designate,master,I798e0b91f2e515562188b5d14cd7ce2055bd64fb,Ensure Object change lists are sorted during to_primitive,MERGED,2014-08-05 01:54:47.000000000,2014-08-13 21:25:51.000000000,2014-08-13 21:25:50.000000000,"[{'_account_id': 3}, {'_account_id': 8094}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-08-05 01:54:47.000000000', 'files': ['designate/objects/base.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/6cf1c81a60e8f2e50cb530e45521c61999355ff8', 'message': 'Ensure Object change lists are sorted during to_primitive\n\nThis ensures our tests succeed with a random PYTHONHASHSEED value.\n\nChange-Id: I798e0b91f2e515562188b5d14cd7ce2055bd64fb\nPartial-Bug: 1348818\n'}]",0,111886,6cf1c81a60e8f2e50cb530e45521c61999355ff8,12,3,1,741,,,0,"Ensure Object change lists are sorted during to_primitive

This ensures our tests succeed with a random PYTHONHASHSEED value.

Change-Id: I798e0b91f2e515562188b5d14cd7ce2055bd64fb
Partial-Bug: 1348818
",git fetch https://review.opendev.org/openstack/designate refs/changes/86/111886/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/objects/base.py'],1,6cf1c81a60e8f2e50cb530e45521c61999355ff8,bug/1348818," 'designate_object.changes': sorted(self._obj_changes),"," 'designate_object.changes': list(self._obj_changes),",1,1
openstack%2Fdesignate~master~I6cc23ce083a7758efa9d34719ac89dfb135a4a42,openstack/designate,master,I6cc23ce083a7758efa9d34719ac89dfb135a4a42,Added policy checking for all all_tenent=True contexts,MERGED,2014-07-21 16:08:50.000000000,2014-08-13 21:11:54.000000000,2014-08-13 21:11:54.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}]","[{'number': 1, 'created': '2014-07-21 16:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/4798166d7dd07c6db54697e4225fb8a7d01f272f', 'message': 'Added policy checking for all all_tenent=True contexts\n\nChange-Id: I6cc23ce083a7758efa9d34719ac89dfb135a4a42\n'}, {'number': 2, 'created': '2014-08-11 15:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/0a4d85a76421c38343dee76cd5f579bd47b6b4ff', 'message': 'Added policy checking for all all_tenent=True contexts\n\nChange-Id: I6cc23ce083a7758efa9d34719ac89dfb135a4a42\n'}, {'number': 3, 'created': '2014-08-12 20:50:48.000000000', 'files': ['designate.sublime-project', 'designate/tests/test_context.py', 'designate/service.py', 'designate/central/service.py', 'designate/api/middleware.py', 'designate/api/service.py', 'designate/context.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/47e92c4da5e8bdbec2016fbad7921656e9722e96', 'message': 'Added policy checking for all all_tenent=True contexts\n\nChange-Id: I6cc23ce083a7758efa9d34719ac89dfb135a4a42\n'}]",0,108422,47e92c4da5e8bdbec2016fbad7921656e9722e96,15,3,3,8099,,,0,"Added policy checking for all all_tenent=True contexts

Change-Id: I6cc23ce083a7758efa9d34719ac89dfb135a4a42
",git fetch https://review.opendev.org/openstack/designate refs/changes/22/108422/3 && git format-patch -1 --stdout FETCH_HEAD,"['designate/service.py', 'designate/tests/test_context.py', 'designate/api/middleware.py', 'designate/context.py']",4,4798166d7dd07c6db54697e4225fb8a7d01f272f,all-tenents,"from designate import policy _all_tenants = False @property def all_tenants(self): return self._all_tenants @all_tenants.setter def all_tenants(self, value): if value: policy.check('all_tenants', self) self._all_tenants = value",,35,4
openstack%2Fapi-site~master~Idee8b70f16ef752043997b9dc04696f928883387,openstack/api-site,master,Idee8b70f16ef752043997b9dc04696f928883387,Add `nested_depth` param to resource-list docs,MERGED,2014-08-12 19:03:53.000000000,2014-08-13 21:09:08.000000000,2014-08-13 21:09:08.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 7253}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-08-12 19:03:53.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/8a12ed8f0c4ec4bd33fa910bd9eb7f45e9eebe5e', 'message': 'Add `nested_depth` param to resource-list docs\n\nImplements: blueprint explode-nested-resources\nChange-Id: Idee8b70f16ef752043997b9dc04696f928883387\n'}]",0,113615,8a12ed8f0c4ec4bd33fa910bd9eb7f45e9eebe5e,9,6,1,9189,,,0,"Add `nested_depth` param to resource-list docs

Implements: blueprint explode-nested-resources
Change-Id: Idee8b70f16ef752043997b9dc04696f928883387
",git fetch https://review.opendev.org/openstack/api-site refs/changes/15/113615/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'],1,8a12ed8f0c4ec4bd33fa910bd9eb7f45e9eebe5e,bp/explode-nested-resources," <request> <representation mediaType=""application/xml""> <param name=""nested_depth"" style=""query"" required=""false""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <para> Also includes resources from nested stacks up to <code>nested_depth</code> levels of recursion. </para> </wadl:doc> </param> </representation> </request>",,13,0
openstack%2Fsahara~master~I71b3cd21dcb9983fd6284a90316b12368481c700,openstack/sahara,master,I71b3cd21dcb9983fd6284a90316b12368481c700,Create etc/edp-examples directory,MERGED,2014-08-07 15:48:14.000000000,2014-08-13 21:03:08.000000000,2014-08-13 21:03:07.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-08-07 15:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/dfab26f9086f36f92b00e7584082ed650605b301', 'message': 'Create sahara/edp-examples directory\n\nMerge the edp examples and the integration test resources into\none directory.  This is part of the effort to move edp-examples\nout of the sahara-extra repo and eliminated duplication.\n\nThe integration tests have been changed to reference the new\nexamples directory, and an EDPJobInfo class has been added to\neliminate path and config value duplication between the tests.\n\nPartial-implements: blueprint edp-move-examples\nChange-Id: I71b3cd21dcb9983fd6284a90316b12368481c700\n'}, {'number': 2, 'created': '2014-08-07 17:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5c43b89eb6fd623fc3caf48140a62d2344f5b36a', 'message': 'Create sahara/edp-examples directory\n\nMerge content from sahara-extra/edp-examples and integration/tests/resources\ninto one directory under sahara/edp-examples. This is part of the effort to\nultimately move edp-examples out of the sahara-extra repo and eliminate duplication.\n\nThe integration tests have been changed to reference the new\nsahara/edp-examples directory, and an EDPJobInfo class has been added to\neliminate path and config value duplication between the tests.\n\nPartial-implements: blueprint edp-move-examples\nChange-Id: I71b3cd21dcb9983fd6284a90316b12368481c700\n'}, {'number': 3, 'created': '2014-08-11 20:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/470dc66663019844a0b67b893d748d99ac656bae', 'message': 'Create etc/edp-examples directory\n\nMerge content from sahara-extra/edp-examples and integration/tests/resources\ninto one directory under etc/edp-examples. This is part of the effort to\nultimately move edp-examples out of the sahara-extra repo and eliminate duplication.\n\nThe integration tests have been changed to reference the new\netc/edp-examples directory, and an EDPJobInfo class has been added to\neliminate path and config value duplication between the tests.\n\nPartial-implements: blueprint edp-move-examples\nChange-Id: I71b3cd21dcb9983fd6284a90316b12368481c700\n'}, {'number': 4, 'created': '2014-08-13 14:11:02.000000000', 'files': ['sahara/tests/integration/tests/resources/edp-lib.jar', 'etc/edp-examples/edp-java/oozie_command_line/wordcount/job.properties', 'etc/edp-examples/pig-job/data/expected_output', 'sahara/tests/integration/tests/gating/test_hdp_gating.py', 'sahara/tests/integration/tests/gating/test_vanilla_gating.py', 'sahara/tests/integration/tests/gating/test_hdp2_gating.py', 'sahara/tests/integration/tests/edp.py', 'etc/edp-examples/edp-java/oozie_command_line/README.rst', 'etc/edp-examples/pig-job/example.pig', 'etc/edp-examples/edp-java/src/NOTICE.txt', 'etc/edp-examples/edp-java/README.rst', 'etc/edp-examples/pig-job/data/input', 'sahara/tests/integration/tests/vanilla_transient_cluster.py', 'etc/edp-examples/hadoop2/edp-java/hadoop-mapreduce-examples-2.3.0.jar', 'etc/edp-examples/pig-job/udf.jar', 'etc/edp-examples/edp-mapreduce/edp-mapreduce.jar', 'sahara/tests/integration/tests/gating/test_cdh_gating.py', 'sahara/tests/integration/tests/gating/test_vanilla_two_gating.py', 'etc/edp-examples/edp-java/src/WordCount.java', 'sahara/tests/integration/tests/resources/edp-java/README', 'etc/edp-examples/edp-java/edp-java.jar', 'etc/edp-examples/pig-job/README.rst', 'etc/edp-examples/edp-java/oozie_command_line/wordcount/workflow.xml'], 'web_link': 'https://opendev.org/openstack/sahara/commit/90187b0322f708dea4ca8cbda80264331ac58d6d', 'message': 'Create etc/edp-examples directory\n\nMerge content from sahara-extra/edp-examples and integration/tests/resources\ninto one directory under etc/edp-examples. This is part of the effort to\nultimately move edp-examples out of the sahara-extra repo and eliminate duplication.\n\nThe integration tests have been changed to reference the new\netc/edp-examples directory, and an EDPJobInfo class has been added to\neliminate path and config value duplication between the tests.\n\nPartial-implements: blueprint edp-move-examples\nChange-Id: I71b3cd21dcb9983fd6284a90316b12368481c700\n'}]",0,112614,90187b0322f708dea4ca8cbda80264331ac58d6d,45,10,4,8091,,,0,"Create etc/edp-examples directory

Merge content from sahara-extra/edp-examples and integration/tests/resources
into one directory under etc/edp-examples. This is part of the effort to
ultimately move edp-examples out of the sahara-extra repo and eliminate duplication.

The integration tests have been changed to reference the new
etc/edp-examples directory, and an EDPJobInfo class has been added to
eliminate path and config value duplication between the tests.

Partial-implements: blueprint edp-move-examples
Change-Id: I71b3cd21dcb9983fd6284a90316b12368481c700
",git fetch https://review.opendev.org/openstack/sahara refs/changes/14/112614/4 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/tests/integration/tests/resources/edp-lib.jar', 'sahara/edp-examples/pig-job/example.pig', 'sahara/tests/integration/tests/gating/test_hdp_gating.py', 'sahara/tests/integration/tests/gating/test_vanilla_gating.py', 'sahara/tests/integration/tests/gating/test_hdp2_gating.py', 'sahara/edp-examples/edp-java/edp-java.jar', 'sahara/tests/integration/tests/edp.py', 'sahara/edp-examples/edp-java/README', 'sahara/edp-examples/pig-job/data/expected_output', 'sahara/edp-examples/hadoop2/edp-java/hadoop-mapreduce-examples-2.3.0.jar', 'sahara/tests/integration/tests/vanilla_transient_cluster.py', 'sahara/edp-examples/pig-job/README.rst', 'sahara/edp-examples/pig-job/udf.jar', 'sahara/tests/integration/tests/gating/test_cdh_gating.py', 'sahara/tests/integration/tests/gating/test_vanilla_two_gating.py', 'sahara/edp-examples/edp-mapreduce/edp-mapreduce.jar', 'sahara/edp-examples/edp-java/src/WordCount.java', 'sahara/edp-examples/pig-job/data/input']",18,dfab26f9086f36f92b00e7584082ed650605b301,bp/edp-move-examples, pomegranate banana apple lychee,,121,158
openstack%2Fkeystone~master~Ib61f9c4c9727eb5e81b7c71102133ef000be395d,openstack/keystone,master,Ib61f9c4c9727eb5e81b7c71102133ef000be395d,Add a URL field to region table,MERGED,2014-07-15 05:49:17.000000000,2014-08-13 21:03:05.000000000,2014-08-13 21:03:04.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8571}, {'_account_id': 8978}, {'_account_id': 9101}, {'_account_id': 11022}, {'_account_id': 11045}, {'_account_id': 11333}, {'_account_id': 11387}, {'_account_id': 12215}]","[{'number': 1, 'created': '2014-07-15 05:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ba0747f4befabfa7c18e23155a15077bd7be3e8d', 'message': 'Add a URL field to region table\n\nAllow a URL to be associated with a certain region.\n\nimplements bp keystone-to-keystone-federation\n\nChange-Id: Ib61f9c4c9727eb5e81b7c71102133ef000be395d\n'}, {'number': 2, 'created': '2014-07-25 04:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/acafa68d41fffeca31e1455a180a1f585b9e006a', 'message': 'Add a URL field to region table\n\nAllow a URL to be associated with a certain region.\n\nimplements bp keystone-to-keystone-federation\n\nChange-Id: Ib61f9c4c9727eb5e81b7c71102133ef000be395d\n'}, {'number': 3, 'created': '2014-07-25 04:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/25c5b5e20497cd574ab9c4501799530974b66517', 'message': 'Add a URL field to region table\n\nAllow a URL to be associated with a certain region.\n\nimplements bp keystone-to-keystone-federation\n\nChange-Id: Ib61f9c4c9727eb5e81b7c71102133ef000be395d\n'}, {'number': 4, 'created': '2014-08-11 19:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/079b77947080b5a28687b74ad206ec4af44f7a01', 'message': 'Add a URL field to region table\n\nAllow a URL to be associated with a certain region.\n\nimplements bp keystone-to-keystone-federation\n\nChange-Id: Ib61f9c4c9727eb5e81b7c71102133ef000be395d\n'}, {'number': 5, 'created': '2014-08-12 03:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1718a98de6173e17fcb0ac8b95d3cc85a9ba5fb7', 'message': 'Add a URL field to region table\n\nAllow a URL to be associated with a certain region.\n\nimplements bp keystone-to-keystone-federation\n\nChange-Id: Ib61f9c4c9727eb5e81b7c71102133ef000be395d\n'}, {'number': 6, 'created': '2014-08-13 14:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a99d45ba2af4b4f65b5f82e1192bbb3e938c2764', 'message': 'Add a URL field to region table\n\nAllow a URL to be associated with a certain region.\n\nimplements bp keystone-to-keystone-federation\n\nChange-Id: Ib61f9c4c9727eb5e81b7c71102133ef000be395d\n'}, {'number': 7, 'created': '2014-08-13 16:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/acae383707d09f3fe9c959e115887fc520885710', 'message': 'Add a URL field to region table\n\nAllow a URL to be associated with a certain region.\n\nimplements bp keystone-to-keystone-federation\n\nChange-Id: Ib61f9c4c9727eb5e81b7c71102133ef000be395d\n'}, {'number': 8, 'created': '2014-08-13 17:10:34.000000000', 'files': ['keystone/tests/test_v3_catalog.py', 'keystone/catalog/backends/kvs.py', 'keystone/catalog/backends/sql.py', 'keystone/common/sql/migrate_repo/versions/052_add_auth_url_to_region.py', 'keystone/tests/test_sql_upgrade.py', 'keystone/tests/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/327f733d498a7ff9a442352d79e7c85e8530fb83', 'message': 'Add a URL field to region table\n\nAllow a URL to be associated with a certain region.\n\nimplements bp keystone-to-keystone-federation\n\nChange-Id: Ib61f9c4c9727eb5e81b7c71102133ef000be395d\n'}]",13,106935,327f733d498a7ff9a442352d79e7c85e8530fb83,60,13,8,6482,,,0,"Add a URL field to region table

Allow a URL to be associated with a certain region.

implements bp keystone-to-keystone-federation

Change-Id: Ib61f9c4c9727eb5e81b7c71102133ef000be395d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/35/106935/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_v3_catalog.py', 'keystone/catalog/backends/sql.py', 'keystone/common/sql/migrate_repo/versions/052_add_auth_url_to_region.py']",3,ba0747f4befabfa7c18e23155a15077bd7be3e8d,bp/keystone-to-keystone-federation,"# Copyright 2014 IBM Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import sqlalchemy as sql _REGION_TABLE_NAME = 'region' def upgrade(migrate_engine): meta = sql.MetaData() meta.bind = migrate_engine region_table = sql.Table(_REGION_TABLE_NAME, meta, autoload=True) url_column = sql.Column('url', sql.String(255), nullable=True) region_table.create_column(url_column) def downgrade(migrate_engine): meta = sql.MetaData() meta.bind = migrate_engine region_table = sql.Table(_REGION_TABLE_NAME, meta, autoload=True) # delete regions with an auth url, since they are likely external d = region_table.delete(region_table.c.url is not None) d.execute() region_table.drop_column('url') ",,58,1
openstack%2Fkeystone~master~I59f8d852870bd3ad26622bfcd00dfadfdf9d5b42,openstack/keystone,master,I59f8d852870bd3ad26622bfcd00dfadfdf9d5b42,Filter List Regions by 'parent_region_id',MERGED,2014-08-01 08:42:20.000000000,2014-08-13 21:03:01.000000000,2014-08-13 21:03:00.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 10873}, {'_account_id': 11717}, {'_account_id': 12215}]","[{'number': 1, 'created': '2014-08-01 08:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/13e6a6492cfca40192dc5a06cdf69965b00e4ad3', 'message': ""Filter List Regions by 'parent_region_id'\n\nList Regions (GET /regions) has an optional query parameter\n'parent_region_id', but the API still returns all the regions.\n\nThis fix adds support of filtering regions by an optional query\nparameter 'parent_region_id'.\n\nCloses-Bug: #1350192\n\nChange-Id: I59f8d852870bd3ad26622bfcd00dfadfdf9d5b42\n""}, {'number': 2, 'created': '2014-08-01 14:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d1755eeb39e6dbafbe375df11c16e52fa46b2dbb', 'message': ""Filter List Regions by 'parent_region_id'\n\nList Regions (GET /regions) has an optional query parameter\n'parent_region_id', but the API still returns all the regions.\n\nThis fix adds support of filtering regions by an optional query\nparameter 'parent_region_id'.\n\nCloses-Bug: #1350192\n\nChange-Id: I59f8d852870bd3ad26622bfcd00dfadfdf9d5b42\n""}, {'number': 3, 'created': '2014-08-01 18:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9fa1b1d248adb5642fb18a296d6389c5b65aeaeb', 'message': ""Filter List Regions by 'parent_region_id'\n\nList Regions (GET /regions) has an optional query parameter\n'parent_region_id', but the API still returns all the regions.\n\nThis fix adds support of filtering regions by an optional query\nparameter 'parent_region_id'.\n\nCloses-Bug: #1350192\n\nChange-Id: I59f8d852870bd3ad26622bfcd00dfadfdf9d5b42\n""}, {'number': 4, 'created': '2014-08-02 07:27:22.000000000', 'files': ['keystone/tests/test_backend_templated.py', 'keystone/tests/test_v3_catalog.py', 'keystone/tests/test_backend_kvs.py', 'keystone/catalog/backends/kvs.py', 'keystone/catalog/backends/sql.py', 'keystone/catalog/core.py', 'keystone/tests/test_backend.py', 'keystone/catalog/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c9f6863c4c4f595678a6ae8db3af13e40f58b403', 'message': ""Filter List Regions by 'parent_region_id'\n\nList Regions (GET /regions) has an optional query parameter\n'parent_region_id', but the API still returns all the regions.\n\nThis fix adds support of filtering regions by an optional query\nparameter 'parent_region_id'.\n\nCloses-Bug: #1350192\n\nChange-Id: I59f8d852870bd3ad26622bfcd00dfadfdf9d5b42\n""}]",19,111200,c9f6863c4c4f595678a6ae8db3af13e40f58b403,34,9,4,12215,,,0,"Filter List Regions by 'parent_region_id'

List Regions (GET /regions) has an optional query parameter
'parent_region_id', but the API still returns all the regions.

This fix adds support of filtering regions by an optional query
parameter 'parent_region_id'.

Closes-Bug: #1350192

Change-Id: I59f8d852870bd3ad26622bfcd00dfadfdf9d5b42
",git fetch https://review.opendev.org/openstack/keystone refs/changes/00/111200/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_v3_catalog.py', 'keystone/catalog/backends/kvs.py', 'keystone/catalog/backends/sql.py', 'keystone/catalog/controllers.py']",4,13e6a6492cfca40192dc5a06cdf69965b00e4ad3,bug/1350192," @controller.filterprotected('parent_region_id') def list_regions(self, context, filters): hints = RegionV3.build_driver_hints(context, filters) refs = self.catalog_api.list_regions(hints) return RegionV3.wrap_collection(context, refs, hints=hints)"," @controller.protected() def list_regions(self, context): refs = self.catalog_api.list_regions() return RegionV3.wrap_collection(context, refs)",29,7
openstack%2Fpython-novaclient~master~I5c8fca8207032814b96b8410213bf58209d9b526,openstack/python-novaclient,master,I5c8fca8207032814b96b8410213bf58209d9b526,Fix listing of flavor-list (V1_1) to display swap value,MERGED,2014-08-10 06:30:34.000000000,2014-08-13 21:02:58.000000000,2014-08-13 21:02:57.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-08-10 06:30:34.000000000', 'files': ['novaclient/v1_1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/53be1f4e2a3ea9a12d25951cf6ab541e0beddcbf', 'message': 'Fix listing of flavor-list (V1_1) to display swap value\n\nCurrent version of flavor-list(v1_1 API) does not show\nswap value because of selecting wrong field name. This\nchange displays swap value in the same way to v3 API\n\nCloses-Bug: 1354546\nChange-Id: I5c8fca8207032814b96b8410213bf58209d9b526\n'}]",0,113115,53be1f4e2a3ea9a12d25951cf6ab541e0beddcbf,11,4,1,5735,,,0,"Fix listing of flavor-list (V1_1) to display swap value

Current version of flavor-list(v1_1 API) does not show
swap value because of selecting wrong field name. This
change displays swap value in the same way to v3 API

Closes-Bug: 1354546
Change-Id: I5c8fca8207032814b96b8410213bf58209d9b526
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/15/113115/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/shell.py'],1,53be1f4e2a3ea9a12d25951cf6ab541e0beddcbf,bug/1354546," 'Swap',"," 'Swap_MB',",1,1
openstack%2Fpython-heatclient~master~I97817b8c6d8bef71c4f237be864d1e79dc09098c,openstack/python-heatclient,master,I97817b8c6d8bef71c4f237be864d1e79dc09098c,Update theme for docs,MERGED,2014-07-24 22:10:13.000000000,2014-08-13 21:02:55.000000000,2014-08-13 21:02:54.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6482}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6899}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-07-24 22:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/a35e46071f2231ae1f5bf5df7ff8e501f53c4277', 'message': 'Update theme for docs\n\nThe current developer docs theme used is out of sync with the other\nopenstack projects. This patch will update the docs to provide a more\nconsistent look and feel when using developer docs\n\nChange-Id: I97817b8c6d8bef71c4f237be864d1e79dc09098c\n'}, {'number': 2, 'created': '2014-07-25 01:24:42.000000000', 'files': ['test-requirements.txt', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/884ad37d8a2556e8e16177b31228e6f31c1b1b77', 'message': 'Update theme for docs\n\nThe current developer docs theme used is out of sync with the other\nopenstack projects. This patch will update the docs to provide a more\nconsistent look and feel when using developer docs\n\nChange-Id: I97817b8c6d8bef71c4f237be864d1e79dc09098c\n'}]",0,109434,884ad37d8a2556e8e16177b31228e6f31c1b1b77,24,20,2,6482,,,0,"Update theme for docs

The current developer docs theme used is out of sync with the other
openstack projects. This patch will update the docs to provide a more
consistent look and feel when using developer docs

Change-Id: I97817b8c6d8bef71c4f237be864d1e79dc09098c
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/34/109434/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/default.css', 'doc/source/_theme/theme.conf', 'doc/source/_static/header_bg.jpg', 'doc/source/_theme/layout.html', 'doc/source/_static/header-line.gif', 'doc/source/_static/nature.css', 'doc/source/_static/tweaks.css', 'doc/source/_static/basic.css', 'doc/source/_static/jquery.tweet.js', 'doc/source/_static/openstack_logo.png', 'doc/source/conf.py']",11,a35e46071f2231ae1f5bf5df7ff8e501f53c4277,update_theme,html_theme_path = ['.'] html_theme = '_theme'html_static_path = ['_static'],# html_theme_path = ['.'] # html_theme = '_theme'# html_static_path = ['_static'],1229,3
openstack%2Fglance~master~I6910b55de8c3b203560d75ff3d1675eda31ae786,openstack/glance,master,I6910b55de8c3b203560d75ff3d1675eda31ae786,Adding status field to image location -- scrubber queue switching,MERGED,2014-01-09 09:20:27.000000000,2014-08-13 21:02:52.000000000,2014-08-13 21:02:51.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 7884}, {'_account_id': 8127}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9751}, {'_account_id': 10585}]","[{'number': 1, 'created': '2014-01-09 09:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7fe6a449c8957c6d68135c00cd19944a066ffa40', 'message': 'Using Database to support image pending deleting\n\nChange Glance to store image pending delete job into central DB instead\nlocal file.\n\nThis change allow cloud admin/operator deploy a central Scrubber\nservice(s) on one or two hosts only, before this Glance require deploy\nit on each API service host since Scrubber only support load pending\ndelete jobs from local file.\n\nImplement bp: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2014-01-13 12:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/38ed68d73e5542b390361b5bb13a2c598d0c3463', 'message': 'Using Database to support image pending deleting\n\nChange Glance to store image pending delete job into central DB instead\nlocal file.\n\nThis change allow cloud admin/operator deploy a central Scrubber\nservice(s) on one or two hosts only, before this Glance require deploy\nit on each API service host since Scrubber only support load pending\ndelete jobs from local file.\n\nImplement bp: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 4, 'created': '2014-01-13 12:03:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9c3aabb79e3137bbe8126c3011e49541ac4a8d4d', 'message': 'Using Database to support image pending deleting\n\nChange Glance to store image pending delete job into central DB instead\nof local file.\n\nThis change allow cloud admin/operator deploy a central Scrubber\nservice(s) on one or two hosts only, before this Glance require deploy\nit on each API service host since Scrubber only support load pending\ndelete jobs from local file.\n\nImplement bp: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 3, 'created': '2014-01-13 12:03:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1a2da7c8913c65c6e54dc4c47d27898c71081673', 'message': 'Using Database to support image pending deleting\n\nChange Glance to store image pending delete job into central DB instead\nof local file.\n\nThis change allow cloud admin/operator deploy a central Scrubber\nservice(s) on one or two hosts only, before this Glance require deploy\nit on each API service host since Scrubber only support load pending\ndelete jobs from local file.\n\nImplement bp: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 5, 'created': '2014-01-16 11:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/45e3dd78f5fffc52d694c14d170c3a35e890fd7d', 'message': ""Adding status field to image location\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 6, 'created': '2014-04-29 05:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d46808122abc8d115cc5cb842d13922b23a3547c', 'message': ""Adding status field to image location -- scrubber DB queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 7, 'created': '2014-05-05 09:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/729fecf7e4eaabee2ecf16ac2081d1e1c28aba09', 'message': ""Adding status field to image location -- scrubber DB queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 8, 'created': '2014-05-05 09:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/533243b183e55304ebb2495c8dbbcaa91d9e0c77', 'message': ""Adding status field to image location -- scrubber queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 9, 'created': '2014-05-29 14:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1a438c9ed3853dce7a9dbd3a01f4e7ab1283b6f9', 'message': ""Adding status field to image location -- scrubber queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 10, 'created': '2014-06-30 11:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/be0b91bf0f7c5e185eb15a2fab1265139ac7b6bd', 'message': ""Adding status field to image location -- scrubber queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 11, 'created': '2014-07-02 16:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/90a6788458f906dd07b201aa0f670d539b3cee14', 'message': ""Adding status field to image location -- scrubber queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 12, 'created': '2014-07-04 08:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6fc94108f815c226b69d0effe1f7d99353a5e12b', 'message': ""Adding status field to image location -- scrubber queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 13, 'created': '2014-07-11 08:35:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0b1b9d0aa2abe00b8a286cf7ec494bfd2d683de5', 'message': ""Adding status field to image location -- scrubber queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 14, 'created': '2014-07-17 05:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3951acf218fcfb60f3db8f6c9505c11bcffa314c', 'message': ""Adding status field to image location -- scrubber queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 15, 'created': '2014-07-21 06:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/be2aa0b35cc24ef5d3b6ca575baed8effbb5253b', 'message': ""Adding status field to image location -- scrubber queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 16, 'created': '2014-08-11 03:04:30.000000000', 'files': ['glance/common/store_utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f338a5c870a36e493f8c818fa783942d1e0565a4', 'message': ""Adding status field to image location -- scrubber queue switching\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is fourth part of this change which covered using scrubber DB queue\nin store. This change allow cloud admin/operator deploy a central\nScrubber service(s) on one or two hosts only, before this Glance require\ndeploy it on each API service host since Scrubber only support load\npending delete jobs from local file.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}]",5,65641,f338a5c870a36e493f8c818fa783942d1e0565a4,106,11,16,6549,,,0,"Adding status field to image location -- scrubber queue switching

Adding a status field to image's each location property, each location
status can be 'active', 'pending_delete' and 'deleted'.

Under location's status information Scrubber service can make cleanup
based on DB records also but not a dedicated queue-file for each image.

This is fourth part of this change which covered using scrubber DB queue
in store. This change allow cloud admin/operator deploy a central
Scrubber service(s) on one or two hosts only, before this Glance require
deploy it on each API service host since Scrubber only support load
pending delete jobs from local file.

Partially-Implements BP: image-location-status

Change-Id: I6910b55de8c3b203560d75ff3d1675eda31ae786
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/41/65641/16 && git format-patch -1 --stdout FETCH_HEAD,['glance/common/store_utils.py'],1,7fe6a449c8957c6d68135c00cd19944a066ffa40,," (_file_queue, db_queue) = scrubber.get_scrub_queues() ret = db_queue.add_location(image_id, location)"," (file_queue, _db_queue) = scrubber.get_scrub_queues() # TODO(zhiyan): using location status to do image scrub. ret = file_queue.add_location(image_id, location)",2,3
openstack-attic%2Fobject-api~master~I6ddb330bedfdd64faf1d7953e988866045da3a0e,openstack-attic/object-api,master,I6ddb330bedfdd64faf1d7953e988866045da3a0e,Removes WADL references from Object Storage API v1.0 dev ref,MERGED,2014-08-08 16:01:51.000000000,2014-08-13 21:02:00.000000000,2014-08-13 21:02:00.000000000,"[{'_account_id': 3}, {'_account_id': 2448}]","[{'number': 1, 'created': '2014-08-08 16:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/object-api/commit/9083feef1c1468b183e1391c31c0bbff8aafa2db', 'message': 'Removes WADL references from Object Storage API v1.0 dev ref\n\nChange-Id: I6ddb330bedfdd64faf1d7953e988866045da3a0e\n'}, {'number': 2, 'created': '2014-08-08 19:29:26.000000000', 'files': ['v1/ch_object-api-operations.xml', 'v1/pom.xml', 'v1/section_object-api-overview.xml', 'pom.xml'], 'web_link': 'https://opendev.org/openstack-attic/object-api/commit/82747f0622aee140c16de2a5af3a6831d3ed5159', 'message': 'Removes WADL references from Object Storage API v1.0 dev ref\n\nChange-Id: I6ddb330bedfdd64faf1d7953e988866045da3a0e\n'}]",0,112960,82747f0622aee140c16de2a5af3a6831d3ed5159,12,2,2,964,,,0,"Removes WADL references from Object Storage API v1.0 dev ref

Change-Id: I6ddb330bedfdd64faf1d7953e988866045da3a0e
",git fetch https://review.opendev.org/openstack-attic/object-api refs/changes/60/112960/1 && git format-patch -1 --stdout FETCH_HEAD,['v1/ch_object-api-operations.xml'],1,9083feef1c1468b183e1391c31c0bbff8aafa2db,removes-wadl-refs," <para>For information about Object Storage API operations, see <link xlink:href=""http://developer.openstack.org/api-ref-objectstorage-v1.html"" ><citetitle>Object Storage API v1.0 (CURRENT)</citetitle></link>.</para>"," <section xml:id=""storage_account_services""> <title>Accounts</title> <para>List containers for a specified account. Create, update, and delete account metadata. Show account metadata.</para> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/object-api/src/os-object-api-1.0.wadl#account""> <wadl:method href=""#showAccountDetails""/> <wadl:method href=""#updateAccountMeta""/> <wadl:method href=""#showAccountMeta""/> </wadl:resource> </wadl:resources> </section> <section xml:id=""storage_container_services""> <title>Containers</title> <para>List objects in a specified container. Create, show details for, and delete containers. Create, update, show, and delete container metadata.</para> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/object-api/src/os-object-api-1.0.wadl#container""> <wadl:method href=""#showContainerDetails""/> <wadl:method href=""#createContainer""/> <wadl:method href=""#deleteContainer""/> <wadl:method href=""#updateContainerMeta""/> <wadl:method href=""#showContainerMeta""/> </wadl:resource> </wadl:resources> </section> <section xml:id=""storage_object_services""> <title>Objects</title> <para>Create, replace, show details for, and delete objects. Copy objects with another object with a new or different name. Update object metadata.</para> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/object-api/src/os-object-api-1.0.wadl#object""> <wadl:method href=""#getObject""/> <wadl:method href=""#createOrReplaceObject""/> <wadl:method href=""#copyObject""/> <wadl:method href=""#deleteObject""/> <wadl:method href=""#showObjectMeta""/> <wadl:method href=""#updateObjectMeta""/> </wadl:resource> </wadl:resources> </section>",3,46
openstack%2Fmanila~master~I61afd92fe386c784a3ae1e83916dabf097ce61d2,openstack/manila,master,I61afd92fe386c784a3ae1e83916dabf097ce61d2,Fix share status waiter within tempest,MERGED,2014-08-07 10:19:41.000000000,2014-08-13 21:00:02.000000000,2014-08-13 21:00:02.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-08-07 10:19:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f897378cabdc548b3bf8775e97bec7afe363bcee', 'message': ""Fix share status waiter within tempest\n\nMethod 'wait_for_share_status' can expect any status for waiting, but now,\nif we expect 'error' or 'error_deleting' statuses we will get exception raised,\nbut should not, because it is expected.\n\nChange-Id: I61afd92fe386c784a3ae1e83916dabf097ce61d2\n""}, {'number': 2, 'created': '2014-08-13 06:40:13.000000000', 'files': ['contrib/tempest/tempest/services/share/json/shares_client.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/148265bea499bf241768bdc601ba8664addd5d35', 'message': ""Fix share status waiter within tempest\n\nMethod 'wait_for_share_status' can expect any status for waiting, but now,\nif we expect 'error' or 'error_deleting' statuses we will get exception raised,\nbut should not, because it is expected.\n\nChange-Id: I61afd92fe386c784a3ae1e83916dabf097ce61d2\n""}]",0,112544,148265bea499bf241768bdc601ba8664addd5d35,13,4,2,8851,,,0,"Fix share status waiter within tempest

Method 'wait_for_share_status' can expect any status for waiting, but now,
if we expect 'error' or 'error_deleting' statuses we will get exception raised,
but should not, because it is expected.

Change-Id: I61afd92fe386c784a3ae1e83916dabf097ce61d2
",git fetch https://review.opendev.org/openstack/manila refs/changes/44/112544/2 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/services/share/json/shares_client.py'],1,f897378cabdc548b3bf8775e97bec7afe363bcee,tempest, if share_status == status: return elif 'error' in share_status:, if 'error' in share_status:,3,1
openstack%2Fmanila~master~I967a48481b79c9e80eb57806fc103704db209bb4,openstack/manila,master,I967a48481b79c9e80eb57806fc103704db209bb4,Fix update of share with share-server-id,MERGED,2014-08-04 18:06:54.000000000,2014-08-13 20:59:56.000000000,2014-08-13 20:59:56.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 6529}]","[{'number': 1, 'created': '2014-08-04 18:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/dd262ff79c085020849f8a40b9cdd3eff04dd557', 'message': ""Fix update of share with share-server-id\n\nIf for some reason share server was not created and fell to 'ERROR' state,\nthen share will not get share-server-id. This causes impossibility\nto delete this share and failed share-server, because of share-dependency.\n\nChange-Id: I967a48481b79c9e80eb57806fc103704db209bb4\nCloses-Bug: #1352424\n""}, {'number': 2, 'created': '2014-08-04 18:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cad4acd7f2b8af890d8e7561473a4de2778b8493', 'message': ""Fix update of share with share-server-id\n\nIf for some reason share server was not created and fell to 'ERROR' state,\nthen share will not get share-server-id. This causes impossibility\nto delete this share and failed share-server, because of share-dependency.\n\nChange-Id: I967a48481b79c9e80eb57806fc103704db209bb4\nCloses-Bug: #1352424\n""}, {'number': 3, 'created': '2014-08-04 18:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ce5193f216a6abc564275f86363fac2325f50c74', 'message': ""Fix update of share with share-server-id\n\nIf for some reason share server was not created and fell to 'ERROR' state,\nthen share will not get share-server-id. This causes impossibility\nto delete this share and failed share-server, because of share-dependency.\n\nChange-Id: I967a48481b79c9e80eb57806fc103704db209bb4\nCloses-Bug: #1352424\n""}, {'number': 4, 'created': '2014-08-05 05:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/afc292dd61ea30c7bc3b5625cd174a8473352ec2', 'message': ""Fix update of share with share-server-id\n\nIf for some reason share server was not created and fell to 'ERROR' state,\nthen share will not get share-server-id. This causes impossibility\nto delete this share and failed share-server, because of share-dependency.\n\nChange-Id: I967a48481b79c9e80eb57806fc103704db209bb4\nCloses-Bug: #1352424\n""}, {'number': 5, 'created': '2014-08-05 10:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/92a36361359d3b02fea862b5b947309ecccea92f', 'message': ""Fix update of share with share-server-id\n\nIf for some reason share server was not created and fell to 'ERROR' state,\nthen share will not get share-server-id. This causes impossibility\nto delete this share and failed share-server, because of share-dependency.\n\nChange-Id: I967a48481b79c9e80eb57806fc103704db209bb4\nCloses-Bug: #1352424\n""}, {'number': 6, 'created': '2014-08-05 11:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0850f7b0bb4be1480b924b72d8774cfe90868545', 'message': ""Fix update of share with share-server-id\n\nIf for some reason share server was not created and fell to 'ERROR' state,\nthen share will not get share-server-id. This causes impossibility\nto delete this share and failed share-server, because of share-dependency.\n\nChange-Id: I967a48481b79c9e80eb57806fc103704db209bb4\nCloses-Bug: #1352424\n""}, {'number': 7, 'created': '2014-08-07 10:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6f2df9145fb2960d8863259b7fed6405c6dbe398', 'message': ""Fix update of share with share-server-id\n\nIf for some reason share server was not created and fell to 'ERROR' state, then\nshare will not get share-server-id. We should know what server was expected\nto be used with each share.\n\nChange-Id: I967a48481b79c9e80eb57806fc103704db209bb4\nCloses-Bug: #1352424\n""}, {'number': 8, 'created': '2014-08-13 06:37:56.000000000', 'files': ['manila/tests/test_share.py', 'manila/share/manager.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/82d30f625a9afc92acd6fa4029dc6fee6b9e6737', 'message': ""Fix update of share with share-server-id\n\nIf for some reason share server was not created and fell to 'ERROR' state, then\nshare will not get share-server-id. We should know what server was expected\nto be used with each share.\n\nChange-Id: I967a48481b79c9e80eb57806fc103704db209bb4\nCloses-Bug: #1352424\n""}]",0,111788,82d30f625a9afc92acd6fa4029dc6fee6b9e6737,37,4,8,8851,,,0,"Fix update of share with share-server-id

If for some reason share server was not created and fell to 'ERROR' state, then
share will not get share-server-id. We should know what server was expected
to be used with each share.

Change-Id: I967a48481b79c9e80eb57806fc103704db209bb4
Closes-Bug: #1352424
",git fetch https://review.opendev.org/openstack/manila refs/changes/88/111788/8 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/test_share.py', 'manila/share/manager.py']",2,dd262ff79c085020849f8a40b9cdd3eff04dd557,bug/1352424," exist = False exist = True except exception.ShareServerNotFound: share_server = self.db.share_server_create( context, { 'host': self.host, 'share_network_id': share_network_id, 'status': constants.STATUS_CREATING } ) LOG.debug(""Using share_server %s for share %s"" % ( share_server['id'], share_id)) if not exist: # Create share server on backend with data from db share_server = self._setup_server(context, share_server) LOG.info(_(""Share server created successfully."")) else: LOG.info(_(""Used already existed share server '%(share_server"" ""_id)s'"") % {'share_server_id': share_server['id']}) LOG.error(_(""Failed to get share serve"" def _setup_server(self, context, share_server, metadata=None): share_network = self.db.share_network_get( context, share_server['share_network_id'])"," except exception.ShareServerNotFound: share_network = self.db.share_network_get( context, share_network_id) share_server = self._setup_server(context, share_network) LOG.info(_(""Share server created successfully."")) LOG.debug(""Using share_server "" ""%s for share %s"" % (share_server['id'], share_id)) LOG.error(_(""Failed to get share server"" def _setup_server(self, context, share_network, metadata=None): share_server_val = { 'host': self.host, 'share_network_id': share_network['id'], 'status': constants.STATUS_CREATING } share_server = self.db.share_server_create(context, share_server_val) share_network = self.db.share_network_get(context, share_network['id'])",86,24
openstack%2Fpython-manilaclient~master~Ib41250d527c5949cdfb7c6956703ff4b371a062b,openstack/python-manilaclient,master,Ib41250d527c5949cdfb7c6956703ff4b371a062b,Cleanup manilaclient.utils module (part 2),MERGED,2014-07-15 12:40:41.000000000,2014-08-13 20:50:47.000000000,2014-08-13 20:50:47.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 6529}, {'_account_id': 7534}, {'_account_id': 8851}, {'_account_id': 11878}]","[{'number': 1, 'created': '2014-07-15 12:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/94e073da8a117935298b8e7427947d64f04bc21e', 'message': ""Cleanup manilaclient.utils module (part 2)\n\nRemove functions 'arg', 'env' and 'add_arg' from\nmanilaclient.utils and use same functions from cliutils instead.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: Ib41250d527c5949cdfb7c6956703ff4b371a062b\n""}, {'number': 2, 'created': '2014-07-21 13:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/6c3410ffb711bd9e92998f9617e94e70289c1a95', 'message': ""Cleanup manilaclient.utils module (part 2)\n\nRemove functions 'arg', 'env' and 'add_arg' from\nmanilaclient.utils and use same functions from cliutils instead.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: Ib41250d527c5949cdfb7c6956703ff4b371a062b\n""}, {'number': 3, 'created': '2014-08-04 14:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/cc87e39cea81bbf4956b244de0d309efd9405b5e', 'message': ""Cleanup manilaclient.utils module (part 2)\n\nRemove functions 'arg', 'env' and 'add_arg' from\nmanilaclient.utils and use same functions from cliutils instead.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: Ib41250d527c5949cdfb7c6956703ff4b371a062b\n""}, {'number': 4, 'created': '2014-08-04 15:06:38.000000000', 'files': ['manilaclient/base.py', 'manilaclient/shell.py', 'manilaclient/v1/shell.py', 'manilaclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/4a7e7cf089469a10ec6e71b20b34923b25f43d33', 'message': ""Cleanup manilaclient.utils module (part 2)\n\nRemove functions 'arg', 'env' and 'add_arg' from\nmanilaclient.utils and use same functions from cliutils instead.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: Ib41250d527c5949cdfb7c6956703ff4b371a062b\n""}]",0,107034,4a7e7cf089469a10ec6e71b20b34923b25f43d33,29,7,4,8851,,,0,"Cleanup manilaclient.utils module (part 2)

Remove functions 'arg', 'env' and 'add_arg' from
manilaclient.utils and use same functions from cliutils instead.

Partially implements: blueprint use-common-code

Change-Id: Ib41250d527c5949cdfb7c6956703ff4b371a062b
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/34/107034/1 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/base.py', 'manilaclient/shell.py', 'manilaclient/utils.py', 'manilaclient/v1/shell.py']",4,94e073da8a117935298b8e7427947d64f04bc21e,bp/use-common-code,"@cliutils.arg( '--tenant', metavar='<tenant-id>', default=None, help='ID of tenant to list the quotas for.') @cliutils.arg( '--user', metavar='<user-id>', default=None, help='ID of user to list the quotas for.')@cliutils.arg( '--tenant', metavar='<tenant-id>', default=None, help='ID of tenant to list the default quotas for.')@cliutils.arg( 'tenant', metavar='<tenant_id>', help='UUID of tenant to set the quotas for.') @cliutils.arg( '--user', metavar='<user-id>', default=None, help='ID of user to set the quotas for.') @cliutils.arg( '--shares', metavar='<shares>', type=int, default=None, help='New value for the ""shares"" quota.') @cliutils.arg( '--snapshots', metavar='<snapshots>', type=int, default=None, help='New value for the ""snapshots"" quota.') @cliutils.arg( '--gigabytes', metavar='<gigabytes>', type=int, default=None, help='New value for the ""gigabytes"" quota.') @cliutils.arg( '--share-networks', metavar='<share-networks>', type=int, default=None, help='New value for the ""share_networks"" quota.') @cliutils.arg( '--force', dest='force', action=""store_true"", default=None, help='Whether force update the quota even if the already used' ' and reserved exceeds the new quota')@cliutils.arg( '--tenant', metavar='<tenant-id>', help='ID of tenant to delete quota for.') @cliutils.arg( '--user', metavar='<user-id>', help='ID of user to delete quota for.')@cliutils.arg( 'class_name', metavar='<class>', help='Name of quota class to list the quotas for.')@cliutils.arg( 'class-name', metavar='<class-name>', help='Name of quota class to set the quotas for.') @cliutils.arg( '--shares', metavar='<shares>', type=int, default=None, help='New value for the ""shares"" quota.') @cliutils.arg( '--snapshots', metavar='<snapshots>', type=int, default=None, help='New value for the ""snapshots"" quota.') @cliutils.arg( '--gigabytes', metavar='<gigabytes>', type=int, default=None, help='New value for the ""gigabytes"" quota.') @cliutils.arg( '--share-networks', metavar='<share-networks>', type=int, default=None, help='New value for the ""share_networks"" quota.')@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg( '--metadata', type=str, nargs='*', metavar='<key=value>', help='Metadata key=value pairs (Optional, Default=None)', default=None) @cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg( 'share', metavar='<share>', help='Name or ID of the share to update metadata on.') @cliutils.arg( 'action', metavar='<action>', choices=['set', 'unset'], help=""Actions: 'set' or 'unset'"") @cliutils.arg( 'metadata', metavar='<key=value>', nargs='+', default=[], help='Metadata to set/unset (only key is necessary on unset)')@cliutils.arg( 'share', metavar='<share>', help='Name or ID of share')@cliutils.arg( 'share', metavar='<share>', help='Name or ID of the share to update metadata on.') @cliutils.arg( 'metadata', metavar='<key=value>', nargs='+', default=[], help='Metadata entry/entries to update.')@cliutils.arg( 'share', metavar='<share>', nargs='+', help='Name or ID of share(s).')@cliutils.arg( 'share', metavar='<share>', nargs='+', help='Name or ID of share(s) to force delete.')@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg( 'share', metavar='<share>', help='Name or ID of the share to rename.') @cliutils.arg( 'name', nargs='?', metavar='<name>', help='New name for the share.') @cliutils.arg( '--description', metavar='<description>', help='Optional share description. (Default=None)', default=None)@cliutils.arg( 'snapshot', metavar='<snapshot>', help='Name or ID of the snapshot to rename.') @cliutils.arg( 'name', nargs='?', metavar='<name>', help='New name for the snapshot.') @cliutils.arg( '--description', metavar='<description>', help='Optional snapshot description. (Default=None)', default=None)@cliutils.arg(@cliutils.arg(@cliutils.arg( 'snapshot', metavar='<snapshot>', help='Name or ID of the snapshot to modify.') @cliutils.arg( '--state', metavar='<state>', default='available', help=('Indicate which state to assign the snapshot. ' 'Options include available, error, creating, deleting, ' 'error_deleting. If no state is provided, ' 'available will be used.'))@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg(@cliutils.arg( 'name', metavar='<name>', help=""Name of the new volume type"")@cliutils.arg( 'id', metavar='<id>', help=""Name or ID of the volume type to delete"")@cliutils.arg( 'vtype', metavar='<vtype>', help=""Name or ID of the volume type"") @cliutils.arg( 'action', metavar='<action>', choices=['set', 'unset'], help=""Actions: 'set' or 'unset'"") @cliutils.arg( 'metadata', metavar='<key=value>', nargs='*', default=None, help='Extra_specs to set/unset (only key is necessary on unset)')","@utils.arg('--tenant', metavar='<tenant-id>', default=None, help='ID of tenant to list the quotas for.') @utils.arg('--user', metavar='<user-id>', default=None, help='ID of user to list the quotas for.')@utils.arg('--tenant', metavar='<tenant-id>', default=None, help='ID of tenant to list the default quotas for.')@utils.arg('tenant', metavar='<tenant_id>', help='UUID of tenant to set the quotas for.') @utils.arg('--user', metavar='<user-id>', default=None, help='ID of user to set the quotas for.') @utils.arg('--shares', metavar='<shares>', type=int, default=None, help='New value for the ""shares"" quota.') @utils.arg('--snapshots', metavar='<snapshots>', type=int, default=None, help='New value for the ""snapshots"" quota.') @utils.arg('--gigabytes', metavar='<gigabytes>', type=int, default=None, help='New value for the ""gigabytes"" quota.') @utils.arg('--share-networks', metavar='<share-networks>', type=int, default=None, help='New value for the ""share_networks"" quota.') @utils.arg('--force', dest='force', action=""store_true"", default=None, help='Whether force update the quota even if the already used' ' and reserved exceeds the new quota')@utils.arg('--tenant', metavar='<tenant-id>', help='ID of tenant to delete quota for.') @utils.arg('--user', metavar='<user-id>', help='ID of user to delete quota for.')@utils.arg('class_name', metavar='<class>', help='Name of quota class to list the quotas for.')@utils.arg('class-name', metavar='<class-name>', help='Name of quota class to set the quotas for.') @utils.arg('--shares', metavar='<shares>', type=int, default=None, help='New value for the ""shares"" quota.') @utils.arg('--snapshots', metavar='<snapshots>', type=int, default=None, help='New value for the ""snapshots"" quota.') @utils.arg('--gigabytes', metavar='<gigabytes>', type=int, default=None, help='New value for the ""gigabytes"" quota.') @utils.arg('--share-networks', metavar='<share-networks>', type=int, default=None, help='New value for the ""share_networks"" quota.')@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg('--metadata', type=str, nargs='*', metavar='<key=value>', help='Metadata key=value pairs (Optional, Default=None)', default=None) @utils.arg(@utils.arg(@utils.arg(@utils.arg('share', metavar='<share>', help='Name or ID of the share to update metadata on.') @utils.arg('action', metavar='<action>', choices=['set', 'unset'], help=""Actions: 'set' or 'unset'"") @utils.arg('metadata', metavar='<key=value>', nargs='+', default=[], help='Metadata to set/unset (only key is necessary on unset)')@utils.arg('share', metavar='<share>', help='Name or ID of share')@utils.arg('share', metavar='<share>', help='Name or ID of the share to update metadata on.') @utils.arg('metadata', metavar='<key=value>', nargs='+', default=[], help='Metadata entry/entries to update.')@utils.arg('share', metavar='<share>', nargs='+', help='Name or ID of share(s).')@utils.arg('share', metavar='<share>', nargs='+', help='Name or ID of share(s) to force delete.')@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg('share', metavar='<share>', help='Name or ID of the share to rename.') @utils.arg('name', nargs='?', metavar='<name>', help='New name for the share.') @utils.arg('--description', metavar='<description>', help='Optional share description. (Default=None)', default=None)@utils.arg('snapshot', metavar='<snapshot>', help='Name or ID of the snapshot to rename.') @utils.arg('name', nargs='?', metavar='<name>', help='New name for the snapshot.') @utils.arg('--description', metavar='<description>', help='Optional snapshot description. (Default=None)', default=None)@utils.arg(@utils.arg(@utils.arg('snapshot', metavar='<snapshot>', help='Name or ID of the snapshot to modify.') @utils.arg('--state', metavar='<state>', default='available', help=('Indicate which state to assign the snapshot. ' 'Options include available, error, creating, deleting, ' 'error_deleting. If no state is provided, ' 'available will be used.'))@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg(@utils.arg('name', metavar='<name>', help=""Name of the new volume type"")@utils.arg('id', metavar='<id>', help=""Name or ID of the volume type to delete"")@utils.arg('vtype', metavar='<vtype>', help=""Name or ID of the volume type"") @utils.arg('action', metavar='<action>', choices=['set', 'unset'], help=""Actions: 'set' or 'unset'"") @utils.arg('metadata', metavar='<key=value>', nargs='*', default=None, help='Extra_specs to set/unset (only key is necessary on unset)')",314,295
openstack%2Fmanila~master~I51ae6ba17b8b41c4e6daeb328a5f7076673f9a1c,openstack/manila,master,I51ae6ba17b8b41c4e6daeb328a5f7076673f9a1c,Refactor cifs helper for generic driver,MERGED,2014-08-06 12:03:57.000000000,2014-08-13 20:47:08.000000000,2014-08-13 20:47:08.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 6529}, {'_account_id': 8851}, {'_account_id': 12808}]","[{'number': 1, 'created': '2014-08-06 12:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cf9e17d2a766b86765afabb37255abd3cec7e9a9', 'message': 'Refactor cifs helper for generic driver\n\nWas:\n- writing own local config\n- copying local config to remote server\n- restart of samba on remote server\n- used locks by each server to avoid collision when\n  service restarted and config changed\n\nBecome:\n- used ""net conf"" command to configure samba\n- locks removed as redundant because new approach is collision-proof\n- config is not changed directly anymore, so removed all stuff\n  related to config change\n\nChange-Id: I51ae6ba17b8b41c4e6daeb328a5f7076673f9a1c\n'}, {'number': 2, 'created': '2014-08-06 12:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0f7ca6ac9556e8906802a1a80c1cc73ab0e22b5b', 'message': 'Refactor cifs helper for generic driver\n\nWas:\n- writing own local config\n- copying local config to remote server\n- restart of samba on remote server\n- used locks by each server to avoid collision when\n  service restarted and config changed\n\nBecome:\n- used ""net conf"" command to configure samba\n- locks removed as redundant because new approach is collision-proof\n- config is not changed directly anymore, so removed all stuff\n  related to config change\n\nChange-Id: I51ae6ba17b8b41c4e6daeb328a5f7076673f9a1c\n'}, {'number': 3, 'created': '2014-08-07 11:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d6928e9716e1a2320731938f37fe4f745b654acb', 'message': 'Refactor cifs helper for generic driver\n\nWas:\n- writing own local config\n- copying local config to remote server\n- restart of samba on remote server\n- used locks by each server to avoid collision when\n  service restarted and config changed\n\nBecome:\n- used ""net conf"" command to configure samba\n- locks removed as redundant because new approach is collision-proof\n- config is not changed directly anymore, so removed all stuff\n  related to config change\n\nChange-Id: I51ae6ba17b8b41c4e6daeb328a5f7076673f9a1c\n'}, {'number': 4, 'created': '2014-08-08 06:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/86f95c14d73402c8dab7535fa5e4e9c92b7fe93a', 'message': 'Refactor cifs helper for generic driver\n\nWas:\n- writing own local config\n- copying local config to remote server\n- restart of samba on remote server\n- used locks by each server to avoid collision when\n  service restarted and config changed\n\nBecome:\n- used ""net conf"" command to configure samba\n- locks removed as redundant because new approach is collision-proof\n- config is not changed directly anymore, so removed all stuff\n  related to config change\n\nChange-Id: I51ae6ba17b8b41c4e6daeb328a5f7076673f9a1c\n'}, {'number': 5, 'created': '2014-08-13 08:35:43.000000000', 'files': ['manila/tests/test_share_generic.py', 'manila/share/drivers/generic.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/6c1f6a9ee0059e2f4c8e6a2c6e91aea97e5dca42', 'message': 'Refactor cifs helper for generic driver\n\nWas:\n- writing own local config\n- copying local config to remote server\n- restart of samba on remote server\n- used locks by each server to avoid collision when\n  service restarted and config changed\n\nBecome:\n- used ""net conf"" command to configure samba\n- locks removed as redundant because new approach is collision-proof\n- config is not changed directly anymore, so removed all stuff\n  related to config change\n\nChange-Id: I51ae6ba17b8b41c4e6daeb328a5f7076673f9a1c\n'}]",10,112279,6c1f6a9ee0059e2f4c8e6a2c6e91aea97e5dca42,30,7,5,8851,,,0,"Refactor cifs helper for generic driver

Was:
- writing own local config
- copying local config to remote server
- restart of samba on remote server
- used locks by each server to avoid collision when
  service restarted and config changed

Become:
- used ""net conf"" command to configure samba
- locks removed as redundant because new approach is collision-proof
- config is not changed directly anymore, so removed all stuff
  related to config change

Change-Id: I51ae6ba17b8b41c4e6daeb328a5f7076673f9a1c
",git fetch https://review.opendev.org/openstack/manila refs/changes/79/112279/3 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/test_share_generic.py', 'manila/share/drivers/generic.py']",2,cf9e17d2a766b86765afabb37255abd3cec7e9a9,master,"class CIFSHelper(NASHelperBase): """"""Manage shares in samba server by net conf tool. Class provides functionality to operate with CIFS shares. Samba server should be configured to use registry as configuration backend to allow dynamically share managements. """""" def init_helper(self, server): # This is smoke check that we have required dependency self._ssh_exec(server, ['sudo', 'net', 'conf', 'list']) def create_export(self, server, share_name, recreate=False): """"""Create share at samba server."""""" create_cmd = [ 'sudo', 'net', 'conf', 'addshare', share_name, self.configuration.share_mount_path, 'writeable=y', 'guest_ok=y', ] try: self._ssh_exec( server, ['sudo', 'net', 'conf', 'showshare', share_name, ]) except exception.ProcessExecutionError: # Share does not exist, create it self._ssh_exec(server, create_cmd) else: # Share exists if recreate: self._ssh_exec( server, ['sudo', 'net', 'conf', 'delshare', share_name, ]) self._ssh_exec(server, create_cmd) else: msg = _('Share section %s already defined.') % share_name raise exception.ShareBackendException(msg=msg) parameters = { 'browseable': 'yes', '\""create mask\""': '0755', '\""hosts deny\""': '0.0.0.0/0', # deny all by default '\""hosts allow\""': '127.0.0.1', '\""read only\""': 'no', } set_of_commands = [':', ] # : is just placeholder for param, value in parameters.items(): # These are combined in one list to run in one process # instead of big chain of one action calls. set_of_commands.extend([';', 'sudo', 'net', 'conf', 'setparm', share_name, param, value]) self._ssh_exec(server, set_of_commands) def remove_export(self, server, share_name): """"""Remove share definition from samba server."""""" try: self._ssh_exec( server, ['sudo', 'net', 'conf', 'delshare', share_name]) except exception.ProcessExecutionError as e: LOG.warning(_(""Caught error trying delete share: %(error)s, try"" ""ing delete it forcibly."") % {'error': e.stderr}) self._ssh_exec(server, ['sudo', 'smbcontrol', 'all', 'close-share', share_name]) def allow_access(self, server, share_name, access_type, access): """"""Add access for share."""""" if access_type != 'ip': reason = _('Only ip access type allowed.') raise exception.InvalidShareAccess(reason=reason) hosts = self._get_allow_hosts(server, share_name) if access in hosts: hosts.append(access) self._set_allow_hosts(server, hosts, share_name) """"""Remove access for share."""""" try: hosts = self._get_allow_hosts(server, share_name) if access in hosts: # Access rule can be in error state, if so # it can be absent in rules, hence - skip removal. hosts.remove(access) self._set_allow_hosts(server, hosts, share_name) except exception.ProcessExecutionError: def _get_allow_hosts(self, server, share_name): (out, _) = self._ssh_exec(server, ['sudo', 'net', 'conf', 'getparm', share_name, '\""hosts allow\""']) return out.split() def _set_allow_hosts(self, server, hosts, share_name): value = ""\"""" + ' '.join(hosts) + ""\"""" self._ssh_exec(server, ['sudo', 'net', 'conf', 'setparm', share_name, '\""hosts allow\""', value])","import ConfigParserimport shutildef cifs_synchronized(f): def wrapped_func(self, *args, **kwargs): key = ""cifs-%s"" % args[0][""instance_id""] @lockutils.synchronized(key) def source_func(self, *args, **kwargs): return f(self, *args, **kwargs) return source_func(self, *args, **kwargs) return wrapped_func class CIFSHelper(NASHelperBase): """"""Class provides functionality to operate with cifs shares"""""" def __init__(self, *args): """"""Store executor and configuration path."""""" super(CIFSHelper, self).__init__(*args) self.config_path = self.configuration.service_instance_smb_config_path self.smb_template_config = self.configuration.smb_template_config_path self.test_config = ""%s_"" % (self.smb_template_config,) self.local_configs = {} def _create_local_config(self, share_network_id): path, ext = os.path.splitext(self.smb_template_config) local_config = '%s-%s%s' % (path, share_network_id, ext) self.local_configs[share_network_id] = local_config shutil.copy(self.smb_template_config, local_config) return local_config def _get_local_config(self, share_network_id): local_config = self.local_configs.get(share_network_id, None) if local_config is None: local_config = self._create_local_config(share_network_id) return local_config @cifs_synchronized def init_helper(self, server): self._recreate_template_config() local_config = self._create_local_config(server['instance_id']) config_dir = os.path.dirname(self.config_path) try: self._ssh_exec(server, ['sudo', 'mkdir', config_dir]) except exception.ProcessExecutionError as e: if 'File exists' not in e.stderr: raise LOG.debug('Directory %s already exists' % config_dir) self._ssh_exec(server, ['sudo', 'chown', self.configuration.service_instance_user, config_dir]) self._ssh_exec(server, ['touch', self.config_path]) try: self._ssh_exec(server, ['sudo', 'stop', 'smbd']) except exception.ProcessExecutionError as e: if 'Unknown instance' not in e.stderr: raise LOG.debug('Samba service is not running') self._write_remote_config(local_config, server) self._ssh_exec(server, ['sudo', 'smbd', '-s', self.config_path]) self._restart_service(server) @cifs_synchronized def create_export(self, server, share_name, recreate=False): """"""Create new export, delete old one if exists."""""" local_path = os.path.join(self.configuration.share_mount_path, share_name) config = self._get_local_config(server['instance_id']) parser = ConfigParser.ConfigParser() parser.read(config) # delete old one if parser.has_section(share_name): if recreate: parser.remove_section(share_name) else: raise exception.Error('Section exists') # Create new one parser.add_section(share_name) parser.set(share_name, 'path', local_path) parser.set(share_name, 'browseable', 'yes') parser.set(share_name, 'guest ok', 'yes') parser.set(share_name, 'read only', 'no') parser.set(share_name, 'writable', 'yes') parser.set(share_name, 'create mask', '0755') parser.set(share_name, 'hosts deny', '0.0.0.0/0') # denying all ips parser.set(share_name, 'hosts allow', '127.0.0.1') self._update_config(parser, config) self._write_remote_config(config, server) self._restart_service(server) @cifs_synchronized def remove_export(self, server, share_name): """"""Remove export."""""" config = self._get_local_config(server['instance_id']) parser = ConfigParser.ConfigParser() parser.read(config) # delete old one if parser.has_section(share_name): parser.remove_section(share_name) self._update_config(parser, config) self._write_remote_config(config, server) self._ssh_exec(server, ['sudo', 'smbcontrol', 'all', 'close-share', share_name]) def _write_remote_config(self, config, server): with open(config, 'r') as f: cfg = ""'%s'"" % f.read() self._ssh_exec(server, ['echo %s > %s' % (cfg, self.config_path)]) @cifs_synchronized def allow_access(self, server, share_name, access_type, access): """"""Allow access to the host."""""" if access_type != 'ip': reason = 'only ip access type allowed' raise exception.InvalidShareAccess(reason) config = self._get_local_config(server['instance_id']) parser = ConfigParser.ConfigParser() parser.read(config) hosts = parser.get(share_name, 'hosts allow') if access in hosts.split(): hosts += ' %s' % (access,) parser.set(share_name, 'hosts allow', hosts) self._update_config(parser, config) self._write_remote_config(config, server) self._restart_service(server) @cifs_synchronized """"""Deny access to the host."""""" config = self._get_local_config(server['instance_id']) parser = ConfigParser.ConfigParser() try: parser.read(config) hosts = parser.get(share_name, 'hosts allow') hosts = hosts.replace(' %s' % (access,), '', 1) parser.set(share_name, 'hosts allow', hosts) self._update_config(parser, config) except ConfigParser.NoSectionError: self._write_remote_config(config, server) self._restart_service(server) def _recreate_template_config(self): """"""Create new SAMBA configuration file."""""" if os.path.exists(self.smb_template_config): os.unlink(self.smb_template_config) parser = ConfigParser.ConfigParser() parser.add_section('global') parser.set('global', 'security', 'user') parser.set('global', 'server string', '%h server (Samba, Openstack)') self._update_config(parser, self.smb_template_config) def _restart_service(self, server): self._ssh_exec(server, 'sudo pkill -HUP smbd'.split()) def _update_config(self, parser, config): """"""Check if new configuration is correct and save it."""""" # Check that configuration is correct with open(self.test_config, 'w') as fp: parser.write(fp) self._execute('testparm', '-s', self.test_config, check_exit_code=True) # save it with open(config, 'w') as fp: parser.write(fp)",283,218
openstack%2Fpython-manilaclient~master~Iefe7da601cdaf030787c6d7588dd0c1706e309cd,openstack/python-manilaclient,master,Iefe7da601cdaf030787c6d7588dd0c1706e309cd,Cleanup manilaclient.utils module (part 1),MERGED,2014-07-15 12:07:05.000000000,2014-08-13 20:47:02.000000000,2014-08-13 20:47:02.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 6529}, {'_account_id': 7534}, {'_account_id': 8851}, {'_account_id': 11878}]","[{'number': 1, 'created': '2014-07-15 12:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/a9d59bf0c0947e137f383d55184eeb7f858bd1b5', 'message': 'Cleanup manilaclient.utils module (part 1)\n\nFirst part of manilaclient.utils module cleanup,\nwhere usage of deleted functions replaced with functions\nfrom common code.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: Iefe7da601cdaf030787c6d7588dd0c1706e309cd\n'}, {'number': 2, 'created': '2014-07-21 13:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/510adb7c4c7e9429ddf915815a73f53569a98d01', 'message': 'Cleanup manilaclient.utils module (part 1)\n\nFirst part of manilaclient.utils module cleanup,\nwhere usage of deleted functions replaced with functions\nfrom common code.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: Iefe7da601cdaf030787c6d7588dd0c1706e309cd\n'}, {'number': 3, 'created': '2014-08-04 14:52:42.000000000', 'files': ['manilaclient/shell.py', 'tests/test_utils.py', 'manilaclient/client.py', 'manilaclient/v1/contrib/list_extensions.py', 'manilaclient/v1/shell.py', 'manilaclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/b11f5d78a288bbf9297e89628eb5fd0f0ec7331b', 'message': 'Cleanup manilaclient.utils module (part 1)\n\nFirst part of manilaclient.utils module cleanup,\nwhere usage of deleted functions replaced with functions\nfrom common code.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: Iefe7da601cdaf030787c6d7588dd0c1706e309cd\n'}]",0,107017,b11f5d78a288bbf9297e89628eb5fd0f0ec7331b,32,7,3,8851,,,0,"Cleanup manilaclient.utils module (part 1)

First part of manilaclient.utils module cleanup,
where usage of deleted functions replaced with functions
from common code.

Partially implements: blueprint use-common-code

Change-Id: Iefe7da601cdaf030787c6d7588dd0c1706e309cd
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/17/107017/1 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/shell.py', 'tests/test_utils.py', 'manilaclient/client.py', 'manilaclient/v1/contrib/list_extensions.py', 'manilaclient/utils.py', 'manilaclient/v1/shell.py']",6,a9d59bf0c0947e137f383d55184eeb7f858bd1b5,bp/use-common-code,"from manilaclient.openstack.common import cliutils return cliutils.find_resource(cs.shares, share) return cliutils.find_resource(cs.share_snapshots, snapshot) return cliutils.find_resource(cs.share_networks, share_network)@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share') share = _find_share(cs, args.share)@cliutils.service_type('share') share = _find_share(cs, args.share)@cliutils.service_type('share') share = _find_share(cs, args.share)@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share') share = _find_share(cs, args.share)@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share') return cliutils.find_resource(cs.volume_types, vtype) @cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')@cliutils.service_type('share')"," return utils.find_resource(cs.shares, share) return utils.find_resource(cs.share_snapshots, snapshot) return utils.find_resource(cs.share_networks, share_network)@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share') share = utils.find_share(cs, args.share)@utils.service_type('share') share = utils.find_share(cs, args.share)@utils.service_type('share') share = utils.find_share(cs, args.share)@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share') share = utils.find_share(cs, args.share)@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share') return utils.find_resource(cs.volume_types, vtype) @utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')@utils.service_type('share')",47,297
openstack%2Fpython-manilaclient~master~I2aca0874e76d1145825b89e34bcd9a53fe7a2b1d,openstack/python-manilaclient,master,I2aca0874e76d1145825b89e34bcd9a53fe7a2b1d,Fix deletion of nonexistent share,MERGED,2014-08-06 12:50:29.000000000,2014-08-13 20:46:56.000000000,2014-08-13 20:46:55.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 6529}]","[{'number': 1, 'created': '2014-08-06 12:50:29.000000000', 'files': ['tests/v1/test_shell.py', 'manilaclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/7a819f9fe4d30634c072d7fecec02b4088c7f98e', 'message': ""Fix deletion of nonexistent share\n\nWhen we try delete share that does not exist, we get following error:\nUnboundLocalError: local variable 'share_ref' referenced before assignment\n\nChange-Id: I2aca0874e76d1145825b89e34bcd9a53fe7a2b1d\nCloses-Bug: #1353466\n""}]",0,112289,7a819f9fe4d30634c072d7fecec02b4088c7f98e,14,5,1,8851,,,0,"Fix deletion of nonexistent share

When we try delete share that does not exist, we get following error:
UnboundLocalError: local variable 'share_ref' referenced before assignment

Change-Id: I2aca0874e76d1145825b89e34bcd9a53fe7a2b1d
Closes-Bug: #1353466
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/89/112289/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/v1/test_shell.py', 'manilaclient/v1/shell.py']",2,7a819f9fe4d30634c072d7fecec02b4088c7f98e,master," print(""Delete for share %s failed: %s"" % (share, e))"," print(""Delete for share %s failed: %s"" % (share_ref.id, e))",8,1
openstack%2Fdevstack~master~I1c06d0511fbf93050cda56d9d2de0ff00813dfb6,openstack/devstack,master,I1c06d0511fbf93050cda56d9d2de0ff00813dfb6,Change ordering of ceilometer service startup,MERGED,2014-08-12 13:32:49.000000000,2014-08-13 20:46:53.000000000,2014-08-13 20:46:53.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7118}, {'_account_id': 10385}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-08-12 13:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d06b640ce3cdb2c9e7dc489d50776fa233f7d3ac', 'message': 'Change ordering of ceilometer service startup\n\nIf the compute-agent starts before the collector directly\nafter a start or restart of the AMQP service, samples published from\nthe compute-agent can be lost before the collector has had a chance\nto establish connections. These lost samples impact the reliability\nof tests which run immediately after the service [re]start.\n\nNote: if there is a restart of the ceilo service, but not the AMQP\nservice, the problem does not present itself becaue the messaging\nservice maintains some state on the exchanges it keeps.\n\nChange-Id: I1c06d0511fbf93050cda56d9d2de0ff00813dfb6\nCloses-bug: 1355809\n'}, {'number': 2, 'created': '2014-08-12 20:57:49.000000000', 'files': ['lib/ceilometer'], 'web_link': 'https://opendev.org/openstack/devstack/commit/4922bfa84674aa8f84f8c65dd5123153495b2717', 'message': 'Change ordering of ceilometer service startup\n\nIf the compute-agent starts before the collector directly\nafter a start or restart of the AMQP service, samples published from\nthe compute-agent can be lost before the collector has had a chance\nto establish connections. These lost samples impact the reliability\nof tests which run immediately after the service [re]start.\n\nNote: if there is a restart of the ceilo service, but not the AMQP\nservice, the problem does not present itself becaue the messaging\nservice maintains some state on the exchanges it keeps.\n\nChange-Id: I1c06d0511fbf93050cda56d9d2de0ff00813dfb6\nCloses-bug: 1355809\n'}]",4,113522,4922bfa84674aa8f84f8c65dd5123153495b2717,20,5,2,11564,,,0,"Change ordering of ceilometer service startup

If the compute-agent starts before the collector directly
after a start or restart of the AMQP service, samples published from
the compute-agent can be lost before the collector has had a chance
to establish connections. These lost samples impact the reliability
of tests which run immediately after the service [re]start.

Note: if there is a restart of the ceilo service, but not the AMQP
service, the problem does not present itself becaue the messaging
service maintains some state on the exchanges it keeps.

Change-Id: I1c06d0511fbf93050cda56d9d2de0ff00813dfb6
Closes-bug: 1355809
",git fetch https://review.opendev.org/openstack/devstack refs/changes/22/113522/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceilometer'],1,d06b640ce3cdb2c9e7dc489d50776fa233f7d3ac,bug/1355809," screen_it ceilometer-acentral ""cd ; ceilometer-agent-central --config-file $CEILOMETER_CONF"" screen_it ceilometer-anotification ""cd ; ceilometer-agent-notification --config-file $CEILOMETER_CONF"" screen_it ceilometer-collector ""cd ; ceilometer-collector --config-file $CEILOMETER_CONF"" screen_it ceilometer-api ""cd ; ceilometer-api -d -v --log-dir=$CEILOMETER_API_LOG_DIR --config-file $CEILOMETER_CONF"" # Wait for the collector to fully wake up and connect to the # message bus before starting the compute agent. See bug #1355809 sleep 1"," screen_it ceilometer-acentral ""cd ; ceilometer-agent-central --config-file $CEILOMETER_CONF"" screen_it ceilometer-anotification ""cd ; ceilometer-agent-notification --config-file $CEILOMETER_CONF"" screen_it ceilometer-collector ""cd ; ceilometer-collector --config-file $CEILOMETER_CONF"" screen_it ceilometer-api ""cd ; ceilometer-api -d -v --log-dir=$CEILOMETER_API_LOG_DIR --config-file $CEILOMETER_CONF""",8,4
openstack%2Fpuppet-cinder~master~Idcad78c78405c17518b8f4fe75e9954107b386f9,openstack/puppet-cinder,master,Idcad78c78405c17518b8f4fe75e9954107b386f9,volume/iscsi: Fix typo and use real default iscsi_helper in tests,MERGED,2014-07-12 09:43:19.000000000,2014-08-13 20:43:29.000000000,2014-07-17 20:24:30.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-07-12 09:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/4ff7be1bd6887edc44c161ded1c612fe22d16a06', 'message': ""volume/iscsi: Fix typo and use real default iscsi_helper in tests\n\nThe default value for iscsi_helper isn't correctly configured in\nvolume::iscsi. This commit fix also a typo in the params class.\n\nCloses-Bug: 1341091\nChange-Id: Idcad78c78405c17518b8f4fe75e9954107b386f9\n""}, {'number': 2, 'created': '2014-07-12 10:06:26.000000000', 'files': ['spec/classes/cinder_volume_iscsi_spec.rb', 'manifests/volume/iscsi.pp', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/0e076dec1111c4573db59f524ddb36f5f36566e6', 'message': ""volume/iscsi: Fix typo and use real default iscsi_helper in tests\n\nThe default value for iscsi_helper isn't correctly configured in\nvolume::iscsi. This commit fix also a typo in the params class.\n\nCloses-Bug: 1341091\nChange-Id: Idcad78c78405c17518b8f4fe75e9954107b386f9\n""}]",0,106554,0e076dec1111c4573db59f524ddb36f5f36566e6,14,3,2,7155,,,0,"volume/iscsi: Fix typo and use real default iscsi_helper in tests

The default value for iscsi_helper isn't correctly configured in
volume::iscsi. This commit fix also a typo in the params class.

Closes-Bug: 1341091
Change-Id: Idcad78c78405c17518b8f4fe75e9954107b386f9
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/54/106554/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/cinder_volume_iscsi_spec.rb', 'manifests/params.pp', 'manifests/volume/iscsi.pp']",3,4ff7be1bd6887edc44c161ded1c612fe22d16a06,bug/1341091," $iscsi_helper = $::cinder::params::iscsi_helper, include cinder::params "," $iscsi_helper = $cinder::params::iscsi_helper,",5,4
openstack%2Ftripleo-image-elements~master~I63f054a8c80f9f676a77341c89e605b5b472d078,openstack/tripleo-image-elements,master,I63f054a8c80f9f676a77341c89e605b5b472d078,Use pacemaker to run neutron l3 agent and metadata agent,MERGED,2014-07-31 19:28:23.000000000,2014-08-13 20:42:18.000000000,2014-08-13 06:45:11.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 7336}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-07-31 19:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/293566f809878049e96096c295ce9576966c5175', 'message': 'Use pacemaker to run neutron l3 agent and metadata agent\n\nCurrently l3-agent and metadata agent can not run in a/a mode\nwithout loosing data if a node goes down. This patch sets a/p\nmode for both services.\n\nNote that this is a short-term solution of providing HA for\nthe services. Other temporary solutions like running l3-agent in a/a mode\nand re-assign routers when a node goes down, might work better but\nimplementation would be much more complex and it would be still\njust a temporary solution until l3-agent supports a/a HA (which is\nplanned for Juno).\n\nChange-Id: I63f054a8c80f9f676a77341c89e605b5b472d078\n'}, {'number': 2, 'created': '2014-08-07 13:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/89f4226980e122707ca5213c6f0c0972d047ddcf', 'message': 'Use pacemaker to run neutron l3 agent and metadata agent\n\nCurrently l3-agent and metadata agent can not run in a/a mode\nwithout loosing data if a node goes down. This patch sets a/p\nmode for both services.\n\nNote that this is a short-term solution of providing HA for\nthe services. Other temporary solutions like running l3-agent in a/a mode\nand re-assign routers when a node goes down, might work better but\nimplementation would be much more complex and it would be still\njust a temporary solution until l3-agent supports a/a HA (which is\nplanned for Juno).\n\nRelies on: Icc97e36a1db198b973041346cf2056f68de661a2\nChange-Id: I63f054a8c80f9f676a77341c89e605b5b472d078\n'}, {'number': 3, 'created': '2014-08-08 10:04:48.000000000', 'files': ['elements/neutron-network-node/element-deps', 'elements/neutron-network-node/os-refresh-config/post-configure.d/80-neutron-networking'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9ae3c52104a2098b2566fe77e5420ec93b5875f7', 'message': 'Use pacemaker to run neutron l3 agent and metadata agent\n\nCurrently l3-agent and metadata agent can not run in a/a mode\nwithout loosing data if a node goes down. This patch sets a/p\nmode for both services.\n\nNote that this is a short-term solution of providing HA for\nthe services. Other temporary solutions like running l3-agent in a/a mode\nand re-assign routers when a node goes down, might work better but\nimplementation would be much more complex and it would be still\njust a temporary solution until l3-agent supports a/a HA (which is\nplanned for Juno).\n\nRelies on: Icc97e36a1db198b973041346cf2056f68de661a2\nChange-Id: I63f054a8c80f9f676a77341c89e605b5b472d078\n'}]",3,111049,9ae3c52104a2098b2566fe77e5420ec93b5875f7,38,6,3,7582,,,0,"Use pacemaker to run neutron l3 agent and metadata agent

Currently l3-agent and metadata agent can not run in a/a mode
without loosing data if a node goes down. This patch sets a/p
mode for both services.

Note that this is a short-term solution of providing HA for
the services. Other temporary solutions like running l3-agent in a/a mode
and re-assign routers when a node goes down, might work better but
implementation would be much more complex and it would be still
just a temporary solution until l3-agent supports a/a HA (which is
planned for Juno).

Relies on: Icc97e36a1db198b973041346cf2056f68de661a2
Change-Id: I63f054a8c80f9f676a77341c89e605b5b472d078
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/49/111049/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/neutron-network-node/element-deps', 'elements/neutron-network-node/os-refresh-config/post-configure.d/80-neutron-networking']",2,293566f809878049e96096c295ce9576966c5175,pcmk-neutron2,"# get resource class (systemd, upstart, lsb). It should be possible # to use 'service' class which is a wrapper for others but this doesn't work # as expected on Fedora - lrmd process segfaults if 'service' resource class # is used: https://bugzilla.redhat.com/show_bug.cgi?id=1117151 CLASS=$(dib-init-system) if [ ""$CLASS"" = ""sysv"" ]; then CLASS=lsb fi if os-is-bootstrap-host; then if ! cibadmin --query --xpath '//primitive[@id=""neutron-metadata-agent""]'; then /usr/sbin/cibadmin -o resources -C -X "" <primitive class=\""$CLASS\"" id=\""neutron-metadata-agent\"" type=\""neutron-metadata-agent\""> <instance_attributes id=\""neutron-metadata-agent-instance_attributes\""/> <operations> <op id=\""neutron-metadata-agent-monitor-start-delay-10s\"" interval=\""30s\"" name=\""monitor\"" start-delay=\""10s\""/> </operations> </primitive>"" fi if ! cibadmin --query --xpath '//primitive[@id=""neutron-l3-agent""]'; then /usr/sbin/cibadmin -o resources -C -X "" <primitive class=\""$CLASS\"" id=\""neutron-l3-agent\"" type=\""neutron-l3-agent\""> <instance_attributes id=\""neutron-l3-agent-instance_attributes\""/> <operations> <op id=\""neutron-l3-agent-monitor-start-delay-10s\"" interval=\""30s\"" name=\""monitor\"" start-delay=\""10s\""/> </operations> </primitive>"" fi fi",os-svc-enable -n neutron-metadata-agent os-svc-enable -n neutron-l3-agent os-svc-restart -n neutron-metadata-agent os-svc-restart -n neutron-l3-agent,30,4
openstack%2Ftripleo-heat-templates~master~I65d85a88152ed4adee60895173f8a05611a6440b,openstack/tripleo-heat-templates,master,I65d85a88152ed4adee60895173f8a05611a6440b,Make removing nodes from scaled items possible.,MERGED,2014-08-12 03:33:20.000000000,2014-08-13 20:05:18.000000000,2014-08-13 20:05:17.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 4190}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-08-12 03:33:20.000000000', 'files': ['examples/scale_map_result_hot_blacklist.yaml', 'test_merge.bash', 'tripleo_heat_merge/merge.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3e35d53061cb65032373ca3c0104cde4720af1f0', 'message': 'Make removing nodes from scaled items possible.\n\nThis makes it possible to remove a dead node (e.g. if NovaCompute2 has\nfailed, regenerate the template with ,2 in the scale parameter, and\nNovaCompute2 will not be enumerated.\n\nChange-Id: I65d85a88152ed4adee60895173f8a05611a6440b\n'}]",0,113431,3e35d53061cb65032373ca3c0104cde4720af1f0,19,4,1,4190,,,0,"Make removing nodes from scaled items possible.

This makes it possible to remove a dead node (e.g. if NovaCompute2 has
failed, regenerate the template with ,2 in the scale parameter, and
NovaCompute2 will not be enumerated.

Change-Id: I65d85a88152ed4adee60895173f8a05611a6440b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/31/113431/1 && git format-patch -1 --stdout FETCH_HEAD,"['examples/scale_map_result_hot_blacklist.yaml', 'test_merge.bash', 'tripleo_heat_merge/merge.py']",3,3e35d53061cb65032373ca3c0104cde4720af1f0,," :param scaling: A dict of prefix -> (count, blacklists). :param scaling: The scaling map (prefix-> (copies, blacklist) to use. for prefix, (copies, blacklist) in scaling.items(): if n not in blacklist: yield prefix, n, prefix[:-1] + str(n) + suffix key, values = item.split('=') values = values.split(',') value = int(values[0]) blacklist = frozenset(int(v) for v in values[1:] if v) result[key + '0'] = value, blacklist help=""Names to scale out. Pass Prefix=2 to cause a key Prefix0Foo to "" ""outside of any copy. Pass Prefix=3,1 to cause Prefix1* to be elided"" ""when scaling Prefix out. Prefix=4,1,2 will likewise elide Prefix1 and"" ""Prefix2."")"," :param scaling: The scaling map to use. for prefix, copies in scaling.items(): yield prefix, n, prefix[:-1] + str(n) + suffix key, value = item.split('=') value = int(value) result[key + '0'] = value help=""Names to scale out. Pass Prefix=1 to cause a key Prefix0Foo to "" ""outside of any copy."")",384,8
openstack%2Fpython-monascaclient~master~I6035592db93aaf98da0a05321ce9727609bc66e9,openstack/python-monascaclient,master,I6035592db93aaf98da0a05321ce9727609bc66e9,Updated Changelog,MERGED,2014-08-13 19:32:56.000000000,2014-08-13 19:52:33.000000000,2014-08-13 19:52:32.000000000,"[{'_account_id': 3}, {'_account_id': 6230}]","[{'number': 1, 'created': '2014-08-13 19:32:56.000000000', 'files': ['ChangeLog'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/e289d569cd0f6cf764ead8987604a67261acfcec', 'message': 'Updated Changelog\n\nChange-Id: I6035592db93aaf98da0a05321ce9727609bc66e9\n'}]",0,114000,e289d569cd0f6cf764ead8987604a67261acfcec,7,2,1,12133,,,0,"Updated Changelog

Change-Id: I6035592db93aaf98da0a05321ce9727609bc66e9
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/00/114000/1 && git format-patch -1 --stdout FETCH_HEAD,['ChangeLog'],1,e289d569cd0f6cf764ead8987604a67261acfcec,changlog,1.0.2 ----- * supports unicode * help for dimensions mentions need for quoting * fix several bashate issues ,,6,0
openstack%2Fneutron~master~Iba498d0600d625f0469392b99ac0bc8c1f1ecff7,openstack/neutron,master,Iba498d0600d625f0469392b99ac0bc8c1f1ecff7,Return port context from _bind_port_if_needed,MERGED,2014-08-10 18:55:43.000000000,2014-08-13 19:47:12.000000000,2014-08-13 01:13:05.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 8213}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10781}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-10 18:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/afbfbf214964e3690c2dad1347eb3424a061ac64', 'message': 'WIP fix\n\nChange-Id: Iba498d0600d625f0469392b99ac0bc8c1f1ecff7\nCloses-Bug: #1354912\n'}, {'number': 2, 'created': '2014-08-10 19:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4a4923967853c2a3e0b854fb9b447815378b48bf', 'message': 'WIP  fix\n\nChange-Id: Iba498d0600d625f0469392b99ac0bc8c1f1ecff7\nCloses-Bug: #1354912\n'}, {'number': 3, 'created': '2014-08-11 07:48:52.000000000', 'files': ['neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/03920290d00148437fe14696621bc7446bfc7e46', 'message': 'Return port context from _bind_port_if_needed\n\nPreviously port was returned causing exception being thrown\nin rpc handling code.\n\nChange-Id: Iba498d0600d625f0469392b99ac0bc8c1f1ecff7\nCloses-Bug: #1354912\n'}]",2,113144,03920290d00148437fe14696621bc7446bfc7e46,93,25,3,6072,,,0,"Return port context from _bind_port_if_needed

Previously port was returned causing exception being thrown
in rpc handling code.

Change-Id: Iba498d0600d625f0469392b99ac0bc8c1f1ecff7
Closes-Bug: #1354912
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/113144/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/plugin.py'],1,afbfbf214964e3690c2dad1347eb3424a061ac64,bug/1354912, return context, return context._port,1,1
openstack%2Ftripleo-incubator~master~I44aec55c7b4f579510f5066e90ad008c17e781be,openstack/tripleo-incubator,master,I44aec55c7b4f579510f5066e90ad008c17e781be,Increase recommended 64bit settings to 3gb ram,ABANDONED,2014-05-21 21:15:26.000000000,2014-08-13 19:47:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6348}, {'_account_id': 7585}, {'_account_id': 8399}, {'_account_id': 8532}, {'_account_id': 9369}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-05-21 21:15:26.000000000', 'files': ['scripts/devtest_testenv.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ae524037755e714194decfa5c6de2da31801eccb', 'message': 'Increase recommended 64bit settings to 3gb ram\n\nWhen running devtest using 64bit ubuntu nodes I encounter ""could not\nallocate memory"" errors in the undercloud. It seems that 3gb ram is the\nminimum with our current settings. We should reccomend that as a value.\n\nChange-Id: I44aec55c7b4f579510f5066e90ad008c17e781be\n'}]",1,94727,ae524037755e714194decfa5c6de2da31801eccb,19,8,1,10035,,,0,"Increase recommended 64bit settings to 3gb ram

When running devtest using 64bit ubuntu nodes I encounter ""could not
allocate memory"" errors in the undercloud. It seems that 3gb ram is the
minimum with our current settings. We should reccomend that as a value.

Change-Id: I44aec55c7b4f579510f5066e90ad008c17e781be
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/27/94727/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_testenv.sh'],1,ae524037755e714194decfa5c6de2da31801eccb,fix/64bit-nodes-need-3gb-mem,## NODE_CPU=1 NODE_MEM=3072 NODE_DISK=40 NODE_ARCH=amd64,## NODE_CPU=1 NODE_MEM=2048 NODE_DISK=40 NODE_ARCH=amd64,1,1
openstack%2Fcinder~master~I843cfa9a4e4758a6bc8e5c04f064e9d3107b01fa,openstack/cinder,master,I843cfa9a4e4758a6bc8e5c04f064e9d3107b01fa,Make manage.py usable,MERGED,2014-08-07 23:29:04.000000000,2014-08-13 19:30:29.000000000,2014-08-13 19:30:28.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2759}, {'_account_id': 7156}, {'_account_id': 9751}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12499}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-08-07 23:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e38f3c824700f7a7c29ed4ee3bfe2b2afb8bf7d', 'message': ""Make manage.py usable\n\nIt's not possible to use manage.py in its current state due to\nan exception thrown by oslo.config:\n\n  oslo.config.cfg.ArgsAlreadyParsedError:\n    arguments already parsed: cannot register CLI option\n\nThis exception is a side-effect of including\ncinder.openstack.common.logging in most of the migration scripts.\n\nThis change therefore suggests removing oslo.config and other imports\nfrom manage.py to make it usable again.\n\nIt is now possible to use manage.py:\n\n  tox -evenv -- python cinder/db/sqlalchemy/migrate_repo/manage.py \\\n    version_control --url=sqlite:///./cinder.db\n\n  tox -evenv -- python cinder/db/sqlalchemy/migrate_repo/manage.py \\\n    upgrade --url=sqlite:///./cinder.db\n\nChange-Id: I843cfa9a4e4758a6bc8e5c04f064e9d3107b01fa\n""}, {'number': 2, 'created': '2014-08-11 16:47:08.000000000', 'files': ['cinder/db/sqlalchemy/migrate_repo/manage.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/186c3e99cf04b22ddbb1046cc9e42d1f7473e8cf', 'message': ""Make manage.py usable\n\nIt's not possible to use manage.py in its current state due to\nan exception thrown by oslo.config:\n\n  oslo.config.cfg.ArgsAlreadyParsedError:\n    arguments already parsed: cannot register CLI option\n\nThis exception is a side-effect of including\ncinder.openstack.common.logging in most of the migration scripts.\n\nThis change therefore suggests removing oslo.config and other imports\nfrom manage.py to make it usable again.\n\nIt is now possible to use manage.py:\n\n  tox -evenv -- python cinder/db/sqlalchemy/migrate_repo/manage.py \\\n    version_control --url=sqlite:///./cinder.db\n\n  tox -evenv -- python cinder/db/sqlalchemy/migrate_repo/manage.py \\\n    upgrade --url=sqlite:///./cinder.db\n\nCloses-bug: #1355297\nChange-Id: I843cfa9a4e4758a6bc8e5c04f064e9d3107b01fa\n""}]",0,112724,186c3e99cf04b22ddbb1046cc9e42d1f7473e8cf,31,14,2,7156,,,0,"Make manage.py usable

It's not possible to use manage.py in its current state due to
an exception thrown by oslo.config:

  oslo.config.cfg.ArgsAlreadyParsedError:
    arguments already parsed: cannot register CLI option

This exception is a side-effect of including
cinder.openstack.common.logging in most of the migration scripts.

This change therefore suggests removing oslo.config and other imports
from manage.py to make it usable again.

It is now possible to use manage.py:

  tox -evenv -- python cinder/db/sqlalchemy/migrate_repo/manage.py \
    version_control --url=sqlite:///./cinder.db

  tox -evenv -- python cinder/db/sqlalchemy/migrate_repo/manage.py \
    upgrade --url=sqlite:///./cinder.db

Closes-bug: #1355297
Change-Id: I843cfa9a4e4758a6bc8e5c04f064e9d3107b01fa
",git fetch https://review.opendev.org/openstack/cinder refs/changes/24/112724/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/db/sqlalchemy/migrate_repo/manage.py'],1,8e38f3c824700f7a7c29ed4ee3bfe2b2afb8bf7d,bug/1355297," main(debug='False',","from oslo.config import cfg from cinder.openstack.common import gettextutils gettextutils.enable_lazy() from cinder import versionCONF = cfg.CONF CONF([], project='cinder', version=version.version_string()) main(debug='False', url=CONF.database.connection,",1,9
openstack%2Fopenstacksdk~master~Iaf830eb2d6879bfb1209d6a5cab1453b518945dc,openstack/openstacksdk,master,Iaf830eb2d6879bfb1209d6a5cab1453b518945dc,database/v1.0 instance resource,MERGED,2014-08-04 17:59:44.000000000,2014-08-13 19:25:46.000000000,2014-08-13 19:25:46.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-04 17:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4fd823704929d269541408b3c0586b7eec325422', 'message': 'database/v1.0 instance resource\n\nChange-Id: Iaf830eb2d6879bfb1209d6a5cab1453b518945dc\n'}, {'number': 2, 'created': '2014-08-13 15:36:16.000000000', 'files': ['openstack/database/__init__.py', 'openstack/tests/database/__init__.py', 'openstack/tests/database/v1/__init__.py', 'openstack/tests/database/v1/test_instance.py', 'openstack/database/database_service.py', 'openstack/database/v1/instance.py', 'openstack/database/v1/__init__.py', 'openstack/tests/database/test_database_service.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/00a0a7a196362a2efe2923aa38bdae6a75c17df7', 'message': 'database/v1.0 instance resource\n\nChange-Id: Iaf830eb2d6879bfb1209d6a5cab1453b518945dc\n'}]",1,111785,00a0a7a196362a2efe2923aa38bdae6a75c17df7,15,3,2,8736,,,0,"database/v1.0 instance resource

Change-Id: Iaf830eb2d6879bfb1209d6a5cab1453b518945dc
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/85/111785/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/database/__init__.py', 'openstack/tests/database/__init__.py', 'openstack/tests/database/v1/__init__.py', 'openstack/tests/database/v1/test_instance.py', 'openstack/database/database_service.py', 'openstack/database/v1/instance.py', 'openstack/database/v1/__init__.py', 'openstack/tests/database/test_database_service.py']",8,4fd823704929d269541408b3c0586b7eec325422,instance,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testtools from openstack.network import network_service class TestNetworkService(testtools.TestCase): def test_service(self): sot = network_service.NetworkService() self.assertEqual('network', sot.service_type) self.assertEqual('public', sot.visibility) self.assertIsNone(sot.region) self.assertIsNone(sot.service_name) ",,227,0
openstack%2Fpython-barbicanclient~master~Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f,openstack/python-barbicanclient,master,Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f,Introduce cliff for cli framework,MERGED,2014-07-17 08:13:57.000000000,2014-08-13 19:25:19.000000000,2014-08-13 19:25:19.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 6482}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7874}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8736}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 9946}, {'_account_id': 10873}, {'_account_id': 11662}, {'_account_id': 11970}]","[{'number': 1, 'created': '2014-07-17 08:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/d9654928014ecad83921c280b86a4d730c3adf23', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application is now divided logically to express actions as commands,\nand entities as facades or interfaces for the barbican library API.\nThus, if a change needs to be done to the entities\' API, there is only one\nplace to modify, which should be entity_handlers.py.\n\nThe only change between how the old cli was used and how it will be used\nnow, is that the action now goes before the entity.\n\ne.g.\n\n    $ barbican <credentials> store secret --payload ""Some payload""\n\nInstead of :\n\n    $ barbican <credentials> secret store --payload ""Some payload""\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}, {'number': 2, 'created': '2014-07-17 09:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/97d786e1f4f734866569c17e959cf535b33f1a28', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application is now divided logically to express actions as commands,\nand entities as facades or interfaces for the barbican library API.\nThus, if a change needs to be done to the entities\' API, there is only one\nplace to modify, which should be entity_handlers.py.\n\nThe only change between how the old cli was used and how it will be used\nnow, is that the action now goes before the entity.\n\ne.g.\n\n    $ barbican <credentials> store secret --payload ""Some payload""\n\nInstead of :\n\n    $ barbican <credentials> secret store --payload ""Some payload""\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}, {'number': 3, 'created': '2014-07-17 14:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/4f49df59504e3679e4ca9239d5932477dda6fca6', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application is now divided logically to express actions as commands,\nand entities as facades or interfaces for the barbican library API.\nThus, if a change needs to be done to the entities\' API, there is only one\nplace to modify, which should be entity_handlers.py.\n\nThe only change between how the old cli was used and how it will be used\nnow, is that the action now goes before the entity.\n\ne.g.\n\n    $ barbican <credentials> store secret --payload ""Some payload""\n\nInstead of :\n\n    $ barbican <credentials> secret store --payload ""Some payload""\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}, {'number': 4, 'created': '2014-07-17 14:07:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/2597e62b84d876bf0fe90aef4080ce453c2fc913', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application is now divided logically to express actions as commands,\nand entities as facades or interfaces for the barbican library API.\nThus, if a change needs to be done to the entities\' API, there is only one\nplace to modify, which should be entity_handlers.py.\n\nThe only change between how the old cli was used and how it will be used\nnow, is that the action now goes before the entity.\n\ne.g.\n\n    $ barbican <credentials> store secret --payload ""Some payload""\n\nInstead of :\n\n    $ barbican <credentials> secret store --payload ""Some payload""\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}, {'number': 5, 'created': '2014-07-29 10:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/3b572d08cfdd10e0ea79daf7834b4fba05b0fc91', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application structure was made so that it resembles the way\npython-openstackclient was done, this will enable the code to be\nintegrated to that client in a more straight forward way.\n\nNOTE: Only secrets and orders were added, since verifications are no\n      longer in use\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}, {'number': 6, 'created': '2014-07-29 10:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/5a06f0e13f59175c9158136a3b5a11fa03b24495', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application structure was made so that it resembles the way\npython-openstackclient was done, this will enable the code to be\nintegrated to that client in a more straight forward way.\n\nNOTE: Only secrets and orders were added, since verifications are no\n      longer in use\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}, {'number': 7, 'created': '2014-08-06 14:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/9300a626e62909d5c270550baffda55a1148b894', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application structure was made so that it resembles the way\npython-openstackclient was done, this will enable the code to be\nintegrated to that client in a more straight forward way.\n\nNOTE: Only secrets and orders were added, since verifications are no\n      longer in use\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}, {'number': 8, 'created': '2014-08-06 15:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/101f2c2f6991adf9fc740103121a5a52685d5ef0', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application structure was made so that it resembles the way\npython-openstackclient was done, this will enable the code to be\nintegrated to that client in a more straight forward way.\n\nNOTE: Only secrets and orders were added, since verifications are no\n      longer in use\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}, {'number': 9, 'created': '2014-08-07 06:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/9617150582e50d2350a8cb1eea2cbabf03cc6439', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application structure was made so that it resembles the way\npython-openstackclient was done, this will enable the code to be\nintegrated to that client in a more straight forward way.\n\nNOTE: Only secrets and orders were added, since verifications are no\n      longer in use\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}, {'number': 10, 'created': '2014-08-07 07:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/b0db1c281ff03d736ce3d6791bafac0bffd1ef5a', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application structure was made so that it resembles the way\npython-openstackclient was done, this will enable the code to be\nintegrated to that client in a more straight forward way.\n\nNOTE: Only secrets and orders were added, since verifications are no\n      longer in use\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}, {'number': 11, 'created': '2014-08-09 11:57:09.000000000', 'files': ['requirements.txt', 'barbicanclient/barbican_cli/orders.py', 'barbicanclient/test/test_barbican.py', 'barbicanclient/barbican_cli/__init__.py', 'barbicanclient/barbican_cli/secrets.py', 'setup.cfg', 'barbicanclient/barbican_cli/formatter.py', 'barbicanclient/barbican.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/9f0452fdc0f7e62dcf7e9fa4829ff82409f84cca', 'message': 'Introduce cliff for cli framework\n\nThis patch introduces the cliff framework from oslo.\nThe same functionality from the old command line interface was\nreplicated, and a few orthographic errors where corrected from the\ncommand help.\n\nThe application structure was made so that it resembles the way\npython-openstackclient was done, this will enable the code to be\nintegrated to that client in a more straight forward way. Same with\nthe naming of classes within the sub-commands. For example, the list\ncommands are List<Entity> and not List<Entities>; this was done in\nsuch way because it is done that way in python-openstack client;\nand the aim of this commit is to produce functional code, and at the\nsame time, follow their standards to be able to integrate this\nthere without much hassle.\n\nNOTE: Only secrets and orders were added, since verifications are no\n      longer in use\n\nImplements: blueprint cliff-for-python-barbicanclient\nChange-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f\n'}]",52,107587,9f0452fdc0f7e62dcf7e9fa4829ff82409f84cca,64,21,11,10873,,,0,"Introduce cliff for cli framework

This patch introduces the cliff framework from oslo.
The same functionality from the old command line interface was
replicated, and a few orthographic errors where corrected from the
command help.

The application structure was made so that it resembles the way
python-openstackclient was done, this will enable the code to be
integrated to that client in a more straight forward way. Same with
the naming of classes within the sub-commands. For example, the list
commands are List<Entity> and not List<Entities>; this was done in
such way because it is done that way in python-openstack client;
and the aim of this commit is to produce functional code, and at the
same time, follow their standards to be able to integrate this
there without much hassle.

NOTE: Only secrets and orders were added, since verifications are no
      longer in use

Implements: blueprint cliff-for-python-barbicanclient
Change-Id: Ice2dddf418dfb76a616b65f22dc8dfd7ef4df36f
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/87/107587/9 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', '.gitreview', 'barbicanclient/entity_handlers.py', 'barbicanclient/test/test_barbican.py', 'setup.cfg', 'barbicanclient/barbican.py']",6,d9654928014ecad83921c280b86a4d730c3adf23,bp/cliff-for-python-barbicanclient,"import sysfrom barbicanclient import entity_handlers import cliff.app import cliff.command import cliff.commandmanager class Barbican(cliff.app.App): """"""Barbican comand line interface."""""" def __init__(self, **kwargs): super(Barbican, self).__init__( description=__doc__.strip(), version='0.1', command_manager=cliff.commandmanager.CommandManager( 'barbican.client'), **kwargs def build_option_parser(self, description, version, argparse_kwargs=None): """"""Introduces global arguments for the application. This is inherited from the framework. """""" parser = super(Barbican, self).build_option_parser( description, version, argparse_kwargs) def initialize_app(self, argv): """"""Initializes the application. Checks if the minimal parameters are provided and creates the client interface. This is inherited from the framework. """""" args = self.options raise Exception( 'ERROR: please specify --endpoint and ' '--os-project-id(or --os-tenant-id)') self.stderr.write(self.parser.format_usage()) raise Exception('ERROR: please specify authentication credentials') class Create(cliff.command.Command): """"""Create a new order."""""" supported_entity_handlers = { ""order"": entity_handlers.OrderHandler, } def get_parser(self, prog_name): parser = super(Create, self).get_parser(prog_name) parser.add_argument('command', metavar='<entity>', choices=self.supported_entity_handlers.keys(), help='Entity used for command, e.g.,' ' order, secret, verification.') parser.add_argument('--name', '-n', help='a human-friendly name.') parser.add_argument('--algorithm', '-a', default='aes', help='the algorithm to be used with the ' 'requested key (default: ' '%(default)s).') parser.add_argument('--bit-length', '-b', default=256, help='the bit length of the requested' ' secret key (default: %(default)s).', type=int) parser.add_argument('--mode', '-m', default='cbc', help='the algorithm mode to be used with ' 'the requested key (default: %(default)s).') parser.add_argument('--payload-content-type', '-t', default='application/octet-stream', help='the type/format of the secret to be' ' generated (default: %(default)s).') parser.add_argument('--expiration', '-x', help='the expiration ' 'time for the secret in ISO 8601 format.') return parser def take_action(self, args): entity_handler = self.supported_entity_handlers[args.command]( self.app.client) entity = entity_handler.create(args.name, args.payload_content_type, args.algorithm, args.bit_length, args.mode, args.expiration) self.app.stdout.write(entity) class Delete(cliff.command.Command): """"""Delete a secret, order or verification by providing its href."""""" supported_entity_handlers = { ""order"": entity_handlers.OrderHandler, ""secret"": entity_handlers.SecretHandler, ""verification"": entity_handlers.VerificationsHandler, } def get_parser(self, prog_name): parser = super(Delete, self).get_parser(prog_name) parser.add_argument('command', metavar='<entity>', choices=self.supported_entity_handlers.keys(), help='Entity used for command, e.g.,' ' order, secret, verification.') parser.add_argument('URI', help='The URI reference for the' ' secret, order ' 'or verification') return parser def take_action(self, args): entity_handler = self.supported_entity_handlers[args.command]( self.app.client) entity_handler.delete(args.URI) class Get(cliff.command.Command): """"""Retrieve a secret, order or verification by providing its URI."""""" supported_entity_handlers = { ""order"": entity_handlers.OrderHandler, ""secret"": entity_handlers.SecretHandler, ""verification"": entity_handlers.VerificationsHandler, } def get_parser(self, prog_name): parser = super(Get, self).get_parser(prog_name) parser.add_argument('command', metavar='<entity>', choices=self.supported_entity_handlers.keys(), help='Entity used for command, e.g.,' ' order, secret, verification.') parser.add_argument('URI', help='The URI reference ' 'for the secret, ' 'order or verification.') parser.add_argument('--decrypt', '-d', help='if specified, keep' ' will retrieve the unencrypted secret data;' ' the data type can be specified with' ' --payload-content-type (only used for' ' secrets).', action='store_true') parser.add_argument('--payload_content_type', '-t', default='text/plain', help='the content type of the decrypted' ' secret (default: %(default)s; only used for' ' secrets)') return parser def take_action(self, args): entity_handler = self.supported_entity_handlers[args.command]( self.app.client) entity = entity_handler.get(args.URI, args.decrypt, args.payload_content_type) self.app.stdout.write(str(entity) + '\n') class List(cliff.command.Command): """"""List secrets, orders or verifications."""""" supported_entity_handlers = { ""order"": entity_handlers.OrderHandler, ""secret"": entity_handlers.SecretHandler, ""verification"": entity_handlers.VerificationsHandler, } def get_parser(self, prog_name): parser = super(List, self).get_parser(prog_name) parser.add_argument('command', metavar='<entity>', choices=self.supported_entity_handlers.keys(), help='Entity used for command, e.g.,' ' order, secret, verification.') parser.add_argument('--limit', '-l', default=10, help='specify ' 'the limit to the number of items to list per' ' page (default: %(default)s; maximum: 100)', type=int) parser.add_argument('--offset', '-o', default=0, help='specify t' 'he page offset (default: %(default)s)', type=int) parser.add_argument('--name', '-n', default=None, help='specify t' 'he secret name (default: %(default)s)') parser.add_argument('--algorithm', '-a', default=None, help='the algorithm filter for the list' '(default: %(default)s).') parser.add_argument('--bit-length', '-b', default=0, help='the bit length filter for the list' ' (default: %(default)s).', type=int) parser.add_argument('--mode', '-m', default=None, help='the algorithm mode filter for the' ' list (default: %(default)s).') return parser def take_action(self, args): entity_handler = self.supported_entity_handlers[args.command]( self.app.client) ls = entity_handler.list(args.limit, args.offset, args.name, args.mode, args.algorithm, args.bit_length) for obj in ls: self.app.stdout.write(str(obj) + '\n') self.app.stdout.write('{0}s displayed: {1} - offset: {2}'.format( args.command, len(ls), args.offset)) class Store(cliff.command.Command): """"""Store a secret in Barbican."""""" supported_entity_handlers = { ""secret"": entity_handlers.SecretHandler, } def get_parser(self, prog_name): parser = super(Store, self).get_parser(prog_name) parser.add_argument('command', metavar='<entity>', choices=self.supported_entity_handlers.keys(), help='Entity used for command, e.g.,' ' order, secret, verification.') parser.add_argument('--name', '-n', help='a human-friendly name.') parser.add_argument('--payload', '-p', help='the unencrypted' ' secret; if provided, ' 'you must also provide' ' a payload_content_type') parser.add_argument('--payload-content-type', '-t', help='the type/format of the provided ' 'secret data; ""text/plain"" is assumed to be' ' UTF-8; required when --payload is' ' supplied.') parser.add_argument('--payload-content-encoding', '-e', help='required if --payload-content-type is' ' ""application/octet-stream"".') parser.add_argument('--algorithm', '-a', default='aes', help='the algorithm (default: ' '%(default)s).') parser.add_argument('--bit-length', '-b', default=256, help='the bit length ' '(default: %(default)s).', type=int) parser.add_argument('--mode', '-m', default='cbc', help='the algorithm mode; used only for ' 'reference (default: %(default)s)') parser.add_argument('--expiration', '-x', help='the expiration ' 'time for the secret in ISO 8601 format.') return parser def take_action(self, args): entity_handler = self.supported_entity_handlers[args.command]( self.app.client) entity = entity_handler.store( args.name, args.payload, args.payload_content_type, args.payload_content_encoding, args.algorithm, args.bit_length, args.mode, args.expiration) self.app.stdout.write(str(entity) + '\n') class Verify(cliff.command.Command): """"""Create a new verification."""""" supported_entity_handlers = { ""verifications"": entity_handlers.VerificationsHandler, } def get_parser(self, prog_name): parser = super(Verify, self).get_parser(prog_name) parser.add_argument('command', metavar='<entity>', choices=self.supported_entity_handlers.keys(), help='Entity used for command, e.g.,' ' order, secret, verification.') parser.add_argument('--type', '-t', default='image', help='resource type to verify, ' 'such as ""image"".') parser.add_argument('--ref', '-r', help='reference URI to ' 'resource to verify.') parser.add_argument('--action', '-a', default='vm_attach', help='action to perform on ' 'resource, such as ""vm_attach"".') parser.add_argument('--impersonation', '-i', default=True, help='is impersonation allowed ' 'for the resource.') return parser def take_action(self, args): entity_handler = self.supported_entity_handlers[args.command]( self.app.client) entity = entity_handler.verify( resource_type=args.type, resource_ref=args.ref, action=args.action, impersonation_allowed=args.impersonation) self.app.stdout.write(entity) def main(argv=sys.argv[1:]): barbican_app = Barbican() return barbican_app.run(argv) sys.exit(main(sys.argv[1:]))"," class Barbican: def __init__(self): self.parser = self._get_main_parser() self.subparsers = self.parser.add_subparsers( title='subcommands', metavar='<action>', description='Action to perform' self._add_create_args() self._add_store_args() self._add_get_args() self._add_list_args() self._add_verify_args() self._add_delete_args() def _get_main_parser(self): parser = argparse.ArgumentParser( description=__doc__.strip() ) parser.add_argument('command', metavar='<entity>', choices=['order', 'secret', 'verification'], help='Entity used for command, e.g.,' ' order, secret, verification.') def _add_verify_args(self): verify_parser = self.subparsers.add_parser('verify', help='Create a new ' 'verification.') verify_parser.add_argument('--type', '-t', default='image', help='resource type to verify, ' 'such as ""image"".') verify_parser.add_argument('--ref', '-r', help='reference URI to ' 'resource to verify.') verify_parser.add_argument('--action', '-a', default='vm_attach', help='action to perform on ' 'resource, such as ""vm_attach"".') verify_parser.add_argument('--impersonation', '-i', default=True, help='is impersonation allowed ' 'for the resource.') verify_parser.set_defaults(func=self.verify) def _add_create_args(self): create_parser = self.subparsers.add_parser('create', help='Create a new order.') create_parser.add_argument('--name', '-n', help='a human-friendly name.') create_parser.add_argument('--algorithm', '-a', default='aes', help='the algorithm to be used with the ' 'requested key (default: ' '%(default)s).') create_parser.add_argument('--bit-length', '-b', default=256, help='the bit length of the requested' ' secret key (default: %(default)s).', type=int) create_parser.add_argument('--mode', '-m', default='cbc', help='the algorithmm mode to be used with ' 'the rquested key (default: %(default)s).') create_parser.add_argument('--payload-content-type', '-t', default='application/octet-stream', help='the type/format of the secret to be' ' generated (default: %(default)s).') create_parser.add_argument('--expiration', '-x', help='the expiration ' 'time for the secret in ISO 8601 format.') create_parser.set_defaults(func=self.create) def _add_store_args(self): store_parser = self.subparsers.add_parser( 'store', help='Store a secret in barbican.' ) store_parser.add_argument('--name', '-n', help='a human-friendly name.') store_parser.add_argument('--payload', '-p', help='the unencrypted' ' secret; if provided, ' 'you must also provide' ' a payload_content_type') store_parser.add_argument('--payload-content-type', '-t', help='the type/format of the provided ' 'secret data; ""text/plain"" is assumed to be' ' UTF-8; required when --payload is' ' supplied.') store_parser.add_argument('--payload-content-encoding', '-e', help='required if --payload-content-type is' ' ""application/octet-stream"".') store_parser.add_argument('--algorithm', '-a', default='aes', help='the algorithm (default: ' '%(default)s).') store_parser.add_argument('--bit-length', '-b', default=256, help='the bit length ' '(default: %(default)s).', type=int) store_parser.add_argument('--mode', '-m', default='cbc', help='the algorithmm mode; used only for ' 'reference (default: %(default)s)') store_parser.add_argument('--expiration', '-x', help='the expiration ' 'time for the secret in ISO 8601 format.') store_parser.set_defaults(func=self.store) def _add_delete_args(self): delete_parser = self.subparsers.add_parser( 'delete', help='Delete a secret, order or ' 'verification by providing its href.' ) delete_parser.add_argument('URI', help='The URI reference for the' ' secret, order ' 'or verification') delete_parser.set_defaults(func=self.delete) def _add_get_args(self): get_parser = self.subparsers.add_parser( 'get', help='Retrieve a secret, order or ' 'verification by providing its URI.' ) get_parser.add_argument('URI', help='The URI reference ' 'for the secret, ' 'order or verification.') get_parser.add_argument('--decrypt', '-d', help='if specified, keep' ' will retrieve the unencrypted secret data;' ' the data type can be specified with' ' --payload-content-type (only used for' ' secrets).', action='store_true') get_parser.add_argument('--payload_content_type', '-t', default='text/plain', help='the content type of the decrypted' ' secret (default: %(default)s; only used for' ' secrets)') get_parser.set_defaults(func=self.get) def _add_list_args(self): list_parser = self.subparsers.add_parser('list', help='List secrets, ' 'orders or ' 'verifications') list_parser.add_argument('--limit', '-l', default=10, help='specify ' 'the limit to the number of items to list per' ' page (default: %(default)s; maximum: 100)', type=int) list_parser.add_argument('--offset', '-o', default=0, help='specify t' 'he page offset (default: %(default)s)', type=int) list_parser.add_argument('--name', '-n', default=None, help='specify t' 'he secret name (default: %(default)s)') list_parser.add_argument('--algorithm', '-a', default=None, help='the algorithm filter for the list' '(default: %(default)s).') list_parser.add_argument('--bit-length', '-b', default=0, help='the bit length filter for the list' ' (default: %(default)s).', type=int) list_parser.add_argument('--mode', '-m', default=None, help='the algorithmm mode filter for the' ' list (default: %(default)s).') list_parser.set_defaults(func=self.list) def store(self, args): if args.command == 'secret': secret = self.client.secrets.store(args.name, args.payload, args.payload_content_type, args.payload_content_encoding, args.algorithm, args.bit_length, args.mode, args.expiration) print(secret) else: self.parser.exit(status=1, message='ERROR: store is only supported' ' for secrets\n') def create(self, args): if args.command == 'order': order = self.client.orders.create(args.name, args.payload_content_type, args.algorithm, args.bit_length, args.mode, args.expiration) print(order) else: self.parser.exit(status=1, message='ERROR: create is only ' 'supported for orders\n') def delete(self, args): if args.command == 'secret': self.client.secrets.delete(args.URI) elif args.command == 'verification': self.client.verifications.delete(args.URI) elif args.command == 'order': self.client.orders.delete(args.URI) else: self.parser.exit(status=1, message='ERROR: delete is only ' 'supported for secrets, ' 'orders or verifications\n') def get(self, args): if args.command == 'secret': if args.decrypt: print(self.client.secrets.decrypt(args.URI, args.payload_content_type)) else: print(self.client.secrets.get(args.URI)) elif args.command == 'verification': print(self.client.verifications.get(args.URI)) elif args.command == 'order': print(self.client.orders.get(args.URI)) else: self.parser.exit(status=1, message='ERROR: get is only ' 'supported for secrets, ' 'orders or verifications\n') def list(self, args): if args.command == 'secret': ls = self.client.secrets.list(limit=args.limit, offset=args.offset, name=args.name, mode=args.mode, algorithm=args.algorithm, bits=args.bit_length) elif args.command == 'verification': ls = self.client.verifications.list(args.limit, args.offset) elif args.command == 'order': ls = self.client.orders.list(args.limit, args.offset) else: self.parser.exit(status=1, message='ERROR: get list is only ' 'supported for secrets, ' 'orders or verifications\n') for obj in ls: print(obj) print('{0}s displayed: {1} - offset: {2}'.format(args.command, len(ls), args.offset)) def verify(self, args): if args.command == 'verification': verify = self.client.verifications\ .create(resource_type=args.type, resource_ref=args.ref, resource_action=args.action, impersonation_allowed=args.impersonation) print(verify) else: self.parser.exit(status=1, message='ERROR: verify is only ' 'supported for verifications\n') def execute(self, **kwargs): args = self.parser.parse_args(kwargs.get('argv')) self.parser.exit( status=1, message='ERROR: please specify --endpoint and ' '--os-project-id(or --os-tenant-id)\n') self.parser.exit( status=1, message='ERROR: please specify authentication credentials\n' ) args.func(args) def main(): k = Barbican() k.execute() main()",501,295
openstack%2Fpython-saharaclient~master~Ib3c47249eb58409b4c72c1beecd2403984c9e82e,openstack/python-saharaclient,master,Ib3c47249eb58409b4c72c1beecd2403984c9e82e,Added hadling of non-json response from Sahara,MERGED,2014-08-08 22:54:31.000000000,2014-08-13 18:38:18.000000000,2014-08-13 18:38:17.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-08-08 22:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/2d715057f96ed5912e3b0b16fabffa4adb5174be', 'message': 'Added hadling of non-json response from Sahara\n\nAdded predicted behavior in case if Sahara responds with\nservice exceptions. Client now can handle non-json responses.\n\nChange-Id: Ib3c47249eb58409b4c72c1beecd2403984c9e82e\nCloses-Bug: #1354556\n'}, {'number': 2, 'created': '2014-08-09 00:08:22.000000000', 'files': ['saharaclient/api/base.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/3403ae4de4134b70c00443b42afaa7470a56d2b5', 'message': 'Added hadling of non-json response from Sahara\n\nAdded predicted behavior in case if Sahara responds with\nservice exceptions. Client now can handle non-json responses.\n\nChange-Id: Ib3c47249eb58409b4c72c1beecd2403984c9e82e\nCloses-Bug: #1354556\n'}]",0,113040,3403ae4de4134b70c00443b42afaa7470a56d2b5,30,6,2,8411,,,0,"Added hadling of non-json response from Sahara

Added predicted behavior in case if Sahara responds with
service exceptions. Client now can handle non-json responses.

Change-Id: Ib3c47249eb58409b4c72c1beecd2403984c9e82e
Closes-Bug: #1354556
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/40/113040/2 && git format-patch -1 --stdout FETCH_HEAD,['saharaclient/api/base.py'],1,2d715057f96ed5912e3b0b16fabffa4adb5174be,bug/1354556,"from saharaclient.openstack.common.gettextutils import _ try: error_data = get_json(resp) except Exception: raise APIException( error_code=resp.status_code, error_message=_(""Failed to parse response from Sahara. Check "" ""if service catalog configured properly."")) ", error_data = get_json(resp),10,1
openstack%2Fnova~master~I27001c9f17dad4dc4ca8cd032e689736553d8225,openstack/nova,master,I27001c9f17dad4dc4ca8cd032e689736553d8225,Neutron v2 API: fix get_floating_ip_pools,MERGED,2014-08-12 15:19:14.000000000,2014-08-13 18:38:08.000000000,2014-08-13 18:38:05.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 642}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2592}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-12 15:19:14.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d449b5d8556e67be08e016c94f9b1c523a69ce7e', 'message': ""Neutron v2 API: fix get_floating_ip_pools\n\nCommit 7254f9b9dfbadadeb3aeda5d02bf37bfeb65e72d changed this method\nin nova.network.api in a way that it now returns simply a list of\nfloating ip pool names, rather a list of dicts in the form\n\n{'name': 'pool_name'}\n\nThe implementation of get_floating_ip_pools for neutron needs to\nbe changed accordingly. Otherwise nova's floating ip extension\nwill return a dict as floating ip pool names when neutron is enabled.\n\nChange-Id: I27001c9f17dad4dc4ca8cd032e689736553d8225\nCloses-Bug: #1355882\n""}]",2,113554,d449b5d8556e67be08e016c94f9b1c523a69ce7e,28,15,1,261,,,0,"Neutron v2 API: fix get_floating_ip_pools

Commit 7254f9b9dfbadadeb3aeda5d02bf37bfeb65e72d changed this method
in nova.network.api in a way that it now returns simply a list of
floating ip pool names, rather a list of dicts in the form

{'name': 'pool_name'}

The implementation of get_floating_ip_pools for neutron needs to
be changed accordingly. Otherwise nova's floating ip extension
will return a dict as floating ip pool names when neutron is enabled.

Change-Id: I27001c9f17dad4dc4ca8cd032e689736553d8225
Closes-Bug: #1355882
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/113554/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py']",2,d449b5d8556e67be08e016c94f9b1c523a69ce7e,bug1355882," """"""Return floating ip pool names."""""" # Note(salv-orlando): Return a list of names to be consistent with # nova.network.api.get_floating_ip_pools return [n['name'] or n['id'] for n in pools]"," """"""Return floating ip pools."""""" return [{'name': n['name'] or n['id']} for n in pools]",5,4
openstack%2Fcinder~master~Ie9d199769e63f5a91270e3fc2e5f58766d1bd41c,openstack/cinder,master,Ie9d199769e63f5a91270e3fc2e5f58766d1bd41c,Add timer info for copy operations,MERGED,2014-08-07 04:19:36.000000000,2014-08-13 18:37:56.000000000,2014-08-13 18:37:55.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 9533}, {'_account_id': 9751}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-08-07 04:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/42c7459f58e425d7163c9bb4453c00879e98aee0', 'message': 'Add timer info for copy operations\n\nThis is just an add of some useful info to monitor\nhow much time we spend on various operations during\nclear volume and copy image_to_volume.\n\nChange-Id: Ie9d199769e63f5a91270e3fc2e5f58766d1bd41c\n'}, {'number': 2, 'created': '2014-08-07 17:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d895e239de9d9c3cf5d3f8e79dba262ec84f152c', 'message': 'Add timer info for copy operations\n\nThis is just an add of some useful info to monitor\nhow much time we spend on various operations during\nclear volume and copy image_to_volume.\n\nChange-Id: Ie9d199769e63f5a91270e3fc2e5f58766d1bd41c\n'}, {'number': 3, 'created': '2014-08-07 19:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d81275c3196c5aa113f6426b3017fcff179f7d29', 'message': 'Add timer info for copy operations\n\nThis is just an add of some useful info to monitor\nhow much time we spend on various operations during\nclear volume and copy image_to_volume.\n\nChange-Id: Ie9d199769e63f5a91270e3fc2e5f58766d1bd41c\n'}, {'number': 4, 'created': '2014-08-11 23:14:42.000000000', 'files': ['cinder/volume/utils.py', 'cinder/image/image_utils.py', 'cinder/tests/test_image_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/202ebc2d987c86984ba9cf8e8e36c32899baaa3b', 'message': 'Add timer info for copy operations\n\nThis is just an add of some useful info to monitor\nhow much time we spend on various operations during\nclear volume and copy image_to_volume.\n\nChange-Id: Ie9d199769e63f5a91270e3fc2e5f58766d1bd41c\n'}]",3,112468,202ebc2d987c86984ba9cf8e8e36c32899baaa3b,45,15,4,2243,,,0,"Add timer info for copy operations

This is just an add of some useful info to monitor
how much time we spend on various operations during
clear volume and copy image_to_volume.

Change-Id: Ie9d199769e63f5a91270e3fc2e5f58766d1bd41c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/68/112468/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/utils.py', 'cinder/image/image_utils.py']",2,42c7459f58e425d7163c9bb4453c00879e98aee0,add_timer_around_copy_operations,"from cinder.openstack.common import timeutils start_time = timeutils.utcnow() duration = timeutils.delta_seconds(start_time, timeutils.utcnow()) LOG.info(_('Image conversion info, source: %(source)s, ' 'destination: %(dest)s, format: %(format)s, ' 'duration: %(duration).2f secs'), {'source': source, 'dest': dest, 'format': format, 'duration': duration}) start_time = timeutils.utcnow() duration = timeutils.delta_seconds(start_time, timeutils.utcnow()) LOG.inf(_('Elapsed time to fetch image from image ' 'service: %.2f seconds') % duration)",,20,1
openstack%2Fgrenade~stable%2Ficehouse~Ieb05c7ba2959c26c987667dba751e94b899772af,openstack/grenade,stable/icehouse,Ieb05c7ba2959c26c987667dba751e94b899772af,Remove deprecated glance commands from javelin setup,MERGED,2014-08-13 13:15:35.000000000,2014-08-13 18:37:50.000000000,2014-08-13 18:37:49.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 7872}, {'_account_id': 9096}]","[{'number': 1, 'created': '2014-08-13 13:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/45cb4f53b85f823336a75a443b941a40728193cd', 'message': 'Remove deprecated glance commands from javelin setup\n\nThere are some deprecated commands being used in the javelin setup\nthey should be removed since we are removing all the deprecated\nglance client commands in this patch\nhttp://review.openstack.org/#/c/108804/\n\nChange-Id: Ieb05c7ba2959c26c987667dba751e94b899772af\n(cherry picked from commit 6c4165320118e669f223398633c6a761ed442522)\n'}, {'number': 2, 'created': '2014-08-13 13:16:02.000000000', 'files': ['setup-javelin'], 'web_link': 'https://opendev.org/openstack/grenade/commit/3be1c825f9217dbedb27ade2facd4834dede141d', 'message': 'Remove deprecated glance commands from javelin setup\n\nThere are some deprecated commands being used in the javelin setup\nthey should be removed since we are removing all the deprecated\nglance client commands in this patch\nhttp://review.openstack.org/#/c/108804/\n\nCloses-Bug: #1356310\n\nChange-Id: Ieb05c7ba2959c26c987667dba751e94b899772af\n(cherry picked from commit 6c4165320118e669f223398633c6a761ed442522)\n'}]",0,113878,3be1c825f9217dbedb27ade2facd4834dede141d,11,5,2,5196,,,0,"Remove deprecated glance commands from javelin setup

There are some deprecated commands being used in the javelin setup
they should be removed since we are removing all the deprecated
glance client commands in this patch
http://review.openstack.org/#/c/108804/

Closes-Bug: #1356310

Change-Id: Ieb05c7ba2959c26c987667dba751e94b899772af
(cherry picked from commit 6c4165320118e669f223398633c6a761ed442522)
",git fetch https://review.opendev.org/openstack/grenade refs/changes/78/113878/2 && git format-patch -1 --stdout FETCH_HEAD,['setup-javelin'],1,45cb4f53b85f823336a75a443b941a40728193cd,bug/1356310,"IMAGE_ID=$(cat /proc/sys/kernel/random/uuid) glance image-create --name $JAVELIN_IMAGE-kernel --is-public True --container-format aki --disk-format aki < ""$KERNEL_ID"" glance image-create --name $JAVELIN_IMAGE-ramdisk --is-public True --container-format ari --disk-format ari < ""$RAMDISK_ID"" glance image-create --name $JAVELIN_IMAGE.img --is-public True --id $IMAGE_ID --container-format ami --disk-format ami --property kernel_id=$KERNEL_ID --property ramdisk_id=$RAMDISK_ID < ""${ROOTDISK}"" IMAGE=$IMAGE_ID"," # Old glance client cuts off name field, use nova image-list for now RVAL=$(glance add --silent-upload name=$JAVELIN_IMAGE-kernel is_public=True container_format=aki disk_format=aki <""$KERNEL"") KERNEL_ID=$(echo $RVAL | cut -d"":"" -f2 | tr -d "" "") RVAL=$(glance add --silent-upload name=$JAVELIN_IMAGE-ramdisk is_public=True container_format=ari disk_format=ari <""$RAMDISK"") RAMDISK_ID=$(echo $RVAL | cut -d"":"" -f2 | tr -d "" "") glance add name=$JAVELIN_IMAGE.img is_public=True container_format=ami disk_format=ami ${KERNEL_ID:+kernel_id=$KERNEL_ID} ${RAMDISK_ID:+ramdisk_id=$RAMDISK_ID} < ""${ROOTDISK}"" IMAGE=$(nova image-list | awk ""/ $JAVELIN_IMAGE.img / { print \$2 }"")",5,7
openstack%2Fcliff~master~I7d31cb8c1700984e6bd951ee05817b2e6a915da4,openstack/cliff,master,I7d31cb8c1700984e6bd951ee05817b2e6a915da4,Set the main logger name to match the application,MERGED,2014-07-25 13:46:15.000000000,2014-08-13 18:37:47.000000000,2014-08-13 18:37:47.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6482}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-07-25 13:46:15.000000000', 'files': ['cliff/app.py'], 'web_link': 'https://opendev.org/openstack/cliff/commit/6bb694439eae235a9e4b88361863f6dee60852ac', 'message': 'Set the main logger name to match the application\n\nChange the main logger to use the application\'s name instead of\n\'cliff.app\' so that unhandled errors reported as oneliners come out as\n""ERROR: myapp some problem happened"" instead of\n""ERROR: cliff.app some problem happened"".\n\nChange-Id: I7d31cb8c1700984e6bd951ee05817b2e6a915da4\nCloses-bug: #1348648\n'}]",0,109578,6bb694439eae235a9e4b88361863f6dee60852ac,21,6,1,2472,,,0,"Set the main logger name to match the application

Change the main logger to use the application's name instead of
'cliff.app' so that unhandled errors reported as oneliners come out as
""ERROR: myapp some problem happened"" instead of
""ERROR: cliff.app some problem happened"".

Change-Id: I7d31cb8c1700984e6bd951ee05817b2e6a915da4
Closes-bug: #1348648
",git fetch https://review.opendev.org/openstack/cliff refs/changes/78/109578/1 && git format-patch -1 --stdout FETCH_HEAD,['cliff/app.py'],1,6bb694439eae235a9e4b88361863f6dee60852ac,bug/1348648," LOG = logging.getLogger(NAME) self.LOG.exception(err) self.LOG.error(err) self.LOG.error(err) self.LOG.exception(err) else: self.LOG.error(err) self.LOG.exception(err2) else: self.LOG.error('Could not clean up: %s', err2) self.LOG.exception(err3) else: self.LOG.error('Could not clean up: %s', err3)","LOG = logging.getLogger(__name__) LOG.exception(err) LOG.error(err) LOG.error(err) LOG.exception(err) else: LOG.error(err) LOG.exception(err2) else: LOG.error('Could not clean up: %s', err2) LOG.exception(err3) else: LOG.error('Could not clean up: %s', err3)",10,12
openstack%2Ftripleo-heat-templates~master~I039f57ab39c1fcfc319a7a34265ba4fabf4ccd08,openstack/tripleo-heat-templates,master,I039f57ab39c1fcfc319a7a34265ba4fabf4ccd08,Switch to heat_template_version: 2013-05-23,MERGED,2014-08-10 21:21:31.000000000,2014-08-13 18:31:43.000000000,2014-08-13 18:31:43.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6928}, {'_account_id': 9369}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-08-10 21:21:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dca4140305de77616871690cecbc54b613035496', 'message': 'Switch to heat_template_version: 2013-05-23\n\nTo support underclouds and seeds running older than the very\nlatest heat.\n\n2013-05-23 lacks function list_join, so this change reverts to\nusing the equivalent function Fn::Join.\n\nChange-Id: I039f57ab39c1fcfc319a7a34265ba4fabf4ccd08\nCloses-Bug: #1354305\n'}, {'number': 2, 'created': '2014-08-12 22:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0e57cef8f2146669adb006df38f94ce75be561f5', 'message': 'Switch to heat_template_version: 2013-05-23\n\nTo support underclouds and seeds running older than the very\nlatest heat.\n\n2013-05-23 lacks function list_join, so this change reverts to\nusing the equivalent function Fn::Join.\n\nChange-Id: I039f57ab39c1fcfc319a7a34265ba4fabf4ccd08\nCloses-Bug: #1354305\n'}, {'number': 3, 'created': '2014-08-12 22:56:08.000000000', 'files': ['examples/source_hot.yaml', 'controller.yaml', 'block-storage-nfs.yaml', 'nfs-server-source.yaml', 'nagios3.yaml', 'tripleo_heat_merge/merge.py', 'undercloud-source.yaml', 'base.yaml', 'overcloud-source.yaml', 'nova-compute-instance.yaml', 'swift-storage-source.yaml', 'swift-deploy.yaml', 'block-storage.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8a99e7d461f211f43751d5c72c8dbc5d1ae05ead', 'message': 'Switch to heat_template_version: 2013-05-23\n\nTo support underclouds and seeds running older than the very\nlatest heat.\n\n2013-05-23 lacks function list_join, so this change reverts to\nusing the equivalent function Fn::Join.\n\nChange-Id: I039f57ab39c1fcfc319a7a34265ba4fabf4ccd08\nCloses-Bug: #1354305\n'}]",0,113148,8a99e7d461f211f43751d5c72c8dbc5d1ae05ead,25,5,3,4571,,,0,"Switch to heat_template_version: 2013-05-23

To support underclouds and seeds running older than the very
latest heat.

2013-05-23 lacks function list_join, so this change reverts to
using the equivalent function Fn::Join.

Change-Id: I039f57ab39c1fcfc319a7a34265ba4fabf4ccd08
Closes-Bug: #1354305
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/48/113148/2 && git format-patch -1 --stdout FETCH_HEAD,"['examples/source_hot.yaml', 'controller.yaml', 'block-storage-nfs.yaml', 'nfs-server-source.yaml', 'nagios3.yaml', 'tripleo_heat_merge/merge.py', 'undercloud-source.yaml', 'base.yaml', 'overcloud-source.yaml', 'nova-compute-instance.yaml', 'swift-storage-source.yaml', 'swift-deploy.yaml', 'block-storage.yaml']",13,dca4140305de77616871690cecbc54b613035496,bug/1354305,"heat_template_version: 2013-05-23 cinder_dsn: {""Fn::Join"": ['', ['mysql://cinder:unset@', {get_attr: [controller0, networks, ctlplane, 0]} , '/cinder']]}","heat_template_version: 2014-10-16 cinder_dsn: {list_join: ['', ['mysql://cinder:unset@', {get_attr: [controller0, networks, ctlplane, 0]} , '/cinder']]}",60,60
openstack%2Fpuppet-horizon~master~I4442d66c68684ad3997c24f7b7563cb4db42d13f,openstack/puppet-horizon,master,I4442d66c68684ad3997c24f7b7563cb4db42d13f,use class apache purge_configs => false for better co-existence,ABANDONED,2014-07-25 18:56:58.000000000,2014-08-13 18:21:36.000000000,,"[{'_account_id': 3}, {'_account_id': 6994}, {'_account_id': 9983}, {'_account_id': 10540}]","[{'number': 1, 'created': '2014-07-25 18:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/bb5fd3eee692be820e95d918133b934c6afdf9e0', 'message': ""use class apache purge_configs => false for better co-existence\n\nSome other openstack modules are moving to use mod_wsgi for\nperformance, security, etc.  Use\n class { '::apache':\n   purge_configs => false,\n }\nso as not to wipe out the apache config from other modules.\nNOTE: This requires that the framework do the initial apache\ninitialization and config using include ::apache.  This means that\npackstack, astapor, staypuft, foreman, etc. will have to somewhere\ndo the include ::apache before processing the puppet manifests for\nthe openstack components.\n\nChange-Id: I4442d66c68684ad3997c24f7b7563cb4db42d13f\nCloses-Bug: #1348729\n""}, {'number': 2, 'created': '2014-07-25 20:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/68419423a7c985b21431c785a580ed824433dbb2', 'message': ""use class apache purge_configs => false for better co-existence\n\nSome other openstack modules are moving to use mod_wsgi for\nperformance, security, etc.  Use\n class { '::apache':\n   purge_configs => false,\n }\nso as not to wipe out the apache config from other modules.\nNOTE: This requires that the framework do the initial apache\ninitialization and config using include ::apache.  This means that\npackstack, astapor, staypuft, foreman, etc. will have to somewhere\ndo the include ::apache before processing the puppet manifests for\nthe openstack components.\n\nChange-Id: I4442d66c68684ad3997c24f7b7563cb4db42d13f\nCloses-Bug: #1348729\n""}, {'number': 3, 'created': '2014-08-08 18:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/35834ba039f91057b7d227e1daa36e1e81abfc4f', 'message': ""use class apache purge_configs => false for better co-existence\n\nSome other openstack modules are moving to use mod_wsgi for\nperformance, security, etc.  Use\n class { '::apache':\n   purge_configs => false,\n }\nso as not to wipe out the apache config from other modules.\nNOTE: This requires that the framework do the initial apache\ninitialization and config using include ::apache.  This means that\npackstack, astapor, staypuft, foreman, etc. will have to somewhere\ndo the include ::apache before processing the puppet manifests for\nthe openstack components.\n\nChange-Id: I4442d66c68684ad3997c24f7b7563cb4db42d13f\nCloses-Bug: #1348729\n""}, {'number': 4, 'created': '2014-08-13 00:16:45.000000000', 'files': ['manifests/wsgi/apache.pp', 'spec/classes/horizon_init_spec.rb', 'spec/classes/horizon_wsgi_apache_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/865d9a7ba8639ad3b55c96da4e4e2461ecbc8c04', 'message': ""use class apache purge_configs => false for better co-existence\n\nSome other openstack modules are moving to use mod_wsgi for\nperformance, security, etc.  Use\n class { '::apache':\n   purge_configs => false,\n }\nso as not to wipe out the apache config from other modules.\nNOTE: This requires that the framework do the initial apache\ninitialization and config using include ::apache.  This means that\npackstack, astapor, staypuft, foreman, etc. will have to somewhere\ndo the include ::apache before processing the puppet manifests for\nthe openstack components.\n\nAlso had to use class { '::apache::mod::ssl' } instead of\ninclude ::apache::mod::ssl to work around a template/class\norder of evaulation problem with PUPPET_SPEC_VERSION ~> 2.7.0\n\nChange-Id: I4442d66c68684ad3997c24f7b7563cb4db42d13f\nCloses-Bug: #1348729\n""}]",7,109683,865d9a7ba8639ad3b55c96da4e4e2461ecbc8c04,18,4,4,9983,,,0,"use class apache purge_configs => false for better co-existence

Some other openstack modules are moving to use mod_wsgi for
performance, security, etc.  Use
 class { '::apache':
   purge_configs => false,
 }
so as not to wipe out the apache config from other modules.
NOTE: This requires that the framework do the initial apache
initialization and config using include ::apache.  This means that
packstack, astapor, staypuft, foreman, etc. will have to somewhere
do the include ::apache before processing the puppet manifests for
the openstack components.

Also had to use class { '::apache::mod::ssl' } instead of
include ::apache::mod::ssl to work around a template/class
order of evaulation problem with PUPPET_SPEC_VERSION ~> 2.7.0

Change-Id: I4442d66c68684ad3997c24f7b7563cb4db42d13f
Closes-Bug: #1348729
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/83/109683/3 && git format-patch -1 --stdout FETCH_HEAD,['manifests/wsgi/apache.pp'],1,bb5fd3eee692be820e95d918133b934c6afdf9e0,bug/1348729," # NOTE: This depends on the framework doing # include ::apache # to initialize the apache config files # e.g. packstack, astapor, staypuft, etc. class { '::apache': purge_configs => false, }", include ::apache,7,1
openstack%2Ftripleo-ci~master~I68f53769484a342990db5273bf47cda932c87bbe,openstack/tripleo-ci,master,I68f53769484a342990db5273bf47cda932c87bbe,Extract audit.log from archive,MERGED,2014-08-11 20:56:16.000000000,2014-08-13 18:13:28.000000000,2014-08-13 18:13:27.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}]","[{'number': 1, 'created': '2014-08-11 20:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a74bfc97ec0802a7f2ed9c31903f7de9223b7a39', 'message': 'WIP: Extract audit.log from archive\n\nThis makes it possible to view the file from a browser without\nhaving to download and to extract the archive file.\n\nChange-Id: I68f53769484a342990db5273bf47cda932c87bbe\n'}, {'number': 2, 'created': '2014-08-12 21:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3abb025f95de32e098bdd220d09054d433acc43b', 'message': 'Extract audit.log from archive\n\nThis makes it possible to view the file from a browser without\nhaving to extract from the archive file.\n\nChange-Id: I68f53769484a342990db5273bf47cda932c87bbe\n'}, {'number': 3, 'created': '2014-08-12 21:37:07.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fd8e00df3f68c41b4dbae92ca54ff8cbe75c1caf', 'message': 'Extract audit.log from archive\n\nThis makes it possible to view the file from a browser without\nhaving to extract from the archive file.\n\nChange-Id: I68f53769484a342990db5273bf47cda932c87bbe\n'}]",0,113370,fd8e00df3f68c41b4dbae92ca54ff8cbe75c1caf,20,5,3,7471,,,0,"Extract audit.log from archive

This makes it possible to view the file from a browser without
having to extract from the archive file.

Change-Id: I68f53769484a342990db5273bf47cda932c87bbe
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/70/113370/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,a74bfc97ec0802a7f2ed9c31903f7de9223b7a39,audit-log," tar xJvf $WORKSPACE/logs/$1_logs.tar.xz -C $WORKSPACE/logs/$1_logs ""var/log/audit/audit.log""",,1,0
openstack%2Fpython-monascaclient~master~I92867da65d5e4dee1bad6a177bf06ec49c850447,openstack/python-monascaclient,master,I92867da65d5e4dee1bad6a177bf06ec49c850447,help for dimensions mentions need for quoting,MERGED,2014-08-12 20:58:43.000000000,2014-08-13 18:11:24.000000000,2014-08-13 18:11:23.000000000,"[{'_account_id': 3}, {'_account_id': 11094}, {'_account_id': 12133}]","[{'number': 1, 'created': '2014-08-12 20:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/15713b117f5a9dad729ca3458e9fefbf79d5f6b9', 'message': 'help for dimensions mentions need for quoting\n\nChange-Id: I92867da65d5e4dee1bad6a177bf06ec49c850447\n'}, {'number': 2, 'created': '2014-08-13 16:25:04.000000000', 'files': ['monascaclient/v2_0/shell.py'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/5ecaf95d0ef93d40a35f01ba22544628c09146c3', 'message': 'help for dimensions mentions need for quoting\n\nChange-Id: I92867da65d5e4dee1bad6a177bf06ec49c850447\n'}]",0,113650,5ecaf95d0ef93d40a35f01ba22544628c09146c3,11,3,2,12133,,,0,"help for dimensions mentions need for quoting

Change-Id: I92867da65d5e4dee1bad6a177bf06ec49c850447
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/50/113650/1 && git format-patch -1 --stdout FETCH_HEAD,['monascaclient/v2_0/shell.py'],1,15713b117f5a9dad729ca3458e9fefbf79d5f6b9,url-dimension," 'separated by a comma. ' 'Dimensions need quoting when they contain special chars [&,(,),{,},>,<] ' 'that confuse the CLI parser.', print(args.dimensions) 'separated by a comma. ' 'Dimensions need quoting when they contain special chars [&,(,),{,},>,<] ' 'that confuse the CLI parser.', 'separated by a comma. ' 'Dimensions need quoting when they contain special chars [&,(,),{,},>,<] ' 'that confuse the CLI parser.', 'separated by a comma. ' 'Dimensions need quoting when they contain special chars [&,(,),{,},>,<] ' 'that confuse the CLI parser.', help='The alarm expression to evaluate. Quoted.') 'separated by a comma. ' 'Dimensions need quoting when they contain special chars [&,(,),{,},>,<] ' 'that confuse the CLI parser.', help='The alarm expression to evaluate. Quoted.') help='The alarm expression to evaluate. Quoted, No spaces.') 'separated by a comma. ' 'Dimensions need quoting when they contain special chars [&,(,),{,},>,<] ' 'that confuse the CLI parser.',"," 'separated by a comma.', 'separated by a comma.', 'separated by a comma.', 'separated by a comma.', help='The alarm expression to evaluate. No spaces.') 'separated by a comma.', help='The alarm expression to evaluate. No spaces.') help='The alarm expression to evaluate. No spaces.') 'separated by a comma.',",22,9
openstack%2Frally~master~Ib7887c0a0b65d67a814222e0786fc228cd5bd2ca,openstack/rally,master,Ib7887c0a0b65d67a814222e0786fc228cd5bd2ca,Update the scenario_base to base in benchmarks,MERGED,2014-08-08 16:59:54.000000000,2014-08-13 18:10:21.000000000,2014-08-13 18:10:20.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-08-08 16:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e3a6d05178355e92c2c7280fc66fdd2f6579f99d', 'message': 'Update the scenari_base to base in benchmarks\n\nKeep the scenario_base only on places where required.\nRest keep it as base instead of scenario_base\n\nChange-Id: Ib7887c0a0b65d67a814222e0786fc228cd5bd2ca\n'}, {'number': 2, 'created': '2014-08-08 17:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e5f3c373367830723f1c15109309b82818af6a24', 'message': 'Update the scenario_base to base in benchmarks\n\nKeep the scenario_base only on places where required.\nRest keep it as base instead of scenario_base\n\nChange-Id: Ib7887c0a0b65d67a814222e0786fc228cd5bd2ca\n'}, {'number': 3, 'created': '2014-08-13 14:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/db29a78bfea96d0ea983290ee1484b4191af44ee', 'message': 'Update the scenario_base to base in benchmarks\n\nKeep the scenario_base only on places where required.\nRest keep it as base instead of scenario_base\n\nChange-Id: Ib7887c0a0b65d67a814222e0786fc228cd5bd2ca\n'}, {'number': 4, 'created': '2014-08-13 16:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/25e4b5ed631a47110fb81a2602124f04eda221dd', 'message': 'Update the scenario_base to base in benchmarks\n\nKeep the scenario_base only on places where required.\nRest keep it as base instead of scenario_base\n\nChange-Id: Ib7887c0a0b65d67a814222e0786fc228cd5bd2ca\n'}, {'number': 5, 'created': '2014-08-13 16:13:44.000000000', 'files': ['tests/doc/test_task_samples.py', 'rally/benchmark/scenarios/quotas/utils.py', 'rally/benchmark/scenarios/heat/stacks.py', 'rally/benchmark/scenarios/ceilometer/queries.py', 'rally/benchmark/scenarios/heat/utils.py', 'rally/benchmark/scenarios/cinder/utils.py', 'rally/benchmark/scenarios/dummy/dummy.py', 'rally/benchmark/scenarios/ceilometer/resources.py', 'rally/benchmark/scenarios/cinder/volumes.py', 'rally/benchmark/scenarios/glance/utils.py', 'rally/benchmark/scenarios/vm/vmtasks.py', 'doc/source/concepts.rst', 'rally/benchmark/scenarios/keystone/basic.py', 'tests/fakes.py', 'rally/benchmark/scenarios/ceilometer/utils.py', 'rally/benchmark/scenarios/quotas/quotas.py', 'rally-scenarios/plugins/fake_plugin.py', 'rally/benchmark/scenarios/ceilometer/alarms.py', 'rally/benchmark/scenarios/vm/utils.py', 'tests/benchmark/scenarios/test_base.py', 'rally/benchmark/scenarios/ceilometer/meters.py', 'rally/benchmark/scenarios/nova/utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'rally/benchmark/scenarios/sahara/node_group_templates.py', 'rally/benchmark/scenarios/neutron/network.py', 'rally/benchmark/scenarios/neutron/utils.py', 'rally/benchmark/scenarios/keystone/utils.py', 'rally/benchmark/scenarios/ceilometer/stats.py', 'rally/benchmark/scenarios/tempest/tempest.py', 'tests/orchestrator/test_api.py', 'tests/benchmark/scenarios/test_authenticate.py', 'rally/benchmark/scenarios/glance/images.py', 'rally/benchmark/scenarios/authenticate/authenticate.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/70a90e01c969a813984089d9fc01bd0079d8295e', 'message': 'Update the scenario_base to base in benchmarks\n\nKeep the scenario_base only on places where required.\nRest keep it as base instead of scenario_base\n\nChange-Id: Ib7887c0a0b65d67a814222e0786fc228cd5bd2ca\n'}]",2,112973,70a90e01c969a813984089d9fc01bd0079d8295e,24,4,5,11105,,,0,"Update the scenario_base to base in benchmarks

Keep the scenario_base only on places where required.
Rest keep it as base instead of scenario_base

Change-Id: Ib7887c0a0b65d67a814222e0786fc228cd5bd2ca
",git fetch https://review.opendev.org/openstack/rally refs/changes/73/112973/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/doc/test_task_samples.py', 'rally/benchmark/scenarios/quotas/utils.py', 'rally/benchmark/scenarios/heat/stacks.py', 'rally/benchmark/scenarios/sahara/utils.py', 'rally/benchmark/scenarios/ceilometer/queries.py', 'rally/benchmark/scenarios/heat/utils.py', 'rally/benchmark/runners/base.py', 'rally/benchmark/scenarios/cinder/utils.py', 'rally/benchmark/scenarios/dummy/dummy.py', 'rally/benchmark/scenarios/ceilometer/resources.py', 'rally/benchmark/scenarios/cinder/volumes.py', 'rally/benchmark/scenarios/glance/utils.py', 'rally/benchmark/scenarios/vm/vmtasks.py', 'doc/source/concepts.rst', 'rally/benchmark/scenarios/keystone/basic.py', 'tests/fakes.py', 'rally/benchmark/scenarios/ceilometer/utils.py', 'rally/benchmark/scenarios/quotas/quotas.py', 'tests/benchmark/runners/test_rps.py', 'rally-scenarios/plugins/fake_plugin.py', 'rally/benchmark/context/images.py', 'rally/benchmark/scenarios/ceilometer/alarms.py', 'rally/benchmark/scenarios/vm/utils.py', 'tests/benchmark/scenarios/test_base.py', 'rally/benchmark/scenarios/ceilometer/meters.py', 'rally/benchmark/scenarios/nova/utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'rally/benchmark/scenarios/sahara/node_group_templates.py', 'rally/benchmark/scenarios/neutron/network.py', 'rally/benchmark/scenarios/neutron/utils.py', 'rally/benchmark/scenarios/keystone/utils.py', 'rally/benchmark/scenarios/ceilometer/stats.py', 'rally/benchmark/scenarios/tempest/tempest.py', 'tests/orchestrator/test_api.py', 'tests/benchmark/scenarios/test_authenticate.py', 'rally/benchmark/scenarios/glance/images.py', 'rally/benchmark/scenarios/authenticate/authenticate.py']",37,e3a6d05178355e92c2c7280fc66fdd2f6579f99d,reversescenariobase,"from rally.benchmark.scenarios import baseclass Authenticate(base.Scenario): @base.scenario() @base.atomic_action_timer('authenticate.keystone') @base.scenario() with base.AtomicAction(self, 'authenticate.validate_glance'): @base.scenario() with base.AtomicAction(self, 'authenticate.validate_nova'): @base.scenario() with base.AtomicAction(self, 'authenticate.validate_cinder'): @base.scenario() with base.AtomicAction(self, 'authenticate.validate_neutron'): @base.scenario() with base.AtomicAction(self, 'authenticate.validate_heat'):","from rally.benchmark.scenarios import base as scenario_baseclass Authenticate(scenario_base.Scenario): @scenario_base.scenario() @scenario_base.atomic_action_timer('authenticate.keystone') @scenario_base.scenario() with scenario_base.AtomicAction(self, 'authenticate.validate_glance'): @scenario_base.scenario() with scenario_base.AtomicAction(self, 'authenticate.validate_nova'): @scenario_base.scenario() with scenario_base.AtomicAction(self, 'authenticate.validate_cinder'): @scenario_base.scenario() with scenario_base.AtomicAction(self, 'authenticate.validate_neutron'): @scenario_base.scenario() with scenario_base.AtomicAction(self, 'authenticate.validate_heat'):",245,256
openstack%2Fmistral~master~Iaa9a5514afdc7ad07f20cb373fd6c356f1391fa9,openstack/mistral,master,Iaa9a5514afdc7ad07f20cb373fd6c356f1391fa9,Moving TaskResult and states to 'workflow' package,MERGED,2014-08-07 09:15:10.000000000,2014-08-13 17:59:07.000000000,2014-08-13 17:59:07.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-08-07 09:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f2176591a504b08b74c06fa48cfd91218cbafbe5', 'message': ""Moving TaskResult and states to 'workflow' package\n\nChange-Id: Iaa9a5514afdc7ad07f20cb373fd6c356f1391fa9\n""}, {'number': 2, 'created': '2014-08-07 15:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ece1200fcf2a6b564cfe38ee5fd5a2567932d08b', 'message': ""Moving TaskResult and states to 'workflow' package\n\nChange-Id: Iaa9a5514afdc7ad07f20cb373fd6c356f1391fa9\n""}, {'number': 3, 'created': '2014-08-07 17:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/95d6ca3e7f4e996004e52743cbc55fb37e8b851a', 'message': ""Moving TaskResult and states to 'workflow' package\n\nChange-Id: Iaa9a5514afdc7ad07f20cb373fd6c356f1391fa9\n""}, {'number': 4, 'created': '2014-08-11 04:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9554909799285d4e7e20bd0338d269c511c76ead', 'message': ""Moving TaskResult and states to 'workflow' package\n\nChange-Id: Iaa9a5514afdc7ad07f20cb373fd6c356f1391fa9\n""}, {'number': 5, 'created': '2014-08-11 06:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2d234d4ef6fb0884201989ee3fc3ae6861053fc6', 'message': ""Moving TaskResult and states to 'workflow' package\n\nChange-Id: Iaa9a5514afdc7ad07f20cb373fd6c356f1391fa9\n""}, {'number': 6, 'created': '2014-08-13 04:26:04.000000000', 'files': ['mistral/tests/unit/engine1/test_states.py', 'mistral/engine1/base.py', 'mistral/workflow/states.py', 'mistral/workflow/base.py', 'mistral/workflow/reverse_workflow.py', 'mistral/tests/unit/workflow/test_reverse_workflow.py', 'mistral/engine1/default_engine.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/4e71b1a69f2ed17ca660de6ed50553f8d1202f5a', 'message': ""Moving TaskResult and states to 'workflow' package\n\nChange-Id: Iaa9a5514afdc7ad07f20cb373fd6c356f1391fa9\n""}]",0,112526,4e71b1a69f2ed17ca660de6ed50553f8d1202f5a,32,5,6,8731,,,0,"Moving TaskResult and states to 'workflow' package

Change-Id: Iaa9a5514afdc7ad07f20cb373fd6c356f1391fa9
",git fetch https://review.opendev.org/openstack/mistral refs/changes/26/112526/5 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine1/base.py', 'mistral/tests/unit/engine1/test_states.py', 'mistral/workflow/states.py', 'mistral/workflow/base.py', 'mistral/workflow/reverse_workflow.py', 'mistral/tests/unit/workflow/test_reverse_workflow.py', 'mistral/engine1/default_engine.py']",7,f2176591a504b08b74c06fa48cfd91218cbafbe5,bp/mistral-extensible-engine-architecture,from mistral.workflow import states,from mistral.engine1 import states,22,23
openstack%2Fmistral~master~I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4,openstack/mistral,master,I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4,Adding implementation of method __repr__ for DB models,MERGED,2014-08-07 06:50:06.000000000,2014-08-13 17:59:01.000000000,2014-08-13 17:59:01.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-08-07 06:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9391a69024168b293f2bac3fee95a04283518953', 'message': 'Adding implementation of method __repr__ for DB models\n\nChange-Id: I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4\n'}, {'number': 2, 'created': '2014-08-07 08:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e449fa67dd4b03a36fa151a52b02c09cff42deff', 'message': 'Adding implementation of method __repr__ for DB models\n\nChange-Id: I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4\n'}, {'number': 3, 'created': '2014-08-07 08:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/57e356062de93f54fd323a4290199cd80e01c457', 'message': 'Adding implementation of method __repr__ for DB models\n\nChange-Id: I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4\n'}, {'number': 4, 'created': '2014-08-07 15:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4b0787111ecb1a1b0c3c475b2283abb9856e58f5', 'message': 'Adding implementation of method __repr__ for DB models\n\nChange-Id: I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4\n'}, {'number': 5, 'created': '2014-08-07 17:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/494044f3259f78cbfcbab15b1b35e0becfcbcf58', 'message': 'Adding implementation of method __repr__ for DB models\n\nChange-Id: I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4\n'}, {'number': 6, 'created': '2014-08-11 04:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bb7861b90f6499dcefbd706df50e3439771724ab', 'message': 'Adding implementation of method __repr__ for DB models\n\nChange-Id: I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4\n'}, {'number': 7, 'created': '2014-08-11 06:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ead1a648e44d0854be81cd76d8e623218f68e4ef', 'message': 'Adding implementation of method __repr__ for DB models\n\nChange-Id: I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4\n'}, {'number': 8, 'created': '2014-08-13 04:26:04.000000000', 'files': ['mistral/db/sqlalchemy/model_base.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/2b243d79aaed84382c5f9debb91a1b59696aa09a', 'message': 'Adding implementation of method __repr__ for DB models\n\nChange-Id: I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4\n'}]",8,112491,2b243d79aaed84382c5f9debb91a1b59696aa09a,34,5,8,8731,,,0,"Adding implementation of method __repr__ for DB models

Change-Id: I5ba1009a4ebf02b3da826c6dd5e78aa0ec9412f4
",git fetch https://review.opendev.org/openstack/mistral refs/changes/91/112491/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/db/sqlalchemy/model_base.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py']",2,9391a69024168b293f2bac3fee95a04283518953,bp/mistral-extensible-engine-architecture," def test_workbook_repr(self): s = db_api.create_workbook(WORKBOOKS[0]).__repr__() self.assertEqual(0, s.find(""Workbook "")) self.assertTrue(s.find(""'name': 'my_workbook1'"") > 0) self.assertTrue(s.find(""'description': 'my description'"") > 0) def test_execution_repr(self): s = db_api.create_execution(EXECUTIONS[0]).__repr__() self.assertEqual(0, s.find(""Execution "")) self.assertTrue(s.find(""'id': '1'"") > 0) self.assertTrue(s.find(""'state': 'IDLE'"") > 0) def test_task_repr(self): ex = db_api.create_execution(EXECUTIONS[0]) values = copy.copy(TASKS[0]) values.update({'execution_id': ex.id}) s = db_api.create_task(values).__repr__() self.assertEqual(0, s.find(""Task "")) self.assertTrue(s.find(""'id': '1'"") > 0) self.assertTrue(s.find(""'name': 'my_task1'"") > 0) ",,28,0
openstack%2Fmistral~master~I1879127bfa1346c179a571b8bd98fa901a90ccd5,openstack/mistral,master,I1879127bfa1346c179a571b8bd98fa901a90ccd5,Working on reverse workflow: on_task_result(),MERGED,2014-08-06 09:24:51.000000000,2014-08-13 17:58:56.000000000,2014-08-13 17:58:55.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-08-06 09:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b5609af62a62e4c98bb43ce8e8fdc5700f5952e0', 'message': ""Working on reverse workflow: on_task_result()\n\n* It's now WIP\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n""}, {'number': 2, 'created': '2014-08-06 09:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/73773082dd5547aeb61c60dbdd77b7230debb4c2', 'message': ""Working on reverse workflow: on_task_result()\n\n* It's now WIP\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n""}, {'number': 3, 'created': '2014-08-06 11:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1bf6c8dd5e77e15977b1b996cbd470c916d7a95a', 'message': ""Working on reverse workflow: on_task_result()\n\n* It's now WIP\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n""}, {'number': 4, 'created': '2014-08-06 12:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/faf8a8d4c6bf90e56fd259f9c1443776753f4232', 'message': ""Working on reverse workflow: on_task_result()\n\n* It's now WIP\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n""}, {'number': 5, 'created': '2014-08-07 05:50:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/dbba4cfa742428d9d0bb9541c81b9685c8b12035', 'message': 'Working on reverse workflow: on_task_result()\n\n* Implementing ReverseWorkflowHandler.on_task_result()\n* Unit tests\n\nTODO:\n * Integrate handler code with Data Flow to process raw task result\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n'}, {'number': 6, 'created': '2014-08-07 06:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1ea097ab6110571ff9e8d42e5bb6457f15377204', 'message': 'Working on reverse workflow: on_task_result()\n\n* Implementing ReverseWorkflowHandler.on_task_result()\n* Unit tests\n\nTODO:\n * Integrate handler code with Data Flow to process raw task result\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n'}, {'number': 7, 'created': '2014-08-07 08:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ba8bfb2bfc0c2572962dd7bdc175aa19eb82a083', 'message': 'Working on reverse workflow: on_task_result()\n\n* Implementing ReverseWorkflowHandler.on_task_result()\n* Unit tests\n\nTODO:\n * Integrate handler code with Data Flow to process raw task result\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n'}, {'number': 8, 'created': '2014-08-07 15:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c41840baf488e95887191116730b0c99dad835c6', 'message': 'Working on reverse workflow: on_task_result()\n\n* Implementing ReverseWorkflowHandler.on_task_result()\n* Unit tests\n\nTODO:\n * Integrate handler code with Data Flow to process raw task result\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n'}, {'number': 9, 'created': '2014-08-07 17:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f3d2c01ffb6436f9e8ecb5a5b6019cb6bb325034', 'message': 'Working on reverse workflow: on_task_result()\n\n* Implementing ReverseWorkflowHandler.on_task_result()\n* Unit tests\n\nTODO:\n * Integrate handler code with Data Flow to process raw task result\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n'}, {'number': 10, 'created': '2014-08-11 04:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b5798050342dba665465796e6b14cc9cc1c2c670', 'message': 'Working on reverse workflow: on_task_result()\n\n* Implementing ReverseWorkflowHandler.on_task_result()\n* Unit tests\n\nTODO:\n * Integrate handler code with Data Flow to process raw task result\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n'}, {'number': 11, 'created': '2014-08-11 06:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/5ae06a8e2a2977da3e76fab18ff7645daad5bd8b', 'message': 'Working on reverse workflow: on_task_result()\n\n* Implementing ReverseWorkflowHandler.on_task_result()\n* Unit tests\n\nTODO:\n * Integrate handler code with Data Flow to process raw task result\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n'}, {'number': 12, 'created': '2014-08-13 04:26:04.000000000', 'files': ['mistral/workflow/base.py', 'mistral/workflow/reverse_workflow.py', 'mistral/tests/unit/workflow/test_reverse_workflow.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/2e14bb0ea932e2376151ceb0e15a0139c892fbf3', 'message': 'Working on reverse workflow: on_task_result()\n\n* Implementing ReverseWorkflowHandler.on_task_result()\n* Unit tests\n\nTODO:\n * Integrate handler code with Data Flow to process raw task result\n\nChange-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5\n'}]",4,112247,2e14bb0ea932e2376151ceb0e15a0139c892fbf3,52,6,12,8731,,,0,"Working on reverse workflow: on_task_result()

* Implementing ReverseWorkflowHandler.on_task_result()
* Unit tests

TODO:
 * Integrate handler code with Data Flow to process raw task result

Change-Id: I1879127bfa1346c179a571b8bd98fa901a90ccd5
",git fetch https://review.opendev.org/openstack/mistral refs/changes/47/112247/3 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/workflow/reverse_workflow.py', 'mistral/tests/unit/workflow/test_reverse_workflow.py']",2,b5609af62a62e4c98bb43ce8e8fdc5700f5952e0,bp/mistral-extensible-engine-architecture,"# TODO(rakhmerov): Should the next two be in package 'workflow'? from mistral.engine1 import base as eng_base task_db = m.Task() task_db.update({ 'id': '1-2-3-4', 'name': 'task1' }) task_specs = self.handler.on_task_result( task_db, eng_base.TaskResult(data='Hey') ) self.assertEqual(1, len(task_specs)) self.assertEqual('task2', task_specs[0].get_name()) self.assertEqual(states.RUNNING, self.exec_db.state) # TODO(rakhmerov): Finish.", # TODO(rakhmerov): Implement. pass,26,8
openstack%2Fmistral~master~I5063ff2ad0395e8b77b3c7de6fb41173411139ea,openstack/mistral,master,I5063ff2ad0395e8b77b3c7de6fb41173411139ea,Working on reverse workflow: implementing method start_workflow(),MERGED,2014-08-05 10:53:21.000000000,2014-08-13 17:58:50.000000000,2014-08-13 17:58:50.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-08-05 10:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/85807800375e993618d1607de1391a06699bdf73', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}, {'number': 2, 'created': '2014-08-06 08:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e99aa685104810c8f6083edced08b06241ee3589', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}, {'number': 3, 'created': '2014-08-06 09:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bd9f7dc43c7a89a9e54b8bd7ed700a79aa519bdd', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}, {'number': 4, 'created': '2014-08-06 09:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/48fb9f76b6c972744f81358a95d8fb4af13758ed', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}, {'number': 5, 'created': '2014-08-06 11:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e21cda6cdbbd94011e7457002ac7dace6acb49d6', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}, {'number': 6, 'created': '2014-08-06 12:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/56ffd7af58832906ec24724cf981975d81025d12', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}, {'number': 7, 'created': '2014-08-07 15:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b93f98417eca82cad9378532630522d8cda0f69a', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}, {'number': 8, 'created': '2014-08-07 17:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b76fbca65cc5f9dce8852f241ce9dd3beb124ca8', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}, {'number': 9, 'created': '2014-08-11 04:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/98723c8adc775f944bd09e2269095c18b76fcee7', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}, {'number': 10, 'created': '2014-08-11 06:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/13d2d868bff35a866ace8d4374370c1485f5dab6', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}, {'number': 11, 'created': '2014-08-13 04:26:04.000000000', 'files': ['mistral/workflow/base.py', 'mistral/workflow/reverse_workflow.py', 'mistral/tests/unit/workflow/test_reverse_workflow.py', 'mistral/workbook/v1/workbook.py', 'mistral/workbook/base.py', 'mistral/engine/workflow.py', 'mistral/workflow/direct_workflow.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/4158f3b28f16ee0f3791104b459d55f4653c356d', 'message': 'Working on reverse workflow: implementing method start_workflow()\n\n* Implementing method start_workflow() in ReverseWorkflowHandler\n* Fixing usages of specification v1 due to changes in BaseSpec class\n\nTODO:\n* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)\n\nChange-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea\n'}]",3,111974,4158f3b28f16ee0f3791104b459d55f4653c356d,50,6,11,8731,,,0,"Working on reverse workflow: implementing method start_workflow()

* Implementing method start_workflow() in ReverseWorkflowHandler
* Fixing usages of specification v1 due to changes in BaseSpec class

TODO:
* Finish the rest in ReverseWorkflowHandler (on_task_result() etc.)

Change-Id: I5063ff2ad0395e8b77b3c7de6fb41173411139ea
",git fetch https://review.opendev.org/openstack/mistral refs/changes/74/111974/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/workflow/base.py', 'mistral/workflow/reverse_workflow.py', 'mistral/tests/unit/workflow/test_reverse_workflow.py', 'mistral/workbook/v1/workbook.py', 'mistral/workbook/base.py', 'mistral/engine/workflow.py']",6,85807800375e993618d1607de1391a06699bdf73,bp/mistral-extensible-engine-architecture," # Find the list of the tasks in the order they're supposed to be executed. task_spec = wb_tasks[task_name] return [node for node in traversal.dfs_postorder_nodes(full_graph.reverse(), task_spec)]def _get_dependency_tasks(tasks_spec, task_spec): dep_task_names = tasks_spec[task_spec.name].get_requires() if len(dep_task_names) == 0: dep_t_specs = set() for t_spec in tasks_spec: for t_name in dep_task_names: if t_name == t_spec.name: dep_t_specs.add(t_spec) return dep_t_specs def _update_dependencies(tasks_spec, graph): for t_spec in tasks_spec: for dep_t_spec in _get_dependency_tasks(tasks_spec, t_spec): graph.add_edge(dep_t_spec, t_spec)"," # Find the list of the tasks in the order they supposed to be executed tasks = [wb_tasks[node] for node in traversal.dfs_postorder_nodes(full_graph.reverse(), task_name)] return tasksdef _get_dependency_tasks(tasks, task): if len(tasks[task].requires) < 1: deps = set() for t in tasks: for dep in tasks[task].requires: if dep == t: deps.add(t) return deps def _update_dependencies(tasks, graph): for task in tasks: for dep in _get_dependency_tasks(tasks, task): graph.add_edge(dep, task)",87,39
openstack%2Fmistral~master~I0476ef417415c7dae98a7104619658979267bb37,openstack/mistral,master,I0476ef417415c7dae98a7104619658979267bb37,Replacing NotImplemented with NotImplementedError,MERGED,2014-08-05 09:00:11.000000000,2014-08-13 17:58:44.000000000,2014-08-13 17:58:44.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-08-05 09:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c29b4648c64feb2dd6f7b4fa63bee9d7c5812781', 'message': 'Replacing NotImplemented with NotImplementedError\n\n* NotImplemented is an old-style class and should not be used\n\nChange-Id: I0476ef417415c7dae98a7104619658979267bb37\n'}, {'number': 2, 'created': '2014-08-06 09:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/55e4c5ad64091f58b5fb99dc7554e2be8caf48f5', 'message': 'Replacing NotImplemented with NotImplementedError\n\n* NotImplemented is an old-style class and should not be used\n\nChange-Id: I0476ef417415c7dae98a7104619658979267bb37\n'}, {'number': 3, 'created': '2014-08-06 09:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1c344e9f13c01b40fa19a98b18203c19180aa977', 'message': 'Replacing NotImplemented with NotImplementedError\n\n* NotImplemented is an old-style class and should not be used\n\nChange-Id: I0476ef417415c7dae98a7104619658979267bb37\n'}, {'number': 4, 'created': '2014-08-06 11:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c03aa14882b2990cb293c0c7581d71be16067bc0', 'message': 'Replacing NotImplemented with NotImplementedError\n\n* NotImplemented is an old-style class and should not be used\n\nChange-Id: I0476ef417415c7dae98a7104619658979267bb37\n'}, {'number': 5, 'created': '2014-08-06 12:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/31d52152c9b91aa9cd63da02c7e87874f4aed901', 'message': 'Replacing NotImplemented with NotImplementedError\n\n* NotImplemented is an old-style class and should not be used\n\nChange-Id: I0476ef417415c7dae98a7104619658979267bb37\n'}, {'number': 6, 'created': '2014-08-07 15:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/8c03fbd0c4262c607a9aa2e9d078563008ca5ab7', 'message': 'Replacing NotImplemented with NotImplementedError\n\n* NotImplemented is an old-style class and should not be used\n\nChange-Id: I0476ef417415c7dae98a7104619658979267bb37\n'}, {'number': 7, 'created': '2014-08-07 17:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/91da54554441a9cafa57a39d94d2be55635c06c8', 'message': 'Replacing NotImplemented with NotImplementedError\n\n* NotImplemented is an old-style class and should not be used\n\nChange-Id: I0476ef417415c7dae98a7104619658979267bb37\n'}, {'number': 8, 'created': '2014-08-11 04:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/63c4b3ab58a66ba21d873b468b18c1396e514493', 'message': 'Replacing NotImplemented with NotImplementedError\n\n* NotImplemented is an old-style class and should not be used\n\nChange-Id: I0476ef417415c7dae98a7104619658979267bb37\n'}, {'number': 9, 'created': '2014-08-11 06:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/94015d200d3bc51cb8bbc00244124e671cadbdde', 'message': 'Replacing NotImplemented with NotImplementedError\n\n* NotImplemented is an old-style class and should not be used\n\nChange-Id: I0476ef417415c7dae98a7104619658979267bb37\n'}, {'number': 10, 'created': '2014-08-13 04:26:04.000000000', 'files': ['mistral/engine1/base.py', 'mistral/workflow/base.py', 'mistral/workflow/reverse_workflow.py', 'mistral/workflow/direct_workflow.py', 'mistral/engine1/default_engine.py', 'mistral/engine1/policies.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/1fe0f4ab0b2956f6c72c951c1cabce0cb0de95be', 'message': 'Replacing NotImplemented with NotImplementedError\n\n* NotImplemented is an old-style class and should not be used\n\nChange-Id: I0476ef417415c7dae98a7104619658979267bb37\n'}]",0,111957,1fe0f4ab0b2956f6c72c951c1cabce0cb0de95be,42,6,10,8731,,,0,"Replacing NotImplemented with NotImplementedError

* NotImplemented is an old-style class and should not be used

Change-Id: I0476ef417415c7dae98a7104619658979267bb37
",git fetch https://review.opendev.org/openstack/mistral refs/changes/57/111957/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine1/base.py', 'mistral/workflow/base.py', 'mistral/workflow/reverse_workflow.py', 'mistral/engine1/default_engine.py', 'mistral/workflow/direct_workflow.py', 'mistral/engine1/policies.py']",6,c29b4648c64feb2dd6f7b4fa63bee9d7c5812781,bp/mistral-extensible-engine-architecture, raise NotImplementedError, raise NotImplemented,16,16
openstack%2Fmistral~master~I8c53a029cd3b2a43e48c0e60c742310f8505b857,openstack/mistral,master,I8c53a029cd3b2a43e48c0e60c742310f8505b857,Working on reverse workflow: fixing specification version injection,MERGED,2014-08-05 08:48:25.000000000,2014-08-13 17:58:38.000000000,2014-08-13 17:58:38.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-08-05 08:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/24197bcec8d79045b8e13f33b2c96cb1d274cdcd', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 2, 'created': '2014-08-05 08:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9c840f5f2216577d11cb06315bbbc3931cf898d8', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 3, 'created': '2014-08-05 08:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/29b18dfe7825cd2a7a9500003caa912fa00df686', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 4, 'created': '2014-08-06 09:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/0437f460400483545408210b464d1248e459de89', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 5, 'created': '2014-08-06 09:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d70a74868b839f0f2d124181f0fe4bf274d48727', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 6, 'created': '2014-08-06 11:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6008e89fd1ceaa58033988c48cd4e830506474ca', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 7, 'created': '2014-08-06 12:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f3e3fec7397c48c29570b85d8698697ebc6170a1', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 8, 'created': '2014-08-07 15:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f814c8d4f5ec94f3957c55e994271c27a0939c89', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 9, 'created': '2014-08-07 16:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9fc43bf2fcbb25da4a44797985a4a6f1b701a833', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 10, 'created': '2014-08-11 04:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4a7a798ade4fd7e0e6bbd20d48b4654a201b2368', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 11, 'created': '2014-08-11 06:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9317427426541a0c68817c53f41dd4e468ec9ae5', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}, {'number': 12, 'created': '2014-08-13 04:26:04.000000000', 'files': ['mistral/workbook/v1/namespaces.py', 'mistral/tests/unit/workbook/v2/test_dsl_specs_v2.py', 'mistral/workflow/reverse_workflow.py', 'mistral/workbook/v1/tasks.py', 'mistral/workbook/v1/actions.py', 'mistral/workbook/v2/actions.py', 'mistral/workbook/v2/tasks.py', 'mistral/workbook/v2/triggers.py', 'mistral/tests/unit/workflow/test_reverse_workflow.py', 'mistral/workbook/base.py', 'mistral/workbook/v2/workflows.py', 'mistral/workbook/v2/namespaces.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/e80f2f17903d6f549ef2f640e69afef2920578c4', 'message': 'Working on reverse workflow: fixing specification version injection\n\nChange-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857\n'}]",6,111955,e80f2f17903d6f549ef2f640e69afef2920578c4,52,6,12,8731,,,0,"Working on reverse workflow: fixing specification version injection

Change-Id: I8c53a029cd3b2a43e48c0e60c742310f8505b857
",git fetch https://review.opendev.org/openstack/mistral refs/changes/55/111955/7 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/workbook/v1/namespaces.py', 'mistral/tests/unit/workbook/v2/test_dsl_specs_v2.py', 'mistral/workflow/reverse_workflow.py', 'mistral/workbook/v2/retry.py', 'mistral/workbook/v1/tasks.py', 'mistral/workbook/v1/actions.py', 'mistral/workbook/v2/actions.py', 'mistral/workbook/v2/tasks.py', 'mistral/workbook/v2/triggers.py', 'mistral/tests/unit/workflow/test_reverse_workflow.py', 'mistral/workbook/base.py', 'mistral/workbook/v2/workflows.py', 'mistral/workbook/v2/namespaces.py']",13,24197bcec8d79045b8e13f33b2c96cb1d274cdcd,bp/mistral-extensible-engine-architecture," ""Version"": {""type"": ""string""}, ""required"": [""Version"", ""name"", ""actions""], _version = '2.0'"," ""required"": [""name"", ""actions""],",55,15
openstack%2Fmistral~master~I11dab20c14217123489015293ed094e954320f9a,openstack/mistral,master,I11dab20c14217123489015293ed094e954320f9a,Unit tests for v2 DB model,MERGED,2014-08-05 06:14:25.000000000,2014-08-13 17:58:33.000000000,2014-08-13 17:58:33.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-08-05 06:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c7bc3d6354cd072092c4954b3f0a02574b121a57', 'message': 'Unit tests for v2 DB model\n\nChange-Id: I11dab20c14217123489015293ed094e954320f9a\n'}, {'number': 2, 'created': '2014-08-06 09:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f19e353fca23bde96677eaf67d44c6a73e87c82f', 'message': 'Unit tests for v2 DB model\n\nChange-Id: I11dab20c14217123489015293ed094e954320f9a\n'}, {'number': 3, 'created': '2014-08-06 09:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c820ab98e926c9a3312acfe093acb3edb8cd5885', 'message': 'Unit tests for v2 DB model\n\nChange-Id: I11dab20c14217123489015293ed094e954320f9a\n'}, {'number': 4, 'created': '2014-08-06 11:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/aeb3db033998d37a761212e71451492d5eaa6720', 'message': 'Unit tests for v2 DB model\n\nChange-Id: I11dab20c14217123489015293ed094e954320f9a\n'}, {'number': 5, 'created': '2014-08-06 12:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/94c5fbe75d290d80bcfc711bea2938729b12f18c', 'message': 'Unit tests for v2 DB model\n\nChange-Id: I11dab20c14217123489015293ed094e954320f9a\n'}, {'number': 6, 'created': '2014-08-07 15:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d92816419a97b7b1f1e8c30238042896c22e5823', 'message': 'Unit tests for v2 DB model\n\nChange-Id: I11dab20c14217123489015293ed094e954320f9a\n'}, {'number': 7, 'created': '2014-08-07 16:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b8f39383cf6464218df4a7e9929546b20870bab6', 'message': 'Unit tests for v2 DB model\n\nChange-Id: I11dab20c14217123489015293ed094e954320f9a\n'}, {'number': 8, 'created': '2014-08-07 16:56:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/71f53bc6095f9ad2273a36d9f1b50472d0a515b3', 'message': 'Unit tests for v2 DB model\n\nChange-Id: I11dab20c14217123489015293ed094e954320f9a\n'}, {'number': 9, 'created': '2014-08-11 04:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/336b697c245c5bcf5b7fdc95577349c6f64e7f89', 'message': 'Unit tests for v2 DB model\n\nChange-Id: I11dab20c14217123489015293ed094e954320f9a\n'}, {'number': 10, 'created': '2014-08-13 04:26:04.000000000', 'files': ['mistral/tests/unit/db/v1/__init__.py', 'mistral/db/v2/sqlalchemy/api.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py', 'mistral/tests/unit/db/v1/test_sqlalchemy_db_api.py', 'mistral/tests/unit/db/v2/__init__.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/9d0b932705156c31102067f3f3aeea0b409608fb', 'message': 'Unit tests for v2 DB model\n\nChange-Id: I11dab20c14217123489015293ed094e954320f9a\n'}]",3,111928,9d0b932705156c31102067f3f3aeea0b409608fb,42,7,10,8731,,,0,"Unit tests for v2 DB model

Change-Id: I11dab20c14217123489015293ed094e954320f9a
",git fetch https://review.opendev.org/openstack/mistral refs/changes/28/111928/10 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/db/v1/__init__.py', 'mistral/db/v2/sqlalchemy/api.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py', 'mistral/tests/unit/db/v1/test_sqlalchemy_db_api.py', 'mistral/tests/unit/db/v2/__init__.py']",5,c7bc3d6354cd072092c4954b3f0a02574b121a57,bp/mistral-extensible-engine-architecture,,,444,2
openstack%2Ffuel-web~master~Ib568fb14bc78d40c214d922907d7bb3adb213eee,openstack/fuel-web,master,Ib568fb14bc78d40c214d922907d7bb3adb213eee,Use dockerctl post_start_hooks to clean iptables,MERGED,2014-08-13 14:12:40.000000000,2014-08-13 17:54:32.000000000,2014-08-13 17:54:32.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7195}, {'_account_id': 8392}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-08-13 14:12:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6b6b307c54b3a4c4712408e2b8bbd12316edc86d', 'message': 'Use dockerctl post_start_hooks to clean iptables\n\niptables -D itself is buggy and doesnot always perform cleanup correctly\nalso we need to cleanup not only DOCKER chain, but also FORWARD\nthis is already done in dockerctl post_start_hooks as solution\nfor removing stale iptables rule after upgrade\n\nWe need to perform invokation of this script after\ncontainer is started because dockerctl uses docker inspect to\nfetch relevant data for containers\n\nChange-Id: Ib568fb14bc78d40c214d922907d7bb3adb213eee\nCloses-Bug: 1349287\n'}, {'number': 2, 'created': '2014-08-13 15:32:08.000000000', 'files': ['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_docker_upgrader.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/58b2ce09edf0ac1af5015630653ed532cd19012d', 'message': 'Use dockerctl post_start_hooks to clean iptables\n\niptables -D itself is buggy and doesnot always perform cleanup correctly\nalso we need to cleanup not only DOCKER chain, but also FORWARD\nthis is already done in dockerctl post_start_hooks as solution\nfor removing stale iptables rule after upgrade\n\nWe need to perform invokation of this script after\ncontainer is started because dockerctl uses docker inspect to\nfetch relevant data for containers\n\nChange-Id: Ib568fb14bc78d40c214d922907d7bb3adb213eee\nCloses-Bug: 1349287\n'}]",0,113903,58b2ce09edf0ac1af5015630653ed532cd19012d,18,8,2,8907,,,0,"Use dockerctl post_start_hooks to clean iptables

iptables -D itself is buggy and doesnot always perform cleanup correctly
also we need to cleanup not only DOCKER chain, but also FORWARD
this is already done in dockerctl post_start_hooks as solution
for removing stale iptables rule after upgrade

We need to perform invokation of this script after
container is started because dockerctl uses docker inspect to
fetch relevant data for containers

Change-Id: Ib568fb14bc78d40c214d922907d7bb3adb213eee
Closes-Bug: 1349287
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/03/113903/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_docker_upgrader.py']",2,6b6b307c54b3a4c4712408e2b8bbd12316edc86d,bug/1349287," def test_clean_docker_iptables_rules(self, exec_cmd_mock): container = {'container_name': 'astute'} self.upgrader.clean_docker_iptables_rules(container) exec_cmd_mock.assert_called_once_with( 'dockerctl post_start_hooks astute')"," self.upgrader.clean_docker_iptables_rules = mock.MagicMock() self.upgrader.clean_docker_iptables_rules.assert_called_once_with( ports) @mock.patch('fuel_upgrade.engines.docker_engine.utils.exec_cmd_iterator') def test_clean_docker_iptables_rules( self, exec_cmd_iterator_mock, exec_cmd_mock): iptables_rules = [ '-A DOCKER -p tcp -m tcp --dport 1 -j DNAT ' '--to-destination 172.17.0.7:1', '-A POSTROUTING -p tcp -m tcp --dport 3 -j DNAT ' '--to-destination 172.17.0.7:3', '-A DOCKER -p tcp -m tcp --dport 2 -j DNAT ' '--to-destination 172.17.0.3:2', '-A DOCKER -d 10.108.0.2/32 -p tcp -m tcp --dport ' '4 -j DNAT --to-destination 172.17.0.11:4'] exec_cmd_iterator_mock.return_value = iter(iptables_rules) self.upgrader.clean_docker_iptables_rules([1, 2, 3, 4]) expected_calls = [ mock.call('iptables -t nat -S'), mock.call('iptables -S'), mock.call('cat /etc/sysconfig/iptables.save'), mock.call( 'iptables -t nat -D DOCKER -p tcp -m tcp --dport 1 -j DNAT ' '--to-destination 172.17.0.7:1'), mock.call( 'iptables -t nat -D DOCKER -p tcp -m tcp --dport 2 -j DNAT ' '--to-destination 172.17.0.3:2'), mock.call( 'iptables -t nat -D DOCKER -d 10.108.0.2/32 -p tcp -m tcp ' '--dport 4 -j DNAT --to-destination 172.17.0.11:4'), mock.call('service iptables save'), mock.call('iptables -t nat -S'), mock.call('iptables -S'), mock.call('cat /etc/sysconfig/iptables.save')] self.assertEqual(exec_cmd_mock.call_args_list, expected_calls)",14,69
openstack%2Fmistral~master~I763cc3f401b8040a182733750ce05577653e1d35,openstack/mistral,master,I763cc3f401b8040a182733750ce05577653e1d35,Refactoring DB access layer,MERGED,2014-08-01 09:41:25.000000000,2014-08-13 17:53:57.000000000,2014-08-13 17:53:57.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-08-01 09:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/aa19cb7978856a595f93e7fd689c4b0ff8f5dc55', 'message': 'Preparing DB objects for the new engine\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 2, 'created': '2014-08-01 10:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/42fb90d49747259b9d6b3b55fbe8138c816b43db', 'message': 'Preparing DB objects for the new engine\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 3, 'created': '2014-08-04 06:58:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2e6ee1433446575dc268a468576f3fdc0d8425ba', 'message': 'Preparing DB objects for the new engine\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 4, 'created': '2014-08-04 09:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/70f4c2d4beb65b478acf5717f74f7abde7a887d3', 'message': 'Preparing DB objects for the new engine\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 5, 'created': '2014-08-04 12:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4615aff4452fb2e0296c8a9b77f0cb34fc79f5bc', 'message': 'Refactoring DB access layer\n\n* Breaking DB api and DB models into separate versions\n* Fixing unit tests and dependent code\n* Preparing DB models for the new API/engine\n\nTODO:\n* Adjust v2 DB models according to the new spec\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 6, 'created': '2014-08-05 04:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/653c7872ab5e83f1dea4f6b955f1facc1b7ccafa', 'message': 'Refactoring DB access layer\n\n* Breaking DB api and DB models into separate versions\n* Fixing unit tests and dependent code\n* Preparing DB models for the new API/engine\n\nTODO:\n* Adjust v2 DB models according to the new spec\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 7, 'created': '2014-08-06 09:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/7ae325879eb2fef9526895015db81e8bc35407e5', 'message': 'Refactoring DB access layer\n\n* Breaking DB api and DB models into separate versions\n* Fixing unit tests and dependent code\n* Preparing DB models for the new API/engine\n\nTODO:\n* Adjust v2 DB models according to the new spec\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 8, 'created': '2014-08-06 09:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/df88cf698104b0b5ee117e51d729fc6292358d0d', 'message': 'Refactoring DB access layer\n\n* Breaking DB api and DB models into separate versions\n* Fixing unit tests and dependent code\n* Preparing DB models for the new API/engine\n\nTODO:\n* Adjust v2 DB models according to the new spec\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 9, 'created': '2014-08-06 11:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/281d45c42a88418834c634f3476e3441b6842170', 'message': 'Refactoring DB access layer\n\n* Breaking DB api and DB models into separate versions\n* Fixing unit tests and dependent code\n* Preparing DB models for the new API/engine\n\nTODO:\n* Adjust v2 DB models according to the new spec\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 10, 'created': '2014-08-06 12:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4438ccac2bbf7900c24fcbc4115a39eef6521d62', 'message': 'Refactoring DB access layer\n\n* Breaking DB api and DB models into separate versions\n* Fixing unit tests and dependent code\n* Preparing DB models for the new API/engine\n\nTODO:\n* Adjust v2 DB models according to the new spec\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 11, 'created': '2014-08-07 16:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2235b0dc885aaabc28125d1612dedab26e24633a', 'message': 'Refactoring DB access layer\n\n* Breaking DB api and DB models into separate versions\n* Fixing unit tests and dependent code\n* Preparing DB models for the new API/engine\n\nTODO:\n* Adjust v2 DB models according to the new spec\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 12, 'created': '2014-08-07 16:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9c75498d327ac3262acee218c3d69faf09f1aa3f', 'message': 'Refactoring DB access layer\n\n* Breaking DB api and DB models into separate versions\n* Fixing unit tests and dependent code\n* Preparing DB models for the new API/engine\n\nTODO:\n* Adjust v2 DB models according to the new spec\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 13, 'created': '2014-08-11 04:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/390a627cf123267b8e6b700a02d39223b0966397', 'message': 'Refactoring DB access layer\n\n* Breaking DB api and DB models into separate versions\n* Fixing unit tests and dependent code\n* Preparing DB models for the new API/engine\n\nTODO:\n* Adjust v2 DB models according to the new spec\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}, {'number': 14, 'created': '2014-08-13 04:26:04.000000000', 'files': ['mistral/tests/unit/engine/test_data_flow_module.py', 'mistral/db/v1/sqlalchemy/__init__.py', 'mistral/tests/api/test_auth.py', 'mistral/tests/unit/actions/test_action_factory.py', 'mistral/tests/api/base.py', 'mistral/db/sqlalchemy/api.py', 'mistral/db/v2/sqlalchemy/models.py', 'mistral/tests/unit/engine/test_transport.py', 'mistral/db/api.py', 'mistral/tests/unit/workflow/test_reverse_workflow.py', 'mistral/actions/action_factory.py', 'mistral/tests/base.py', 'mistral/db/sqlalchemy/model_base.py', 'mistral/db/v2/sqlalchemy/api.py', 'mistral/db/v2/sqlalchemy/__init__.py', 'mistral/db/v1/sqlalchemy/models.py', 'mistral/db/v2/__init__.py', 'mistral/exceptions.py', 'mistral/db/sqlalchemy/base.py', 'mistral/db/v1/sqlalchemy/api.py', 'mistral/db/v1/api.py', 'mistral/db/v2/api.py', 'mistral/tests/unit/engine/test_task_retry.py', 'mistral/actions/std_actions.py', 'mistral/db/v1/__init__.py', 'mistral/tests/unit/db/test_sqlalchemy_db_api.py', 'mistral/tests/unit/engine/default/test_engine.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/3b8e451d875fede18c5d56e48dfc6ac45d9cdf30', 'message': 'Refactoring DB access layer\n\n* Breaking DB api and DB models into separate versions\n* Fixing unit tests and dependent code\n* Preparing DB models for the new API/engine\n\nTODO:\n* Adjust v2 DB models according to the new spec\n\nChange-Id: I763cc3f401b8040a182733750ce05577653e1d35\n'}]",26,111218,3b8e451d875fede18c5d56e48dfc6ac45d9cdf30,61,6,14,8731,,,0,"Refactoring DB access layer

* Breaking DB api and DB models into separate versions
* Fixing unit tests and dependent code
* Preparing DB models for the new API/engine

TODO:
* Adjust v2 DB models according to the new spec

Change-Id: I763cc3f401b8040a182733750ce05577653e1d35
",git fetch https://review.opendev.org/openstack/mistral refs/changes/18/111218/7 && git format-patch -1 --stdout FETCH_HEAD,['mistral/db/sqlalchemy/models1.py'],1,aa19cb7978856a595f93e7fd689c4b0ff8f5dc55,bp/mistral-extensible-engine-architecture,"# -*- coding: utf-8 -*- # # Copyright 2013 - Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import sqlalchemy as sa import uuid from mistral.db.sqlalchemy import model_base as mb from mistral.db.sqlalchemy import types as st # Helpers. def _generate_unicode_uuid(): return unicode(str(uuid.uuid4())) def _id_column(): return sa.Column( sa.String(36), primary_key=True, default=_generate_unicode_uuid ) class Workbook(mb.MistralBase): """"""Contains info about workbook (including definition in Mistral DSL)."""""" __tablename__ = 'workbooks' __table_args__ = ( sa.UniqueConstraint('name'), ) id = _id_column() name = sa.Column(sa.String(80), primary_key=True) definition = sa.Column(sa.Text(), nullable=True) tags = sa.Column(st.JsonListType()) scope = sa.Column(sa.String(80)) project_id = sa.Column(sa.String(80)) trust_id = sa.Column(sa.String(80)) class Execution(mb.MistralBase): """"""Contains info about particular workflow execution."""""" __tablename__ = 'executions' id = _id_column() wb_name = sa.Column(sa.String(80)) wf_name = sa.Column(sa.String(80)) task = sa.Column(sa.String(80)) state = sa.Column(sa.String(20)) context = sa.Column(st.JsonDictType()) class Task(mb.MistralBase): """"""Contains info about particular task."""""" __tablename__ = 'tasks' id = _id_column() name = sa.Column(sa.String(80)) requires = sa.Column(st.JsonListType()) workbook_name = sa.Column(sa.String(80)) execution_id = sa.Column(sa.String(36)) description = sa.Column(sa.String(200)) task_spec = sa.Column(st.JsonDictType()) action_spec = sa.Column(st.JsonDictType()) state = sa.Column(sa.String(20)) tags = sa.Column(st.JsonListType()) # Data Flow properties. in_context = sa.Column(st.JsonDictType()) parameters = sa.Column(st.JsonDictType()) output = sa.Column(st.JsonDictType()) # Runtime context like iteration_no of a repeater. # Effectively internal engine properties which will be used to determine # execution of a task. task_runtime_context = sa.Column(st.JsonDictType()) ",,93,0
openstack%2Fmistral~master~I4d6949588635ff45775f68186ea43b16163b6a72,openstack/mistral,master,I4d6949588635ff45775f68186ea43b16163b6a72,Implementing DSL specification v2 (partially),MERGED,2014-07-29 05:32:10.000000000,2014-08-13 17:53:36.000000000,2014-08-13 17:53:36.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-07-29 05:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/aca6b06acb13a53fcda36e01dda11f82aea852be', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 2, 'created': '2014-07-29 05:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9d02110c736e86eb392b5c60b42a68f12c56d889', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 3, 'created': '2014-07-29 06:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1f78de74dba05a37aa34a9a0657b4e1e2062048c', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 4, 'created': '2014-07-29 06:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6ea940ee23eb0870e93c723e02fdbf5ae7b6f199', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 5, 'created': '2014-07-29 08:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6a493367641fd94e22cdf89c32b144fac25d4abf', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 6, 'created': '2014-07-29 08:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/3955be9e31fd231862f87121fa4f665ce6f16932', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 7, 'created': '2014-07-30 09:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9e21ef641faaa12fe7b6cc520fb0670632331339', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 8, 'created': '2014-07-30 11:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4726302550c8aea9d00d75ec03b9dea0ef9b09e9', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 9, 'created': '2014-07-30 11:37:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b798f44a8d4244fe88b4d6e2d7b5435ffdd20201', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 10, 'created': '2014-07-30 12:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/64f6c77a371b3232595f82aa2e2cdd5ae3a547ac', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 11, 'created': '2014-07-31 04:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d84c407c30014569165a5ce090730f383c11e437', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 12, 'created': '2014-07-31 11:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/75c4001e6dc147aa91ee68d7ad5b34760f42ab6d', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 13, 'created': '2014-07-31 12:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/40dd462ecaa592939366b008970d82babc9a8aad', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 14, 'created': '2014-07-31 13:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/dc48e817b35d3bc22b2bb6b38f14002f430a4918', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 15, 'created': '2014-08-01 05:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6add8b05fdab11e6d78e1e241972aec7e2dfb0f4', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 16, 'created': '2014-08-01 05:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/811e5a084a9402aaf17e67023777ae8d753a2ed2', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 17, 'created': '2014-08-01 07:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/7f275deeced5815c26d5535c3dcd22236a9086e5', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 18, 'created': '2014-08-01 07:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ea103a076c91503beb53aa7fae8a2fab241c7837', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 19, 'created': '2014-08-01 09:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e8851d1c1a23687d610df3158c22fcc4b3278bc1', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 20, 'created': '2014-08-04 09:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ec99d671868e33498d7d49373958d33b3f3eee0a', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 21, 'created': '2014-08-06 09:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e7ecf6f542aee6a188cbd7c8bc7dcff14f3b79a3', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 22, 'created': '2014-08-06 09:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/a11939182e21fcef53f1f75dd43e6a3f809ca0cb', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 23, 'created': '2014-08-06 11:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/56fed882187074ab741d425170efbf35d8fbc865', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 24, 'created': '2014-08-06 12:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9539a4b3b7dfd7ef6c22f7908e261e68fcc255e4', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 25, 'created': '2014-08-07 16:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/3529ab5f872af1bcccb13081f3dcf4dfb682e269', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 26, 'created': '2014-08-11 04:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/060acda62d93db616a3eef62a1dda81cddd41d81', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}, {'number': 27, 'created': '2014-08-13 04:26:04.000000000', 'files': ['mistral/workbook/v1/namespaces.py', 'mistral/tests/unit/engine/test_data_flow_module.py', 'mistral/workbook/parser.py', 'mistral/workbook/actions.py', 'mistral/workflow/base.py', 'mistral/tests/unit/workbook/v2/test_dsl_specs_v2.py', 'mistral/workbook/namespaces.py', 'mistral/tests/unit/engine/test_workflow.py', 'mistral/tests/unit/actions/test_action_factory.py', 'mistral/workbook/v2/workbook.py', 'mistral/workbook/v1/actions.py', 'mistral/tests/unit/actions/test_std_adhoc_action.py', 'mistral/tests/resources/test_rest.yaml', 'mistral/utils/__init__.py', 'mistral/workbook/v2/actions.py', 'mistral/services/scheduler.py', 'requirements.txt', 'mistral/workbook/v2/triggers.py', 'mistral/tests/unit/workflow/test_reverse_workflow.py', 'mistral/workbook/v1/workbook.py', 'mistral/actions/action_factory.py', 'mistral/services/periodic.py', 'mistral/tests/unit/workbook/v1/test_dsl_specs_v1.py', 'mistral/tests/resources/control_flow/direct_flow.yaml', 'mistral/workflow/reverse_workflow.py', 'mistral/workbook/v2/retry.py', 'mistral/exceptions.py', 'mistral/tests/unit/workbook/v1/test_get_on_state.py', 'mistral/tests/unit/workflow/test_direct_workflow.py', 'mistral/workbook/v1/tasks.py', 'mistral/engine/__init__.py', 'mistral/workflow/direct_workflow.py', 'mistral/tests/unit/utils/test_utils.py', 'mistral/tests/unit/workbook/v1/__init__.py', 'mistral/workflow/selector.py', 'mistral/tests/api/v1/controllers/test_workbook_definition.py', 'mistral/workbook/v2/tasks.py', 'mistral/tests/unit/workflow/__init__.py', 'mistral/workbook/v1/workflow.py', 'mistral/tests/resources/dsl_v2/reverse_workflow.yaml', 'mistral/engine/data_flow.py', 'mistral/tests/unit/workbook/v2/__init__.py', 'mistral/tests/unit/engine/test_task_retry.py', 'mistral/workbook/base.py', 'mistral/workbook/v2/workflows.py', 'mistral/dsl_parser.py', 'mistral/workbook/v2/namespaces.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/f997ca183d9548acc8da41c2bea72db226513954', 'message': ""Implementing DSL specification v2 (partially)\n\n* Rewriting package 'workbook' to have v1 and v2 separately\n* Refactoring all required places to use v1 spec explicitly\n* Refactoring and making specs more consistent\n\nTODO:\n* Fully implement spec v2 when it's complete\n\nChange-Id: I4d6949588635ff45775f68186ea43b16163b6a72\n""}]",12,110207,f997ca183d9548acc8da41c2bea72db226513954,106,6,27,8731,,,0,"Implementing DSL specification v2 (partially)

* Rewriting package 'workbook' to have v1 and v2 separately
* Refactoring all required places to use v1 spec explicitly
* Refactoring and making specs more consistent

TODO:
* Fully implement spec v2 when it's complete

Change-Id: I4d6949588635ff45775f68186ea43b16163b6a72
",git fetch https://review.opendev.org/openstack/mistral refs/changes/07/110207/3 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/workbook/v1/namespaces.py', 'mistral/workbook/actions.py', 'mistral/workbook/namespaces.py', 'mistral/workbook/v2/base.py', 'mistral/workbook/v1/tasks.py', 'mistral/workbook/v2/workbook.py', 'mistral/workbook/tasks.py', 'mistral/workbook/v1/actions.py', 'mistral/workbook/v2/actions.py', 'mistral/workbook/v2/tasks.py', 'mistral/workbook/v1/base.py', 'mistral/workbook/v1/workflow.py', 'mistral/tests/resources/dsl_v2/reverse_workflow.yaml', 'mistral/workbook/v1/workbook.py', 'mistral/tests/workflow/test_reverse_workflow.py', 'mistral/workbook/v2/workflow.py', 'mistral/workbook/base.py', 'mistral/workbook/workbook.py', 'mistral/workbook/workflow.py', 'mistral/workbook/v2/namespaces.py']",20,aca6b06acb13a53fcda36e01dda11f82aea852be,bp/mistral-extensible-engine-architecture,"# -*- coding: utf-8 -*- # # Copyright 2013 - Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from mistral.workbook import actions from mistral.workbook import base # TODO(rakhmerov): In progress. def merge_dicts(left, right): for k, v in right.iteritems(): if k not in left: left[k] = v else: left_v = left[k] if isinstance(left_v, dict) and isinstance(v, dict): merge_dicts(left_v, v) def merge_base_parameters(action, ns_base_parameters): if not ns_base_parameters: return if 'base-parameters' not in action: action['base-parameters'] = ns_base_parameters return action_base_parameters = action['base-parameters'] merge_dicts(action_base_parameters, ns_base_parameters) class NamespaceSpec(base.BaseSpec): _required_keys = ['name', 'actions'] def __init__(self, namespace): super(NamespaceSpec, self).__init__(namespace) if self.validate(): self.name = namespace['name'] self.clazz = namespace.get('class') self.base_parameters = namespace.get('base-parameters') self.parameters = namespace.get('parameters') for _, action in namespace['actions'].iteritems(): action['namespace'] = self.name if 'class' not in action: action['class'] = self.clazz merge_base_parameters(action, self.base_parameters) self.actions = actions.ActionSpecList(namespace['actions']) class NamespaceSpecList(base.BaseSpecList): item_class = NamespaceSpec ",,788,0
openstack%2Fironic~master~I250d7c82cc4d048b60e5f360aca26f593f77b04a,openstack/ironic,master,I250d7c82cc4d048b60e5f360aca26f593f77b04a,"Add list() to Chassis, Node, Port objects",MERGED,2014-08-13 13:14:31.000000000,2014-08-13 17:51:33.000000000,2014-08-13 17:51:33.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-08-13 13:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/659e44310514036540144854eb4614fe58909a9d', 'message': 'Add list() to Chassis, Node, Port objects\n\nWhat it says and remove the direct calls to dbapi and switch code to\nuse the object interfaces.\n\nPartial-Bug: 1314732\nChange-Id: I250d7c82cc4d048b60e5f360aca26f593f77b04a\n'}, {'number': 2, 'created': '2014-08-13 13:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c54ea001d2ec7e1a43bd5d703e2078fa182b3ed2', 'message': 'Add list() to Chassis, Node, Port objects\n\nWhat it says and remove the direct calls to dbapi and switch code to\nuse the object interfaces.\n\nPartial-Bug: 1314732\nChange-Id: I250d7c82cc4d048b60e5f360aca26f593f77b04a\n'}, {'number': 3, 'created': '2014-08-13 13:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4ab67be95dd5d3999a94cdf37d0d60bc1c152032', 'message': 'Add list() to Chassis, Node, Port objects\n\nWhat it says and remove the direct calls to dbapi and switch code to\nuse the object interfaces.\n\nPartial-Bug: 1314732\nChange-Id: I250d7c82cc4d048b60e5f360aca26f593f77b04a\n'}, {'number': 4, 'created': '2014-08-13 14:05:50.000000000', 'files': ['ironic/objects/node.py', 'ironic/api/controllers/v1/port.py', 'ironic/api/controllers/v1/chassis.py', 'ironic/db/sqlalchemy/api.py', 'ironic/objects/chassis.py', 'ironic/tests/objects/test_node.py', 'ironic/objects/port.py', 'ironic/tests/objects/test_chassis.py', 'ironic/tests/objects/test_port.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/19ea0327ddbe281e939f314b9444508db5d21e53', 'message': 'Add list() to Chassis, Node, Port objects\n\nWhat it says and remove the direct calls to dbapi and switch code to\nuse the object interfaces.\n\nPartial-Bug: 1314732\nChange-Id: I250d7c82cc4d048b60e5f360aca26f593f77b04a\n'}]",0,113877,19ea0327ddbe281e939f314b9444508db5d21e53,16,4,4,6773,,,0,"Add list() to Chassis, Node, Port objects

What it says and remove the direct calls to dbapi and switch code to
use the object interfaces.

Partial-Bug: 1314732
Change-Id: I250d7c82cc4d048b60e5f360aca26f593f77b04a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/77/113877/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/objects/node.py', 'ironic/api/controllers/v1/port.py', 'ironic/api/controllers/v1/chassis.py', 'ironic/db/sqlalchemy/api.py', 'ironic/objects/chassis.py', 'ironic/tests/objects/test_node.py', 'ironic/objects/port.py', 'ironic/tests/objects/test_chassis.py', 'ironic/tests/objects/test_port.py', 'ironic/api/controllers/v1/node.py']",10,659e44310514036540144854eb4614fe58909a9d,bug/1314732," nodes = objects.Node.list(pecan.request.context, filters, limit, marker_obj, sort_key=sort_key, sort_dir=sort_dir)"," nodes = pecan.request.dbapi.get_node_list(filters, limit, marker_obj, sort_key=sort_key, sort_dir=sort_dir)",120,16
openstack%2Ftripleo-image-elements~master~I1f0e66a3ec53ae15b4ef85444f78cc4abb9e45e2,openstack/tripleo-image-elements,master,I1f0e66a3ec53ae15b4ef85444f78cc4abb9e45e2,"Revert ""Revert ""Adding haproxy reload check""""",MERGED,2014-08-06 17:40:57.000000000,2014-08-13 17:50:07.000000000,2014-08-13 17:50:06.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 9369}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-08-06 17:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/01eaca6d260babbfb3cc4d4de4b1f388affbd85f', 'message': 'Revert ""Revert ""Adding haproxy reload check""""\n\nWith the previous workaround commit this should work again.\n\nThis reverts commit d35bc8570f197e8499ddf09657ff6b9c8224a20f.\n\nChange-Id: I1f0e66a3ec53ae15b4ef85444f78cc4abb9e45e2\n'}, {'number': 2, 'created': '2014-08-06 17:42:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8643b6f6f54e42568542d3e2423d799319dcbe9a', 'message': 'Revert ""Revert ""Adding haproxy reload check""""\n\nWith the previous workaround commit this should work again.\n\nThis reverts commit d35bc8570f197e8499ddf09657ff6b9c8224a20f.\n\nChange-Id: I1f0e66a3ec53ae15b4ef85444f78cc4abb9e45e2\nCloses-Bug: 1348931\n'}, {'number': 3, 'created': '2014-08-11 21:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f20c3c3e8c3397e0a02b3d6dbc21b259e385898e', 'message': 'Revert ""Revert ""Adding haproxy reload check""""\n\nWith the previous workaround commit this should work again.\n\nThis reverts commit d35bc8570f197e8499ddf09657ff6b9c8224a20f.\n\nChange-Id: I1f0e66a3ec53ae15b4ef85444f78cc4abb9e45e2\nCloses-Bug: 1348931\n'}, {'number': 4, 'created': '2014-08-12 21:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f2c3887bd22df31346ed332790fd56dcf6aa8731', 'message': 'Revert ""Revert ""Adding haproxy reload check""""\n\nWith the previous workaround commit this should work again.\n\nThis reverts commit d35bc8570f197e8499ddf09657ff6b9c8224a20f.\n\nChange-Id: I1f0e66a3ec53ae15b4ef85444f78cc4abb9e45e2\nCloses-Bug: 1348931\n'}, {'number': 5, 'created': '2014-08-12 21:38:15.000000000', 'files': ['elements/haproxy/os-refresh-config/configure.d/21-haproxy'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/753a5f2d6047d7b4bbaddfa90c0cd77db0872d78', 'message': 'Revert ""Revert ""Adding haproxy reload check""""\n\nWith the previous workaround commit this should work again.\n\nThis reverts commit d35bc8570f197e8499ddf09657ff6b9c8224a20f.\n\nChange-Id: I1f0e66a3ec53ae15b4ef85444f78cc4abb9e45e2\nCloses-Bug: 1348931\n'}]",0,112367,753a5f2d6047d7b4bbaddfa90c0cd77db0872d78,69,8,5,6928,,,0,"Revert ""Revert ""Adding haproxy reload check""""

With the previous workaround commit this should work again.

This reverts commit d35bc8570f197e8499ddf09657ff6b9c8224a20f.

Change-Id: I1f0e66a3ec53ae15b4ef85444f78cc4abb9e45e2
Closes-Bug: 1348931
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/67/112367/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/haproxy/os-refresh-config/post-configure.d/20-haproxy'],1,01eaca6d260babbfb3cc4d4de4b1f388affbd85f,bug/1348931,if service haproxy status; then service haproxy reload else service haproxy restart fi,service haproxy restart,5,1
openstack%2Fneutron~master~Id5a4c98059894eef33faf19d5ab063780b362f4a,openstack/neutron,master,Id5a4c98059894eef33faf19d5ab063780b362f4a,add auth token to context,MERGED,2014-08-04 14:59:34.000000000,2014-08-13 17:33:51.000000000,2014-08-13 17:33:49.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 841}, {'_account_id': 1923}, {'_account_id': 2031}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5735}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7576}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 11208}, {'_account_id': 12441}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-04 14:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e538de0462d40fab3e083dc0c706c7771bea1235', 'message': 'add auth token to context\n\nAs discusses at\nhttp://lists.openstack.org/pipermail/openstack-dev/2014-July/040644.html\nSerivceVM project needs auth token in context.\nthe first user will be l3 routervm plugin.\n\nChange-Id: Id5a4c98059894eef33faf19d5ab063780b362f4a\n'}, {'number': 2, 'created': '2014-08-05 06:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f832ba243009c96db02488661fd4aea412760333', 'message': 'add auth token to context\n\nAs discusses at\nhttp://lists.openstack.org/pipermail/openstack-dev/2014-July/040644.html\nSerivceVM project (and other routervm plugins) need auth token in context.\nthe first user will be l3 routervm plugin.\n\nCloses-Bug: #1352698\nChange-Id: Id5a4c98059894eef33faf19d5ab063780b362f4a\n'}, {'number': 3, 'created': '2014-08-08 16:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4330bbc09d8c13244a11780bf7975af2a2382bc2', 'message': 'add auth token to context\n\nAs discusses at\nhttp://lists.openstack.org/pipermail/openstack-dev/2014-July/040644.html\nSerivceVM project (and other routervm plugins) need auth token in context.\nthe first user will be l3 routervm plugin.\n\nCloses-Bug: #1352698\nChange-Id: Id5a4c98059894eef33faf19d5ab063780b362f4a\n'}, {'number': 4, 'created': '2014-08-12 02:22:21.000000000', 'files': ['neutron/auth.py', 'neutron/tests/unit/test_neutron_context.py', 'neutron/common/rpc.py', 'neutron/context.py', 'neutron/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f9c285fd617403ab89c857e3d8bab0d06d19d3ba', 'message': 'add auth token to context\n\nAs discussed at\nhttp://lists.openstack.org/pipermail/openstack-dev/2014-July/040644.html\nSerivceVM project (and other routervm plugins) need auth token in context.\nThe first user will be l3 routervm plugin.\n\nCloses-Bug: #1343854\nCloses-Bug: #1352698\nChange-Id: Id5a4c98059894eef33faf19d5ab063780b362f4a\n'}]",23,111756,f9c285fd617403ab89c857e3d8bab0d06d19d3ba,127,32,4,333,,,0,"add auth token to context

As discussed at
http://lists.openstack.org/pipermail/openstack-dev/2014-July/040644.html
SerivceVM project (and other routervm plugins) need auth token in context.
The first user will be l3 routervm plugin.

Closes-Bug: #1343854
Closes-Bug: #1352698
Change-Id: Id5a4c98059894eef33faf19d5ab063780b362f4a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/111756/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/auth.py', 'neutron/tests/unit/test_neutron_context.py', 'neutron/context.py']",3,e538de0462d40fab3e083dc0c706c7771bea1235,add-auth-token-to-context," overwrite=True, auth_token=None, **kwargs): request_id=request_id, auth_token=auth_token) 'auth_token': self.auth_token,"," overwrite=True, **kwargs): request_id=request_id)",24,3
openstack%2Fceilometer~master~Ia776ca5ada841698d652f2749e74aabe57d804eb,openstack/ceilometer,master,Ia776ca5ada841698d652f2749e74aabe57d804eb,Improve performance of libvirt inspector requests,MERGED,2014-06-06 11:28:52.000000000,2014-08-13 17:33:42.000000000,2014-08-13 17:33:42.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-06-06 11:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7e1f43549b2632c4965772738b0b7845701be5ba', 'message': 'Improve performance of libvirt inspector requests\n\nCurrently libvirt inspector call _test_connection before every\nrequest. It takes 30% of running time.\nIn patch we catch libvirt exceptions at runtime and try to restart\na failed request.\n\nChange-Id: Ia776ca5ada841698d652f2749e74aabe57d804eb\n'}, {'number': 2, 'created': '2014-07-29 14:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c62575d4ff814903f8c06ba213b3823d35ea4df4', 'message': 'Improve performance of libvirt inspector requests\n\nCurrently libvirt inspector call _test_connection before every\nrequest. It takes 30% of running time.\nIn patch we catch libvirt exceptions at runtime and try to restart\na failed request.\n\nChange-Id: Ia776ca5ada841698d652f2749e74aabe57d804eb\n'}, {'number': 3, 'created': '2014-08-08 12:50:55.000000000', 'files': ['ceilometer/compute/virt/libvirt/inspector.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6792475c51da8a9ef259e7beff97a09157f11458', 'message': 'Improve performance of libvirt inspector requests\n\nCurrently libvirt inspector call _test_connection before every\nrequest. It takes 30% of running time.\nIn patch we catch libvirt exceptions at runtime and try to restart\na failed request.\n\nChange-Id: Ia776ca5ada841698d652f2749e74aabe57d804eb\n'}]",18,98377,6792475c51da8a9ef259e7beff97a09157f11458,37,8,3,7729,,,0,"Improve performance of libvirt inspector requests

Currently libvirt inspector call _test_connection before every
request. It takes 30% of running time.
In patch we catch libvirt exceptions at runtime and try to restart
a failed request.

Change-Id: Ia776ca5ada841698d652f2749e74aabe57d804eb
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/77/98377/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/compute/virt/libvirt/inspector.py'],1,7e1f43549b2632c4965772738b0b7845701be5ba,(detached,"def retry_on_disconnect(function): def decorator(self, *args, **kwargs): try: return function(self, *args, **kwargs) except libvirt.libvirtError as e: if (e.get_error_code() == libvirt.VIR_ERR_SYSTEM_ERROR and e.get_error_domain() in (libvirt.VIR_FROM_REMOTE, libvirt.VIR_FROM_RPC)): LOG.debug(_('Connection to libvirt broke')) self.connection = None return function(self, *args, **kwargs) else: raise e return decorator if not self.connection: @retry_on_disconnect if (error_code == libvirt.VIR_ERR_SYSTEM_ERROR and ex.get_error_domain() in (libvirt.VIR_FROM_REMOTE, libvirt.VIR_FROM_RPC)): raise ex @retry_on_disconnect"," if not self.connection or not self._test_connection(): def _test_connection(self): try: self.connection.getCapabilities() return True except libvirt.libvirtError as e: if (e.get_error_code() == libvirt.VIR_ERR_SYSTEM_ERROR and e.get_error_domain() in (libvirt.VIR_FROM_REMOTE, libvirt.VIR_FROM_RPC)): LOG.debug(_('Connection to libvirt broke')) return False raise ",23,13
openstack%2Fheat~master~I7fea68f11c58d395c1eb31fae834afcab5dc4d1e,openstack/heat,master,I7fea68f11c58d395c1eb31fae834afcab5dc4d1e,Deny updates to AWS::EC2::Volume resource,MERGED,2014-08-06 11:45:45.000000000,2014-08-13 17:33:35.000000000,2014-08-13 17:33:34.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 8328}, {'_account_id': 8435}, {'_account_id': 8537}, {'_account_id': 9542}, {'_account_id': 11599}]","[{'number': 1, 'created': '2014-08-06 11:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b424bcc9f2ee66b44fb9f144762022b49659134f', 'message': 'Deny updates to AWS::EC2::Volume resource\n\nAccording to AWS docs [1] Volume resource does not support updates\n(including resource replacement) of any of its properties.\nTo align our AWS-compatible resource with such behavior, all properties\nof AWS::EC2::Volume resource are marked as immutable.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volume.html\n\nChange-Id: I7fea68f11c58d395c1eb31fae834afcab5dc4d1e\nImplements: bp/aws-updates-not-supported\nCloses-Bug: #1340093\n'}, {'number': 2, 'created': '2014-08-06 11:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8f2fa73df3c11afdc40addf88f8ac96c3c0dc458', 'message': 'Deny updates to AWS::EC2::Volume resource\n\nAccording to AWS docs [1] Volume resource does not support updates\n(including resource replacement) of any of its properties.\nTo align our AWS-compatible resource with such behavior, all properties\nof AWS::EC2::Volume resource are marked as immutable.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volume.html\n\nChange-Id: I7fea68f11c58d395c1eb31fae834afcab5dc4d1e\nCloses-Bug: #1340093\n'}, {'number': 3, 'created': '2014-08-07 12:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c66663e1514eadac6e6c1670ec7b36bc1d6fcb3a', 'message': 'Deny updates to AWS::EC2::Volume resource\n\nAccording to AWS docs [1] Volume resource does not support updates\n(including resource replacement) of any of its properties.\nTo align our AWS-compatible resource with such behavior, all properties\nof AWS::EC2::Volume resource are marked as immutable.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volume.html\n\nChange-Id: I7fea68f11c58d395c1eb31fae834afcab5dc4d1e\nCloses-Bug: #1340093\n'}, {'number': 4, 'created': '2014-08-08 08:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e5a83dd9b7da86fe3e4f14fde3bb70444ad8109a', 'message': 'Deny updates to AWS::EC2::Volume resource\n\nAccording to AWS docs [1] Volume resource does not support updates\n(including resource replacement) of any of its properties.\nTo align our AWS-compatible resource with such behavior, all properties\nof AWS::EC2::Volume resource are marked as immutable.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volume.html\n\nChange-Id: I7fea68f11c58d395c1eb31fae834afcab5dc4d1e\nCloses-Bug: #1340093\n'}, {'number': 5, 'created': '2014-08-08 13:15:02.000000000', 'files': ['heat/engine/resources/volume.py', 'heat/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a08dcd796fa1768becdcce0a4c77c0f15245dd8d', 'message': 'Deny updates to AWS::EC2::Volume resource\n\nAccording to AWS docs [1] Volume resource does not support updates\n(including resource replacement) of any of its properties.\nTo align our AWS-compatible resource with such behavior, all properties\nof AWS::EC2::Volume resource are marked as immutable.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volume.html\n\nChange-Id: I7fea68f11c58d395c1eb31fae834afcab5dc4d1e\nCloses-Bug: #1340093\n'}]",0,112274,a08dcd796fa1768becdcce0a4c77c0f15245dd8d,32,10,5,9542,,,0,"Deny updates to AWS::EC2::Volume resource

According to AWS docs [1] Volume resource does not support updates
(including resource replacement) of any of its properties.
To align our AWS-compatible resource with such behavior, all properties
of AWS::EC2::Volume resource are marked as immutable.

[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-ebs-volume.html

Change-Id: I7fea68f11c58d395c1eb31fae834afcab5dc4d1e
Closes-Bug: #1340093
",git fetch https://review.opendev.org/openstack/heat refs/changes/74/112274/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/volume.py'],1,b424bcc9f2ee66b44fb9f144762022b49659134f,bug/1340093," required=True, immutable=True immutable=True, 'volume.'), immutable=True immutable=True,", required=True 'volume.'),6,2
openstack%2Fheat~master~I10fe495a2a35429b3d6e254c23ae91732e2e4dd8,openstack/heat,master,I10fe495a2a35429b3d6e254c23ae91732e2e4dd8,Amend docs with `immutable` property attribute.,MERGED,2014-08-06 11:45:45.000000000,2014-08-13 17:33:27.000000000,2014-08-13 17:33:26.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 8435}, {'_account_id': 8537}, {'_account_id': 9542}, {'_account_id': 11599}, {'_account_id': 12437}]","[{'number': 1, 'created': '2014-08-06 11:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/876676e2b6962a6552171aef9bed5e623b5d3ab8', 'message': 'Amend docs with `immutable` property attribute.\n\nInclude warning about updates not being supported for a propety\nbased on its `immutable` value being True.\n\nChange-Id: I10fe495a2a35429b3d6e254c23ae91732e2e4dd8\nImplements: blueprint aws-updates-not-supported\n'}, {'number': 2, 'created': '2014-08-06 11:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/378c9399a09a96bb81ed5b2553d58277c94cdafd', 'message': 'Amend docs with `immutable` property attribute.\n\nInclude warning about updates not being supported for a propety\nbased on its `immutable` value being True.\n\nChange-Id: I10fe495a2a35429b3d6e254c23ae91732e2e4dd8\nImplements: blueprint implement-aws-updates-not-supported\n'}, {'number': 3, 'created': '2014-08-07 12:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7d18f03a0c2a665d44e59ef35cdce83627bdaff2', 'message': 'Amend docs with `immutable` property attribute.\n\nInclude warning about updates not being supported for a propety\nbased on its `immutable` value being True.\n\nChange-Id: I10fe495a2a35429b3d6e254c23ae91732e2e4dd8\nImplements: blueprint implement-aws-updates-not-supported\n'}, {'number': 4, 'created': '2014-08-08 08:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/12e85bdc1a57174fcc7e59cfafe86308b8652b10', 'message': 'Amend docs with `immutable` property attribute.\n\nInclude warning about updates not being supported for a propety\nbased on its `immutable` value being True.\n\nChange-Id: I10fe495a2a35429b3d6e254c23ae91732e2e4dd8\nImplements: blueprint implement-aws-updates-not-supported\n'}, {'number': 5, 'created': '2014-08-08 13:15:02.000000000', 'files': ['doc/source/ext/resources.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7d1cf3d680cea7dec02bf1dec9ee19abb61cf9eb', 'message': 'Amend docs with `immutable` property attribute.\n\nInclude warning about updates not being supported for a propety\nbased on its `immutable` value being True.\n\nChange-Id: I10fe495a2a35429b3d6e254c23ae91732e2e4dd8\nImplements: blueprint implement-aws-updates-not-supported\n'}]",2,112273,7d1cf3d680cea7dec02bf1dec9ee19abb61cf9eb,33,10,5,9542,,,0,"Amend docs with `immutable` property attribute.

Include warning about updates not being supported for a propety
based on its `immutable` value being True.

Change-Id: I10fe495a2a35429b3d6e254c23ae91732e2e4dd8
Implements: blueprint implement-aws-updates-not-supported
",git fetch https://review.opendev.org/openstack/heat refs/changes/73/112273/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/ext/resources.py'],1,876676e2b6962a6552171aef9bed5e623b5d3ab8,bug/1340093," elif prop.immutable: para = nodes.paragraph('', _('Updates are not supported. ' 'Resource update will fail on any ' 'attempt to update this property.')) definition.append(para)",,5,1
openstack%2Fceilometer~master~I6e83fbcbee23a519fe26c3036f42cc619848a989,openstack/ceilometer,master,I6e83fbcbee23a519fe26c3036f42cc619848a989,Doc enhancement for API service deployment with mod_wsgi,MERGED,2014-08-04 03:24:49.000000000,2014-08-13 17:33:19.000000000,2014-08-13 17:33:17.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6484}, {'_account_id': 6537}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8290}]","[{'number': 1, 'created': '2014-08-04 03:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/25d301da8018dc01f76e87a7157190c0cc2c1008', 'message': ""Doc enhancement for API service deployment with mod_wsgi\n\nNow Pecan is sharing the same debug configration with Ceilometer,\nbut DebugMiddleware of Pecan doesn't support multi processes.\nThat means user can't enable the Ceilometer debug mode if he is\nusing multi process mode for mod_wsgi config.\n\nCloses-Bug: 1352088\n\nChange-Id: I6e83fbcbee23a519fe26c3036f42cc619848a989\n""}, {'number': 2, 'created': '2014-08-04 22:25:04.000000000', 'files': ['doc/source/install/mod_wsgi.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f2685fc531cf83539e4d86efef0b306fe304addb', 'message': ""Doc enhancement for API service deployment with mod_wsgi\n\nNow Pecan is sharing the same debug configration with Ceilometer,\nbut DebugMiddleware of Pecan doesn't support multi processes.\nThat means user can't enable the Ceilometer debug mode if he is\nusing multi process mode for mod_wsgi config.\n\nCloses-Bug: 1352088\n\nChange-Id: I6e83fbcbee23a519fe26c3036f42cc619848a989\n""}]",7,111623,f2685fc531cf83539e4d86efef0b306fe304addb,26,8,2,6484,,,0,"Doc enhancement for API service deployment with mod_wsgi

Now Pecan is sharing the same debug configration with Ceilometer,
but DebugMiddleware of Pecan doesn't support multi processes.
That means user can't enable the Ceilometer debug mode if he is
using multi process mode for mod_wsgi config.

Closes-Bug: 1352088

Change-Id: I6e83fbcbee23a519fe26c3036f42cc619848a989
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/23/111623/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/mod_wsgi.rst'],1,25d301da8018dc01f76e87a7157190c0cc2c1008,bug/1352088," Limitation ========== Because Ceilometer is using Pecan and Pecan's DebugMiddleware doesn't support multiple processes. So user will run into HTTP 500 error if the mod_wsgi's multiple processes is enabled and the Ceilometer debug mode is enabled at the same time. There is no good way to make both of them work, since Pecan is sharing the debug mode with Ceilometer, see https://github.com/openstack/ceilometer/blob/master/ceilometer/api/app.py#L73 If you really need to enable both, a possible workaround is hacking this line and hardcode the debug configration to False.",,11,0
openstack%2Frequirements~master~I9fe54837781774f9ac4262260bc4124ecc86c905,openstack/requirements,master,I9fe54837781774f9ac4262260bc4124ecc86c905,Add oslo.serialization to projects.txt,MERGED,2014-08-08 18:20:29.000000000,2014-08-13 17:33:16.000000000,2014-08-13 17:33:15.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-08-08 18:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4d82289d7037b21dc8e0d93b175f5718c35cdd65', 'message': 'Add oslo.serialization to projects.txt\n\nChange-Id: I9fe54837781774f9ac4262260bc4124ecc86c905\n'}, {'number': 2, 'created': '2014-08-12 17:01:07.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c2d70bb10b0728a838230f3dcc3cc5ab589dc91b', 'message': 'Add oslo.serialization to projects.txt\n\nChange-Id: I9fe54837781774f9ac4262260bc4124ecc86c905\n'}]",0,112993,c2d70bb10b0728a838230f3dcc3cc5ab589dc91b,19,4,2,6928,,,0,"Add oslo.serialization to projects.txt

Change-Id: I9fe54837781774f9ac4262260bc4124ecc86c905
",git fetch https://review.opendev.org/openstack/requirements refs/changes/93/112993/2 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,4d82289d7037b21dc8e0d93b175f5718c35cdd65,serialization,openstack/oslo.serialization,,1,0
openstack%2Ftraining-guides~master~Ie1d5237f750fc82c7f4c13d672c81c4172a4a56b,openstack/training-guides,master,Ie1d5237f750fc82c7f4c13d672c81c4172a4a56b,Adds cinder scripts for training labs,MERGED,2014-08-12 12:22:23.000000000,2014-08-13 17:29:17.000000000,2014-08-13 17:29:17.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 9178}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-12 12:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/c8048a687c162e86e2e79582ba1e06c1f17d8dac', 'message': 'Adds cinder scripts for training labs\n\nAdds cinder scripts for training labs which will install and configure\ncinder.\n\nChange-Id: Ie1d5237f750fc82c7f4c13d672c81c4172a4a56b\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 2, 'created': '2014-08-12 14:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/1c4a823bfc2b84e55cd165ccd641d8afdb90aaff', 'message': 'Adds cinder scripts for training labs\n\nAdds cinder scripts for training labs which will install and configure\ncinder.\n\nChange-Id: Ie1d5237f750fc82c7f4c13d672c81c4172a4a56b\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 3, 'created': '2014-08-12 16:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/fac0dc949259d67fa03bf84038157af9e9887aa0', 'message': 'Adds cinder scripts for training labs\n\nAdds cinder scripts for training labs which will install and configure\ncinder.\n\nChange-Id: Ie1d5237f750fc82c7f4c13d672c81c4172a4a56b\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 4, 'created': '2014-08-12 16:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/16caf8c7d4005f6a743f0775d00d190ee0a426be', 'message': 'Adds cinder scripts for training labs\n\nAdds cinder scripts for training labs which will install and configure\ncinder.\n\nChange-Id: Ie1d5237f750fc82c7f4c13d672c81c4172a4a56b\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 5, 'created': '2014-08-12 19:06:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/97d47bb45559494805f7ab20c667e0592aaa4bae', 'message': 'Adds cinder scripts for training labs\n\nAdds cinder scripts for training labs which will install and configure\ncinder.\n\nChange-Id: Ie1d5237f750fc82c7f4c13d672c81c4172a4a56b\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 6, 'created': '2014-08-13 13:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/818cc1216cff0f840e783dd69508bde61d3933c6', 'message': 'Adds cinder scripts for training labs\n\nAdds cinder scripts for training labs which will install and configure\ncinder.\n\nChange-Id: Ie1d5237f750fc82c7f4c13d672c81c4172a4a56b\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 7, 'created': '2014-08-13 13:39:06.000000000', 'files': ['labs/scripts/setup_cinder_volumes.sh', 'labs/config/scripts.controller', 'labs/scripts/setup_cinder_controller.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/b305de4eb1b3669b0a8e94864916cba5b9531da3', 'message': 'Adds cinder scripts for training labs\n\nAdds cinder scripts for training labs which will install and configure\ncinder.\n\nChange-Id: Ie1d5237f750fc82c7f4c13d672c81c4172a4a56b\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}]",2,113509,b305de4eb1b3669b0a8e94864916cba5b9531da3,30,4,7,7007,,,0,"Adds cinder scripts for training labs

Adds cinder scripts for training labs which will install and configure
cinder.

Change-Id: Ie1d5237f750fc82c7f4c13d672c81c4172a4a56b
Co-Authored-By: Roger Luethi <rl@patchworkscience.org>
Partial-Bug: 1312764
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/09/113509/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/config/scripts.controller', 'labs/scripts/setup_cinder.sh']",2,c8048a687c162e86e2e79582ba1e06c1f17d8dac,bug/1312764,"#!/usr/bin/env bash TOP_DIR=$(cd $(dirname ""$0"")/.. && pwd) source ""$TOP_DIR/config/paths"" source ""$CONFIG_DIR/credentials"" source ""$LIB_DIR/functions.guest"" source ""$CONFIG_DIR/labs-openstackrc.sh"" exec_logfile indicate_current_auto #------------------------------------------------------------------------------ # Set up Block Storage Service (cinder). #------------------------------------------------------------------------------ echo ""Installing cinder."" sudo apt-get install -y cinder-api cinder-scheduler lvm2 cinder-volume echo ""Setting up database for cinder."" setup_database cinder function get_database_url { local db_user=$(service_to_db_user cinder) local db_password=$(service_to_db_password cinder) local database_host=controller-mgmt echo ""mysql://$db_user:$db_password@$database_host/cinder"" } database_url=$(get_database_url) echo ""Configuring cinder."" echo ""Setting database connection: $database_url."" iniset_sudo /etc/cinder/cinder.conf database connection ""$database_url"" echo ""Creating the database tables for cinder."" sudo cinder-manage db_sync cinder_admin_user=$(service_to_user_name cinder) cinder_admin_password=$(service_to_user_password cinder) echo ""Creating cinder user and giving it admin role under service tenant."" keystone user-create \ --name ""$cinder_admin_user"" \ --pass ""$cinder_admin_password"" \ --email cinder@domain.com keystone user-role-add \ --user ""$cinder_admin_user"" \ --tenant ""$SERVICE_TENANT_NAME"" \ --role ""$ADMIN_ROLE_NAME"" echo ""Configuring cinder to use keystone for authentication."" echo ""Configuring cinder-api.conf."" conf=/etc/cinder/cinder.conf # Configure [keystone_authtoken] section. iniset_sudo $conf keystone_authtoken auth_uri ""http://controller-mgmt:5000"" iniset_sudo $conf keystone_authtoken auth_host controller-mgmt iniset_sudo $conf keystone_authtoken auth_port 35357 iniset_sudo $conf keystone_authtoken auth_protocol http iniset_sudo $conf keystone_authtoken admin_tenant_name ""$SERVICE_TENANT_NAME"" iniset_sudo $conf keystone_authtoken admin_user ""$cinder_admin_user"" iniset_sudo $conf keystone_authtoken admin_password ""$cinder_admin_password"" # Configure [DEFAULT} section. iniset_sudo $conf DEFAULT rpc_backend cinder.openstack.common.rpc.impl_kombu iniset_sudo $conf DEFAULT rabbit_host = controller-mgmt iniset_sudo $conf DEFAULT rabbit_port = 5672 iniset_sudo $conf DEFAULT rabbit_userid = guest iniset_sudo $conf DEFAULT rabbit_password = $RABBIT_PASSWORD echo ""Registering cinder with keystone so that other services can locate it."" keystone service-create \ --name cinder \ --type block_storage\ --description ""OpenStack Block Storage Service"" cinder_service_id=$(keystone service-list | awk '/ image / {print $2}') keystone endpoint-create \ --service-id ""$cinder_service_id"" \ --publicurl ""http://controller-api:9292"" \ --adminurl ""http://controller-mgmt:9292"" \ --internalurl ""http://controller-mgmt:9292"" # TODO: Add a Virtual/Physical HDD to Cinder as Cinder Volumes # Link: http://docs.openstack.org/icehouse/install-guide/install/apt/content/cinder-node.html echo ""Restarting cinder service."" sudo service cinder-scheduler restart sudo service cinder-api restart sudo service cinder-volume restart sudo service tgt restart ",,95,0
openstack%2Fopenstacksdk~master~I112eb4ed071f51ba036ff57caca82f0b6f34d9dd,openstack/openstacksdk,master,I112eb4ed071f51ba036ff57caca82f0b6f34d9dd,compute/v2 extension resource,MERGED,2014-08-08 21:04:38.000000000,2014-08-13 17:19:40.000000000,2014-08-13 17:19:39.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-08 21:04:38.000000000', 'files': ['openstack/compute/v2/extension.py', 'openstack/tests/compute/v2/test_extension.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3cca5a2e0430d338eb416d9b45494f49370e93b3', 'message': 'compute/v2 extension resource\n\nChange-Id: I112eb4ed071f51ba036ff57caca82f0b6f34d9dd\n'}]",0,113023,3cca5a2e0430d338eb416d9b45494f49370e93b3,10,3,1,8736,,,0,"compute/v2 extension resource

Change-Id: I112eb4ed071f51ba036ff57caca82f0b6f34d9dd
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/23/113023/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/compute/v2/extension.py', 'openstack/tests/compute/v2/test_extension.py']",2,3cca5a2e0430d338eb416d9b45494f49370e93b3,extension,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testtools from openstack.compute.v2 import extension IDENTIFIER = 'IDENTIFIER' EXAMPLE = { 'alias': '1', 'description': '2', 'links': '3', 'name': '4', 'namespace': '5', 'updated': '6', } class TestExtension(testtools.TestCase): def test_basic(self): sot = extension.Extension() self.assertEqual('extension', sot.resource_key) self.assertEqual('extensions', sot.resources_key) self.assertEqual('/extensions', sot.base_path) self.assertEqual('compute', sot.service.service_type) self.assertFalse(sot.allow_create) self.assertFalse(sot.allow_retrieve) self.assertFalse(sot.allow_update) self.assertFalse(sot.allow_delete) self.assertTrue(sot.allow_list) def test_make_it(self): sot = extension.Extension(EXAMPLE) self.assertEqual(EXAMPLE['alias'], sot.alias) self.assertEqual(EXAMPLE['description'], sot.description) self.assertEqual(EXAMPLE['links'], sot.links) self.assertEqual(EXAMPLE['name'], sot.name) self.assertEqual(EXAMPLE['namespace'], sot.namespace) self.assertEqual(EXAMPLE['updated'], sot.updated) ",,81,0
openstack%2Fmonasca-api~master~Ie5428d1cdd0b4821252b08df045da274d47cdabf,openstack/monasca-api,master,Ie5428d1cdd0b4821252b08df045da274d47cdabf,Add copyrights to files without them,MERGED,2014-08-10 16:46:44.000000000,2014-08-13 17:15:47.000000000,2014-08-13 17:15:47.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}]","[{'number': 1, 'created': '2014-08-10 16:46:44.000000000', 'files': ['src/test/java/com/hpcloud/mon/domain/model/NotificationMethodTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/influxdb/UtilsTest.java', 'src/test/java/com/hpcloud/mon/domain/model/AbstractModelTest.java', 'src/test/java/com/hpcloud/mon/app/validation/AlarmExpressionsTest.java', 'src/main/java/com/hpcloud/mon/infrastructure/persistence/vertica/MetricQueries.java', 'src/test/java/com/hpcloud/mon/app/command/CreateAlarmCommandTest.java', 'src/test/java/com/hpcloud/mon/app/command/CreateNotificationMethodTest.java', 'src/test/java/com/hpcloud/mon/integration/AlarmIntegrationTest.java', 'src/main/java/com/hpcloud/mon/infrastructure/package-info.java', 'src/test/java/com/hpcloud/mon/resource/LinksTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/vertica/MetricQueriesTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/vertica/MeasurementVerticaRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/app/validation/DimensionsTest.java', 'src/test/java/com/hpcloud/mon/app/AlarmServiceTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/influxdb/AlarmStateHistoryInfluxDbRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/domain/model/AlarmTest.java', 'src/test/java/com/hpcloud/mon/resource/AlarmResourceTest.java', 'src/test/java/com/hpcloud/mon/resource/VersionResourceTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/SubAlarmQueriesTest.java', 'src/test/java/com/hpcloud/mon/domain/model/VersionTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/vertica/MetricDefinitionVerticaRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/resource/AbstractMonApiResourceTest.java', 'src/test/java/com/hpcloud/mon/integration/MetricIntegrationTest.java', 'src/test/java/com/hpcloud/mon/resource/exception/ErrorMessages.java', 'src/test/java/com/hpcloud/mon/resource/NotificationMethodResourceTest.java', 'src/main/java/com/hpcloud/mon/infrastructure/servlet/RoleAuthorizationFilter.java', 'src/test/java/com/hpcloud/mon/resource/StatisticResourceTest.java', 'src/test/java/com/hpcloud/mon/MonApiApplicationRunner.java', 'src/test/java/com/hpcloud/mon/resource/MetricResourceTest.java', 'src/test/java/com/hpcloud/mon/integration/NotificationMethodIntegrationTest.java', 'src/main/java/com/hpcloud/mon/app/package-info.java', 'src/main/java/com/hpcloud/mon/domain/package-info.java', 'src/test/java/com/hpcloud/mon/integration/docker/ITInfluxDBTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/vertica/AlarmStateHistoryVerticaRepositoryImplTest.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/8cb9723fbc08926bb34ac06d2e6b6c55706296c6', 'message': 'Add copyrights to files without them\n\nChange-Id: Ie5428d1cdd0b4821252b08df045da274d47cdabf\n'}]",0,113140,8cb9723fbc08926bb34ac06d2e6b6c55706296c6,10,3,1,11809,,,0,"Add copyrights to files without them

Change-Id: Ie5428d1cdd0b4821252b08df045da274d47cdabf
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/40/113140/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/test/java/com/hpcloud/mon/domain/model/NotificationMethodTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/influxdb/UtilsTest.java', 'src/test/java/com/hpcloud/mon/domain/model/AbstractModelTest.java', 'src/test/java/com/hpcloud/mon/app/validation/AlarmExpressionsTest.java', 'src/main/java/com/hpcloud/mon/infrastructure/persistence/vertica/MetricQueries.java', 'src/test/java/com/hpcloud/mon/app/command/CreateAlarmCommandTest.java', 'src/test/java/com/hpcloud/mon/app/command/CreateNotificationMethodTest.java', 'src/test/java/com/hpcloud/mon/integration/AlarmIntegrationTest.java', 'src/main/java/com/hpcloud/mon/infrastructure/package-info.java', 'src/test/java/com/hpcloud/mon/resource/LinksTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/vertica/MetricQueriesTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/vertica/MeasurementVerticaRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/app/validation/DimensionsTest.java', 'src/test/java/com/hpcloud/mon/app/AlarmServiceTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/influxdb/AlarmStateHistoryInfluxDbRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/domain/model/AlarmTest.java', 'src/test/java/com/hpcloud/mon/resource/AlarmResourceTest.java', 'src/test/java/com/hpcloud/mon/resource/VersionResourceTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/SubAlarmQueriesTest.java', 'src/test/java/com/hpcloud/mon/domain/model/VersionTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/vertica/MetricDefinitionVerticaRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/resource/AbstractMonApiResourceTest.java', 'src/test/java/com/hpcloud/mon/integration/MetricIntegrationTest.java', 'src/test/java/com/hpcloud/mon/resource/exception/ErrorMessages.java', 'src/test/java/com/hpcloud/mon/resource/NotificationMethodResourceTest.java', 'src/main/java/com/hpcloud/mon/infrastructure/servlet/RoleAuthorizationFilter.java', 'src/test/java/com/hpcloud/mon/resource/StatisticResourceTest.java', 'src/test/java/com/hpcloud/mon/MonApiApplicationRunner.java', 'src/test/java/com/hpcloud/mon/resource/MetricResourceTest.java', 'src/test/java/com/hpcloud/mon/integration/NotificationMethodIntegrationTest.java', 'src/main/java/com/hpcloud/mon/app/package-info.java', 'src/main/java/com/hpcloud/mon/domain/package-info.java', 'src/test/java/com/hpcloud/mon/integration/docker/ITInfluxDBTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/vertica/AlarmStateHistoryVerticaRepositoryImplTest.java']",34,8cb9723fbc08926bb34ac06d2e6b6c55706296c6,add_copyrights,"/* * Copyright (c) 2014 Hewlett-Packard Development Company, L.P. * * Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except * in compliance with the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software distributed under the License * is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express * or implied. See the License for the specific language governing permissions and limitations under * the License. */ ",,479,3
openstack%2Fmonasca-agent~master~Iaf9240fe9d5025d533ad8f866189f3c72516302a,openstack/monasca-agent,master,Iaf9240fe9d5025d533ad8f866189f3c72516302a,Updated agent documentation,MERGED,2014-08-08 15:16:44.000000000,2014-08-13 16:43:49.000000000,2014-08-13 16:43:48.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1976}, {'_account_id': 2419}]","[{'number': 1, 'created': '2014-08-08 15:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/6320d25daf8da0a226e8074ab7cafca1fcac62f4', 'message': 'Updating agent documentation and added error message if running on unsupported os.\n\nChange-Id: Iaf9240fe9d5025d533ad8f866189f3c72516302a\n'}, {'number': 2, 'created': '2014-08-12 18:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/672e04b8658f7c4ef1aef29f9d2ed20002869b3d', 'message': 'Updated agent documentation\n\nUpdate user documentation and generate error for unsupported os\n\nChange-Id: Iaf9240fe9d5025d533ad8f866189f3c72516302a\n'}, {'number': 3, 'created': '2014-08-13 06:53:38.000000000', 'files': ['monasca-agent_arch.png', 'monsetup/main.py', 'README.md'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/c299ac861ae31ba91188746228f5eaa166993cc8', 'message': 'Updated agent documentation\n\nUpdate user documentation and generate error for unsupported os\n\nChange-Id: Iaf9240fe9d5025d533ad8f866189f3c72516302a\n'}]",0,112921,c299ac861ae31ba91188746228f5eaa166993cc8,29,4,3,12108,,,0,"Updated agent documentation

Update user documentation and generate error for unsupported os

Change-Id: Iaf9240fe9d5025d533ad8f866189f3c72516302a
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/21/112921/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca-agent_arch.png', 'monsetup/main.py', 'README.md']",3,6320d25daf8da0a226e8074ab7cafca1fcac62f4,monasca/update-documentation,"<!-- START doctoc generated TOC please keep comment here to allow auto update --> <!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --> **Table of Contents** - [Introduction](#introduction) - [Architecture](#architecture) - [Installing](#installing) - [Configuring](#configuring) - [Configuration Options](#configuration-options) - [Configuring Plugins](#configuring-plugins) - [monasca-setup](#monasca-setup) - [Configuration Options](#configuration-options-1) - [Chef Cookbook](#chef-cookbook) - [monasca-alarm-manager](#monasca-alarm-manager) - [Running](#running) - [Running from the command-line](#running-from-the-command-line) - [Running as a daemon](#running-as-a-daemon) - [Trouble-shooting](#trouble-shooting) - [Naming conventions](#naming-conventions) - [Common Naming Conventions](#common-naming-conventions) - [Metric Names](#metric-names) - [Dimensions](#dimensions) - [OpenStack Specific Naming Conventions](#openstack-specific-naming-conventions) - [Metric Names](#metric-names-1) - [Dimensions](#dimensions-1) - [Checks](#checks) - [System Metrics](#system-metrics) - [Nagios](#nagios) - [Statsd](#statsd) - [Log Parsing](#log-parsing) - [Host alive](#host-alive) - [Process exists](#process-exists) - [Http Endpoint checks](#http-endpoint-checks) - [MySQL](#mysql) - [RabbitMQ](#rabbitmq) - [Kafka](#kafka) - [Other](#other) - [OpenStack](#openstack) - [Nova](#nova) - [Swift](#swift) - [Glance](#glance) - [Cinder](#cinder) - [Neutron](#neutron) - [Keystone](#keystone) - [Seed Controller](#seed-controller) - [Developing New Checks](#developing-new-checks) - [AgentCheck Interface](#agentcheck-interface) - [ServicesCheck interface](#servicescheck-interface) - [Sending Metrics](#sending-metrics) - [Plugin Configuration](#plugin-configuration) - [init_config](#init_config) - [instances](#instances) - [Plugin Documentation](#plugin-documentation) - [License](#license) <!-- END doctoc generated TOC please keep comment here to allow auto update --> * Retrieving metrics from log files written in a specific format. * Host alive. The Monasca Agent can perform active checks on a host to determine if it is alive using ping(ICMP) or SSH.This diagram illustrates the monasca-agent architecture, and the table which follows it explains each component. ![alt text](monasca-agent_arch.png) | Supervisor | supervisord | Runs as root, launches all other processes as the ""monasca-agent"" user | | Collector | monasca-collector | Gathers system & application metrics | | Monstatsd | monasca-statsd | Statsd engine capable of handling dimensions associated with metrics submitted by a client that supports them. Also supports metrics from the standard statsd client. (udp/8125) | | Forwarder | monasca-forwarder | Gathers data from statsd and submits it to Monasca API over SSL (tcp/17123) | The Agent includes the script ""monasca-setup"", that can be used for automatically configuring the agent to generate metrics that are sent to the API. It creates the agent.conf file locate in /etc/monasca/agent directory. It also sets up additional checks based on what is running locally on that machine. For instance, if this is a compute node, the agent will setup checks to monitor the Nova processes and setup a http_status check on the nova-api. It can also detect other servers such as mySQL and Kafka and setup checks for them as well.The Agent (monasca-agent) is available for installation from the Python Package Index (PyPI). To install it, you first need `pip` installed on the node to be monitored. Instructions on installing pip may be found at https://pip.pypa.io/en/latest/installing.html. The Agent will NOT run under any flavor of Windows or Mac OS at this time but has been tested thoroughly on Ubuntu and should work under most flavors of Linux. Support may be added for Mac OS and Windows in the future. Example of an Ubuntu or Debian based install:sudo apt-get install python-pipsudo pip install --upgrade pipsudo pip install monasca-agentThe Agent requires configuration in order to run. There are two ways to configure the agent, either using the [monasca-setup](#monasca-setup) script or manually. ## monasca-setup (Recommended) The Monasca agent has a script, called ""monasca-setup"", that should be used to automatically configure the Agent to send metrics to a Monasca API. This script will create the agent.conf configuration file as well as any plugin configuration yaml files needed to monitor the processes on the local machine. The agent configuration files are located in /etc/monasca/agent. The plugin configuration files are located in located in /etc/monasca/agent/conf.d. To run monasca-setup: ``` sudo monasca-setup --username KEYSTONE_USERNAME --password KEYSTONE_PASSWORD --project_name KEYSTONE_PROJECT_NAME --service SERVICE_NAME --keystone_url http://URL_OF_KEYSTONE_API:35357/v3 --monasca_url http://URL_OF_MONASCA_API:8080/v2.0 --overwrite ``` ### Explanation of monasca-setup command-line parameters: All parameters require a '--' before the parameter such as '--verbose' | Parameter | Description | Example Value| | ----------- | ------------ | ----------- | | username | This is a required parameter that specifies the username needed to login to Keystone to get a token | myuser | | password | This is a required parameter that specifies the password needed to login to Keystone to get a token | mypassword | | project_name | This is a required parameter that specifies the name of the Keystone project name to store the metrics under | myproject | | keystone_url | This is a required parameter that specifies the url of the keystone api for retrieving tokens | http://192.168.1.5:35357/v3 | | service | This is a required parameter that specifies the name of the service associated with this particular node | nova, cinder, myservice | | monasca_url | This is a required parameter that specifies the url of the monasca api for retrieving tokens | http://192.168.1.4:8080/v2.0 | | config_dir | This is an optional parameter that specifies the directory where the agent configuration files will be stored. | /etc/monasca/agent | | log_dir | This is an optional parameter that specifies the directory where the agent log files will be stored. | /var/log/monasca/agent | | template_dir | This is an optional parameter that specifies the directory where the agent template files will be stored. | /usr/local/share/monasca/agent | | user | This is an optional parameter that specifies the user name to run monasca-agent as | monasca-agent | | headless | This is an optional parameter that specifies whether monasca-setup should run in a non-interactive mode | | | skip_enable | This is an optional parameter. By default the service is enabled, which requires the script run as root. Set this parameter to skip that step. | | | verbose | This is an optional parameter that specifies whether the monasca-setup script will print additional information for debugging purposes | | | overwrite | This is an optional parameter to overwrite the plugin configuration. Use this if you don't want to keep the original configuration. If this parameter is not specified, the configuration will be appended to the existing configuration, possibly creating duplicate checks. **NOTE:** The agent config file, agent.conf, will always be overwritten, even if this parameter is not specified | | ### Manual Configuration of the Agent This is not the recommended way to configure the agent but if you are having trouble running the monasca-setup program, you can manually configure the agent using the steps below: Start by creating an agent.conf file. An example configuration file can be found in /usr/local/share/monasca/agent/. sudo mkdir -p /etc/monasca/agent sudo cp /usr/local/share/monasca/agent/agent.conf.template /etc/monasca/agent/agent.conf sudo nano /etc/monasca/agent/agent.conf In particular, replace any values that have curly braces. Example: Change username: {args.username} to username: myuser You must replace all of the curly brace values and you can also optionally tweak any of the other configuration items as well like a port number in the case of a port conflict. The config file options are documented in the agent.conf.template file. You may also specify zero or more dimensions that would be included in every metric generated on that node, using the dimensions: value. Example: (include no extra dimensions on every metric) dimensions: (This means no dimensions) OR dimensions: service:nova (This means one dimension called service with a value of nova) OR dimensions: service:nova, group:group_a, zone:2 (This means three dimensions) Once the configuration file has been updated and saved, monasca-agent must be restarted. sudo service monasca-agent restart ### Manual Configuration of Plugins If you did not run monasca-setup and/or there are additional plugins you would like to activate, follow the steps below: Agent plugins are activated by placing a valid configuration file in the /etc/monasca/agent/conf.d/ directory. Configuration files are in YAML format, with the file extension .yaml. You may find example configuration files in /usr/local/share/monasca/agent/conf.d/ sudo mkdir -p /etc/monasca/agent/conf.d sudo cp /usr/local/share/monasca/agent/conf.d/http_check.yaml.example /etc/monasca/agent/conf.d/http_check.yaml sudo nano /etc/monasca/agent/conf.d/http_check.yamlinit_config and instancesA plugin config is specified something like this: init_config: is_jmx: true # Metrics collected by this check. You should not have to modify this. conf: # # Aggregate cluster stats # - include: domain: '""kafka.server""' bean: '""kafka.server"":type=""BrokerTopicMetrics"",name=""AllTopicsBytesOutPerSec""' attribute: MeanRate: metric_type: counter alias: kafka.net.bytes_out instances: - host: localhost port: 9999 name: jmx_instance user: username password: password #java_bin_path: /path/to/java #Optional, should be set if the agent cannot find your java executable #trust_store_path: /path/to/trustStore.jks # Optional, should be set if ssl is enabled #trust_store_password: password dimensions: env: stage newDim: test An example cookbook for Chef configuration of the monitoring agent is at [https://github.com/stackforge/cookbook-monasca-agent](https://github.com/stackforge/cookbook-monasca-agent). This cookbook can be used as an example of how to automate the install and configuration of the monasca-agent.To run the agent from the command-line, you will need to start at least 2 processes in order to send metrics. These are the collector and forwarder. If you have already installed the monasca-agent package and run the monasca-setup configuration script, run the following commands from the Linux command-line: * From a terminal window, use netcat to listen for metrics on a local port: nc -lk 8080 * From a second terminal window, launch the forwarder in the background: python ddagent.py & * From the second terminal window, launch the collector in the foreground: python agent.py foreground --use-local-forwarder * Metric payloads will start to appear in the first terminal window running netcat To control the monasca-agent daemon, you can use the init.d commands that are listed below: * To start the agent: sudo service monasca-agent start * To stop the agent: sudo service monasca-agent stop * To restart the agent if it is already running: sudo service monasca-agent restart| system.cpu.idle_perc | | Percentage of time the CPU is idle when no I/O requests are in progress || system.cpu.stolen_perc | | Percentage of stolen CPU time, i.e. the time spent in other OS contexts when running in a virtualized environment | | system.cpu.system_perc | | Percentage of time the CPU is used at the system level | | system.cpu.user_perc | | Percentage of time the CPU is used at the user level || system.mountpoint | | (OS dependent) The amount of disk space being used | system.inodes | device | | | system.mountpoint | | (OS dependent) inodes remaining in a filesystem| system.mountpoint | | (OS dependent) Percentage of inodes remaining in a filesystem | system.io_read_kbytes_sec device | | Kbytes/sec read by an io device | system.io.read_req_sec | device | Number of read requests/sec to an io device| system.io.write_req_sec | device | Number of write requests/sec to an io device | system.cpu.load_avg_1min | | The average system load over a 1 minute period | system.cpu.load_avg_5min | | The average system load over a 5 minute period | system.cpu.load_avg_15min | | The average system load over a 15 minute periodmonstatsd will accept metrics submitted by functions in either the standard statsd Python client library, or monasca-agent's monstatsd-python Python client library. The advantage of using the monstatsd-python library is that it is possible to specify dimensions on submitted metrics. Dimensions are not handled by the standard statsd client.Developers can extend the functionality of the Agent by writing custom plugins. Plugins are written in Python according to the conventions described below. The plugin script is placed in /etc/monasca/agent/checks.d, and a YAML file containing the configuration for the plugin is placed in /etc/monasca/agent/conf.d. The YAML file must have the same stem name as the plugin script.Most monasca-agent plugin code uses the AgentCheck interface. All custom checks inherit from the AgentCheck class found in monagent/collector/checks/__init__.py and require a check() method that takes one argument, instance, which is a dict specifying the configuration of the instance on behalf of the plugin being executed. The check() method is run once per instance defined in the check's configuration (discussed later).Some monasca-agent plugins use the ServicesCheck class found in monagent/collector/services_checks.py. These require a _check() method that is similar to AgentCheck's check(), but instead of being called once per iteration in a linear fashion, it is run against a threadpool to allow concurrent instances to be checked. Also, _check() must return a tuple consisting of either Status.UP or 'Status.DOWN(frommonagent.collector.checks.services_checks`), plus a text description.Your plugin should include an example YAML configuration file to be placed in /etc/monasca/agent/conf.d/ which has the name of the plugin YAML file plus the extension '.example', so the example configuration file for the process plugin would be at /etc/monasca/agent/conf.d/process.yaml.example. This file should include a set of example init_config and instances clauses that demonstrate how the plugin can be configured.","* Log Parsing. * Host alive. The Monasca Agent can perform active checks if a host is alive using ping(ICMP) or SSH.| Supervisor | supervisord | Runs as root, launches all other processes as the ""mon-agent"" user | | Collector | mon-collector | Gathers system & application metrics | | Monstatsd | monstatsd | Statsd engine capable of handling dimensions associated with metrics submitted by a client that supports them. Also supports metrics from the standard statsd client. (udp/8125) | | Forwarder | mon-forwarder | Gathers data from statsd and submits it to Mon API over SSL (tcp/17123) | The Agent includes the script ""monasca-setup"", that can be used for automatically configuring the metrics that are sent to the API.The Agent (monasca-agent) is available for installation from the Python Package Index (PyPI). To install it, you first need `pip` installed on the node to be monitored. Instructions or installing pip may be found at https://pip.pypa.io/en/latest/installing.html but for most uses, under a Debian or Ubuntu-based operating system,apt-get install python-pippip install --upgrade pippip install monasca-agentThe Agent requires configuration in order to run. Example configuration files can be found in /usr/local/share/mon/agent/. Start by creating an agent.conf file sudo cp /usr/local/share/mon/agent/agent.conf.example /etc/mon-agent/agent.conf sudo nano /etc/mon-agent/agent.conf In particular, replace the ""CHANGE_ME"" values as needed. You may also specify zero or more dimensions that would be included in every metric generated on that node, using the dimensions: value. Example: (include no extra dimensions on every metric) dimensions: (include one extra dimension on every metric) dimensions: service:mini-mon (include three extra dimensions on every metric) dimensions: service:mini-mon, group:group_a, az:2 Once the configuration file has been updated and saved, mon-agent may be started. sudo service mon-agent start The Agent has a number of configuration options that can be configured. To help configure the agent the script `monasca-setup` can be run. ## Configuration Options TBD ## Configuring Plugins Agent plugins are activated by placing a valid configuration file in the /etc/mon-agent/conf.d/ directory. Configuration files are in YAML format, with the file extension .yaml. You may find example configuration files in /usr/local/share/mon/agent/conf.d/ sudo cp /usr/local/share/mon/agent/conf.d/http_check.yaml.example /etc/mon-agent/conf.d/http_check.yaml sudo nano /etc/mon-agent/conf.d/http_check.yaml init_config: and instances: ## monasca-setup The Monasca agent has a script, called ""monasca-setup"", that can be used to automatically configure the Agent to send metrics to a Monasca API. To run monasca-setup ``` monasca-setup -u me -p pass --project_name myproject -s mini-mon --keystone_url https://keystone --monasca_url https://mon-api ``` ### Configuration OptionsAn example cookbook for Chef configuration of the monitoring agent is at [https://github.com/stackforge/cookbook-monasca-agent](https://github.com/stackforge/cookbook-monasca-agent).| system.cpu.idle_perc | | Percentage of time the CPU is idle when no I/O requests are in progress || system.cpu.stolen_perc | | Percentage of stolen CPU time, i.e. the time spent in other OS contexts when running in a virtualized environment | | system.cpu.system_perc | | Percentage of time the CPU is used at the system level | | system.cpu.user_perc | | Percentage of time the CPU is used at the user level || system.mountpoint | | (OS dependent) The amount of disk space being used | system.inodes | device | | | system.mountpoint | | (OS dependent) inodes remaining in a filesystem| system.mountpoint | | (OS dependent) Percentage of inodes remaining in a filesystem | system.io_read_kbytes_sec device | | Kbytes/sec read by an io device | system.io.read_req_sec | device | Number of read requests/sec to an io device| system.io.write_req_sec | device | Number of write requests/sec to an io device | system.cpu.load_avg_1min | | The average system load over a 1 minute period | system.cpu.load_avg_5min | | The average system load over a 5 minute period | system.cpu.load_avg_15min | | The average system load over a 15 minute periodmonstatsd will accept metrics submitted by functions in either the standard statsd Python client library, or mon-agent's monstatsd-python Python client library. The advantage of using the monstatsd-python library is that it is possible to specify dimensions on submitted metrics. Dimensions are not handled by the standard statsd client.Developers can extend the functionality of the Agent by writing custom plugins. Plugins are written in Python according to the conventions described below. The plugin script is placed in /etc/mon-agent/checks.d, and a YAML file containing the configuration for the plugin is placed in /etc/mon-agent/conf.d. The YAML file must have the same stem name as the plugin script.Most mon-agent plugin code uses the AgentCheck interface. All custom checks inherit from the AgentCheck class found in monagent/collector/checks/__init__.py and require a check() method that takes one argument, instance, which is a dict specifying the configuration of the instance on behalf of the plugin being executed. The check() method is run once per instance defined in the check's configuration (discussed later).Some mon-agent plugins use the ServicesCheck class found in monagent/collector/services_checks.py. These require a _check() method that is similar to AgentCheck's check(), but instead of being called once per iteration in a linear fashion, it is run against a threadpool to allow concurrent instances to be checked. Also, _check() must return a tuple consisting of either Status.UP or 'Status.DOWN(frommonagent.collector.checks.services_checks`), plus a text description.Your plugin should include an example YAML configuration file to be placed in /etc/mon-agent/conf.d/ which has the name of the plugin YAML file plus the extension '.example', so the example configuration file for the process plugin would be at /etc/mon-agent/conf.d/process.yaml.example. This file should include a set of example init_config and instances clauses that demonstrate how the plugin can be configured.",211,67
openstack%2Ftraining-guides~master~If3808436a218cc15ce2fd037ea52ec2fa5176a1e,openstack/training-guides,master,If3808436a218cc15ce2fd037ea52ec2fa5176a1e,Updates pre-download section,MERGED,2014-08-13 13:49:17.000000000,2014-08-13 16:30:54.000000000,2014-08-13 16:30:54.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-13 13:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/f73130003869ab0166af556278dc0cbe8fd02de5', 'message': 'Updates pre-download section.\n\nChange-Id: If3808436a218cc15ce2fd037ea52ec2fa5176a1e\n'}, {'number': 2, 'created': '2014-08-13 13:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/eb12b28e72c9b20b6f8bab5780f5ebf5af07ce2d', 'message': 'Updates pre-download section.\n\nImplements: blueprint openstack-training-labs\nChange-Id: If3808436a218cc15ce2fd037ea52ec2fa5176a1e\n'}, {'number': 3, 'created': '2014-08-13 15:22:30.000000000', 'files': ['labs/scripts/apt_pre-download.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/8c38ec350a350429e55dc7ac2d94f0fac7b924e8', 'message': 'Updates pre-download section\n\nThis patch removes some of the packages that are currently\npre-downloaded to the basedisk even though they are not needed for the\ntraining cluster.\n\nImplements: blueprint openstack-training-labs\nChange-Id: If3808436a218cc15ce2fd037ea52ec2fa5176a1e\n'}]",0,113891,8c38ec350a350429e55dc7ac2d94f0fac7b924e8,13,3,3,7007,,,0,"Updates pre-download section

This patch removes some of the packages that are currently
pre-downloaded to the basedisk even though they are not needed for the
training cluster.

Implements: blueprint openstack-training-labs
Change-Id: If3808436a218cc15ce2fd037ea52ec2fa5176a1e
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/91/113891/2 && git format-patch -1 --stdout FETCH_HEAD,['labs/scripts/apt_pre-download.sh'],1,f73130003869ab0166af556278dc0cbe8fd02de5,bug/1312764,sudo apt-get install -y --download-only cinder-api cinder-scheduler lvm2 \ cinder-volume glance openstack-dashboard memcached keystone \ neutron-server neutron-plugin-ml2 nova-api nova-cert nova-conductor \ nova-consoleauth nova-novncproxy nova-scheduler python-novaclient ,sudo apt-get install -y --download-only bridge-utils cinder-api cinder-scheduler cinder-volume glance iscsitarget iscsitarget-dkms keystone libvirt-bin memcached mysql-server neutron-dhcp-agent neutron-l3-agent neutron-plugin-openvswitch-agent neutron-server nova-ajax-console-proxy nova-api nova-cert nova-compute-kvm nova-conductor nova-consoleauth nova-doc nova-novncproxy nova-scheduler novnc ntp open-iscsi openstack-dashboard openvswitch-datapath-dkms openvswitch-switch pm-utils python-guestfs python-mysqldb python-novaclient rabbitmq-server vlan,5,1
openstack%2Fheat~master~I8352732328d0009688724f2b2ef8ca90fab16955,openstack/heat,master,I8352732328d0009688724f2b2ef8ca90fab16955,Refactor calling handle_* into a separate task,MERGED,2014-07-24 02:37:40.000000000,2014-08-13 16:16:28.000000000,2014-08-13 16:16:28.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 6498}, {'_account_id': 7193}, {'_account_id': 7404}, {'_account_id': 8537}, {'_account_id': 9542}, {'_account_id': 11599}]","[{'number': 1, 'created': '2014-07-24 02:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e521feac4e3c70df5913562314f81f94e60e0a0f', 'message': 'Refactor calling handle_* into a separate task\n\nChange-Id: I8352732328d0009688724f2b2ef8ca90fab16955\n'}, {'number': 2, 'created': '2014-08-08 15:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ef6baff07fd39d818e11b7458dd47e6f33ab8313', 'message': 'Refactor calling handle_* into a separate task\n\nChange-Id: I8352732328d0009688724f2b2ef8ca90fab16955\n'}, {'number': 3, 'created': '2014-08-12 22:02:53.000000000', 'files': ['heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/93b483402671659d0ac9b4ac1674a3ca9c760776', 'message': 'Refactor calling handle_* into a separate task\n\nChange-Id: I8352732328d0009688724f2b2ef8ca90fab16955\n'}]",3,109171,93b483402671659d0ac9b4ac1674a3ca9c760776,30,10,3,4257,,,0,"Refactor calling handle_* into a separate task

Change-Id: I8352732328d0009688724f2b2ef8ca90fab16955
",git fetch https://review.opendev.org/openstack/heat refs/changes/71/109171/3 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resource.py'],1,e521feac4e3c70df5913562314f81f94e60e0a0f,typeless-function-plugins," def action_handler_task(self, action, args=[], action_prefix=None): ''' A task to calls the Resource subclass's handler methods for an action. Calls the handle_<ACTION>() method for the given action and then calls the check_<ACTION>_complete() method with the result in a loop until it returns True. If the methods are not provided, the call is omitted. Any args provided are passed to the handler. If a prefix is supplied, the handler method handle_<PREFIX>_<ACTION>() is called instead. ''' handler_action = action.lower() check = getattr(self, 'check_%s_complete' % handler_action, None) if action_prefix: handler_action = '%s_%s' % (action_prefix.lower(), handler_action) handler = getattr(self, 'handle_%s' % handler_action, None) if callable(handler): handler_data = handler(*args) yield if callable(check): while not check(handler_data): yield @scheduler.wrappertask handler_args = [resource_data] if resource_data is not None else [] yield self.action_handler_task(action, args=handler_args) @scheduler.wrappertask yield self.action_handler_task(action, args=[after, tmpl_diff, prop_diff]) @scheduler.wrappertask if deletion_policy != self.t.RETAIN: if deletion_policy == self.t.SNAPSHOT: action_args = [[initial_state], 'snapshot'] else: action_args = [] yield self.action_handler_task(action, *action_args)"," action_l = action.lower() handle = getattr(self, 'handle_%s' % action_l, None) check = getattr(self, 'check_%s_complete' % action_l, None) handle_data = None if callable(handle): handle_data = (handle(resource_data) if resource_data else handle()) yield if callable(check): while not check(handle_data): yield if callable(getattr(self, 'handle_update', None)): handle_data = self.handle_update(after, tmpl_diff, prop_diff) yield if callable(getattr(self, 'check_update_complete', None)): while not self.check_update_complete(handle_data): yield handle_data = None if deletion_policy == self.t.DELETE: if callable(getattr(self, 'handle_delete', None)): handle_data = self.handle_delete() yield elif deletion_policy == self.t.SNAPSHOT: if callable(getattr(self, 'handle_snapshot_delete', None)): handle_data = self.handle_snapshot_delete(initial_state) yield if (deletion_policy != self.t.RETAIN and callable(getattr(self, 'check_delete_complete', None))): while not self.check_delete_complete(handle_data): yield",40,31
openstack%2Fcinder~master~Iced5e45362aef4286bb7f1c848ab7cb3573b5c02,openstack/cinder,master,Iced5e45362aef4286bb7f1c848ab7cb3573b5c02,Add ProphetStor DPL Storage server volume driver for Cinder,MERGED,2014-05-27 16:50:07.000000000,2014-08-13 15:41:10.000000000,2014-08-12 19:15:29.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 6094}, {'_account_id': 6491}, {'_account_id': 7860}, {'_account_id': 8871}, {'_account_id': 9416}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12018}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12311}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12499}, {'_account_id': 12641}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-05-27 16:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e5b8a13b2b2b3c6783fb2099af50ba1e5d95db60', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 2, 'created': '2014-05-27 16:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/00fe0327a530a1bede19188da1cddd601f36237e', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 3, 'created': '2014-05-27 17:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/18f23340b168bd53c71f007e1f7a1365d41a132f', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 4, 'created': '2014-05-27 18:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cd9c3f329b29ae2f7ae3d279c014979a6ec126db', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 5, 'created': '2014-05-29 16:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/daa2d7b484df59933fbab7471030f1e95b032023', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 6, 'created': '2014-05-29 16:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/962539e11c868a1fa753b02c59cf4c4e8389be1f', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 7, 'created': '2014-05-30 01:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/09d183542ac993753404fefd76297effb4b04c9b', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\n\nAdd dependence:\n    #92318\n\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 8, 'created': '2014-05-30 01:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d8d4be5cb8d9288e37300f43ae406d10f97498cb', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 9, 'created': '2014-05-30 01:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/90a0d25817af481c2dffc0a5a27267714119b42d', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 10, 'created': '2014-05-30 02:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/17c0c845d988c8a9304677353a0a6b05a94672f7', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 11, 'created': '2014-05-30 02:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/50419b09a66758597695464758625f8867e781ab', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 12, 'created': '2014-05-30 03:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b63c67ea73184efbc91852cf84d258fa5f02aa99', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 13, 'created': '2014-05-30 08:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a38a4a963f6b2b3e083b14c69a59918dafc5b233', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 14, 'created': '2014-05-30 16:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d6e832ea1761f78a45200531db2fc27f86b68886', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 15, 'created': '2014-07-01 11:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/39135c2a97d202806d5d54058c32ef61feec4bce', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 16, 'created': '2014-07-01 11:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/142198821ea352bf1e9ccc8375c4013462ff0766', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 17, 'created': '2014-07-01 11:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f4c6e3085486a753a9aa2825e41e4bda1e84f390', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 18, 'created': '2014-07-01 11:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4a29047779524bc18c890f7e87e519e5133dfb74', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 19, 'created': '2014-07-02 15:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/905bb6b41458ff02a8da6335150ef9a09b0c2640', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 20, 'created': '2014-07-14 01:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/34b4178b7520714885e271a055914d9008c9cdd1', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*Remove roll-back function\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 21, 'created': '2014-07-14 01:49:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0934d10aa170fd2a7913ed057248044fbc7183cb', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*Remove roll-back function\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 22, 'created': '2014-07-14 03:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/633d850a21d008fc667fa12ac173ad39c8786ce1', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 23, 'created': '2014-07-16 08:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7b0b19b39e18279713cb9b801cdc6ebe016b4c45', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 24, 'created': '2014-07-16 09:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/62fc07f0480563f1d49f6268aeab41156faf22e2', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 25, 'created': '2014-07-16 14:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/66c4eba1709f83f6e210ee3e5692fdb1def67b76', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 26, 'created': '2014-07-16 15:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d7d88d601b2e486898161abd79d932a1033caf34', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 27, 'created': '2014-07-16 15:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1ea64506a5d93d89ea927a169bc4479ef85c1012', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 28, 'created': '2014-07-17 02:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/57c152b9e5029b21727af80020d2bdbb0460c19c', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 29, 'created': '2014-07-17 02:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/aa8f735e7145800733ca4f2a4e092f912fbf3462', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 30, 'created': '2014-07-17 03:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1059f549f0fde3e3178d29fcfcc899a85049f9f3', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 31, 'created': '2014-07-17 03:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1d4a0951b529aa84f756e66b999eefd9dada9fd6', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 32, 'created': '2014-07-17 03:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6b6db705c4588bd980de20757348669da9e7f10c', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 33, 'created': '2014-07-18 03:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2f7b16977137573ed8e4bdb2fbc4352820fa0692', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 34, 'created': '2014-07-18 03:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d73ed6924ee8aef6e8d5cffdc5b1cbb07ad54d35', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 35, 'created': '2014-07-19 01:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a3eb867e2ad04a05211d0cfb964a83f1587a1461', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 36, 'created': '2014-07-19 01:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0a4392af3e1ab21a3d29fe1d2f6e9affdc3b9aa2', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 37, 'created': '2014-07-19 02:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8b2a164ac4d270e0aeb95691c69ab218d1aa2d8d', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 38, 'created': '2014-07-19 03:30:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3bffdb77d20414d6c8d655097fe9718c85036c39', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 39, 'created': '2014-07-19 03:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/86576c787513db424f454daf6bde6985f7bc24e1', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 40, 'created': '2014-07-19 15:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cd14b3f8ba9175ee10a7dd90d6b50df8179ec746', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.a5BXW6xt3p\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 41, 'created': '2014-07-21 04:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c9af6fa78e259a5e2735991f0e653725e41bf2ab', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 42, 'created': '2014-07-21 05:30:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/564bca3e5213cd66924dbe0d556ecb3a135f79dd', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 43, 'created': '2014-07-28 05:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/16bd423470005eab0445e723d897638bd3272a34', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 44, 'created': '2014-07-28 07:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/98dec71351aea3cefbb1e284417432895d8c7981', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 45, 'created': '2014-07-28 07:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f2ba7f6a895d04817d90b17a7d008b4108dae694', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 46, 'created': '2014-07-28 09:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4ceed5705e3241d218aee189bbbb6a94b74a5eb9', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 47, 'created': '2014-07-28 09:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dd6c9ce80884b3795fa3255eeb4c1e1adfe4cc3e', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 48, 'created': '2014-07-28 14:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2b71a6ce2daa49ccd1232304ea73676b8a38d821', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 49, 'created': '2014-07-28 15:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d5bd59d4b136acee22994523457183dc1dcc52f', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 50, 'created': '2014-07-28 15:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/aa24f6c6d4a8baebbbc8e7326f218a8112dfb1a0', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 51, 'created': '2014-07-28 15:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/744d6d488c7c8332d9bc7acffd7d276cc2d48ca5', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 52, 'created': '2014-07-28 16:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4824781e6edda6c2195bc54f9a1f3fdb6a121485', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nrecheck prophetstor\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 53, 'created': '2014-07-28 16:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ec8e3b808f0d7d8a75fc3df9be7bbf87750ed1d6', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n\nrecheck prophetstor for CI\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 54, 'created': '2014-07-29 15:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9cf8f243408e7d28e07c02abccd5653affa35780', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n\nrecheck prophetstor for CI\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 55, 'created': '2014-07-29 15:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/90a99109f07add0ef557a35d5459113c6e197df1', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 56, 'created': '2014-07-30 01:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6062f14cd9b712a2e03df8c1151e06691b25557a', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 1\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 57, 'created': '2014-07-30 08:24:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f28696fea773c81254d17770f8d470eeef744335', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 2\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 58, 'created': '2014-07-30 08:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6e4ab58576bc011c8375b61ff0c581e7896a36e4', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 3\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 59, 'created': '2014-07-30 08:58:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7ce108c22254bdfce89f9bcd5728d4ae0d55af65', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 4\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 60, 'created': '2014-07-31 10:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9dff172e22496373c0a9361686bbe0e70a223556', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 4\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 61, 'created': '2014-07-31 10:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/770523adb7159f9b35a91b6a290daf83dc17eeab', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 4\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 62, 'created': '2014-07-31 15:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/113ee4c284d83bf70dbd583201ddd9f95d8314a4', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 4\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 63, 'created': '2014-08-01 04:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5f7046a1267a0ed892127d9df755eef010e2e309', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 5\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 64, 'created': '2014-08-01 07:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9e19966b9bcc2f9bcda3f59aae60e18c9c02e1b3', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 6\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 65, 'created': '2014-08-01 08:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5fdbacfb4b7cc0e5fade6c4367a61c76919a5a05', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 7\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 66, 'created': '2014-08-01 13:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/308d3f2a4d64e8a401ef7a45d6acf4090e8352c5', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 8\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 67, 'created': '2014-08-01 13:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8f7ce968df6833e4f45cdeedb667ace78131dcaf', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 9\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 68, 'created': '2014-08-03 00:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2428edda5b9d010e86e0b3c8b0fbcbbbccfbb37f', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 10\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 69, 'created': '2014-08-04 04:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c202980fd0f938b42bd8c9f43a62db40e8bb0f59', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 11\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 70, 'created': '2014-08-04 04:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1ba9f0034bd0d0cbd4d1c4871cc8e28ab27a7044', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 12\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 71, 'created': '2014-08-04 04:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/904406749d2f7e855a945739092d76bb847d809b', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 13\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 72, 'created': '2014-08-04 09:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/677341e38e36db56fd46eb980fd894175b2ab594', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 14\n*[2014/07/31] Rebase\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 73, 'created': '2014-08-05 04:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a87b27a27ab6d56b5494eb719dcb97917fee9e3f', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 14\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 74, 'created': '2014-08-05 04:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2744d856f0f2240f57efd2e7131c2bdc28c791b5', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 15\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 75, 'created': '2014-08-05 04:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a8761cbac3920b51d90213339326faf3f8fe1dab', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 16\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 76, 'created': '2014-08-05 04:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b43c5401f6d865233cc033469e48143a882f2ac7', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 17\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 77, 'created': '2014-08-05 06:19:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e4e14c7d5804eaf49643749119123861e8100619', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 17\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 78, 'created': '2014-08-05 07:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9483be7bad3ff69be8c5522851a8d1f158ad654d', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 17\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 79, 'created': '2014-08-05 07:20:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9a2493bbf41c9adb23480703a7af0947dc72b850', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 18\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 80, 'created': '2014-08-05 07:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6f47cd15e702555ca0b8e2266ed8eb16c6f3b119', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 18\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 81, 'created': '2014-08-05 07:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3e3f3859db57f9cde70c44a3a2b778b381748653', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 18\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 82, 'created': '2014-08-05 08:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2596f2a5d9e03bcd1c20bd9b5bf2428acf1ee28d', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 18\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 83, 'created': '2014-08-05 09:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fb1baab0d2ebcf39e53e7ea1bbade86554e92dce', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 18\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 84, 'created': '2014-08-05 09:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3699e2ea0b84c221a349914732432f576fa09cc7', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 19\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 85, 'created': '2014-08-05 14:33:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ca5692ee13cfad40f7f95d739b847c035520dcb6', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 20\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 86, 'created': '2014-08-06 03:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/46e20b2ebeeb819446065e894441d556f130e4c4', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 20\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 87, 'created': '2014-08-06 07:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/96171c2bc44071658d52b26ff8823950b07ed8d5', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 21\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 88, 'created': '2014-08-06 07:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/77498fe7aed5eacbb11fff6d96ee0956676164cb', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 22\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 89, 'created': '2014-08-06 08:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d8ebdcb0f8271728cbc5f58ac371734756bd1bc1', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 23\n*[2014/07/31] Rebase\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 90, 'created': '2014-08-06 09:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d582a0cc13228bf792748b96160c9526a89902b9', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 23\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 91, 'created': '2014-08-06 16:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/294b3d1b06a51a85cec1713a28625b2a3d73a8ef', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 24\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: http://download.prophetstor.com/cinder-cert-results/tmp.FLf8UoGtEp\n                     https://launchpadlibrarian.net/181127452/tmp.FLf8UoGtEp\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 92, 'created': '2014-08-11 01:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/320d7be197a9361f04c41e0863ec17f9a04b0153', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 24\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n*[2014/08/11] Rebase and enhance to support thin/thick volume\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: https://bugs.launchpad.net/cinder/+bug/1354066\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 93, 'created': '2014-08-11 02:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cecc9dd3c862eca86cb084ef30a7f9d616ecd0b5', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 24\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n*[2014/08/11] Rebase and enhance to support thin/thick volume\n\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: https://bugs.launchpad.net/cinder/+bug/1354066\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 94, 'created': '2014-08-11 03:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d9203890acebfde2f0fe22f5de06815dd7ffea60', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 25\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n*[2014/08/11] Rebase and enhance to support thin/thick volume\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: https://bugs.launchpad.net/cinder/+bug/1354066\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 95, 'created': '2014-08-11 03:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8a77d1652503c1654c4e9c7c7522f646d832b1ed', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 25\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n*[2014/08/11] Rebase and enhance to support thin/thick volume\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: https://bugs.launchpad.net/cinder/+bug/1354066\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 96, 'created': '2014-08-11 03:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/25067035b893e74ff9a2550f10289d8c93167295', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 25\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n*[2014/08/11] Rebase and enhance to support thin/thick volume\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: https://bugs.launchpad.net/cinder/+bug/1354066\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 97, 'created': '2014-08-11 03:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/394c5d89700b519a3e7a87b29a932d567d95e363', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 26\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n*[2014/08/11] Rebase and enhance to support thin/thick volume\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: https://bugs.launchpad.net/cinder/+bug/1354066\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 98, 'created': '2014-08-11 08:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71024e82d6b5ea4c543278a5e24cd8dbfae089e5', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 26\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n*[2014/08/11] Rebase and enhance to support thin/thick volume\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: https://bugs.launchpad.net/cinder/+bug/1354066\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 99, 'created': '2014-08-11 10:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/83599b3933c285213989c9eec970320888ee69ca', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 27\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n*[2014/08/11] Rebase and enhance to support thin/thick volume\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: https://bugs.launchpad.net/cinder/+bug/1354066\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}, {'number': 100, 'created': '2014-08-12 01:26:50.000000000', 'files': ['cinder/volume/drivers/prophetstor/dplcommon.py', 'etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/prophetstor/dpl_iscsi.py', 'cinder/volume/drivers/prophetstor/__init__.py', 'cinder/tests/test_prophetstor_dpl.py', 'cinder/volume/drivers/prophetstor/dpl_fc.py', 'cinder/volume/drivers/prophetstor/options.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e188dc1c80c2213c7a580021006f042140c30f3b', 'message': 'Add ProphetStor DPL Storage server volume driver for Cinder\n\nProphetStor DPL Storage server enables x86 commodity hardware as\nenterprise-grade storage systems.\n*[2014/07/14] Remove roll-back function.\n*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and\n              terminate_connection.\n              Use mock instead of mox in tests.\n*[2014/07/21] Update cinder volume certification report.\n*[2014/07/29] Openstack continuous integration platform test.\n              Retry: 27\n*[2014/07/31] Rebase\n*[2014/08/06] Refine code\n*[2014/08/11] Rebase and enhance to support thin/thick volume\nImplements: blueprint prophetstor-dpl-driver\ncinder-cert-results: https://bugs.launchpad.net/cinder/+bug/1354066\nChange-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02\n'}]",65,95829,e188dc1c80c2213c7a580021006f042140c30f3b,575,25,100,9416,,,0,"Add ProphetStor DPL Storage server volume driver for Cinder

ProphetStor DPL Storage server enables x86 commodity hardware as
enterprise-grade storage systems.
*[2014/07/14] Remove roll-back function.
*[2014/07/16] Add decorate fiber zone manage utils in initialize_connection and
              terminate_connection.
              Use mock instead of mox in tests.
*[2014/07/21] Update cinder volume certification report.
*[2014/07/29] Openstack continuous integration platform test.
              Retry: 27
*[2014/07/31] Rebase
*[2014/08/06] Refine code
*[2014/08/11] Rebase and enhance to support thin/thick volume
Implements: blueprint prophetstor-dpl-driver
cinder-cert-results: https://bugs.launchpad.net/cinder/+bug/1354066
Change-Id: Iced5e45362aef4286bb7f1c848ab7cb3573b5c02
",git fetch https://review.opendev.org/openstack/cinder refs/changes/29/95829/97 && git format-patch -1 --stdout FETCH_HEAD,['etc/cinder/cinder.conf.sample'],1,e5b8a13b2b2b3c6783fb2099af50ba1e5d95db60,bp/prophetstor-dpl-driver,"#qpid_hostname=cinder#rabbit_host=cinder# Options defined in cinder.volume.drivers.prophetstor.options # # DPL pool uuid in which DPL volumes are stored. (string # value) #dpl_pool= # DPL port number. (integer value) #dpl_port=8357 ## Prefix to prepend at the beginning of the path (string # value)# Host providing the admin Identity API endpoint (string # value)# Port of the admin Identity API endpoint (integer value)# Protocol of the admin Identity API endpoint(http or https) # (string value)# Allows to pass in the name of a fake http_handler callback # function used instead of httplib.HTTPConnection or # httplib.HTTPSConnection. Useful for unit testing where # network is not available. (string value) #http_handler=<None> # If defined, the memcache server(s) to use for caching (list # value)# In order to prevent excessive requests and validations, the # middleware uses an in-memory cache for the tokens the # Keystone API returns. This is only valid if memcache_servers # is defined. Set to -1 to disable caching completely. # (integer value)# Value only used for unit testing (integer value) #revocation_cache_time=1","#qpid_hostname=localhost#rabbit_host=localhost# Prefix to prepend at the beginning of the path. Deprecated, # use identity_uri. (string value)# Host providing the admin Identity API endpoint. Deprecated, # use identity_uri. (string value)# Port of the admin Identity API endpoint. Deprecated, use # identity_uri. (integer value)# Protocol of the admin Identity API endpoint (http or https). # Deprecated, use identity_uri. (string value)# Complete admin Identity API endpoint. This should specify # the unversioned root endpoint eg. https://localhost:35357/ # (string value) #identity_uri=<None> # Optionally specify a list of memcached server(s) to use for # caching. If left undefined, tokens will instead be cached # in-process. (list value)# In order to prevent excessive effort spent validating # tokens, the middleware caches previously-seen tokens for a # configurable duration (in seconds). Set to -1 to disable # caching completely. (integer value)# Determines the frequency at which the list of revoked tokens # is retrieved from the Identity service (in seconds). A high # number of revocation events combined with a low cache # duration may significantly reduce performance. (integer # value) #revocation_cache_time=300",36,28
openstack%2Fpython-heatclient~master~I9c53ce664b164003fe42ed03d1f850d954bf0971,openstack/python-heatclient,master,I9c53ce664b164003fe42ed03d1f850d954bf0971,Add a tox job for generating docs,MERGED,2014-07-24 22:08:01.000000000,2014-08-13 15:24:34.000000000,2014-08-13 15:24:34.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6899}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 9542}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-07-24 22:08:01.000000000', 'files': ['.gitignore', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/e78762152c26e9b010b56aaa66b85aa59b8cd07e', 'message': 'Add a tox job for generating docs\n\nAdd a tox job to make it easier for developers to generate their\nown docs before submitting a patch.\n\nChange-Id: I9c53ce664b164003fe42ed03d1f850d954bf0971\n'}]",2,109433,e78762152c26e9b010b56aaa66b85aa59b8cd07e,15,18,1,6482,,,0,"Add a tox job for generating docs

Add a tox job to make it easier for developers to generate their
own docs before submitting a patch.

Change-Id: I9c53ce664b164003fe42ed03d1f850d954bf0971
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/33/109433/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'tox.ini']",2,e78762152c26e9b010b56aaa66b85aa59b8cd07e,add_docs_to_tox,[testenv:docs] commands= python setup.py build_sphinx ,,5,0
openstack%2Frally~master~I1280f5f3f4cd7415788a3e474dd1852c68a3c35c,openstack/rally,master,I1280f5f3f4cd7415788a3e474dd1852c68a3c35c,Added Sahara Clusters scenario,MERGED,2014-07-25 11:51:51.000000000,2014-08-13 15:20:56.000000000,2014-08-13 15:20:56.000000000,"[{'_account_id': 3}, {'_account_id': 6124}, {'_account_id': 6172}, {'_account_id': 7132}, {'_account_id': 9545}, {'_account_id': 9601}]","[{'number': 1, 'created': '2014-07-25 11:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/26fe40a5787d89e4ca2948d023feee017b85d322', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 2, 'created': '2014-07-25 11:56:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5b389805a1fbec87f06d4ea7882c801154325dcd', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 3, 'created': '2014-07-25 14:08:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/55cf470b8f52f2a9a280f10e3eefd20dbb3e5193', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 4, 'created': '2014-07-29 09:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/72df4277075f62d6d7b1edb50a8e4824b5341ef5', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 5, 'created': '2014-07-29 12:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f9d9151b22de9c3aafd1e459842d196938a0a54c', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 6, 'created': '2014-07-29 14:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/78ad61245088b6141af281454956e27f60d0d9c8', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 7, 'created': '2014-07-30 14:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d117ba203311917b93736580b5e6ce41aa8e54f6', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 8, 'created': '2014-07-30 15:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/556deda7b4bdc5a9371fba6927a031b515ccec0b', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 9, 'created': '2014-07-31 10:43:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/546654e56ee55192f37aab15ca65b8f38d491a22', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 10, 'created': '2014-07-31 11:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cc177615fe8b15323ee456cce02c8320dff247ec', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 11, 'created': '2014-07-31 13:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/63a004e2d539c00708817cfccaad50f4b7ee2b90', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 12, 'created': '2014-08-12 10:18:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b04cfa8d21e3f947c1fc2bb036467503fe3abe04', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}, {'number': 13, 'created': '2014-08-12 11:12:37.000000000', 'files': ['tests/benchmark/scenarios/sahara/test_utils.py', 'etc/rally/rally.conf.sample', 'doc/samples/tasks/scenarios/sahara/create_and_delete_cluster.yaml', 'tests/benchmark/scenarios/sahara/test_clusters.py', 'rally/benchmark/scenarios/sahara/clusters.py', 'rally/benchmark/scenarios/sahara/utils.py', 'doc/samples/tasks/scenarios/sahara/create_and_delete_cluster.json'], 'web_link': 'https://opendev.org/openstack/rally/commit/e2a3e1c941fdc6a71b031d91b073f0356d0fcef6', 'message': 'Added Sahara Clusters scenario\n\nThe scenario creates and deletes a Hadoop cluster.\n\nChange-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c\n'}]",14,109557,e2a3e1c941fdc6a71b031d91b073f0356d0fcef6,62,6,13,7132,,,0,"Added Sahara Clusters scenario

The scenario creates and deletes a Hadoop cluster.

Change-Id: I1280f5f3f4cd7415788a3e474dd1852c68a3c35c
",git fetch https://review.opendev.org/openstack/rally refs/changes/57/109557/13 && git format-patch -1 --stdout FETCH_HEAD,"['doc/samples/tasks/scenarios/sahara/create_and_delete_cluster.yaml', 'rally/benchmark/scenarios/sahara/clusters.py', 'rally/benchmark/scenarios/sahara/utils.py', 'doc/samples/tasks/scenarios/sahara/create_and_delete_cluster.json']",4,26fe40a5787d89e4ca2948d023feee017b85d322,sahara_clusters,"{ ""SaharaCluster.create_and_delete_cluster"": [ { ""args"": { ""flavor_id"": ""2"", ""node_count"": 2, ""plugin_name"": ""vanilla"", ""hadoop_version"": ""2.3.0"" }, ""runner"": { ""type"": ""constant"", ""times"": 4, ""concurrency"": 2 }, ""context"": { ""users"": { ""tenants"": 1, ""users_per_tenant"": 1 }, ""sahara_image"": { ""image_url"": ""http://sahara-files.mirantis.com/sahara-icehouse-vanilla-2.3.0-ubuntu-13.10.qcow2"", ""username"": ""ubuntu"", ""plugin_name"": ""vanilla"", ""hadoop_version"": ""2.3.0"" } } } ] }",,175,0
openstack%2Fnova~master~I0164bf23f4d51505871cee8db170b73534410c4a,openstack/nova,master,I0164bf23f4d51505871cee8db170b73534410c4a,VMware: test_driver_api: Use local variables in closures,MERGED,2014-07-08 13:43:31.000000000,2014-08-13 15:02:55.000000000,2014-08-13 12:41:11.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 7148}, {'_account_id': 8027}, {'_account_id': 8412}, {'_account_id': 8574}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10614}]","[{'number': 1, 'created': '2014-07-08 13:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3bb832222babadc72bbc0884c9164d4d6a12cd70', 'message': 'VMware: test_driver_api: Use local variables in closures\n\nSome closures were unecessarily storing constants used by closures in\nthe test object. This change converts them to use local variables\ninstead. Values which are modified remain in the test object.\n\nAdditionally, 1 unused value is removed.\n\nTrivialFix\n\nChange-Id: I0164bf23f4d51505871cee8db170b73534410c4a\n'}, {'number': 2, 'created': '2014-07-10 08:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f76890c8dcac2c36ca564688b9cf9185394b235', 'message': 'VMware: test_driver_api: Use local variables in closures\n\nSome closures were unecessarily storing constants used by closures in\nthe test object. This change converts them to use local variables\ninstead. Values which are modified remain in the test object.\n\nAdditionally, 1 unused value is removed.\n\nTrivialFix\n\nChange-Id: I0164bf23f4d51505871cee8db170b73534410c4a\n'}, {'number': 3, 'created': '2014-07-14 08:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fd23abdade4dd7a2e4dec0a2cf71dc13da32dcd', 'message': 'VMware: test_driver_api: Use local variables in closures\n\nSome closures were unecessarily storing constants used by closures in\nthe test object. This change converts them to use local variables\ninstead. Values which are modified remain in the test object.\n\nAdditionally, 1 unused value is removed.\n\nTrivialFix\n\nChange-Id: I0164bf23f4d51505871cee8db170b73534410c4a\n'}, {'number': 4, 'created': '2014-07-14 16:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/31dfe27976347717f89fc07c15f75ea78abbccb5', 'message': 'VMware: test_driver_api: Use local variables in closures\n\nSome closures were unecessarily storing constants used by closures in\nthe test object. This change converts them to use local variables\ninstead. Values which are modified remain in the test object.\n\nAdditionally, 1 unused value is removed.\n\nTrivialFix\n\nChange-Id: I0164bf23f4d51505871cee8db170b73534410c4a\n'}, {'number': 5, 'created': '2014-07-17 11:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85fb90840633df4a5f1e5a19092c91663e9da107', 'message': 'VMware: test_driver_api: Use local variables in closures\n\nSome closures were unecessarily storing constants used by closures in\nthe test object. This change converts them to use local variables\ninstead. Values which are modified remain in the test object.\n\nAdditionally, 1 unused value is removed.\n\nTrivialFix\n\nChange-Id: I0164bf23f4d51505871cee8db170b73534410c4a\n'}, {'number': 6, 'created': '2014-07-28 22:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a026d266a5b11b16858ddb93245deeba6a8a8a7d', 'message': 'VMware: test_driver_api: Use local variables in closures\n\nSome closures were unecessarily storing constants used by closures in\nthe test object. This change converts them to use local variables\ninstead. Values which are modified remain in the test object.\n\nAdditionally, 1 unused value is removed.\n\nTrivialFix\n\nChange-Id: I0164bf23f4d51505871cee8db170b73534410c4a\n'}, {'number': 7, 'created': '2014-08-04 13:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d79bcf06187b878da0f3236333077b99fb7123d1', 'message': 'VMware: test_driver_api: Use local variables in closures\n\nSome closures were unecessarily storing constants used by closures in\nthe test object. This change converts them to use local variables\ninstead. Values which are modified remain in the test object.\n\nAdditionally, 1 unused value is removed.\n\nTrivialFix\n\nChange-Id: I0164bf23f4d51505871cee8db170b73534410c4a\n'}, {'number': 8, 'created': '2014-08-07 13:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a4c10bac266ac3788eb8c99be95f7c03615ae19', 'message': 'VMware: test_driver_api: Use local variables in closures\n\nSome closures were unecessarily storing constants used by closures in\nthe test object. This change converts them to use local variables\ninstead. Values which are modified remain in the test object.\n\nAdditionally, 1 unused value is removed.\n\nTrivialFix\n\nChange-Id: I0164bf23f4d51505871cee8db170b73534410c4a\n'}, {'number': 9, 'created': '2014-08-08 13:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39dbe01318d535348a9e259686f2b461c3ae5b9d', 'message': 'VMware: test_driver_api: Use local variables in closures\n\nSome closures were unecessarily storing constants used by closures in\nthe test object. This change converts them to use local variables\ninstead. Values which are modified remain in the test object.\n\nAdditionally, 1 unused value is removed.\n\nTrivialFix\n\nChange-Id: I0164bf23f4d51505871cee8db170b73534410c4a\n'}, {'number': 10, 'created': '2014-08-08 17:26:05.000000000', 'files': ['nova/tests/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a55e87d5b4517106fcea22b7642b9690cde78b47', 'message': 'VMware: test_driver_api: Use local variables in closures\n\nSome closures were unecessarily storing constants used by closures in\nthe test object. This change converts them to use local variables\ninstead. Values which are modified remain in the test object.\n\nAdditionally, 1 unused value is removed.\n\nTrivialFix\n\nChange-Id: I0164bf23f4d51505871cee8db170b73534410c4a\n'}]",2,105454,a55e87d5b4517106fcea22b7642b9690cde78b47,113,18,10,9555,,,0,"VMware: test_driver_api: Use local variables in closures

Some closures were unecessarily storing constants used by closures in
the test object. This change converts them to use local variables
instead. Values which are modified remain in the test object.

Additionally, 1 unused value is removed.

TrivialFix

Change-Id: I0164bf23f4d51505871cee8db170b73534410c4a
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/105454/10 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/vmwareapi/test_driver_api.py'],1,3bb832222babadc72bbc0884c9164d4d6a12cd70,bp/vmware-spawn-refactor," iso_path = ds_util.DatastorePath(self.ds, 'vmware_base', self.fake_image_uuid, '%s.iso' % self.fake_image_uuid) self.assertEqual(iso_uploaded_path, str(iso_path)) iso_path = [ self.assertEqual(iso_uploaded_path, str(iso_path[self.iso_index])) iso_path = ds_util.DatastorePath(self.ds, 'fake-config-drive') self.assertEqual(iso_uploaded_path, str(iso_path)) vmwareapi_fake._add_file(str(root))"," self.iso_path = ds_util.DatastorePath(self.ds, 'vmware_base', self.fake_image_uuid, '%s.iso' % self.fake_image_uuid) self.assertEqual(iso_uploaded_path, str(self.iso_path)) self.iso_path = [ self.iso_unit_nos = [0, 1] self.assertEqual(iso_uploaded_path, str(self.iso_path[self.iso_index])) self.iso_path = ds_util.DatastorePath(self.ds, 'fake-config-drive') self.assertEqual(iso_uploaded_path, str(self.iso_path)) self.root = root vmwareapi_fake._add_file(str(self.root))",9,12
openstack%2Fironic~master~Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296,openstack/ironic,master,Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296,Mechanism to cleanup all ImageCaches,MERGED,2014-07-30 07:36:33.000000000,2014-08-13 14:38:41.000000000,2014-08-13 14:38:41.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 9315}, {'_account_id': 10239}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-07-30 07:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9ec08d93979f749de548c99ee0ff9d3b395afb11', 'message': 'Move code to cleanup ImageCache to a common place\n\nThis commit moves the cleanup code of ImageCache to a\ncommon place in image_cache.py so that it can be accessed\nfrom anywhere in the ironic source tree outside pxe driver.\n\nChange-Id: Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296\n'}, {'number': 2, 'created': '2014-07-31 09:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/363fd4aa51bb2799c6d4ee185176c22e3e5814b8', 'message': 'Move code to cleanup ImageCache to a common place\n\nThis commit moves the cleanup code of ImageCache to a\ncommon place in image_cache.py so that it can be accessed\nfrom anywhere in the ironic source tree outside pxe driver.\n\nImplements: blueprint cleanup-all-imagecaches\nChange-Id: Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296\n'}, {'number': 3, 'created': '2014-08-06 10:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/400214822a294ec4dfa6f9d39a4e30eef94aa997', 'message': 'Move code to cleanup ImageCache to a common place\n\nThis commit moves the cleanup code of ImageCache to a\ncommon place in image_cache.py so that it can be accessed\nfrom anywhere in the ironic source tree outside pxe driver.\n\nIt also introduces a new decorator @image_cache.cleanup()\nfor subclasses of ImageCache which wishes to be cleaned up.\nThis also has provision for providing a priority for the order\nof cleanup.\n\nImplements: blueprint cleanup-all-imagecaches\nChange-Id: Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296\n'}, {'number': 4, 'created': '2014-08-07 07:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/425705ed12079ab521f6504f0453c8985da60b4d', 'message': 'Move code to cleanup ImageCache to a common place\n\nThis commit moves the cleanup code of ImageCache to a\ncommon place in image_cache.py so that it can be accessed\nfrom anywhere in the ironic source tree outside pxe driver.\n\nIt also introduces a new decorator @image_cache.cleanup()\nfor subclasses of ImageCache which wishes to be cleaned up.\nThis also has provision for providing a priority for the order\nof cleanup.\n\nImplements: blueprint cleanup-all-imagecaches\nChange-Id: Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296\n'}, {'number': 5, 'created': '2014-08-11 10:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d7d08e619ee2c495d2fad76706f21bd4e1e7a857', 'message': 'Move code to cleanup ImageCache to a common place\n\nThis commit moves the cleanup code of ImageCache to a\ncommon place in image_cache.py so that it can be accessed\nfrom anywhere in the ironic source tree outside pxe driver.\n\nIt also introduces a new decorator @image_cache.cleanup()\nfor subclasses of ImageCache which wishes to be cleaned up.\nThis also has provision for providing a priority for the order\nof cleanup.\n\nImplements: blueprint cleanup-all-imagecaches\nChange-Id: Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296\n'}, {'number': 6, 'created': '2014-08-11 17:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/12a088512098652ec862543fdf4a36d356bda583', 'message': 'Move code to cleanup ImageCache to a common place\n\nThis commit moves the cleanup code of ImageCache to a\ncommon place in image_cache.py so that it can be accessed\nfrom anywhere in the ironic source tree outside pxe driver.\n\nIt also introduces a new decorator @image_cache.cleanup()\nfor subclasses of ImageCache which wishes to be cleaned up.\nThis also has provision for providing a priority for the order\nof cleanup.\n\nImplements: blueprint cleanup-all-imagecaches\nChange-Id: Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296\n'}, {'number': 7, 'created': '2014-08-12 13:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/dbd8e350b6c87a02d401a016674423ff9619e3bb', 'message': 'Move code to cleanup ImageCache to a common place\n\nThis commit moves the cleanup code of ImageCache to a\ncommon place in image_cache.py so that it can be accessed\nfrom anywhere in the ironic source tree outside pxe driver.\n\nIt also introduces a new decorator @image_cache.cleanup()\nfor subclasses of ImageCache which wishes to be cleaned up.\nThis also has provision for providing a priority for the order\nof cleanup.\n\nImplements: blueprint cleanup-all-imagecaches\nChange-Id: Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296\n'}, {'number': 8, 'created': '2014-08-13 04:04:59.000000000', 'files': ['ironic/drivers/modules/image_cache.py', 'ironic/drivers/modules/agent.py', 'ironic/common/exception.py', 'ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_image_cache.py', 'ironic/tests/drivers/test_pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1d522cc6a0c5a88d68e2e05781262b50c080047e', 'message': 'Mechanism to cleanup all ImageCaches\n\nThis commit moves the cleanup code of ImageCache to a\ncommon place in image_cache.py so that it can be accessed\nfrom anywhere in the ironic source tree outside pxe driver.\n\nIt also introduces a new decorator @image_cache.cleanup()\nfor subclasses of ImageCache which wishes to be cleaned up.\nThis also has provision for providing a priority for the order\nof cleanup.\n\nImplements: blueprint cleanup-all-imagecaches\nChange-Id: Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296\n'}]",60,110560,1d522cc6a0c5a88d68e2e05781262b50c080047e,56,5,8,9315,,,0,"Mechanism to cleanup all ImageCaches

This commit moves the cleanup code of ImageCache to a
common place in image_cache.py so that it can be accessed
from anywhere in the ironic source tree outside pxe driver.

It also introduces a new decorator @image_cache.cleanup()
for subclasses of ImageCache which wishes to be cleaned up.
This also has provision for providing a priority for the order
of cleanup.

Implements: blueprint cleanup-all-imagecaches
Change-Id: Idb54cee6cc1eee4f52ff07f8ca6e1f83378b2296
",git fetch https://review.opendev.org/openstack/ironic refs/changes/60/110560/8 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/image_cache.py', 'ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_image_cache.py', 'ironic/tests/drivers/test_pxe.py']",4,9ec08d93979f749de548c99ee0ff9d3b395afb11,bp/cleanup-all-imagecaches,"from ironic.drivers.modules import image_cache@mock.patch.object(image_cache, '_get_global_caches_to_cleanup') def setUp(self): super(PXEPrivateFetchImagesTestCase, self).setUp() self.mock_instance_cache = mock.MagicMock(use_for_global_cleanup=True) self.mock_tftp_cache = mock.MagicMock(use_for_global_cleanup=True) self.global_caches = [self.mock_instance_cache.return_value, self.mock_tftp_cache.return_value] self.mock_instance_cache.return_value.master_dir = 'instance_dir' self.mock_tftp_cache.return_value.master_dir = 'tftp_dir' get_caches_mock): get_caches_mock.return_value = self.global_caches self.assertFalse(self.mock_instance_cache.return_value.clean_up.called) self.assertFalse(self.mock_tftp_cache.return_value.clean_up.called) get_caches_mock): get_caches_mock.return_value = self.global_caches self.mock_instance_cache.return_value.clean_up.assert_called_once_with( self.assertFalse(self.mock_tftp_cache.return_value.clean_up.called) mock_statvfs, get_caches_mock): get_caches_mock.return_value = self.global_caches self.mock_tftp_cache.return_value.clean_up.assert_called_once_with( self.assertFalse(self.mock_instance_cache.return_value.clean_up.called) get_caches_mock): get_caches_mock.return_value = self.global_caches self.mock_instance_cache.return_value.clean_up.assert_called_once_with( self.mock_tftp_cache.return_value.clean_up.assert_called_once_with( get_caches_mock): get_caches_mock.return_value = self.global_caches self.mock_instance_cache.return_value.clean_up.assert_called_once_with( self.mock_tftp_cache.return_value.clean_up.assert_called_once_with(","@mock.patch.object(pxe, 'TFTPImageCache') @mock.patch.object(pxe, 'InstanceImageCache') mock_instance_cache, mock_tftp_cache): self.assertFalse(mock_instance_cache.return_value.clean_up.called) self.assertFalse(mock_tftp_cache.return_value.clean_up.called) mock_instance_cache, mock_tftp_cache): mock_instance_cache.return_value.clean_up.assert_called_once_with( self.assertFalse(mock_tftp_cache.return_value.clean_up.called) mock_statvfs, mock_instance_cache, mock_tftp_cache): mock_tftp_cache.return_value.clean_up.assert_called_once_with( self.assertFalse(mock_instance_cache.return_value.clean_up.called) mock_instance_cache, mock_tftp_cache): mock_instance_cache.return_value.clean_up.assert_called_once_with( mock_tftp_cache.return_value.clean_up.assert_called_once_with( mock_instance_cache, mock_tftp_cache): mock_instance_cache.return_value.clean_up.assert_called_once_with( mock_tftp_cache.return_value.clean_up.assert_called_once_with(",135,59
openstack%2Fdesignate~master~Id8205c4f329afa6e448d8259f734bb730388b415,openstack/designate,master,Id8205c4f329afa6e448d8259f734bb730388b415,Validate that no parent zones are created in another tenant,MERGED,2014-07-22 18:19:32.000000000,2014-08-13 14:36:44.000000000,2014-08-13 14:36:43.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}, {'_account_id': 11626}]","[{'number': 1, 'created': '2014-07-22 18:19:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/af883a8d90955e510644cff15496b91a004f7f77', 'message': 'WIP: Validate that no parent zones are created in another tenant\n\nChange-Id: Id8205c4f329afa6e448d8259f734bb730388b415\nImplements: blueprint subzone-validation\n'}, {'number': 2, 'created': '2014-07-24 14:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e6a721ff29239374cb2f6ad24c4ac7b92adae52b', 'message': 'WIP: Validate that no parent zones are created in another tenant\n\nChange-Id: Id8205c4f329afa6e448d8259f734bb730388b415\nImplements: blueprint subzone-validation\n'}, {'number': 3, 'created': '2014-07-24 14:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/f2e4dc3f2ee0a2bd63779d83bb1fd753bfef90a7', 'message': 'WIP: Validate that no parent zones are created in another tenant\n\nChange-Id: Id8205c4f329afa6e448d8259f734bb730388b415\nImplements: blueprint subzone-validation\n'}, {'number': 4, 'created': '2014-08-13 11:55:28.000000000', 'files': ['designate/central/service.py', 'designate/tests/test_central/test_service.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/4986d62aabdea454d94f6fafa6995669e4751fa7', 'message': 'Validate that no parent zones are created in another tenant\n\nChange-Id: Id8205c4f329afa6e448d8259f734bb730388b415\nImplements: blueprint subzone-validation\n'}]",0,108791,4986d62aabdea454d94f6fafa6995669e4751fa7,23,4,4,11626,,,0,"Validate that no parent zones are created in another tenant

Change-Id: Id8205c4f329afa6e448d8259f734bb730388b415
Implements: blueprint subzone-validation
",git fetch https://review.opendev.org/openstack/designate refs/changes/91/108791/2 && git format-patch -1 --stdout FETCH_HEAD,"['designate/central/service.py', 'designate/tests/test_central/test_service.py']",2,af883a8d90955e510644cff15496b91a004f7f77,bp/subzone-validation,"import copy def test_is_superdomain(self): context = self.get_context() # Create a domain (using the specified domain name) self.create_domain(name='example.org.') LOG.debug(""Testing 'org.'"") result = self.central_service._is_superdomain(context, 'org.') self.assertTrue(result) LOG.debug(""Testing 'www.example.net.'"") result = self.central_service._is_superdomain(context, 'www.example.net.') self.assertFalse(result) LOG.debug(""Testing 'example.org.'"") result = self.central_service._is_superdomain(context, 'example.org.') self.assertTrue(result) LOG.debug(""Testing 'www.example.org.'"") result = self.central_service._is_superdomain(context, 'www.example.org.') self.assertFalse(result) def test_create_superdomain(self): # Prepare values for the domain and subdomain # using fixture 1 as a base domain_values = self.get_domain_fixture(1) subdomain_values = copy.deepcopy(domain_values) subdomain_values['name'] = 'www.%s' % domain_values['name'] subdomain_values['context'] = self.admin_context LOG.debug(""domain_values: {0}"".format(domain_values)) LOG.debug(""subdomain_values: {0}"".format(subdomain_values)) # Create the subdomain subdomain = self.create_domain(**subdomain_values) # Create the Parent Domain using fixture 1 parent_domain = self.central_service.create_domain( self.admin_context, domain=objects.Domain(**domain_values) ) subdomain = self.central_service.get_domain(self.admin_context, subdomain.id) # Ensure all values have been set correctly self.assertIsNotNone(parent_domain['id']) self.assertEqual(subdomain['parent_domain_id'], parent_domain['id']) def test_create_superdomain_failure(self): context = self.get_admin_context() # Explicitly set a tenant_id context.tenant = '1' # Set up domain and subdomain values domain_values = self.get_domain_fixture(1) domain_name = domain_values['name'] subdomain_values = copy.deepcopy(domain_values) subdomain_values['name'] = 'www.%s' % domain_name subdomain_values['context'] = context # Create sub domain self.create_domain(**subdomain_values) context = self.get_admin_context() # Explicitly use a different tenant_id context.tenant = '2' # Attempt to create the domain with testtools.ExpectedException(exceptions.Forbidden): self.central_service.create_domain( context, domain=objects.Domain(**domain_values)) ",,124,2
openstack%2Foslo.rootwrap~master~Ic71f63fb0fab0470e4732099bb8ab5c13dd98538,openstack/oslo.rootwrap,master,Ic71f63fb0fab0470e4732099bb8ab5c13dd98538,Move test requirement coverage into tox.ini,MERGED,2014-07-21 11:30:36.000000000,2014-08-13 14:29:57.000000000,2014-08-13 14:29:56.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-07-21 11:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/18d3bbd576a5709690b58c4b11c86833c6ec1675', 'message': 'Move test requirement coverage into tox.ini\n\nLike commented in the test-requirements.ini file the test requirement\ncoverage can be moved into the tox.ini file when tox>=1.4 is required.\nThe minimum version at the moment is 1.6.\n\nChange-Id: Ic71f63fb0fab0470e4732099bb8ab5c13dd98538\n'}, {'number': 2, 'created': '2014-07-21 11:32:02.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/1ae4684f495837449c12bb032f8c9403dd19b03a', 'message': 'Move test requirement coverage into tox.ini\n\nLike commented in the test-requirements.ini file the test requirement\ncoverage can be moved into the tox.ini file when tox>=1.4 is required.\nThe minimum version at the moment is 1.6.\n\nChange-Id: Ic71f63fb0fab0470e4732099bb8ab5c13dd98538\n'}]",0,108345,1ae4684f495837449c12bb032f8c9403dd19b03a,14,3,2,167,,,0,"Move test requirement coverage into tox.ini

Like commented in the test-requirements.ini file the test requirement
coverage can be moved into the tox.ini file when tox>=1.4 is required.
The minimum version at the moment is 1.6.

Change-Id: Ic71f63fb0fab0470e4732099bb8ab5c13dd98538
",git fetch https://review.opendev.org/openstack/oslo.rootwrap refs/changes/45/108345/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,18d3bbd576a5709690b58c4b11c86833c6ec1675,move_coverage_requirement,deps = {[testenv]deps} coverage ,,3,5
openstack%2Fironic~master~Ia5ce05e30b3fb00261854857aeef46238a8b00f8,openstack/ironic,master,Ia5ce05e30b3fb00261854857aeef46238a8b00f8,Raise MissingParameterValue instead of Invalid,MERGED,2014-07-21 18:07:10.000000000,2014-08-13 14:19:45.000000000,2014-08-13 14:19:44.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 7763}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 10239}, {'_account_id': 11424}]","[{'number': 1, 'created': '2014-07-21 18:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7114152f5f85ecbf4197c8f59e36a7f9a424be63', 'message': 'Raise MissingParameterValue instead of invalid\n\nThe function _check_for_missing_params was raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 2, 'created': '2014-07-22 15:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ef0402fdace377631fd96dff08eb0e66b376211d', 'message': 'Raise MissingParameterValue instead of invalid\n\nThe function _check_for_missing_params was raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 3, 'created': '2014-07-22 22:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2231d42e09f6dda12e8d8d915179abfe22d56ee2', 'message': 'Raise MissingParameterValue instead of invalid\n\nThe function _check_for_missing_params was raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 4, 'created': '2014-07-23 12:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/251756f6732d1837d2643d6d82ba3e4bf6ee3c7b', 'message': 'Raise MissingParameterValue instead of invalid\n\nThe function _check_for_missing_params was raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 5, 'created': '2014-07-23 16:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7f811b61a6147b94bd4ace2ceb5a6928fe27f1c0', 'message': 'Raise MissingParameterValue instead of invalid\n\nThe function _check_for_missing_params was raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 6, 'created': '2014-07-28 22:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/458931d76d0d389696c83fd7d72f74761d158307', 'message': 'Raise MissingParameterValue instead of invalid\n\nThe function _check_for_missing_params was raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 7, 'created': '2014-07-29 09:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/248a005b7cafba02aa686939fe800779be95d2fd', 'message': 'Raise MissingParameterValue instead of invalid\n\nThe function _check_for_missing_params was raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 8, 'created': '2014-07-29 11:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f1fdade2f496099cf0df7fbd835eb506a68a72bb', 'message': 'Raise MissingParameterValue instead of invalid\n\nThe function _check_for_missing_params was raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 9, 'created': '2014-07-29 22:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c50057d3436f14ee6721e9aa30ea57ed3e2b75bf', 'message': 'Raise MissingParameterValue instead of Invalid\n\nThere are several functions that were raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 10, 'created': '2014-08-07 06:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ae5d2623c5e63eb021487882d5354bdc178369dd', 'message': 'Raise MissingParameterValue instead of Invalid\n\nThere are several functions that were raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 11, 'created': '2014-08-12 07:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bdbf9aac3d702a4e62f47a1635b0d6fc05413ec8', 'message': 'Raise MissingParameterValue instead of Invalid\n\nThere are several functions that were raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 12, 'created': '2014-08-12 11:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1d1e3beb85e6149704316512040adf8d3923c5a2', 'message': 'Raise MissingParameterValue instead of Invalid\n\nThere are several functions that were raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}, {'number': 13, 'created': '2014-08-12 21:22:31.000000000', 'files': ['ironic/api/controllers/v1/port.py', 'ironic/drivers/utils.py', 'ironic/tests/drivers/test_ipmitool.py', 'ironic/tests/drivers/test_ssh.py', 'ironic/tests/drivers/ilo/test_common.py', 'ironic/drivers/base.py', 'ironic/tests/drivers/test_ipminative.py', 'ironic/tests/drivers/test_seamicro.py', 'ironic/tests/drivers/test_pxe.py', 'ironic/conductor/rpcapi.py', 'ironic/common/exception.py', 'ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py', 'ironic/drivers/modules/ilo/common.py', 'ironic/drivers/modules/pxe.py', 'ironic/drivers/modules/seamicro.py', 'ironic/drivers/modules/ssh.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py', 'ironic/drivers/modules/fake.py', 'ironic/tests/conductor/test_conductor_utils.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/3419b38b1128a44147733b3ff003cdf0f61bebc6', 'message': 'Raise MissingParameterValue instead of Invalid\n\nThere are several functions that were raising InvalidParameterValue,\nwhen it should be a MissingParamenteValue. This way we can differentiate\nboth exceptions when needed.\n\nChange-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8\n'}]",76,108455,3419b38b1128a44147733b3ff003cdf0f61bebc6,108,12,13,1726,,,0,"Raise MissingParameterValue instead of Invalid

There are several functions that were raising InvalidParameterValue,
when it should be a MissingParamenteValue. This way we can differentiate
both exceptions when needed.

Change-Id: Ia5ce05e30b3fb00261854857aeef46238a8b00f8
",git fetch https://review.opendev.org/openstack/ironic refs/changes/55/108455/5 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/exception.py', 'ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_pxe.py']",3,7114152f5f85ecbf4197c8f59e36a7f9a424be63,missing_parameter_value," self.assertRaises(exception.MissingParameterValue, self.assertRaises(exception.MissingParameterValue, self.assertRaises(exception.MissingParameterValue, self.assertRaises(exception.MissingParameterValue, self.assertRaises(exception.MissingParameterValue,"," self.assertRaises(exception.InvalidParameterValue, self.assertRaises(exception.InvalidParameterValue, self.assertRaises(exception.InvalidParameterValue, self.assertRaises(exception.InvalidParameterValue, self.assertRaises(exception.InvalidParameterValue,",10,6
openstack%2Frally~master~Iee36e17774310669bda49de18d97bd8286397f6c,openstack/rally,master,Iee36e17774310669bda49de18d97bd8286397f6c,add server_ready to support check network status ready,ABANDONED,2014-04-14 18:18:48.000000000,2014-08-13 14:17:12.000000000,,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6835}, {'_account_id': 8336}, {'_account_id': 10165}]","[{'number': 1, 'created': '2014-04-14 18:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/12f90a440f510d3475f5923e6f2c24c25791f43d', 'message': 'add scenario: boot_server_and_fetch_ip\n\nThis scenario could be used to verify booting lots of instances with\ncorrect network/IP. The result of this scenario could descibe how well\nNeutron works.\n\nChange-Id: Iee36e17774310669bda49de18d97bd8286397f6c\n'}, {'number': 2, 'created': '2014-04-15 15:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1636b257c84fa63ad3f6b695cd33b39f466581b7', 'message': 'add server_ready to support check network status ready\n\nThis new is_ready method could help checking netowkr status when\ninstance booted with nics argument. Instance is ready only when the\nstatus is ACTIVE and has correct networks (server would get N IPs if\nthere are N nics in request).\n\nChange-Id: Iee36e17774310669bda49de18d97bd8286397f6c\n'}, {'number': 3, 'created': '2014-04-16 03:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4f1bc34133730f0d8c04ee176c6693434305e314', 'message': 'add server_ready to support check network status ready\n\nThis new is_ready method could help checking network status when\ninstance booted with nics argument. Instance is ready only when the\nstatus is ACTIVE and has correct networks (server would get N IPs if\nthere are N nics in request).\n\nChange-Id: Iee36e17774310669bda49de18d97bd8286397f6c\n'}, {'number': 4, 'created': '2014-04-16 04:15:56.000000000', 'files': ['rally/benchmark/scenarios/nova/utils.py', 'tests/benchmark/scenarios/nova/test_utils.py', 'rally/benchmark/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/275328b8cc02f83166831475011e726159b98f95', 'message': 'add server_ready to support check network status ready\n\nThis new is_ready method could help checking network status when\ninstance booted with nics argument. Instance is ready only when the\nstatus is ACTIVE and has correct networks (server would get N IPs if\nthere are N nics in request).\n\nChange-Id: Iee36e17774310669bda49de18d97bd8286397f6c\n'}]",5,87347,275328b8cc02f83166831475011e726159b98f95,27,5,4,6835,,,0,"add server_ready to support check network status ready

This new is_ready method could help checking network status when
instance booted with nics argument. Instance is ready only when the
status is ACTIVE and has correct networks (server would get N IPs if
there are N nics in request).

Change-Id: Iee36e17774310669bda49de18d97bd8286397f6c
",git fetch https://review.opendev.org/openstack/rally refs/changes/47/87347/4 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/validation.py', 'doc/samples/tasks/nova/boot_server_and_fetch_ip.yaml', 'rally/benchmark/scenarios/nova/servers.py', 'doc/samples/tasks/nova/boot_server_and_fetch_ip.json']",4,12f90a440f510d3475f5923e6f2c24c25791f43d,master,"{ ""NovaServers.boot_server"": [ { ""args"": { ""flavor_id"": 1, ""image_id"": ""73257560-c59b-4275-a1ec-ab140e5b9979"", ""nics"": [""<network-id> 1"", ""<network-id> 2""] }, ""runner"": { ""type"": ""continuous"", ""times"": 10, ""active_users"": 2 }, ""context"": { ""users"": { ""tenants"": 3, ""users_per_tenant"": 2 } } } ] } ",,66,0
openstack%2Fopenstacksdk~master~Ib6ed56db495e23ba6878c112cdcb02359b6e7398,openstack/openstacksdk,master,Ib6ed56db495e23ba6878c112cdcb02359b6e7398,Add support for Swift containers,MERGED,2014-08-04 19:25:35.000000000,2014-08-13 14:12:31.000000000,2014-08-13 14:12:30.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-04 19:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6b5b5b715ffd3a9b8126c2c8db81402c0d5632af', 'message': 'Add support for Swift accounts and containers\n\nCan GET/HEAD for account and container details. No support for objects\nat the moment.\n\nChange-Id: Ib6ed56db495e23ba6878c112cdcb02359b6e7398\n'}, {'number': 2, 'created': '2014-08-08 17:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0c52274a2752dea9f9302fa3ab7f2a545d93b1c5', 'message': 'Add support for Swift accounts and containers\n\nCan GET/HEAD for account and container details. No support for objects\nat the moment.\n\nChange-Id: Ib6ed56db495e23ba6878c112cdcb02359b6e7398\n'}, {'number': 3, 'created': '2014-08-13 14:00:15.000000000', 'files': ['openstack/tests/object_store/test_object_store_service.py', 'openstack/object_store/v1/__init__.py', 'openstack/tests/object_store/v1/test_container.py', 'openstack/object_store/__init__.py', 'openstack/tests/object_store/__init__.py', 'openstack/object_store/v1/container.py', 'openstack/tests/object_store/v1/__init__.py', 'openstack/object_store/object_store_service.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e8b06b5c9c9f657075e409ec0412d7e6ae6550f1', 'message': 'Add support for Swift containers\n\nCan GET/HEAD for account and container details. No support for objects\nat the moment.\n\nChange-Id: Ib6ed56db495e23ba6878c112cdcb02359b6e7398\n'}]",5,111807,e8b06b5c9c9f657075e409ec0412d7e6ae6550f1,21,3,3,8257,,,0,"Add support for Swift containers

Can GET/HEAD for account and container details. No support for objects
at the moment.

Change-Id: Ib6ed56db495e23ba6878c112cdcb02359b6e7398
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/07/111807/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/object_store/test_object_store_service.py', 'openstack/tests/test_resource.py', 'examples/swift_list.py', 'openstack/object_store/__init__.py', 'openstack/object_store/v1/container.py', 'openstack/tests/object_store/v1/__init__.py', 'openstack/object_store/object_store_service.py', 'openstack/object_store/v1/__init__.py', 'openstack/tests/object_store/v1/test_container.py', 'openstack/resource.py', 'openstack/tests/object_store/__init__.py', 'openstack/object_store/v1/account.py', 'openstack/tests/object_store/v1/test_account.py']",13,6b5b5b715ffd3a9b8126c2c8db81402c0d5632af,swift_containers,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testtools from openstack.object_store.v1 import account # Note: id actually comes in as x-trans-id in headers, but is converted to id # to match how that value appears in response bodies. EXAMPLE = { 'content-length': '0', 'accept-ranges': 'bytes', 'x-timestamp': '1403312946.78273', 'id': 'tx4272aa0d6e1e4f8f971f8-0053b84f54', 'date': 'Sat, 05 Jul 2014 19:17:40 GMT', 'x-account-bytes-used': '12345', 'x-account-container-count': '678', 'content-type': 'text/plain; charset=utf-8', 'x-account-object-count': '98765' } class TestAccount(testtools.TestCase): def test_repr(self): sot = account.Account(EXAMPLE) result = repr(sot) self.assertEqual(result, ""bytes_used: 12345, containers: 678, objects: 98765"") def test_basic(self): sot = account.Account() self.assertIsNone(sot.resources_key) self.assertEqual('/', sot.base_path) self.assertEqual('object-store', sot.service.service_type) self.assertTrue(sot.allow_create) self.assertTrue(sot.allow_head) self.assertFalse(sot.allow_retrieve) self.assertFalse(sot.allow_update) self.assertFalse(sot.allow_delete) self.assertFalse(sot.allow_list) def test_make_it(self): sot = account.Account(EXAMPLE) self.assertIsNone(sot.id) self.assertEqual(EXAMPLE['x-timestamp'], sot.timestamp) self.assertEqual(EXAMPLE['x-account-bytes-used'], sot.bytes_used) self.assertEqual(EXAMPLE['x-account-container-count'], sot.container_count) self.assertEqual(EXAMPLE['x-account-object-count'], sot.object_count) ",,366,3
openstack%2Foslo.messaging~master~I1562330af99553b4322f7dc062b310cc4ef93ccf,openstack/oslo.messaging,master,I1562330af99553b4322f7dc062b310cc4ef93ccf,Enable PEP8 check E714,MERGED,2014-07-23 19:07:23.000000000,2014-08-13 14:11:30.000000000,2014-08-13 14:11:29.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1994}, {'_account_id': 5638}, {'_account_id': 7763}]","[{'number': 1, 'created': '2014-07-23 19:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/058ee2cca5443c2acb8557896dd251d27adc498e', 'message': 'Enable PEP8 check E714\n\nChange-Id: I1562330af99553b4322f7dc062b310cc4ef93ccf\n'}, {'number': 2, 'created': '2014-08-04 12:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/bb1ae46c79cc93452928266b631c9cf1bdb50ff6', 'message': 'Enable PEP8 check E714\n\nChange-Id: I1562330af99553b4322f7dc062b310cc4ef93ccf\n'}, {'number': 3, 'created': '2014-08-08 06:07:17.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/dd1d6d12ed8436bd9464bdce4d4a368ec17043c6', 'message': 'Enable PEP8 check E714\n\nChange-Id: I1562330af99553b4322f7dc062b310cc4ef93ccf\n'}]",0,109080,dd1d6d12ed8436bd9464bdce4d4a368ec17043c6,18,5,3,167,,,0,"Enable PEP8 check E714

Change-Id: I1562330af99553b4322f7dc062b310cc4ef93ccf
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/80/109080/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,058ee2cca5443c2acb8557896dd251d27adc498e,enable_e714,"ignore = H237,H402,H405,H904","ignore = E714,H237,H402,H405,H904",1,1
openstack%2Foslo.messaging~master~Idf41d967fb06a063d02c19987733ba3757aa466f,openstack/oslo.messaging,master,Idf41d967fb06a063d02c19987733ba3757aa466f,Enable PEP8 check E265,MERGED,2014-07-23 19:05:11.000000000,2014-08-13 14:11:28.000000000,2014-08-13 14:11:28.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1994}, {'_account_id': 5638}, {'_account_id': 7763}]","[{'number': 1, 'created': '2014-07-23 19:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b2b5a23a67175066f292784b3e986545b8c1e46f', 'message': 'Enable PEP8 check E265\n\nChange-Id: Idf41d967fb06a063d02c19987733ba3757aa466f\n'}, {'number': 2, 'created': '2014-08-04 12:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/06a73d322a9d9e7b13bb1d9b132a6f4f4548b84b', 'message': 'Enable PEP8 check E265\n\nChange-Id: Idf41d967fb06a063d02c19987733ba3757aa466f\n'}, {'number': 3, 'created': '2014-08-08 06:07:09.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ec9ffdb979ab1c0ff36853e6a1c35c38fef793e4', 'message': 'Enable PEP8 check E265\n\nChange-Id: Idf41d967fb06a063d02c19987733ba3757aa466f\n'}]",0,109079,ec9ffdb979ab1c0ff36853e6a1c35c38fef793e4,18,5,3,167,,,0,"Enable PEP8 check E265

Change-Id: Idf41d967fb06a063d02c19987733ba3757aa466f
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/79/109079/3 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b2b5a23a67175066f292784b3e986545b8c1e46f,enable_e265,"ignore = E714,H237,H402,H405,H904","ignore = E265,E714,H237,H402,H405,H904",1,1
openstack%2Fpbr~master~If2f3c7fcabe474902cdb18cd6890a49144266690,openstack/pbr,master,If2f3c7fcabe474902cdb18cd6890a49144266690,cleanup tox.ini,MERGED,2014-08-12 15:18:13.000000000,2014-08-13 14:11:26.000000000,2014-08-13 14:11:26.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6482}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-08-12 15:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/9894cc2670cf3b717d90366e16ddd1f97fb73d3a', 'message': 'cleanup tox.ini\n\nremove unnecessary dependency declarations\n\nChange-Id: If2f3c7fcabe474902cdb18cd6890a49144266690\n'}, {'number': 2, 'created': '2014-08-12 16:03:46.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/pbr/commit/b561ef2e149c09eb5cc3da9e1b668f3d883449e0', 'message': 'cleanup tox.ini\n\nremove unnecessary dependency declarations\n\nChange-Id: If2f3c7fcabe474902cdb18cd6890a49144266690\n'}]",1,113553,b561ef2e149c09eb5cc3da9e1b668f3d883449e0,14,5,2,6482,,,0,"cleanup tox.ini

remove unnecessary dependency declarations

Change-Id: If2f3c7fcabe474902cdb18cd6890a49144266690
",git fetch https://review.opendev.org/openstack/pbr refs/changes/53/113553/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9894cc2670cf3b717d90366e16ddd1f97fb73d3a,cleanup_tox,,deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txtdeps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt,0,4
