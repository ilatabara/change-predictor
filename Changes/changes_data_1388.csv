id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Foslo-incubator~master~I8adccdc8bf82f7b97dbbc8969d6b9de4be31e214,openstack/oslo-incubator,master,I8adccdc8bf82f7b97dbbc8969d6b9de4be31e214,stop using + \ in help string,ABANDONED,2013-07-19 11:53:24.000000000,2013-07-19 14:03:59.000000000,,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 2750}, {'_account_id': 7708}]","[{'number': 1, 'created': '2013-07-19 11:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f6921df29f6dd0e45e1bef136c8849a2fa104a24', 'message': ""stop using + \\ in help string\n\nHacking specifies 'Long lines should be wrapped in parentheses\nin preference to using a backslash for line continuation.' Was\nnoticed when merging this into nova. It's a minor cleanup, but\ngood to be consistent.\n\nThis keeps the old formatting of no newlines, though if newlines\nwere fine a docstring might also be appropriate.\n\nChange-Id: I8adccdc8bf82f7b97dbbc8969d6b9de4be31e214\n""}, {'number': 2, 'created': '2013-07-19 11:59:24.000000000', 'files': ['openstack/common/eventlet_backdoor.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/96a50358b68fb3ba654fc154b4497029c2731ac4', 'message': ""stop using + \\ in help string\n\nHacking specifies 'Long lines should be wrapped in parentheses\nin preference to using a backslash for line continuation.' Was\nnoticed when merging this into nova. It's a minor cleanup, but\ngood to be consistent.\n\nThis keeps the old formatting of no newlines, though if newlines\nwere fine a docstring might also be appropriate.\n\nChange-Id: I8adccdc8bf82f7b97dbbc8969d6b9de4be31e214\n""}]",0,37882,96a50358b68fb3ba654fc154b4497029c2731ac4,6,4,2,2750,,,0,"stop using + \ in help string

Hacking specifies 'Long lines should be wrapped in parentheses
in preference to using a backslash for line continuation.' Was
noticed when merging this into nova. It's a minor cleanup, but
good to be consistent.

This keeps the old formatting of no newlines, though if newlines
were fine a docstring might also be appropriate.

Change-Id: I8adccdc8bf82f7b97dbbc8969d6b9de4be31e214
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/82/37882/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/eventlet_backdoor.py'],1,f6921df29f6dd0e45e1bef136c8849a2fa104a24,,"help_for_backdoor_port = ('Acceptable ' 'values are 0, <port> and <start>:<end>, where 0 results in ' 'listening on a random tcp port number, <port> results in ' 'listening on the specified port number and not enabling backdoor' 'if it is in use and <start>:<end> results in listening on the ' 'smallest unused port number within the specified range of port ' 'numbers. The chosen port is displayed in the service\'s log file.')","help_for_backdoor_port = 'Acceptable ' + \ 'values are 0, <port> and <start>:<end>, where 0 results in ' + \ 'listening on a random tcp port number, <port> results in ' + \ 'listening on the specified port number and not enabling backdoor' + \ 'if it is in use and <start>:<end> results in listening on the ' + \ 'smallest unused port number within the specified range of port ' + \ 'numbers. The chosen port is displayed in the service\'s log file.'",7,7
openstack%2Fmurano~master~I4f766510227af9ae12042bc14aa4c16693843f44,openstack/murano,master,I4f766510227af9ae12042bc14aa4c16693843f44,lastStatus introduced,MERGED,2013-07-18 12:28:23.000000000,2013-07-19 14:01:42.000000000,2013-07-19 14:01:42.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-07-18 12:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/bff4fde067ac2fb16a8e78f243d0b2ce30c9e8f7', 'message': ""lastStatus introduced\n\nAdded an API call to fetch the latest status of Session's services regardless of deployments\n\nChange-Id: I4f766510227af9ae12042bc14aa4c16693843f44\n""}, {'number': 2, 'created': '2013-07-19 11:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b88da3d22808bf6063f2ee24a42435d1d2b9361a', 'message': ""lastStatus introduced\n\nAdded an API call to fetch the latest status of Session's services regardless of deployments\n\nChange-Id: I4f766510227af9ae12042bc14aa4c16693843f44\n""}, {'number': 3, 'created': '2013-07-19 11:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/5267a2dfabdc680e852f6f7782d2024541b7bee2', 'message': ""lastStatus introduced\n\nAdded an API call to fetch the latest status of Session's services regardless of deployments\n\nChange-Id: I4f766510227af9ae12042bc14aa4c16693843f44\n""}, {'number': 4, 'created': '2013-07-19 13:40:48.000000000', 'files': ['muranoapi/api/v1/router.py', 'muranoapi/api/v1/deployments.py', 'muranoapi/common/utils.py', 'muranoapi/api/v1/environments.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/2b21f4a05658be444afb5cd37ffd0f22c75ba3b8', 'message': ""lastStatus introduced\n\nAdded an API call to fetch the latest status of Session's services regardless of deployments\n\nChange-Id: I4f766510227af9ae12042bc14aa4c16693843f44\n""}]",0,37670,2b21f4a05658be444afb5cd37ffd0f22c75ba3b8,14,3,4,8127,,,0,"lastStatus introduced

Added an API call to fetch the latest status of Session's services regardless of deployments

Change-Id: I4f766510227af9ae12042bc14aa4c16693843f44
",git fetch https://review.opendev.org/openstack/murano refs/changes/70/37670/2 && git format-patch -1 --stdout FETCH_HEAD,"['muranoapi/api/v1/router.py', 'muranoapi/api/v1/deployments.py', 'muranoapi/common/utils.py', 'muranoapi/api/v1/environments.py']",4,bff4fde067ac2fb16a8e78f243d0b2ce30c9e8f7,feature_lastOperation,"from muranoapi import utils from muranoapi.common.utils import build_entity_map from sqlalchemy import descfrom muranoapi.db.models import Environment, Status @utils.verify_session def last(self, request, environment_id): session_id = request.context.session services = CoreServices.get_data(environment_id, '/services', session_id) db_session = get_session() result = {} for service in services: service_id = service['id'] entity_ids = build_entity_map(service).keys() last_status = db_session.query(Status). \ filter(Status.entity_id.in_(entity_ids)). \ order_by(desc(Status.created)). \ first() result[service_id] = last_status return result ",from muranoapi.db.models import Environment,44,6
openstack%2Fpython-muranoclient~master~I7c529eb9ed811f99d3d5aa5b093ba3ddfca0abea,openstack/python-muranoclient,master,I7c529eb9ed811f99d3d5aa5b093ba3ddfca0abea,Modified client to support lastStatus fetching,MERGED,2013-07-18 12:58:02.000000000,2013-07-19 14:00:15.000000000,2013-07-19 14:00:15.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-07-18 12:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/439fcaeae7e04913ad30c52b95cad680b72dd6f7', 'message': 'Modified client to support lastStatus fetching\n\nChange-Id: I7c529eb9ed811f99d3d5aa5b093ba3ddfca0abea\n'}, {'number': 2, 'created': '2013-07-19 09:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/9931b98a025e4fbc387391694192bdb07986e2c6', 'message': 'Modified client to support lastStatus fetching\n\nChange-Id: I7c529eb9ed811f99d3d5aa5b093ba3ddfca0abea\n'}, {'number': 3, 'created': '2013-07-19 11:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/86d66d66714bb71891ca9f9cad1c6d0bb53db6ce', 'message': 'Modified client to support lastStatus fetching\n\nChange-Id: I7c529eb9ed811f99d3d5aa5b093ba3ddfca0abea\n'}, {'number': 4, 'created': '2013-07-19 13:42:06.000000000', 'files': ['muranoclient/v1/environments.py', 'muranoclient/v1/sessions.py', 'tests/test_methods.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/0e8a2f913fba2f06c3e29aeda61fc7eb1c089564', 'message': 'Modified client to support lastStatus fetching\n\nChange-Id: I7c529eb9ed811f99d3d5aa5b093ba3ddfca0abea\n'}]",0,37673,0e8a2f913fba2f06c3e29aeda61fc7eb1c089564,11,3,4,8127,,,0,"Modified client to support lastStatus fetching

Change-Id: I7c529eb9ed811f99d3d5aa5b093ba3ddfca0abea
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/73/37673/4 && git format-patch -1 --stdout FETCH_HEAD,['muranoclient/v1/environments.py'],1,439fcaeae7e04913ad30c52b95cad680b72dd6f7,featureLastOperation," def last_status(self, environment_id, session_id): headers = {'X-Configuration-Session': session_id} path = 'environments/{id}/lastStatus' path = path.format(id=environment_id) status_dict = self._get(path, return_raw=True, headers=headers) return status_dict",,7,0
openstack%2Fceilometer~master~Ifaf49a07ba27e35a3a6dc03b92a61526973f2afd,openstack/ceilometer,master,Ifaf49a07ba27e35a3a6dc03b92a61526973f2afd,Multiple dispatcher enablment - use pipeline,ABANDONED,2013-06-27 19:34:55.000000000,2013-07-19 13:59:27.000000000,,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2860}, {'_account_id': 7336}]","[{'number': 1, 'created': '2013-06-27 19:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/74105e41ac4ef923acd58041ec6ffc6d046ef177', 'message': 'Multiple dispatcher enablment\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: Ifaf49a07ba27e35a3a6dc03b92a61526973f2afd\n'}, {'number': 2, 'created': '2013-06-28 02:50:15.000000000', 'files': ['ceilometer/pipeline.py', 'doc/source/install/manual.rst', 'setup.cfg', 'ceilometer/collector/service.py', 'ceilometer/publisher/file.py', 'etc/ceilometer/ceilometer.conf.sample'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5ca0c5fad8c1d1109803fe43cc6eb8dccb8d8d5f', 'message': 'Multiple dispatcher enablment - use pipeline\n\nCeilometer does not allow multiple outlets for metering data.\nWith this implementation, one can use multiple pipelines to process\nmetering data, a meter can be saved into a database and other\nsystems based on publishers used in the configuration.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: Ifaf49a07ba27e35a3a6dc03b92a61526973f2afd\n'}]",19,34783,5ca0c5fad8c1d1109803fe43cc6eb8dccb8d8d5f,21,6,2,2860,,,0,"Multiple dispatcher enablment - use pipeline

Ceilometer does not allow multiple outlets for metering data.
With this implementation, one can use multiple pipelines to process
metering data, a meter can be saved into a database and other
systems based on publishers used in the configuration.

blueprint multi-dispatcher-enablement

Change-Id: Ifaf49a07ba27e35a3a6dc03b92a61526973f2afd
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/83/34783/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/pipeline.py', 'setup.cfg', 'ceilometer/collector/service.py', 'ceilometer/publisher/file.py']",4,74105e41ac4ef923acd58041ec6ffc6d046ef177,bp/multi-dispatcher-enablement,"# -*- encoding: utf-8 -*- # # Copyright 2013 IBM Corp # # Author: Tong Li <litong01@us.ibm.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo.config import cfg import logging import logging.handlers from ceilometer.openstack.common import log from ceilometer import publisher file_publisher_opts = [ cfg.StrOpt('file-path', default='/tmp/meters.txt', help='(Optional) Name and the location of the file to record ' 'meters. If this is not set, meters will go to log.'), cfg.IntOpt('max-bytes', default=10000000, help='The max bytes for the file before it starts rotating'), cfg.IntOpt('backup-count', default=5, help='The backup count for the file'), ] CONF = cfg.CONF opt_group = cfg.OptGroup(name='file_publisher', title='Options for file publisher') CONF.register_group(opt_group) CONF.register_opts(file_publisher_opts, opt_group) LOG = log.getLogger(__name__) class FilePublisher(publisher.PublisherBase): """"""Publisher metering data to file. The publisher which records metering data into a file. The file name and location should be configured in ceilometer configuration file. An example configuration may look like this [file_publisher] file_path = /opt/stack/data/ceilometer/file_dispatcher max_bytes = 10000000 backup_count = 5 To enable this publisher, add the following section to file /etc/ceilometer/publisher.yaml - name: meter_file interval: 600 counters: - ""*"" transformers: publishers: - file """""" def __init__(self, parsed_url): super(FilePublisher, self).__init__(parsed_url) self.publisher_logger = logging.getLogger('file_publisher') self.publisher_logger.setLevel(logging.INFO) # create RatatingFile handler which logs meters rfh = logging.handlers.RotatingFileHandler( CONF.file_publisher.file_path, encoding='utf8', maxBytes=CONF.file_publisher.max_bytes, backupCount=CONF.file_publisher.backup_count) rfh.setLevel(logging.INFO) self.publisher_logger.addHandler(rfh) def publish_counters(self, context, counters, source): """"""Send a metering message for publishing :param context: Execution context from the service or RPC call :param counter: Counter from pipeline after transformation :param source: counter source """""" self.publisher_logger.info(counters) ",,158,0
openstack%2Fmurano-dashboard~master~Ibced092fc241f813b83865e3450ce2668e9fefbb,openstack/murano-dashboard,master,Ibced092fc241f813b83865e3450ce2668e9fefbb,Fix Farm naming,MERGED,2013-07-19 13:46:23.000000000,2013-07-19 13:49:34.000000000,2013-07-19 13:49:34.000000000,"[{'_account_id': 3}, {'_account_id': 7226}]","[{'number': 1, 'created': '2013-07-19 13:46:23.000000000', 'files': ['muranodashboard/panel/consts.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f8bc4bc9cc1d778cfb80f26da92a2d17f0520df0', 'message': 'Fix Farm naming\n\nChange-Id: Ibced092fc241f813b83865e3450ce2668e9fefbb\n'}]",0,37901,f8bc4bc9cc1d778cfb80f26da92a2d17f0520df0,5,2,1,7549,,,0,"Fix Farm naming

Change-Id: Ibced092fc241f813b83865e3450ce2668e9fefbb
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/01/37901/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/consts.py'],1,f8bc4bc9cc1d778cfb80f26da92a2d17f0520df0,fix_asp_name,IIS_FARM_NAME = 'webServerFarm' ASP_FARM_NAME = 'aspNetAppFarm',IIS_FARM_NAME = 'aspNetAppFarm' ASP_FARM_NAME = 'webServerFarm',2,2
openstack%2Fmurano-dashboard~master~Ie112e21426c29516835b7e7217edaf0f86b3b8e1,openstack/murano-dashboard,master,Ie112e21426c29516835b7e7217edaf0f86b3b8e1,Enable getting list of aval. zones by non admin,MERGED,2013-07-19 13:14:05.000000000,2013-07-19 13:44:46.000000000,2013-07-19 13:44:46.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-07-19 13:14:05.000000000', 'files': ['muranodashboard/panel/forms.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/c550f992bb49d2a10cbaf86e90d8061fcdd080d0', 'message': 'Enable getting list of aval. zones by non admin\n\nChange-Id: Ie112e21426c29516835b7e7217edaf0f86b3b8e1\n'}]",0,37894,c550f992bb49d2a10cbaf86e90d8061fcdd080d0,5,2,1,7549,,,0,"Enable getting list of aval. zones by non admin

Change-Id: Ie112e21426c29516835b7e7217edaf0f86b3b8e1
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/94/37894/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/forms.py'],1,c550f992bb49d2a10cbaf86e90d8061fcdd080d0,MRN-599_login_error," availability_zones = novaclient(request).availability_zones.\ list(detailed=False) az_choices = [(az.zoneName, az.zoneName) for az in availability_zones if az.zoneState] if az_choices: az_choices.insert(0, ("""", _(""Select Availability Zone""))) else: az_choices.insert(0, ("""", _(""No availability zone available.""))) self.fields['availability_zone'].choices = az_choices"," availability_zones = novaclient(request).availability_zones.list() if availability_zones: availability_zones.insert(0, ("""", _(""Select "" ""Availability Zone""))) else: availability_zones.insert(0, ("""", _(""No availability "" ""zone available.""))) self.fields['availability_zone'].choices = \ [(az.zoneName, az.zoneName) for az in availability_zones if az.zoneState]",10,10
openstack%2Fmurano-deployment~master~Idd4ac952fde91562ba411ed969f720185ceeefba,openstack/murano-deployment,master,Idd4ac952fde91562ba411ed969f720185ceeefba,murano-git-install updated.,MERGED,2013-07-19 13:41:55.000000000,2013-07-19 13:42:49.000000000,2013-07-19 13:42:49.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-19 13:41:55.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/45eb97997e8d6640ad14a5f588dc345e9acea2bc', 'message': 'murano-git-install updated.\n\nHelp added.\nPrerequisites installation added.\n\nChange-Id: Idd4ac952fde91562ba411ed969f720185ceeefba\n'}]",0,37900,45eb97997e8d6640ad14a5f588dc345e9acea2bc,5,2,1,7562,,,0,"murano-git-install updated.

Help added.
Prerequisites installation added.

Change-Id: Idd4ac952fde91562ba411ed969f720185ceeefba
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/00/37900/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,45eb97997e8d6640ad14a5f588dc345e9acea2bc,devbox-script-update,"mode=${1:-'help'}function install_prerequisites { case $os_version in 'CentOS') log ""** Installing additional software sources ..."" yum install -y 'http://rdo.fedorapeople.org/openstack/openstack-grizzly/rdo-release-grizzly.rpm' yum install -y 'http://mirror.yandex.ru/epel/6/x86_64/epel-release-6-8.noarch.rpm' log ""** Updating system ..."" yum update -y log ""** Installing OpenStack dashboard ..."" yum install make gcc python-netaddr.noarch python-keystoneclient.noarch python-django-horizon.noarch python-django-openstack-auth.noarch httpd.x86_64 mod_wsgi.x86_64 openstack-dashboard.noarch --assumeyes ;; 'Ubuntu') log ""** Installing additional software sources ..."" echo 'deb http://ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/grizzly main' > /etc/apt/sources.list.d/grizzly.list apt-get install -y ubuntu-cloud-keyring log ""** Updating system ..."" apt-get update -y apt-get upgrade -y log ""** Installing OpenStack dashboard ..."" apt-get install -y memcached libapache2-mod-wsgi openstack-dashboard log ""** Removing Ubuntu Dashboard Theme ..."" dpkg --purge openstack-dashboard-ubuntu-theme log ""** Restarting Apache server ..."" service apache2 restart ;; esac } if [[ $mode =~ '?'|'help'|'-h'|'--help' ]] ; then cat << EOF The following options are awailable: * help - show help. This is a default action. * install - install and configure Murano components. Please be sure that you have prerequisites installed first. * configure - configure Murano components. * prerequisites - install prerequisites for Murano (OpenStack dashboard and other packages) * restart - restart Murano components and Apache server EOF exit fi 'prerequisites') install_prerequisites ;;",mode=${1:-'install'},53,1
openstack%2Fopenstack-manuals~master~I914e3ab50f0cf55016a5b3b5b81f80cc95cb9eac,openstack/openstack-manuals,master,I914e3ab50f0cf55016a5b3b5b81f80cc95cb9eac,Restructure hypervisor section,MERGED,2013-07-15 05:37:43.000000000,2013-07-19 13:28:23.000000000,2013-07-19 13:28:22.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 7063}]","[{'number': 1, 'created': '2013-07-15 05:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c20ebf1340d0f8326345734099a75e1ad2450dbe', 'message': ""Restructure hypervisor section\n\nThis patch splits xen out into intro, configure and install,\nin preparation for our documentation restructure.\n\nExisting guides are modified so they aren't adversely affected.\n\nChange-Id: I914e3ab50f0cf55016a5b3b5b81f80cc95cb9eac\nbp:restructure-documentation\n""}, {'number': 2, 'created': '2013-07-18 14:58:15.000000000', 'files': ['doc/src/docbkx/common/xen-install.xml', 'doc/src/docbkx/common/compute-hypervisor-selection.xml', 'doc/src/docbkx/openstack-config/compute-configure-xen.xml', 'doc/src/docbkx/openstack-config/ch_computehypervisors.xml', 'doc/src/docbkx/common/introduction-to-xen.xml', 'doc/src/docbkx/common/xapi-install-plugins.xml', 'doc/src/docbkx/openstack-install/ch_installcompute.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6393fda6e4156c8b3386e43b3764c2a2f3067026', 'message': ""Restructure hypervisor section\n\nThis patch splits xen out into intro, configure and install,\nin preparation for our documentation restructure.\n\nExisting guides are modified so they aren't adversely affected.\npatchset 2 - diane fleming - made editorial changes/spellcheck/formatting\n\nChange-Id: I914e3ab50f0cf55016a5b3b5b81f80cc95cb9eac\nbp:restructure-documentation\n""}]",8,37015,6393fda6e4156c8b3386e43b3764c2a2f3067026,12,6,2,612,,,0,"Restructure hypervisor section

This patch splits xen out into intro, configure and install,
in preparation for our documentation restructure.

Existing guides are modified so they aren't adversely affected.
patchset 2 - diane fleming - made editorial changes/spellcheck/formatting

Change-Id: I914e3ab50f0cf55016a5b3b5b81f80cc95cb9eac
bp:restructure-documentation
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/15/37015/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/common/xen-install.xml', 'doc/src/docbkx/common/compute-hypervisor-selection.xml', 'doc/src/docbkx/openstack-config/compute-configure-xen.xml', 'doc/src/docbkx/openstack-config/ch_computehypervisors.xml', 'doc/src/docbkx/common/introduction-to-xen.xml', 'doc/src/docbkx/openstack-install/ch_installcompute.xml']",6,c20ebf1340d0f8326345734099a75e1ad2450dbe,bp/restructure-documentation," <section xml:id=""configuring-hypervisors""> <title>Configuring Hypervisors</title> <para> Please refer to the Compute Administration guide <link xlink:href=""http://docs.openstack.org/trunk/openstack-compute/admin/content/ch_hypervisors.html"">Hypervisors</link> chapter for more details. </para> </section>"," <xi:include href=""compute-hypervisor-selection.xml""/> <xi:include href=""../common/kvm.xml"" /> <xi:include href=""../common/qemu.xml"" /> <xi:include href=""../common/introduction-to-xen.xml"" />",271,227
openstack%2Fpython-novaclient~master~I68823a3d719ee2f5d9d8b6227ca8eb858fc270c3,openstack/python-novaclient,master,I68823a3d719ee2f5d9d8b6227ca8eb858fc270c3,Fix interface-list got none mac address.,MERGED,2013-07-10 09:50:25.000000000,2013-07-19 13:21:21.000000000,2013-07-19 13:21:21.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1678}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 7439}]","[{'number': 1, 'created': '2013-07-10 09:50:25.000000000', 'files': ['novaclient/v1_1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/70e6cd97906fde9a888bae6eadc435560b64ec09', 'message': 'Fix interface-list got none mac address.\n\nnovaclient expect the response json body has a column \'mac_address\', but\nactually is \'mac_addr\'. This patch is a quick fix. Just print out\n""mac_addr"" is readable enough.\n\nFix bug: #1199706\n\nChange-Id: I68823a3d719ee2f5d9d8b6227ca8eb858fc270c3\n'}]",0,36421,70e6cd97906fde9a888bae6eadc435560b64ec09,9,6,1,1678,,,0,"Fix interface-list got none mac address.

novaclient expect the response json body has a column 'mac_address', but
actually is 'mac_addr'. This patch is a quick fix. Just print out
""mac_addr"" is readable enough.

Fix bug: #1199706

Change-Id: I68823a3d719ee2f5d9d8b6227ca8eb858fc270c3
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/21/36421/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/shell.py'],1,70e6cd97906fde9a888bae6eadc435560b64ec09,, 'MAC Addr'], 'MAC Address'],1,1
openstack%2Fsahara~master~Ib1fae214f6b49262b60fd5326156560000552407,openstack/sahara,master,Ib1fae214f6b49262b60fd5326156560000552407,Cluster scaling bug fixing:,MERGED,2013-07-19 12:51:40.000000000,2013-07-19 12:59:09.000000000,2013-07-19 12:59:09.000000000,"[{'_account_id': 3}, {'_account_id': 6786}]","[{'number': 1, 'created': '2013-07-19 12:51:40.000000000', 'files': ['savanna/plugins/vanilla/plugin.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/c545e24e7a5988ba090232433ce4c5b3af673776', 'message': 'Cluster scaling bug fixing:\n\nFixes: bug #1203041\n\nChange-Id: Ib1fae214f6b49262b60fd5326156560000552407\n'}]",0,37892,c545e24e7a5988ba090232433ce4c5b3af673776,5,2,1,7478,,,0,"Cluster scaling bug fixing:

Fixes: bug #1203041

Change-Id: Ib1fae214f6b49262b60fd5326156560000552407
",git fetch https://review.opendev.org/openstack/sahara refs/changes/92/37892/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/plugins/vanilla/plugin.py'],1,c545e24e7a5988ba090232433ce4c5b3af673776,bug/1203041," jt = utils.get_jobtracker(cluster) if jt: run.refresh_nodes(jt.remote, ""mradmin"")"," run.refresh_nodes(utils.get_jobtracker(cluster).remote, ""mradmin"")",3,1
openstack%2Frequirements~master~I9de754941f11e6adbb8ef4a18d0ea300d9d95dcc,openstack/requirements,master,I9de754941f11e6adbb8ef4a18d0ea300d9d95dcc,Move python-ldap to requirements,ABANDONED,2013-07-17 03:17:23.000000000,2013-07-19 12:57:00.000000000,,"[{'_account_id': 3}, {'_account_id': 1994}]","[{'number': 1, 'created': '2013-07-17 03:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4c3eb78b12d8500adedf0b08f37ad83fdf320524', 'message': 'Add python-ldap to requirements\n\npython-ldap provides an object-oriented API to access LDAP directory servers\nfrom Python programs. Mainly it wraps the OpenLDAP 2.x libs for that purpose.\nThe ldap module is used in Nova and Keystone.\n\nChange-Id: I9de754941f11e6adbb8ef4a18d0ea300d9d95dcc\n'}, {'number': 2, 'created': '2013-07-17 03:21:45.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c2a300878bbaf0165d304aca657c23d21eeec63b', 'message': 'Move python-ldap to requirements\n\nThe ldap module is used in Nova and Keystone. Both projects use ldap\non their services not tests\n\nChange-Id: I9de754941f11e6adbb8ef4a18d0ea300d9d95dcc\n'}]",0,37380,c2a300878bbaf0165d304aca657c23d21eeec63b,5,2,2,1994,,,0,"Move python-ldap to requirements

The ldap module is used in Nova and Keystone. Both projects use ldap
on their services not tests

Change-Id: I9de754941f11e6adbb8ef4a18d0ea300d9d95dcc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/80/37380/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4c3eb78b12d8500adedf0b08f37ad83fdf320524,python-ldap,python-ldap>=2.4.13,,1,0
openstack%2Fmurano-deployment~master~Ic060fe56c8d7cb84e912bfe5388525a73943a51e,openstack/murano-deployment,master,Ic060fe56c8d7cb84e912bfe5388525a73943a51e,murano-git-install fixed.,MERGED,2013-07-19 12:47:40.000000000,2013-07-19 12:48:15.000000000,2013-07-19 12:48:15.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-19 12:47:40.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/d5d62eafe13e454bb2cb10fcb6c4d8cc5a4b1d70', 'message': 'murano-git-install fixed.\n\nChange-Id: Ic060fe56c8d7cb84e912bfe5388525a73943a51e\n'}]",0,37891,d5d62eafe13e454bb2cb10fcb6c4d8cc5a4b1d70,5,2,1,7562,,,0,"murano-git-install fixed.

Change-Id: Ic060fe56c8d7cb84e912bfe5388525a73943a51e
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/91/37891/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,d5d62eafe13e454bb2cb10fcb6c4d8cc5a4b1d70,devbox-scrips-fix," iniset '' 'OPENSTACK_HOST' ""'$LAB_HOST'"" ""$config_file"" log ""** Restarting '$service_name'"" log ""** Restarting 'Apache'"" case $os_version in 'CentOS') service httpd restart ;; 'Ubuntu') service apache2 restart ;; esac"," iniset '' 'OPENSTACK_HOST' ""$LAB_HOST"" ""$config_file""",12,1
openstack%2Fnova~master~I72b296668f60b1de71ff8c6d7bbb749023d89f12,openstack/nova,master,I72b296668f60b1de71ff8c6d7bbb749023d89f12,Handle instance being deleted while in filter scheduler,MERGED,2013-06-14 21:44:17.000000000,2013-07-19 12:33:25.000000000,2013-07-19 12:33:22.000000000,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 1030}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2033}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 2889}, {'_account_id': 5652}, {'_account_id': 7369}]","[{'number': 1, 'created': '2013-06-14 21:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ad461b3881a0aa8649b258d706eaab8ccf3b259', 'message': 'Handle instance being deleted while in fliter scheduler\n\nAdds handling of InstanceNotFound when trying to update the\nscheduled_at time of an instance.\n\nUsers can delete an instance at any time, so this should\nbe a warning not an error\n\nFixes bug 1191126\n\nChange-Id: I72b296668f60b1de71ff8c6d7bbb749023d89f12\n'}, {'number': 2, 'created': '2013-06-16 20:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a282a1a1ef4df2c293633acd9ebc09507bd673b1', 'message': 'Handle instance being deleted while in fliter scheduler\n\nAdds handling of InstanceNotFound when trying to update the\nscheduled_at time of an instance.\n\nUsers can delete an instance at any time, so this should\nbe a warning not an error\n\nFixes bug 1191126\n\nChange-Id: I72b296668f60b1de71ff8c6d7bbb749023d89f12\n'}, {'number': 3, 'created': '2013-06-20 17:14:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/881f96c011ffb5b6b063c6260974b698c172b4fc', 'message': 'Handle instance being deleted while in filter scheduler\n\nAdds handling of InstanceNotFound when trying to update the\nscheduled_at time of an instance.\n\nUsers can delete an instance at any time, so this should\nbe a warning not an error\n\nFixes bug 1191126\n\nChange-Id: I72b296668f60b1de71ff8c6d7bbb749023d89f12\n'}, {'number': 4, 'created': '2013-07-12 10:49:32.000000000', 'files': ['nova/tests/scheduler/test_filter_scheduler.py', 'nova/scheduler/filter_scheduler.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/79039a7f6ffce2d5cc2e92eee03de94a3c2292f8', 'message': 'Handle instance being deleted while in filter scheduler\n\nAdds handling of InstanceNotFound when trying to update the\nscheduled_at time of an instance.\n\nUsers can delete an instance at any time (and many test\ncases delete very quickly), so this should be a warning\nnot an error\n\nFixes bug 1191126\n\nChange-Id: I72b296668f60b1de71ff8c6d7bbb749023d89f12\n'}]",7,33122,79039a7f6ffce2d5cc2e92eee03de94a3c2292f8,30,12,4,1501,,,0,"Handle instance being deleted while in filter scheduler

Adds handling of InstanceNotFound when trying to update the
scheduled_at time of an instance.

Users can delete an instance at any time (and many test
cases delete very quickly), so this should be a warning
not an error

Fixes bug 1191126

Change-Id: I72b296668f60b1de71ff8c6d7bbb749023d89f12
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/33122/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_filter_scheduler.py', 'nova/scheduler/filter_scheduler.py']",2,3ad461b3881a0aa8649b258d706eaab8ccf3b259,bug/1191126," try: updated_instance = driver.instance_update_db(context, instance_uuid, extra_values=values) self._post_select_populate_filter_properties(filter_properties, weighed_host.obj) self.compute_rpcapi.run_instance(context, instance=updated_instance, host=weighed_host.obj.host, request_spec=request_spec, filter_properties=filter_properties, requested_networks=requested_networks, injected_files=injected_files, admin_password=admin_password, is_first_time=is_first_time, node=weighed_host.obj.nodename) except exception.InstanceNotFound: LOG.warning(_(""Instance disappeared during reboot""), context=context, instance_uuid=instance_uuid)"," updated_instance = driver.instance_update_db(context, instance_uuid, extra_values=values) self._post_select_populate_filter_properties(filter_properties, weighed_host.obj) self.compute_rpcapi.run_instance(context, instance=updated_instance, host=weighed_host.obj.host, request_spec=request_spec, filter_properties=filter_properties, requested_networks=requested_networks, injected_files=injected_files, admin_password=admin_password, is_first_time=is_first_time, node=weighed_host.obj.nodename)",44,11
openstack%2Fmurano-dashboard~master~Ia1a62d41f65b51fa32f5cbac8549622f72eac3c5,openstack/murano-dashboard,master,Ia1a62d41f65b51fa32f5cbac8549622f72eac3c5,Make availability_zone filed not required.,MERGED,2013-07-19 12:18:06.000000000,2013-07-19 12:21:18.000000000,2013-07-19 12:21:17.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-07-19 12:18:06.000000000', 'files': ['muranodashboard/panel/forms.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/6c43bbf91b0a82cbd8284ad556c832b6a57698b4', 'message': 'Make availability_zone filed not required.\n\nChange-Id: Ia1a62d41f65b51fa32f5cbac8549622f72eac3c5\n'}]",0,37889,6c43bbf91b0a82cbd8284ad556c832b6a57698b4,5,2,1,7549,,,0,"Make availability_zone filed not required.

Change-Id: Ia1a62d41f65b51fa32f5cbac8549622f72eac3c5
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/89/37889/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/forms.py'],1,6c43bbf91b0a82cbd8284ad556c832b6a57698b4,MRN-599_login_error," availability_zone = forms.ChoiceField(label=_('Availability zone'), required=False) if availability_zones: availability_zones.insert(0, ("""", _(""Select "" ""Availability Zone""))) else: availability_zones.insert(0, ("""", _(""No availability "" ""zone available.""))) ", availability_zone = forms.ChoiceField(label=_('Availability zone')),9,1
openstack%2Fmurano-deployment~master~I5d33005bf4a807cfd54f51eaebe886b4ae0e9046,openstack/murano-deployment,master,I5d33005bf4a807cfd54f51eaebe886b4ae0e9046,Fixes in murano-git-install,MERGED,2013-07-19 11:58:47.000000000,2013-07-19 11:59:13.000000000,2013-07-19 11:59:13.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-19 11:58:47.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/d8f05b3ffca21e38e44e6cbe18f91920dce5e7de', 'message': 'Fixes in murano-git-install\n\nChange-Id: I5d33005bf4a807cfd54f51eaebe886b4ae0e9046\n'}]",0,37886,d8f05b3ffca21e38e44e6cbe18f91920dce5e7de,5,2,1,7562,,,0,"Fixes in murano-git-install

Change-Id: I5d33005bf4a807cfd54f51eaebe886b4ae0e9046
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/86/37886/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,d8f05b3ffca21e38e44e6cbe18f91920dce5e7de,devbox-scripts-update,"#set -o xtrace log ""** Configuring Murano ..."" log ""** Configuring file '$config_file'"" '/etc/murano-api/murano-api-paste.ini') iniset 'filter:authtoken' 'auth_host' ""$LAB_HOST"" ""$config_file"" iniset 'filter:authtoken' 'admin_user' ""$ADMIN_USER"" ""$config_file"" iniset 'filter:authtoken' 'admin_password' ""$ADMIN_PASSWORD"" ""$config_file"" ;;log ""* Running mode '$mode'"" 'restart') restart_murano ;;"," '/etc/murano-conductor/conductor-paste.ini') iniset 'filter:authtoken' 'auth_host' ""$LAB_HOST"" ""$config_file"" iniset 'filter:authtoken' 'admin_user' ""$ADMIN_USER"" ""$config_file"" iniset 'filter:authtoken' 'admin_password' ""$ADMIN_PASSWORD"" ""$config_file"" ;;",15,5
openstack%2Fceilometer~master~I709b588f0e545e1921d75473f1dc25b75045a8fa,openstack/ceilometer,master,I709b588f0e545e1921d75473f1dc25b75045a8fa,Sync models with migrations.,ABANDONED,2013-07-19 11:47:36.000000000,2013-07-19 11:48:02.000000000,,[],"[{'number': 1, 'created': '2013-07-19 11:47:36.000000000', 'files': ['ceilometer/storage/sqlalchemy/utils.py', 'ceilometer/storage/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6e69779d0407bfae1a53d92063ef44354b97c9b1', 'message': 'Sync models with migrations.\n\nThere are a lot of difference in models and actual db state\nfrom migrations.\nThis patch fixes:\n- wrong type of column,\n- wrong length of column,\n- missing indexes,\n- extra indexes,\n- errors.\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I709b588f0e545e1921d75473f1dc25b75045a8fa\n'}]",0,37880,6e69779d0407bfae1a53d92063ef44354b97c9b1,1,0,1,6507,,,0,"Sync models with migrations.

There are a lot of difference in models and actual db state
from migrations.
This patch fixes:
- wrong type of column,
- wrong length of column,
- missing indexes,
- extra indexes,
- errors.

bp: ceilometer-db-sync-models-with-migrations

Change-Id: I709b588f0e545e1921d75473f1dc25b75045a8fa
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/80/37880/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/sqlalchemy/utils.py', 'ceilometer/storage/sqlalchemy/models.py']",2,6e69779d0407bfae1a53d92063ef44354b97c9b1,bp/ceilometer-db-sync-models-with-migrations,"from sqlalchemy.types import TypeDecorator impl = StringIndex('idx_su', sourceassoc.c['source_id'], sourceassoc.c['user_id']), Index('idx_sp', sourceassoc.c['source_id'], sourceassoc.c['project_id']), Index('idx_sr', sourceassoc.c['source_id'], sourceassoc.c['resource_id']), Index('idx_sm', sourceassoc.c['source_id'], sourceassoc.c['meter_id']), Index('ix_sourceassoc_source_id', sourceassoc.c['source_id']) resource_metadata = Column(JSONEncodedDict(5000)) __table_args__ = ( resource_metadata = Column(JSONEncodedDict(5000)) __table_args__ = ( __table_args__ = ( Index('ix_unique_name_key', 'key'), ) key = Column(String(255)) __table_args__ = ( Index('ix_trait_t_int', 't_int'), Index('ix_trait_t_string', 't_string'), Index('ix_trait_t_datetime', 't_datetime'), Index('ix_trait_t_type', 't_type'), Index('ix_trait_t_float', 't_float'), ) t_type = Column(Integer) t_string = Column(String(255), nullable=True, default=None) t_float = Column(Float, nullable=True, default=None) t_int = Column(Integer, nullable=True, default=None) t_datetime = Column(Float(asdecimal=True), nullable=True, default=None)","from sqlalchemy.types import TypeDecorator, VARCHAR impl = VARCHAR resource_metadata = Column(JSONEncodedDict) __table_ards__ = ( resource_metadata = Column(JSONEncodedDict) __table_ards__ = ( key = Column(String(255), index=True, unique=True) t_type = Column(Integer, index=True) t_string = Column(String(255), nullable=True, default=None, index=True) t_float = Column(Float, nullable=True, default=None, index=True) t_int = Column(Integer, nullable=True, default=None, index=True) t_datetime = Column(Float(asdecimal=True), nullable=True, default=None, index=True)",199,13
openstack%2Fmurano-dashboard~master~I7dfe9d9c5b37979b659c48a32bc7f55f39e2d4cc,openstack/murano-dashboard,master,I7dfe9d9c5b37979b659c48a32bc7f55f39e2d4cc,Catch unauthorized exception,MERGED,2013-07-19 11:27:30.000000000,2013-07-19 11:45:58.000000000,2013-07-19 11:45:58.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-07-19 11:27:30.000000000', 'files': ['muranodashboard/panel/views.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/69976201aa74d3e8c26753e12386c30b69d9550c', 'message': 'Catch unauthorized exception\n\nChange-Id: I7dfe9d9c5b37979b659c48a32bc7f55f39e2d4cc\n'}]",0,37875,69976201aa74d3e8c26753e12386c30b69d9550c,5,2,1,7549,,,0,"Catch unauthorized exception

Change-Id: I7dfe9d9c5b37979b659c48a32bc7f55f39e2d4cc
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/75/37875/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/views.py'],1,69976201aa74d3e8c26753e12386c30b69d9550c,MRN-599_login_error, except HTTPUnauthorized: exceptions.handle(self.request) except HTTPUnauthorized: exceptions.handle(self.request) except HTTPForbidden:, except:,7,1
openstack%2Foslo.config~master~I803a5a9a4bf30dc053b3f3a260a69ce19f3a6c9b,openstack/oslo.config,master,I803a5a9a4bf30dc053b3f3a260a69ce19f3a6c9b,Add eclipse project files to .gitignore,MERGED,2013-07-18 22:40:48.000000000,2013-07-19 11:41:40.000000000,2013-07-19 11:41:40.000000000,"[{'_account_id': 3}, {'_account_id': 1247}]","[{'number': 1, 'created': '2013-07-18 22:40:48.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/d836c1f05ac6909409b1c8763d5926d31fad5e2f', 'message': 'Add eclipse project files to .gitignore\n\nLike some of the other projects (nova, heat) ignore eclipse\nproject files, for those people that work with eclipse (yuck :)\n\nChange-Id: I803a5a9a4bf30dc053b3f3a260a69ce19f3a6c9b\n'}]",0,37801,d836c1f05ac6909409b1c8763d5926d31fad5e2f,5,2,1,7996,,,0,"Add eclipse project files to .gitignore

Like some of the other projects (nova, heat) ignore eclipse
project files, for those people that work with eclipse (yuck :)

Change-Id: I803a5a9a4bf30dc053b3f3a260a69ce19f3a6c9b
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/01/37801/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,d836c1f05ac6909409b1c8763d5926d31fad5e2f,ignore-eclipse,.project .pydevproject,,2,0
openstack%2Fmurano-deployment~master~I8185e654fa28f767afb1feb6773caa97b4985f3c,openstack/murano-deployment,master,I8185e654fa28f767afb1feb6773caa97b4985f3c,murano-git-install updated.,MERGED,2013-07-19 11:34:23.000000000,2013-07-19 11:35:01.000000000,2013-07-19 11:35:01.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-19 11:34:23.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/0cfcb5e091e2ba05884cac742f92406d52040fb2', 'message': 'murano-git-install updated.\n\nChange-Id: I8185e654fa28f767afb1feb6773caa97b4985f3c\n'}]",0,37877,0cfcb5e091e2ba05884cac742f92406d52040fb2,5,2,1,7562,,,0,"murano-git-install updated.

Change-Id: I8185e654fa28f767afb1feb6773caa97b4985f3c
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/77/37877/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,0cfcb5e091e2ba05884cac742f92406d52040fb2,devbox-scripts-update,"# Helper funtions #-------------------------------------------------#------------------------------------------------- # Workflow functions #------------------------------------------------- function install_murano { configuration_required='false' for config_file in $murano_config_files ; do if [ ! -f ""$config_file"" ] ; then log ""! Required config file '$config_file' not exists. Murano should be configured before start."" configuration_required='true' done for app_name in $murano_components ; do log ""* Working with '$app_name'"" git_repo=""$git_prefix/$app_name.git"" git_clone_dir=""$git_clone_root/$app_name"" if [ ! -d ""$git_clone_dir"" ] ; then git clone $git_repo $git_clone_dir || die ""Unable to clone repository '$git_repo'"" up_to_date='false' else cd ""$git_clone_dir"" git reset --hard git clean -fd git remote update git checkout master rev_on_local=$(git rev-list --max-count=1 master) rev_on_origin=$(git rev-list --max-count=1 origin/master) if [ ""$rev_on_local"" == ""$rev_on_origin"" ] ; then up_to_date='true' else git pull origin master up_to_date='false' fi fi if [ ""$up_to_date"" == 'false' ] ; then chmod +x ""$git_clone_dir""/setup*.sh log ""* Uninstalling '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh uninstall ;; 'Ubuntu') ""$git_clone_dir""/setup.sh uninstall ;; esac sleep 2 log ""* Installing '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh install ;; 'Ubuntu') ""$git_clone_dir""/setup.sh install ;; esac fi done if [ ""$configuration_required"" == 'true' ] ; then configure_murano fi restart_murano } function configure_murano { if [ ! -f '/etc/murano-deployment/lab-binding.rc' ] ; then '/etc/murano-conductor/conductor-paste.ini') iniset 'filter:authtoken' 'auth_host' ""$LAB_HOST"" ""$config_file"" iniset 'filter:authtoken' 'admin_user' ""$ADMIN_USER"" ""$config_file"" iniset 'filter:authtoken' 'admin_password' ""$ADMIN_PASSWORD"" ""$config_file"" ;;} function restart_murano { for service_name in $murano_services ; do stop ""$service_name"" start ""$service_name"" done } #------------------------------------------------- mkdir -p $git_clone_root if [ -f /etc/redhat-release ] ; then os_version=$(cat /etc/redhat-release | cut -d ' ' -f 1) fi if [ -f /etc/lsb-release ] ; then os_version=$(cat /etc/lsb-release | grep DISTRIB_ID | cut -d '=' -f 2) fi if [ -z $os_version ] ; then die ""Unable to determine OS version. Exiting."" else log ""* OS version is '$os_version'""case $mode in 'install') install_murano ;; 'configure') configure_murano ;; esac"," mkdir -p $git_clone_root if [ -f /etc/redhat-release ] ; then os_version=$(cat /etc/redhat-release | cut -d ' ' -f 1) fi if [ -f /etc/lsb-release ] ; then os_version=$(cat /etc/lsb-release | grep DISTRIB_ID | cut -d '=' -f 2) fi if [ -z $os_version ] ; then die ""Unable to determine OS version. Exiting."" else log ""* OS version is '$os_version'"" fi configuration_required='false' for config_file in $murano_config_files ; do if [ ! -f ""$config_file"" ] ; then log ""! Required config file '$config_file' not exists. Murano should be configured before start."" configuration_required='true' fi done for app_name in $murano_components ; do log ""* Working with '$app_name'"" git_repo=""$git_prefix/$app_name.git"" git_clone_dir=""$git_clone_root/$app_name"" if [ ! -d ""$git_clone_dir"" ] ; then git clone $git_repo $git_clone_dir || die ""Unable to clone repository '$git_repo'"" up_to_date='false' else cd ""$git_clone_dir"" git reset --hard git clean -fd git remote update git checkout master rev_on_local=$(git rev-list --max-count=1 master) rev_on_origin=$(git rev-list --max-count=1 origin/master) if [ ""$rev_on_local"" == ""$rev_on_origin"" ] ; then up_to_date='true' else git pull origin master up_to_date='false' fi if [ ""$up_to_date"" == 'false' ] ; then chmod +x ""$git_clone_dir""/setup*.sh log ""* Uninstalling '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh uninstall ;; 'Ubuntu') ""$git_clone_dir""/setup.sh uninstall ;; esac sleep 2 log ""* Installing '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh install ;; 'Ubuntu') ""$git_clone_dir""/setup.sh install ;; esac fi done if [ ""$configuration_required"" == 'true' ] ; then if [ ! -f '/etc/murano-deployment/lab-binding.rc' ] ; then iniset 'filter:authtoken' 'auth_host' ""$LAB_HOST"" ""$config_file"" iniset 'filter:authtoken' 'admin_user' ""$ADMIN_USER"" ""$config_file"" iniset 'filter:authtoken' 'admin_password' ""$ADMIN_PASSWORD"" ""$config_file"" ;; '/etc/murano-conductor/conductor-paste.ini')for service_name in $murano_services ; do stop ""$service_name"" start ""$service_name"" done",114,90
openstack%2Fmurano-deployment~master~I24d672aa106675accdfbc3b46fe62a87894895bc,openstack/murano-deployment,master,I24d672aa106675accdfbc3b46fe62a87894895bc,murano-git-install updated.,MERGED,2013-07-19 11:07:26.000000000,2013-07-19 11:08:14.000000000,2013-07-19 11:08:14.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-19 11:07:26.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/f8a0da9eb07be1c205dc9f9032c55f0f67c831c7', 'message': 'murano-git-install updated.\n\nMurano configuration phase added.\n\nChange-Id: I24d672aa106675accdfbc3b46fe62a87894895bc\n'}]",0,37873,f8a0da9eb07be1c205dc9f9032c55f0f67c831c7,5,2,1,7562,,,0,"murano-git-install updated.

Murano configuration phase added.

Change-Id: I24d672aa106675accdfbc3b46fe62a87894895bc
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/73/37873/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,f8a0da9eb07be1c205dc9f9032c55f0f67c831c7,devbox-scripts-update,"#!/bin/bash mode=${1:-'install'}# ""/etc/murano-deployment/lab-binding.rc"" sample ################################################## #LAB_HOST='' # #AUTH_URL=""http://$LAB_HOST:5000/v2.0"" # #ADMIN_USER='' #ADMIN_PASSWORD='' # #RABBITMQ_LOGIN='' #RABBITMQ_PASSWORD='' #RABBITMQ_VHOST='/' ################################################## function iniset { local section=$1 local option=$2 local value=$3 local file=$4 if [ -z $section ] ; then sed -i -e ""s/^\($option[ \t]*=[ \t]*\).*$/\1$value/"" ""$file"" else sed -i -e ""/^\[$section\]/,/^\[.*\]/ s|^\($option[ \t]*=[ \t]*\).*$|\1$value|"" ""$file"" fi } if [ -f /etc/lsb-release ] ; then if [ ! -f '/etc/murano-deployment/lab-binding.rc' ] ; then log ""One or several configuraiton files were not found before installation was launched."" log ""Create '/etc/murano-dashboard/lab-binding.rc' or configure services individually."" die ""Murano components require configuration."" fi source /etc/murano-deployment/lab-binding.rc for config_file in $murano_config_files ; do if [ ! -f ""$config_file"" ] ; then cp ""$config_file.sample"" ""$config_file"" fi case ""$config_file"" in '/etc/murano-api/murano-api.conf') iniset 'rabbitmq' 'host' ""$LAB_HOST"" ""$config_file"" iniset 'rabbitmq' 'login' ""$RABBITMQ_LOGIN"" ""$config_file"" iniset 'rabbitmq' 'password' ""$RABBITMQ_PASSWORD"" ""$config_file"" iniset 'rabbitmq' 'virtual_host' ""$RABBITMQ_VHOST"" ""$config_file"" ;; '/etc/murano-conductor/conductor.conf') iniset 'filter:authtoken' 'auth_host' ""$LAB_HOST"" ""$config_file"" iniset 'filter:authtoken' 'admin_user' ""$ADMIN_USER"" ""$config_file"" iniset 'filter:authtoken' 'admin_password' ""$ADMIN_PASSWORD"" ""$config_file"" ;; '/etc/murano-conductor/conductor-paste.ini') iniset 'heat' 'auth_url' ""$AUTH_URL"" ""$config_file"" iniset 'rabbitmq' 'host' ""$LAB_HOST"" ""$config_file"" iniset 'rabbitmq' 'login' ""$RABBITMQ_LOGIN"" ""$config_file"" iniset 'rabbitmq' 'password' ""$RABBITMQ_PASSWORD"" ""$config_file"" iniset 'rabbitmq' 'virtual_host' ""$RABBITMQ_VHOST"" ""$config_file"" ;; '/etc/openstack-dashboard/local_settings') iniset '' 'OPENSTACK_HOST' ""$LAB_HOST"" ""$config_file"" ;; esac done","#!/bin/shmurano_config_dirs=""/etc/murano-api /etc/murano-conductor /etc/murano-dashboard""if [ -f /etc/lsb_release ] ; then die ""One or several configuraiton files were not found before installation started. Please confugure Murano before start services.""",68,4
openstack%2Fmurano-dashboard~master~I3f22aff9235a9e676cb1e525707e09c5dc43b486,openstack/murano-dashboard,master,I3f22aff9235a9e676cb1e525707e09c5dc43b486,Add availability_zone picking. Change flavor type return value.,MERGED,2013-07-19 11:00:34.000000000,2013-07-19 11:07:21.000000000,2013-07-19 11:07:21.000000000,"[{'_account_id': 3}, {'_account_id': 7226}]","[{'number': 1, 'created': '2013-07-19 11:00:34.000000000', 'files': ['muranodashboard/panel/views.py', 'muranodashboard/panel/forms.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/03404631aad2666dbc24bb8ce87e4fa3b763de30', 'message': 'Add availability_zone picking. Change flavor type return value.\n\nChange-Id: I3f22aff9235a9e676cb1e525707e09c5dc43b486\n'}]",0,37871,03404631aad2666dbc24bb8ce87e4fa3b763de30,5,2,1,7549,,,0,"Add availability_zone picking. Change flavor type return value.

Change-Id: I3f22aff9235a9e676cb1e525707e09c5dc43b486
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/71/37871/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/panel/views.py', 'muranodashboard/panel/forms.py']",2,03404631aad2666dbc24bb8ce87e4fa3b763de30,add_az,"from horizon import exceptions from openstack_dashboard.api.nova import novaclient flavor = forms.ChoiceField(label=_('Instance flavor')) availability_zone = forms.ChoiceField(label=_('Availability zone')) flavors = novaclient(request).flavors.list() self.fields['flavor'].choices = [(flavor.name, flavor.name) #TODO: uncomment this when custom filter for valid images will try: availability_zones = novaclient(request).availability_zones.list() except: availability_zones = [] exceptions.handle(request, _(""Unable to retrieve availability zones."")) self.fields['availability_zone'].choices = \ [(az.zoneName, az.zoneName) for az in availability_zones if az.zoneState]","from openstack_dashboard.api import nova as novaapi flavor = forms.ChoiceField(label=_('Instance flavor'), required=False) # az = forms.CharField(label=_('Availability zone'), required=False) flavors = novaapi.flavor_list(request) self.fields['flavor'].choices = [(flavor.id, ""%s"" % flavor.name) #TODO: uncomment this when custom filter for valid template will",20,10
openstack%2Fhorizon~master~I63d3a92cea4da042942540b0800b5c4e825983c5,openstack/horizon,master,I63d3a92cea4da042942540b0800b5c4e825983c5,Prevent an array index exception if server does not have an image.,MERGED,2013-07-18 19:01:04.000000000,2013-07-19 11:01:13.000000000,2013-07-19 11:01:13.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 1952}, {'_account_id': 2455}, {'_account_id': 6610}]","[{'number': 1, 'created': '2013-07-18 19:01:04.000000000', 'files': ['openstack_dashboard/api/nova.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ef8ca80344781c32e618281b70b59bb5e7dddac2', 'message': 'Prevent an array index exception if server does not have an image.\n\nChange-Id: I63d3a92cea4da042942540b0800b5c4e825983c5\nFixes: bug #1202784\n'}]",0,37746,ef8ca80344781c32e618281b70b59bb5e7dddac2,8,5,1,8191,,,0,"Prevent an array index exception if server does not have an image.

Change-Id: I63d3a92cea4da042942540b0800b5c4e825983c5
Fixes: bug #1202784
",git fetch https://review.opendev.org/openstack/horizon refs/changes/46/37746/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/api/nova.py'],1,ef8ca80344781c32e618281b70b59bb5e7dddac2,bug/1202784," if not self.image: return ""(not found)""",,2,0
openstack%2Fnova~master~I62b4009ef97ea47b20442a149ba172de4e343e15,openstack/nova,master,I62b4009ef97ea47b20442a149ba172de4e343e15,Make servers::update() use Instance.save() to do the work,MERGED,2013-06-30 16:12:27.000000000,2013-07-19 10:08:44.000000000,2013-07-19 10:08:41.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 5652}]","[{'number': 1, 'created': '2013-06-30 16:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b21bdd31ab66176b5c1821ca1d10d96b658e5c7', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 2, 'created': '2013-06-30 18:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d7081a388dcbedb4f309bd57ad273e0fe0915d7', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 3, 'created': '2013-07-02 15:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dfe64503bf383e88766493514cd94ccd189708b7', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 4, 'created': '2013-07-02 17:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9d09292f98a54fcbec5eaca7825d43dfb59ee50', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 5, 'created': '2013-07-02 22:06:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f2cf598c9a62e655b6cfbe760b84746fbbc7f66', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 6, 'created': '2013-07-03 00:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1b711bb26f6e257cdc6d8c1f6fba131b0747ab96', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 7, 'created': '2013-07-04 00:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/34d1592bf89e8e6658ed39de6b0b56217f6db728', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 8, 'created': '2013-07-05 23:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/029f3b9c6cb95232928a8a27ed89f7bb5a54f679', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 9, 'created': '2013-07-05 23:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c82610e21c58f9fcaf2698eff99635acfe938ca6', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 10, 'created': '2013-07-05 23:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1bd9aa3edc8574c4fc7d22419d42c0c2c833f24', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 11, 'created': '2013-07-08 17:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d158e1e57ac1e51fe41501583709fa7aa0f3ab8', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 12, 'created': '2013-07-08 20:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf0738c338848feb64a0a885e9691462f8d7bd1f', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 13, 'created': '2013-07-08 20:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce0dbedb649b17ee8e0564b9b112abc908249739', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 14, 'created': '2013-07-08 22:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/737fc6b95dd70280fa2679e157500bed85683efc', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 15, 'created': '2013-07-09 23:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42082199da9460d976bad34b9da6f6455f4cac7c', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 16, 'created': '2013-07-10 20:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/017605040f14d9f6ec15f336ebdbe8437606d661', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 17, 'created': '2013-07-10 23:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5cec14613bdc7e3eddf450699e498835590682c9', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 18, 'created': '2013-07-10 23:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d5ed8167e4f20171b01cd43b9729c3ec593359f', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 19, 'created': '2013-07-11 00:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4034058e8cc4bb2878b6cd12ac59b47912749ad7', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 20, 'created': '2013-07-11 05:56:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/302214dcae37259a3420382fbc66a0885a94136a', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 21, 'created': '2013-07-11 17:02:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6deaca3a5ea15bc9a48278412d5257f9d8188eab', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 22, 'created': '2013-07-11 19:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2086e845e1b2297ac91792807f088fa51500ded4', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 23, 'created': '2013-07-11 22:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd6188787b6add10b13cca38f6d1eaad11c11a42', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 24, 'created': '2013-07-12 01:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab571769c01c7a03b43a6e31acff391b8f459515', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 25, 'created': '2013-07-12 21:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47cc94dbf5824352bc4f41db9d55f917d86626ca', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 26, 'created': '2013-07-17 01:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a6bfc2084e190f62445f32e85ff0bbef1073d43a', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 27, 'created': '2013-07-17 16:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cba0bf3567292647ea3cf2b11321d11c7d1b7b81', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 28, 'created': '2013-07-17 23:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2618cfc85a93fc430af89422d75ca7f3856bec86', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 29, 'created': '2013-07-18 17:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30f848e0ca688e6eab6d3923effddc101c16b1bc', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}, {'number': 30, 'created': '2013-07-18 18:16:06.000000000', 'files': ['nova/tests/api/openstack/compute/test_servers.py', 'nova/tests/fake_network.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ae3711aafeae8b8abc2b403e16e9d3194e3dfbf4', 'message': ""Make servers::update() use Instance.save() to do the work\n\nThis makes the update() api call operate on the instance object\ndirectly, by calling update() and save(), instead of calling into\ncompute_api to do the work.\n\nThis requires an extension to a previous kludge for api_samples\nto make sure that the database gets updated in sync with the\nvalues we're stubbing out for network information.\n\nThis also requires a tweak to one of the tests to return an\nupdated fake instance object directly from the database, instead\nof just from the compute_api.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I62b4009ef97ea47b20442a149ba172de4e343e15\n""}]",2,35041,ae3711aafeae8b8abc2b403e16e9d3194e3dfbf4,88,7,30,4393,,,0,"Make servers::update() use Instance.save() to do the work

This makes the update() api call operate on the instance object
directly, by calling update() and save(), instead of calling into
compute_api to do the work.

This requires an extension to a previous kludge for api_samples
to make sure that the database gets updated in sync with the
values we're stubbing out for network information.

This also requires a tweak to one of the tests to return an
updated fake instance object directly from the database, instead
of just from the compute_api.

Related to blueprint compute-api-objects

Change-Id: I62b4009ef97ea47b20442a149ba172de4e343e15
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/35041/30 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/test_servers.py', 'nova/tests/fake_network.py', 'nova/api/openstack/compute/servers.py']",3,0b21bdd31ab66176b5c1821ca1d10d96b658e5c7,bp/compute-api-objects, instance.update(update_dict) instance.save()," self.compute_api.update(ctxt, instance, **update_dict) # FIXME(danms): Until compute_api.update() is object-aware, # we need to apply the updates to the instance object so # that views will return the new data instance.update(update_dict) ",22,7
openstack%2Fnova~master~I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f,openstack/nova,master,I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f,Make Instance.save() handle cells DB updates,MERGED,2013-07-04 00:26:34.000000000,2013-07-19 10:08:23.000000000,2013-07-19 10:08:21.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-04 00:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a2ee5721d06a40bc407f8f8862e57d53fc6d0927', 'message': 'Prep Instance.save() to handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 2, 'created': '2013-07-05 23:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0020b9eb6366391e0a1d6d7afeb8d0e555b3bfb9', 'message': 'Make Instance.save() to handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 3, 'created': '2013-07-05 23:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39ad427fac91087b12f969d2f78fc2b7461a7be2', 'message': 'Make Instance.save() to handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 4, 'created': '2013-07-05 23:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/910fca29f1e610e39720fa72ff12548e1b92c7ce', 'message': 'Make Instance.save() to handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 5, 'created': '2013-07-08 17:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f06b261d1e1e6e40285e35aeac245dacf751b29', 'message': 'Make Instance.save() to handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 6, 'created': '2013-07-08 20:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47a716f5036d164659d05f83b21eae4395d8615c', 'message': 'Make Instance.save() to handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 7, 'created': '2013-07-08 20:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62915206c7b24f8833da134d949f54e4e9b4c97b', 'message': 'Make Instance.save() to handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 8, 'created': '2013-07-08 22:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32e3b543c913a9bf070f026907a12b87a8859932', 'message': 'Make Instance.save() to handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 9, 'created': '2013-07-09 23:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3da6f2d9b15a98bc19c3d2615b8f16bea2750c8', 'message': 'Make Instance.save() to handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 10, 'created': '2013-07-10 20:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/133aeaf12ffdd5200ff7ef71d7d389524208e9e7', 'message': 'Make Instance.save() to handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 11, 'created': '2013-07-10 23:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d32ff9333b23d789337c0be57597baeb066baf79', 'message': 'Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 12, 'created': '2013-07-10 23:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9db151d4f56fe2b6988cddd655aaa4118ebc305b', 'message': 'Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 13, 'created': '2013-07-11 00:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6badd4c316273fabfd513ddb2ab746c06f0a51a2', 'message': 'Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 14, 'created': '2013-07-11 05:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/772e0dce25686f3b826c94e8aeec19222a77a788', 'message': 'Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 15, 'created': '2013-07-11 17:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2eb39d9bd1c1b5e8a96cdd9337a8e1f72ffc09c4', 'message': 'Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 16, 'created': '2013-07-11 19:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcbbafa168e13336491002f6055d5fc259a1d9cd', 'message': 'Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 17, 'created': '2013-07-11 22:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a24d3210da41671955b1fafe47b1a0a960a7ad9b', 'message': 'Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nAdding update_cells kwarg to db.instance_update_and_get_original() is a\ntemporary necessity as we transition to doing all updates via\nInstance.save().\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n'}, {'number': 18, 'created': '2013-07-12 01:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a748b3891ce19ed0675e9e85feccead95e7f121f', 'message': ""Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nInstance.save() needs to support expected_vm_state when saving changes.\nIt also needs to understand whether or not any task_state/vm_state\nchanges are coming from a forced-reset.  Normally we do not want to\nupdate child cells' view of vm_state and task_state, but forced-resets\nshould be sent down.\n\nAdds a new cells method for updating instances in child cells.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n""}, {'number': 19, 'created': '2013-07-12 21:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1011b3e71f5b99ec173a00ee472d551616aec742', 'message': ""Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nInstance.save() needs to support expected_vm_state when saving changes.\nIt also needs to understand whether or not any task_state/vm_state\nchanges are coming from a forced-reset.  Normally we do not want to\nupdate child cells' view of vm_state and task_state, but forced-resets\nshould be sent down.\n\nAdds a new cells method for updating instances in child cells.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n""}, {'number': 20, 'created': '2013-07-17 01:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c268716c1af6f95f96fb9a63083a7b10200a31d', 'message': ""Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nInstance.save() needs to support expected_vm_state when saving changes.\nIt also needs to understand whether or not any task_state/vm_state\nchanges are coming from a forced-reset.  Normally we do not want to\nupdate child cells' view of vm_state and task_state, but forced-resets\nshould be sent down.\n\nAdds a new cells method for updating instances in child cells.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n""}, {'number': 21, 'created': '2013-07-17 16:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19886b9f71cb7bffe1da49ddec08f1ebdb35af25', 'message': ""Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nInstance.save() needs to support expected_vm_state when saving changes.\nIt also needs to understand whether or not any task_state/vm_state\nchanges are coming from a forced-reset.  Normally we do not want to\nupdate child cells' view of vm_state and task_state, but forced-resets\nshould be sent down.\n\nAdds a new cells method for updating instances in child cells.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n""}, {'number': 22, 'created': '2013-07-17 23:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7208dc019ebb2b30b6b54321cadb86a8eb81fa27', 'message': ""Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nInstance.save() needs to support expected_vm_state when saving changes.\nIt also needs to understand whether or not any task_state/vm_state\nchanges are coming from a forced-reset.  Normally we do not want to\nupdate child cells' view of vm_state and task_state, but forced-resets\nshould be sent down.\n\nAdds a new cells method for updating instances in child cells.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n""}, {'number': 23, 'created': '2013-07-18 17:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/399ec1c85eeb5d655554880e9f215d38d953352d', 'message': ""Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nInstance.save() needs to support expected_vm_state when saving changes.\nIt also needs to understand whether or not any task_state/vm_state\nchanges are coming from a forced-reset.  Normally we do not want to\nupdate child cells' view of vm_state and task_state, but forced-resets\nshould be sent down.\n\nAdds a new cells method for updating instances in child cells.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n""}, {'number': 24, 'created': '2013-07-18 18:16:09.000000000', 'files': ['nova/tests/api/openstack/compute/test_servers.py', 'nova/tests/cells/test_cells_rpcapi.py', 'nova/tests/api/openstack/compute/test_server_actions.py', 'nova/tests/cells/test_cells_messaging.py', 'nova/tests/cells/test_cells_manager.py', 'nova/cells/messaging.py', 'nova/tests/compute/test_shelve.py', 'nova/tests/compute/test_compute.py', 'nova/tests/objects/test_instance.py', 'nova/cells/manager.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'nova/objects/instance.py', 'nova/db/api.py', 'nova/cells/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b4964ae82503104d895003047eddcb5e9eebfd06', 'message': ""Make Instance.save() handle cells DB updates\n\nThis adds support to Instance.save() to handle updating cells with\nchanges to the instance.\n\nInstance.save() needs to support expected_vm_state when saving changes.\nIt also needs to understand whether or not any task_state/vm_state\nchanges are coming from a forced-reset.  Normally we do not want to\nupdate child cells' view of vm_state and task_state, but forced-resets\nshould be sent down.\n\nAdds a new cells method for updating instances in child cells.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f\n""}]",4,35577,b4964ae82503104d895003047eddcb5e9eebfd06,67,6,24,1030,,,0,"Make Instance.save() handle cells DB updates

This adds support to Instance.save() to handle updating cells with
changes to the instance.

Instance.save() needs to support expected_vm_state when saving changes.
It also needs to understand whether or not any task_state/vm_state
changes are coming from a forced-reset.  Normally we do not want to
update child cells' view of vm_state and task_state, but forced-resets
should be sent down.

Adds a new cells method for updating instances in child cells.

Related to blueprint compute-api-objects

Change-Id: I228bc3e0288ca94fd30b91eaf1bc5b77bcdc249f
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/35577/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_instance.py', 'nova/cells/manager.py', 'nova/objects/instance.py', 'nova/cells/messaging.py', 'nova/db/api.py', 'nova/cells/rpcapi.py']",6,a2ee5721d06a40bc407f8f8862e57d53fc6d0927,bp/compute-api-objects," 1.11 - Adds instance_update_in_cell() def instance_update_in_cell(self, ctxt, cell_name, instance, expected_vm_state, expected_task_state, admin_state_reset): """"""Update an instance in a particular cell. This method takes a new-world instance object. """""" if not CONF.cells.enable: return self.cast(ctxt, self.make_msg('instance_update_in_cell', cell_name=cell_name, instance=instance, expected_vm_state=expected_vm_state, expected_task_state=expected_task_state, admin_state_reset=admin_state_reset), version='1.11')",,96,19
openstack%2Fnova~master~I256e495b214742f28d21ca9d779716f32c56f9bc,openstack/nova,master,I256e495b214742f28d21ca9d779716f32c56f9bc,Convert suspend/resume to use objects,MERGED,2013-07-01 23:22:35.000000000,2013-07-19 10:08:03.000000000,2013-07-19 10:08:00.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-01 23:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a77343a2cf8540276b573b5c69cc4da9801ea5f9', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts tests to be\nunit tests.  The original compute manager tests are left to test the case\nwhere an old-style dict is passed across RPC for backwards compatibility.\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 2, 'created': '2013-07-01 23:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26cd84325b1b24fef09817eeb4a39216dfc2e8f1', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 3, 'created': '2013-07-02 16:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e6eaca2c987129cb647214829e732987383906c', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 4, 'created': '2013-07-02 18:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0dd1e70a4e359e5146b5365df01da1cf4676efa0', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 5, 'created': '2013-07-02 22:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83be60a543ad395577371751e84dcdf3a053ecf1', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 6, 'created': '2013-07-03 00:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/707813b3e577e61d4394adc34a2e06a905d79f18', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 7, 'created': '2013-07-03 23:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01e2831176ec3ac4563a5e8794f2a83aada3328c', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 8, 'created': '2013-07-05 23:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed2c85794b3a0fab50072819dcae7d051de55040', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 9, 'created': '2013-07-08 17:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57b5302b40cfca015d38426407a8dc861a37ffcd', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 10, 'created': '2013-07-08 20:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/071ea9fbefcca293cd9bdbcaafeea8275b920332', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 11, 'created': '2013-07-09 23:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/afc3b7eb3c5818b2a33850add6a3fc84ee127d73', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 12, 'created': '2013-07-10 20:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48832fca7d311fd584406a1b2e733fd18df8c368', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 13, 'created': '2013-07-10 23:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5dfd142733d374fdde7838c697685b78a1b73027', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 14, 'created': '2013-07-10 23:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1942aecd199a78d7659f6d28e9af3de793fc4813', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 15, 'created': '2013-07-11 00:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d554e1f3fc8d4a2608159a389afe211932459865', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 16, 'created': '2013-07-11 05:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db73b4bcdd8cba7200a82065d3624b56e3a51a01', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 17, 'created': '2013-07-11 17:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96ec53bd6d40db1e6f11726d711af9ebb13b6341', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 18, 'created': '2013-07-11 19:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58173b1cba83be5b42c0fb98a62a8149e6f7336a', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 19, 'created': '2013-07-12 01:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/237b6aba266b3e56af6a055dc442d40456ef4af8', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 20, 'created': '2013-07-12 21:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c454396c0097ab937d12bd71e58b99a1a623ded6', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 21, 'created': '2013-07-17 01:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1bb8c0f32d86c8a24be19cb95d6da89dd280e56d', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 22, 'created': '2013-07-17 16:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38d0ae3e4c0be7daed608856381048ec1b43f570', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 23, 'created': '2013-07-17 23:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e53d416f0b161f8847c2877bcde5bb3c56b6c668', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 24, 'created': '2013-07-18 17:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cda6f01f07884251096eb1679e0267530049d679', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}, {'number': 25, 'created': '2013-07-18 18:16:08.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/admin_actions.py', 'nova/tests/api/openstack/compute/contrib/test_admin_actions.py', 'nova/tests/cells/test_cells_rpcapi.py', 'nova/tests/cells/test_cells_messaging.py', 'nova/tests/api/openstack/compute/plugins/v3/test_admin_actions.py', 'nova/tests/cells/test_cells_manager.py', 'nova/api/openstack/compute/contrib/admin_actions.py', 'nova/cells/messaging.py', 'nova/tests/compute/test_compute.py', 'nova/tests/compute/test_compute_api.py', 'nova/cells/manager.py', 'nova/compute/cells_api.py', 'nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/cells/rpcapi.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0165ff51f9b9a45dcab0418be24d3c8cab31ab5f', 'message': 'Convert suspend/resume to use objects\n\nSwitch suspend/resume to use objects.  This also converts the compute\nAPI tests to be unit tests.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I256e495b214742f28d21ca9d779716f32c56f9bc\n'}]",3,35224,0165ff51f9b9a45dcab0418be24d3c8cab31ab5f,70,6,25,1030,,,0,"Convert suspend/resume to use objects

Switch suspend/resume to use objects.  This also converts the compute
API tests to be unit tests.

Related to blueprint compute-api-objects

Change-Id: I256e495b214742f28d21ca9d779716f32c56f9bc
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/35224/13 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_api.py', 'nova/tests/compute/test_rpcapi.py', 'nova/cells/messaging.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py']",7,a77343a2cf8540276b573b5c69cc4da9801ea5f9,bp/compute-api-objects,," def test_suspend(self): # Ensure instance can be suspended. instance = jsonutils.to_primitive(self._create_fake_instance()) instance_uuid = instance['uuid'] self.compute.run_instance(self.context, instance=instance) self.assertEqual(instance['task_state'], None) self.compute_api.suspend(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(instance['task_state'], task_states.SUSPENDING) db.instance_destroy(self.context, instance['uuid']) def test_resume(self): # Ensure instance can be resumed (if suspended). instance = jsonutils.to_primitive(self._create_fake_instance()) self.compute.run_instance(self.context, instance=instance) db.instance_update(self.context, instance['uuid'], {'vm_state': vm_states.SUSPENDED}) instance = db.instance_get(self.context, instance['id']) self.assertEqual(instance['task_state'], None) self.compute_api.resume(self.context, instance) instance = db.instance_get_by_uuid(self.context, instance['uuid']) self.assertEqual(instance['task_state'], task_states.RESUMING) db.instance_destroy(self.context, instance['uuid']) ",84,68
openstack%2Fnova~master~If06e726e606f4a27c8ec4617400b728ce7112e3b,openstack/nova,master,If06e726e606f4a27c8ec4617400b728ce7112e3b,Raise exceptions when Spice/VNC are unavailable,MERGED,2013-06-20 00:09:42.000000000,2013-07-19 09:45:46.000000000,2013-07-19 09:45:44.000000000,"[{'_account_id': 3}, {'_account_id': 1525}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-06-20 00:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a839373053bb386526a05da2b7513b03644a30e', 'message': 'Allow automatic fallback of Spice to VNC consoles\n\nBug 1192724\n\nUpdated the libvirt driver to return a proper exception when we are\nunable to get the necessary info for Spice. Previously this would\nresult in a completely uncaught exception. The exception propagates\nthrough to the console API extention, which has a configurable\noption to fall back to VNC in the aforementioned case.\n\n    New config option:\n        auto_spice_fallback_to_vnc=True (default)\n\nChange-Id: If06e726e606f4a27c8ec4617400b728ce7112e3b\nFlags: DocImpact\n'}, {'number': 2, 'created': '2013-06-20 00:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83fc49e743948ae58b3423ef8c31085692fed1c2', 'message': 'Allow automatic fallback of Spice to VNC consoles\n\nBug 1192724\n\nUpdated the libvirt driver to return a proper exception when we are\nunable to get the necessary info for Spice. Previously this would\nresult in a completely uncaught exception. The exception propagates\nthrough to the console API extention, which catches it to make a VNC\nrequest as needed.\n\nChange-Id: If06e726e606f4a27c8ec4617400b728ce7112e3b\n'}, {'number': 3, 'created': '2013-06-20 00:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11661e2171ea93a9c7b438dfe51fc387b8a90f2e', 'message': 'Allow automatic fallback of Spice to VNC consoles\n\nBug 1192724\n\nUpdated the libvirt driver to return a proper exception when we are\nunable to get the necessary info for Spice. Previously this would\nresult in a completely uncaught exception. The exception propagates\nthrough to the console API extension, which catches it to make a VNC\nrequest as needed.\n\nChange-Id: If06e726e606f4a27c8ec4617400b728ce7112e3b\n'}, {'number': 4, 'created': '2013-06-20 08:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/071d3cb42c87d48ff1c554a4bc61c0f91f6fdb4c', 'message': 'Allow automatic fallback of Spice to VNC consoles\n\nBug 1192724\n\nUpdated the libvirt driver to return a proper exception when we are\nunable to get the necessary info for Spice. Previously this would\nresult in a completely uncaught exception. The exception propagates\nthrough to the console API extension, which catches it to make a VNC\nrequest as needed.\n\nChange-Id: If06e726e606f4a27c8ec4617400b728ce7112e3b\n'}, {'number': 5, 'created': '2013-07-02 00:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/612e1d8ad7642ed11219389d3e72e1e6aa468f53', 'message': 'Raise exceptions when Spice/VNC are unavailable\n\nBug 1192724\n\nBoth Spice and/or VNC may be enabled from the perspective of compute\nconfiguration but their actual availability can vary based on\nwhether either was enabled/disabled at the time the instance was\nlaunched. This patch raises a proper exception in this case, such\nthat clients (including Horizon) can either message the user or fall\nback.\n\nChange-Id: If06e726e606f4a27c8ec4617400b728ce7112e3b\n'}, {'number': 6, 'created': '2013-07-02 00:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dc40f7f8096b8c2dcf8a37180a4eba20c5c3f222', 'message': 'Raise exceptions when Spice/VNC are unavailable\n\nBug 1192724\n\nBoth Spice and/or VNC may be enabled from the perspective of compute\nconfiguration but their actual availability can vary based on\nwhether either was enabled/disabled at the time the instance was\nlaunched. This patch raises a proper exception in this case, such\nthat clients (including Horizon) can either message the user or fall\nback.\n\nChange-Id: If06e726e606f4a27c8ec4617400b728ce7112e3b\n'}, {'number': 7, 'created': '2013-07-18 01:14:03.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/exception.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cc8021df5fd04c0872bd0dece552c0e7e84b6a16', 'message': 'Raise exceptions when Spice/VNC are unavailable\n\nBug 1192724\n\nBoth Spice and/or VNC may be enabled from the perspective of compute\nconfiguration but their actual availability can vary based on\nwhether either was enabled/disabled at the time the instance was\nlaunched. This patch raises a proper exception in this case, such\nthat clients (including Horizon) can either message the user or fall\nback.\n\nChange-Id: If06e726e606f4a27c8ec4617400b728ce7112e3b\n'}]",3,33737,cc8021df5fd04c0872bd0dece552c0e7e84b6a16,37,6,7,1525,,,0,"Raise exceptions when Spice/VNC are unavailable

Bug 1192724

Both Spice and/or VNC may be enabled from the perspective of compute
configuration but their actual availability can vary based on
whether either was enabled/disabled at the time the instance was
launched. This patch raises a proper exception in this case, such
that clients (including Horizon) can either message the user or fall
back.

Change-Id: If06e726e606f4a27c8ec4617400b728ce7112e3b
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/33737/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/api/openstack/compute/contrib/consoles.py', 'nova/compute/manager.py']",3,7a839373053bb386526a05da2b7513b03644a30e,bug/1192724,,,23,2
openstack%2Fpython-glanceclient~master~I7ed4521698570cbae9c20e69ddca8b11b57c65ad,openstack/python-glanceclient,master,I7ed4521698570cbae9c20e69ddca8b11b57c65ad,Increase default page_size value,MERGED,2013-07-11 18:05:39.000000000,2013-07-19 09:45:42.000000000,2013-07-19 09:45:42.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2537}, {'_account_id': 4463}, {'_account_id': 6159}, {'_account_id': 7780}]","[{'number': 1, 'created': '2013-07-11 18:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/25dc77899fa76beae6287f04a659a1da552cfa8a', 'message': ""Increase default page_size value\n\nThis is a temporary solution. Increasing the default page size (which is being\nused everytime, since the client is ignoring nova's --limit param). This should\ndecrease the number of queries that glance does when nova requests an image\ndetail list.\n\nBug 1200257\n\nChange-Id: I7ed4521698570cbae9c20e69ddca8b11b57c65ad\n""}, {'number': 2, 'created': '2013-07-12 14:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/97ed0cb212855c3bc8b923c2192831bc30b87bd2', 'message': ""Increase default page_size value\n\nThis is a temporary solution. Increasing the default page size (which is being\nused everytime, since the client is ignoring nova's --limit param). This should\ndecrease the number of queries that glance does when nova requests an image\ndetail list.\n\nBug 1200257\n\nChange-Id: I7ed4521698570cbae9c20e69ddca8b11b57c65ad\n""}, {'number': 3, 'created': '2013-07-15 15:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/8282de4ee06ebf66c4e96effbd4a1f3ba06cb5b2', 'message': ""Increase default page_size value\n\nThis is a temporary solution. Increasing the default page size (which is being\nused everytime, since the client is ignoring nova's --limit param). This should\ndecrease the number of queries that glance does when nova requests an image\ndetail list.\n\nBug 1200257\n\nChange-Id: I7ed4521698570cbae9c20e69ddca8b11b57c65ad\n""}, {'number': 4, 'created': '2013-07-16 15:46:53.000000000', 'files': ['glanceclient/v1/images.py', 'tests/v1/test_images.py', 'glanceclient/v2/images.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/02116565d358a4fa254217779fef82b14b38d8ca', 'message': ""Increase default page_size value\n\nThis is a temporary solution. Increasing the default page size (which is being\nused everytime, since the client is ignoring nova's --limit param). This should\ndecrease the number of queries that glance does when nova requests an image\ndetail list.\n\nBug 1200257\n\nChange-Id: I7ed4521698570cbae9c20e69ddca8b11b57c65ad\n""}]",2,36705,02116565d358a4fa254217779fef82b14b38d8ca,19,6,4,7780,,,0,"Increase default page_size value

This is a temporary solution. Increasing the default page size (which is being
used everytime, since the client is ignoring nova's --limit param). This should
decrease the number of queries that glance does when nova requests an image
detail list.

Bug 1200257

Change-Id: I7ed4521698570cbae9c20e69ddca8b11b57c65ad
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/05/36705/1 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/v1/images.py', 'glanceclient/v2/images.py']",2,25dc77899fa76beae6287f04a659a1da552cfa8a,bug/1200257,DEFAULT_PAGE_SIZE = 100,DEFAULT_PAGE_SIZE = 20,2,2
openstack%2Fdevstack~master~I94e1a078d12f1e1b52030b25dc64aee106ceb783,openstack/devstack,master,I94e1a078d12f1e1b52030b25dc64aee106ceb783,Add per service WRAPPER variables for debugging,ABANDONED,2013-06-21 08:50:13.000000000,2013-07-19 09:33:36.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-06-21 08:50:13.000000000', 'files': ['lib/ceilometer', 'lib/cinder', 'lib/nova', 'lib/quantum_thirdparty/ryu', 'lib/heat', 'lib/keystone', 'lib/swift', 'lib/glance', 'lib/quantum'], 'web_link': 'https://opendev.org/openstack/devstack/commit/dcba77688ff5794edeb6ab3df28b48a41e255d34', 'message': 'Add per service WRAPPER variables for debugging\n\nThe WRAPPER-<service-screen-name> variables can be defined\nas an environment variable or they can be in the localrc.\n\nYou can use different wrappers with different\n options for different services.\n\nChange-Id: I94e1a078d12f1e1b52030b25dc64aee106ceb783\n'}]",0,33932,dcba77688ff5794edeb6ab3df28b48a41e255d34,10,5,1,5803,,,0,"Add per service WRAPPER variables for debugging

The WRAPPER-<service-screen-name> variables can be defined
as an environment variable or they can be in the localrc.

You can use different wrappers with different
 options for different services.

Change-Id: I94e1a078d12f1e1b52030b25dc64aee106ceb783
",git fetch https://review.opendev.org/openstack/devstack refs/changes/32/33932/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ceilometer', 'lib/cinder', 'lib/nova', 'lib/heat', 'lib/keystone', 'lib/quantum_thirdparty/ryu', 'lib/swift', 'lib/glance', 'lib/quantum']",9,dcba77688ff5794edeb6ab3df28b48a41e255d34,master," screen_it q-svc ""cd $QUANTUM_DIR && ${WRAPPER_Q_SVC} python $QUANTUM_DIR/bin/quantum-server $CFG_FILE_OPTIONS"" screen_it q-agt ""cd $QUANTUM_DIR && ${WRAPPER_Q_AGT} python $AGENT_BINARY --config-file $QUANTUM_CONF --config-file /$Q_PLUGIN_CONF_FILE"" screen_it q-dhcp ""cd $QUANTUM_DIR && ${WRAPPER_Q_DHCP} python $AGENT_DHCP_BINARY --config-file $QUANTUM_CONF --config-file=$Q_DHCP_CONF_FILE"" screen_it q-l3 ""cd $QUANTUM_DIR && ${WRAPPER_Q_L3} python $AGENT_L3_BINARY --config-file $QUANTUM_CONF --config-file=$Q_L3_CONF_FILE"" screen_it q-meta ""cd $QUANTUM_DIR && ${WRAPPER_Q_META} python $AGENT_META_BINARY --config-file $QUANTUM_CONF --config-file=$Q_META_CONF_FILE"" screen_it q-domua ""cd $QUANTUM_DIR && ${WRAPPER_Q_DOMUA} python $AGENT_BINARY --config-file $QUANTUM_CONF --config-file /$Q_PLUGIN_CONF_FILE.domU"" screen_it q-lbaas ""cd $QUANTUM_DIR && ${WRAPPER_Q_LBAAS} python $AGENT_LBAAS_BINARY --config-file $QUANTUM_CONF --config-file=$LBAAS_AGENT_CONF_FILENAME"""," screen_it q-svc ""cd $QUANTUM_DIR && python $QUANTUM_DIR/bin/quantum-server $CFG_FILE_OPTIONS"" screen_it q-agt ""cd $QUANTUM_DIR && python $AGENT_BINARY --config-file $QUANTUM_CONF --config-file /$Q_PLUGIN_CONF_FILE"" screen_it q-dhcp ""cd $QUANTUM_DIR && python $AGENT_DHCP_BINARY --config-file $QUANTUM_CONF --config-file=$Q_DHCP_CONF_FILE"" screen_it q-l3 ""cd $QUANTUM_DIR && python $AGENT_L3_BINARY --config-file $QUANTUM_CONF --config-file=$Q_L3_CONF_FILE"" screen_it q-meta ""cd $QUANTUM_DIR && python $AGENT_META_BINARY --config-file $QUANTUM_CONF --config-file=$Q_META_CONF_FILE"" screen_it q-domua ""cd $QUANTUM_DIR && python $AGENT_BINARY --config-file $QUANTUM_CONF --config-file /$Q_PLUGIN_CONF_FILE.domU"" screen_it q-lbaas ""cd $QUANTUM_DIR && python $AGENT_LBAAS_BINARY --config-file $QUANTUM_CONF --config-file=$LBAAS_AGENT_CONF_FILENAME""",40,40
openstack%2Fmurano-dashboard~master~Iba44536f03e080c4b72400d26e1f5c937262e11d,openstack/murano-dashboard,master,Iba44536f03e080c4b72400d26e1f5c937262e11d,Fix typo,MERGED,2013-07-19 09:24:25.000000000,2013-07-19 09:33:29.000000000,2013-07-19 09:33:29.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-07-19 09:24:25.000000000', 'files': ['muranodashboard/templates/_create_service_wizard.html'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/b8fa4e09337b2c8338cf1c2d12e32b4426991f48', 'message': 'Fix typo\n\nChange-Id: Iba44536f03e080c4b72400d26e1f5c937262e11d\n'}]",0,37859,b8fa4e09337b2c8338cf1c2d12e32b4426991f48,5,2,1,7549,,,0,"Fix typo

Change-Id: Iba44536f03e080c4b72400d26e1f5c937262e11d
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/59/37859/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/templates/_create_service_wizard.html'],1,b8fa4e09337b2c8338cf1c2d12e32b4426991f48,, <p>Set flavor for an instance on which service would be created.</p>, <p>Set flavor for an instance on witch service would be created.</p>,1,1
openstack%2Fmurano-dashboard~master~I68576607cd4d34743f7b12c3ed6f50aaf631d961,openstack/murano-dashboard,master,I68576607cd4d34743f7b12c3ed6f50aaf631d961,Split checkbox input and label in one line,MERGED,2013-07-19 09:04:06.000000000,2013-07-19 09:07:48.000000000,2013-07-19 09:07:48.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-07-19 09:04:06.000000000', 'files': ['muranodashboard/templatetags/__init__.py', 'muranodashboard/templates/_horizon_form_fields.html', 'muranodashboard/templatetags/custom_filters.py', 'muranodashboard/panel/forms.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/e8971b77ca2d093a452939c46006458d83c36024', 'message': 'Split checkbox input and label in one line\n\nChange-Id: I68576607cd4d34743f7b12c3ed6f50aaf631d961\n'}]",0,37855,e8971b77ca2d093a452939c46006458d83c36024,5,2,1,7549,,,0,"Split checkbox input and label in one line

Change-Id: I68576607cd4d34743f7b12c3ed6f50aaf631d961
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/55/37855/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/templatetags/__init__.py', 'muranodashboard/templates/_horizon_form_fields.html', 'muranodashboard/templatetags/custom_filters.py', 'muranodashboard/panel/forms.py']",4,e8971b77ca2d093a452939c46006458d83c36024,checkbox_in_the_same_line, #add style to split label and checkbox mixed_mode.widget.attrs['style'] = 'float: left; \ width: auto; \ margin-right: 10px;',,20,1
openstack%2Fneutron~master~I59394fa2c4d8cee84ce7040a9d03288ec1e4bab4,openstack/neutron,master,I59394fa2c4d8cee84ce7040a9d03288ec1e4bab4,Fix revision branches appeared after merging recent patches,MERGED,2013-07-18 20:45:24.000000000,2013-07-19 08:55:21.000000000,2013-07-19 08:55:20.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-18 20:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/94b4e2e351c9aa34c39ffbf557cfdc5ba4266169', 'message': 'fix revision branches appeared after merging recent patches\n\nChange-Id: I59394fa2c4d8cee84ce7040a9d03288ec1e4bab4\n'}, {'number': 2, 'created': '2013-07-18 21:31:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/54af34e1816adb17fc50a10e1676f3425b62e945', 'message': 'fix revision branches appeared after merging recent patches\n\nfixes bug 1202859\n\nChange-Id: I59394fa2c4d8cee84ce7040a9d03288ec1e4bab4\n'}, {'number': 3, 'created': '2013-07-18 21:39:28.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/2032abe8edac_lbaas_add_status_des.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/713838e24cfd1a0cfdbedf20b08da15e82cd60e3', 'message': 'Fix revision branches appeared after merging recent patches\n\nThe branch was introduced with ""Add status description field for lbaas objects""\n\nfixes bug 1202859\n\nChange-Id: I59394fa2c4d8cee84ce7040a9d03288ec1e4bab4\n'}]",2,37772,713838e24cfd1a0cfdbedf20b08da15e82cd60e3,20,5,3,6072,,,0,"Fix revision branches appeared after merging recent patches

The branch was introduced with ""Add status description field for lbaas objects""

fixes bug 1202859

Change-Id: I59394fa2c4d8cee84ce7040a9d03288ec1e4bab4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/37772/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/versions/2032abe8edac_lbaas_add_status_des.py'],1,94b4e2e351c9aa34c39ffbf557cfdc5ba4266169,bug/1202859,Revises: 477a4488d3f4down_revision = '477a4488d3f4',Revises: b7a8863760edown_revision = 'b7a8863760e',2,2
openstack%2Fmurano-deployment~master~I74d66eb19662a0d5f62fe18227222320e3272905,openstack/murano-deployment,master,I74d66eb19662a0d5f62fe18227222320e3272905,murano-git-install updated.,MERGED,2013-07-19 08:38:59.000000000,2013-07-19 08:43:58.000000000,2013-07-19 08:43:58.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-19 08:38:59.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/0a0c7fff76c193242fa8cebbf30f493c4ebc8d78', 'message': 'murano-git-install updated.\n\nThe script now can detect if remote branch is newer.\nIn this case local services will be restarted.\n\nChange-Id: I74d66eb19662a0d5f62fe18227222320e3272905\n'}]",0,37853,0a0c7fff76c193242fa8cebbf30f493c4ebc8d78,5,2,1,7562,,,0,"murano-git-install updated.

The script now can detect if remote branch is newer.
In this case local services will be restarted.

Change-Id: I74d66eb19662a0d5f62fe18227222320e3272905
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/53/37853/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,0a0c7fff76c193242fa8cebbf30f493c4ebc8d78,devbox-script-update," up_to_date='false' rev_on_local=$(git rev-list --max-count=1 master) rev_on_origin=$(git rev-list --max-count=1 origin/master) if [ ""$rev_on_local"" == ""$rev_on_origin"" ] ; then up_to_date='true' else git pull origin master up_to_date='false' fi if [ ""$up_to_date"" == 'false' ] ; then chmod +x ""$git_clone_dir""/setup*.sh log ""* Uninstalling '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh uninstall ;; 'Ubuntu') ""$git_clone_dir""/setup.sh uninstall ;; esac sleep 2 log ""* Installing '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh install ;; 'Ubuntu') ""$git_clone_dir""/setup.sh install ;; esac fi"," git pull origin master chmod +x ""$git_clone_dir""/setup*.sh log ""* Uninstalling '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh uninstall ;; 'Ubuntu') ""$git_clone_dir""/setup.sh uninstall ;; esac sleep 2 log ""* Installing '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh install ;; 'Ubuntu') ""$git_clone_dir""/setup.sh install ;; esac",36,24
openstack%2Fsahara~master~I836df5821acdfae9095cdb469859bbd6379439a7,openstack/sahara,master,I836df5821acdfae9095cdb469859bbd6379439a7,Added __init__.py to migration directory,MERGED,2013-07-19 08:23:33.000000000,2013-07-19 08:33:43.000000000,2013-07-19 08:33:42.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}]","[{'number': 1, 'created': '2013-07-19 08:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0d29ca0450fa35e24bdd96ede98c652462a69124', 'message': 'Added __init__.py to migration directory\n\nChange-Id: I836df5821acdfae9095cdb469859bbd6379439a7\nFixes: bug #1201956\n'}, {'number': 2, 'created': '2013-07-19 08:25:17.000000000', 'files': ['savanna/db/migration/alembic_migrations/__init__.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/e9eb47589155a25c2969a38ca639686304ffa583', 'message': 'Added __init__.py to migration directory\n\nFixes: bug #1201956\n\nChange-Id: I836df5821acdfae9095cdb469859bbd6379439a7\n'}]",0,37850,e9eb47589155a25c2969a38ca639686304ffa583,7,3,2,7132,,,0,"Added __init__.py to migration directory

Fixes: bug #1201956

Change-Id: I836df5821acdfae9095cdb469859bbd6379439a7
",git fetch https://review.opendev.org/openstack/sahara refs/changes/50/37850/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/db/migration/alembic_migrations/__init__.py'],1,0d29ca0450fa35e24bdd96ede98c652462a69124,bug/1201956,,,0,0
openstack%2Fheat~master~Iad2a9aaad2e9f1dc3cbeb509c822a61427f12817,openstack/heat,master,Iad2a9aaad2e9f1dc3cbeb509c822a61427f12817,Move url_for into heat_keystoneclient.,MERGED,2013-07-18 01:48:14.000000000,2013-07-19 08:32:34.000000000,2013-07-19 08:32:34.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-18 01:48:14.000000000', 'files': ['heat/tests/fakes.py', 'heat/common/heat_keystoneclient.py', 'heat/engine/clients.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b02b8260831ee2ab8fed1ba22ab947a499e1a003', 'message': 'Move url_for into heat_keystoneclient.\n\nThis allows faking of this call, and removes one instance of\naccessing the encapsulated keystone client.\n\nChange-Id: Iad2a9aaad2e9f1dc3cbeb509c822a61427f12817\n'}]",0,37602,b02b8260831ee2ab8fed1ba22ab947a499e1a003,6,3,1,4571,,,0,"Move url_for into heat_keystoneclient.

This allows faking of this call, and removes one instance of
accessing the encapsulated keystone client.

Change-Id: Iad2a9aaad2e9f1dc3cbeb509c822a61427f12817
",git fetch https://review.opendev.org/openstack/heat refs/changes/02/37602/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/fakes.py', 'heat/common/heat_keystoneclient.py', 'heat/engine/clients.py']",3,b02b8260831ee2ab8fed1ba22ab947a499e1a003,bp/auth-token-only, return self.keystone().url_for(**kwargs), return self.keystone().client.service_catalog.url_for(**kwargs),7,1
openstack%2Fheat~master~I3c54ec76a4d2bfd03cf60b70c422bc6269af01c9,openstack/heat,master,I3c54ec76a4d2bfd03cf60b70c422bc6269af01c9,Test utils dummy_context for tests that need one.,MERGED,2013-07-18 01:48:14.000000000,2013-07-19 08:24:10.000000000,2013-07-19 08:24:10.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-18 01:48:14.000000000', 'files': ['heat/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/808e34ee152a0ecb4c9c946fe1383986304cf59e', 'message': 'Test utils dummy_context for tests that need one.\n\nChange-Id: I3c54ec76a4d2bfd03cf60b70c422bc6269af01c9\n'}]",0,37601,808e34ee152a0ecb4c9c946fe1383986304cf59e,6,3,1,4571,,,0,"Test utils dummy_context for tests that need one.

Change-Id: I3c54ec76a4d2bfd03cf60b70c422bc6269af01c9
",git fetch https://review.opendev.org/openstack/heat refs/changes/01/37601/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/utils.py'],1,808e34ee152a0ecb4c9c946fe1383986304cf59e,bp/auth-token-only,"def dummy_context(user='test_username', tenant_id='test_tenant_id', password='password', roles=[]): return context.RequestContext.from_dict({ 'tenant_id': tenant_id, 'tenant': 'test_tenant', 'username': user, 'password': password, 'roles': roles, 'auth_url': 'http://localhost:5000/v2.0' }) def parse_stack(t, params={}, stack_name='test_stack', stack_id=None): ctx = dummy_context()","def parse_stack(t, params={}, stack_name='test_stack', stack_id=None): ctx = context.RequestContext.from_dict({'tenant_id': 'test_tenant', 'tenant': 'test_tenant', 'username': 'test_username', 'password': 'password', 'auth_url': 'http://localhost:5000/v2.0'})",13,6
openstack%2Fheat~master~Ic4ee82edec842ee756b104a36dfef28bf3f89717,openstack/heat,master,Ic4ee82edec842ee756b104a36dfef28bf3f89717,Handle InstanceType change in Instance.handle_update,MERGED,2013-07-16 13:35:07.000000000,2013-07-19 08:22:16.000000000,2013-07-19 08:22:15.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6800}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-07-16 13:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a86e597356bf18f55d123fa3e5bdaa73139a2beb', 'message': 'Handle InstanceType change in Instance.handle_update\n\nMake a resize API call against Nova if the InstanceType of an Instance\nresource is change via a resource update.\n\nImplements: blueprint instance-resize-update-stack\nChange-Id: Ic4ee82edec842ee756b104a36dfef28bf3f89717\n'}, {'number': 2, 'created': '2013-07-16 13:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/439f93947a26c52b0e748004151f6f6290407d96', 'message': 'Handle InstanceType change in Instance.handle_update\n\nMake a resize API call against Nova if the InstanceType of an Instance\nresource is change via a resource update.\n\nImplements: blueprint instance-resize-update-stack\nChange-Id: Ic4ee82edec842ee756b104a36dfef28bf3f89717\n'}, {'number': 3, 'created': '2013-07-16 14:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/32a48070859f33cae2b4975438e122cb3ecb3ec3', 'message': 'Handle InstanceType change in Instance.handle_update\n\nMake a resize API call against Nova if the InstanceType of an Instance\nresource is change via a resource update.\n\nImplements: blueprint instance-resize-update-stack\nChange-Id: Ic4ee82edec842ee756b104a36dfef28bf3f89717\n'}, {'number': 4, 'created': '2013-07-16 15:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e6c7c05de924d592fb82301ae9a5ffe822adb58e', 'message': 'Handle InstanceType change in Instance.handle_update\n\nMake a resize API call against Nova if the InstanceType of an Instance\nresource is change via a resource update.\n\nImplements: blueprint instance-resize-update-stack\nChange-Id: Ic4ee82edec842ee756b104a36dfef28bf3f89717\n'}, {'number': 5, 'created': '2013-07-18 16:29:32.000000000', 'files': ['heat/tests/test_instance.py', 'heat/engine/resources/instance.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/60a1f0c47122cec0601885095ccffbdc13e77f5b', 'message': 'Handle InstanceType change in Instance.handle_update\n\nMake a resize API call against Nova if the InstanceType of an Instance\nresource is change via a resource update.\n\nImplements: blueprint instance-resize-update-stack\nChange-Id: Ic4ee82edec842ee756b104a36dfef28bf3f89717\n'}]",3,37246,60a1f0c47122cec0601885095ccffbdc13e77f5b,17,6,5,7385,,,0,"Handle InstanceType change in Instance.handle_update

Make a resize API call against Nova if the InstanceType of an Instance
resource is change via a resource update.

Implements: blueprint instance-resize-update-stack
Change-Id: Ic4ee82edec842ee756b104a36dfef28bf3f89717
",git fetch https://review.opendev.org/openstack/heat refs/changes/46/37246/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_instance.py', 'heat/tests/v1_1/fakes.py', 'heat/engine/resources/instance.py']",3,a86e597356bf18f55d123fa3e5bdaa73139a2beb,bp/instance-resize-update-stack,"from heat.openstack.common.gettextutils import _ # template keys supported for handle_update update_allowed_keys = ('Metadata', 'InstanceType') self.metadata = tmpl_diff['Metadata'] if 'InstanceType' in tmpl_diff: flavor = tmpl_diff['InstanceType'] server = self.nova().servers.get(self.resource_id) server.resize(flavor) scheduler.TaskRunner(self._check_resize, server, flavor)() def _check_resize(self, server, flavor): """""" Verify that the server is properly resized. If that's the case, confirm the resize, if not revert it or raise an error. """""" yield server.get() while server.status == 'RESIZE': yield server.get() if server.status == 'VERIFY_RESIZE': server.confirm_resize() elif server.status == 'REVERT_RESIZE': server.revert_resize() raise exception.Error( ""Resizing to '%s' reverted"" % (flavor,)) else: raise exception.Error( ""Resizing to '%s' failed, status '%s'"" % ( flavor, server.status))"," # template keys supported for handle_update, note trailing comma # is required for a single item to get a tuple not a string update_allowed_keys = ('Metadata',) self.metadata = tmpl_diff.get('Metadata', {})",126,4
openstack%2Fmurano-deployment~master~I44568f9821d7b25ce97bf488bfa2de91514c0db4,openstack/murano-deployment,master,I44568f9821d7b25ce97bf488bfa2de91514c0db4,murano-git-install.sh added.,MERGED,2013-07-19 08:11:19.000000000,2013-07-19 08:20:43.000000000,2013-07-19 08:20:43.000000000,"[{'_account_id': 3}, {'_account_id': 7562}, {'_account_id': 7613}]","[{'number': 1, 'created': '2013-07-19 08:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/1327b2746e8342c16d6f360c9c9dcb02f65e2f1e', 'message': 'murano-git-install.sh added.\n\nThis script simplifies install/update operations for Murano components.\n\nChange-Id: I44568f9821d7b25ce97bf488bfa2de91514c0db4\n'}, {'number': 2, 'created': '2013-07-19 08:20:17.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/dca13ee4addc6293921a1551d1c89367dd68433e', 'message': 'murano-git-install.sh added.\n\nThis script simplifies install/update operations for Murano components.\n\nChange-Id: I44568f9821d7b25ce97bf488bfa2de91514c0db4\n'}]",0,37847,dca13ee4addc6293921a1551d1c89367dd68433e,8,3,2,7562,,,0,"murano-git-install.sh added.

This script simplifies install/update operations for Murano components.

Change-Id: I44568f9821d7b25ce97bf488bfa2de91514c0db4
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/47/37847/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,1327b2746e8342c16d6f360c9c9dcb02f65e2f1e,murano-git-install-script,"#!/bin/sh curr_dir=$(cd $(dirname ""$0"") && pwd) murano_components=""murano-api murano-conductor python-muranoclient murano-dashboard"" murano_services=""murano-api murano-conductor"" murano_config_dirs=""/etc/murano-api /etc/murano-conductor /etc/murano-dashboard"" murano_config_files='/etc/murano-api/murano-api.conf /etc/murano-api/murano-api-paste.ini /etc/murano-conductor/conductor.conf /etc/murano-conductor/conductor-paste.ini /etc/openstack-dashboard/local_settings' git_prefix=""https://github.com/stackforge"" git_clone_root='/opt/git' os_version='' function die { printf ""\n==============================\n"" printf ""$@"" printf ""\n==============================\n"" exit 1 } function log { printf ""$@\n"" } mkdir -p $git_clone_root if [ -f /etc/redhat-release ] ; then os_version=$(cat /etc/redhat-release | cut -d ' ' -f 1) fi if [ -f /etc/lsb_release ] ; then os_version=$(cat /etc/lsb-release | grep DISTRIB_ID | cut -d '=' -f 2) fi if [ -z $os_version ] ; then die ""Unable to determine OS version. Exiting."" else log ""* OS version is '$os_version'"" fi configuration_required='false' for config_file in $murano_config_files ; do if [ ! -f ""$config_file"" ] ; then log ""! Required config file '$config_file' not exists. Murano should be configured before start."" configuration_required='true' fi done for app_name in $murano_components ; do log ""* Working with '$app_name'"" git_repo=""$git_prefix/$app_name.git"" git_clone_dir=""$git_clone_root/$app_name"" if [ ! -d ""$git_clone_dir"" ] ; then git clone $git_repo $git_clone_dir || die ""Unable to clone repository '$git_repo'"" else cd ""$git_clone_dir"" git reset --hard git clean -fd git remote update git checkout master git pull origin master fi chmod +x ""$git_clone_dir""/setup*.sh log ""* Uninstalling '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh uninstall ;; 'Ubuntu') ""$git_clone_dir""/setup.sh uninstall ;; esac sleep 2 log ""* Installing '$app_name' ..."" case $os_version in 'CentOS') ""$git_clone_dir""/setup-centos.sh install ;; 'Ubuntu') ""$git_clone_dir""/setup.sh install ;; esac done if [ ""$configuration_required"" == 'true' ] ; then die ""One or several configuraiton files were not found before installation started. Please confugure Murano before start services."" fi for service_name in $murano_services ; do restart ""$service_name"" done ",,107,0
openstack%2Fmurano-dashboard~master~I8d0cd2e98a395335bbd223bcead94ee9cf176790,openstack/murano-dashboard,master,I8d0cd2e98a395335bbd223bcead94ee9cf176790,Convert mixedModeAuth from str to bool,MERGED,2013-07-18 15:23:28.000000000,2013-07-19 07:49:47.000000000,2013-07-19 07:49:47.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7549}]","[{'number': 1, 'created': '2013-07-18 15:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/231d0d873b7435723cc32c5e7719c4bd3b8888dd', 'message': 'Convert mixedModeAuth from str to bool\n\nChange-Id: I8d0cd2e98a395335bbd223bcead94ee9cf176790\n'}, {'number': 2, 'created': '2013-07-18 15:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f2d82cbe738c4b645859476b51153f59b24b30b9', 'message': 'Convert mixedModeAuth from str to bool\n\nChange-Id: I8d0cd2e98a395335bbd223bcead94ee9cf176790\n'}, {'number': 3, 'created': '2013-07-18 15:28:38.000000000', 'files': ['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/9f7f7853581dfe0159d8b06cfc87ad0cce17afab', 'message': 'Convert mixedModeAuth from str to bool\n\nChange-Id: I8d0cd2e98a395335bbd223bcead94ee9cf176790\n'}]",0,37701,9f7f7853581dfe0159d8b06cfc87ad0cce17afab,12,3,3,7549,,,0,"Convert mixedModeAuth from str to bool

Change-Id: I8d0cd2e98a395335bbd223bcead94ee9cf176790
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/01/37701/2 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/views.py'],1,231d0d873b7435723cc32c5e7719c4bd3b8888dd,disable_sa_if_checked," mixed_mode = step1_data.get('mixed_mode', False)"," mixed_mode = str( step1_data.get('mixed_mode', ''))",1,3
openstack%2Fneutron~master~I4ca1148e81fdb39bf6b58eef806536439e9f0c6f,openstack/neutron,master,I4ca1148e81fdb39bf6b58eef806536439e9f0c6f,Add support for the agent extension to NVP Plugin.,MERGED,2013-07-06 16:06:39.000000000,2013-07-19 06:39:36.000000000,2013-07-19 06:39:35.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 5948}]","[{'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3fe19ecf638b2fbcdf187d66e5b1d01d2bf89c40', 'message': 'Add support for the agent extension to NVP Plugin.\n\nOf DHCP and L3 agents, NVP uses DHCP; This patch adds support\nfor the extension to this plugin.\n\nImplements blueprint nvp-agent-scheduler-extension\n\nChange-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f\n'}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/843dc8a73254e60b6ce8abedbdda68257f1935b9', 'message': 'Add support for the agent extension to NVP Plugin.\n\nOf DHCP and L3 agents, NVP uses DHCP; This patch adds support\nfor the extension to this plugin, however L3 agent specific\nmethods are overriden to raise NotImplementedError.\n\nWith this patch we also avoid masking NotImplementedError(s).\nPreviously, a catch-all clause returned 500, and it makes\nsense to distinguish between genuine 500 errors (i.e. a bug),\nversus 501 ones.\n\nThis opens up the issue of keeping the server behavior\nconsistent from one release to another, but one might argue\nthat this was bad design decision in the first place.\n\nImplements blueprint nvp-agent-scheduler-extension\n\nChange-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea3e130a5836baa70d3dff289a2976c75cd70e13', 'message': ""Add support to Agent Extension to NVP Plugin.\n\nOf DHCP and L3 agents, NVP uses DHCP; This patch adds support\nfor the extension to this plugin, however L3 agent specific\nmethods are overriden to raise NotImplementedError.\n\nThat said, the client will only see 'Internal Server Error',\nunless common errors are properly handled in the base controller.\n\nImplements blueprint nvp-agent-scheduler-extension\n\nChange-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f\n""}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d3f46703ae47574d87c3970bac2d08be1563eb3', 'message': 'Add support for the agent extension to NVP Plugin.\n\nOf DHCP and L3 agents, NVP uses DHCP; This patch adds support\nfor the extension to this plugin, however L3 agent specific\nmethods are overriden to raise NotImplementedError.\n\nWith this patch we also avoid masking NotImplementedError(s).\nPreviously, a catch-all clause returned 500, and it makes\nsense to distinguish between genuine 500 errors (i.e. a bug),\nversus a 501.\n\nThis opens up the issue of keeping the server behavior\nconsistent from one release to another\n\nImplements blueprint nvp-agent-scheduler-extension\n\nChange-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d03aca0ac0cba68fadf9267fd7ee3690b7ae7a1', 'message': ""Add support for the agent extension to NVP Plugin.\n\nOf DHCP and L3 agents, NVP uses DHCP; This patch adds support\nfor the extension to this plugin, however L3 agent specific\nmethods are overriden to raise NotImplementedError.\n\nThat said, the client will only see 'Internal Server Error',\nunless common errors are properly handled in the base controller.\n\nImplements blueprint nvp-agent-scheduler-extension\n\nChange-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f\n""}, {'number': 6, 'created': '2013-07-09 17:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a9c547842c135fcfca21f4a41e6a7fc69102867', 'message': 'Add support for the agent extension to NVP Plugin.\n\nOf DHCP and L3 agents, NVP uses DHCP; This patch adds support\nfor the extension to this plugin.\n\nImplements blueprint nvp-agent-scheduler-extension\n\nChange-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f\n'}, {'number': 7, 'created': '2013-07-10 22:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c0d808cf681faca5c619fb79e05ea60daa0d3695', 'message': 'Add support for the agent extension to NVP Plugin.\n\nOf DHCP and L3 agents, NVP uses DHCP; This patch adds support\nfor the extension to this plugin.\n\nThis patch also moves some tests around, as a result of the\nrefactory done in https://review.openstack.org/#/c/35266/\nSome code duplication is also removed.\n\nImplements blueprint nvp-agent-scheduler-extension\n\nChange-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f\n'}, {'number': 8, 'created': '2013-07-11 02:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5cda7b90111767ca02ba87ab55efe7f1e1920d79', 'message': 'Add support for the agent extension to NVP Plugin.\n\nOf DHCP and L3 agents, NVP uses DHCP; This patch adds support\nfor the extension to this plugin.\n\nThis patch also moves some tests around, as a result of the\nrefactory done in https://review.openstack.org/#/c/35266/\nSome code duplication is also removed.\n\nImplements blueprint nvp-agent-scheduler-extension\n\nChange-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f\n'}, {'number': 9, 'created': '2013-07-15 15:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5bd3aed583327629fd11c4b6346ab8efc0aad110', 'message': 'Add support for the agent extension to NVP Plugin.\n\nOf DHCP and L3 agents, NVP uses DHCP; This patch adds support\nfor the extension to this plugin.\n\nThis patch also moves some tests around, as a result of the\nrefactory done in https://review.openstack.org/#/c/35266/\nSome code duplication is also removed.\n\nImplements blueprint nvp-agent-scheduler-extension\n\nChange-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f\n'}, {'number': 10, 'created': '2013-07-18 15:03:10.000000000', 'files': ['neutron/plugins/nicira/NeutronPlugin.py', 'neutron/tests/unit/nicira/test_agent_scheduler.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a1e483d049a104a8475febc828107c4b323f6def', 'message': 'Add support for the agent extension to NVP Plugin.\n\nOf DHCP and L3 agents, NVP uses DHCP; This patch adds support\nfor the extension to this plugin.\n\nThis patch also moves some tests around, as a result of the\nrefactory done in https://review.openstack.org/#/c/35266/\nSome code duplication is also removed.\n\nImplements blueprint nvp-agent-scheduler-extension\n\nChange-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f\n'}]",11,34675,a1e483d049a104a8475febc828107c4b323f6def,49,7,10,748,,,0,"Add support for the agent extension to NVP Plugin.

Of DHCP and L3 agents, NVP uses DHCP; This patch adds support
for the extension to this plugin.

This patch also moves some tests around, as a result of the
refactory done in https://review.openstack.org/#/c/35266/
Some code duplication is also removed.

Implements blueprint nvp-agent-scheduler-extension

Change-Id: I4ca1148e81fdb39bf6b58eef806536439e9f0c6f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/34675/5 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/tests/unit/nicira/test_agent_scheduler.py', 'quantum/plugins/nicira/QuantumPlugin.py']",2,3fe19ecf638b2fbcdf187d66e5b1d01d2bf89c40,bp/nvp-agent-scheduler-extension," supported_extension_aliases = [""agent"", ""agent_scheduler"", ""mac-learning"","," supported_extension_aliases = [""mac-learning"",",48,1
openstack%2Fheat~master~I537d9f4aa0750c6b771f6bc842e8137e1ab8606e,openstack/heat,master,I537d9f4aa0750c6b771f6bc842e8137e1ab8606e,Do not evaluate data generated before heat engine started,ABANDONED,2013-07-19 04:22:01.000000000,2013-07-19 06:27:03.000000000,,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-07-19 04:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/19544e0c14eab31e42d42772813dfedaa0bb1ff5', 'message': 'Do not evaluate data generated before heat engine started\n\nThe heat beats will not be written to database during heat engine is\nstopped. When heat engine is started again, it looks at the heat beat\ndata stored in database, and found some heat beats missing so restart\nthe resources.\n\nThe solution is to evaluate only the data generated in current heat\nengine session. For the data in previous session, current session does\nnot take action.\n\nChange-Id: I537d9f4aa0750c6b771f6bc842e8137e1ab8606e\nFixes: bug #1202552\n'}, {'number': 2, 'created': '2013-07-19 04:29:23.000000000', 'files': ['heat/tests/test_watch.py', 'heat/engine/watchrule.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/75694f4ae2ebaf0117f43721e5e1f26087061979', 'message': 'Do not evaluate data generated before heat engine started\n\nThe heat beats will not be written to database during heat engine is\nstopped. When heat engine is started again, it looks at the heat beat\ndata stored in database, and found some heat beats missing so restart\nthe resources.\n\nThe solution is to evaluate only the data generated in current heat\nengine session. For the data in previous session, current session does\nnot take action.\n\nChange-Id: I537d9f4aa0750c6b771f6bc842e8137e1ab8606e\nFixes: bug #1202552\n'}]",0,37837,75694f4ae2ebaf0117f43721e5e1f26087061979,4,3,2,7761,,,0,"Do not evaluate data generated before heat engine started

The heat beats will not be written to database during heat engine is
stopped. When heat engine is started again, it looks at the heat beat
data stored in database, and found some heat beats missing so restart
the resources.

The solution is to evaluate only the data generated in current heat
engine session. For the data in previous session, current session does
not take action.

Change-Id: I537d9f4aa0750c6b771f6bc842e8137e1ab8606e
Fixes: bug #1202552
",git fetch https://review.opendev.org/openstack/heat refs/changes/37/37837/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_watch.py', 'heat/engine/watchrule.py']",2,19544e0c14eab31e42d42772813dfedaa0bb1ff5,bug/1202552, started_at = timeutils.utcnow() # Skip data before heat engine started if self.now < (self.started_at + self.timeperiod): return [] ,,36,1
openstack%2Fnova~master~I820d734e098b65910a3a0a44d176827ee9a868b9,openstack/nova,master,I820d734e098b65910a3a0a44d176827ee9a868b9,PCI passthrough Scheduler layer,ABANDONED,2013-06-27 00:58:07.000000000,2013-07-19 06:03:09.000000000,,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 2166}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-06-27 00:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef08080125ef1a13d0e003d553ac9f5fa9451540', 'message': 'PCI passthrough Scheduler layer\n\nChange HostState\n  Now it contains also available pci labels\n\nAdd new filter PciPassthroughFilter:\n  That checks that host has all required labels\n\nAdd new tests and fix old\n\nblueprint pci-passthrough-base\n\nChange-Id: I820d734e098b65910a3a0a44d176827ee9a868b9\n'}, {'number': 2, 'created': '2013-07-01 11:37:31.000000000', 'files': ['nova/scheduler/filters/pci_passthrough_filter.py', 'nova/tests/scheduler/fakes.py', 'nova/tests/scheduler/test_host_filters.py', 'nova/tests/scheduler/test_filter_scheduler.py', 'nova/scheduler/filter_scheduler.py', 'nova/tests/scheduler/test_host_manager.py', 'nova/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e5986660906a238717f5062920b86a95dab3003e', 'message': 'PCI passthrough Scheduler layer\n\nChange HostState\n  Now it contains also available pci labels\n\nAdd new filter PciPassthroughFilter:\n  That checks that host has all required labels\n\nAdd new tests and fix old\n\nblueprint pci-passthrough-base\n\nChange-Id: I820d734e098b65910a3a0a44d176827ee9a868b9\n'}]",2,34647,e5986660906a238717f5062920b86a95dab3003e,8,4,2,6172,,,0,"PCI passthrough Scheduler layer

Change HostState
  Now it contains also available pci labels

Add new filter PciPassthroughFilter:
  That checks that host has all required labels

Add new tests and fix old

blueprint pci-passthrough-base

Change-Id: I820d734e098b65910a3a0a44d176827ee9a868b9
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/34647/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/filters/pci_passthrough_filter.py', 'nova/tests/scheduler/fakes.py', 'nova/tests/scheduler/test_host_filters.py', 'nova/tests/scheduler/test_filter_scheduler.py', 'nova/scheduler/filter_scheduler.py', 'nova/tests/scheduler/test_host_manager.py', 'nova/scheduler/host_manager.py']",7,ef08080125ef1a13d0e003d553ac9f5fa9451540,bp/pci-passthrough-libvirt,"from nova import pci self.free_pci_labels = [] self.free_pci_labels = [dev['label'] for dev in compute.get('pci_devices', []) if dev['status'] == 'available'] inst_type = instance.get('instance_type') requested_pci_labels = pci.get_labels_from_instance_type(inst_type) for label in requested_pci_labels: self.free_pci_labels.remove(label) ",,156,17
openstack%2Fnova~master~Ie169b3f3925e9c0be734dd73ff043ab39dcbf1db,openstack/nova,master,Ie169b3f3925e9c0be734dd73ff043ab39dcbf1db,PCI passthrough Utils layer,ABANDONED,2013-06-27 00:58:06.000000000,2013-07-19 06:03:09.000000000,,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 2166}, {'_account_id': 4573}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-06-27 00:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d8a7ededfc6624fffbbede4715eb21968d7d408', 'message': ""PCI passthrough Utils layer\n\nThese utils are used for few things:\n\n1) Functions that are used often:\nget_labels_from_instance_type()\n  It get labels as a list from json string which is in specific\n  extra_spec in instance_type\n\ncheck_pci_device_address()\nChecks that address of pci deivce is in right format (by regex)\n\nparse_address()\nfrom address get tuple of (domain, bus, slot, function)\n\n2) Sync nova.conf with DB state\nsync_pci_devices()\n*) Gets json string from nova confg param pci_passthrough_devices\n*) Checks that it is well formated (by jsonschema schema validator)\n*) Gets list of device from this json string (make object from json)\n*) Check that there is no duplicated addresses in these devices\n*) delete all devices in db on this host. (If device is used, change\n   status to 'to_delete'). And this device will be deleted when instance\n   will be destroyed.\n\nresource tracker will call this on each compute_node_sync:\n*) Try to create devices that are left\n   (some of the device couldn't be created, because they are used)\n\nblueprint pci-passthrough-base\n\nChange-Id: Ie169b3f3925e9c0be734dd73ff043ab39dcbf1db\n""}, {'number': 2, 'created': '2013-07-01 11:37:32.000000000', 'files': ['nova/tests/test_pci_device.py', 'nova/pci/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/afd84a539a7595c5507dc5df9d6d6bc84938b471', 'message': ""PCI passthrough Utils layer\n\nThese utils are used for few things:\n\n1) Functions that are used often:\nget_labels_from_instance_type()\n  It get labels as a list from json string which is in specific\n  extra_spec in instance_type\n\ncheck_pci_device_address()\nChecks that address of pci deivce is in right format (by regex)\n\nparse_address()\nfrom address get tuple of (domain, bus, slot, function)\n\n2) Sync nova.conf with DB state\nsync_pci_devices()\n*) Gets json string from nova confg param pci_passthrough_devices\n*) Checks that it is well formated (by jsonschema schema validator)\n*) Gets list of device from this json string (make object from json)\n*) Check that there is no duplicated addresses in these devices\n*) delete all devices in db on this host. (If device is used, change\n   status to 'to_delete'). And this device will be deleted when instance\n   will be destroyed.\n\nresource tracker will call this on each compute_node_sync:\n*) Try to create devices that are left\n   (some of the device couldn't be created, because they are used)\n\nblueprint pci-passthrough-base\n\nChange-Id: Ie169b3f3925e9c0be734dd73ff043ab39dcbf1db\n""}]",3,34646,afd84a539a7595c5507dc5df9d6d6bc84938b471,11,5,2,6172,,,0,"PCI passthrough Utils layer

These utils are used for few things:

1) Functions that are used often:
get_labels_from_instance_type()
  It get labels as a list from json string which is in specific
  extra_spec in instance_type

check_pci_device_address()
Checks that address of pci deivce is in right format (by regex)

parse_address()
from address get tuple of (domain, bus, slot, function)

2) Sync nova.conf with DB state
sync_pci_devices()
*) Gets json string from nova confg param pci_passthrough_devices
*) Checks that it is well formated (by jsonschema schema validator)
*) Gets list of device from this json string (make object from json)
*) Check that there is no duplicated addresses in these devices
*) delete all devices in db on this host. (If device is used, change
   status to 'to_delete'). And this device will be deleted when instance
   will be destroyed.

resource tracker will call this on each compute_node_sync:
*) Try to create devices that are left
   (some of the device couldn't be created, because they are used)

blueprint pci-passthrough-base

Change-Id: Ie169b3f3925e9c0be734dd73ff043ab39dcbf1db
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/34646/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_pci_device.py', 'nova/pci/__init__.py']",2,1d8a7ededfc6624fffbbede4715eb21968d7d408,bp/pci-passthrough-libvirt,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Copyright (c) 2013 ISP RAS. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Module for PCI passthrough."""""" import jsonschema import re from oslo.config import cfg from nova import conductor from nova import exception from nova.openstack.common import jsonutils from nova.openstack.common import log as logging # NOTE(boris-42): DB access from compute nodes have to be through conductor. conductor_api = conductor.API() LOG = logging.getLogger(__name__) pci_opts = [ cfg.StrOpt('pci_passthrough_devices', default='[]', help='List of avaiable for PCI passthrough devices as list of ' 'json objects: ' ' {""label"": string, ' ' ""address"": string in format domain:bus:slot.function}') ] CONF = cfg.CONF CONF.register_opts(pci_opts) _PCI_ADDRESS_PATTERN = ""^(hex{4}):(hex{2}):(hex{2}).(oct{1})$"".\ replace(""hex"", ""[\da-fA-F]"").\ replace(""oct"", ""[0-7]"") _PCI_ADDRESS_REGEX = re.compile(_PCI_ADDRESS_PATTERN) _PCI_PASSTHROUGH_DEVICES_SCHEMA = { ""title"": ""Available PCI devices"", ""type"": ""array"", ""items"": { ""title"": ""PCI device"", ""type"": ""object"", ""additionalProperties"": False, ""properties"": { ""label"": { ""type"": ""string"", ""minLength"": 1, ""maxLength"": 200 }, ""address"": { ""type"": ""string"", ""pattern"": _PCI_ADDRESS_PATTERN }, ""vendor_id"": { ""type"": ""string"", ""pattern"": ""^[\da-fA-F]{4}$"" }, ""product_id"": { ""type"": ""string"", ""pattern"": ""^[\da-fA-F]{4}$"" } }, ""required"": [""label"", ""address""] } } def get_labels_from_instance_type(instance_type): specs = instance_type[""extra_specs""] return jsonutils.loads(specs.get('pci_passthrough:labels', '[]')) def check_pci_device_address(address): if _PCI_ADDRESS_REGEX.match(address) is None: raise exception.PCIDeviceWrongAddressFormat(pci_address=address) def parse_address(address): """""" Returns (domain, bus, slot, function) from PCI address that is stored in PciDevice DB table. """""" m = _PCI_ADDRESS_REGEX.match(address) if not m: raise exception.PCIDeviceWrongAddressFormat(pci_address=address) return m.groups() def _validate_and_parse_pci_devices_from_config(host=None): """"""Validate PCI devices that are in CONF.pci_passthrough.devices."""""" devs = CONF.pci_passthrough_devices try: devs = jsonutils.loads(devs) jsonschema.validate(devs, _PCI_PASSTHROUGH_DEVICES_SCHEMA) addresses = set() for addr in [dev['address'] for dev in devs]: if addr in addresses: raise exception.PCIDeviceAlreadyExistsOnHost(host=host, pci_address=addr) addresses.add(addr) except Exception as e: raise exception.PCIDeviceInvalidConfig(error_msg=str(e)) return devs _WAS_INITED = False _UNCREATED_PCI_DEVS = [] def _create_pci_devices(context, host, compute_id, devs=None): """""" Try to create devices that are in devs param. If devs is None try to create it from _UNCREATED_PCI_DEVS. """""" global _UNCREATED_PCI_DEVS if not devs: devs = _UNCREATED_PCI_DEVS _UNCREATED_PCI_DEVS = [] for dev in devs: dev['host'] = host dev['compute_id'] = compute_id try: conductor_api.pci_device_create(context, dev) except exception.PCIDeviceAlreadyExistsOnHost: _UNCREATED_PCI_DEVS.append(dev) LOG.info(_(""Couldn't update PCI device with address: %(address)s."" "" PCI device is busy.""), {'address': dev['address']}) def sync_pci_devices(context, host, compute_id, init_once=True): """""" This method is called on each call of update_available_resource in resource_tracker. When it is called first time it will remove previous PCI devices from DB and populate it with new pci devices that are specified in CONF. Other calls are required because we are not able to delete devices that are used by instance. We should wait until they are released and then create (if they are in conf). """""" global _WAS_INITED if _WAS_INITED and init_once: _WAS_INITED = True _create_pci_devices(context, host, compute_id) return _WAS_INITED = True conductor_api.pci_device_destroy_all_on_host(context, host) _create_pci_devices(context, host, compute_id, devs=_validate_and_parse_pci_devices_from_config(host)) ",,387,0
openstack%2Fheat~master~Ie24d8f1d16fcce1dbeba947086b2d6ddc7c76c2c,openstack/heat,master,Ie24d8f1d16fcce1dbeba947086b2d6ddc7c76c2c,Rackspace cloud database handle_delete throws exception if database was already deleted Fixes bug: #1197077,ABANDONED,2013-07-03 18:06:55.000000000,2013-07-19 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 6434}, {'_account_id': 7162}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7395}]","[{'number': 2, 'created': '2013-07-03 18:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f000bb54780395f0487c8d704604367a9c56723e', 'message': 'Rackspace cloud database handle_delete throws exception if database was already deleted\nFixes bug: #1197077\n\nChange-Id: Ie24d8f1d16fcce1dbeba947086b2d6ddc7c76c2c\n'}, {'number': 3, 'created': '2013-07-03 18:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c6a417c4c34ec1b78c33eaa090c4cc37fdbf4eb7', 'message': 'Rackspace cloud database handle_delete throws exception if database was already deleted\nFixes bug: #1197077\n\nChange-Id: Ie24d8f1d16fcce1dbeba947086b2d6ddc7c76c2c\n'}, {'number': 1, 'created': '2013-07-03 18:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/74d4fab04ca41a90328ba26c48234aab470f8b1c', 'message': 'Rackspace cloud database handle_delete throws exception if database was already deleted\nFixes bug: #1197077\n\nChange-Id: Ie24d8f1d16fcce1dbeba947086b2d6ddc7c76c2c\n'}, {'number': 4, 'created': '2013-07-03 18:06:55.000000000', 'files': ['heat/engine/resources/rackspace/clouddatabase.py', 'heat/tests/test_clouddatabase.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0488949bfe1c4d9b425c7b9177b8ed52d811a8ee', 'message': 'Rackspace cloud database handle_delete throws exception if database was already deleted\nFixes bug: #1197077\n\nChange-Id: Ie24d8f1d16fcce1dbeba947086b2d6ddc7c76c2c\n'}]",2,35524,0488949bfe1c4d9b425c7b9177b8ed52d811a8ee,22,8,4,7230,,,0,"Rackspace cloud database handle_delete throws exception if database was already deleted
Fixes bug: #1197077

Change-Id: Ie24d8f1d16fcce1dbeba947086b2d6ddc7c76c2c
",git fetch https://review.opendev.org/openstack/heat refs/changes/24/35524/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/rackspace/clouddatabase.py', 'heat/tests/test_clouddatabase.py']",2,f000bb54780395f0487c8d704604367a9c56723e,bug/1197077,,"from heat.common import exception def test_clouddbinstance_delete_resource_notfound(self): instance = self._setup_test_clouddbinstance('dbinstance_delete') instance.resource_id = None self.m.ReplayAll() self.assertRaises(exception.ResourceNotFound, instance.handle_delete) self.m.VerifyAll() ",7,12
openstack%2Fcinder~master~Ie77886286723957561d4512d51abe8b64b32391f,openstack/cinder,master,Ie77886286723957561d4512d51abe8b64b32391f,Bring back dmsetup remove.,ABANDONED,2013-07-11 01:05:53.000000000,2013-07-19 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4523}]","[{'number': 1, 'created': '2013-07-11 01:05:53.000000000', 'files': ['cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1097a6ba31d278c87d513d41f8a4cc66a0f25203', 'message': ""Bring back dmsetup remove.\n\nHeavy loads doing things like running delete on\nhundreds of LVM volumes on a single cinder node\ncan result in some failures.\n\nParticularly issues with iscsi tgt's, and what's\nworse is you can end up in an error-deleting state\nthat you can't get out of because the tgt system\nhas the device as still in use.\n\nBring back dmsetup remove, but ignore situations where\nit might fail, the worst that can happen here is that it\nfails to remove the mapped device and it happens to still\nbe open and we have the same failure situation we\ncurrently have.\n\nFixes bug: 1191960\n\nChange-Id: Ie77886286723957561d4512d51abe8b64b32391f\n""}]",0,36594,1097a6ba31d278c87d513d41f8a4cc66a0f25203,7,4,1,2243,,,0,"Bring back dmsetup remove.

Heavy loads doing things like running delete on
hundreds of LVM volumes on a single cinder node
can result in some failures.

Particularly issues with iscsi tgt's, and what's
worse is you can end up in an error-deleting state
that you can't get out of because the tgt system
has the device as still in use.

Bring back dmsetup remove, but ignore situations where
it might fail, the worst that can happen here is that it
fails to remove the mapped device and it happens to still
be open and we have the same failure situation we
currently have.

Fixes bug: 1191960

Change-Id: Ie77886286723957561d4512d51abe8b64b32391f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/94/36594/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/lvm.py'],1,1097a6ba31d278c87d513d41f8a4cc66a0f25203,bug/1191960," try: self._try_execute('dmsetup', 'remove', '-f', dev_path, run_as_root=True) except Exception: pass dev_path = self.local_path(volume) if os.path.exists(dev_path): self.clear_volume(volume) try: self._try_execute('dmsetup', 'remove', '-f', dev_path, run_as_root=True) except Exception: pass ",,17,0
openstack%2Fceilometer~master~I4372a261d0e38eb3818ed3b2e6ac42dea9a7679c,openstack/ceilometer,master,I4372a261d0e38eb3818ed3b2e6ac42dea9a7679c,Move tests into ceilometer package.,ABANDONED,2013-07-06 03:15:19.000000000,2013-07-19 06:03:03.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-06 03:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f289d8ffbc444586cd18f4d4e66dedb207fa747b', 'message': ""Move tests into ceilometer package.\n\ntests.* is a package in the global namespace and is not one that we\nare providing. Also, as should be clear from ceilometer's consumption of\nnova's tests, you never know who might want to consume your test suite.\n\nChange-Id: I4372a261d0e38eb3818ed3b2e6ac42dea9a7679c\n""}, {'number': 2, 'created': '2013-07-06 03:18:30.000000000', 'files': ['ceilometer/tests/compute/test_pollsters.py', 'ceilometer/tests/storage/test_impl_log.py', 'ceilometer/tests/compute/virt/__init__.py', 'ceilometer/tests/api/__init__.py', 'ceilometer/tests/api/v1/list_sources.py', 'ceilometer/tests/compute/test_notifications.py', 'ceilometer/tests/central/__init__.py', 'ceilometer/tests/api/v2/test_impl_sqlalchemy.py', 'ceilometer/tests/objectstore/test_swift.py', 'ceilometer/tests/storage/test_impl_mongodb.py', 'ceilometer/tests/test_bin.py', 'ceilometer/tests/api/v1/test_impl_mongodb.py', 'ceilometer/tests/compute/virt/libvirt/__init__.py', 'ceilometer/tests/storage/test_register_opts.py', 'ceilometer/tests/api/v2/list_meters.py', 'ceilometer/tests/api/v1/sum_resource_volume.py', 'ceilometer/tests/image/test_notifications.py', 'ceilometer/tests/test_utils.py', 'ceilometer/tests/volume/__init__.py', 'ceilometer/tests/volume/test_notifications.py', 'ceilometer/tests/collector/test_manager.py', 'tests/api/__init__.py', 'ceilometer/tests/api/v1/list_meters.py', 'ceilometer/tests/energy/__init__.py', 'ceilometer/tests/storage/test_base.py', 'ceilometer/tests/test_notifier.py', 'ceilometer/tests/api/v2/acl.py', 'ceilometer/tests/api/v2/statistics.py', 'ceilometer/tests/test_tools_notificationclient.py', 'ceilometer/tests/network/test_floatingip.py', 'ceilometer/tests/storage/test_get_engine.py', 'ceilometer/tests/api/v1/max_resource_volume.py', 'ceilometer/tests/publisher/__init__.py', 'ceilometer/tests/api/v1/test_impl_hbase.py', 'ceilometer/tests/image/__init__.py', 'ceilometer/tests/publisher/test_rpc_publisher.py', 'ceilometer/tests/test_service.py', 'ceilometer/tests/api/v1/test_app.py', 'ceilometer/tests/api/v2/test_impl_hbase.py', 'ceilometer/tests/sources.json', 'ceilometer/tests/storage/test_impl_sqlalchemy.py', 'ceilometer/tests/api/v2/test_app.py', 'ceilometer/tests/storage/test_impl_hbase.py', 'tests/__init__.py', 'ceilometer/tests/api/v1/test_impl_sqlalchemy.py', 'ceilometer/tests/test_pipeline.py', 'ceilometer/tests/publisher/test_udp.py', 'ceilometer/tests/policy.json', 'ceilometer/tests/api/v2/post_samples.py', 'ceilometer/tests/api/v1/list_projects.py', 'ceilometer/tests/api/v2/base.py', 'ceilometer/tests/api/v1/max_project_volume.py', 'ceilometer/tests/image/test_glance.py', 'ceilometer/tests/api/v2/compute_duration_by_resource.py', 'ceilometer/tests/collector/__init__.py', 'ceilometer/tests/network/test_notifications.py', 'ceilometer/tests/storage/base.py', 'ceilometer/tests/compute/test_instance.py', 'ceilometer/tests/objectstore/__init__.py', 'ceilometer/tests/central/test_manager.py', 'ceilometer/tests/api/v1/list_users.py', 'ceilometer/tests/compute/virt/libvirt/test_inspector.py', 'ceilometer/tests/storage/__init__.py', 'ceilometer/tests/api/v2/__init__.py', 'ceilometer/tests/storage/test_models.py', 'nova_tests/test_notifier.py', 'ceilometer/tests/api/v1/__init__.py', 'ceilometer/tests/energy/test_kwapi.py', 'ceilometer/tests/network/__init__.py', 'ceilometer/tests/api/v1/list_resources.py', 'ceilometer/tests/test_novaclient.py', 'ceilometer/tests/api/v1/test_get_query_ts.py', 'ceilometer/tests/compute/__init__.py', 'ceilometer/tests/compute/test_manager.py', 'ceilometer/tests/agentbase.py', 'ceilometer/tests/api/v1/list_events.py', 'ceilometer/tests/api/v2/test_impl_mongodb.py', 'ceilometer/tests/api/v1/compute_duration_by_resource.py', 'ceilometer/tests/base.py', 'ceilometer/tests/api/v2/list_resources.py', '.testr.conf', 'ceilometer/tests/api/v2/test_statistics.py', 'ceilometer/tests/api/v2/alarm.py', 'ceilometer/tests/api/v1/sum_project_volume.py', 'ceilometer/tests/api/v2/list_events.py', 'nova_tests/__init__.py', 'ceilometer/tests/objectstore/test_swift_middleware.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3132c7c8d513a9542ae12e264fd26fd2c876327d', 'message': ""Move tests into ceilometer package.\n\ntests.* is a package in the global namespace and is not one that we\nare providing. Also, as should be clear from ceilometer's consumption of\nnova's tests, you never know who might want to consume your test suite.\n\nChange-Id: I4372a261d0e38eb3818ed3b2e6ac42dea9a7679c\n""}]",0,35938,3132c7c8d513a9542ae12e264fd26fd2c876327d,7,3,2,2,,,0,"Move tests into ceilometer package.

tests.* is a package in the global namespace and is not one that we
are providing. Also, as should be clear from ceilometer's consumption of
nova's tests, you never know who might want to consume your test suite.

Change-Id: I4372a261d0e38eb3818ed3b2e6ac42dea9a7679c
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/38/35938/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/compute/test_pollsters.py', 'ceilometer/tests/storage/test_impl_log.py', 'ceilometer/tests/compute/virt/__init__.py', 'ceilometer/tests/api/__init__.py', 'ceilometer/tests/api/v1/list_sources.py', 'ceilometer/tests/compute/test_notifications.py', 'ceilometer/tests/central/__init__.py', 'ceilometer/tests/api/v2/test_impl_sqlalchemy.py', 'ceilometer/tests/objectstore/test_swift.py', 'ceilometer/tests/storage/test_impl_mongodb.py', 'ceilometer/tests/test_bin.py', 'ceilometer/tests/api/v1/test_impl_mongodb.py', 'ceilometer/tests/compute/virt/libvirt/__init__.py', 'ceilometer/tests/storage/test_register_opts.py', 'ceilometer/tests/api/v2/list_meters.py', 'ceilometer/tests/api/v1/sum_resource_volume.py', 'ceilometer/tests/image/test_notifications.py', 'ceilometer/tests/test_utils.py', 'ceilometer/tests/volume/__init__.py', 'ceilometer/tests/volume/test_notifications.py', 'ceilometer/tests/collector/test_manager.py', 'tests/api/__init__.py', 'ceilometer/tests/api/v1/list_meters.py', 'ceilometer/tests/energy/__init__.py', 'ceilometer/tests/storage/test_base.py', 'ceilometer/tests/test_notifier.py', 'ceilometer/tests/api/v2/acl.py', 'ceilometer/tests/api/v2/statistics.py', 'ceilometer/tests/test_tools_notificationclient.py', 'ceilometer/tests/network/test_floatingip.py', 'ceilometer/tests/storage/test_get_engine.py', 'ceilometer/tests/api/v1/max_resource_volume.py', 'ceilometer/tests/publisher/__init__.py', 'ceilometer/tests/api/v1/test_impl_hbase.py', 'ceilometer/tests/image/__init__.py', 'ceilometer/tests/publisher/test_rpc_publisher.py', 'ceilometer/tests/test_service.py', 'ceilometer/tests/api/v1/test_app.py', 'ceilometer/tests/api/v2/test_impl_hbase.py', 'ceilometer/tests/sources.json', 'ceilometer/tests/storage/test_impl_sqlalchemy.py', 'ceilometer/tests/api/v2/test_app.py', 'ceilometer/tests/storage/test_impl_hbase.py', 'tests/__init__.py', 'ceilometer/tests/api/v1/test_impl_sqlalchemy.py', 'ceilometer/tests/test_pipeline.py', 'ceilometer/tests/publisher/test_udp.py', 'ceilometer/tests/policy.json', 'ceilometer/tests/api/v2/post_samples.py', 'ceilometer/tests/api/v1/list_projects.py', 'ceilometer/tests/api/v2/base.py', 'ceilometer/tests/api/v1/max_project_volume.py', 'ceilometer/tests/image/test_glance.py', 'ceilometer/tests/api/v2/compute_duration_by_resource.py', 'ceilometer/tests/collector/__init__.py', 'ceilometer/tests/network/test_notifications.py', 'ceilometer/tests/storage/base.py', 'ceilometer/tests/compute/test_instance.py', 'ceilometer/tests/objectstore/__init__.py', 'ceilometer/tests/central/test_manager.py', 'ceilometer/tests/api/v1/list_users.py', 'ceilometer/tests/compute/virt/libvirt/test_inspector.py', 'ceilometer/tests/storage/__init__.py', 'ceilometer/tests/api/v2/__init__.py', 'ceilometer/tests/storage/test_models.py', 'nova_tests/test_notifier.py', 'ceilometer/tests/api/v1/__init__.py', 'ceilometer/tests/energy/test_kwapi.py', 'ceilometer/tests/network/__init__.py', 'ceilometer/tests/api/v1/list_resources.py', 'ceilometer/tests/test_novaclient.py', 'ceilometer/tests/api/v1/test_get_query_ts.py', 'ceilometer/tests/compute/__init__.py', 'ceilometer/tests/compute/test_manager.py', 'ceilometer/tests/agentbase.py', 'ceilometer/tests/api/v1/list_events.py', 'ceilometer/tests/api/v2/test_impl_mongodb.py', 'ceilometer/tests/api/v1/compute_duration_by_resource.py', 'ceilometer/tests/base.py', 'ceilometer/tests/api/v2/list_resources.py', '.testr.conf', 'ceilometer/tests/api/v2/test_statistics.py', 'ceilometer/tests/api/v2/alarm.py', 'ceilometer/tests/api/v1/sum_project_volume.py', 'ceilometer/tests/api/v2/list_events.py', 'nova_tests/__init__.py', 'ceilometer/tests/objectstore/test_swift_middleware.py']",87,f289d8ffbc444586cd18f4d4e66dedb207fa747b,remove-distribute,,,22,39
openstack%2Ftrove~master~I507734358f9aa680c5460ebccc2b0114f31e96be,openstack/trove,master,I507734358f9aa680c5460ebccc2b0114f31e96be,Aadded positive and negative backup tests,ABANDONED,2013-06-19 16:10:46.000000000,2013-07-19 06:03:03.000000000,,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1375}, {'_account_id': 1925}, {'_account_id': 6268}, {'_account_id': 6877}, {'_account_id': 7092}, {'_account_id': 7273}]","[{'number': 1, 'created': '2013-06-19 16:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/48ec4d15fcf5b8e2161a4cd59f10bddb8cb376d3', 'message': 'added positive and negative backup tests\n\nChange-Id: I507734358f9aa680c5460ebccc2b0114f31e96be\n'}, {'number': 2, 'created': '2013-06-19 19:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b7de3c3d2d51030e18d5e18eac00a68aa7bc1004', 'message': 'added positive and negative backup tests\n\nChange-Id: I507734358f9aa680c5460ebccc2b0114f31e96be\n'}, {'number': 3, 'created': '2013-06-19 19:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a44627c048b0da715110890ec799efc078b5f6c1', 'message': 'added positive and negative backup tests\n\nChange-Id: I507734358f9aa680c5460ebccc2b0114f31e96be\n'}, {'number': 4, 'created': '2013-06-19 20:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/241eb785c801bbf64796957af91fcc1e66026bcf', 'message': 'added positive and negative backup tests\n\nChange-Id: I507734358f9aa680c5460ebccc2b0114f31e96be\n'}, {'number': 5, 'created': '2013-06-25 20:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/cf6d19d1d4ab15ad64e6bfcf12283d8f4cbc0b6d', 'message': 'REBASED after reddwarf to trove namechange\nadded positive and negative backup tests\n\nChange-Id: I507734358f9aa680c5460ebccc2b0114f31e96be\n'}, {'number': 6, 'created': '2013-06-27 23:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/653917cb9bcc454534364eba4705b67a28b8cd33', 'message': 'Aadded positive and negative backup tests\n\nREBASED after reddwarf to trove namechange\n\nFixed reddwarfclient to troveclient import\n\nChange-Id: I507734358f9aa680c5460ebccc2b0114f31e96be\n'}, {'number': 7, 'created': '2013-06-28 20:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/48f2d94bc3360edc64a81d594a98cbc590b65b10', 'message': 'Aadded positive and negative backup tests\n\nREBASED after reddwarf to trove namechange\n\nFixed reddwarfclient to troveclient import\n\nAdded some bug fixes in code\n\nChange-Id: I507734358f9aa680c5460ebccc2b0114f31e96be\n'}, {'number': 8, 'created': '2013-06-28 21:10:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/01d3e3aa33b0c2e0c2f9d7a2ea1dfe5cfc875c45', 'message': 'Aadded positive and negative backup tests\n\nREBASED after reddwarf to trove namechange\n\nFixed reddwarfclient to troveclient import\n\nAdded some bug fixes in code\n\nChange-Id: I507734358f9aa680c5460ebccc2b0114f31e96be\n'}, {'number': 9, 'created': '2013-07-02 16:17:04.000000000', 'files': ['trove/tests/api/backups.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/91fb4a521feddb027a0adbd4d9ff40bacb5b1090', 'message': 'Aadded positive and negative backup tests\n\nREBASED after reddwarf to trove namechange\n\nFixed reddwarfclient to troveclient import\n\nAdded some bug fixes in code\n\nfixed _verify_databases\n\nChange-Id: I507734358f9aa680c5460ebccc2b0114f31e96be\n'}]",8,33670,91fb4a521feddb027a0adbd4d9ff40bacb5b1090,50,8,9,6877,,,0,"Aadded positive and negative backup tests

REBASED after reddwarf to trove namechange

Fixed reddwarfclient to troveclient import

Added some bug fixes in code

fixed _verify_databases

Change-Id: I507734358f9aa680c5460ebccc2b0114f31e96be
",git fetch https://review.opendev.org/openstack/trove refs/changes/70/33670/6 && git format-patch -1 --stdout FETCH_HEAD,['reddwarf/tests/api/backups.py'],1,48ec4d15fcf5b8e2161a4cd59f10bddb8cb376d3,backup_pub,"from proboscis.asserts import assert_is_not_nonefrom proboscis import before_classfrom reddwarf import tests from reddwarf.tests import utilfrom reddwarf.tests.api.instances import GROUP_START from reddwarf.tests.util.users import Requirements#from reddwarfclient import backups from reddwarfclient import exceptions from datetime import datetime # Define groupsGROUP_POSITIVE = GROUP + "".positive"" GROUP_NEGATIVE = GROUP + "".negative"" # Define GlobalsBACKUP_DESC = 'test description for backup' backup_name = None backup_desc = None databases = [] users = [] backup_resp = None depends_on_groups=[GROUP_START],class BackupsBase(object): """""" Base class for Positive and Negative classes for test cases """""" #def set_up(self): def __init__(self): self.backup_status = None self.backup_id = None self.restore_id = None self.dbaas = util.create_dbaas_client(instance_info.user) def _create_backup(self, backup_name, backup_desc, inst_id=None): if inst_id is None: inst_id = instance_info.id backup_resp = instance_info.dbaas.backups.create(backup_name, inst_id, backup_desc) return backup_resp def _create_restore(self, client, backup_id): restorePoint = {""backupRef"": backup_id} restore_resp = client.instances.create( instance_info.name + ""_restore"", instance_info.dbaas_flavor_href, instance_info.volume, restorePoint=restorePoint) return restore_resp def _create_new_restore(self, backup_id, name, flavor=None, volume=None): restorePoint = {""backupRef"": backup_id} restore_resp = instance_info.dbaas.instances.create( name + ""_restore"", (1 if flavor is None else flavor), {'size': (1 if volume is None else volume)}, restorePoint=restorePoint) return restore_resp def _list_backups_by_instance(self, inst_id=None): if inst_id is None: inst_id = instance_info.id return instance_info.dbaas.instances.backups(inst_id) def _get_backup_status(self, backup_id): return instance_info.dbaas.backups.get(backup_id).status def _delete_backup(self, backup_id): assert_not_equal(backup_id, None, ""Backup ID is not found"") instance_info.dbaas.backups.delete(backup_id) assert_equal(202, instance_info.dbaas.last_http_code) def _backup_is_gone(self, backup_id=None): result = None if backup_id is None: backup_id = self.backup_id try: result = instance_info.dbaas.backups.get(backup_id) except exceptions.NotFound: assert_equal(result.status, ""404"", ""status error: %r != 404)"" % result.status) finally: return result is None def _instance_is_gone(self, inst_id): result = None try: result = instance_info.dbaas.instances.get(inst_id) return False except exceptions.NotFound: return True def _result_is_active(self): instance = instance_info.dbaas.instances.get(self.restore_id) if instance.status == ""ACTIVE"": return True else: # If its not ACTIVE, anything but BUILD must be an error. assert_equal(""BUILD"", instance.status) if instance_info.volume is not None: assert_equal(instance.volume.get('used', None), None) return False def _verify_instance_is_active(self): result = instance_info.dbaas.instances.get(instance_info.id) return result.status == 'ACTIVE' def _verify_instance_status(self, instance_id, status): result = instance_info.dbaas.instances.get(instance_id) return result.status == status def _verify_backup_status(self, backup_id, status): result = instance_info.dbaas.backups.get(backup_id) return result.status == status @test(depends_on_classes=[WaitForGuestInstallationToFinish], groups=[GROUP, GROUP_POSITIVE]) class TestBackupPositive(BackupsBase): backup_id = None restore_id = None restored_name = ""restored_backup"" restored_desc = ""Backup from Restored Instance"" @test def test_create_backup(self): result = self._create_backup(BACKUP_NAME, BACKUP_DESC, instance_info.id) assert_equal(result.name, BACKUP_NAME) assert_equal(result.description, BACKUP_DESC) assert_equal(result.instance_id, instance_info.id) assert_equal(result.status, 'NEW') assert_is_not_none(result.id, 'backup.id does not exist') assert_is_not_none(result.created, 'backup.created does not exist') assert_is_not_none(result.updated, 'backup.updated does not exist') instance = instance_info.dbaas.instances.list()[0] assert_equal(instance.status, 'BACKUP') self.backup_id = result.id # Get Backup status by backup id during and after backup creation poll_until(lambda: self._verify_backup_status(result.id, 'NEW'), time_out=120, sleep_time=1) poll_until(lambda: self._verify_instance_status(instance.id, 'BACKUP'), time_out=120, sleep_time=1) poll_until(lambda: self._verify_backup_status(result.id, 'COMPLETED'), time_out=120, sleep_time=1) poll_until(lambda: self._verify_instance_status(instance.id, 'ACTIVE'), time_out=120, sleep_time=1) @test(runs_after=[test_create_backup]) def test_list_backups(self): result = instance_info.dbaas.backups.list() assert_equal(1, len(result)) backup = result[0] assert_equal(backup.name, BACKUP_NAME) assert_equal(backup.description, BACKUP_DESC) assert_equal(backup.instance_id, instance_info.id) assert_equal(backup.status, 'COMPLETED') assert_is_not_none(backup.id, 'backup.id does not exist') assert_is_not_none(backup.created, 'backup.created does not exist') assert_is_not_none(backup.updated, 'backup.updated does not exist') @test(runs_after=[test_create_backup]) def test_list_backups_for_instance(self): result = self._list_backups_by_instance() assert_equal(1, len(result)) backup = result[0] assert_equal(backup.name, BACKUP_NAME) assert_equal(backup.description, BACKUP_DESC) assert_equal(backup.instance_id, instance_info.id) assert_equal(backup.status, 'COMPLETED') assert_is_not_none(backup.id, 'backup.id does not exist') assert_is_not_none(backup.created, 'backup.created does not exist') assert_is_not_none(backup.updated, 'backup.updated does not exist') @test(runs_after=[test_create_backup]) def test_get_backup(self): backup = instance_info.dbaas.backups.get(self.backup_id) assert_equal(backup.id, self.backup_id) assert_equal(backup.name, BACKUP_NAME) assert_equal(backup.description, BACKUP_DESC) assert_equal(backup.instance_id, instance_info.id) assert_equal(backup.status, 'COMPLETED') assert_is_not_none(backup.created, 'backup.created does not exist') assert_is_not_none(backup.updated, 'backup.updated does not exist') @test(runs_after=[test_create_backup]) def test_restore_backup(self): if test_config.auth_strategy == ""fake"": # We should create restore logic in fake guest agent to not skip raise SkipTest(""Skipping restore tests for fake mode."") restore_resp = self._create_restore(instance_info.dbaas, self.backup_id) assert_equal(200, instance_info.dbaas.last_http_code) assert_equal(""BUILD"", restore_resp.status) assert_is_not_none(restore_resp.id, 'restored inst_id does not exist') self.restore_id = restore_resp.id poll_until(self._result_is_active) restored_inst = instance_info.dbaas.instances.get(self.restore_id) assert_equal(restored_inst.name, BACKUP_NAME) assert_equal(restored_inst.status, 'ACTIVE') assert_is_not_none(restored_inst.id, 'restored inst_id does not exist') @test(runs_after=[test_list_backups, test_list_backups_for_instance], always_run=True) def test_delete_backup(self): self._delete_backup(self.backup_id) poll_until(self._backup_is_gone) @test(runs_after=[test_restore_backup], always_run=True) def test_delete_restored_instance(self): if test_config.auth_strategy == ""fake"": raise SkipTest(""Skipping delete restored instance for fake mode."") # Create a backup to list after instance is deleted result = self._create_backup(self.restored_name, self.restored_desc, inst_id=self.restore_id) assert_equal(200, instance_info.dbaas.last_http_code) poll_until(lambda: self._verify_backup_status(result.id, 'COMPLETED'), time_out=120, sleep_time=1) instance_info.dbaas.instances.delete(self.restore_id) assert_equal(202, instance_info.dbaas.last_http_code) poll_until(lambda: self._instance_is_gone(self.restore_id)) assert_raises(exceptions.NotFound, instance_info.dbaas.instances.get, self.restore_id) @test(runs_after=[test_delete_restored_instance]) def test_list_backups_for_deleted_instance(self): if test_config.auth_strategy == ""fake"": raise SkipTest(""Skipping deleted instance tests for fake mode."") result = self._list_backups_by_instance(inst_id=self.restore_id) assert_equal(1, len(result)) backup = result[0] assert_equal(backup.name, self.restored_name) assert_equal(backup.description, self.restored_desc) assert_equal(backup.instance_id, self.restore_id) assert_equal(backup.status, 'COMPLETED') assert_is_not_none(backup.id, 'backup.id does not exist') assert_is_not_none(backup.created, 'backup.created does not exist') assert_is_not_none(backup.updated, 'backup.updated does not exist') @test(depends_on_classes=[WaitForGuestInstallationToFinish], groups=[GROUP, GROUP_NEGATIVE]) class TestBackupNegative(BackupsBase): databases = [] users = [] starttime_list = [] xtra_instance = None xtra_backup = None spare_client = None spare_user = None @before_class def setUp(self): #instance_info.dbaas.instances.get(). self.spare_user = test_config.users.find_user( Requirements(is_admin=False, services=[""reddwarf""]), black_list=[instance_info.user.auth_user]) self.spare_client = util.create_dbaas_client(self.spare_user) def test_create_backup(self): result = self._create_backup(BACKUP_NAME, BACKUP_DESC, instance_info.id) poll_until(lambda: self._verify_backup_status(result.id, 'COMPLETED'), time_out=120, sleep_time=1) @test(runs_after=[test_create_backup]) def test_create_backup_with_instance_not_active(self): name = ""spare_instance"" flavor = 2 self.databases.append({""name"": ""db2""}) self.users.append({""name"": ""lite"", ""password"": ""litepass"", ""databases"": [{""name"": ""db2""}]}) volume = {'size': 2} self.xtra_instance = instance_info.dbaas.instances.create( name, flavor, volume, self.databases, self.users) assert_equal(200, instance_info.dbaas.last_http_code) # immediately create the backup while instance is still in ""BUILD"" try: self.xtra_backup = self._create_backup( BACKUP_NAME, BACKUP_DESC, inst_id=self.xtra_instance.id) except exceptions.UnprocessableEntity: assert_equal(422, instance_info.dbaas.last_http_code) assert_equal(422, instance_info.dbaas.last_http_code) # make sure the instance status goes back to ""ACTIVE"" poll_until(lambda: self._verify_instance_status(self.xtra_instance.id, ""ACTIVE""), time_out=120, sleep_time=1) # Now that it's active, create the backup self.xtra_backup = self._create_backup(BACKUP_NAME, BACKUP_DESC) assert_equal(202, instance_info.dbaas.last_http_code) poll_until(lambda: self._verify_backup_status(self.xtra_backup.id, 'COMPLETED'), time_out=120, sleep_time=1) # DON'T Delete backup instance now, Need it for restore to smaller @test(runs_after=[test_create_backup_with_instance_not_active]) def test_restore_backups_to_smaller_instance(self): if test_config.auth_strategy == ""fake"": raise SkipTest(""Skipping restore tests for fake mode."") # Create a 2GB instance and DB # Backup a 2GB Database result = self._create_backup(""2GB_backup"", ""restore backup to smaller"") assert_equal(202, instance_info.dbaas.last_http_code) backup_id = result.id # Try to restore it to a 1GB instance try: restore_result = self._create_new_restore(backup_id, ""1GB instance too small"", flavor=1, volume=1) except exceptions.UnprocessableEntity: assert_equal(422, instance_info.dbaas.last_http_code) # Now delete the backup self._delete_backup(backup_id) assert_equal(202, instance_info.dbaas.last_http_code) poll_until(lambda: self._backup_is_gone(backup_id=backup_id)) @test def test_list_backups_account_not_owned(self): raise SkipTest(""Please see Launchpad Bug #1188822"") std_backup = instance_info.dbaas.backups.list()[0] try: self.spare_client.backups.get(std_backup) except exceptions.NotFound: assert_equal(404, self.spare_client.last_http_code) # The SPARE user should not be able to ""get"" the STD user backups assert_equal(404, self.spare_client.last_http_code) @test def test_restore_backup_account_not_owned(self): if test_config.auth_strategy == ""fake"": raise SkipTest(""Skipping restore tests for fake mode."") result = self._create_backup(""rest_not_owned_backup"", ""restoring a backup of a different user"") assert_equal(202, instance_info.dbaas.last_http_code) restore_result = self._create_restore(self.spare_client, result.id) assert_equal(404, instance_info.dbaas.last_http_code) @test def test_delete_backup_account_not_owned(self): raise SkipTest(""Please see Launchpad Bug #1188822"") std_backup = instance_info.dbaas.backups.list()[0] print(""SPARE USER: %r STD BACKUP: %r"" % (self.spare_user.auth_user, self.spare_client.backups.get(std_backup))) instance_info.dbaas.backups.delete(std_backup.id) print(""Resp code: Delete backup no owned: %r "" % instance_info.dbaas.last_http_code) def test_backup_delete_not_found(self): """"""test delete unknown backup"""""" assert_raises(exceptions.NotFound, instance_info.dbaas.backups.delete, 'nonexistent_backup') @test def test_restore_backup_that_did_not_complete(self): if test_config.auth_strategy == ""fake"": raise SkipTest(""Skipping restore tests for fake mode."") # Backup a 10GB Database result = self._create_backup(""10GB_backup"", ""restore before complete"") backup_id = result.id assert_equal(202, instance_info.dbaas.last_http_code) # restore immediately, before the backup is completed restore_result = self._create_new_restore(backup_id, ""backup did not complete"", flavor=2, volume=10) assert_equal(400, instance_info.dbaas.last_http_code) @test def test_delete_while_backing_up(self): result = self._create_backup(""delete_as_backup"", ""delete backup while backing up"") backup_id = result.id assert_equal(202, instance_info.dbaas.last_http_code) # Dont wait for backup to complete, try to delete it try: self._delete_backup(backup_id) except: assert_equal(422, instance_info.dbaas.last_http_code) def test_restore_deleted_backup(self): result = self._create_backup(""rest_del_backup"", ""restoring a deleted backup"") backup_id = result.id self._delete_backup(backup_id) poll_until(self._backup_is_gone) restore_result = self._create_restore(instance_info.dbaas, backup_id) assert_equal(400, instance_info.dbaas.last_http_code) print dir(restore_result) def test_delete_deleted_backup(self): result = self._create_backup(""del_backup"", ""delete a deleted backup"") backup_id = result.id poll_until(lambda: self._verify_backup_status(backup_id, 'COMPLETED'), time_out=120, sleep_time=1) self._delete_backup(backup_id) poll_until(lambda: self._backup_is_gone(backup_id)) try: self._delete_backup(backup_id) except exceptions.NotFound: assert_equal(404, instance_info.dbaas.last_http_code) @test(runs_after=[test_create_backup_with_instance_not_active, test_restore_backups_to_smaller_instance], always_run=True) def test_delete_negative_instance(self): try: self._delete_backup(self.xtra_backup.id) assert_equal(202, instance_info.dbaas.last_http_code) poll_until(lambda: self._backup_is_gone(self.xtra_backup.id)) except exceptions.NotFound: assert_equal(404, instance_info.dbaas.last_http_code) try: instance_info.dbaas.instances.delete(self.xtra_instance.id) assert_equal(202, instance_info.dbaas.last_http_code) poll_until(lambda: self._instance_is_gone(self.xtra_instance.id)) except exceptions.NotFound: assert_equal(404, instance_info.dbaas.last_http_code) finally: assert_raises(exceptions.NotFound, instance_info.dbaas.instances.get, self.xtra_instance.id)","from proboscis.asserts import failfrom reddwarfclient import exceptionsimport time BACKUP_DESC = 'test description' backup_info = None restore_instance_id = Noneclass CreateBackups(object): def test_backup_create_instance(self): """"""test create backup for a given instance"""""" result = instance_info.dbaas.backups.create(BACKUP_NAME, instance_info.id, BACKUP_DESC) assert_equal(BACKUP_NAME, result.name) assert_equal(BACKUP_DESC, result.description) assert_equal(instance_info.id, result.instance_id) assert_equal('NEW', result.status) instance = instance_info.dbaas.instances.list()[0] assert_equal('BACKUP', instance.status) global backup_info backup_info = result @test(runs_after=[CreateBackups], groups=[GROUP]) class AfterBackupCreation(object): @test(runs_after=[AfterBackupCreation], groups=[GROUP]) class WaitForBackupCreateToFinish(object): """""" Wait until the backup create is finished. """""" @time_out(60 * 30) def test_backup_created(self): # This version just checks the REST API status. def result_is_active(): backup = instance_info.dbaas.backups.get(backup_info.id) if backup.status == ""COMPLETED"": return True else: assert_not_equal(""FAILED"", backup.status) return False poll_until(result_is_active) @test(depends_on=[WaitForBackupCreateToFinish], groups=[GROUP]) class ListBackups(object): @test def test_backup_list(self): """"""test list backups"""""" result = instance_info.dbaas.backups.list() assert_equal(1, len(result)) backup = result[0] assert_equal(BACKUP_NAME, backup.name) assert_equal(BACKUP_DESC, backup.description) assert_equal(instance_info.id, backup.instance_id) assert_equal('COMPLETED', backup.status) @test def test_backup_list_for_instance(self): """"""test backup list for instance"""""" result = instance_info.dbaas.instances.backups(instance_info.id) assert_equal(1, len(result)) backup = result[0] assert_equal(BACKUP_NAME, backup.name) assert_equal(BACKUP_DESC, backup.description) assert_equal(instance_info.id, backup.instance_id) assert_equal('COMPLETED', backup.status) @test def test_backup_get(self): """"""test get backup"""""" backup = instance_info.dbaas.backups.get(backup_info.id) assert_equal(backup_info.id, backup.id) assert_equal(backup_info.name, backup.name) assert_equal(backup_info.description, backup.description) assert_equal(instance_info.id, backup.instance_id) assert_equal('COMPLETED', backup.status) @test(runs_after=[ListBackups], groups=[GROUP]) class RestoreUsingBackup(object): @test def test_restore(self): """"""test restore"""""" restorePoint = {""backupRef"": backup_info.id} result = instance_info.dbaas.instances.create( instance_info.name + ""_restore"", instance_info.dbaas_flavor_href, instance_info.volume, restorePoint=restorePoint) assert_equal(200, instance_info.dbaas.last_http_code) assert_equal(""BUILD"", result.status) global restore_instance_id restore_instance_id = result.id @test(depends_on_classes=[RestoreUsingBackup], runs_after=[RestoreUsingBackup], groups=[GROUP]) class WaitForRestoreToFinish(object): """""" Wait until the instance is finished restoring. """""" @test @time_out(60 * 32) def test_instance_restored(self): if test_config.auth_strategy == ""fake"": raise SkipTest(""Skipping restore tests for fake mode."") # This version just checks the REST API status. def result_is_active(): instance = instance_info.dbaas.instances.get(restore_instance_id) if instance.status == ""ACTIVE"": return True else: # If its not ACTIVE, anything but BUILD must be # an error. assert_equal(""BUILD"", instance.status) if instance_info.volume is not None: assert_equal(instance.volume.get('used', None), None) return False poll_until(result_is_active) @test(runs_after=[WaitForRestoreToFinish], groups=[GROUP]) class DeleteBackups(object): @test def test_delete_restored_instance(self): """"""test delete restored instance"""""" if test_config.auth_strategy == ""fake"": raise SkipTest(""Skipping delete restored instance for fake mode."") instance_info.dbaas.instances.delete(restore_instance_id) def instance_is_gone(): try: instance_info.dbaas.instances.get(restore_instance_id) return False except exceptions.NotFound: return True poll_until(instance_is_gone) assert_raises(exceptions.NotFound, instance_info.dbaas.instances.get, restore_instance_id) def test_backup_delete_not_found(self): """"""test delete unknown backup"""""" assert_raises(exceptions.NotFound, instance_info.dbaas.backups.delete, 'nonexistent_backup') @test @time_out(60 * 2) def test_backup_delete(self): """"""test delete"""""" instance_info.dbaas.backups.delete(backup_info.id) def backup_is_gone(): result = instance_info.dbaas.instances.backups(instance_info.id) if len(result) == 0: return True else: return False poll_until(backup_is_gone) assert_raises(exceptions.NotFound, instance_info.dbaas.backups.get, backup_info.id)",421,173
openstack%2Fnova~master~I0aa43ff085dfcd7bb6c665f0e25bbeb89aa549c7,openstack/nova,master,I0aa43ff085dfcd7bb6c665f0e25bbeb89aa549c7,Fix migrate and resize operation confusion issue.,ABANDONED,2013-07-01 12:40:38.000000000,2013-07-19 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 7040}, {'_account_id': 7494}]","[{'number': 2, 'created': '2013-07-01 12:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f91ece2cf408bf696db5229b7840aadc0656b379', 'message': 'Fix migrate and resize operation confusion issue.\n\nThe migrate and resize operation share the same code path as\nwell as instance status task status and notification messages\nin current nova code base, somehow it might confuse the user\nwhen he/she perform migrate but got VERIFY_RESIZE status, this\npatch fixed this issue by seperate different instance status,\ntask status and notification messages between migrate and resize.\n\nFixed bug #1196416\nFixed bug #1194019\n\nChange-Id: I0aa43ff085dfcd7bb6c665f0e25bbeb89aa549c7\n'}, {'number': 3, 'created': '2013-07-01 13:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6054cc523d98ed377ccfcc6c82e820ffd312ff7f', 'message': 'Fix migrate and resize operation confusion issue.\n\nThe migrate and resize operation share the same code path as\nwell as instance status task status and notification messages\nin current nova code base, somehow it might confuse the user\nwhen he/she perform migrate but got VERIFY_RESIZE status, this\npatch fixed this issue by seperate different instance status,\ntask status and notification messages between migrate and resize.\n\nFixed bug #1196416\nFixed bug #1194019\n\nChange-Id: I0aa43ff085dfcd7bb6c665f0e25bbeb89aa549c7\n'}, {'number': 4, 'created': '2013-07-02 06:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c26c4bed802f47a8420b3e01aea4e55ad9459cc', 'message': 'Fix migrate and resize operation confusion issue.\n\nThe migrate and resize operation share the same code path as\nwell as instance status task status and notification messages\nin current nova code base, somehow it might confuse the user\nwhen he/she perform migrate but got VERIFY_RESIZE status, this\npatch fixed this issue by seperate different instance status,\ntask status and notification messages between migrate and resize.\n\nFixed bug #1196416\nFixed bug #1194019\n\nChange-Id: I0aa43ff085dfcd7bb6c665f0e25bbeb89aa549c7\n'}, {'number': 5, 'created': '2013-07-02 08:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/590a623c94e63b263d457cc5f71f0abf5bebf67e', 'message': 'Fix migrate and resize operation confusion issue.\n\nThe migrate and resize operation share the same code path as\nwell as instance status task status and notification messages\nin current nova code base, somehow it might confuse the user\nwhen he/she perform migrate but got VERIFY_RESIZE status, this\npatch fixed this issue by seperate different instance status,\ntask status and notification messages between migrate and resize.\n\nFixed bug #1196416\nFixed bug #1194019\n\nChange-Id: I0aa43ff085dfcd7bb6c665f0e25bbeb89aa549c7\n'}, {'number': 6, 'created': '2013-07-07 19:54:28.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/compute/task_states.py', 'nova/api/openstack/common.py', 'nova/compute/manager.py', 'nova/compute/instance_actions.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ba4a09490852e9857df34de9091f21af50ba6815', 'message': 'Fix migrate and resize operation confusion issue.\n\nThe migrate and resize operation share the same code path as\nwell as instance status task status and notification messages\nin current nova code base, somehow it might confuse the user\nwhen he/she perform migrate but got VERIFY_RESIZE status, this\npatch fixed this issue by seperate different instance status,\ntask status and notification messages between migrate and resize.\n\nFixed bug #1196416\nFixed bug #1194019\n\nChange-Id: I0aa43ff085dfcd7bb6c665f0e25bbeb89aa549c7\n'}]",2,35127,ba4a09490852e9857df34de9091f21af50ba6815,21,6,5,7040,,,0,"Fix migrate and resize operation confusion issue.

The migrate and resize operation share the same code path as
well as instance status task status and notification messages
in current nova code base, somehow it might confuse the user
when he/she perform migrate but got VERIFY_RESIZE status, this
patch fixed this issue by seperate different instance status,
task status and notification messages between migrate and resize.

Fixed bug #1196416
Fixed bug #1194019

Change-Id: I0aa43ff085dfcd7bb6c665f0e25bbeb89aa549c7
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/35127/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/task_states.py', 'nova/compute/vm_states.py', 'nova/api/openstack/common.py', 'nova/compute/manager.py', 'nova/compute/instance_actions.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py']",7,f91ece2cf408bf696db5229b7840aadc0656b379,bug/1196416," # Ensure notifications on instance resize. def test_migrate_instance_notification(self): # Ensure notifications on instance migrate. old_time = datetime.datetime(2012, 4, 1) cur_time = datetime.datetime(2012, 12, 21, 12, 21) timeutils.set_time_override(old_time) instance = jsonutils.to_primitive(self._create_fake_instance()) self.compute.run_instance(self.context, instance=instance) timeutils.set_time_override(cur_time) test_notifier.NOTIFICATIONS = [] new_instance = db.instance_update(self.context, instance['uuid'], {'host': 'foo'}) new_instance = jsonutils.to_primitive(new_instance) instance_type = flavors.extract_flavor(new_instance) self.compute.prep_resize(self.context, instance=new_instance, instance_type=instance_type, image={}) db.migration_get_by_instance_and_status(self.context.elevated(), new_instance['uuid'], 'pre-migrating') self.assertEquals(len(test_notifier.NOTIFICATIONS), 3) msg = test_notifier.NOTIFICATIONS[0] self.assertEquals(msg['event_type'], 'compute.instance.exists') msg = test_notifier.NOTIFICATIONS[1] self.assertEquals(msg['event_type'], 'compute.instance.migrate.prep.start') msg = test_notifier.NOTIFICATIONS[2] self.assertEquals(msg['event_type'], 'compute.instance.migrate.prep.end') self.assertEquals(msg['priority'], 'INFO') payload = msg['payload'] self.assertEquals(payload['tenant_id'], self.project_id) self.assertEquals(payload['user_id'], self.user_id) self.assertEquals(payload['instance_id'], new_instance['uuid']) self.assertEquals(payload['instance_type'], 'm1.tiny') type_id = flavors.get_flavor_by_name('m1.tiny')['id'] self.assertEquals(str(payload['instance_type_id']), str(type_id)) self.assertTrue('display_name' in payload) self.assertTrue('created_at' in payload) self.assertTrue('launched_at' in payload) image_ref_url = glance.generate_image_url(FAKE_IMAGE_REF) self.assertEquals(payload['image_ref_url'], image_ref_url) self.compute.terminate_instance(self.context, instance=new_instance) # Ensure instance can be resized. def _test_migrate_instance(self, vm_state): # Ensure instance can be migrated. instance = jsonutils.to_primitive(self._create_fake_instance()) instance_type = flavors.get_flavor_by_name('m1.tiny') old_vm_state = vm_state self.compute.run_instance(self.context, instance=instance) new_instance = db.instance_update(self.context, instance['uuid'], {'host': 'foo'}) new_instance = jsonutils.to_primitive(new_instance) instance_uuid = new_instance['uuid'] new_instance = db.instance_update(self.context, instance_uuid, {'vm_state': old_vm_state}) self.compute.prep_resize(self.context, instance=new_instance, instance_type=instance_type, image={}) migration_ref = db.migration_get_by_instance_and_status( self.context.elevated(), instance_uuid, 'pre-migrating') # verify 'old_vm_state' was set on system_metadata inst = db.instance_get_by_uuid(self.context, instance_uuid) sys_meta = utils.metadata_to_dict(inst['system_metadata']) db.instance_update(self.context, instance_uuid, {""task_state"": task_states.MIGRATE_PREP}) self.compute.resize_instance(self.context, instance=new_instance, migration=migration_ref, image={}, instance_type=jsonutils.to_primitive(instance_type)) inst = db.instance_get_by_uuid(self.context, instance_uuid) self.assertEqual(migration_ref['dest_compute'], inst['host']) self.compute.terminate_instance(self.context, instance=jsonutils.to_primitive(inst)) def test_migrate_from_active(self): # Ensure instance can be migrated with active status. self._test_migrate_instance(vm_states.ACTIVE) def test_migrate_from_stopped(self): # Ensure instance can be migrated with stopped status. self._test_migrate_instance(vm_states.STOPPED) self.compute_api.resize(self.context, instance, flavors.get_flavor_by_name('m1.large')['id']) self.assertNotEqual(request_spec['instance_type'], old_instance_type) # progress set to 0 and task_state set to MIGRATE_PREP. old_instance_type = flavors.extract_flavor(instance) new_instance_type = flavors.get_flavor_by_name('m1.xlarge') self.compute_api.resize(self.context, instance, new_instance_type['id']) self.compute_api.resize(self.context, instance, flavors.get_flavor_by_name('m1.large')['id']) task_states.MIGRATE_PREP).AndRaise( task_states.MIGRATE_PREP, exc_info).AndReturn(True)"," # Ensure notifications on instance migrate/resize. # Ensure instance can be migrated/resized. self.compute_api.resize(self.context, instance, None) self.assertEqual(request_spec['instance_type'], orig_instance_type) # progress set to 0 and task_state set to RESIZE_PREP. orig_instance_type = flavors.extract_flavor(instance) self.compute_api.resize(self.context, instance, None) self.compute_api.resize(self.context, instance, None) task_states.RESIZE_PREP).AndRaise( task_states.RESIZE_PREP, exc_info).AndReturn(True)",194,34
openstack%2Fnova~stable%2Ffolsom~Ifaa9910e13614554d1769e71e8eba9587ec5a13b,openstack/nova,stable/folsom,Ifaa9910e13614554d1769e71e8eba9587ec5a13b,Fix 'to integer' conversion of max and min count values,ABANDONED,2013-06-26 05:52:58.000000000,2013-07-19 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1812}, {'_account_id': 2914}, {'_account_id': 5174}, {'_account_id': 5652}, {'_account_id': 7598}]","[{'number': 1, 'created': '2013-06-26 05:52:58.000000000', 'files': ['nova/tests/api/openstack/compute/test_servers.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/998778e9b503a3249edc714b15ccdbc10e9721c4', 'message': ""Fix 'to integer' conversion of max and min count values\n\nUntil now when you used values non-integer to max_count and/or min_count the\ncoercion worked like: min_count = int(2.5) so min_count received 2 instead of\nraise bad request.\n\nConvert to string before coerce to int solves the problem since int coercion\ncannot convert from a string which is not a perfect int.\n\nConflicts:\n\tnova/tests/api/openstack/compute/test_servers.py\n\nChange-Id: Ifaa9910e13614554d1769e71e8eba9587ec5a13b\n(cherry picked from commit 6b3bba9141c7fdc4b00025f7e6ee8d980e41ec9a)\n""}]",0,34495,998778e9b503a3249edc714b15ccdbc10e9721c4,8,7,1,7915,,,0,"Fix 'to integer' conversion of max and min count values

Until now when you used values non-integer to max_count and/or min_count the
coercion worked like: min_count = int(2.5) so min_count received 2 instead of
raise bad request.

Convert to string before coerce to int solves the problem since int coercion
cannot convert from a string which is not a perfect int.

Conflicts:
	nova/tests/api/openstack/compute/test_servers.py

Change-Id: Ifaa9910e13614554d1769e71e8eba9587ec5a13b
(cherry picked from commit 6b3bba9141c7fdc4b00025f7e6ee8d980e41ec9a)
",git fetch https://review.opendev.org/openstack/nova refs/changes/95/34495/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/test_servers.py', 'nova/api/openstack/compute/servers.py']",2,998778e9b503a3249edc714b15ccdbc10e9721c4,, min_count = int(str(min_count)) max_count = int(str(max_count)), min_count = int(min_count) max_count = int(max_count),48,2
openstack%2Fneutron~master~Ia697a2deeb9dd639ae3b7d0843fea60f83d9cde4,openstack/neutron,master,Ia697a2deeb9dd639ae3b7d0843fea60f83d9cde4,add possibility to rewrite existing configurations,ABANDONED,2013-07-18 13:05:19.000000000,2013-07-19 05:46:41.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 748}]","[{'number': 1, 'created': '2013-07-18 13:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa595c4e6774c2f38b6447cecc3990c18f5d1c46', 'message': ""add possibility to rewrite existing configurations\n\nInside the methods _output_opts_file and _output_hosts_file the method\nutils.replace_file is used to write the new options/hosts. It first\ncreates a temporary file and afterwards renames this temporary file to\nthe name of the destination file.\n\nThis patch adds the possibility to directly write the new configuration\ninto the existing files. That's necessary for some environments to not\nchange the existings inodes of the configuration files.\n\nfixes bug #1202641\n\nChange-Id: Ia697a2deeb9dd639ae3b7d0843fea60f83d9cde4\n""}, {'number': 2, 'created': '2013-07-18 13:31:01.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/agent/linux/utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f883411cf5b0b59fdc47323bcb798dd1c2adf997', 'message': ""add possibility to rewrite existing configurations\n\nInside the methods _output_opts_file and _output_hosts_file the method\nutils.replace_file is used to write the new options/hosts. It first\ncreates a temporary file and afterwards renames this temporary file to\nthe name of the destination file.\n\nThis patch adds the possibility to directly write the new configuration\ninto the existing files. That's necessary for some environments to not\nchange the existings inodes of the configuration files.\n\nfixes bug #1202641\n\nChange-Id: Ia697a2deeb9dd639ae3b7d0843fea60f83d9cde4\n""}]",2,37675,f883411cf5b0b59fdc47323bcb798dd1c2adf997,5,3,2,167,,,0,"add possibility to rewrite existing configurations

Inside the methods _output_opts_file and _output_hosts_file the method
utils.replace_file is used to write the new options/hosts. It first
creates a temporary file and afterwards renames this temporary file to
the name of the destination file.

This patch adds the possibility to directly write the new configuration
into the existing files. That's necessary for some environments to not
change the existings inodes of the configuration files.

fixes bug #1202641

Change-Id: Ia697a2deeb9dd639ae3b7d0843fea60f83d9cde4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/37675/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/dhcp.py', 'neutron/agent/linux/utils.py']",2,aa595c4e6774c2f38b6447cecc3990c18f5d1c46,bug/1202641," def rewrite_file(file_name, data): """"""Truncates an existing file file_name and writes data afterwards. It's sometimes necessary to keep the inode of an existing file to not corrupt open file handles inside external processes (like dnsmasq). """""" fp = open(file_name, 'w') fp.write(data) fp.close()",,24,4
openstack%2Fneutron~master~Ic660f079a976f36be6df39149337ac53a454b562,openstack/neutron,master,Ic660f079a976f36be6df39149337ac53a454b562,Fix migration branch,ABANDONED,2013-07-19 01:20:03.000000000,2013-07-19 05:44:18.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-19 01:20:03.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/20ae61555e95_ml2_gre_type_driver.py', 'neutron/db/migration/alembic_migrations/versions/2032abe8edac_lbaas_add_status_des.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0b89c55ae53f82a26cf41367614d53dd79cf2fe4', 'message': 'Fix migration branch\n\nBug #1202897\n\nChange-Id: Ic660f079a976f36be6df39149337ac53a454b562\n'}]",0,37823,0b89c55ae53f82a26cf41367614d53dd79cf2fe4,10,5,1,261,,,0,"Fix migration branch

Bug #1202897

Change-Id: Ic660f079a976f36be6df39149337ac53a454b562
",git fetch https://review.opendev.org/openstack/neutron refs/changes/23/37823/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/20ae61555e95_ml2_gre_type_driver.py', 'neutron/db/migration/alembic_migrations/versions/2032abe8edac_lbaas_add_status_des.py']",2,0b89c55ae53f82a26cf41367614d53dd79cf2fe4,bug/1202897,Revises: 13de305df56edown_revision = '13de305df56e',Revises: b7a8863760edown_revision = 'b7a8863760e',4,4
openstack%2Fnova~master~Ia438999f32cd1f146a9dcfabc0b653dbbeb68633,openstack/nova,master,Ia438999f32cd1f146a9dcfabc0b653dbbeb68633,Do not merge: time trial of not setting a default value for a col,ABANDONED,2013-07-17 02:18:49.000000000,2013-07-19 04:40:06.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2271}]","[{'number': 1, 'created': '2013-07-17 02:18:49.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/201_add_instance_cleaned.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/46c28d21ce2e0f5af42f9c1953d29cec7384e2e6', 'message': 'Do not merge: time trial of not setting a default value for a col\n\nJust seeing if not setting a default value for a new column is\nfaster or not.\n\nChange-Id: Ia438999f32cd1f146a9dcfabc0b653dbbeb68633\n'}]",0,37374,46c28d21ce2e0f5af42f9c1953d29cec7384e2e6,5,3,1,2271,,,0,"Do not merge: time trial of not setting a default value for a col

Just seeing if not setting a default value for a new column is
faster or not.

Change-Id: Ia438999f32cd1f146a9dcfabc0b653dbbeb68633
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/37374/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/migrate_repo/versions/201_add_instance_cleaned.py'],1,46c28d21ce2e0f5af42f9c1953d29cec7384e2e6,bp/deferred-instance-delete-timetrial-1,"# Copyright 2013 Rackspace Australia # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from sqlalchemy import Column, Index, Integer, MetaData, Table def upgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine instances = Table('instances', meta, autoload=True) shadow_instances = Table('shadow_instances', meta, autoload=True) cleaned_column = Column('cleaned', Integer) instances.create_column(cleaned_column) shadow_instances.create_column(cleaned_column.copy()) cleaned_index = Index('instances_cleaned_idx', instances.c.cleaned) cleaned_index.create(migrate_engine) def downgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine instances = Table('instances', meta, autoload=True) instances.columns.cleaned.drop() shadow_instances = Table('shadow_instances', meta, autoload=True) shadow_instances.columns.cleaned.drop() ",,41,0
openstack%2Fneutron~master~I5c3a00c737903aa59cc6a2a248ee61aa53e54fbe,openstack/neutron,master,I5c3a00c737903aa59cc6a2a248ee61aa53e54fbe,Add decorator helping to log method calls.,MERGED,2013-07-15 09:01:47.000000000,2013-07-19 04:20:21.000000000,2013-07-19 04:20:20.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 7141}]","[{'number': 1, 'created': '2013-07-15 09:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ade4d3c1fed55a3397a298ced5e9be98fe8c9f19', 'message': 'Add decorator helping to log method calls.\n\nChange-Id: I5c3a00c737903aa59cc6a2a248ee61aa53e54fbe\n'}, {'number': 2, 'created': '2013-07-15 09:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1ba47b1ea6f328553dfffb7ac8e31d217be7e37a', 'message': 'Add decorator helping to log method calls.\n\nFixes bug 1201328\n\nChange-Id: I5c3a00c737903aa59cc6a2a248ee61aa53e54fbe\n'}, {'number': 3, 'created': '2013-07-16 15:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/decf800c9a8d7b64b428e1bb629e141e5cf66b9f', 'message': 'Add decorator helping to log method calls.\n\nFixes bug 1201328\n\nChange-Id: I5c3a00c737903aa59cc6a2a248ee61aa53e54fbe\n'}, {'number': 4, 'created': '2013-07-17 08:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/16e03e2cadcd86b689956c1e4ee0ea0485c78e3c', 'message': 'Add decorator helping to log method calls.\n\nFixes bug 1201328\n\nChange-Id: I5c3a00c737903aa59cc6a2a248ee61aa53e54fbe\n'}, {'number': 5, 'created': '2013-07-17 08:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f0a33852b235969f186ccb5c3fbdeaa4faf9b06', 'message': 'Add decorator helping to log method calls.\n\nFixes bug 1201328\n\nChange-Id: I5c3a00c737903aa59cc6a2a248ee61aa53e54fbe\n'}, {'number': 6, 'created': '2013-07-17 08:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f7b066a899ed66302e7f9bb75081836951e48253', 'message': 'Add decorator helping to log method calls.\n\nFixes bug 1201328\n\nChange-Id: I5c3a00c737903aa59cc6a2a248ee61aa53e54fbe\n'}, {'number': 7, 'created': '2013-07-18 08:50:42.000000000', 'files': ['neutron/services/loadbalancer/drivers/noop/noop_driver.py', 'neutron/common/log.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c2427c277368109b1ab747c3447e8c95f954733a', 'message': 'Add decorator helping to log method calls.\n\nFixes bug 1201328\n\nChange-Id: I5c3a00c737903aa59cc6a2a248ee61aa53e54fbe\n'}]",6,37033,c2427c277368109b1ab747c3447e8c95f954733a,39,9,7,7141,,,0,"Add decorator helping to log method calls.

Fixes bug 1201328

Change-Id: I5c3a00c737903aa59cc6a2a248ee61aa53e54fbe
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/37033/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/common/utils.py'],1,ade4d3c1fed55a3397a298ced5e9be98fe8c9f19,bug/1201328," def log(method): """"""Decorator helping to log method calls."""""" def wrapper(*args, **kwargs): instance = args[0] data = {""class_name"": instance.__class__.__name__, ""method_name"": method.__name__, ""args"": args, ""kwargs"": kwargs} LOG.debug(_('%(class_name)s method %(method_name)s' 'called with arguments %(args)s %(kwargs)s ') % data) return method(*args, **kwargs) return wrapper",,14,0
openstack%2Fswift~master~I5d363249676032a025a22a67275c2eed3151b264,openstack/swift,master,I5d363249676032a025a22a67275c2eed3151b264,Ensure that files are always closed in the tests.,MERGED,2013-07-19 00:31:47.000000000,2013-07-19 03:30:16.000000000,2013-07-19 03:30:16.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7652}]","[{'number': 1, 'created': '2013-07-19 00:31:47.000000000', 'files': ['test/unit/proxy/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/710e4a007f29c7c7589482282ab4588a4b8bb38a', 'message': 'Ensure that files are always closed in the tests.\n\nA failure to close files in a timely fassion means\nthat data is not necessarily written immediately\non Pythons which do not use reference counting\n(e.g. PyPy).\n\nChange-Id: I5d363249676032a025a22a67275c2eed3151b264\n'}]",0,37816,710e4a007f29c7c7589482282ab4588a4b8bb38a,10,5,1,7680,,,0,"Ensure that files are always closed in the tests.

A failure to close files in a timely fassion means
that data is not necessarily written immediately
on Pythons which do not use reference counting
(e.g. PyPy).

Change-Id: I5d363249676032a025a22a67275c2eed3151b264
",git fetch https://review.opendev.org/openstack/swift refs/changes/16/37816/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/proxy/test_server.py'],1,710e4a007f29c7c7589482282ab4588a4b8bb38a,close-files," with GzipFile(os.path.join(_testdir, 'account.ring.gz'), 'wb') as f: pickle.dump(ring.RingData([[0, 1, 0, 1], [1, 0, 1, 0]], [{'id': 0, 'zone': 0, 'device': 'sda1', 'ip': '127.0.0.1', 'port': acc1lis.getsockname()[1]}, {'id': 1, 'zone': 1, 'device': 'sdb1', 'ip': '127.0.0.1', 'port': acc2lis.getsockname()[1]}], 30), f) with GzipFile(os.path.join(_testdir, 'container.ring.gz'), 'wb') as f: pickle.dump(ring.RingData([[0, 1, 0, 1], [1, 0, 1, 0]], [{'id': 0, 'zone': 0, 'device': 'sda1', 'ip': '127.0.0.1', 'port': con1lis.getsockname()[1]}, {'id': 1, 'zone': 1, 'device': 'sdb1', 'ip': '127.0.0.1', 'port': con2lis.getsockname()[1]}], 30), f) with GzipFile(os.path.join(_testdir, 'object.ring.gz'), 'wb') as f: pickle.dump(ring.RingData([[0, 1, 0, 1], [1, 0, 1, 0]], [{'id': 0, 'zone': 0, 'device': 'sda1', 'ip': '127.0.0.1', 'port': obj1lis.getsockname()[1]}, {'id': 1, 'zone': 1, 'device': 'sdb1', 'ip': '127.0.0.1', 'port': obj2lis.getsockname()[1]}], 30), f)"," pickle.dump(ring.RingData([[0, 1, 0, 1], [1, 0, 1, 0]], [{'id': 0, 'zone': 0, 'device': 'sda1', 'ip': '127.0.0.1', 'port': acc1lis.getsockname()[1]}, {'id': 1, 'zone': 1, 'device': 'sdb1', 'ip': '127.0.0.1', 'port': acc2lis.getsockname()[1]}], 30), GzipFile(os.path.join(_testdir, 'account.ring.gz'), 'wb')) pickle.dump(ring.RingData([[0, 1, 0, 1], [1, 0, 1, 0]], [{'id': 0, 'zone': 0, 'device': 'sda1', 'ip': '127.0.0.1', 'port': con1lis.getsockname()[1]}, {'id': 1, 'zone': 1, 'device': 'sdb1', 'ip': '127.0.0.1', 'port': con2lis.getsockname()[1]}], 30), GzipFile(os.path.join(_testdir, 'container.ring.gz'), 'wb')) pickle.dump(ring.RingData([[0, 1, 0, 1], [1, 0, 1, 0]], [{'id': 0, 'zone': 0, 'device': 'sda1', 'ip': '127.0.0.1', 'port': obj1lis.getsockname()[1]}, {'id': 1, 'zone': 1, 'device': 'sdb1', 'ip': '127.0.0.1', 'port': obj2lis.getsockname()[1]}], 30), GzipFile(os.path.join(_testdir, 'object.ring.gz'), 'wb'))",21,18
openstack%2Fneutron~master~Ib240a42ba1075d9a410da904b3d3ae9e19b2d86e,openstack/neutron,master,Ib240a42ba1075d9a410da904b3d3ae9e19b2d86e,Allow to clear extra routes in NVP,MERGED,2013-07-19 00:55:15.000000000,2013-07-19 02:45:13.000000000,2013-07-19 02:45:13.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 4395}]","[{'number': 1, 'created': '2013-07-19 00:55:15.000000000', 'files': ['neutron/plugins/nicira/nvplib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f129121a1c8331c702204cf95951444ae53ef9c', 'message': 'Allow to clear extra routes in NVP\n\nSince the neutron client can unset any attribute, ensure\nwe can handle empty routes as a way to clear the extraroutes\nfor the router.\n\nFixes bug #1202890\n\nChange-Id: Ib240a42ba1075d9a410da904b3d3ae9e19b2d86e\n'}]",0,37820,0f129121a1c8331c702204cf95951444ae53ef9c,6,3,1,748,,,0,"Allow to clear extra routes in NVP

Since the neutron client can unset any attribute, ensure
we can handle empty routes as a way to clear the extraroutes
for the router.

Fixes bug #1202890

Change-Id: Ib240a42ba1075d9a410da904b3d3ae9e19b2d86e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/37820/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/nicira/nvplib.py'],1,0f129121a1c8331c702204cf95951444ae53ef9c,bug/1202890, if routes is not None:, if routes:,1,1
openstack%2Freviewday~master~I4f2cbcc262973b02e3a13b9bba1edde53d5e6d9e,openstack/reviewday,master,I4f2cbcc262973b02e3a13b9bba1edde53d5e6d9e,LP specification name caching.,MERGED,2013-07-17 13:52:15.000000000,2013-07-19 01:22:09.000000000,2013-07-19 01:22:09.000000000,"[{'_account_id': 3}, {'_account_id': 360}]","[{'number': 1, 'created': '2013-07-17 13:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/reviewday/commit/7d5490eb0bcf3c237162ff56b8fe4b5c0e3ab5db', 'message': 'LP specification name caching.\n\nThis updates our LP calls to obtain blueprint information so that\nthey run faster. Previously calling spec.name would cause an LP hit\nfor each spec. Given that we call lp.specification many times during\na reviewday run this was causing slow runtimes.\n\nWhat we do now is just scrap the blueprint name off of the Spec URL\n(thus avoiding an extra LP hit).\n\nChange-Id: I4f2cbcc262973b02e3a13b9bba1edde53d5e6d9e\n'}, {'number': 2, 'created': '2013-07-17 13:56:10.000000000', 'files': ['reviewday/launchpad.py'], 'web_link': 'https://opendev.org/openstack/reviewday/commit/82c28bd48b72e20a8acc9e6337852f8509e9293a', 'message': 'LP specification name caching.\n\nThis updates our LP calls to obtain blueprint information so that\nthey run faster. Previously calling spec.name would cause an LP hit\nfor each spec. Given that we call lp.specification many times during\na reviewday run this was causing slow runtimes.\n\nWhat we do now is just scrap the blueprint name off of the Spec URL\n(thus avoiding many of the extra LP hits).\n\nChange-Id: I4f2cbcc262973b02e3a13b9bba1edde53d5e6d9e\n'}]",0,37475,82c28bd48b72e20a8acc9e6337852f8509e9293a,8,2,2,360,,,0,"LP specification name caching.

This updates our LP calls to obtain blueprint information so that
they run faster. Previously calling spec.name would cause an LP hit
for each spec. Given that we call lp.specification many times during
a reviewday run this was causing slow runtimes.

What we do now is just scrap the blueprint name off of the Spec URL
(thus avoiding many of the extra LP hits).

Change-Id: I4f2cbcc262973b02e3a13b9bba1edde53d5e6d9e
",git fetch https://review.opendev.org/openstack/reviewday refs/changes/75/37475/1 && git format-patch -1 --stdout FETCH_HEAD,['reviewday/launchpad.py'],1,7d5490eb0bcf3c237162ff56b8fe4b5c0e3ab5db,bp/information," cache = {} for spec in specs: spec_str = str(spec) spec_name = spec_str[spec_str.index('+spec/')+6:] cache[spec_name] = spec self.spec_cache[project] = cache for name, spec in specs.iteritems(): if name == spec_name:", self.spec_cache[project] = specs for spec in specs: if spec.name == spec_name:,8,3
openstack%2Fswift~master~I75ac7c6f0230e71bfb24328e44c33734b520b4cd,openstack/swift,master,I75ac7c6f0230e71bfb24328e44c33734b520b4cd,Refactor and add tests for db_replicator,MERGED,2013-05-20 16:49:55.000000000,2013-07-19 01:21:54.000000000,2013-07-19 01:21:54.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1531}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 2696}, {'_account_id': 6529}]","[{'number': 1, 'created': '2013-05-20 16:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2895b769dd96a643157e86def0f29316d0696234', 'message': 'Add tests for db_replicator\n\nAdd tests for replicate_object and _repl_to_node functions.\n\nChange-Id: I75ac7c6f0230e71bfb24328e44c33734b520b4cd\n'}, {'number': 2, 'created': '2013-05-21 15:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/34b4e83957d2d7742573802302483e6ac38a03b7', 'message': 'Refactor and add tests for db_replicator\n\n* Create class for testing _repl_to_not and replicate_object fuctions to\n  prevent duplication code by adding all preparation into setUp function.\n* Move existed test function which testin _repl_to_not and\n  replicate_object into created classes.\n* Add tests for replicate_object and _repl_to_node functions.\n\nChange-Id: I75ac7c6f0230e71bfb24328e44c33734b520b4cd\n'}, {'number': 3, 'created': '2013-05-21 19:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2e2c8727ef8a3fd0ebadac8c251b290af28f3ef7', 'message': 'Refactor and add tests for db_replicator\n\n* Create class for testing _repl_to_not and replicate_object fuctions to\n  prevent duplication code by adding all preparation into setUp function.\n* Move existed test function which testin _repl_to_not and\n  replicate_object into created classes.\n* Add tests for replicate_object and _repl_to_node functions.\n\nChange-Id: I75ac7c6f0230e71bfb24328e44c33734b520b4cd\n'}, {'number': 4, 'created': '2013-05-24 09:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bce37bf59ba6c01927e7907928035ff71f05dcfd', 'message': 'Refactor and add tests for db_replicator\n\n* Create class for testing _repl_to_not and replicate_object fuctions to\n  prevent duplication code by adding all preparation into setUp function.\n* Move existed test function which testin _repl_to_not and\n  replicate_object into created classes.\n* Add tests for replicate_object and _repl_to_node functions.\n\nChange-Id: I75ac7c6f0230e71bfb24328e44c33734b520b4cd\n'}, {'number': 5, 'created': '2013-05-24 13:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/36d4796fa58da968fde2b3a8eb828d446793e19d', 'message': 'Refactor and add tests for db_replicator\n\n* Create class for testing _repl_to_not and replicate_object fuctions to\n  prevent duplication code by adding all preparation into setUp function.\n* Move existed test function which testin _repl_to_not and\n  replicate_object into created classes.\n* Add tests for replicate_object and _repl_to_node functions.\n\nChange-Id: I75ac7c6f0230e71bfb24328e44c33734b520b4cd\n'}, {'number': 6, 'created': '2013-06-19 08:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/57825f15f95c0d3f12692469e0dc3f930ea2157d', 'message': 'Refactor and add tests for db_replicator\n\n* Create class for testing _repl_to_not and replicate_object fuctions to\n  prevent duplication code by adding all preparation into setUp function.\n* Move existed test function which testin _repl_to_not and\n  replicate_object into created classes.\n* Add tests for replicate_object and _repl_to_node functions.\n\nChange-Id: I75ac7c6f0230e71bfb24328e44c33734b520b4cd\n'}, {'number': 7, 'created': '2013-07-02 13:11:09.000000000', 'files': ['test/unit/common/test_db_replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/1f7d2a60d658935391fbab6cee6d3f37c8f8788e', 'message': 'Refactor and add tests for db_replicator\n\n* Create class for testing _repl_to_not and replicate_object fuctions to\n  prevent duplication code by adding all preparation into setUp function.\n* Move existed test function which testin _repl_to_not and\n  replicate_object into created classes.\n* Add tests for replicate_object and _repl_to_node functions.\n\nChange-Id: I75ac7c6f0230e71bfb24328e44c33734b520b4cd\n'}]",4,29798,1f7d2a60d658935391fbab6cee6d3f37c8f8788e,29,7,7,6529,,,0,"Refactor and add tests for db_replicator

* Create class for testing _repl_to_not and replicate_object fuctions to
  prevent duplication code by adding all preparation into setUp function.
* Move existed test function which testin _repl_to_not and
  replicate_object into created classes.
* Add tests for replicate_object and _repl_to_node functions.

Change-Id: I75ac7c6f0230e71bfb24328e44c33734b520b4cd
",git fetch https://review.opendev.org/openstack/swift refs/changes/98/29798/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/common/test_db_replicator.py'],1,2895b769dd96a643157e86def0f29316d0696234,tests_for_db_replicator,"import mock import simplejsonfrom swift.common.exceptions import DriveNotMounted meta='' ), dict( id=5, weight=10.0, zone=5, ip='1.1.1.5', port=6000, device='sdb', meta='' ), dict( id=6, weight=10.0, zone=6, ip='1.1.1.6', port=6000, device='sdb', def __init__(self, response=None, set_status=200): self.set_status = set_status status = self.set_statusclass TestReplToNode(unittest.TestCase): def setUp(self): db_replicator.ring = FakeRing() self.delete_db_calls = [] self.replicator = TestReplicator({}) self.fake_node = {'ip': '127.0.0.1', 'device': 'sda1', 'port': 1000} self.fake_info = {'id': 'a', 'point': -1, 'max_row': 10, 'hash': 'b', 'created_at': 100, 'put_timestamp': 0, 'delete_timestamp': 0, 'count': 0, 'metadata': {'Test': ('Value', normalize_timestamp(1))}} self.replicator.logger= mock.Mock() self.replicator._rsync_db = mock.Mock(return_value=True) self.replicator._usync_db = mock.Mock(return_value=True) def test_repl_to_node_usync_success(self): rinfo = {""id"": 3, ""point"": -1, ""max_row"": 5, ""hash"": ""c""} http = ReplHttp(simplejson.dumps(rinfo)) broker = FakeBroker() local_sync = broker.get_sync() self.replicator._http_connect = lambda *args: http self.assertEquals(self.replicator._repl_to_node( self.fake_node, broker, '0', self.fake_info), True) self.replicator._usync_db.assert_has_calls( [mock.call(max(rinfo['point'], local_sync), broker, http, rinfo['id'], self.fake_info['id'])]) def test_repl_to_node_rsync_success(self): rinfo = {""id"": 3, ""point"": -1, ""max_row"": 4, ""hash"": ""c""} http = ReplHttp(simplejson.dumps(rinfo)) broker = FakeBroker() local_sync = broker.get_sync() self.replicator._http_connect = lambda *args: http self.assertEquals(self.replicator._repl_to_node( self.fake_node, broker, '0', self.fake_info), True) self.replicator.logger.increment.assert_has_calls( [mock.call.increment('remote_merges')]) self.replicator._rsync_db.assert_has_calls( [mock.call(broker, self.fake_node, http, self.fake_info['id'], replicate_method='rsync_then_merge', replicate_timeout=(self.fake_info['count'] / 2000))]) def test_repl_to_node_already_in_sync(self): rinfo = {""id"": 3, ""point"": -1, ""max_row"": 10, ""hash"": ""b""} http = ReplHttp(simplejson.dumps(rinfo)) broker = FakeBroker() local_sync = broker.get_sync() self.replicator._http_connect = lambda *args: http self.assertEquals(self.replicator._repl_to_node( self.fake_node, broker, '0', self.fake_info), True) self.assertEquals(self.replicator._rsync_db.call_count, 0) self.assertEquals(self.replicator._usync_db.call_count, 0) def test_repl_to_node_not_found(self): http = ReplHttp('{""id"": 3, ""point"": -1}', set_status=404) self.replicator._http_connect = lambda *args: http broker = FakeBroker() self.assertEquals(self.replicator._repl_to_node( self.fake_node, broker, '0', self.fake_info), True) self.replicator.logger.increment.assert_has_calls( [mock.call.increment('rsyncs')]) self.replicator._rsync_db.assert_has_calls( [mock.call(broker, self.fake_node, http, self.fake_info['id'])]) def test_repl_to_node_drive_not_mounted(self): self.replicator._http_connect = lambda *args: ReplHttp( '{""id"": 3, ""point"": -1}', set_status=507) self.assertRaises(DriveNotMounted, self.replicator._repl_to_node, self.fake_node, FakeBroker(), '0', self.fake_info) def test_repl_to_node_300_status(self): self.replicator._http_connect = lambda *args: ReplHttp( '{""id"": 3, ""point"": -1}', set_status=300) self.assertEquals(self.replicator._repl_to_node( self.fake_node, FakeBroker(), '0', self.fake_info), None) def test_repl_to_node_http_connect_fails(self): self.replicator._http_connect = lambda *args: None self.assertEquals(self.replicator._repl_to_node( self.fake_node, FakeBroker(), '0', self.fake_info), False) def test_repl_to_node_not_response(self): def http(*args): pass http.replicate = lambda *args: None self.replicator._http_connect = lambda *args: http self.assertEquals(self.replicator._repl_to_node( self.fake_node, FakeBroker(), '0', self.fake_info), False) class TestReplicateObject(unittest.TestCase): def setUp(self): db_replicator.ring = FakeRingWithNodes self.replicator = TestReplicator({}) self.replicator.logger.increment = mock.Mock() self.replicator.delete_db = mock.Mock() self._patchers = [] def tearDown(self): for patcher in self._patchers: patcher.stop() def _patch(self, patching_fn, *args, **kwargs): patcher = patching_fn(*args, **kwargs) patched_thing = patcher.start() self._patchers.append(patcher) return patched_thing def test_replicate_quarantine(self): def mock_renamer(was, new, cause_colision=False): if cause_colision and '-' not in new: raise OSError(errno.EEXIST, ""File already exists"") self.assertEquals('/a/b/c/d/e', was) if '-' in new: self.assert_( new.startswith('/a/quarantined/containers/e-')) else: self.assertEquals('/a/quarantined/containers/e', new) def mock_renamer_error(was, new): return mock_renamer(was, new, cause_colision=True) self._patch(patch.object, self.replicator.brokerclass, 'db_file', '/a/b/c/d/e/hey') self._patch(patch.object, self.replicator.brokerclass, 'get_repl_missing_table', True) with patch.object(db_replicator, 'renamer', mock_renamer): self.assertEquals( None, self.replicator._replicate_object('0', 'file', 'node_id')) with patch.object(db_replicator, 'renamer', mock_renamer_error): self.assertEquals( None, self.replicator._replicate_object('0', 'file', 'node_id')) def test_replicate_primary_success(self): self.replicator._repl_to_node = mock.Mock(return_value=True) self.replicator._replicate_object('0', '/path/to/file', 1) nodes = \ [call[0][0] for call in \ self.replicator._repl_to_node.call_args_list] self.assertEquals(nodes, db_replicator.ring.Ring.devs[1:3]) self.assertEquals(self.replicator.delete_db.call_count, 0) self.replicator.logger.increment.assert_has_calls( [mock.call.increment('attempts'), mock.call.increment('successes'), mock.call.increment('successes')]) def test_replicate_primary_drive_not_mount(self): self.replicator._repl_to_node = mock.Mock(side_effect=[True, DriveNotMounted, DriveNotMounted, True]) self.replicator._replicate_object('0', '/path/to/file', 1) nodes = \ [call[0][0] for call in \ self.replicator._repl_to_node.call_args_list] self.assertEquals(nodes, db_replicator.ring.Ring.devs[1:5]) self.assertEquals(self.replicator.delete_db.call_count, 0) self.replicator.logger.increment.assert_has_calls( [mock.call('attempts'), mock.call('successes'), mock.call('failures'), mock.call('failures'), mock.call('successes')]) def test_replicate_primary_exception(self): self.replicator._repl_to_node = mock.Mock(side_effect=[True, Exception]) self.replicator._replicate_object('0', '/path/to/file', 1) nodes = \ [call[0][0] for call in \ self.replicator._repl_to_node.call_args_list] self.assertEquals(nodes, db_replicator.ring.Ring.devs[1:3]) self.assertEquals(self.replicator.delete_db.call_count, 0) self.replicator.logger.increment.assert_has_calls( [mock.call('attempts'), mock.call('successes'), mock.call('failures')]) def test_replicate_handoff_success(self): self.replicator._repl_to_node = mock.Mock(return_value=True) self.replicator._replicate_object('0', '/path/to/file', 4) nodes = \ [call[0][0] for call in \ self.replicator._repl_to_node.call_args_list] self.assertEquals(nodes, db_replicator.ring.Ring.devs[:3]) self.assertEquals(self.replicator.delete_db.call_count, 1) self.replicator.logger.increment.assert_has_calls( [mock.call('attempts'), mock.call('successes'), mock.call('successes'), mock.call('successes')]) def test_replicate_handoff_drive_not_mount(self): self.replicator._repl_to_node = mock.Mock(side_effect=[True, DriveNotMounted, True, True]) self.replicator._replicate_object('0', '/path/to/file', 4) nodes = \ [call[0][0] for call in \ self.replicator._repl_to_node.call_args_list] self.assertEquals(nodes, db_replicator.ring.Ring.devs[0:4]) self.assertEquals(self.replicator.delete_db.call_count, 0) self.replicator.logger.increment.assert_has_calls( [mock.call('attempts'), mock.call('successes'), mock.call('failures'), mock.call('successes'), mock.call('successes')]) def test_replicate_handoff_drive_not_mount(self): self.replicator._repl_to_node = mock.Mock(side_effect=[True, DriveNotMounted, True, True]) self.replicator._replicate_object('0', '/path/to/file', 4) nodes = \ [call[0][0] for call in \ self.replicator._repl_to_node.call_args_list] self.assertEquals(nodes, db_replicator.ring.Ring.devs[0:4]) self.assertEquals(self.replicator.delete_db.call_count, 0) self.replicator.logger.increment.assert_has_calls( [mock.call('attempts'), mock.call('successes'), mock.call('failures'), mock.call('successes'), mock.call('successes')]) "," def __init__(self, response=None): status = 200 def test_repl_to_node(self): replicator = TestReplicator({}) fake_node = {'ip': '127.0.0.1', 'device': 'sda1', 'port': 1000} fake_info = {'id': 'a', 'point': -1, 'max_row': 0, 'hash': 'b', 'created_at': 100, 'put_timestamp': 0, 'delete_timestamp': 0, 'metadata': {'Test': ('Value', normalize_timestamp(1))}} replicator._http_connect = lambda *args: ReplHttp( '{""id"": 3, ""point"": -1}') self.assertEquals(replicator._repl_to_node( fake_node, FakeBroker(), '0', fake_info), True) def test_replicate_object(self): db_replicator.ring = FakeRingWithNodes() replicator = TestReplicator({}) replicator.delete_db = self.stub_delete_db replicator._replicate_object('0', '/path/to/file', 'node_id') self.assertEquals([], self.delete_db_calls) def test_replicate_object_quarantine(self): replicator = TestReplicator({}) was_db_file = replicator.brokerclass.db_file try: def mock_renamer(was, new, cause_colision=False): if cause_colision and '-' not in new: raise OSError(errno.EEXIST, ""File already exists"") self.assertEquals('/a/b/c/d/e', was) if '-' in new: self.assert_( new.startswith('/a/quarantined/containers/e-')) else: self.assertEquals('/a/quarantined/containers/e', new) def mock_renamer_error(was, new): return mock_renamer(was, new, cause_colision=True) was_renamer = db_replicator.renamer db_replicator.renamer = mock_renamer replicator.brokerclass.get_repl_missing_table = True replicator.brokerclass.db_file = '/a/b/c/d/e/hey' replicator._replicate_object('0', 'file', 'node_id') # try the double quarantine db_replicator.renamer = mock_renamer_error replicator._replicate_object('0', 'file', 'node_id') finally: replicator.brokerclass.db_file = was_db_file db_replicator.renamer = was_renamer def test_replicate_object_delete_because_deleted(self): replicator = TestReplicator({}) try: replicator.delete_db = self.stub_delete_db replicator.brokerclass.stub_replication_info = { 'delete_timestamp': 2, 'put_timestamp': 1, 'count': 0} replicator._replicate_object('0', '/path/to/file', 'node_id') finally: replicator.brokerclass.stub_replication_info = None self.assertEquals(['/path/to/file'], self.delete_db_calls) def test_replicate_object_delete_because_not_shouldbehere(self): replicator = TestReplicator({}) replicator.delete_db = self.stub_delete_db replicator._replicate_object('0', '/path/to/file', 'node_id') self.assertEquals(['/path/to/file'], self.delete_db_calls) ",245,67
openstack%2Fnova~master~I3e44b5db8d67787bfa14f0e57d30a02a271a8833,openstack/nova,master,I3e44b5db8d67787bfa14f0e57d30a02a271a8833,Fix filtering aggregate metadata by key,MERGED,2013-07-15 14:59:25.000000000,2013-07-19 01:21:38.000000000,2013-07-19 01:21:35.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-15 14:59:25.000000000', 'files': ['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7e8fa8f3e6acac0e510cd1fc5af591f9a321d03a', 'message': 'Fix filtering aggregate metadata by key\n\nFiltering by metadata key has no effect in the following two functions:\n\n    aggregate_metadata_get_by_host\n    aggregate_host_get_by_metadata_key\n\nRely on the explicit join instead of joinedload to load the _metadata\nrelationship in these functions (indicated by the contains_eager\noption), so that filtering by key still applies when the metadata is\ncollected.\n\nFixes bug 1201283.\n\nChange-Id: I3e44b5db8d67787bfa14f0e57d30a02a271a8833\n'}]",0,37069,7e8fa8f3e6acac0e510cd1fc5af591f9a321d03a,7,4,1,5733,,,0,"Fix filtering aggregate metadata by key

Filtering by metadata key has no effect in the following two functions:

    aggregate_metadata_get_by_host
    aggregate_host_get_by_metadata_key

Rely on the explicit join instead of joinedload to load the _metadata
relationship in these functions (indicated by the contains_eager
option), so that filtering by key still applies when the metadata is
collected.

Fixes bug 1201283.

Change-Id: I3e44b5db8d67787bfa14f0e57d30a02a271a8833
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/37069/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,7e8fa8f3e6acac0e510cd1fc5af591f9a321d03a,bug/1201283,"from sqlalchemy.orm import contains_eager query = model_query(context, models.Aggregate) query = query.join(""_hosts"") query = query.join(""_metadata"") query = query.filter(models.AggregateHost.host == host) query = query.options(contains_eager(""_metadata"")) query = model_query(context, models.Aggregate) query = query.join(""_metadata"") query = query.filter(models.AggregateMetadata.key == key) query = query.options(contains_eager(""_metadata"")) query = query.options(joinedload(""_hosts""))"," query = model_query(context, models.Aggregate).join( ""_hosts"").filter(models.AggregateHost.host == host).join( ""_metadata"") query = model_query(context, models.Aggregate).join( ""_metadata"").filter(models.AggregateMetadata.key == key)",43,20
openstack%2Fnova~master~I87ebfe3de193b9ae47e3a2c8350a49d9cc863fb0,openstack/nova,master,I87ebfe3de193b9ae47e3a2c8350a49d9cc863fb0,Fix aggregate_get_by_host host filtering,MERGED,2013-07-15 07:19:42.000000000,2013-07-19 01:18:18.000000000,2013-07-19 01:18:15.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-15 07:19:42.000000000', 'files': ['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/13513a182a54dffb62900a8464529459dd836136', 'message': 'Fix aggregate_get_by_host host filtering\n\naggregate_get_by_host never actually joins the _hosts relationship,\nso aggregates with non-matching hosts are still included in the output.\n\nThis change adds the join and improves the tests to cover the bug.\n\nFixes bug 1201277.\n\nChange-Id: I87ebfe3de193b9ae47e3a2c8350a49d9cc863fb0\n'}]",0,37026,13513a182a54dffb62900a8464529459dd836136,7,4,1,5733,,,0,"Fix aggregate_get_by_host host filtering

aggregate_get_by_host never actually joins the _hosts relationship,
so aggregates with non-matching hosts are still included in the output.

This change adds the join and improves the tests to cover the bug.

Fixes bug 1201277.

Change-Id: I87ebfe3de193b9ae47e3a2c8350a49d9cc863fb0
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/37026/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,13513a182a54dffb62900a8464529459dd836136,bug/1201277, query = query.options(joinedload('_hosts')) query = query.join('_hosts')," query = query.options(joinedload('_hosts', innerjoin=True))",23,9
openstack%2Fnova~master~I4fb184388c37ea8708cdacc173dc1b2dbd4d1597,openstack/nova,master,I4fb184388c37ea8708cdacc173dc1b2dbd4d1597,Unimplemented pause should not change vm state on PowerVM,MERGED,2013-07-17 14:16:29.000000000,2013-07-19 00:58:45.000000000,2013-07-19 00:58:43.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 7282}]","[{'number': 1, 'created': '2013-07-17 14:16:29.000000000', 'files': ['nova/virt/powervm/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e16260bef0abb8dba419c168245664d3baf09ab7', 'message': ""Unimplemented pause should not change vm state on PowerVM\n\nThe instance of PowerVM does not support pause, but\nafter pause the instance, the state change to PAUSED,\nit's unreasonable.\n\nChange-Id: I4fb184388c37ea8708cdacc173dc1b2dbd4d1597\nFixes: bug #1202082\n""}]",4,37482,e16260bef0abb8dba419c168245664d3baf09ab7,10,6,1,7282,,,0,"Unimplemented pause should not change vm state on PowerVM

The instance of PowerVM does not support pause, but
after pause the instance, the state change to PAUSED,
it's unreasonable.

Change-Id: I4fb184388c37ea8708cdacc173dc1b2dbd4d1597
Fixes: bug #1202082
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/37482/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/powervm/driver.py'],1,e16260bef0abb8dba419c168245664d3baf09ab7,bug/1202082," msg = _(""pause is not supported for PowerVM"") raise NotImplementedError(msg) msg = _(""unpause is not supported for PowerVM"") raise NotImplementedError(msg)", pass pass,4,2
openstack%2Fnova~master~Id12e196519473cce27a998e37f33ce584f703a4f,openstack/nova,master,Id12e196519473cce27a998e37f33ce584f703a4f,Code dedup in test_libvirt_vif,MERGED,2013-07-05 08:47:30.000000000,2013-07-19 00:58:23.000000000,2013-07-19 00:58:21.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5511}, {'_account_id': 6172}, {'_account_id': 6509}, {'_account_id': 6938}, {'_account_id': 7249}, {'_account_id': 7293}]","[{'number': 1, 'created': '2013-07-05 08:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2249dcbe6ee12627a74cd2eeba3f5207176985e8', 'message': 'Refactor test_libvirt_vif\n\nRemoved code duplication.\n\nChange-Id: Id12e196519473cce27a998e37f33ce584f703a4f\n'}, {'number': 2, 'created': '2013-07-05 09:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/04eb205a2122f867a23a45cd6ee9cd641826e812', 'message': 'Refactor test_libvirt_vif\n\nRemoved code duplication.\n\nbp nova-tests-code-duplication\n\nChange-Id: Id12e196519473cce27a998e37f33ce584f703a4f\n'}, {'number': 3, 'created': '2013-07-05 10:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f83b5ec4828d21dfb873662b82a1ebf3f4343379', 'message': 'Refactor test_libvirt_vif\n\nRemoved code duplication.\n\nbp nova-tests-code-duplication\n\nChange-Id: Id12e196519473cce27a998e37f33ce584f703a4f\n'}, {'number': 4, 'created': '2013-07-16 12:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edc16d8ec7098fa216380ea350b03b0e4d66f23c', 'message': 'Code dedup in test_libvirt_vif\n\nExterned common assertions to methods.\n\nbp nova-tests-code-duplication\n\nChange-Id: Id12e196519473cce27a998e37f33ce584f703a4f\n'}, {'number': 5, 'created': '2013-07-16 14:14:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0343bcabeb9ada2912dacc47d6d153c9d6cff197', 'message': 'Code dedup in test_libvirt_vif\n\n- externed common assertions to methods\n- externed common parts to methods:\n  - description of net data\n  - description of mappings data\n  - creating fakelibvirt connection\n  - creating libvirt configuration\n  - getting node from xml\n\nbp nova-tests-code-duplication\n\nChange-Id: Id12e196519473cce27a998e37f33ce584f703a4f\n'}, {'number': 6, 'created': '2013-07-17 06:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15ba980d2010c015349fd4c2e7cc2102aaa6a8c4', 'message': 'Code dedup in test_libvirt_vif\n\n- externed common assertions to methods\n- externed common parts to methods:\n  - description of net data\n  - description of mappings data\n  - creating fakelibvirt connection\n  - creating libvirt configuration\n  - getting node from xml\n\nbp nova-tests-code-duplication\n\nChange-Id: Id12e196519473cce27a998e37f33ce584f703a4f\n'}, {'number': 7, 'created': '2013-07-17 07:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fff8b4fb608c968ee7c14a4a60f8c6eca44c6e0a', 'message': 'Code dedup in test_libvirt_vif\n\n- externed common assertions to methods\n- externed common parts to methods:\n  - description of net data\n  - description of mappings data\n  - creating fakelibvirt connection\n  - creating libvirt configuration\n  - getting node from xml\n\nbp nova-tests-code-duplication\n\nChange-Id: Id12e196519473cce27a998e37f33ce584f703a4f\n'}, {'number': 8, 'created': '2013-07-18 07:17:50.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1b40765a80ba546a4b25aa6a26d2c41090b97720', 'message': 'Code dedup in test_libvirt_vif\n\n- externed common assertions to methods\n- externed common parts to methods:\n  - description of net data\n  - description of mappings data\n  - creating fakelibvirt connection\n  - creating libvirt configuration\n  - getting node from xml\n\nbp nova-tests-code-duplication\n\nChange-Id: Id12e196519473cce27a998e37f33ce584f703a4f\n'}]",23,35763,1b40765a80ba546a4b25aa6a26d2c41090b97720,57,10,8,7249,,,0,"Code dedup in test_libvirt_vif

- externed common assertions to methods
- externed common parts to methods:
  - description of net data
  - description of mappings data
  - creating fakelibvirt connection
  - creating libvirt configuration
  - getting node from xml

bp nova-tests-code-duplication

Change-Id: Id12e196519473cce27a998e37f33ce584f703a4f
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/35763/8 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_libvirt_vif.py'],1,2249dcbe6ee12627a74cd2eeba3f5207176985e8,bp/nova-tests-code-duplication," body = { 'cidr': '101.168.1.0/24', 'cidr_v6': '101:1db9::/64', 'gateway_v6': '101:1db9::1', 'netmask_v6': '64', 'netmask': '255.255.255.0', 'vlan': 99, 'gateway': '101.168.1.1', 'broadcast': '101.168.1.255', 'dns1': '8.8.8.8', 'id': 'network-id-xxx-yyy-zzz' } net_bridge = body.copy() net_bridge['bridge'] = 'br0' net_bridge['bridge_interface'] = 'eth0' net_bridge_quantum = body.copy() net_bridge_quantum['bridge_interface'] = 'eth0' net_ovs = body.copy() net_ovs['bridge'] = 'br0' net_8021 = body.copy() net_8021['interface'] = 'eth0' mapping_body = { 'vif_devname': 'tap-xxx-yyy-zzz' } mapping_bridge = mapping_body.copy() mapping_bridge['gateway_v6'] = net_bridge['gateway_v6'] mapping_bridge['vif_type'] = network_model.VIF_TYPE_BRIDGE mapping_bridge_quantum = mapping_body.copy() mapping_bridge_quantum['gateway_v6'] = net_bridge['gateway_v6'] mapping_ovs = mapping_body.copy() mapping_ovs['gateway_v6'] = net_ovs['gateway_v6'] mapping_ovs['vif_type'] = network_model.VIF_TYPE_OVS mapping_ovs['ovs_interfaceid'] = 'aaa-bbb-ccc' mapping_ivs = mapping_body.copy() mapping_ivs['gateway_v6'] = net_ovs['gateway_v6'] mapping_ivs['vif_type'] = network_model.VIF_TYPE_IVS mapping_ivs['ivs_interfaceid'] = 'aaa-bbb-ccc' mapping_ovs_legacy = mapping_body.copy() mapping_ovs_legacy['gateway_v6'] = net_ovs['gateway_v6'] del mapping_ovs_legacy['vif_devname'] } mapping_none = mapping_body.copy() mapping_none['gateway_v6'] = net_bridge['gateway_v6'] conf = self._get_conf() conf = self._get_conf() d = vif.LibvirtGenericVIFDriver(self._get_conn()) self._assertModelEquals(xml) d = vif.LibvirtGenericVIFDriver(self._get_conn()) self._assertModelEquals(xml, ""virtio"") d = vif.LibvirtGenericVIFDriver(self._get_conn()) self._assertModelEquals(xml, ""e1000"") d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) self._assertModelEquals(xml, ""virtio"", ""qemu"") d = vif.LibvirtGenericVIFDriver(self._get_conn(""xen:///system"")) self._assertModelEquals(xml) d = vif.LibvirtGenericVIFDriver(self._get_conn()) node = self._get_node(xml) self._assertTypeAndMacEquals(node, ""bridge"", ""source"", ""bridge"", self.mapping_bridge, br_want, 1) d = vif.LibvirtBridgeDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.QuantumLinuxBridgeVIFDriver(self._get_conn()) node = self._get_node(xml) self._assertTypeAndMacEquals(node, ""ethernet"", ""target"", ""dev"", self.mapping_ivs, prefix=dev_prefix) node = self._get_node(xml) self._assertTypeAndMacEquals(node, ""ethernet"", ""target"", ""dev"", self.mapping_ovs, prefix=dev_prefix) d = vif.LibvirtOpenVswitchDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) node = self._get_node(xml) self._assertTypeAndMacEquals(node, ""ethernet"", ""target"", ""dev"", mapping, mapping['vif_devname']) node = self._get_node(xml) self._assertTypeAndMacEquals(node, ""bridge"", ""source"", ""bridge"", mapping, ""br0"") d = vif.LibvirtOpenVswitchVirtualPortDriver(self._get_conn(ver=9011)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9011)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9011)) node = self._get_node(xml) self._assertTypeAndMacEquals(node, ""bridge"", ""source"", ""bridge"", mapping, br_want, 1) d = vif.LibvirtHybridOVSBridgeDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) node = self._get_node(xml) self._assertTypeEquals(node, ""direct"", ""source"", ""dev"", ""eth0"") self._assertMacEquals(node, self.mapping_8021qbh) d = vif.LibvirtGenericVIFDriver(self._get_conn()) node = self._get_node(xml) self._assertTypeEquals(node, ""direct"", ""source"", ""dev"", ""eth0"") self._assertMacEquals(node, self.mapping_8021qbg) def _get_conn(self, uri=""qemu:///session"", ver=None): def __inner(): if ver is None: return fakelibvirt.Connection(uri, False) else: return fakelibvirt.Connection(uri, False, ver) return __inner def _get_node(self, xml): doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) return ret[0] def _assertMacEquals(self, node, mapping): mac = node.find(""mac"").get(""address"") self.assertEqual(mac, mapping['mac']) def _assertTypeEquals(self, node, type, attr, source, br_want, prefix=None): self.assertEqual(node.get(""type""), type) br_name = node.find(attr).get(source) if prefix is None: self.assertEqual(br_name, br_want) else: self.assertTrue(br_name.startswith(prefix)) def _assertTypeAndMacEquals(self, node, type, attr, source, mapping, br_want=None, size=0, prefix=None): ret = node.findall(""filterref"") self.assertEqual(len(ret), size) self._assertTypeEquals(node, type, attr, source, br_want, prefix) self._assertMacEquals(node, mapping) def _assertModelEquals(self, xml, model_want=None, driver_want=None): node = self._get_node(xml) if model_want is None: ret = node.findall(""model"") self.assertEqual(len(ret), 0) else: model = node.find(""model"").get(""type"") self.assertEqual(model, model_want) if driver_want is None: ret = node.findall(""driver"") self.assertEqual(len(ret), 0) else: driver = node.find(""driver"").get(""name"") self.assertEqual(driver, driver_want) def _get_conf(self): conf = vconfig.LibvirtConfigGuest() conf.virt_type = ""qemu"" conf.name = ""fake-name"" conf.uuid = ""fake-uuid"" conf.memory = 100 * 1024 conf.vcpus = 4 return conf"," net_bridge = { 'cidr': '101.168.1.0/24', 'cidr_v6': '101:1db9::/64', 'gateway_v6': '101:1db9::1', 'netmask_v6': '64', 'netmask': '255.255.255.0', 'bridge': 'br0', 'bridge_interface': 'eth0', 'vlan': 99, 'gateway': '101.168.1.1', 'broadcast': '101.168.1.255', 'dns1': '8.8.8.8', 'id': 'network-id-xxx-yyy-zzz' } net_bridge_quantum = { 'cidr': '101.168.1.0/24', 'cidr_v6': '101:1db9::/64', 'gateway_v6': '101:1db9::1', 'netmask_v6': '64', 'netmask': '255.255.255.0', 'bridge_interface': 'eth0', 'vlan': 99, 'gateway': '101.168.1.1', 'broadcast': '101.168.1.255', 'dns1': '8.8.8.8', 'id': 'network-id-xxx-yyy-zzz' } mapping_bridge = { 'gateway_v6': net_bridge['gateway_v6'], 'vif_devname': 'tap-xxx-yyy-zzz', 'vif_type': network_model.VIF_TYPE_BRIDGE, } mapping_bridge_quantum = { 'mac': 'ca:fe:de:ad:be:ef', 'gateway_v6': net_bridge['gateway_v6'], 'ips': [{'ip': '101.168.1.9'}], 'dhcp_server': '191.168.1.1', 'vif_uuid': 'vif-xxx-yyy-zzz', 'vif_devname': 'tap-xxx-yyy-zzz', } net_ovs = { 'cidr': '101.168.1.0/24', 'cidr_v6': '101:1db9::/64', 'gateway_v6': '101:1db9::1', 'netmask_v6': '64', 'netmask': '255.255.255.0', 'bridge': 'br0', 'vlan': 99, 'gateway': '101.168.1.1', 'broadcast': '101.168.1.255', 'dns1': '8.8.8.8', 'id': 'network-id-xxx-yyy-zzz' } mapping_ovs = { 'mac': 'ca:fe:de:ad:be:ef', 'gateway_v6': net_ovs['gateway_v6'], 'ips': [{'ip': '101.168.1.9'}], 'dhcp_server': '191.168.1.1', 'vif_uuid': 'vif-xxx-yyy-zzz', 'vif_devname': 'tap-xxx-yyy-zzz', 'vif_type': network_model.VIF_TYPE_OVS, 'ovs_interfaceid': 'aaa-bbb-ccc', } mapping_ivs = { 'mac': 'ca:fe:de:ad:be:ef', 'gateway_v6': net_ovs['gateway_v6'], 'ips': [{'ip': '101.168.1.9'}], 'dhcp_server': '191.168.1.1', 'vif_uuid': 'vif-xxx-yyy-zzz', 'vif_devname': 'tap-xxx-yyy-zzz', 'vif_type': network_model.VIF_TYPE_IVS, 'ivs_interfaceid': 'aaa-bbb-ccc', } mapping_ovs_legacy = { 'mac': 'ca:fe:de:ad:be:ef', 'gateway_v6': net_ovs['gateway_v6'], 'ips': [{'ip': '101.168.1.9'}], 'dhcp_server': '191.168.1.1', 'vif_uuid': 'vif-xxx-yyy-zzz', } net_8021 = { 'cidr': '101.168.1.0/24', 'cidr_v6': '101:1db9::/64', 'gateway_v6': '101:1db9::1', 'netmask_v6': '64', 'netmask': '255.255.255.0', 'interface': 'eth0', 'vlan': 99, 'gateway': '101.168.1.1', 'broadcast': '101.168.1.255', 'dns1': '8.8.8.8', 'id': 'network-id-xxx-yyy-zzz' } } mapping_none = { 'mac': 'ca:fe:de:ad:be:ef', 'gateway_v6': net_bridge['gateway_v6'], 'ips': [{'ip': '101.168.1.9'}], 'dhcp_server': '191.168.1.1', 'vif_uuid': 'vif-xxx-yyy-zzz', 'vif_devname': 'tap-xxx-yyy-zzz', } conf = vconfig.LibvirtConfigGuest() conf.virt_type = ""qemu"" conf.name = ""fake-name"" conf.uuid = ""fake-uuid"" conf.memory = 100 * 1024 conf.vcpus = 4 conf = vconfig.LibvirtConfigGuest() conf.virt_type = ""qemu"" conf.name = ""fake-name"" conf.uuid = ""fake-uuid"" conf.memory = 100 * 1024 conf.vcpus = 4 def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] ret = node.findall(""model"") self.assertEqual(len(ret), 0) ret = node.findall(""driver"") self.assertEqual(len(ret), 0) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] model = node.find(""model"").get(""type"") self.assertEqual(model, ""virtio"") ret = node.findall(""driver"") self.assertEqual(len(ret), 0) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] model = node.find(""model"").get(""type"") self.assertEqual(model, ""e1000"") ret = node.findall(""driver"") self.assertEqual(len(ret), 0) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] model = node.find(""model"").get(""type"") self.assertEqual(model, ""virtio"") driver = node.find(""driver"").get(""name"") self.assertEqual(driver, ""qemu"") def get_connection(): return fakelibvirt.Connection(""xen:///system"", False) d = vif.LibvirtGenericVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] ret = node.findall(""model"") self.assertEqual(len(ret), 0) ret = node.findall(""driver"") self.assertEqual(len(ret), 0) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] ret = node.findall(""filterref"") self.assertEqual(len(ret), 1) self.assertEqual(node.get(""type""), ""bridge"") br_name = node.find(""source"").get(""bridge"") self.assertEqual(br_name, br_want) mac = node.find(""mac"").get(""address"") self.assertEqual(mac, self.mapping_bridge['mac']) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtBridgeDriver(get_connection) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.QuantumLinuxBridgeVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] ret = node.findall(""filterref"") self.assertEqual(len(ret), 0) self.assertEqual(node.get(""type""), ""ethernet"") dev_name = node.find(""target"").get(""dev"") self.assertTrue(dev_name.startswith(dev_prefix)) mac = node.find(""mac"").get(""address"") self.assertEqual(mac, self.mapping_ivs['mac']) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] ret = node.findall(""filterref"") self.assertEqual(len(ret), 0) self.assertEqual(node.get(""type""), ""ethernet"") dev_name = node.find(""target"").get(""dev"") self.assertTrue(dev_name.startswith(dev_prefix)) mac = node.find(""mac"").get(""address"") self.assertEqual(mac, self.mapping_ovs['mac']) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False, 9010) d = vif.LibvirtOpenVswitchDriver(get_connection) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False, 9010) d = vif.LibvirtGenericVIFDriver(get_connection) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False, 9010) d = vif.LibvirtGenericVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] ret = node.findall(""filterref"") self.assertEqual(len(ret), 0) self.assertEqual(node.get(""type""), ""ethernet"") tap_name = node.find(""target"").get(""dev"") self.assertEqual(tap_name, mapping['vif_devname']) mac = node.find(""mac"").get(""address"") self.assertEqual(mac, mapping['mac']) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] ret = node.findall(""filterref"") self.assertEqual(len(ret), 0) self.assertEqual(node.get(""type""), ""bridge"") br_name = node.find(""source"").get(""bridge"") self.assertEqual(br_name, ""br0"") mac = node.find(""mac"").get(""address"") self.assertEqual(mac, mapping['mac']) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False, 9011) d = vif.LibvirtOpenVswitchVirtualPortDriver(get_connection) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False, 9011) d = vif.LibvirtGenericVIFDriver(get_connection) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False, 9011) d = vif.LibvirtGenericVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] ret = node.findall(""filterref"") self.assertEqual(len(ret), 1) self.assertEqual(node.get(""type""), ""bridge"") br_name = node.find(""source"").get(""bridge"") self.assertEqual(br_name, br_want) mac = node.find(""mac"").get(""address"") self.assertEqual(mac, mapping['mac']) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtHybridOVSBridgeDriver(get_connection) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] self.assertEqual(node.get(""type""), ""direct"") br_name = node.find(""source"").get(""dev"") self.assertEqual(br_name, ""eth0"") mac = node.find(""mac"").get(""address"") self.assertEqual(mac, self.mapping_8021qbh['mac']) def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] self.assertEqual(node.get(""type""), ""direct"") br_name = node.find(""source"").get(""dev"") self.assertEqual(br_name, ""eth0"") mac = node.find(""mac"").get(""address"") self.assertEqual(mac, self.mapping_8021qbg['mac'])",155,347
openstack%2Fnova~master~Ic6afbe7b431e3eb9ff28d3c9b3fa35a52efb3fb6,openstack/nova,master,Ic6afbe7b431e3eb9ff28d3c9b3fa35a52efb3fb6,Fix parse_transport_url when url has query string,MERGED,2013-07-16 09:17:36.000000000,2013-07-19 00:58:03.000000000,2013-07-19 00:58:01.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2835}, {'_account_id': 5511}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-07-16 09:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/04c5d82b52d03a413b1ea286f1129b16f741f55a', 'message': ""Fix parse_transport_url when url has query string\n\nIn python 2.7 the query is extracted from the path and can be found in\nin the 'query' member of ParseResult  while in python 2.6 it is left\nunparsed in the path member.\n\nChange-Id: Ic6afbe7b431e3eb9ff28d3c9b3fa35a52efb3fb6\n""}, {'number': 2, 'created': '2013-07-16 09:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96a71a65f0e0130976b1aa878e710f4baf1e6939', 'message': ""Fix parse_transport_url when url has query string\n\nIn python 2.7.5 the query is extracted from the path and can be found in\nin the 'query' member of ParseResult  while in python 2.6 it is left\nunparsed in the path member.\n\nChange-Id: Ic6afbe7b431e3eb9ff28d3c9b3fa35a52efb3fb6\n""}, {'number': 3, 'created': '2013-07-17 12:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1b0e79d1d4aa0028ff5508d3ed6ea160a317802d', 'message': ""Fix parse_transport_url when url has query string\n\nIn python < 2.7.4 the query string from an url is only parsed for the\nschemes that the module knows about (not including 'qpid' and 'rabbit').\nThis behaviour was changed in python 2.7.4 and now it parses the query\nstring for all the schemes and doesn't appear any more in the path.\n\nThis change makes sure that we look for the query string in both members\n(query and path).\n\nSee http://bugs.python.org/issue9374\n\nFixes bug #1202149\n\nChange-Id: Ic6afbe7b431e3eb9ff28d3c9b3fa35a52efb3fb6\n""}, {'number': 4, 'created': '2013-07-17 13:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/febe711c9cd76f151e072002333766affc04747f', 'message': ""Fix parse_transport_url when url has query string\n\nIn python < 2.7.4 the query string from an url is only parsed for the\nschemes that the module knows about (not including 'qpid' and 'rabbit').\nThis behaviour was changed in python 2.7.4 and now it parses the query\nstring for all the schemes and doesn't appear any more in the path.\n\nThis change makes sure that we look for the query string in both members\n(query and path).\n\nSee http://bugs.python.org/issue9374\n\nFixes bug #1202149\n\nChange-Id: Ic6afbe7b431e3eb9ff28d3c9b3fa35a52efb3fb6\n""}, {'number': 5, 'created': '2013-07-18 08:24:22.000000000', 'files': ['nova/tests/cells/test_cells_rpc_driver.py', 'nova/cells/rpc_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dcdb54541d1d3cedb99889362bca1722e4bf5124', 'message': ""Fix parse_transport_url when url has query string\n\nIn python < 2.7.4 the query string from an url is only parsed for the\nschemes that the module knows about (not including 'qpid' and 'rabbit').\nThis behaviour was changed in python 2.7.4 and now it parses the query\nstring for all the schemes and doesn't appear any more in the path.\n\nThis change makes sure that we look for the query string in both members\n(query and path).\n\nSee http://bugs.python.org/issue9374\n\nFixes bug #1202149\n\nChange-Id: Ic6afbe7b431e3eb9ff28d3c9b3fa35a52efb3fb6\n""}]",5,37199,dcdb54541d1d3cedb99889362bca1722e4bf5124,29,7,5,7808,,,0,"Fix parse_transport_url when url has query string

In python < 2.7.4 the query string from an url is only parsed for the
schemes that the module knows about (not including 'qpid' and 'rabbit').
This behaviour was changed in python 2.7.4 and now it parses the query
string for all the schemes and doesn't appear any more in the path.

This change makes sure that we look for the query string in both members
(query and path).

See http://bugs.python.org/issue9374

Fixes bug #1202149

Change-Id: Ic6afbe7b431e3eb9ff28d3c9b3fa35a52efb3fb6
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/37199/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/cells/rpc_driver.py'],1,04c5d82b52d03a413b1ea286f1129b16f741f55a,bug/1202149, if '?' in parsed.path or parsed.query:, if '?' in parsed.path:,1,1
openstack%2Fpuppet-cinder~master~Ic3fe0e672a84978b01bc7c9014dd701ecf2b0bde,openstack/puppet-cinder,master,Ic3fe0e672a84978b01bc7c9014dd701ecf2b0bde,Update revision for rabbitmq,MERGED,2013-07-18 23:53:35.000000000,2013-07-19 00:51:46.000000000,2013-07-19 00:51:46.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 6994}]","[{'number': 1, 'created': '2013-07-18 23:53:35.000000000', 'files': ['.fixtures.yml'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/20177fb47229d5a9a8e2b48bd0ec803bda7d9552', 'message': 'Update revision for rabbitmq\n\nThis commit updates the revision of rabbitmq to install for testing.\n\nThis revision was chosen for two reasons:\n\n- later revisions remove the rabbitmq::server class\n- later revisions do not support installing from your local distro (which\nmeans you will likely get a version not tested with openstack)\n\nChange-Id: Ic3fe0e672a84978b01bc7c9014dd701ecf2b0bde\n'}]",0,37811,20177fb47229d5a9a8e2b48bd0ec803bda7d9552,7,3,1,2265,,,0,"Update revision for rabbitmq

This commit updates the revision of rabbitmq to install for testing.

This revision was chosen for two reasons:

- later revisions remove the rabbitmq::server class
- later revisions do not support installing from your local distro (which
means you will likely get a version not tested with openstack)

Change-Id: Ic3fe0e672a84978b01bc7c9014dd701ecf2b0bde
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/11/37811/1 && git format-patch -1 --stdout FETCH_HEAD,['.fixtures.yml'],1,20177fb47229d5a9a8e2b48bd0ec803bda7d9552,master," ""rabbitmq"": repo: ""git://github.com/puppetlabs/puppetlabs-rabbitmq"" ref: 43a000b95b13c62e4fbea14e31bc61929bda1b23"," ""rabbitmq"": ""git://github.com/puppetlabs/puppetlabs-rabbitmq.git""",3,1
openstack%2Fpuppet-nova~master~Id73e7c9b43c25dbb6300c69565de2178b1a2462b,openstack/puppet-nova,master,Id73e7c9b43c25dbb6300c69565de2178b1a2462b,Update rabbitmq dependency,MERGED,2013-07-18 22:29:19.000000000,2013-07-19 00:51:24.000000000,2013-07-19 00:51:24.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 6994}]","[{'number': 1, 'created': '2013-07-18 22:29:19.000000000', 'files': ['.fixtures.yml', 'spec/classes/nova_rabbitmq_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/6d9123ffc3e8618cdde239db5589e6238d1945c2', 'message': 'Update rabbitmq dependency\n\nThis commit updates the revision of rabbitmq to install for testing.\n\nThis revision was chosen for two reasons:\n\n- later revisions remove the rabbitmq::server class\n- later revisions do not support installing from your local distro (which\nmeans you will likely get a version not tested with openstack)\n\nChange-Id: Id73e7c9b43c25dbb6300c69565de2178b1a2462b\n'}]",0,37797,6d9123ffc3e8618cdde239db5589e6238d1945c2,6,3,1,2265,,,0,"Update rabbitmq dependency

This commit updates the revision of rabbitmq to install for testing.

This revision was chosen for two reasons:

- later revisions remove the rabbitmq::server class
- later revisions do not support installing from your local distro (which
means you will likely get a version not tested with openstack)

Change-Id: Id73e7c9b43c25dbb6300c69565de2178b1a2462b
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/97/37797/1 && git format-patch -1 --stdout FETCH_HEAD,"['.fixtures.yml', 'spec/classes/nova_rabbitmq_spec.rb']",2,6d9123ffc3e8618cdde239db5589e6238d1945c2,master," { :puppetversion => '2.7', :osfamily => 'Debian' }", {:puppetversion => '2.7'} ,12,7
openstack%2Fcinder~master~Ib1ca12a3a8690899469420c751045d181f3d4096,openstack/cinder,master,Ib1ca12a3a8690899469420c751045d181f3d4096,Fix unit suffix and add no_suffix option.,ABANDONED,2013-07-02 19:34:45.000000000,2013-07-19 00:33:17.000000000,,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 5997}]","[{'number': 1, 'created': '2013-07-02 19:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/da6e23fef4f2fd93a35b4642206d68b90b87a92d', 'message': ""Fix unit suffix and add no_suffix option.\n\nIn Cinder we've been using gibibytes, however\nwe have code in some places using Gigabytes, the brick\nLVM code was one of those places.\n\nThis change sets the default suffix to gibibytes/mibibytes (1024 based)\nand also provides an option to ommit the suffix from the response now\nthat we can say that we're consistent in what is expected.\n\nChange-Id: Ib1ca12a3a8690899469420c751045d181f3d4096\n""}, {'number': 2, 'created': '2013-07-04 16:32:11.000000000', 'files': ['cinder/brick/local_dev/lvm.py', 'cinder/tests/brick/test_brick_lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a73eba0aea0d5eaa7bf0350baaaed3c175ef7271', 'message': ""Fix unit suffix and add no_suffix option.\n\nIn Cinder we've been using gibibytes, however\nwe have code in some places using Gigabytes, the brick\nLVM code was one of those places.\n\nThis change sets the default suffix to gibibytes/mibibytes (1024 based)\nand also provides an option to ommit the suffix from the response now\nthat we can say that we're consistent in what is expected.\n\nChange-Id: Ib1ca12a3a8690899469420c751045d181f3d4096\n""}]",4,35373,a73eba0aea0d5eaa7bf0350baaaed3c175ef7271,10,5,2,2243,,,0,"Fix unit suffix and add no_suffix option.

In Cinder we've been using gibibytes, however
we have code in some places using Gigabytes, the brick
LVM code was one of those places.

This change sets the default suffix to gibibytes/mibibytes (1024 based)
and also provides an option to ommit the suffix from the response now
that we can say that we're consistent in what is expected.

Change-Id: Ib1ca12a3a8690899469420c751045d181f3d4096
",git fetch https://review.opendev.org/openstack/cinder refs/changes/73/35373/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/brick/local_dev/lvm.py', 'cinder/tests/brick/test_brick_lvm.py']",2,da6e23fef4f2fd93a35b4642206d68b90b87a92d,add_units_designator_to_brick_lvm," #Stub processutils.execute for static methods False, None, 'default', self.fake_execute) if 'vgs, --noheadings, --unit=g, -o, name' == cmd_string: data = "" fake-volumes\n"" elif 'vgs, --noheadings, -o, name' == cmd_string: elif 'vgs, --noheadings, --unit=g, -o, name,size,free,lv_count,uuid'\ in cmd_string: elif 'lvs, --noheadings, --unit=g, -o, vg_name,name,size'\ in cmd_string: # lvm.supports_thin() is a static method and doesn't # us the self._executor fake we pass in on init # so we need to stub proessutils.execute appropriately self.stubs.Set(processutils, 'execute', self.fake_pretend_lvm_version) self.assertTrue(self.vg.supports_thin_provisioning()) "," False, None, 'default', self.fake_execute) if 'vgs, --noheadings, -o, name' == cmd_string: elif 'vgs, --noheadings, -o, name,size,free,lv_count,uuid' in\ cmd_string: elif 'lvs, --noheadings, -o, vg_name,name,size' in cmd_string: data = "" fake-volumes fake-1 1.00g\n"" data += "" fake-volumes fake-2 1.00g\n"" elif 'lvs, --noheadings, -o, vg_name,name,size' in cmd_string:",54,16
openstack%2Foslo-incubator~master~Ia0366dbdf38557c4e6a9307fb27c77fd1c1873c3,openstack/oslo-incubator,master,Ia0366dbdf38557c4e6a9307fb27c77fd1c1873c3,Raise ValueError if sort_dir is unknown,MERGED,2013-07-10 12:42:04.000000000,2013-07-19 00:27:39.000000000,2013-07-19 00:27:39.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1531}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 7331}]","[{'number': 1, 'created': '2013-07-10 12:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9471738ad674020657f876f867146bb0e75a4ec3', 'message': ""Raise ValueError if sort_dir is unknown\n\nRaise ValueError in case of KeyError, when sort_dir is not\n'asc' or 'desc'.\n\nValueError while adding pagination has never been raised before,\nbecause if sort direction was incorrect, KeyError has been\nraised while adding sorting.\n\nChange-Id: Ia0366dbdf38557c4e6a9307fb27c77fd1c1873c3\n""}, {'number': 2, 'created': '2013-07-11 07:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/080d63aa3e3582a7b8608dd0cd3642e168ce09f8', 'message': ""Raise ValueError if sort_dir is unknown\n\nRaise ValueError in case of KeyError, when sort_dir is not\n'asc' or 'desc'.\n\nValueError while adding pagination has never been raised before,\nbecause if sort direction was incorrect, KeyError has been\nraised while adding sorting.\n\nChange-Id: Ia0366dbdf38557c4e6a9307fb27c77fd1c1873c3\n""}, {'number': 3, 'created': '2013-07-17 12:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f572963c793a73ccaa7baceb70442096c7729594', 'message': ""Raise ValueError if sort_dir is unknown\n\nRaise ValueError in case of KeyError, when sort_dir is not\n'asc' or 'desc'.\n\nAdd unknown value to error message\n\nValueError while adding pagination has never been raised before,\nbecause if sort direction was incorrect, KeyError has been\nraised while adding sorting.\n\nChange-Id: Ia0366dbdf38557c4e6a9307fb27c77fd1c1873c3\n""}, {'number': 4, 'created': '2013-07-17 12:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/8b0b7eb9908608f54a06c7b3901f4fb1b5601911', 'message': ""Raise ValueError if sort_dir is unknown\n\nRaise ValueError in case of KeyError, when sort_dir is not\n'asc' or 'desc'.\n\nAdd unknown value to error message\n\nValueError while adding pagination has never been raised before,\nbecause if sort direction was incorrect, KeyError has been\nraised while adding sorting.\n\nChange-Id: Ia0366dbdf38557c4e6a9307fb27c77fd1c1873c3\n""}, {'number': 5, 'created': '2013-07-18 10:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c798b09561edf02f9d9bf0dca66edebe37010d61', 'message': ""Raise ValueError if sort_dir is unknown\n\nRaise ValueError in case of KeyError, when sort_dir is not\n'asc' or 'desc'.\n\nValueError while adding pagination has never been raised before,\nbecause if sort direction was incorrect, KeyError has been\nraised while adding sorting.\n\nChange-Id: Ia0366dbdf38557c4e6a9307fb27c77fd1c1873c3\n""}, {'number': 6, 'created': '2013-07-18 10:17:24.000000000', 'files': ['tests/unit/db/sqlalchemy/test_utils.py', 'openstack/common/db/sqlalchemy/utils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/5758360a2e970a48a9c64e91b3a14a8a65825be0', 'message': ""Raise ValueError if sort_dir is unknown\n\nRaise ValueError in case of KeyError, when sort_dir is not\n'asc' or 'desc'.\n\nValueError while adding pagination has never been raised before,\nbecause if sort direction was incorrect, KeyError has been\nraised while adding sorting.\n\nChange-Id: Ia0366dbdf38557c4e6a9307fb27c77fd1c1873c3\n""}]",1,36456,5758360a2e970a48a9c64e91b3a14a8a65825be0,24,8,6,7331,,,0,"Raise ValueError if sort_dir is unknown

Raise ValueError in case of KeyError, when sort_dir is not
'asc' or 'desc'.

ValueError while adding pagination has never been raised before,
because if sort direction was incorrect, KeyError has been
raised while adding sorting.

Change-Id: Ia0366dbdf38557c4e6a9307fb27c77fd1c1873c3
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/56/36456/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/db/sqlalchemy/test_utils.py', 'openstack/common/db/sqlalchemy/utils.py']",2,9471738ad674020657f876f867146bb0e75a4ec3,," try: sort_dir_func = { 'asc': sqlalchemy.asc, 'desc': sqlalchemy.desc, }[current_sort_dir] except KeyError: raise ValueError(_(""Unknown sort direction, "" ""must be 'desc' or 'asc'""))"," sort_dir_func = { 'asc': sqlalchemy.asc, 'desc': sqlalchemy.desc, }[current_sort_dir] else: raise ValueError(_(""Unknown sort direction, "" ""must be 'desc' or 'asc'""))",8,10
openstack%2Foslo-incubator~master~Ibec636bf23872d221bac17f6514fc97bd09c4e86,openstack/oslo-incubator,master,Ibec636bf23872d221bac17f6514fc97bd09c4e86,Add tests for cinder/common/sqlalchemyutils.py,MERGED,2013-07-10 12:24:58.000000000,2013-07-19 00:26:53.000000000,2013-07-19 00:26:53.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1531}, {'_account_id': 1994}, {'_account_id': 5638}, {'_account_id': 7331}]","[{'number': 1, 'created': '2013-07-10 12:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a06c4db65d83b04f901fe6db9677402eab16b563', 'message': 'Add tests for cinder/common/sqlalchemyutils.py\n\nAdd test cases:\n- test_paginate_query_no_pagination_no_sort_dirs - tests\nsorting only\n- test_paginate_query_no_pagination - tests sorting only\n- test_paginate_query_attribute_error\n- test_paginate_query_assertion_error\n- test_paginate_query_assertion_error_2\n- test_paginate_query - tests both sorting and pagination\n- test_paginate_query_value_error - is skipped now\n\nChange-Id: Ibec636bf23872d221bac17f6514fc97bd09c4e86\n'}, {'number': 2, 'created': '2013-07-10 12:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/61e6c273e63207f96f4d7ec2241ffb7124104bd0', 'message': 'Add tests for openstack/common/db/sqlalchemy/utils.py\n\nAdd test cases:\n- test_paginate_query_no_pagination_no_sort_dirs - tests\nsorting only\n- test_paginate_query_no_pagination - tests sorting only\n- test_paginate_query_attribute_error\n- test_paginate_query_assertion_error\n- test_paginate_query_assertion_error_2\n- test_paginate_query - tests both sorting and pagination\n- test_paginate_query_value_error - is skipped now\n\nChange-Id: Ibec636bf23872d221bac17f6514fc97bd09c4e86\n'}, {'number': 3, 'created': '2013-07-17 12:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/ac087d7c243f7a6e0ecda1b4026cc8a5e6b111e7', 'message': 'Add tests for cinder/common/sqlalchemyutils.py\n\nAdd test cases:\n- test_paginate_query_no_pagination_no_sort_dirs - tests\nsorting only\n- test_paginate_query_no_pagination - tests sorting only\n- test_paginate_query_attribute_error\n- test_paginate_query_assertion_error\n- test_paginate_query_assertion_error_2\n- test_paginate_query - tests both sorting and pagination\n- test_paginate_query_value_error - is skipped now\n\nChange-Id: Ibec636bf23872d221bac17f6514fc97bd09c4e86\n'}, {'number': 4, 'created': '2013-07-18 09:49:34.000000000', 'files': ['tests/unit/db/sqlalchemy/test_utils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a9a7a5fb3322cc5b40aa49ddc9e0c7b4f8cc804a', 'message': 'Add tests for cinder/common/sqlalchemyutils.py\n\nAdd test cases:\n- test_paginate_query_no_pagination_no_sort_dirs - tests\nsorting only\n- test_paginate_query_no_pagination - tests sorting only\n- test_paginate_query_attribute_error\n- test_paginate_query_assertion_error\n- test_paginate_query_assertion_error_2\n- test_paginate_query - tests both sorting and pagination\n- test_paginate_query_value_error - is skipped now\n\nChange-Id: Ibec636bf23872d221bac17f6514fc97bd09c4e86\n'}]",3,36450,a9a7a5fb3322cc5b40aa49ddc9e0c7b4f8cc804a,19,6,4,7331,,,0,"Add tests for cinder/common/sqlalchemyutils.py

Add test cases:
- test_paginate_query_no_pagination_no_sort_dirs - tests
sorting only
- test_paginate_query_no_pagination - tests sorting only
- test_paginate_query_attribute_error
- test_paginate_query_assertion_error
- test_paginate_query_assertion_error_2
- test_paginate_query - tests both sorting and pagination
- test_paginate_query_value_error - is skipped now

Change-Id: Ibec636bf23872d221bac17f6514fc97bd09c4e86
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/50/36450/4 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/db/sqlalchemy/test_utils.py'],1,a06c4db65d83b04f901fe6db9677402eab16b563,,"#Copyright 2011 OpenStack LLC. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Tests for openstack.common.db.sqlalchemy.utils.py """""" import sqlalchemy import testtools from openstack.common.db.sqlalchemy import utils from tests import utils as testutils class FakeModel(object): def __init__(self, values): self.values = values def __getattr__(self, name): try: value = self.values[name] except KeyError: raise AttributeError(name) return value def __getitem__(self, key): if key in self.values: return self.values[key] else: raise NotImplementedError() def __repr__(self): return '<FakeModel: %s>' % self.values class TestPaginateQuery(testutils.BaseTestCase): def setUp(self): super(TestPaginateQuery, self).setUp() self.query = self.mox.CreateMockAnything() self.mox.StubOutWithMock(sqlalchemy, 'asc') self.mox.StubOutWithMock(sqlalchemy, 'desc') self.marker = FakeModel({ 'user_id': 'user', 'project_id': 'p', 'snapshot_id': 's', }) self.model = FakeModel({ 'user_id': 'user', 'project_id': 'project', 'snapshot_id': 'snapshot', }) def test_paginate_query_no_pagination_no_sort_dirs(self): sqlalchemy.asc('user').AndReturn('asc_3') self.query.order_by('asc_3').AndReturn(self.query) sqlalchemy.asc('project').AndReturn('asc_2') self.query.order_by('asc_2').AndReturn(self.query) sqlalchemy.asc('snapshot').AndReturn('asc_1') self.query.order_by('asc_1').AndReturn(self.query) self.query.limit(5).AndReturn(self.query) self.mox.ReplayAll() utils.paginate_query(self.query, self.model, 5, ['user_id', 'project_id', 'snapshot_id']) def test_paginate_query_no_pagination(self): sqlalchemy.asc('user').AndReturn('asc') self.query.order_by('asc').AndReturn(self.query) sqlalchemy.desc('project').AndReturn('desc') self.query.order_by('desc').AndReturn(self.query) self.query.limit(5).AndReturn(self.query) self.mox.ReplayAll() utils.paginate_query(self.query, self.model, 5, ['user_id', 'project_id'], sort_dirs=['asc', 'desc']) def test_paginate_query_attribute_error(self): sqlalchemy.asc('user').AndReturn('asc') self.query.order_by('asc').AndReturn(self.query) self.mox.ReplayAll() self.assertRaises(utils.InvalidSortKey, utils.paginate_query, self.query, self.model, 5, ['user_id', 'non-existent key']) def test_paginate_query_assertion_error(self): self.mox.ReplayAll() self.assertRaises(AssertionError, utils.paginate_query, self.query, self.model, 5, ['user_id'], marker=self.marker, sort_dir='asc', sort_dirs=['asc']) def test_paginate_query_assertion_error_2(self): self.mox.ReplayAll() self.assertRaises(AssertionError, utils.paginate_query, self.query, self.model, 5, ['user_id'], marker=self.marker, sort_dir=None, sort_dirs=['asc', 'desk']) def test_paginate_query(self): sqlalchemy.asc('user').AndReturn('asc_1') self.query.order_by('asc_1').AndReturn(self.query) sqlalchemy.desc('project').AndReturn('desc_1') self.query.order_by('desc_1').AndReturn(self.query) self.mox.StubOutWithMock(sqlalchemy.sql, 'and_') sqlalchemy.sql.and_(False).AndReturn('some_crit') sqlalchemy.sql.and_(True, False).AndReturn('another_crit') self.mox.StubOutWithMock(sqlalchemy.sql, 'or_') sqlalchemy.sql.or_('some_crit', 'another_crit').AndReturn('some_f') self.query.filter('some_f').AndReturn(self.query) self.query.limit(5).AndReturn(self.query) self.mox.ReplayAll() utils.paginate_query(self.query, self.model, 5, ['user_id', 'project_id'], marker=self.marker, sort_dirs=['asc', 'desc']) @testtools.skip('The bug is not fixed: ValueError never raises') def test_paginate_query_value_error(self): sqlalchemy.asc('user').AndReturn('asc_1') self.query.order_by('asc_1').AndReturn(self.query) self.mox.ReplayAll() self.assertRaises(ValueError, utils.paginate_query, self.query, self.model, 5, ['user_id', 'project_id'], marker=self.marker, sort_dirs=['asc', 'mixed']) ",,137,0
openstack%2Fnova~master~I60103610f9143f1c668927fe40d10a14b39b4c25,openstack/nova,master,I60103610f9143f1c668927fe40d10a14b39b4c25,Fix HTTP response for PortInUse during boot,MERGED,2013-06-29 13:41:32.000000000,2013-07-18 23:57:45.000000000,2013-07-18 23:57:43.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 4120}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-06-29 13:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e104f844f48ffa68a1ded720dd666f2ba6bf65e4', 'message': 'Fix HTTP response for PortInUse during boot\n\nIf an in use port is passed as a network parameter in the request, Nova API\nshould raise an HTTPConflict (409) error\n\nFixes bug #1160887\n\nChange-Id: I60103610f9143f1c668927fe40d10a14b39b4c25\n'}, {'number': 2, 'created': '2013-07-02 18:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fd48f033e67235050ff1b2326ce5414bb4d4efc', 'message': 'Fix HTTP response for PortInUse during boot\n\nIf an in use port is passed as a network parameter in the request, Nova API\nshould raise an HTTPConflict (409) error\n\nFixes bug #1160887\n\nChange-Id: I60103610f9143f1c668927fe40d10a14b39b4c25\n'}, {'number': 3, 'created': '2013-07-18 15:29:33.000000000', 'files': ['nova/tests/api/openstack/compute/test_servers.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/48b31c9a1f5d2a45d881e70c6223411c5abbcb72', 'message': 'Fix HTTP response for PortInUse during boot\n\nIf an in use port is passed as a network parameter in the request, Nova API\nshould raise an HTTPConflict (409) error\n\nFixes bug #1160887\n\nChange-Id: I60103610f9143f1c668927fe40d10a14b39b4c25\n'}]",0,34997,48b31c9a1f5d2a45d881e70c6223411c5abbcb72,20,6,3,4120,,,0,"Fix HTTP response for PortInUse during boot

If an in use port is passed as a network parameter in the request, Nova API
should raise an HTTPConflict (409) error

Fixes bug #1160887

Change-Id: I60103610f9143f1c668927fe40d10a14b39b4c25
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/34997/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/servers.py'],1,e104f844f48ffa68a1ded720dd666f2ba6bf65e4,bug/1160887, except exception.PortInUse as error: raise exc.HTTPConflict(explanation=error.format_message()),,2,0
openstack%2Fglance~master~I3f040374455feb876e970a1813099598301774b5,openstack/glance,master,I3f040374455feb876e970a1813099598301774b5,File system store can send metadata back with the location.,MERGED,2013-07-12 19:26:40.000000000,2013-07-18 23:21:12.000000000,2013-07-18 23:21:12.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1390}, {'_account_id': 2166}, {'_account_id': 6159}, {'_account_id': 6493}, {'_account_id': 6549}]","[{'number': 1, 'created': '2013-07-12 19:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bf19a310092c4b9f64d0eed1ac1dd9e2164ff439', 'message': 'File system store can send metadata back with the location.\n\nThis patch allows the glance operator to associate metadata with\nthe file system store.  The metadata will be returned to v2 users\nwith each location that was created by the file system store.  This\ninformation can give clients context into how to consume the data.\n\nThe new configuration option: file system_store_metadata_file is\nadded.  This is a path to a JSON file.  The JSON document can\ncontain lists, dicts and unicode values only.\n\nblueprint: direct-url-meta-data\nblueprint: multiple-image-locations\ndocImpact\nChange-Id: I3f040374455feb876e970a1813099598301774b5\n'}, {'number': 2, 'created': '2013-07-15 16:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3fdf861c0d3c07fd6cc8240e2fd7335c8b1f0a72', 'message': 'File system store can send metadata back with the location.\n\nThis patch allows the glance operator to associate metadata with\nthe file system store.  The metadata will be returned to v2 users\nwith each location that was created by the file system store.  This\ninformation can give clients context into how to consume the data.\n\nThe new configuration option: file system_store_metadata_file is\nadded.  This is a path to a JSON file.  The JSON document can\ncontain lists, dicts and unicode values only.\n\nblueprint: direct-url-meta-data\nblueprint: multiple-image-locations\ndocImpact\nChange-Id: I3f040374455feb876e970a1813099598301774b5\n'}, {'number': 3, 'created': '2013-07-15 19:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a4fc49a16374899db2de850fa0745f870ac4d6d0', 'message': 'File system store can send metadata back with the location.\n\nThis patch allows the glance operator to associate metadata with\nthe file system store.  The metadata will be returned to v2 users\nwith each location that was created by the file system store.  This\ninformation can give clients context into how to consume the data.\n\nThe new configuration option: file system_store_metadata_file is\nadded.  This is a path to a JSON file.  The JSON document can\ncontain lists, dicts and unicode values only.\n\nblueprint: direct-url-meta-data\nblueprint: multiple-image-locations\ndocImpact\nChange-Id: I3f040374455feb876e970a1813099598301774b5\n'}, {'number': 4, 'created': '2013-07-15 20:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bdf08711cf8dfd2b48968c46d762491d64be743a', 'message': 'File system store can send metadata back with the location.\n\nThis patch allows the glance operator to associate metadata with\nthe file system store.  The metadata will be returned to v2 users\nwith each location that was created by the file system store.  This\ninformation can give clients context into how to consume the data.\n\nThe new configuration option: file system_store_metadata_file is\nadded.  This is a path to a JSON file.  The JSON document can\ncontain lists, dicts and unicode values only.\n\nblueprint: direct-url-meta-data\nblueprint: multiple-image-locations\ndocImpact\nChange-Id: I3f040374455feb876e970a1813099598301774b5\n'}, {'number': 5, 'created': '2013-07-16 20:18:39.000000000', 'files': ['glance/tests/unit/test_filesystem_store.py', 'etc/glance-api.conf', 'glance/store/filesystem.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/3726418603dc657b7b7adc8a8eaac0e0921b0526', 'message': 'File system store can send metadata back with the location.\n\nThis patch allows the glance operator to associate metadata with\nthe file system store.  The metadata will be returned to v2 users\nwith each location that was created by the file system store.  This\ninformation can give clients context into how to consume the data.\n\nThe new configuration option: file system_store_metadata_file is\nadded.  This is a path to a JSON file.  The JSON document can\ncontain lists, dicts and unicode values only.\n\nblueprint: direct-url-meta-data\nblueprint: multiple-image-locations\ndocImpact\nChange-Id: I3f040374455feb876e970a1813099598301774b5\n'}]",16,36884,3726418603dc657b7b7adc8a8eaac0e0921b0526,28,7,5,6493,,,0,"File system store can send metadata back with the location.

This patch allows the glance operator to associate metadata with
the file system store.  The metadata will be returned to v2 users
with each location that was created by the file system store.  This
information can give clients context into how to consume the data.

The new configuration option: file system_store_metadata_file is
added.  This is a path to a JSON file.  The JSON document can
contain lists, dicts and unicode values only.

blueprint: direct-url-meta-data
blueprint: multiple-image-locations
docImpact
Change-Id: I3f040374455feb876e970a1813099598301774b5
",git fetch https://review.opendev.org/openstack/glance refs/changes/84/36884/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_filesystem_store.py', 'glance/store/filesystem.py']",2,bf19a310092c4b9f64d0eed1ac1dd9e2164ff439,bp/direct-url-meta-data,"import jsonmetadata_opt = cfg.StrOpt('filesystem_store_metadata_file', help=_(""The path to a file which contains the "" ""metadata to be returned with any location "" ""associated with this store. The file must "" ""contain a valid JSON dict.""))CONF.register_opt(metadata_opt) def _get_metadata(self): if CONF.filesystem_store_metadata_file is None: return {} try: fptr = open(CONF.filesystem_store_metadata_file, 'r') metadata = json.load(fptr) glance.store._check_meta_data(metadata) return metadata except glance.store.BackendException as bee: LOG.error(_('The JSON in the metadata file %s could not be used: ' '%s An empty dictionary will be returned ' 'to the client.' % (CONF.filesystem_store_metadata_file, str(bee)))) return {} except IOError as ioe: LOG.error(_('The path for the metadata file %s could not be ' 'opened: %s An empty dictionary will be returned ' 'to the client.' % (CONF.filesystem_store_metadata_file, ioe.message))) return {} except Exception as ex: LOG.error(_('An error occured processing the storage systems meta ' 'data file: %s. An empty dictionary will be returned ' 'to the client.' % (str(ex)))) return {} metadata = self._get_metadata() return ('file://%s' % filepath, bytes_written, checksum_hex, metadata)"," return ('file://%s' % filepath, bytes_written, checksum_hex, {})",96,1
openstack%2Fdevstack~master~I86e4734c3a9e57f1dc68f1104449d7c041d6927d,openstack/devstack,master,I86e4734c3a9e57f1dc68f1104449d7c041d6927d,Create an endpoint for nova api v3.,MERGED,2013-06-17 14:46:24.000000000,2013-07-18 23:19:22.000000000,2013-07-18 23:19:22.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 5586}, {'_account_id': 5803}, {'_account_id': 6864}]","[{'number': 2, 'created': '2013-06-17 14:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/abea848674f57d6873d6b9190efac00a447b14ba', 'message': 'Create an endpoint for nova api v3.\n\nSupports both SQL and templated keystone backend.\nCreate an additional endpoint for nova api v3.\nThe service type is computev3.\nThe endpoint is identical to the v2 one except for\nthe ""v3"" string instead of ""v2"".\n\nFixes: bug #1191798\nChange-Id: I86e4734c3a9e57f1dc68f1104449d7c041d6927d\n'}, {'number': 1, 'created': '2013-06-17 14:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/600c6afe4867d270c5c3ab0b0579623fb856b38b', 'message': 'Create an endpoint for nova api v3.\n\nSupports both SQL and templated keystone backend.\nCreate an additional endpoint for nova api v3.\nThe service type is computev3.\nThe endpoint is identical to the v2 one except for\nthe ""v3"" string instead of ""v2"".\n\nFixes: bug #1191798\nChange-Id: I86e4734c3a9e57f1dc68f1104449d7c041d6927d\n'}, {'number': 3, 'created': '2013-07-18 09:35:00.000000000', 'files': ['files/default_catalog.templates', 'lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/806233e0ed30e59d9deb9934f831f8ffad879733', 'message': 'Create an endpoint for nova api v3.\n\nSupports both SQL and templated keystone backend.\nCreate an additional endpoint for nova api v3.\nThe service type is computev3.\nThe endpoint is similar to the v2 one but the version\npart is ""v3"" rather than ""v2"", and it does not include\nthe tenantid anymore.\n\nFixes: bug #1191798\nChange-Id: I86e4734c3a9e57f1dc68f1104449d7c041d6927d\n'}]",2,33277,806233e0ed30e59d9deb9934f831f8ffad879733,35,8,3,1921,,,0,"Create an endpoint for nova api v3.

Supports both SQL and templated keystone backend.
Create an additional endpoint for nova api v3.
The service type is computev3.
The endpoint is similar to the v2 one but the version
part is ""v3"" rather than ""v2"", and it does not include
the tenantid anymore.

Fixes: bug #1191798
Change-Id: I86e4734c3a9e57f1dc68f1104449d7c041d6927d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/77/33277/3 && git format-patch -1 --stdout FETCH_HEAD,"['files/default_catalog.templates', 'lib/nova']",2,abea848674f57d6873d6b9190efac00a447b14ba,bug/1191798," NOVA_V3_SERVICE=$(keystone service-create \ --name=nova \ --type=computev3 \ --description=""Nova Compute Service V3"" \ | grep "" id "" | get_field 2) keystone endpoint-create \ --region RegionOne \ --service_id $NOVA_V3_SERVICE \ --publicurl ""$NOVA_SERVICE_PROTOCOL://$NOVA_SERVICE_HOST:$NOVA_SERVICE_PORT/v3/\$(tenant_id)s"" \ --adminurl ""$NOVA_SERVICE_PROTOCOL://$NOVA_SERVICE_HOST:$NOVA_SERVICE_PORT/v3/\$(tenant_id)s"" \ --internalurl ""$NOVA_SERVICE_PROTOCOL://$NOVA_SERVICE_HOST:$NOVA_SERVICE_PORT/v3/\$(tenant_id)s""",,17,0
openstack%2Fdevstack~master~I775cae40edc9f8f55177f9d95cdbaa9416c4bfcd,openstack/devstack,master,I775cae40edc9f8f55177f9d95cdbaa9416c4bfcd,fix name of scheduler_driver in produced nova.conf,MERGED,2013-07-17 15:43:09.000000000,2013-07-18 23:19:21.000000000,2013-07-18 23:19:20.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1082}, {'_account_id': 1653}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-17 15:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d740f6e3ce9e6c811ac92d00b09f51a359b11be8', 'message': 'fix name of scheduler_driver in produced nova.conf\n\nfix #1202174.  The nova.conf config variable that configures which\nscheduler to use is scheduler_driver, not compute_scheduler_driver.\n\nChange-Id: I775cae40edc9f8f55177f9d95cdbaa9416c4bfcd\n'}, {'number': 2, 'created': '2013-07-17 17:54:15.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/50686e56200e7064f5ba65834a03977b6d9ce413', 'message': 'fix name of scheduler_driver in produced nova.conf\n\nFixes bug #1202174.  The nova.conf config variable that configures which\nscheduler to use is scheduler_driver, not compute_scheduler_driver.\n\nChange-Id: I775cae40edc9f8f55177f9d95cdbaa9416c4bfcd\n'}]",0,37509,50686e56200e7064f5ba65834a03977b6d9ce413,15,5,2,1082,,,0,"fix name of scheduler_driver in produced nova.conf

Fixes bug #1202174.  The nova.conf config variable that configures which
scheduler to use is scheduler_driver, not compute_scheduler_driver.

Change-Id: I775cae40edc9f8f55177f9d95cdbaa9416c4bfcd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/09/37509/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,d740f6e3ce9e6c811ac92d00b09f51a359b11be8,bug/1202174," iniset $NOVA_CONF DEFAULT scheduler_driver ""$SCHEDULER"""," iniset $NOVA_CONF DEFAULT compute_scheduler_driver ""$SCHEDULER""",1,1
openstack%2Fnova~master~Ib0eb582f472116bda817d3e35e26888dc116ad58,openstack/nova,master,Ib0eb582f472116bda817d3e35e26888dc116ad58,Fix IPAddress and CIDR type decorators,MERGED,2013-07-15 14:16:22.000000000,2013-07-18 22:21:25.000000000,2013-07-18 22:21:23.000000000,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-07-15 14:16:22.000000000', 'files': ['nova/db/sqlalchemy/types.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cd382933eb5b6b09f34398cf2c963164bc5b6fc7', 'message': 'Fix IPAddress and CIDR type decorators\n\nUse load_dialect_impl() user hook instead of calling\nwith_variant() on a type implementation in IPAddress\nand CIDR type decorators. This makes this code work\nwith SQLAlchemy 0.8.x versions.\n\nFixes bug 1200231\n\nChange-Id: Ib0eb582f472116bda817d3e35e26888dc116ad58\n'}]",0,37060,cd382933eb5b6b09f34398cf2c963164bc5b6fc7,8,5,1,6849,,,0,"Fix IPAddress and CIDR type decorators

Use load_dialect_impl() user hook instead of calling
with_variant() on a type implementation in IPAddress
and CIDR type decorators. This makes this code work
with SQLAlchemy 0.8.x versions.

Fixes bug 1200231

Change-Id: Ib0eb582f472116bda817d3e35e26888dc116ad58
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/37060/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/types.py'],1,cd382933eb5b6b09f34398cf2c963164bc5b6fc7,bug/1200231," impl = types.String def load_dialect_impl(self, dialect): if dialect.name == 'postgresql': return dialect.type_descriptor(postgresql.INET()) else: return dialect.type_descriptor(types.String(39)) impl = types.String def load_dialect_impl(self, dialect): if dialect.name == 'postgresql': return dialect.type_descriptor(postgresql.INET()) else: return dialect.type_descriptor(types.String(43))"," impl = types.String(39).with_variant(postgresql.INET(), 'postgresql') impl = types.String(43).with_variant(postgresql.INET(), 'postgresql')",16,2
openstack%2Fnova~master~Iea81532911478026b9b2c0578a1eda7a97b09d80,openstack/nova,master,Iea81532911478026b9b2c0578a1eda7a97b09d80,Refresh network cache when reassigning a floating IP in Neutron,MERGED,2013-06-14 13:33:55.000000000,2013-07-18 22:21:05.000000000,2013-07-18 22:21:03.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 7823}]","[{'number': 1, 'created': '2013-06-14 13:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c1d1776b1b9f8b1aaf2ea2fafabb8f7bea28e87', 'message': 'Refresh network cache when reassigning a floating IP in quantum\n\nWhen Nova associates or disassociates a floating IP address\nthe network info cache is always refreshed due to the\n@refresh_cache decorator\n\nHowever if you (re)associate a floating IP which is already\nassociated with another instance on a Quantum based system then\nthe address is correcly disassociated first, but the cache refresh\nis not trigged for the original  instance. As a result Nova will\nshow the same address for two instances until the periodic\nclean-up kicks in some minutes later.\n\nFixed bug: 1173227\n\nChange-Id: Iea81532911478026b9b2c0578a1eda7a97b09d80\n'}, {'number': 3, 'created': '2013-06-14 15:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/010eaf785f32d880c58b6b73042a48b18b0e537b', 'message': 'Refresh network cache when reassigning a floating IP in quantum\n\nWhen Nova associates or disassociates a floating IP address\nthe network info cache is always refreshed due to the\n@refresh_cache decorator\n\nHowever if you (re)associate a floating IP which is already\nassociated with another instance on a Quantum based system then\nthe address is correcly disassociated first, but the cache refresh\nis not trigged for the original  instance. As a result Nova will\nshow the same address for two instances until the periodic\nclean-up kicks in some minutes later.\n\nFixed bug: 1173227\n\nChange-Id: Iea81532911478026b9b2c0578a1eda7a97b09d80\n'}, {'number': 2, 'created': '2013-06-14 15:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6606ba79aee3d51fe95857089050c781356d08e1', 'message': 'Refresh network cache when reassigning a floating IP in quantum\n\nWhen Nova associates or disassociates a floating IP address\nthe network info cache is always refreshed due to the\n@refresh_cache decorator\n\nHowever if you (re)associate a floating IP which is already\nassociated with another instance on a Quantum based system then\nthe address is correcly disassociated first, but the cache refresh\nis not trigged for the original  instance. As a result Nova will\nshow the same address for two instances until the periodic\nclean-up kicks in some minutes later.\n\nFixed bug: 1173227\n\nChange-Id: Iea81532911478026b9b2c0578a1eda7a97b09d80\n'}, {'number': 4, 'created': '2013-07-17 10:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dc43c8fb1ba967ed15a7f8263d81174a4d5beba3', 'message': 'Refresh network cache when reassigning a floating IP in quantum\n\nWhen Nova associates or disassociates a floating IP address\nthe network info cache is always refreshed due to the\n@refresh_cache decorator\n\nHowever if you (re)associate a floating IP which is already\nassociated with another instance on a Quantum based system then\nthe address is correcly disassociated first, but the cache refresh\nis not trigged for the original  instance. As a result Nova will\nshow the same address for two instances until the periodic\nclean-up kicks in some minutes later.\n\nFixed bug: 1173227\n\nChange-Id: Iea81532911478026b9b2c0578a1eda7a97b09d80\n'}, {'number': 5, 'created': '2013-07-17 15:12:16.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/49fdad5b6d1e0878438571c2e9c0421bc522cb2e', 'message': 'Refresh network cache when reassigning a floating IP in Neutron\n\nWhen Nova associates or disassociates a floating IP address\nthe network info cache is always refreshed due to the\n@refresh_cache decorator\n\nHowever if you (re)associate a floating IP which is already\nassociated with another instance on a Neutron based system then\nthe address is correcly disassociated first, but the cache refresh\nis not trigged for the original  instance. As a result Nova will\nshow the same address for two instances until the periodic\nclean-up kicks in some minutes later.\n\nFixed bug: 1173227\n\nChange-Id: Iea81532911478026b9b2c0578a1eda7a97b09d80\n'}]",15,33054,49fdad5b6d1e0878438571c2e9c0421bc522cb2e,61,11,5,1501,,,0,"Refresh network cache when reassigning a floating IP in Neutron

When Nova associates or disassociates a floating IP address
the network info cache is always refreshed due to the
@refresh_cache decorator

However if you (re)associate a floating IP which is already
associated with another instance on a Neutron based system then
the address is correcly disassociated first, but the cache refresh
is not trigged for the original  instance. As a result Nova will
show the same address for two instances until the periodic
clean-up kicks in some minutes later.

Fixed bug: 1173227

Change-Id: Iea81532911478026b9b2c0578a1eda7a97b09d80
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/33054/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/quantumv2/api.py', 'nova/tests/network/test_quantumv2.py']",2,6c1d1776b1b9f8b1aaf2ea2fafabb8f7bea28e87,bug/1173227," self.instance2 = {'project_id': '9d049e4b60b64716978ab415e6fbd5c0', 'uuid': str(uuid.uuid4()), 'display_name': 'test_instance2', 'availability_zone': 'nova', 'security_groups': []} 'device_id': self.instance2['uuid'], self.port_address2 = '10.0.2.2' 'device_id': self.instance['uuid'], 'fixed_ips': [{'ip_address': self.port_address2, 'subnet_id': 'my_subid2'}], self.assertEquals(self.instance2['uuid'], result[0]['instance_uuid']) self.assertEquals(self.instance['uuid'], result[1]['instance_uuid']) self.assertEquals(self.instance2['uuid'], result['instance_uuid']) def _setup_mock_for_refresh_cache(self, api, instances): for instance in instances: nw_info.json() api._get_instance_nw_info(mox.IgnoreArg(), instance).\ AndReturn(nw_info) api.db.instance_info_cache_update(mox.IgnoreArg(), instance['uuid'], mox.IgnoreArg()) address = self.fip_unassociated['floating_ip_address'] fixed_address = self.port_address2 fip_id = self.fip_unassociated['id'] AndReturn({'floatingips': [self.fip_unassociated]}) self._setup_mock_for_refresh_cache(api, [self.instance]) def test_reassociate_floating_ip(self): api = quantumapi.API() address = self.fip_associated['floating_ip_address'] old_fixed_address = self.fip_associated['fixed_ip_address'] new_fixed_address = self.port_address fip_id = self.fip_associated['id'] search_opts = {'device_owner': 'compute:nova', 'device_id': self.instance2['uuid']} self.moxed_client.list_ports(**search_opts).\ AndReturn({'ports': [self.port_data2[0]]}) self.moxed_client.list_floatingips(floating_ip_address=address).\ AndReturn({'floatingips': [self.fip_associated]}) self.moxed_client.update_floatingip( fip_id, {'floatingip': {'port_id': 'my_portid1', 'fixed_ip_address': new_fixed_address}}) self.moxed_client.show_port(self.fip_associated['port_id']).\ AndReturn({'port': self.port_data2[1]}) self.mox.StubOutWithMock(api.db, 'instance_get_by_uuid') api.db.instance_get_by_uuid(mox.IgnoreArg(), self.instance['uuid']).\ AndReturn(self.instance) self._setup_mock_for_refresh_cache(api, [self.instance, self.instance2]) self.mox.ReplayAll() api.associate_floating_ip(self.context, self.instance2, address, new_fixed_address) self._setup_mock_for_refresh_cache(api, [self.instance]) self._setup_mock_for_refresh_cache(api, [self.instance]) self._setup_mock_for_refresh_cache(api, [self.instance])"," 'device_id': 'device_id1', 'device_id': 'device_id2', 'fixed_ips': [{'ip_address': '10.0.2.2', 'subnet_id': 'my_subid2'}], self.assertEquals('device_id1', result[0]['instance_uuid']) self.assertEquals('device_id2', result[1]['instance_uuid']) self.assertEquals('device_id1', result['instance_uuid']) def _setup_mock_for_refresh_cache(self, api): nw_info.json() api._get_instance_nw_info(mox.IgnoreArg(), self.instance).\ AndReturn(nw_info) api.db.instance_info_cache_update(mox.IgnoreArg(), self.instance['uuid'], mox.IgnoreArg()) address = self.fip_associated['floating_ip_address'] fixed_address = self.fip_associated['fixed_ip_address'] fip_id = self.fip_associated['id'] AndReturn({'floatingips': [self.fip_associated]}) self._setup_mock_for_refresh_cache(api) self._setup_mock_for_refresh_cache(api) self._setup_mock_for_refresh_cache(api) self._setup_mock_for_refresh_cache(api)",73,22
openstack%2Fdesignate~master~Iedf9d60b24cd835f3f628b90993ca125faa9389b,openstack/designate,master,Iedf9d60b24cd835f3f628b90993ca125faa9389b,Accept trailing /'s on URLs.,MERGED,2013-07-18 21:31:09.000000000,2013-07-18 22:20:38.000000000,2013-07-18 22:20:38.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}]","[{'number': 1, 'created': '2013-07-18 21:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/55c516eadb096b30cf31363c020e0f4dd0932805', 'message': ""Accept trailing /'s on URLs.\n\nThe API should accept trailing slashes.  The werkzeug map rule strict\nslashes is set to False to allow trailing slashes.  The tests have\nbeen updated using mock methods to verify that the api accepts the\ncall and then calls central service.\nFixes: bug 1202411\nChange-Id: Iedf9d60b24cd835f3f628b90993ca125faa9389b\n""}, {'number': 2, 'created': '2013-07-18 21:45:56.000000000', 'files': ['designate/tests/test_api/test_v1/test_records.py', 'designate/tests/test_api/test_v1/test_servers.py', 'designate/api/v1/__init__.py', 'designate/tests/test_api/test_v1/test_domains.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/6103e82981f4841bc183f083a3ae3cf5f4edef1c', 'message': ""Accept trailing /'s on URLs.\n\nThe API should accept trailing slashes.  The werkzeug map rule strict\nslashes is set to False to allow trailing slashes.  The tests have\nbeen updated using mock methods to verify that the api accepts the\ncall and then calls central service.\nFixes: bug 1202411\nChange-Id: Iedf9d60b24cd835f3f628b90993ca125faa9389b\n""}]",0,37783,6103e82981f4841bc183f083a3ae3cf5f4edef1c,8,3,2,8094,,,0,"Accept trailing /'s on URLs.

The API should accept trailing slashes.  The werkzeug map rule strict
slashes is set to False to allow trailing slashes.  The tests have
been updated using mock methods to verify that the api accepts the
call and then calls central service.
Fixes: bug 1202411
Change-Id: Iedf9d60b24cd835f3f628b90993ca125faa9389b
",git fetch https://review.opendev.org/openstack/designate refs/changes/83/37783/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/tests/test_api/test_v1/test_records.py', 'designate/tests/test_api/test_v1/test_servers.py', 'designate/api/v1/__init__.py', 'designate/tests/test_api/test_v1/test_domains.py']",4,55c516eadb096b30cf31363c020e0f4dd0932805,bug/1202411," @patch.object(central_service.Service, 'create_domain') def test_create_domain_trailing_slash(self, mock): # Create a server self.create_server() self.post('domains/', data=self.get_domain_fixture(0)) # verify that the central service is called self.assertTrue(mock.called) @patch.object(central_service.Service, 'find_domains') def test_get_domains_trailing_slash(self, mock): self.get('domains/') # verify that the central service is called self.assertTrue(mock.called) @patch.object(central_service.Service, 'get_domain') def test_get_domain_trailing_slash(self, mock): # Create a domain domain = self.create_domain() self.get('domains/%s/' % domain['id']) # verify that the central service is called self.assertTrue(mock.called) @patch.object(central_service.Service, 'update_domain') def test_update_domain_trailing_slash(self, mock): # Create a domain domain = self.create_domain() data = {'email': 'prefix-%s' % domain['email']} self.put('domains/%s/' % domain['id'], data=data) # verify that the central service is called self.assertTrue(mock.called) @patch.object(central_service.Service, 'delete_domain') def test_delete_domain_trailing_slash(self, mock): # Create a domain domain = self.create_domain() self.delete('domains/%s/' % domain['id']) # verify that the central service is called self.assertTrue(mock.called) ",,151,1
openstack%2Fnova~master~I20d7ade5acd27d23ba53ef065d0e4d24218182c2,openstack/nova,master,I20d7ade5acd27d23ba53ef065d0e4d24218182c2,Remove redundant if statements in cells.state,MERGED,2013-07-16 03:00:24.000000000,2013-07-18 22:04:55.000000000,2013-07-18 22:04:53.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 5292}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-07-16 03:00:24.000000000', 'files': ['nova/cells/state.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/97f8069eb1613fd6fa3f6b28e2088dbfdb6183a3', 'message': 'Remove redundant if statements in cells.state\n\nRemoved redundant if statements since checking if cell is None twice\nwas not intuitive.\n\nChange-Id: I20d7ade5acd27d23ba53ef065d0e4d24218182c2\n'}]",0,37164,97f8069eb1613fd6fa3f6b28e2088dbfdb6183a3,8,7,1,1994,,,0,"Remove redundant if statements in cells.state

Removed redundant if statements since checking if cell is None twice
was not intuitive.

Change-Id: I20d7ade5acd27d23ba53ef065d0e4d24218182c2
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/37164/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/cells/state.py'],1,97f8069eb1613fd6fa3f6b28e2088dbfdb6183a3,cells_state, cell = (self.child_cells.get(cell_name) or self.parent_cells.get(cell_name)) cell = (self.child_cells.get(cell_name) or self.parent_cells.get(cell_name)), cell = self.child_cells.get(cell_name) if not cell: cell = self.parent_cells.get(cell_name) cell = self.child_cells.get(cell_name) if not cell: cell = self.parent_cells.get(cell_name),4,6
openstack%2Fnova~master~Ia2ef4ab8cb63878d16360378c61e5182f4593200,openstack/nova,master,Ia2ef4ab8cb63878d16360378c61e5182f4593200,port disk_config API into v3 part1,MERGED,2013-07-01 22:16:49.000000000,2013-07-18 22:00:15.000000000,2013-07-18 22:00:13.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5586}, {'_account_id': 5754}]","[{'number': 1, 'created': '2013-07-01 22:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e0177377c6000a4e15c1f56d5b44b510d3a1070', 'message': 'port disk_config API into v3 part1\n\nThis changeset only copies the v2 files into the appropriate v3\ndirectories unchanged. The copy as-is will not be loaded by either\nthe v2 or v3 extension loaders. The second changeset will then\nmake the changes required for it to work as a v3 extension.\n\nThis is being tried in order to make reviewing of extension\nporting easier as gerrit will display only what is actually\nchanged for v3 rather than entirely new files.\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: Ia2ef4ab8cb63878d16360378c61e5182f4593200\n'}, {'number': 2, 'created': '2013-07-11 08:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a235656b02f2780f33732c82d08ec9fff359f4b', 'message': 'port disk_config API into v3 part1\n\nThis changeset only copies the v2 files into the appropriate v3\ndirectories unchanged. The copy as-is will not be loaded by either\nthe v2 or v3 extension loaders. The second changeset will then\nmake the changes required for it to work as a v3 extension.\n\nThis is being tried in order to make reviewing of extension\nporting easier as gerrit will display only what is actually\nchanged for v3 rather than entirely new files.\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: Ia2ef4ab8cb63878d16360378c61e5182f4593200\n'}, {'number': 3, 'created': '2013-07-14 21:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/688ea8420f1562d4e13b833cacd53fed70a43bc5', 'message': 'port disk_config API into v3 part1\n\nThis changeset only copies the v2 files into the appropriate v3\ndirectories unchanged. The copy as-is will not be loaded by either\nthe v2 or v3 extension loaders. The second changeset will then\nmake the changes required for it to work as a v3 extension.\n\nThis is being tried in order to make reviewing of extension\nporting easier as gerrit will display only what is actually\nchanged for v3 rather than entirely new files.\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: Ia2ef4ab8cb63878d16360378c61e5182f4593200\n'}, {'number': 4, 'created': '2013-07-15 00:23:34.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/disk_config.py', 'nova/tests/api/openstack/compute/plugins/v3/test_disk_config.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7f7d29dbbb3df7379fd9af4664c11258ead9da1a', 'message': 'port disk_config API into v3 part1\n\nThis changeset only copies the v2 files into the appropriate v3\ndirectories unchanged. The copy as-is will not be loaded by either\nthe v2 or v3 extension loaders. The second changeset will then\nmake the changes required for it to work as a v3 extension.\n\nThis is being tried in order to make reviewing of extension\nporting easier as gerrit will display only what is actually\nchanged for v3 rather than entirely new files.\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: Ia2ef4ab8cb63878d16360378c61e5182f4593200\n'}]",0,35212,7f7d29dbbb3df7379fd9af4664c11258ead9da1a,24,7,4,5586,,,0,"port disk_config API into v3 part1

This changeset only copies the v2 files into the appropriate v3
directories unchanged. The copy as-is will not be loaded by either
the v2 or v3 extension loaders. The second changeset will then
make the changes required for it to work as a v3 extension.

This is being tried in order to make reviewing of extension
porting easier as gerrit will display only what is actually
changed for v3 rather than entirely new files.

Partially implements: bp v3-api-extension-versioning

Change-Id: Ia2ef4ab8cb63878d16360378c61e5182f4593200
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/35212/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/disk_config.py', 'nova/tests/api/openstack/compute/plugins/v3/test_disk_config.py']",2,6e0177377c6000a4e15c1f56d5b44b510d3a1070,bp/v3-api-extension-versioning,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Copyright 2011 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime from nova.api.openstack import compute import nova.db.api from nova.openstack.common import jsonutils import nova.openstack.common.rpc from nova import test from nova.tests.api.openstack import fakes import nova.tests.image.fake MANUAL_INSTANCE_UUID = fakes.FAKE_UUID AUTO_INSTANCE_UUID = fakes.FAKE_UUID.replace('a', 'b') stub_instance = fakes.stub_instance API_DISK_CONFIG = 'OS-DCF:diskConfig' def instance_addresses(context, instance_id): return None class DiskConfigTestCase(test.TestCase): def setUp(self): super(DiskConfigTestCase, self).setUp() self.flags(verbose=True, osapi_compute_extension=[ 'nova.api.openstack.compute.contrib.select_extensions'], osapi_compute_ext_list=['Disk_config']) nova.tests.image.fake.stub_out_image_service(self.stubs) fakes.stub_out_nw_api(self.stubs) FAKE_INSTANCES = [ fakes.stub_instance(1, uuid=MANUAL_INSTANCE_UUID, auto_disk_config=False), fakes.stub_instance(2, uuid=AUTO_INSTANCE_UUID, auto_disk_config=True) ] def fake_instance_get(context, id_): for instance in FAKE_INSTANCES: if id_ == instance['id']: return instance self.stubs.Set(nova.db, 'instance_get', fake_instance_get) def fake_instance_get_by_uuid(context, uuid): for instance in FAKE_INSTANCES: if uuid == instance['uuid']: return instance self.stubs.Set(nova.db, 'instance_get_by_uuid', fake_instance_get_by_uuid) def fake_instance_get_all(context, *args, **kwargs): return FAKE_INSTANCES self.stubs.Set(nova.db, 'instance_get_all', fake_instance_get_all) self.stubs.Set(nova.db, 'instance_get_all_by_filters', fake_instance_get_all) def fake_instance_create(context, inst_, session=None): class FakeModel(dict): def save(self, session=None): pass inst = FakeModel(**inst_) inst['id'] = 1 inst['uuid'] = AUTO_INSTANCE_UUID inst['created_at'] = datetime.datetime(2010, 10, 10, 12, 0, 0) inst['updated_at'] = datetime.datetime(2010, 10, 10, 12, 0, 0) inst['progress'] = 0 inst['name'] = 'instance-1' # this is a property inst['task_state'] = '' inst['vm_state'] = '' # NOTE(vish): db create translates security groups into model # objects. Translate here so tests pass inst['security_groups'] = [{'name': group} for group in inst['security_groups']] def fake_instance_get_for_create(context, id_, *args, **kwargs): return (inst, inst) self.stubs.Set(nova.db, 'instance_update_and_get_original', fake_instance_get_for_create) def fake_instance_get_all_for_create(context, *args, **kwargs): return [inst] self.stubs.Set(nova.db, 'instance_get_all', fake_instance_get_all_for_create) self.stubs.Set(nova.db, 'instance_get_all_by_filters', fake_instance_get_all_for_create) def fake_instance_add_security_group(context, instance_id, security_group_id): pass self.stubs.Set(nova.db, 'instance_add_security_group', fake_instance_add_security_group) return inst self.stubs.Set(nova.db, 'instance_create', fake_instance_create) self.app = compute.APIRouter(init_only=('servers', 'images')) def tearDown(self): super(DiskConfigTestCase, self).tearDown() nova.tests.image.fake.FakeImageService_reset() def assertDiskConfig(self, dict_, value): self.assert_(API_DISK_CONFIG in dict_) self.assertEqual(dict_[API_DISK_CONFIG], value) def test_show_server(self): req = fakes.HTTPRequest.blank( '/fake/servers/%s' % MANUAL_INSTANCE_UUID) res = req.get_response(self.app) server_dict = jsonutils.loads(res.body)['server'] self.assertDiskConfig(server_dict, 'MANUAL') req = fakes.HTTPRequest.blank( '/fake/servers/%s' % AUTO_INSTANCE_UUID) res = req.get_response(self.app) server_dict = jsonutils.loads(res.body)['server'] self.assertDiskConfig(server_dict, 'AUTO') def test_detail_servers(self): req = fakes.HTTPRequest.blank('/fake/servers/detail') res = req.get_response(self.app) server_dicts = jsonutils.loads(res.body)['servers'] expectations = ['MANUAL', 'AUTO'] for server_dict, expected in zip(server_dicts, expectations): self.assertDiskConfig(server_dict, expected) def test_show_image(self): req = fakes.HTTPRequest.blank( '/fake/images/a440c04b-79fa-479c-bed1-0b816eaec379') res = req.get_response(self.app) image_dict = jsonutils.loads(res.body)['image'] self.assertDiskConfig(image_dict, 'MANUAL') req = fakes.HTTPRequest.blank( '/fake/images/70a599e0-31e7-49b7-b260-868f441e862b') res = req.get_response(self.app) image_dict = jsonutils.loads(res.body)['image'] self.assertDiskConfig(image_dict, 'AUTO') def test_detail_image(self): req = fakes.HTTPRequest.blank('/fake/images/detail') res = req.get_response(self.app) image_dicts = jsonutils.loads(res.body)['images'] expectations = ['MANUAL', 'AUTO'] for image_dict, expected in zip(image_dicts, expectations): # NOTE(sirp): image fixtures 6 and 7 are setup for # auto_disk_config testing if image_dict['id'] in (6, 7): self.assertDiskConfig(image_dict, expected) def test_create_server_override_auto(self): req = fakes.HTTPRequest.blank('/fake/servers') req.method = 'POST' req.content_type = 'application/json' body = {'server': { 'name': 'server_test', 'imageRef': 'cedef40a-ed67-4d10-800e-17455edce175', 'flavorRef': '1', API_DISK_CONFIG: 'AUTO' }} req.body = jsonutils.dumps(body) res = req.get_response(self.app) server_dict = jsonutils.loads(res.body)['server'] self.assertDiskConfig(server_dict, 'AUTO') def test_create_server_override_manual(self): req = fakes.HTTPRequest.blank('/fake/servers') req.method = 'POST' req.content_type = 'application/json' body = {'server': { 'name': 'server_test', 'imageRef': 'cedef40a-ed67-4d10-800e-17455edce175', 'flavorRef': '1', API_DISK_CONFIG: 'MANUAL' }} req.body = jsonutils.dumps(body) res = req.get_response(self.app) server_dict = jsonutils.loads(res.body)['server'] self.assertDiskConfig(server_dict, 'MANUAL') def test_create_server_detect_from_image(self): """"""If user doesn't pass in diskConfig for server, use image metadata to specify AUTO or MANUAL. """""" req = fakes.HTTPRequest.blank('/fake/servers') req.method = 'POST' req.content_type = 'application/json' body = {'server': { 'name': 'server_test', 'imageRef': 'a440c04b-79fa-479c-bed1-0b816eaec379', 'flavorRef': '1', }} req.body = jsonutils.dumps(body) res = req.get_response(self.app) server_dict = jsonutils.loads(res.body)['server'] self.assertDiskConfig(server_dict, 'MANUAL') req = fakes.HTTPRequest.blank('/fake/servers') req.method = 'POST' req.content_type = 'application/json' body = {'server': { 'name': 'server_test', 'imageRef': '70a599e0-31e7-49b7-b260-868f441e862b', 'flavorRef': '1', }} req.body = jsonutils.dumps(body) res = req.get_response(self.app) server_dict = jsonutils.loads(res.body)['server'] self.assertDiskConfig(server_dict, 'AUTO') def test_update_server_invalid_disk_config(self): # Return BadRequest if user passes an invalid diskConfig value. req = fakes.HTTPRequest.blank( '/fake/servers/%s' % MANUAL_INSTANCE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {API_DISK_CONFIG: 'server_test'}} req.body = jsonutils.dumps(body) res = req.get_response(self.app) self.assertEqual(res.status_int, 400) expected_msg = ('{""badRequest"": {""message"": ""%s must be either' ' \'MANUAL\' or \'AUTO\'."", ""code"": 400}}' % API_DISK_CONFIG) self.assertEqual(res.body, expected_msg) ",,449,0
openstack%2Fnova~master~Ie28d771d25636decb7b1f17756654be56762b35f,openstack/nova,master,Ie28d771d25636decb7b1f17756654be56762b35f,Sync v2/v3 console_output API extensions,MERGED,2013-07-11 07:05:58.000000000,2013-07-18 21:59:55.000000000,2013-07-18 21:59:53.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-11 07:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a50f1d18efd889fd1f83b7560975fb38d24d2b2a', 'message': 'Sync v2/v3 console_output API extensions\n\nSynchronises changes made to the v2 version of the console_output\nAPI extension to v3 in commit c651f4928c65407cff86a9f9efc046a0f76a9519\nwhich fixed bug  #1194032\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Ie28d771d25636decb7b1f17756654be56762b35f\n'}, {'number': 2, 'created': '2013-07-13 05:31:15.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_console_output.py', 'nova/api/openstack/compute/plugins/v3/console_output.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2b750f7a85384ea3391af216466b8058b8c27d6a', 'message': 'Sync v2/v3 console_output API extensions\n\nSynchronises changes made to the v2 version of the console_output\nAPI extension to v3 in commit c651f4928c65407cff86a9f9efc046a0f76a9519\nwhich fixed bug  #1194032\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Ie28d771d25636decb7b1f17756654be56762b35f\n'}]",0,36609,2b750f7a85384ea3391af216466b8058b8c27d6a,12,6,2,5292,,,0,"Sync v2/v3 console_output API extensions

Synchronises changes made to the v2 version of the console_output
API extension to v3 in commit c651f4928c65407cff86a9f9efc046a0f76a9519
which fixed bug  #1194032

Partially implements blueprint nova-v3-api

Change-Id: Ie28d771d25636decb7b1f17756654be56762b35f
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/36609/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_console_output.py', 'nova/api/openstack/compute/plugins/v3/console_output.py']",2,a50f1d18efd889fd1f83b7560975fb38d24d2b2a,bug/1194032, remove_re = re.compile('[\x00-\x08\x0B-\x1F]'), remove_re = re.compile('[\x00-\x08\x0B-\x0C\x0E-\x1F-\x0D]'),23,1
openstack%2Fpython-novaclient~master~Ib62aabc3702db88f02259cd721f9efb31404bcb7,openstack/python-novaclient,master,Ib62aabc3702db88f02259cd721f9efb31404bcb7,Allow tenant ID for authentication,MERGED,2013-06-27 22:09:44.000000000,2013-07-18 21:51:19.000000000,2013-07-18 21:51:19.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 679}, {'_account_id': 1501}, {'_account_id': 1849}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-06-27 22:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/f05223f63d226e6a32ff5af100c98167c4adbb74', 'message': 'Allow tenant ID for authentication\n\nTenant names are not necessary unique for a User, so the client\nshould also allow authentication by tenant_id\n\nFixes bug 1195454\n\nChange-Id: Ib62aabc3702db88f02259cd721f9efb31404bcb7\n'}, {'number': 2, 'created': '2013-06-27 23:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/cfa381dca3f3e0ee8b8addead3f17963f04b36d9', 'message': 'Allow tenant ID for authentication\n\nTenant names are not necessarily unique for a User, so the client\nshould also allow authentication by tenant_id\n\nFixes bug 1195454\n\nChange-Id: Ib62aabc3702db88f02259cd721f9efb31404bcb7\n'}, {'number': 3, 'created': '2013-07-03 15:08:52.000000000', 'files': ['novaclient/tests/test_shell.py', 'novaclient/v1_1/client.py', 'novaclient/client.py', 'novaclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/02f906bcd6866b24fa0b48d47f573197b17f0753', 'message': 'Allow tenant ID for authentication\n\nTenant names are not necessarily unique for a User, so the client\nshould also allow authentication by tenant_id\n\nIf both ID and Name are specificed then use the ID\n\nFixes bug 1195454\n\nChange-Id: Ib62aabc3702db88f02259cd721f9efb31404bcb7\n'}]",4,34809,02f906bcd6866b24fa0b48d47f573197b17f0753,14,8,3,1501,,,0,"Allow tenant ID for authentication

Tenant names are not necessarily unique for a User, so the client
should also allow authentication by tenant_id

If both ID and Name are specificed then use the ID

Fixes bug 1195454

Change-Id: Ib62aabc3702db88f02259cd721f9efb31404bcb7
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/09/34809/3 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/test_shell.py', 'novaclient/v1_1/client.py', 'novaclient/client.py', 'novaclient/shell.py']",4,f05223f63d226e6a32ff5af100c98167c4adbb74,bug/1195454," parser.add_argument('--os-tenant-id', metavar='<auth-tenant-id>', default=utils.env('OS_TENANT_ID'), help='Defaults to env[OS_TENANT_ID].') parser.add_argument('--os_tenant_id', help=argparse.SUPPRESS) (os_username, os_tenant_name, os_tenant_id, os_auth_url, args.os_tenant_name, args.os_tenant_id, args.os_auth_url, if not os_tenant_name and not os_tenant_id: ""or tenant id via --os-tenant-name, "" ""--os-tenant-id, env[OS_TENANT_NAME] "" ""or env[OS_TENANT_ID]"") if not os_tenant_name and not os_tenant_id: ""or tenant id via --os-tenant-name, "" ""--os-tenant-id, env[OS_TENANT_NAME] "" ""or env[OS_TENANT_ID]"") os_password, os_tenant_name, tenant_id=os_tenant_id, auth_url=os_auth_url, insecure=insecure,"," (os_username, os_tenant_name, os_auth_url, args.os_tenant_name, args.os_auth_url, if not os_tenant_name: ""via either --os-tenant-name or "" ""env[OS_TENANT_NAME]"") if not os_tenant_name: ""via either --os-tenant-name or env[OS_TENANT_NAME]"") os_password, os_tenant_name, os_auth_url, insecure,",55,20
openstack%2Fhacking~master~Ib0f49d50c9541dd93ace6dd29361e143eb0b6828,openstack/hacking,master,Ib0f49d50c9541dd93ace6dd29361e143eb0b6828,Make H103 Invalid Apache throw error on correct line,MERGED,2013-07-18 18:18:53.000000000,2013-07-18 21:46:18.000000000,2013-07-18 21:46:18.000000000,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-18 18:18:53.000000000', 'files': ['hacking/core.py'], 'web_link': 'https://opendev.org/openstack/hacking/commit/cf90af6281796c11bf0d98e8eb1747b09a9f663c', 'message': ""Make H103 Invalid Apache throw error on correct line\n\nH103 shouldn't trigger on the first line of a file, but rather on the\nfirst line of the apache licence in the file.  Otherwise the error can\nbe confusing to users.\n\nChange-Id: Ib0f49d50c9541dd93ace6dd29361e143eb0b6828\n""}]",1,37738,cf90af6281796c11bf0d98e8eb1747b09a9f663c,6,2,1,1849,,,0,"Make H103 Invalid Apache throw error on correct line

H103 shouldn't trigger on the first line of a file, but rather on the
first line of the apache licence in the file.  Otherwise the error can
be confusing to users.

Change-Id: Ib0f49d50c9541dd93ace6dd29361e143eb0b6828
",git fetch https://review.opendev.org/openstack/hacking refs/changes/38/37738/1 && git format-patch -1 --stdout FETCH_HEAD,['hacking/core.py'],1,cf90af6281796c11bf0d98e8eb1747b09a9f663c,cleanup," content = re.sub('\s+', ' ', content).strip() if _project_is_apache() and len(lines) > 10: column = physical_line.find('Licensed under the Apache License') if (0 < column < 10 and not _check_for_exact_apache(line_number-1, lines)): return (column, ""H103: Header does not match Apache 2.0 "" ""License notice"")"," content = re.sub('\s+', ' ', content) if _project_is_apache() and not line_number > 1 and len(lines) > 10: for idx, line in enumerate(lines): # if it's more than 10 characters in, it's probably not in the # header if (0 < line.find('Licensed under the Apache License') < 10 and not _check_for_exact_apache(idx, lines)): return (idx, ""H103: Header does not match Apache 2.0 "" ""License notice"")",7,9
openstack%2Fhacking~master~Ib27bac23313a62e2c1e01d73e02f3360cdda490f,openstack/hacking,master,Ib27bac23313a62e2c1e01d73e02f3360cdda490f,Make H232 message mention its py3 related,MERGED,2013-07-18 17:41:15.000000000,2013-07-18 21:46:18.000000000,2013-07-18 21:46:18.000000000,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-18 17:41:15.000000000', 'files': ['hacking/core.py'], 'web_link': 'https://opendev.org/openstack/hacking/commit/193d08f69efbd47db9a1d9c84067147bf27ac208', 'message': 'Make H232 message mention its py3 related\n\nSince H323 is a python 3.x compatibility check the message returned to\nthe user should say so.\n\nChange-Id: Ib27bac23313a62e2c1e01d73e02f3360cdda490f\n'}]",0,37730,193d08f69efbd47db9a1d9c84067147bf27ac208,6,2,1,1849,,,0,"Make H232 message mention its py3 related

Since H323 is a python 3.x compatibility check the message returned to
the user should say so.

Change-Id: Ib27bac23313a62e2c1e01d73e02f3360cdda490f
",git fetch https://review.opendev.org/openstack/hacking refs/changes/30/37730/1 && git format-patch -1 --stdout FETCH_HEAD,['hacking/core.py'],1,193d08f69efbd47db9a1d9c84067147bf27ac208,cleanup," yield 0, (""H232: Python 3.x incompatible octal %s should be "" ""written as 0o%s "" %"," yield 0, (""H232: octal %s should be written as 0o%s "" %",2,1
openstack%2Fkeystone~master~I9865a244281def963ab425537f5400f883054319,openstack/keystone,master,I9865a244281def963ab425537f5400f883054319,python3: Introduce py33 to tox.ini,MERGED,2013-06-01 21:51:50.000000000,2013-07-18 21:46:11.000000000,2013-07-18 21:46:11.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 866}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 6482}, {'_account_id': 7191}]","[{'number': 2, 'created': '2013-06-01 21:51:50.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/821435f09c5c2bd39c0724ffb495d8594cb33c08', 'message': 'python3: Introduce py33 to tox.ini\n\nIntroduce py33 to tox.ini to make testing with\npython3 easier.\n\nChange-Id: I9865a244281def963ab425537f5400f883054319\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}, {'number': 1, 'created': '2013-06-01 21:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/573959c42223336d0ba14d1f3db6d731559a81f7', 'message': 'python3: Introduce py33 to tox.ini\n\nIntroduce py33 to tox.ini to make testing with\npython3 easier.\n\nChange-Id: I9865a244281def963ab425537f5400f883054319\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",0,31397,821435f09c5c2bd39c0724ffb495d8594cb33c08,26,8,2,24,,,0,"python3: Introduce py33 to tox.ini

Introduce py33 to tox.ini to make testing with
python3 easier.

Change-Id: I9865a244281def963ab425537f5400f883054319
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/97/31397/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,821435f09c5c2bd39c0724ffb495d8594cb33c08,,"envlist = py26,py27,py33,pep8","envlist = py26,py27,pep8",1,1
openstack%2Fceilometer~master~I1d8198c0c12d99a2ffde11e4321d29723c947178,openstack/ceilometer,master,I1d8198c0c12d99a2ffde11e4321d29723c947178,Avoid dropping cpu_util for multiple instances.,MERGED,2013-07-18 17:11:43.000000000,2013-07-18 21:43:51.000000000,2013-07-18 21:43:51.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 4715}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-18 17:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b2bdeee5bd78f40b173454637899ab0ff8ae89c3', 'message': 'Avoid dropping cpu_util for multiple instances.\n\nWhen multiple instances exist, the ordering of pipleline\nhandle_sample() and flush() calls on the transformer caused\ncpu_util samples for subsequent instances to be dropped.\n\nChange-Id: I1d8198c0c12d99a2ffde11e4321d29723c947178\n'}, {'number': 2, 'created': '2013-07-18 17:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a472b8980b34ffb38df5f616b302a302be8b8236', 'message': 'Avoid dropping cpu_util for multiple instances.\n\nFixes bug 1202756\n\nWhen multiple instances exist, the ordering of pipleline\nhandle_sample() and flush() calls on the transformer caused\ncpu_util samples for subsequent instances to be dropped.\n\nChange-Id: I1d8198c0c12d99a2ffde11e4321d29723c947178\n'}, {'number': 3, 'created': '2013-07-18 17:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6a4abe34d3c697f8b0c0ae77689d3c01439273cd', 'message': 'Avoid dropping cpu_util for multiple instances.\n\nFixes bug 1202756\n\nWhen multiple instances exist, the ordering of pipleline\nhandle_sample() and flush() calls on the transformer caused\ncpu_util samples for subsequent instances to be dropped.\n\nChange-Id: I1d8198c0c12d99a2ffde11e4321d29723c947178\n'}, {'number': 4, 'created': '2013-07-18 17:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/10ff839cdfdf4fe2eba566ca0c14e1f31e25a82a', 'message': 'Avoid dropping cpu_util for multiple instances.\n\nFixes bug 1202756\n\nWhen multiple instances exist, the ordering of pipleline\nhandle_sample() and flush() calls on the transformer caused\ncpu_util samples for subsequent instances to be dropped.\n\nChange-Id: I1d8198c0c12d99a2ffde11e4321d29723c947178\n'}, {'number': 5, 'created': '2013-07-18 19:56:25.000000000', 'files': ['tests/test_pipeline.py', 'ceilometer/transformer/conversions.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/879a4cc03252b2fc51d2efa5d78013a6e1e45994', 'message': 'Avoid dropping cpu_util for multiple instances.\n\nFixes bug 1202756\n\nWhen multiple instances exist, the ordering of pipleline\nhandle_sample() and flush() calls on the transformer caused\ncpu_util samples for subsequent instances to be dropped.\n\nChange-Id: I1d8198c0c12d99a2ffde11e4321d29723c947178\n'}]",0,37724,879a4cc03252b2fc51d2efa5d78013a6e1e45994,17,6,5,2284,,,0,"Avoid dropping cpu_util for multiple instances.

Fixes bug 1202756

When multiple instances exist, the ordering of pipleline
handle_sample() and flush() calls on the transformer caused
cpu_util samples for subsequent instances to be dropped.

Change-Id: I1d8198c0c12d99a2ffde11e4321d29723c947178
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/24/37724/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_pipeline.py', 'ceilometer/transformer/conversions.py']",2,b2bdeee5bd78f40b173454637899ab0ff8ae89c3,, self.preserved = [] self.preserved.append(transformed) counters.append(self.preserved.pop(0)), self.preserved = None self.preserved = transformed counters.append(self.preserved) self.preserved = None,40,8
openstack%2Fneutron~master~I578c1b62115f298c9de32d62161171fd2f3f5b7c,openstack/neutron,master,I578c1b62115f298c9de32d62161171fd2f3f5b7c,Update the ML2 README file with the latest tunnel changes,MERGED,2013-07-18 16:48:32.000000000,2013-07-18 21:37:50.000000000,2013-07-18 21:37:49.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1689}, {'_account_id': 4395}, {'_account_id': 6524}, {'_account_id': 6659}]","[{'number': 1, 'created': '2013-07-18 16:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cdb870d2f1ffcd79233f1e951435adcb8b43f082', 'message': 'Update the ML2 README file with the latest tunnel changes\n\nThe ML2 README file was slightly out of date with all of the H2 changes\nwhich went in around GRE and VXLAN tunneling. This patch updates it to\nreflect what the code is capable of currently.\n\nFixes bug 1202743.\n\nChange-Id: I578c1b62115f298c9de32d62161171fd2f3f5b7c\n'}, {'number': 2, 'created': '2013-07-18 19:11:39.000000000', 'files': ['neutron/plugins/ml2/README'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7fe0de83280e549eb46882e99cffcffbd2fb589b', 'message': 'Update the ML2 README file with the latest tunnel changes\n\nThe ML2 README file was slightly out of date with all of the H2 changes\nwhich went in around GRE and VXLAN tunneling. This patch updates it to\nreflect what the code is capable of currently.\n\nFixes bug 1202743.\n\nChange-Id: I578c1b62115f298c9de32d62161171fd2f3f5b7c\n'}]",4,37719,7fe0de83280e549eb46882e99cffcffbd2fb589b,12,6,2,105,,,0,"Update the ML2 README file with the latest tunnel changes

The ML2 README file was slightly out of date with all of the H2 changes
which went in around GRE and VXLAN tunneling. This patch updates it to
reflect what the code is capable of currently.

Fixes bug 1202743.

Change-Id: I578c1b62115f298c9de32d62161171fd2f3f5b7c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/19/37719/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/README'],1,cdb870d2f1ffcd79233f1e951435adcb8b43f082,bug/1202743,"Each available network type is managed by an ml2 TypeDriver. TypeDrivers maintain any needed type-specific network state, and perform provider network validation and tenant network allocation. The initial ml2 version includes drivers for the local, flat, vlan, gre, and vxlan network types.ML2 supports devstack at the moment with either the Open vSwitch or LinuxBridge L2 agents for local, flat, vlan, or gre network types. Note that ml2 does not yet work with nova's GenericVIFDriver, so it is necessary to configure nova to use a specific driver compatible with the L2 agent deployed on each compute node. Additionally, support for configuring additional ML2 items is a work in progress in devstack. This includes configuring VXLAN support for ML2 with the OVS agent.","Each available network type is managed by an ml2 TypeDriver. TypeDrivers maintain any needed type-specific network state, and perform provider network validation and tenant network allocation. The initial ml2 version includes drivers for the local, flat, and vlan network types. Additional TypeDrivers for gre and vxlan network types are expected before the havana release.A devstack patch supporting use of the ml2 plugin with either the openvswitch or linuxbridge L2 agent for the local, flat and vlan network types is under review at https://review.openstack.org/#/c/27576/. Note that the gre network type and the tunnel-related RPCs are not yet implemented, so use the vlan network type for multi-node testing. Also note that ml2 does not yet work with nova's GenericVIFDriver, so it is necessary to configure nova to use a specific driver compatible with the L2 agent deployed on each compute node.- Implement TypeDriver for GRE networks - Implement GRE tunnel endpoint management RPCs - Implement TypeDriver for VXLAN networks ",12,22
openstack%2Fnova~master~I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf,openstack/nova,master,I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf,Make compute_api.reboot() use objects,MERGED,2013-06-30 22:05:06.000000000,2013-07-18 21:37:32.000000000,2013-07-18 21:37:29.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 7494}]","[{'number': 1, 'created': '2013-06-30 22:05:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca33c4b970b73b9551a9fdbda5ae0e0173d47d3e', 'message': ""WIP Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nNOTE: This breaks some of the cells tests in the same way that\nthe start/stop patch did initially. Will need some help from\ncomstud to resolve.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 2, 'created': '2013-07-01 13:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4a1e3979d3df3d4ae9c7428390fa78409838165', 'message': ""WIP Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nNOTE: This breaks some of the cells tests in the same way that\nthe start/stop patch did initially. Will need some help from\ncomstud to resolve.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 3, 'created': '2013-07-02 15:35:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa683ed5ac46e3d993da9238202d1113e6d9f269', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 4, 'created': '2013-07-02 17:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb23cd006a0049cffbcd1cd4ac3dc667e7b9d91a', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 5, 'created': '2013-07-02 22:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fedc4a7ad8f5c3d178090f11892145f9c9a459db', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 6, 'created': '2013-07-03 00:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a0bcef4dd204eb137ffa3b2301916f4c5231122', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 7, 'created': '2013-07-03 15:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60d575aece4a011c5026e46cb670ec62bac41db1', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 8, 'created': '2013-07-03 17:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea1cf652d9fecee93dbdf9e3568087d3e9656603', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 9, 'created': '2013-07-03 19:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b1492ea4fbe4028c2e0dfecae6a74f4a329f155', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 10, 'created': '2013-07-03 20:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cffad22e5976a43e5fae395abc69470e5566b6f4', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 11, 'created': '2013-07-03 23:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/420efe381ef42a96215771a2e6062fccd5404ef7', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 12, 'created': '2013-07-05 19:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/175285f3bea8cd43a9506f4e463e95e2c8c1b314', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 13, 'created': '2013-07-08 17:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99f493b07fb4d4a88de8b7644c0ddde0836aa150', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 14, 'created': '2013-07-08 17:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f394d36461dc984d43fc6c5fe1ddc426f1cc087c', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 15, 'created': '2013-07-08 17:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/153e8801357c2e40d51bc6856295c95b50c4952a', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 16, 'created': '2013-07-08 17:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f64f1a0acc1471f7308722e42c593d94578bb034', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 17, 'created': '2013-07-09 22:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eac86fa580b35cc0923a8219ec2584e3d3cffbf4', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 18, 'created': '2013-07-10 15:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13760e2c457c3600c8f0d87c95835826343ccc89', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 19, 'created': '2013-07-11 01:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0dd2c2cf0d325ea2f3f003a432e1a5d6beb6db87', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 20, 'created': '2013-07-11 05:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2770e6de8f5f47b27533e4159b914dda036af264', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 21, 'created': '2013-07-11 17:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9174c5b1688cd9d0652174a020276776bce27e4', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nThis also adds a new cells method for passing the object to reboot in\nthe child cell.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 22, 'created': '2013-07-11 19:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4479006a9aec65316f04910518309d578fb3ede', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 23, 'created': '2013-07-11 19:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/beec46f3e8683a0e5dfbaf0ad26b3f2c979aa03f', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nThis also adds a new cells method for passing the object to reboot in\nthe child cell.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 24, 'created': '2013-07-12 01:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d127dc56a2ae3fb5996fb65778a41efc37c2923c', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nThis also adds a new cells method for passing the object to reboot in\nthe child cell.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 25, 'created': '2013-07-12 21:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b936fe51f1ba5583d4d0eeb924f025ad78369ec7', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nThis also adds a new cells method for passing the object to reboot in\nthe child cell.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 26, 'created': '2013-07-17 01:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a03a3f7193f6a4dd140544708da8192747d025af', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nThis also adds a new cells method for passing the object to reboot in\nthe child cell.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 27, 'created': '2013-07-17 16:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/944ebe8df4ac815fccbb863483cef3d3ca5782d6', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nThis also adds a new cells method for passing the object to reboot in\nthe child cell.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 28, 'created': '2013-07-17 23:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35e5c7b0abe7eba2c134a69fab08cc0488a91ebf', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nThis also adds a new cells method for passing the object to reboot in\nthe child cell.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 29, 'created': '2013-07-18 17:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb922c55f28244979d3f3a090cb05cc168e720a2', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nThis also adds a new cells method for passing the object to reboot in\nthe child cell.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}, {'number': 30, 'created': '2013-07-18 18:16:10.000000000', 'files': ['nova/tests/cells/test_cells_rpcapi.py', 'nova/tests/cells/test_cells_messaging.py', 'nova/api/ec2/cloud.py', 'nova/tests/cells/test_cells_manager.py', 'nova/cells/messaging.py', 'nova/tests/compute/test_compute.py', 'nova/tests/compute/test_compute_api.py', 'nova/cells/manager.py', 'nova/compute/cells_api.py', 'nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/cells/rpcapi.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7f0051d4736ae1b464efb6c1edcadbab688bb496', 'message': ""Make compute_api.reboot() use objects\n\nThis makes the compute api's reboot() method use objects and pass\nthem to compute/manager.\n\nThe one place we call back from compute/manager to compute/api's\nreboot() is also converted to use objects in this patch. That\nalmost makes bug 1196301 go away, but will require instance\nactions work as well.\n\nThis also adds a new cells method for passing the object to reboot in\nthe child cell.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf\n""}]",6,35067,7f0051d4736ae1b464efb6c1edcadbab688bb496,96,8,30,4393,,,0,"Make compute_api.reboot() use objects

This makes the compute api's reboot() method use objects and pass
them to compute/manager.

The one place we call back from compute/manager to compute/api's
reboot() is also converted to use objects in this patch. That
almost makes bug 1196301 go away, but will require instance
actions work as well.

This also adds a new cells method for passing the object to reboot in
the child cell.

Related to blueprint compute-api-objects

Change-Id: I7845daa266687b5dc24fc2b1a98f2e5a2841e4bf
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/35067/24 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/ec2/cloud.py', 'nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py']",6,ca33c4b970b73b9551a9fdbda5ae0e0173d47d3e,bp/compute-api-objects," self.mox.StubOutWithMock(db, 'instance_update_and_get_original') db_instance = fake_instance.fake_db_instance( **dict(uuid='fake-instance', power_state=power_state.NOSTATE, vm_state=vm_states.ACTIVE, launched_at=timeutils.utcnow())) instance = instance_obj.Instance._from_db_object( econtext, instance_obj.Instance(), db_instance) updated_dbinstance1 = fake_instance.fake_db_instance( **dict(uuid='updated-instance1', power_state=10003, vm_state=vm_states.ACTIVE, launched_at=timeutils.utcnow())) updated_dbinstance2 = fake_instance.fake_db_instance( **dict(uuid='updated-instance2', power_state=10003, vm_state=vm_states.ACTIVE, launched_at=timeutils.utcnow())) if test_unrescue: instance['vm_state'] = vm_states.RESCUED instance.obj_reset_changes() fake_nw_model = network_model.NetworkInfo() self.mox.StubOutWithMock(fake_nw_model, 'legacy') fake_block_dev_info = 'fake_block_dev_info' fake_power_state1 = 10001 fake_power_state2 = power_state.RUNNING fake_power_state3 = 10002 reboot_type = soft and 'SOFT' or 'HARD' # Beginning of calls we expect. db.instance_update_and_get_original(econtext, instance['uuid'], {'power_state': fake_power_state1} ).AndReturn((None, updated_dbinstance1)) 'args': (econtext, instance, expected_nw_info, instance).AndReturn(fake_power_state2) instance).AndReturn(fake_power_state3) db.instance_update_and_get_original( econtext, updated_dbinstance1['uuid'], {'power_state': new_power_state, 'task_state': None, 'vm_state': vm_states.ACTIVE} ).AndRaise(exception.InstanceNotFound( instance_id=instance['uuid'])) self.compute._notify_about_instance_usage( econtext, instance, 'reboot.end') elif fail_reboot and not fail_running: db.instance_update_and_get_original( econtext, updated_dbinstance1['uuid'], {'vm_state': vm_states.ERROR} ).AndRaise(exception.InstanceNotFound( instance_id=instance['uuid'])) else: db.instance_update_and_get_original( econtext, updated_dbinstance1['uuid'], {'power_state': new_power_state, 'task_state': None, 'vm_state': vm_states.ACTIVE} ).AndReturn((None, updated_dbinstance2)) self.compute._notify_about_instance_usage( econtext, instance, 'reboot.end') inst_obj = instance_obj.Instance.get_by_uuid(self.context, instance['uuid']) non_admin_context, inst_obj, 'SOFT') instance = db.instance_get_by_uuid(self.context, instance_uuid) inst_obj.refresh() non_admin_context, inst_obj, 'SOFT') inst_obj.refresh() self.compute_api.reboot(self.context, inst_obj, 'SOFT') inst = instance_obj.Instance.get_by_uuid(self.context, instance['uuid']) self.assertEqual(inst['task_state'], None) inst.vm_state = vm_state inst.save() self.compute_api.reboot(self.context, inst, reboot_type) inst.refresh() self.assertEqual(inst['task_state'], task_states.REBOOTING) db.instance_destroy(self.context, inst['uuid']) inst = instance_obj.Instance.get_by_uuid(self.context, instance['uuid']) self.assertEqual(inst['task_state'], None) inst.vm_state = vm_state inst.save() self.compute_api.reboot(self.context, inst, reboot_type) inst.refresh() self.assertEqual(inst['task_state'], task_states.REBOOTING_HARD) db.instance_destroy(self.context, inst['uuid']) inst = instance_obj.Instance.get_by_uuid(self.context, instance['uuid']) inst.task_state = task_states.REBOOTING inst.save() self.compute_api.reboot(self.context, inst, reboot_type) inst.refresh() self.assertEqual(inst['task_state'], task_states.REBOOTING_HARD) db.instance_destroy(self.context, inst['uuid']) inst = instance_obj.Instance.get_by_uuid(self.context, instance['uuid']) inst.task_state = task_states.REBOOTING inst.save() inst, inst = instance_obj.Instance.get_by_uuid(self.context, instance['uuid']) inst.vm_state = vm_states.RESCUED inst.save() inst, inst, inst = instance_obj.Instance.get_by_uuid(self.context, instance['uuid']) self.assertEqual(inst['task_state'], None) inst.vm_state = vm_states.ERROR inst.launched_at = None inst.save() inst, inst,"," instance = dict(uuid='fake-instance', power_state='unknown', vm_state=vm_states.ACTIVE, launched_at=timeutils.utcnow()) updated_instance1 = dict(uuid='updated-instance1', power_state='fake', vm_state=vm_states.ACTIVE, launched_at=timeutils.utcnow()) updated_instance2 = dict(uuid='updated-instance2', power_state='fake', vm_state=vm_states.ACTIVE, launched_at=timeutils.utcnow()) if test_unrescue: instance['vm_state'] = vm_states.RESCUED fake_nw_model = network_model.NetworkInfo() self.mox.StubOutWithMock(fake_nw_model, 'legacy') fake_block_dev_info = 'fake_block_dev_info' fake_power_state1 = 'fake_power_state1' fake_power_state2 = power_state.RUNNING fake_power_state3 = 'fake_power_state3' reboot_type = soft and 'SOFT' or 'HARD' # Beginning of calls we expect. self.compute._instance_update(econtext, instance['uuid'], power_state=fake_power_state1).AndReturn(updated_instance1) 'args': (econtext, updated_instance1, expected_nw_info, updated_instance1).AndReturn(fake_power_state2) updated_instance1).AndReturn(fake_power_state3) self.compute._instance_update(econtext, updated_instance1['uuid'], power_state=new_power_state, task_state=None, vm_state=vm_states.ACTIVE).AndRaise( exception.InstanceNotFound( instance_id=updated_instance1['uuid'])) self.compute._notify_about_instance_usage(econtext, updated_instance1, 'reboot.end') elif fail_reboot and not fail_running: self.compute._instance_update(econtext, updated_instance1['uuid'], vm_state=vm_states.ERROR).AndRaise( exception.InstanceNotFound( instance_id=updated_instance1['uuid'])) else: self.compute._instance_update(econtext, updated_instance1['uuid'], power_state=new_power_state, task_state=None, vm_state=vm_states.ACTIVE).AndReturn(updated_instance2) self.compute._notify_about_instance_usage(econtext, updated_instance2, 'reboot.end') instance = db.instance_get_by_uuid(self.context, instance_uuid) non_admin_context, instance, 'SOFT') non_admin_context, instance, 'SOFT') self.compute_api.reboot(self.context, instance, 'SOFT') inst_ref = db.instance_get_by_uuid(self.context, instance['uuid']) self.assertEqual(inst_ref['task_state'], None) db.instance_update(self.context, instance['uuid'], {""vm_state"": vm_state}) self.compute_api.reboot(self.context, inst_ref, reboot_type) inst_ref = db.instance_get_by_uuid(self.context, inst_ref['uuid']) self.assertEqual(inst_ref['task_state'], task_states.REBOOTING) db.instance_destroy(self.context, inst_ref['uuid']) inst_ref = db.instance_get_by_uuid(self.context, instance['uuid']) self.assertEqual(inst_ref['task_state'], None) db.instance_update(self.context, instance['uuid'], {""vm_state"": vm_state}) self.compute_api.reboot(self.context, inst_ref, reboot_type) inst_ref = db.instance_get_by_uuid(self.context, inst_ref['uuid']) self.assertEqual(inst_ref['task_state'], task_states.REBOOTING_HARD) db.instance_destroy(self.context, inst_ref['uuid']) inst_ref = db.instance_get_by_uuid(self.context, instance['uuid']) db.instance_update(self.context, instance['uuid'], {""task_state"": task_states.REBOOTING}) self.compute_api.reboot(self.context, inst_ref, reboot_type) inst_ref = db.instance_get_by_uuid(self.context, inst_ref['uuid']) self.assertEqual(inst_ref['task_state'], task_states.REBOOTING_HARD) db.instance_destroy(self.context, inst_ref['uuid']) inst_ref = db.instance_get_by_uuid(self.context, instance['uuid']) db.instance_update(self.context, instance['uuid'], {""task_state"": task_states.REBOOTING}) inst_ref = db.instance_get_by_uuid(self.context, inst_ref['uuid']) inst_ref, inst_ref = db.instance_get_by_uuid(self.context, instance['uuid']) db.instance_update(self.context, instance['uuid'], {""vm_state"": vm_states.RESCUED}) inst_ref = db.instance_get_by_uuid(self.context, inst_ref['uuid']) inst_ref, inst_ref, inst_ref = db.instance_get_by_uuid(self.context, instance['uuid']) self.assertEqual(inst_ref['task_state'], None) db.instance_update(self.context, instance['uuid'], {""vm_state"": vm_states.ERROR, ""launched_at"": None}) inst_ref = db.instance_get_by_uuid(self.context, inst_ref['uuid']) inst_ref, inst_ref,",146,132
openstack%2Fneutron~master~Iceac6cb82323287bfcd9c9ee8c80519125f63490,openstack/neutron,master,Iceac6cb82323287bfcd9c9ee8c80519125f63490,Imported Translations from Transifex,MERGED,2013-07-18 19:55:10.000000000,2013-07-18 21:05:29.000000000,2013-07-18 21:05:29.000000000,"[{'_account_id': 3}, {'_account_id': 2031}]","[{'number': 1, 'created': '2013-07-18 19:55:10.000000000', 'files': ['neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d300d93d38daf0ae61108ecd8c73556c60cdbcf', 'message': 'Imported Translations from Transifex\n\nChange-Id: Iceac6cb82323287bfcd9c9ee8c80519125f63490\n'}]",0,37756,6d300d93d38daf0ae61108ecd8c73556c60cdbcf,6,2,1,3,,,0,"Imported Translations from Transifex

Change-Id: Iceac6cb82323287bfcd9c9ee8c80519125f63490
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/37756/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po']",20,6d300d93d38daf0ae61108ecd8c73556c60cdbcf,transifex/translations,"""POT-Creation-Date: 2013-07-18 19:54+0000\n""#: neutron/manager.py:70#: neutron/manager.py:82#: neutron/manager.py:111 neutron/plugins/metaplugin/meta_neutron_plugin.py:114#: neutron/manager.py:114 neutron/manager.py:163#: neutron/manager.py:117 neutron/manager.py:166#: neutron/manager.py:118#: neutron/manager.py:136#: neutron/manager.py:145#: neutron/manager.py:158#: neutron/manager.py:167#: neutron/manager.py:174#: neutron/manager.py:180#: neutron/quota.py:31#: neutron/quota.py:35#: neutron/quota.py:39#: neutron/quota.py:43#: neutron/quota.py:47#: neutron/quota.py:51#: neutron/quota.py:225#: neutron/agent/dhcp_agent.py:63 neutron/agent/l3_agent.py:171#: neutron/agent/dhcp_agent.py:528 neutron/agent/l3_agent.py:159#: neutron/agent/dhcp_agent.py:542 neutron/agent/l3_agent.py:202#: neutron/agent/dhcp_agent.py:848 neutron/agent/l3_agent.py:805#: neutron/agent/dhcp_agent.py:854 neutron/agent/l3_agent.py:810#: neutron/agent/dhcp_agent.py:862 neutron/agent/l3_agent.py:815#: neutron/agent/l3_agent.py:156 neutron/debug/debug_agent.py:48#: neutron/agent/l3_agent.py:163#: neutron/agent/l3_agent.py:167#: neutron/agent/l3_agent.py:173#: neutron/agent/l3_agent.py:178#: neutron/agent/l3_agent.py:180#: neutron/agent/l3_agent.py:183#: neutron/agent/l3_agent.py:195#: neutron/agent/l3_agent.py:237#: neutron/agent/l3_agent.py:266#: neutron/agent/l3_agent.py:334#: neutron/agent/l3_agent.py:336 neutron/db/l3_db.py:924#: neutron/agent/l3_agent.py:470#: neutron/agent/l3_agent.py:607#: neutron/agent/l3_agent.py:612#: neutron/agent/l3_agent.py:620#: neutron/agent/l3_agent.py:624#: neutron/agent/l3_agent.py:631#: neutron/agent/l3_agent.py:687 neutron/agent/l3_agent.py:716#: neutron/agent/l3_agent.py:712#: neutron/agent/l3_agent.py:720#: neutron/agent/l3_agent.py:740#: neutron/agent/l3_agent.py:748#: neutron/plugins/nec/extensions/packetfilter.py:48#: neutron/db/agentschedulers_db.py:39 msgid ""Driver to use for scheduling network to DHCP agent"" msgstr """" #: neutron/db/agentschedulers_db.py:42 msgid ""Driver to use for scheduling router to a default L3 agent"" msgstr """" #: neutron/db/agentschedulers_db.py:45 msgid ""Allow auto scheduling networks to DHCP agent."" msgstr """" #: neutron/db/agentschedulers_db.py:47 msgid ""Allow auto scheduling routers to L3 agent."" msgstr """" #: neutron/db/agentschedulers_db.py:49 msgid ""Number of DHCP agents scheduled to host a network."" msgstr """" #: neutron/db/agentschedulers_db.py:422#: neutron/db/db_base_plugin_v2.py:599#: neutron/db/db_base_plugin_v2.py:611#: neutron/db/db_base_plugin_v2.py:617#: neutron/db/db_base_plugin_v2.py:637#: neutron/db/db_base_plugin_v2.py:646 neutron/db/db_base_plugin_v2.py:679#: neutron/db/db_base_plugin_v2.py:694#: neutron/db/db_base_plugin_v2.py:702#: neutron/db/db_base_plugin_v2.py:757#: neutron/db/db_base_plugin_v2.py:762#: neutron/db/db_base_plugin_v2.py:782#: neutron/db/db_base_plugin_v2.py:789#: neutron/db/db_base_plugin_v2.py:796#: neutron/db/db_base_plugin_v2.py:800#: neutron/db/db_base_plugin_v2.py:805#: neutron/db/db_base_plugin_v2.py:818#: neutron/db/db_base_plugin_v2.py:829#: neutron/db/db_base_plugin_v2.py:842 neutron/db/db_base_plugin_v2.py:846#: neutron/db/db_base_plugin_v2.py:968#: neutron/db/db_base_plugin_v2.py:1067#: neutron/db/db_base_plugin_v2.py:1091#: neutron/db/db_base_plugin_v2.py:1104#: neutron/db/db_base_plugin_v2.py:1366#: neutron/db/db_base_plugin_v2.py:1446#: neutron/db/l3_db.py:600 neutron/plugins/nicira/NeutronPlugin.py:1861#: neutron/db/loadbalancer/loadbalancer_db.py:250#: neutron/db/loadbalancer/loadbalancer_db.py:254msgid """" ""Invalid value for ICMP %(field)s (%(attr)s) %(value)s. It must be 0 to "" ""255."" msgstr """" #: neutron/extensions/securitygroup.py:48 #, python-format#: neutron/extensions/securitygroup.py:52#: neutron/extensions/securitygroup.py:56#: neutron/extensions/securitygroup.py:60#: neutron/extensions/securitygroup.py:64#: neutron/extensions/securitygroup.py:70#: neutron/extensions/securitygroup.py:75#: neutron/extensions/securitygroup.py:80#: neutron/extensions/securitygroup.py:84#: neutron/extensions/securitygroup.py:89#: neutron/extensions/securitygroup.py:93#: neutron/extensions/securitygroup.py:97#: neutron/extensions/securitygroup.py:101#: neutron/extensions/securitygroup.py:149#: neutron/extensions/securitygroup.py:226#: neutron/extensions/securitygroup.py:230#: neutron/plugins/brocade/NeutronPlugin.py:123#: neutron/plugins/brocade/NeutronPlugin.py:137 #: neutron/plugins/brocade/NeutronPlugin.py:154#: neutron/plugins/brocade/NeutronPlugin.py:279 #: neutron/plugins/brocade/NeutronPlugin.py:322 #: neutron/plugins/brocade/NeutronPlugin.py:372#: neutron/plugins/brocade/NeutronPlugin.py:280 #: neutron/plugins/brocade/NeutronPlugin.py:323 #: neutron/plugins/brocade/NeutronPlugin.py:373#: neutron/plugins/brocade/NeutronPlugin.py:281#: neutron/plugins/brocade/NeutronPlugin.py:289#: neutron/plugins/linuxbridge/common/config.py:34#: neutron/plugins/openvswitch/common/config.py:51#: neutron/plugins/linuxbridge/common/config.py:46#: neutron/plugins/nec/common/config.py:31 #: neutron/plugins/openvswitch/common/config.py:63#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:733#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:746#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:867#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:643#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:649#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:656#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:665 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:688#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:674#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:680#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:685#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:761#: neutron/plugins/linuxbridge/common/config.py:30#: neutron/plugins/linuxbridge/common/config.py:41#: neutron/plugins/linuxbridge/common/config.py:50#: neutron/plugins/nicira/NeutronPlugin.py:1060#: neutron/plugins/ml2/config.py:22#: neutron/plugins/ml2/config.py:26#: neutron/plugins/ml2/config.py:30#: neutron/plugins/ml2/drivers/type_tunnel.py:95#: neutron/plugins/ml2/rpc.py:87#: neutron/plugins/ml2/rpc.py:96#: neutron/plugins/ml2/rpc.py:102#: neutron/plugins/ml2/rpc.py:122#: neutron/plugins/ml2/rpc.py:130#: neutron/plugins/ml2/rpc.py:139#: neutron/plugins/ml2/rpc.py:153#: neutron/plugins/ml2/rpc.py:161#: neutron/plugins/ml2/drivers/type_gre.py:34 msgid """" ""Comma-separated list of <tun_min>:<tun_max> tuples enumerating ranges of "" ""GRE tunnel IDs that are available for tenant network allocation"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:79 msgid ""provider:physical_network specified for GRE network"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:85 msgid ""segmentation_id required for GRE provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:98 #, python-format msgid ""Reserving specific gre tunnel %s from pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:102 #, python-format msgid ""Reserving specific gre tunnel %s outside pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:115 #, python-format msgid ""Allocating gre tunnel id %(gre_id)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:133 #, python-format msgid ""Releasing gre tunnel %s to pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:138 #, python-format msgid ""Releasing gre tunnel %s outside pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:141 #, python-format msgid ""gre_id %s not found"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:151 #, python-format msgid ""Skipping unreasonable gre ID range %(tun_min)s:%(tun_max)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:169 #: neutron/plugins/ml2/drivers/type_vxlan.py:177 #: neutron/plugins/openvswitch/ovs_db_v2.py:233 #, python-format msgid ""Removing tunnel %s from pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:184 msgid ""get_gre_endpoints() called"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:193 #, python-format msgid ""add_gre_endpoint() called for ip %s"" msgstr """" #: neutron/plugins/ml2/drivers/type_gre.py:199 #, python-format msgid ""Gre endpoint with ip %s already exists"" msgstr """" #: neutron/plugins/ml2/drivers/type_tunnel.py:60 #, python-format msgid ""Invalid tunnel ID range: '%(range)s' - %(e)s. Agent terminated!"" msgstr """" #: neutron/plugins/ml2/drivers/type_tunnel.py:63 #, python-format msgid ""%(type)s ID ranges: %(range)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:37 msgid """" ""Comma-separated list of <vni_min>:<vni_max> tuples enumerating ranges of "" ""VXLAN VNI IDs that are available for tenant network allocation"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:41 msgid ""Multicast group for VXLAN. If unset, disables VXLAN multicast mode."" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:86 msgid ""provider:physical_network specified for VXLAN network"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:92 msgid ""segmentation_id required for VXLAN provider network"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:105 #, python-format msgid ""Reserving specific vxlan tunnel %s from pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:109 #, python-format msgid ""Reserving specific vxlan tunnel %s outside pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:122 #, python-format msgid ""Allocating vxlan tunnel vni %(vxlan_vni)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:140 #, python-format msgid ""Releasing vxlan tunnel %s to pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:145 #, python-format msgid ""Releasing vxlan tunnel %s outside pool"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:148 #, python-format msgid ""vxlan_vni %s not found"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:159 #, python-format msgid ""Skipping unreasonable VXLAN VNI range %(tun_min)s:%(tun_max)s"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:194 msgid ""get_vxlan_endpoints() called"" msgstr """" #: neutron/plugins/ml2/drivers/type_vxlan.py:204 #, python-format msgid ""add_vxlan_endpoint() called for ip %s"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:752#: neutron/plugins/nec/nec_plugin.py:158#: neutron/plugins/nec/nec_plugin.py:162#: neutron/plugins/nec/nec_plugin.py:166#: neutron/plugins/nec/nec_plugin.py:182#: neutron/plugins/nec/nec_plugin.py:188#: neutron/plugins/nec/nec_plugin.py:206#: neutron/plugins/nec/nec_plugin.py:210#: neutron/plugins/nec/nec_plugin.py:229#: neutron/plugins/nec/nec_plugin.py:248#: neutron/plugins/nec/nec_plugin.py:264#: neutron/plugins/nec/nec_plugin.py:304#: neutron/plugins/nec/nec_plugin.py:313#: neutron/plugins/nec/nec_plugin.py:329#: neutron/plugins/nec/nec_plugin.py:342#: neutron/plugins/nec/nec_plugin.py:354#: neutron/plugins/nec/nec_plugin.py:373#: neutron/plugins/nec/nec_plugin.py:399#: neutron/plugins/nec/nec_plugin.py:510#: neutron/plugins/nec/nec_plugin.py:529#: neutron/plugins/nec/nec_plugin.py:534#: neutron/plugins/nec/packet_filter.py:41 msgid ""Disabled packet-filter extension."" msgstr """" #: neutron/plugins/nec/packet_filter.py:46 #, python-format msgid ""create_packet_filter() called, packet_filter=%s ."" msgstr """" #: neutron/plugins/nec/packet_filter.py:59 #, python-format msgid ""update_packet_filter() called, id=%(id)s packet_filter=%(packet_filter)s ."" msgstr """" #: neutron/plugins/nec/packet_filter.py:85 #, python-format msgid ""delete_packet_filter() called, id=%s ."" msgstr """" #: neutron/plugins/nec/packet_filter.py:92 #, python-format msgid ""failed to delete packet_filter id=%s which remains in error status."" msgstr """" #: neutron/plugins/nec/packet_filter.py:106 #, python-format msgid ""activate_packet_filter_if_ready() called, packet_filter=%s."" msgstr """" #: neutron/plugins/nec/packet_filter.py:115 #, python-format msgid """" ""activate_packet_filter_if_ready(): skip pf_id=%s, "" ""packet_filter.admin_state_up is False."" msgstr """" #: neutron/plugins/nec/packet_filter.py:118 #, python-format msgid """" ""activate_packet_filter_if_ready(): skip pf_id=%s, no portinfo for the "" ""in_port."" msgstr """" #: neutron/plugins/nec/packet_filter.py:121 msgid """" ""_activate_packet_filter_if_ready(): skip, ofc_packet_filter already "" ""exists."" msgstr """" #: neutron/plugins/nec/packet_filter.py:124 #, python-format msgid ""activate_packet_filter_if_ready(): create packet_filter id=%s on OFC."" msgstr """" #: neutron/plugins/nec/packet_filter.py:131 #, python-format msgid ""failed to create packet_filter id=%(id)s on OFC: %(exc)s"" msgstr """" #: neutron/plugins/nec/packet_filter.py:144 #, python-format msgid ""deactivate_packet_filter_if_ready() called, packet_filter=%s."" msgstr """" #: neutron/plugins/nec/packet_filter.py:151 #, python-format msgid ""deactivate_packet_filter(): deleting packet_filter id=%s from OFC."" msgstr """" #: neutron/plugins/nec/packet_filter.py:157 #, python-format msgid ""failed to delete packet_filter id=%(id)s from OFC: %(exc)s"" msgstr """" #: neutron/plugins/nec/packet_filter.py:161 #, python-format msgid """" ""deactivate_packet_filter(): skip, Not found OFC Mapping for packet_filter"" "" id=%s."" msgstr """" #: neutron/plugins/nec/common/config.py:26 #: neutron/plugins/openvswitch/common/config.py:30#: neutron/plugins/nec/common/config.py:37#: neutron/plugins/nec/common/config.py:39#: neutron/plugins/nec/common/config.py:41#: neutron/plugins/nec/common/config.py:43#: neutron/plugins/nec/common/config.py:45#: neutron/plugins/nec/common/config.py:47#: neutron/plugins/nec/common/config.py:49#: neutron/plugins/nec/db/packetfilter.py:34 #, python-format msgid ""PacketFilter %(id)s could not be found"" msgstr """" #: neutron/plugins/nec/extensions/packetfilter.py:34#: neutron/plugins/nicira/NeutronPlugin.py:236#: neutron/plugins/nicira/NeutronPlugin.py:271#: neutron/plugins/nicira/NeutronPlugin.py:273#: neutron/plugins/nicira/NeutronPlugin.py:276#: neutron/plugins/nicira/NeutronPlugin.py:351#: neutron/plugins/nicira/NeutronPlugin.py:357#: neutron/plugins/nicira/NeutronPlugin.py:363#: neutron/plugins/nicira/NeutronPlugin.py:408#: neutron/plugins/nicira/NeutronPlugin.py:434 #: neutron/plugins/nicira/NeutronPlugin.py:469 #: neutron/plugins/nicira/NeutronPlugin.py:637#: neutron/plugins/nicira/NeutronPlugin.py:454 #: neutron/plugins/nicira/NeutronPlugin.py:534 #: neutron/plugins/nicira/NeutronPlugin.py:656#: neutron/plugins/nicira/NeutronPlugin.py:458#: neutron/plugins/nicira/NeutronPlugin.py:476#: neutron/plugins/nicira/NeutronPlugin.py:485#: neutron/plugins/nicira/NeutronPlugin.py:491#: neutron/plugins/nicira/NeutronPlugin.py:510 #: neutron/plugins/nicira/NeutronPlugin.py:912#: neutron/plugins/nicira/NeutronPlugin.py:522#: neutron/plugins/nicira/NeutronPlugin.py:541#: neutron/plugins/nicira/NeutronPlugin.py:549#: neutron/plugins/nicira/NeutronPlugin.py:586#: neutron/plugins/nicira/NeutronPlugin.py:618#: neutron/plugins/nicira/NeutronPlugin.py:622 #: neutron/plugins/nicira/NeutronPlugin.py:1806#: neutron/plugins/nicira/NeutronPlugin.py:624#: neutron/plugins/nicira/NeutronPlugin.py:694#: neutron/plugins/nicira/NeutronPlugin.py:723#: neutron/plugins/nicira/NeutronPlugin.py:727#: neutron/plugins/nicira/NeutronPlugin.py:731#: neutron/plugins/nicira/NeutronPlugin.py:735 #: neutron/plugins/nicira/NeutronPlugin.py:750#: neutron/plugins/nicira/NeutronPlugin.py:756#: neutron/plugins/nicira/NeutronPlugin.py:787#: neutron/plugins/nicira/NeutronPlugin.py:809#: neutron/plugins/nicira/NeutronPlugin.py:836#: neutron/plugins/nicira/NeutronPlugin.py:894#: neutron/plugins/nicira/NeutronPlugin.py:922#: neutron/plugins/nicira/NeutronPlugin.py:925#: neutron/plugins/nicira/NeutronPlugin.py:951#: neutron/plugins/nicira/NeutronPlugin.py:961 #: neutron/plugins/nicira/NeutronPlugin.py:1009#: neutron/plugins/nicira/NeutronPlugin.py:1023#: neutron/plugins/nicira/NeutronPlugin.py:1038#: neutron/plugins/nicira/NeutronPlugin.py:1042#: neutron/plugins/nicira/NeutronPlugin.py:1128#: neutron/plugins/nicira/NeutronPlugin.py:1137#: neutron/plugins/nicira/NeutronPlugin.py:1164#: neutron/plugins/nicira/NeutronPlugin.py:1171#: neutron/plugins/nicira/NeutronPlugin.py:1237#: neutron/plugins/nicira/NeutronPlugin.py:1245#: neutron/plugins/nicira/NeutronPlugin.py:1249#: neutron/plugins/nicira/NeutronPlugin.py:1324#: neutron/plugins/nicira/NeutronPlugin.py:1350#: neutron/plugins/nicira/NeutronPlugin.py:1474 #: neutron/plugins/nicira/NeutronPlugin.py:1518#: neutron/plugins/nicira/NeutronPlugin.py:1487#: neutron/plugins/nicira/NeutronPlugin.py:1527#: neutron/plugins/nicira/NeutronPlugin.py:1543#: neutron/plugins/nicira/NeutronPlugin.py:1547#: neutron/plugins/nicira/NeutronPlugin.py:1549#: neutron/plugins/nicira/NeutronPlugin.py:1582#: neutron/plugins/nicira/NeutronPlugin.py:1586#: neutron/plugins/nicira/NeutronPlugin.py:1606#: neutron/plugins/nicira/NeutronPlugin.py:1633#: neutron/plugins/nicira/NeutronPlugin.py:1655#: neutron/plugins/nicira/NeutronPlugin.py:1681#: neutron/plugins/nicira/NeutronPlugin.py:1716#: neutron/plugins/nicira/NeutronPlugin.py:1761#: neutron/plugins/nicira/NeutronPlugin.py:1773#: neutron/plugins/nicira/NeutronPlugin.py:1802#: neutron/plugins/nicira/NeutronPlugin.py:1828#: neutron/plugins/nicira/NeutronPlugin.py:1834#: neutron/plugins/nicira/NeutronPlugin.py:1900#: neutron/plugins/nicira/NeutronPlugin.py:1924#: neutron/plugins/nicira/NeutronPlugin.py:1967#: neutron/plugins/nicira/NeutronPlugin.py:1970#: neutron/plugins/nicira/NeutronPlugin.py:1996#: neutron/plugins/nicira/NeutronPlugin.py:2018#: neutron/plugins/nicira/common/config.py:21#: neutron/plugins/nicira/common/config.py:24#: neutron/plugins/nicira/common/config.py:27#: neutron/plugins/nicira/common/config.py:29#: neutron/plugins/nicira/common/config.py:32#: neutron/plugins/nicira/common/config.py:40#: neutron/plugins/nicira/common/config.py:43#: neutron/plugins/nicira/common/config.py:50#: neutron/plugins/nicira/common/config.py:54#: neutron/plugins/nicira/common/config.py:57#: neutron/plugins/nicira/common/config.py:60#: neutron/plugins/nicira/common/config.py:63#: neutron/plugins/nicira/common/config.py:66#: neutron/plugins/nicira/common/config.py:68#: neutron/plugins/nicira/common/config.py:73#: neutron/plugins/nicira/common/config.py:78#: neutron/plugins/nicira/common/config.py:82#: neutron/plugins/nicira/common/config.py:86#: neutron/plugins/nicira/common/config.py:89#: neutron/plugins/nicira/common/config.py:102#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:297#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:300#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:328#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:331#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:353#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:372#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:392#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:401#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:413#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:447#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:498#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:511#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:556#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:577#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:583#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:637#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:719#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:739#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:771#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:779#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:790#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:797#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:802#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:817#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:836#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:839#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:855#: neutron/plugins/openvswitch/common/config.py:32#: neutron/plugins/openvswitch/common/config.py:34#: neutron/plugins/openvswitch/common/config.py:36#: neutron/plugins/openvswitch/common/config.py:39#: neutron/plugins/openvswitch/common/config.py:42#: neutron/plugins/openvswitch/common/config.py:45#: neutron/plugins/openvswitch/common/config.py:47#: neutron/plugins/openvswitch/common/config.py:55#: neutron/plugins/openvswitch/common/config.py:57#: neutron/plugins/openvswitch/common/config.py:66#: neutron/plugins/openvswitch/common/config.py:69#: neutron/scheduler/l3_agent_scheduler.py:57#: neutron/scheduler/l3_agent_scheduler.py:62#: neutron/scheduler/l3_agent_scheduler.py:70 #: neutron/scheduler/l3_agent_scheduler.py:128#: neutron/scheduler/l3_agent_scheduler.py:89#: neutron/scheduler/l3_agent_scheduler.py:103#: neutron/scheduler/l3_agent_scheduler.py:137#: neutron/scheduler/l3_agent_scheduler.py:142#: neutron/scheduler/l3_agent_scheduler.py:151#: neutron/services/loadbalancer/plugin.py:35#: neutron/services/loadbalancer/plugin.py:68#~ msgid """" #~ ""_activate_packet_filter_if_ready(): skip, "" #~ ""packet_filter.admin_state_up is False.""#~ msgid """" #~ ""_activate_packet_filter_if_ready(): skip, "" #~ ""network.admin_state_up is False."" #~ msgstr """" #~ msgid ""_activate_packet_filter_if_ready(): skip, invalid in_port_id."" #~ msgstr """" #~ msgid ""_activate_packet_filter_if_ready(): skip, no portinfo for in_port."" #~ msgstr """" #~ msgid ""create_ofc_packet_filter() failed due to %s"" #~ msgstr """" #~ msgid ""_deactivate_packet_filter(): skip, ofc_packet_filter does not exist."" #~ msgstr """" #~ msgid ""delete_ofc_packet_filter() failed due to %s"" #~ msgstr """" #~ msgid ""NECPluginV2.create_packet_filter() called, packet_filter=%s ."" #~ msgstr """" #~ msgid """" #~ ""NECPluginV2.update_packet_filter() called, id=%(id)s "" #~ ""packet_filter=%(packet_filter)s ."" #~ msgstr """" #~ msgid ""NECPluginV2.delete_packet_filter() called, id=%s ."" #~ msgstr """" #~ msgid ""No tunnel_type specified, cannot add tunnel port""","""POT-Creation-Date: 2013-07-16 19:58+0000\n""#: neutron/manager.py:69#: neutron/manager.py:81#: neutron/manager.py:110 neutron/plugins/metaplugin/meta_neutron_plugin.py:114#: neutron/manager.py:113 neutron/manager.py:161#: neutron/manager.py:116 neutron/manager.py:164#: neutron/manager.py:117#: neutron/manager.py:134#: neutron/manager.py:143#: neutron/manager.py:156#: neutron/manager.py:165#: neutron/manager.py:172#: neutron/manager.py:178#: neutron/quota.py:30#: neutron/quota.py:34#: neutron/quota.py:38#: neutron/quota.py:42#: neutron/quota.py:46#: neutron/quota.py:50#: neutron/quota.py:223#: neutron/agent/dhcp_agent.py:63 neutron/agent/l3_agent.py:172#: neutron/agent/dhcp_agent.py:528 neutron/agent/l3_agent.py:160#: neutron/agent/dhcp_agent.py:542 neutron/agent/l3_agent.py:203#: neutron/agent/dhcp_agent.py:848 neutron/agent/l3_agent.py:806#: neutron/agent/dhcp_agent.py:854 neutron/agent/l3_agent.py:811#: neutron/agent/dhcp_agent.py:862 neutron/agent/l3_agent.py:816#: neutron/agent/l3_agent.py:157 neutron/debug/debug_agent.py:48#: neutron/agent/l3_agent.py:164#: neutron/agent/l3_agent.py:168#: neutron/agent/l3_agent.py:174#: neutron/agent/l3_agent.py:179#: neutron/agent/l3_agent.py:181#: neutron/agent/l3_agent.py:184#: neutron/agent/l3_agent.py:196#: neutron/agent/l3_agent.py:238#: neutron/agent/l3_agent.py:267#: neutron/agent/l3_agent.py:335#: neutron/agent/l3_agent.py:337 neutron/db/l3_db.py:924#: neutron/agent/l3_agent.py:471#: neutron/agent/l3_agent.py:608#: neutron/agent/l3_agent.py:613#: neutron/agent/l3_agent.py:621#: neutron/agent/l3_agent.py:625#: neutron/agent/l3_agent.py:632#: neutron/agent/l3_agent.py:688 neutron/agent/l3_agent.py:717#: neutron/agent/l3_agent.py:713#: neutron/agent/l3_agent.py:721#: neutron/agent/l3_agent.py:741#: neutron/agent/l3_agent.py:749#: neutron/db/agentschedulers_db.py:399#: neutron/db/db_base_plugin_v2.py:600#: neutron/db/db_base_plugin_v2.py:612#: neutron/db/db_base_plugin_v2.py:618#: neutron/db/db_base_plugin_v2.py:638#: neutron/db/db_base_plugin_v2.py:647 neutron/db/db_base_plugin_v2.py:680#: neutron/db/db_base_plugin_v2.py:695#: neutron/db/db_base_plugin_v2.py:703#: neutron/db/db_base_plugin_v2.py:758#: neutron/db/db_base_plugin_v2.py:763#: neutron/db/db_base_plugin_v2.py:783#: neutron/db/db_base_plugin_v2.py:790#: neutron/db/db_base_plugin_v2.py:797#: neutron/db/db_base_plugin_v2.py:801#: neutron/db/db_base_plugin_v2.py:806#: neutron/db/db_base_plugin_v2.py:819#: neutron/db/db_base_plugin_v2.py:830#: neutron/db/db_base_plugin_v2.py:843 neutron/db/db_base_plugin_v2.py:847#: neutron/db/db_base_plugin_v2.py:969#: neutron/db/db_base_plugin_v2.py:1068#: neutron/db/db_base_plugin_v2.py:1092#: neutron/db/db_base_plugin_v2.py:1105#: neutron/db/db_base_plugin_v2.py:1367#: neutron/db/db_base_plugin_v2.py:1447#: neutron/db/l3_db.py:600 neutron/plugins/nicira/NeutronPlugin.py:1821#: neutron/db/loadbalancer/loadbalancer_db.py:243#: neutron/db/loadbalancer/loadbalancer_db.py:247#: neutron/extensions/securitygroup.py:47#: neutron/extensions/securitygroup.py:51#: neutron/extensions/securitygroup.py:55#: neutron/extensions/securitygroup.py:59#: neutron/extensions/securitygroup.py:65#: neutron/extensions/securitygroup.py:70#: neutron/extensions/securitygroup.py:75#: neutron/extensions/securitygroup.py:79#: neutron/extensions/securitygroup.py:84#: neutron/extensions/securitygroup.py:88#: neutron/extensions/securitygroup.py:92#: neutron/extensions/securitygroup.py:96#: neutron/extensions/securitygroup.py:144#: neutron/extensions/securitygroup.py:221#: neutron/extensions/securitygroup.py:225#: neutron/plugins/brocade/NeutronPlugin.py:125#: neutron/plugins/brocade/NeutronPlugin.py:139 #: neutron/plugins/brocade/NeutronPlugin.py:156#: neutron/plugins/brocade/NeutronPlugin.py:281 #: neutron/plugins/brocade/NeutronPlugin.py:324 #: neutron/plugins/brocade/NeutronPlugin.py:374#: neutron/plugins/brocade/NeutronPlugin.py:282 #: neutron/plugins/brocade/NeutronPlugin.py:325 #: neutron/plugins/brocade/NeutronPlugin.py:375#: neutron/plugins/brocade/NeutronPlugin.py:283#: neutron/plugins/brocade/NeutronPlugin.py:291#: neutron/plugins/linuxbridge/common/config.py:35#: neutron/plugins/openvswitch/common/config.py:52#: neutron/plugins/linuxbridge/common/config.py:47#: neutron/plugins/nec/common/config.py:32 #: neutron/plugins/openvswitch/common/config.py:64#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:731#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:744#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:865#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:641#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:647#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:654#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:663 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:686#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:672#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:678#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:683#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:759#: neutron/plugins/linuxbridge/common/config.py:31#: neutron/plugins/linuxbridge/common/config.py:42#: neutron/plugins/linuxbridge/common/config.py:51#: neutron/plugins/nicira/NeutronPlugin.py:1020#: neutron/plugins/ml2/config.py:24#: neutron/plugins/ml2/config.py:28#: neutron/plugins/ml2/config.py:32#: neutron/plugins/ml2/rpc.py:79#: neutron/plugins/ml2/rpc.py:88#: neutron/plugins/ml2/rpc.py:94#: neutron/plugins/ml2/rpc.py:114#: neutron/plugins/ml2/rpc.py:122#: neutron/plugins/ml2/rpc.py:131#: neutron/plugins/ml2/rpc.py:145#: neutron/plugins/ml2/rpc.py:153#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:750#: neutron/plugins/nec/nec_plugin.py:159#: neutron/plugins/nec/nec_plugin.py:163#: neutron/plugins/nec/nec_plugin.py:167#: neutron/plugins/nec/nec_plugin.py:186#: neutron/plugins/nec/nec_plugin.py:192#: neutron/plugins/nec/nec_plugin.py:210#: neutron/plugins/nec/nec_plugin.py:214#: neutron/plugins/nec/nec_plugin.py:234#: neutron/plugins/nec/nec_plugin.py:253#: neutron/plugins/nec/nec_plugin.py:269#: neutron/plugins/nec/nec_plugin.py:319#: neutron/plugins/nec/nec_plugin.py:328#: neutron/plugins/nec/nec_plugin.py:343#: neutron/plugins/nec/nec_plugin.py:361#: neutron/plugins/nec/nec_plugin.py:373#: neutron/plugins/nec/nec_plugin.py:392#: neutron/plugins/nec/nec_plugin.py:418msgid """" ""_activate_packet_filter_if_ready(): skip, packet_filter.admin_state_up is"" "" False."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:483 msgid ""_activate_packet_filter_if_ready(): skip, network.admin_state_up is False."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:487 msgid ""_activate_packet_filter_if_ready(): skip, invalid in_port_id."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:491 msgid ""_activate_packet_filter_if_ready(): skip, no portinfo for in_port."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:497 msgid """" ""_activate_packet_filter_if_ready(): skip, ofc_packet_filter already "" ""exists."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:506 #, python-format msgid ""create_ofc_packet_filter() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:519 msgid ""_deactivate_packet_filter(): skip, ofc_packet_filter does not exist."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:525 #, python-format msgid ""delete_ofc_packet_filter() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:536 #, python-format msgid ""NECPluginV2.create_packet_filter() called, packet_filter=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:552 #, python-format msgid """" ""NECPluginV2.update_packet_filter() called, id=%(id)s "" ""packet_filter=%(packet_filter)s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:576 #, python-format msgid ""NECPluginV2.delete_packet_filter() called, id=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:622#: neutron/plugins/nec/nec_plugin.py:653#: neutron/plugins/nec/nec_plugin.py:672#: neutron/plugins/nec/nec_plugin.py:677#: neutron/plugins/nec/common/config.py:27 #: neutron/plugins/openvswitch/common/config.py:31#: neutron/plugins/nec/common/config.py:38#: neutron/plugins/nec/common/config.py:40#: neutron/plugins/nec/common/config.py:42#: neutron/plugins/nec/common/config.py:44#: neutron/plugins/nec/common/config.py:46#: neutron/plugins/nec/common/config.py:48#: neutron/plugins/nec/common/config.py:50#: neutron/plugins/nec/common/exceptions.py:39 #, python-format msgid ""PacketFilter %(id)s could not be found"" msgstr """" #: neutron/plugins/nec/extensions/packetfilter.py:33#: neutron/plugins/nicira/NeutronPlugin.py:232#: neutron/plugins/nicira/NeutronPlugin.py:267#: neutron/plugins/nicira/NeutronPlugin.py:269#: neutron/plugins/nicira/NeutronPlugin.py:272#: neutron/plugins/nicira/NeutronPlugin.py:295#: neutron/plugins/nicira/NeutronPlugin.py:301#: neutron/plugins/nicira/NeutronPlugin.py:307#: neutron/plugins/nicira/NeutronPlugin.py:352#: neutron/plugins/nicira/NeutronPlugin.py:378 #: neutron/plugins/nicira/NeutronPlugin.py:413 #: neutron/plugins/nicira/NeutronPlugin.py:597#: neutron/plugins/nicira/NeutronPlugin.py:398 #: neutron/plugins/nicira/NeutronPlugin.py:478 #: neutron/plugins/nicira/NeutronPlugin.py:616#: neutron/plugins/nicira/NeutronPlugin.py:402#: neutron/plugins/nicira/NeutronPlugin.py:420#: neutron/plugins/nicira/NeutronPlugin.py:429#: neutron/plugins/nicira/NeutronPlugin.py:435#: neutron/plugins/nicira/NeutronPlugin.py:454 #: neutron/plugins/nicira/NeutronPlugin.py:872#: neutron/plugins/nicira/NeutronPlugin.py:466#: neutron/plugins/nicira/NeutronPlugin.py:485#: neutron/plugins/nicira/NeutronPlugin.py:493#: neutron/plugins/nicira/NeutronPlugin.py:539#: neutron/plugins/nicira/NeutronPlugin.py:578#: neutron/plugins/nicira/NeutronPlugin.py:582 #: neutron/plugins/nicira/NeutronPlugin.py:1766#: neutron/plugins/nicira/NeutronPlugin.py:584#: neutron/plugins/nicira/NeutronPlugin.py:654#: neutron/plugins/nicira/NeutronPlugin.py:683#: neutron/plugins/nicira/NeutronPlugin.py:687#: neutron/plugins/nicira/NeutronPlugin.py:691#: neutron/plugins/nicira/NeutronPlugin.py:695 #: neutron/plugins/nicira/NeutronPlugin.py:710#: neutron/plugins/nicira/NeutronPlugin.py:716#: neutron/plugins/nicira/NeutronPlugin.py:747#: neutron/plugins/nicira/NeutronPlugin.py:769#: neutron/plugins/nicira/NeutronPlugin.py:796#: neutron/plugins/nicira/NeutronPlugin.py:854#: neutron/plugins/nicira/NeutronPlugin.py:882#: neutron/plugins/nicira/NeutronPlugin.py:885#: neutron/plugins/nicira/NeutronPlugin.py:911#: neutron/plugins/nicira/NeutronPlugin.py:921 #: neutron/plugins/nicira/NeutronPlugin.py:969#: neutron/plugins/nicira/NeutronPlugin.py:983#: neutron/plugins/nicira/NeutronPlugin.py:998#: neutron/plugins/nicira/NeutronPlugin.py:1002#: neutron/plugins/nicira/NeutronPlugin.py:1088#: neutron/plugins/nicira/NeutronPlugin.py:1097#: neutron/plugins/nicira/NeutronPlugin.py:1124#: neutron/plugins/nicira/NeutronPlugin.py:1131#: neutron/plugins/nicira/NeutronPlugin.py:1197#: neutron/plugins/nicira/NeutronPlugin.py:1205#: neutron/plugins/nicira/NeutronPlugin.py:1209#: neutron/plugins/nicira/NeutronPlugin.py:1284#: neutron/plugins/nicira/NeutronPlugin.py:1310#: neutron/plugins/nicira/NeutronPlugin.py:1434 #: neutron/plugins/nicira/NeutronPlugin.py:1478#: neutron/plugins/nicira/NeutronPlugin.py:1447#: neutron/plugins/nicira/NeutronPlugin.py:1487#: neutron/plugins/nicira/NeutronPlugin.py:1503#: neutron/plugins/nicira/NeutronPlugin.py:1507#: neutron/plugins/nicira/NeutronPlugin.py:1509#: neutron/plugins/nicira/NeutronPlugin.py:1542#: neutron/plugins/nicira/NeutronPlugin.py:1546#: neutron/plugins/nicira/NeutronPlugin.py:1566#: neutron/plugins/nicira/NeutronPlugin.py:1593#: neutron/plugins/nicira/NeutronPlugin.py:1615#: neutron/plugins/nicira/NeutronPlugin.py:1641#: neutron/plugins/nicira/NeutronPlugin.py:1676#: neutron/plugins/nicira/NeutronPlugin.py:1721#: neutron/plugins/nicira/NeutronPlugin.py:1733#: neutron/plugins/nicira/NeutronPlugin.py:1762#: neutron/plugins/nicira/NeutronPlugin.py:1788#: neutron/plugins/nicira/NeutronPlugin.py:1794#: neutron/plugins/nicira/NeutronPlugin.py:1860#: neutron/plugins/nicira/NeutronPlugin.py:1884#: neutron/plugins/nicira/NeutronPlugin.py:1927#: neutron/plugins/nicira/NeutronPlugin.py:1930#: neutron/plugins/nicira/NeutronPlugin.py:1956#: neutron/plugins/nicira/NeutronPlugin.py:1978#: neutron/plugins/nicira/common/config.py:23#: neutron/plugins/nicira/common/config.py:26#: neutron/plugins/nicira/common/config.py:29#: neutron/plugins/nicira/common/config.py:31#: neutron/plugins/nicira/common/config.py:34#: neutron/plugins/nicira/common/config.py:42#: neutron/plugins/nicira/common/config.py:45#: neutron/plugins/nicira/common/config.py:52#: neutron/plugins/nicira/common/config.py:56#: neutron/plugins/nicira/common/config.py:59#: neutron/plugins/nicira/common/config.py:62#: neutron/plugins/nicira/common/config.py:65#: neutron/plugins/nicira/common/config.py:68#: neutron/plugins/nicira/common/config.py:70#: neutron/plugins/nicira/common/config.py:75#: neutron/plugins/nicira/common/config.py:80#: neutron/plugins/nicira/common/config.py:84#: neutron/plugins/nicira/common/config.py:88#: neutron/plugins/nicira/common/config.py:91#: neutron/plugins/nicira/common/config.py:105#: neutron/plugins/openvswitch/ovs_db_v2.py:233 #, python-format msgid ""Removing tunnel %s from pool"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:295#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:298#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:326#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:329#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:351#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:370#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:390#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:399#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:411#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:445#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:496#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:509#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:554#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:575#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:581#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:635#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:709 msgid ""No tunnel_type specified, cannot add tunnel port"" msgstr """" #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:717#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:737#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:769#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:777#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:788#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:795#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:800#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:815#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:834#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:837#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:853#: neutron/plugins/openvswitch/common/config.py:33#: neutron/plugins/openvswitch/common/config.py:35#: neutron/plugins/openvswitch/common/config.py:37#: neutron/plugins/openvswitch/common/config.py:40#: neutron/plugins/openvswitch/common/config.py:43#: neutron/plugins/openvswitch/common/config.py:46#: neutron/plugins/openvswitch/common/config.py:48#: neutron/plugins/openvswitch/common/config.py:56#: neutron/plugins/openvswitch/common/config.py:58#: neutron/plugins/openvswitch/common/config.py:67#: neutron/plugins/openvswitch/common/config.py:70#: neutron/scheduler/__init__.py:25 msgid ""Driver to use for scheduling network to DHCP agent"" msgstr """" #: neutron/scheduler/__init__.py:28 msgid ""Driver to use for scheduling router to a default L3 agent"" msgstr """" #: neutron/scheduler/__init__.py:31 msgid ""Allow auto scheduling networks to DHCP agent."" msgstr """" #: neutron/scheduler/__init__.py:33 msgid ""Allow auto scheduling routers to L3 agent."" msgstr """" #: neutron/scheduler/__init__.py:35 msgid ""Number of DHCP agents scheduled to host a network."" msgstr """" #: neutron/scheduler/l3_agent_scheduler.py:56#: neutron/scheduler/l3_agent_scheduler.py:61#: neutron/scheduler/l3_agent_scheduler.py:67 #: neutron/scheduler/l3_agent_scheduler.py:124#: neutron/scheduler/l3_agent_scheduler.py:85#: neutron/scheduler/l3_agent_scheduler.py:99#: neutron/scheduler/l3_agent_scheduler.py:133#: neutron/scheduler/l3_agent_scheduler.py:138#: neutron/scheduler/l3_agent_scheduler.py:147#: neutron/services/loadbalancer/plugin.py:34#: neutron/services/loadbalancer/plugin.py:66#~ msgid ""Failed dealing with router '%s' deletion RPC message""#~ msgid ""Failed dealing with routers update RPC message""",12128,8141
openstack%2Fnova~master~I62e2967e1ef2e85ec653d75d3b3a90aeb9331400,openstack/nova,master,I62e2967e1ef2e85ec653d75d3b3a90aeb9331400,Enhance VMware Hyper instance disk usage.,ABANDONED,2013-06-17 10:11:17.000000000,2013-07-18 21:00:10.000000000,,"[{'_account_id': 3}, {'_account_id': 1313}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4395}, {'_account_id': 7629}]","[{'number': 1, 'created': '2013-06-17 10:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fd1a80e29ffd01cc59c48845f340bb46ef33a0f', 'message': 'Ehance VMware Hyper instance disk usage.\n\nExtend the root disk to instance flavor specific size.\nPartly implement blueprint improve-vmware-disk-usage\n\nChange-Id: I62e2967e1ef2e85ec653d75d3b3a90aeb9331400\n'}, {'number': 2, 'created': '2013-06-18 07:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d8f65b1fc3b796e1e1ab4a3ebe2ecc55793edcfe', 'message': 'Ehance VMware Hyper instance disk usage.\n\nExtend the root disk to instance flavor specific size.\nPartly implement blueprint improve-vmware-disk-usage\n\nChange-Id: I62e2967e1ef2e85ec653d75d3b3a90aeb9331400\n'}, {'number': 3, 'created': '2013-06-18 08:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c30e331a09a03e603f15f4a777d8b4d28ce10f23', 'message': 'Ehance VMware Hyper instance disk usage.\n\nExtend the root disk to instance flavor specific size.\nPartly implement blueprint improve-vmware-disk-usage\n\nChange-Id: I62e2967e1ef2e85ec653d75d3b3a90aeb9331400\n'}, {'number': 4, 'created': '2013-06-27 08:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/496deb331e9c615628c969d032b15cd8b5b3f831', 'message': 'Ehance VMware Hyper instance disk usage.\n\nExtend the root disk to instance flavor specific size.\nPartly implement blueprint improve-vmware-disk-usage\n\nChange-Id: I62e2967e1ef2e85ec653d75d3b3a90aeb9331400\n'}, {'number': 5, 'created': '2013-06-28 10:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6bd93e7f8d7c34977076184d060fcace5007e37', 'message': 'Ehance VMware Hyper instance disk usage.\n\nWhen build a instance, extend the root disk to instance flavor\nspecific size and add support for ephemeral disk.\n\nImplement blueprint improve-vmware-disk-usage\n\nChange-Id: I62e2967e1ef2e85ec653d75d3b3a90aeb9331400\n'}, {'number': 6, 'created': '2013-06-28 13:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad4c6ba4a1c9a670c3d7c80d4734c2c6c0751e82', 'message': 'Ehance VMware Hyper instance disk usage.\n\nWhen build a instance, extend the root disk to instance flavor\nspecific size and add support for ephemeral disk.\n\nImplement blueprint improve-vmware-disk-usage\n\nChange-Id: I62e2967e1ef2e85ec653d75d3b3a90aeb9331400\n'}, {'number': 7, 'created': '2013-07-10 12:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb813d6cb7999e75a34f721d1c542f55e4ce33fb', 'message': 'Enhance VMware Hyper instance disk usage.\n\nWhen build a instance, extend the root disk to instance flavor\nspecific size and add support for ephemeral disk.\n\nImplement blueprint improve-vmware-disk-usage\n\nChange-Id: I62e2967e1ef2e85ec653d75d3b3a90aeb9331400\n'}, {'number': 8, 'created': '2013-07-10 16:07:05.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/db_fakes.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/virt/vmwareapi/disk_util.py', 'nova/virt/vmwareapi/fake.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e61dd009deb2cfbc17bed990a24db8c80f84fb5c', 'message': 'Enhance VMware Hyper instance disk usage.\n\nWhen build a instance, extend the root disk to instance flavor\nspecific size and add support for ephemeral disk.\n\nImplement blueprint improve-vmware-disk-usage\n\nChange-Id: I62e2967e1ef2e85ec653d75d3b3a90aeb9331400\n'}]",3,33238,e61dd009deb2cfbc17bed990a24db8c80f84fb5c,34,6,8,1313,,,0,"Enhance VMware Hyper instance disk usage.

When build a instance, extend the root disk to instance flavor
specific size and add support for ephemeral disk.

Implement blueprint improve-vmware-disk-usage

Change-Id: I62e2967e1ef2e85ec653d75d3b3a90aeb9331400
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/33238/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/virt/vmwareapi/disk_util.py']",2,0fd1a80e29ffd01cc59c48845f340bb46ef33a0f,bp/improve-vmware-disk-usage,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (c) 2013 Canonical. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" The VMware API disk operation utility methods. """""" def extend_disk(session, name, dc_ref, size, eagerZero=False): """"""Extend disk size to instance flavor size."""""" service_content = session._get_vim()._get_service_content() vmdk_create_task = session._call_method( session._get_vim(), ""ExtendVirtualDisk_Task"", service_content.virtualDiskManager, name=name, datacenter=dc_ref, newCapacityKb=size, eagerZero) session._wait_for_task(instance['uuid'], vmdk_create_task) ",,38,1
openstack%2Fdiskimage-builder~master~I0c651091d9623d7607bb59bd05ffec20fd78633c,openstack/diskimage-builder,master,I0c651091d9623d7607bb59bd05ffec20fd78633c,Allow 'sudo kpartx -d' used in EACTION for Fedora,MERGED,2013-07-18 20:27:58.000000000,2013-07-18 20:27:58.000000000,2013-07-18 20:27:58.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-18 20:27:58.000000000', 'files': ['sudoers.d/img-build-sudoers'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/1651cfb53a5bae80a4677f0a3365369f9b04e6a1', 'message': ""Allow 'sudo kpartx -d' used in EACTION for Fedora\n\nChange-Id: I0c651091d9623d7607bb59bd05ffec20fd78633c\n""}]",0,37570,1651cfb53a5bae80a4677f0a3365369f9b04e6a1,6,3,1,7555,,,0,"Allow 'sudo kpartx -d' used in EACTION for Fedora

Change-Id: I0c651091d9623d7607bb59bd05ffec20fd78633c
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/70/37570/1 && git format-patch -1 --stdout FETCH_HEAD,['sudoers.d/img-build-sudoers'],1,1651cfb53a5bae80a4677f0a3365369f9b04e6a1,master,ALL ALL=(root) NOPASSWD: /sbin/kpartx -d /tmp/*/*.raw,,1,0
openstack%2Fdevstack~master~I967289524a50f650cdf2476d5067d263dbf55b03,openstack/devstack,master,I967289524a50f650cdf2476d5067d263dbf55b03,UUID Token provider in keystone.conf,MERGED,2013-07-16 01:12:44.000000000,2013-07-18 20:27:25.000000000,2013-07-18 20:27:25.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 970}, {'_account_id': 1613}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5174}]","[{'number': 1, 'created': '2013-07-16 01:12:44.000000000', 'files': ['lib/keystone'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3763141cf7763390bf35b86b2d143b156c25a915', 'message': 'UUID Token provider in keystone.conf\n\nToken provider needs to be set to uuid.Provider when the token format is\nUUID. PKI is the default.\n\nChange-Id: I967289524a50f650cdf2476d5067d263dbf55b03\nFixes: bug #1201639\n'}]",0,37151,3763141cf7763390bf35b86b2d143b156c25a915,11,7,1,1613,,,0,"UUID Token provider in keystone.conf

Token provider needs to be set to uuid.Provider when the token format is
UUID. PKI is the default.

Change-Id: I967289524a50f650cdf2476d5067d263dbf55b03
Fixes: bug #1201639
",git fetch https://review.opendev.org/openstack/devstack refs/changes/51/37151/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/keystone'],1,3763141cf7763390bf35b86b2d143b156c25a915,bug/1201639," if [[ ""$KEYSTONE_TOKEN_FORMAT"" = ""UUID"" ]]; then iniset $KEYSTONE_CONF token provider keystone.token.providers.uuid.Provider fi ",,5,0
openstack%2Fopenstack-manuals~master~Iae0cf22a59e13cc04dc4843d6501a624c3a05a0b,openstack/openstack-manuals,master,Iae0cf22a59e13cc04dc4843d6501a624c3a05a0b,Put Configuration Reference  section back,MERGED,2013-07-18 20:07:32.000000000,2013-07-18 20:19:38.000000000,2013-07-18 20:19:37.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 6414}]","[{'number': 1, 'created': '2013-07-18 20:07:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/966cea6a5ad0f09b783ffb64fe33fef091c3b416', 'message': 'Put Configuration Reference  section back\n\nThis was wrongly removed in a previos patch, and is causing\n validation errors.\n\nValidation and build are now successful locally.\n\nChange-Id: Iae0cf22a59e13cc04dc4843d6501a624c3a05a0b\n'}, {'number': 2, 'created': '2013-07-18 20:16:55.000000000', 'files': ['doc/src/docbkx/openstack-compute-admin/computescheduler.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8b44bb36d633938e13ceab69432b98f6d404e96b', 'message': 'Put Configuration Reference  section back\n\nThis was wrongly removed in a previos patch, and is causing\n validation errors.\n\nValidation and build are now successful locally.\n\nChange-Id: Iae0cf22a59e13cc04dc4843d6501a624c3a05a0b\n'}]",0,37761,8b44bb36d633938e13ceab69432b98f6d404e96b,8,3,2,6414,,,0,"Put Configuration Reference  section back

This was wrongly removed in a previos patch, and is causing
 validation errors.

Validation and build are now successful locally.

Change-Id: Iae0cf22a59e13cc04dc4843d6501a624c3a05a0b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/61/37761/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-compute-admin/computescheduler.xml'],1,966cea6a5ad0f09b783ffb64fe33fef091c3b416,scheduler-fix," <section xml:id=""compute-scheduler-config-ref""> <title>Configuration Reference</title> <xi:include href=""../common/tables/nova-scheduling.xml""/> </section>",,4,0
openstack%2Fopenstack-manuals~stable%2Fgrizzly~I3a30e54fbefe58a3b96a8a6ac5a65ed91b7da085,openstack/openstack-manuals,stable/grizzly,I3a30e54fbefe58a3b96a8a6ac5a65ed91b7da085,Cherry-picked from https://review.openstack.org/37063 and https://review.openstack.org/37190,MERGED,2013-07-17 10:02:23.000000000,2013-07-18 19:33:49.000000000,2013-07-18 19:33:49.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 612}, {'_account_id': 7063}]","[{'number': 1, 'created': '2013-07-17 10:02:23.000000000', 'files': ['doc/src/docbkx/common/kvm.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/54f2d15aca1c31f1cc529597b839d2d04d7cf4aa', 'message': 'Cherry-picked from https://review.openstack.org/37063 and https://review.openstack.org/37190\n\nChange-Id: I3a30e54fbefe58a3b96a8a6ac5a65ed91b7da085\n'}]",0,37441,54f2d15aca1c31f1cc529597b839d2d04d7cf4aa,7,4,1,7166,,,0,"Cherry-picked from https://review.openstack.org/37063 and https://review.openstack.org/37190

Change-Id: I3a30e54fbefe58a3b96a8a6ac5a65ed91b7da085
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/41/37441/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/common/kvm.xml'],1,54f2d15aca1c31f1cc529597b839d2d04d7cf4aa,grizzly-bug/1197117, <prompt>#</prompt> <userinput>apt-get install cpu-checker</userinput>, <prompt>#</prompt> <userinput>apt-get install cpu</userinput>,1,1
openstack%2Fmurano-agent~master~Ia303b0f895d130876659cf942235d117bbf80fef,openstack/murano-agent,master,Ia303b0f895d130876659cf942235d117bbf80fef,Wrong AcceptablePolicyErrors default for SSL in agent,MERGED,2013-07-18 18:53:36.000000000,2013-07-18 19:31:42.000000000,2013-07-18 19:31:42.000000000,"[{'_account_id': 3}, {'_account_id': 7226}]","[{'number': 1, 'created': '2013-07-18 18:53:36.000000000', 'files': ['WindowsAgent/RabbitMqClient.cs'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/5eecc15d561df4719d1ff5d4cbc0d42a289fabb1', 'message': 'Wrong AcceptablePolicyErrors default for SSL in agent\n\nChange-Id: Ia303b0f895d130876659cf942235d117bbf80fef\n'}]",0,37744,5eecc15d561df4719d1ff5d4cbc0d42a289fabb1,5,2,1,7226,,,0,"Wrong AcceptablePolicyErrors default for SSL in agent

Change-Id: Ia303b0f895d130876659cf942235d117bbf80fef
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/44/37744/1 && git format-patch -1 --stdout FETCH_HEAD,['WindowsAgent/RabbitMqClient.cs'],1,5eecc15d561df4719d1ff5d4cbc0d42a289fabb1,, SslPolicyErrors.RemoteCertificateChainErrors : SslPolicyErrors.None, SslPolicyErrors.RemoteCertificateNameMismatch : SslPolicyErrors.None,1,1
openstack%2Fnova~master~I5ad2c6366032a39c2e55dd11a16b9f1780ab9ed0,openstack/nova,master,I5ad2c6366032a39c2e55dd11a16b9f1780ab9ed0,Check that the configuration file sample is up to date,MERGED,2013-07-01 15:41:21.000000000,2013-07-18 19:31:26.000000000,2013-07-18 19:31:24.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 679}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 2166}, {'_account_id': 2271}]","[{'number': 1, 'created': '2013-07-01 15:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/439302437980d0dec1b16665f863023fa82e6827', 'message': 'Add a check so configuration file is uptodate\n\nWe added this check recently to Ceilometer, and it helps a lot to keep this\nfile always up to date and not falling behind.\n\nChange-Id: I5ad2c6366032a39c2e55dd11a16b9f1780ab9ed0\n'}, {'number': 2, 'created': '2013-07-08 10:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/101c397cbd0f84d9c1da40348703d5d5ca79a632', 'message': 'Add a check so configuration file is uptodate\n\nWe added this check recently to Ceilometer, and it helps a lot to keep this\nfile always up to date and not falling behind.\n\nChange-Id: I5ad2c6366032a39c2e55dd11a16b9f1780ab9ed0\n'}, {'number': 3, 'created': '2013-07-10 14:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/346e1b68e1ee1d8f4454398a6968599e8f253157', 'message': 'Add a check so configuration file is uptodate\n\nWe added this check recently to Ceilometer, and it helps a lot to keep this\nfile always up to date and not falling behind.\n\nChange-Id: I5ad2c6366032a39c2e55dd11a16b9f1780ab9ed0\n'}, {'number': 4, 'created': '2013-07-17 09:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b13193f08a4921f3dce49691b2c8df681e142bc', 'message': 'Check that the configuration file sample is up to date\n\nWe added this check recently to Ceilometer, and it helps a lot to keep this\nfile always up to date and not falling behind.\n\nChange-Id: I5ad2c6366032a39c2e55dd11a16b9f1780ab9ed0\n'}, {'number': 5, 'created': '2013-07-18 10:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad199504f22529719437eadcde0428c638b4dd50', 'message': 'Check that the configuration file sample is up to date\n\nWe added this check recently to Ceilometer, and it helps a lot to keep this\nfile always up to date and not falling behind.\n\nChange-Id: I5ad2c6366032a39c2e55dd11a16b9f1780ab9ed0\n'}, {'number': 6, 'created': '2013-07-18 18:23:38.000000000', 'files': ['tools/conf/check_uptodate.sh', 'test-requirements.txt', 'etc/nova/nova.conf.sample', 'tools/conf/generate_sample.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/923a7eeaa3c61759d79baab0626f5e5c5777f883', 'message': 'Check that the configuration file sample is up to date\n\nWe added this check recently to Ceilometer, and it helps a lot to keep this\nfile always up to date and not falling behind.\n\nChange-Id: I5ad2c6366032a39c2e55dd11a16b9f1780ab9ed0\n'}]",12,35151,923a7eeaa3c61759d79baab0626f5e5c5777f883,44,7,6,1669,,,0,"Check that the configuration file sample is up to date

We added this check recently to Ceilometer, and it helps a lot to keep this
file always up to date and not falling behind.

Change-Id: I5ad2c6366032a39c2e55dd11a16b9f1780ab9ed0
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/35151/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/openstack/common/config/generator.py', 'tools/conf/check_uptodate.sh', 'etc/nova/nova.conf.sample', 'test-requirements.txt', 'tools/conf/generate_sample.sh', 'tox.ini']",6,439302437980d0dec1b16665f863023fa82e6827,jd/check-config-uptodate, {toxinidir}/tools/conf/check_uptodate.sh,,133,14
openstack%2Fopenstack-manuals~master~I41d03f96bf349fba3b2f2b131dffd378b51a3138,openstack/openstack-manuals,master,I41d03f96bf349fba3b2f2b131dffd378b51a3138,"Redirect old ""Starter Guide"" from trunk.",MERGED,2013-07-18 18:09:58.000000000,2013-07-18 19:21:40.000000000,2013-07-18 19:21:40.000000000,"[{'_account_id': 3}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-18 18:09:58.000000000', 'files': ['www/.htaccess'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/16ceddffdb0a8512e01fd9883318e6cf4064fa4e', 'message': 'Redirect old ""Starter Guide"" from trunk.\n\nFix bug 1202776\n\nChange-Id: I41d03f96bf349fba3b2f2b131dffd378b51a3138\n'}]",0,37734,16ceddffdb0a8512e01fd9883318e6cf4064fa4e,5,2,1,964,,,0,"Redirect old ""Starter Guide"" from trunk.

Fix bug 1202776

Change-Id: I41d03f96bf349fba3b2f2b131dffd378b51a3138
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/34/37734/1 && git format-patch -1 --stdout FETCH_HEAD,['www/.htaccess'],1,16ceddffdb0a8512e01fd9883318e6cf4064fa4e,bug/1202776,# Redirecting diablo versionredirect 301 /trunk/openstack-compute/starter/ /trunk/,# Redirecting cactus version,2,1
openstack%2Fcinder~master~I4d20bf6b7a7e6d35e1319dbc758f1ccc305b4971,openstack/cinder,master,I4d20bf6b7a7e6d35e1319dbc758f1ccc305b4971,Imported Translations from Transifex,MERGED,2013-07-18 18:09:59.000000000,2013-07-18 19:11:10.000000000,2013-07-18 19:11:10.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2759}]","[{'number': 1, 'created': '2013-07-18 18:09:59.000000000', 'files': ['cinder/locale/ko/LC_MESSAGES/cinder.po', 'cinder/locale/hu/LC_MESSAGES/cinder.po', 'cinder/locale/tr/LC_MESSAGES/cinder.po', 'cinder/locale/en_US/LC_MESSAGES/cinder.po', 'cinder/locale/fi_FI/LC_MESSAGES/cinder.po', 'cinder/locale/pt_BR/LC_MESSAGES/cinder.po', 'cinder/locale/tr_TR/LC_MESSAGES/cinder.po', 'cinder/locale/ca/LC_MESSAGES/cinder.po', 'cinder/locale/cinder.pot', 'cinder/locale/nb/LC_MESSAGES/cinder.po', 'cinder/locale/it/LC_MESSAGES/cinder.po', 'cinder/locale/zh_CN/LC_MESSAGES/cinder.po', 'cinder/locale/ko_KR/LC_MESSAGES/cinder.po', 'cinder/locale/ms/LC_MESSAGES/cinder.po', 'cinder/locale/nl_NL/LC_MESSAGES/cinder.po', 'cinder/locale/zh_HK/LC_MESSAGES/cinder.po', 'cinder/locale/es/LC_MESSAGES/cinder.po', 'cinder/locale/cs/LC_MESSAGES/cinder.po', 'cinder/locale/pt/LC_MESSAGES/cinder.po', 'cinder/locale/sw_KE/LC_MESSAGES/cinder.po', 'cinder/locale/tl/LC_MESSAGES/cinder.po', 'cinder/locale/en_GB/LC_MESSAGES/cinder.po', 'cinder/locale/ru_RU/LC_MESSAGES/cinder.po', 'cinder/locale/bg_BG/LC_MESSAGES/cinder.po', 'cinder/locale/uk/LC_MESSAGES/cinder.po', 'cinder/locale/en_AU/LC_MESSAGES/cinder.po', 'cinder/locale/fr/LC_MESSAGES/cinder.po', 'cinder/locale/id/LC_MESSAGES/cinder.po', 'cinder/locale/da/LC_MESSAGES/cinder.po', 'cinder/locale/ru/LC_MESSAGES/cinder.po', 'cinder/locale/vi_VN/LC_MESSAGES/cinder.po', 'cinder/locale/hr/LC_MESSAGES/cinder.po', 'cinder/locale/pl_PL/LC_MESSAGES/cinder.po', 'cinder/locale/ro/LC_MESSAGES/cinder.po', 'cinder/locale/ja/LC_MESSAGES/cinder.po', 'cinder/locale/ka_GE/LC_MESSAGES/cinder.po', 'cinder/locale/zh_TW/LC_MESSAGES/cinder.po', 'cinder/locale/sl_SI/LC_MESSAGES/cinder.po', 'cinder/locale/it_IT/LC_MESSAGES/cinder.po', 'cinder/locale/de/LC_MESSAGES/cinder.po', 'cinder/locale/bs/LC_MESSAGES/cinder.po'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b123edca4f91b10da5fa18a8fd2a926caf3f1842', 'message': 'Imported Translations from Transifex\n\nChange-Id: I4d20bf6b7a7e6d35e1319dbc758f1ccc305b4971\n'}]",0,37735,b123edca4f91b10da5fa18a8fd2a926caf3f1842,6,3,1,3,,,0,"Imported Translations from Transifex

Change-Id: I4d20bf6b7a7e6d35e1319dbc758f1ccc305b4971
",git fetch https://review.opendev.org/openstack/cinder refs/changes/35/37735/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/locale/ko/LC_MESSAGES/cinder.po', 'cinder/locale/hu/LC_MESSAGES/cinder.po', 'cinder/locale/tr/LC_MESSAGES/cinder.po', 'cinder/locale/en_US/LC_MESSAGES/cinder.po', 'cinder/locale/fi_FI/LC_MESSAGES/cinder.po', 'cinder/locale/pt_BR/LC_MESSAGES/cinder.po', 'cinder/locale/tr_TR/LC_MESSAGES/cinder.po', 'cinder/locale/ca/LC_MESSAGES/cinder.po', 'cinder/locale/cinder.pot', 'cinder/locale/nb/LC_MESSAGES/cinder.po', 'cinder/locale/it/LC_MESSAGES/cinder.po', 'cinder/locale/zh_CN/LC_MESSAGES/cinder.po', 'cinder/locale/ko_KR/LC_MESSAGES/cinder.po', 'cinder/locale/ms/LC_MESSAGES/cinder.po', 'cinder/locale/nl_NL/LC_MESSAGES/cinder.po', 'cinder/locale/zh_HK/LC_MESSAGES/cinder.po', 'cinder/locale/es/LC_MESSAGES/cinder.po', 'cinder/locale/cs/LC_MESSAGES/cinder.po', 'cinder/locale/pt/LC_MESSAGES/cinder.po', 'cinder/locale/sw_KE/LC_MESSAGES/cinder.po', 'cinder/locale/tl/LC_MESSAGES/cinder.po', 'cinder/locale/en_GB/LC_MESSAGES/cinder.po', 'cinder/locale/ru_RU/LC_MESSAGES/cinder.po', 'cinder/locale/bg_BG/LC_MESSAGES/cinder.po', 'cinder/locale/uk/LC_MESSAGES/cinder.po', 'cinder/locale/en_AU/LC_MESSAGES/cinder.po', 'cinder/locale/fr/LC_MESSAGES/cinder.po', 'cinder/locale/id/LC_MESSAGES/cinder.po', 'cinder/locale/da/LC_MESSAGES/cinder.po', 'cinder/locale/ru/LC_MESSAGES/cinder.po', 'cinder/locale/vi_VN/LC_MESSAGES/cinder.po', 'cinder/locale/hr/LC_MESSAGES/cinder.po', 'cinder/locale/pl_PL/LC_MESSAGES/cinder.po', 'cinder/locale/ro/LC_MESSAGES/cinder.po', 'cinder/locale/ja/LC_MESSAGES/cinder.po', 'cinder/locale/ka_GE/LC_MESSAGES/cinder.po', 'cinder/locale/zh_TW/LC_MESSAGES/cinder.po', 'cinder/locale/sl_SI/LC_MESSAGES/cinder.po', 'cinder/locale/it_IT/LC_MESSAGES/cinder.po', 'cinder/locale/de/LC_MESSAGES/cinder.po', 'cinder/locale/bs/LC_MESSAGES/cinder.po']",41,b123edca4f91b10da5fa18a8fd2a926caf3f1842,transifex/translations,"""POT-Creation-Date: 2013-07-18 18:09+0000\n""#: cinder/db/sqlalchemy/api.py:1947 cinder/db/sqlalchemy/api.py:1973#: cinder/db/sqlalchemy/api.py:2030#: cinder/db/sqlalchemy/api.py:2074#: cinder/db/sqlalchemy/api.py:2136#: cinder/db/sqlalchemy/api.py:2224#: cinder/db/sqlalchemy/api.py:2248#: cinder/db/sqlalchemy/api.py:2271#: cinder/tests/test_storwize_svc.py:242#: cinder/tests/test_storwize_svc.py:1215#: cinder/tests/test_storwize_svc.py:1218#: cinder/tests/test_storwize_svc.py:1223#: cinder/volume/manager.py:606#: cinder/volume/driver.py:481 cinder/volume/manager.py:768 #: cinder/volume/drivers/lvm.py:546 cinder/volume/drivers/lvm.py:673 #: cinder/volume/drivers/storwize_svc.py:1356#: cinder/volume/manager.py:119#: cinder/volume/manager.py:142#: cinder/volume/manager.py:147#: cinder/volume/manager.py:152#: cinder/volume/manager.py:154#: cinder/volume/manager.py:157#: cinder/volume/manager.py:231#: cinder/volume/manager.py:242#: cinder/volume/manager.py:246#: cinder/volume/manager.py:250#: cinder/volume/manager.py:259#: cinder/volume/manager.py:270#: cinder/volume/manager.py:297#: cinder/volume/manager.py:318#: cinder/volume/manager.py:328#: cinder/volume/manager.py:371#: cinder/volume/manager.py:379#: cinder/volume/manager.py:398#: cinder/volume/manager.py:411#: cinder/volume/manager.py:415#: cinder/volume/manager.py:420#: cinder/volume/manager.py:449 cinder/volume/manager.py:462#: cinder/volume/manager.py:455#: cinder/volume/manager.py:460#: cinder/volume/manager.py:465#: cinder/volume/manager.py:488#: cinder/volume/manager.py:492#: cinder/volume/manager.py:507#: cinder/volume/manager.py:512#: cinder/volume/manager.py:531#: cinder/volume/manager.py:540 cinder/volume/manager.py:545#: cinder/volume/manager.py:548#: cinder/volume/manager.py:578#: cinder/volume/manager.py:581#: cinder/volume/manager.py:599#: cinder/volume/manager.py:603#: cinder/volume/manager.py:669 cinder/volume/manager.py:674#: cinder/volume/manager.py:679#: cinder/volume/manager.py:698#: cinder/volume/manager.py:781#: cinder/volume/manager.py:785#: cinder/volume/manager.py:823 #, python-format msgid """" ""Quota exceeded for %(s_pid)s, tried to extend volume by %(s_size)sG, "" ""(%(d_consumed)dG of %(d_quota)dG already consumed)"" msgstr """" #: cinder/volume/manager.py:834#: cinder/volume/manager.py:836#: cinder/volume/manager.py:838#: cinder/volume/utils.py:160 #, python-format msgid """" ""Incorrect value error: %(blocksize)s, it may indicate that "" ""'volume_dd_blocksize' was configured incorrectly. Fall back to default."" msgstr """" #: cinder/volume/drivers/block_device.py:135 #: cinder/volume/drivers/block_device.py:146 cinder/volume/drivers/lvm.py:495 #: cinder/volume/drivers/lvm.py:509#: cinder/volume/drivers/block_device.py:160 cinder/volume/drivers/lvm.py:527#: cinder/volume/drivers/block_device.py:185 cinder/volume/drivers/lvm.py:328#: cinder/volume/drivers/block_device.py:202 cinder/volume/drivers/lvm.py:349#: cinder/volume/drivers/block_device.py:274 cinder/volume/drivers/lvm.py:185#: cinder/volume/drivers/block_device.py:287 cinder/volume/drivers/lvm.py:200#: cinder/volume/drivers/block_device.py:309 cinder/volume/drivers/lvm.py:250 #: cinder/volume/drivers/lvm.py:650#: cinder/volume/drivers/block_device.py:376#: cinder/volume/drivers/block_device.py:389#: cinder/volume/drivers/lvm.py:80#: cinder/volume/drivers/lvm.py:180#: cinder/volume/drivers/lvm.py:220#: cinder/volume/drivers/lvm.py:363#: cinder/volume/drivers/lvm.py:415#: cinder/volume/drivers/lvm.py:569#: cinder/volume/drivers/storwize_svc.py:359#: cinder/volume/drivers/storwize_svc.py:395#: cinder/volume/drivers/storwize_svc.py:418#: cinder/volume/drivers/storwize_svc.py:486#: cinder/volume/drivers/storwize_svc.py:514#: cinder/volume/drivers/storwize_svc.py:526#: cinder/volume/drivers/storwize_svc.py:541#: cinder/volume/drivers/storwize_svc.py:557#: cinder/volume/drivers/storwize_svc.py:580#: cinder/volume/drivers/storwize_svc.py:610#: cinder/volume/drivers/storwize_svc.py:623#: cinder/volume/drivers/storwize_svc.py:629#: cinder/volume/drivers/storwize_svc.py:639#: cinder/volume/drivers/storwize_svc.py:647#: cinder/volume/drivers/storwize_svc.py:673 msgid ""The connector does not contain the required information."" msgstr """" #: cinder/volume/drivers/storwize_svc.py:692#: cinder/volume/drivers/storwize_svc.py:708#: cinder/volume/drivers/storwize_svc.py:719#: cinder/volume/drivers/storwize_svc.py:726#: cinder/volume/drivers/storwize_svc.py:728#: cinder/volume/drivers/storwize_svc.py:745#: cinder/volume/drivers/storwize_svc.py:753#: cinder/volume/drivers/storwize_svc.py:786#: cinder/volume/drivers/storwize_svc.py:791#: cinder/volume/drivers/storwize_svc.py:809#: cinder/volume/drivers/storwize_svc.py:819#: cinder/volume/drivers/storwize_svc.py:834#: cinder/volume/drivers/storwize_svc.py:842#: cinder/volume/drivers/storwize_svc.py:899#: cinder/volume/drivers/storwize_svc.py:923#: cinder/volume/drivers/storwize_svc.py:957#: cinder/volume/drivers/storwize_svc.py:962#: cinder/volume/drivers/storwize_svc.py:972 #: cinder/volume/drivers/storwize_svc.py:986#: cinder/volume/drivers/storwize_svc.py:998 #: cinder/volume/drivers/storwize_svc.py:1008#: cinder/volume/drivers/storwize_svc.py:1022#: cinder/volume/drivers/storwize_svc.py:1049#: cinder/volume/drivers/storwize_svc.py:1060#: cinder/volume/drivers/storwize_svc.py:1065#: cinder/volume/drivers/storwize_svc.py:1072#: cinder/volume/drivers/storwize_svc.py:1079#: cinder/volume/drivers/storwize_svc.py:1090#: cinder/volume/drivers/storwize_svc.py:1102#: cinder/volume/drivers/storwize_svc.py:1110#: cinder/volume/drivers/storwize_svc.py:1117#: cinder/volume/drivers/storwize_svc.py:1129#: cinder/volume/drivers/storwize_svc.py:1139#: cinder/volume/drivers/storwize_svc.py:1144#: cinder/volume/drivers/storwize_svc.py:1166#: cinder/volume/drivers/storwize_svc.py:1174#: cinder/volume/drivers/storwize_svc.py:1176#: cinder/volume/drivers/storwize_svc.py:1204#: cinder/volume/drivers/storwize_svc.py:1209#: cinder/volume/drivers/storwize_svc.py:1235#: cinder/volume/drivers/storwize_svc.py:1269#: cinder/volume/drivers/storwize_svc.py:1294#: cinder/volume/drivers/storwize_svc.py:1308#: cinder/volume/drivers/storwize_svc.py:1373#: cinder/volume/drivers/storwize_svc.py:1385#: cinder/volume/drivers/storwize_svc.py:1386#: cinder/volume/drivers/storwize_svc.py:1424#: cinder/volume/drivers/storwize_svc.py:1430#: cinder/volume/drivers/storwize_svc.py:1437#: cinder/volume/drivers/storwize_svc.py:1444#: cinder/volume/drivers/storwize_svc.py:1449#: cinder/volume/drivers/storwize_svc.py:1455#: cinder/volume/drivers/storwize_svc.py:1464#: cinder/volume/drivers/storwize_svc.py:1476#: cinder/volume/drivers/storwize_svc.py:1483#: cinder/volume/drivers/storwize_svc.py:1500#: cinder/volume/drivers/storwize_svc.py:1519#: cinder/volume/drivers/storwize_svc.py:1527#: cinder/volume/drivers/storwize_svc.py:1541#: cinder/volume/drivers/storwize_svc.py:1549","""POT-Creation-Date: 2013-07-17 18:10+0000\n""#: cinder/db/sqlalchemy/api.py:1942 cinder/db/sqlalchemy/api.py:1968#: cinder/db/sqlalchemy/api.py:2025#: cinder/db/sqlalchemy/api.py:2069#: cinder/db/sqlalchemy/api.py:2131#: cinder/db/sqlalchemy/api.py:2219#: cinder/db/sqlalchemy/api.py:2243#: cinder/db/sqlalchemy/api.py:2266#: cinder/tests/test_storwize_svc.py:243#: cinder/tests/test_storwize_svc.py:1217#: cinder/tests/test_storwize_svc.py:1220#: cinder/tests/test_storwize_svc.py:1225#: cinder/volume/manager.py:604#: cinder/volume/api.py:825 #, python-format msgid """" ""Quota exceeded for %(s_pid)s, tried to extend volume by %(s_size)sG, "" ""(%(d_consumed)dG of %(d_quota)dG already consumed)"" msgstr """" #: cinder/volume/driver.py:481 cinder/volume/manager.py:766 #: cinder/volume/drivers/lvm.py:596 cinder/volume/drivers/lvm.py:723 #: cinder/volume/drivers/storwize_svc.py:1346#: cinder/volume/manager.py:117#: cinder/volume/manager.py:140#: cinder/volume/manager.py:145#: cinder/volume/manager.py:150#: cinder/volume/manager.py:152#: cinder/volume/manager.py:155#: cinder/volume/manager.py:229#: cinder/volume/manager.py:240#: cinder/volume/manager.py:244#: cinder/volume/manager.py:248#: cinder/volume/manager.py:257#: cinder/volume/manager.py:268#: cinder/volume/manager.py:295#: cinder/volume/manager.py:316#: cinder/volume/manager.py:326#: cinder/volume/manager.py:369#: cinder/volume/manager.py:377#: cinder/volume/manager.py:396#: cinder/volume/manager.py:409#: cinder/volume/manager.py:413#: cinder/volume/manager.py:418#: cinder/volume/manager.py:447 cinder/volume/manager.py:460#: cinder/volume/manager.py:453#: cinder/volume/manager.py:458#: cinder/volume/manager.py:463#: cinder/volume/manager.py:486#: cinder/volume/manager.py:490#: cinder/volume/manager.py:505#: cinder/volume/manager.py:510#: cinder/volume/manager.py:529#: cinder/volume/manager.py:538 cinder/volume/manager.py:543#: cinder/volume/manager.py:546#: cinder/volume/manager.py:576#: cinder/volume/manager.py:579#: cinder/volume/manager.py:597#: cinder/volume/manager.py:601#: cinder/volume/manager.py:667 cinder/volume/manager.py:672#: cinder/volume/manager.py:677#: cinder/volume/manager.py:696#: cinder/volume/manager.py:779#: cinder/volume/manager.py:783#: cinder/volume/manager.py:808#: cinder/volume/manager.py:810#: cinder/volume/manager.py:812#: cinder/volume/drivers/block_device.py:134 #: cinder/volume/drivers/block_device.py:145 cinder/volume/drivers/lvm.py:545 #: cinder/volume/drivers/lvm.py:559#: cinder/volume/drivers/block_device.py:159 cinder/volume/drivers/lvm.py:577#: cinder/volume/drivers/block_device.py:184 cinder/volume/drivers/lvm.py:378#: cinder/volume/drivers/block_device.py:201 cinder/volume/drivers/lvm.py:399#: cinder/volume/drivers/block_device.py:273 cinder/volume/drivers/lvm.py:237#: cinder/volume/drivers/block_device.py:286 cinder/volume/drivers/lvm.py:251#: cinder/volume/drivers/block_device.py:329 cinder/volume/drivers/lvm.py:301 #: cinder/volume/drivers/lvm.py:700#: cinder/volume/drivers/block_device.py:395#: cinder/volume/drivers/block_device.py:408#: cinder/volume/drivers/lvm.py:84#: cinder/volume/drivers/lvm.py:115 #, python-format msgid """" ""Incorrect value error: %(blocksize)s, it may indicate that "" ""'volume_dd_blocksize' was configured incorrectly. Fall back to default."" msgstr """" #: cinder/volume/drivers/lvm.py:232#: cinder/volume/drivers/lvm.py:271#: cinder/volume/drivers/lvm.py:413#: cinder/volume/drivers/lvm.py:465#: cinder/volume/drivers/lvm.py:619#: cinder/volume/drivers/storwize_svc.py:360#: cinder/volume/drivers/storwize_svc.py:396#: cinder/volume/drivers/storwize_svc.py:419#: cinder/volume/drivers/storwize_svc.py:487#: cinder/volume/drivers/storwize_svc.py:515#: cinder/volume/drivers/storwize_svc.py:527#: cinder/volume/drivers/storwize_svc.py:542#: cinder/volume/drivers/storwize_svc.py:555#: cinder/volume/drivers/storwize_svc.py:578#: cinder/volume/drivers/storwize_svc.py:611#: cinder/volume/drivers/storwize_svc.py:621#: cinder/volume/drivers/storwize_svc.py:627#: cinder/volume/drivers/storwize_svc.py:637#: cinder/volume/drivers/storwize_svc.py:645#: cinder/volume/drivers/storwize_svc.py:677#: cinder/volume/drivers/storwize_svc.py:693#: cinder/volume/drivers/storwize_svc.py:704#: cinder/volume/drivers/storwize_svc.py:711#: cinder/volume/drivers/storwize_svc.py:713#: cinder/volume/drivers/storwize_svc.py:730#: cinder/volume/drivers/storwize_svc.py:738#: cinder/volume/drivers/storwize_svc.py:771#: cinder/volume/drivers/storwize_svc.py:776#: cinder/volume/drivers/storwize_svc.py:794#: cinder/volume/drivers/storwize_svc.py:804#: cinder/volume/drivers/storwize_svc.py:819#: cinder/volume/drivers/storwize_svc.py:827#: cinder/volume/drivers/storwize_svc.py:884#: cinder/volume/drivers/storwize_svc.py:908#: cinder/volume/drivers/storwize_svc.py:946#: cinder/volume/drivers/storwize_svc.py:951#: cinder/volume/drivers/storwize_svc.py:963 #: cinder/volume/drivers/storwize_svc.py:977#: cinder/volume/drivers/storwize_svc.py:989 #: cinder/volume/drivers/storwize_svc.py:999#: cinder/volume/drivers/storwize_svc.py:1013#: cinder/volume/drivers/storwize_svc.py:1040#: cinder/volume/drivers/storwize_svc.py:1051#: cinder/volume/drivers/storwize_svc.py:1056#: cinder/volume/drivers/storwize_svc.py:1063#: cinder/volume/drivers/storwize_svc.py:1070#: cinder/volume/drivers/storwize_svc.py:1081#: cinder/volume/drivers/storwize_svc.py:1093#: cinder/volume/drivers/storwize_svc.py:1101#: cinder/volume/drivers/storwize_svc.py:1108#: cinder/volume/drivers/storwize_svc.py:1120#: cinder/volume/drivers/storwize_svc.py:1130#: cinder/volume/drivers/storwize_svc.py:1135#: cinder/volume/drivers/storwize_svc.py:1157#: cinder/volume/drivers/storwize_svc.py:1165#: cinder/volume/drivers/storwize_svc.py:1167#: cinder/volume/drivers/storwize_svc.py:1195#: cinder/volume/drivers/storwize_svc.py:1200#: cinder/volume/drivers/storwize_svc.py:1226#: cinder/volume/drivers/storwize_svc.py:1259#: cinder/volume/drivers/storwize_svc.py:1284#: cinder/volume/drivers/storwize_svc.py:1298#: cinder/volume/drivers/storwize_svc.py:1363#: cinder/volume/drivers/storwize_svc.py:1375#: cinder/volume/drivers/storwize_svc.py:1376#: cinder/volume/drivers/storwize_svc.py:1414#: cinder/volume/drivers/storwize_svc.py:1420#: cinder/volume/drivers/storwize_svc.py:1427#: cinder/volume/drivers/storwize_svc.py:1434#: cinder/volume/drivers/storwize_svc.py:1439#: cinder/volume/drivers/storwize_svc.py:1445#: cinder/volume/drivers/storwize_svc.py:1454#: cinder/volume/drivers/storwize_svc.py:1466#: cinder/volume/drivers/storwize_svc.py:1473#: cinder/volume/drivers/storwize_svc.py:1490#: cinder/volume/drivers/storwize_svc.py:1509#: cinder/volume/drivers/storwize_svc.py:1517#: cinder/volume/drivers/storwize_svc.py:1531#: cinder/volume/drivers/storwize_svc.py:1539#~ msgid ""Failed to access the device on the path %(path)s: %(error)s."" #~ msgstr """" #~ msgid ""Update SolidFire Cluster stats failed: %s"" #~ msgstr """" ",6971,7047
openstack%2Fcookbook-openstack-block-storage~master~I4cb75bfbc224564897ca39a4f54258e6acff1f7e,openstack/cookbook-openstack-block-storage,master,I4cb75bfbc224564897ca39a4f54258e6acff1f7e,remove duplicate test case,MERGED,2013-07-17 15:48:23.000000000,2013-07-18 18:57:05.000000000,2013-07-18 18:57:05.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 7572}]","[{'number': 1, 'created': '2013-07-17 15:48:23.000000000', 'files': ['spec/volume-redhat_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/913145991a1e318931023ef3f036e38af02edd15', 'message': 'remove duplicate test case\n\nChange-Id: I4cb75bfbc224564897ca39a4f54258e6acff1f7e\n'}]",0,37510,913145991a1e318931023ef3f036e38af02edd15,6,3,1,2340,,,0,"remove duplicate test case

Change-Id: I4cb75bfbc224564897ca39a4f54258e6acff1f7e
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/10/37510/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/volume-redhat_spec.rb'],1,913145991a1e318931023ef3f036e38af02edd15,duplicate-test,," it ""has different tgt"" do expect(@chef_run).to create_file_with_content ""/etc/tgt/targets.conf"", ""/var/lib/cinder/volumes"" end",0,4
openstack%2Fdiskimage-builder~master~I551c075e0bb6853b2ef79268b7f6455a4f06743d,openstack/diskimage-builder,master,I551c075e0bb6853b2ef79268b7f6455a4f06743d,Move the getsources hook earlier.,MERGED,2013-07-18 18:56:43.000000000,2013-07-18 18:56:43.000000000,2013-07-18 18:56:43.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-18 18:56:43.000000000', 'files': ['elements/source-repositories/extra-data.d/98-source-repositories'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/e187a402aed26563e802187aec58d4fd20b9197f', 'message': 'Move the getsources hook earlier.\n\nCaching PyPI objects will require inspecting the content downloaded by\nthe source repositories, so needs to run after it.\n\nChange-Id: I551c075e0bb6853b2ef79268b7f6455a4f06743d\n'}]",0,37661,e187a402aed26563e802187aec58d4fd20b9197f,6,3,1,4190,,,0,"Move the getsources hook earlier.

Caching PyPI objects will require inspecting the content downloaded by
the source repositories, so needs to run after it.

Change-Id: I551c075e0bb6853b2ef79268b7f6455a4f06743d
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/61/37661/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/source-repositories/extra-data.d/98-source-repositories'],1,e187a402aed26563e802187aec58d4fd20b9197f,,,,0,0
openstack%2Fzaqar~master~I5475e5ad8bf3c3ad5125fadc4b6f221747982b48,openstack/zaqar,master,I5475e5ad8bf3c3ad5125fadc4b6f221747982b48,Add Test for Health endpoint.,MERGED,2013-07-17 16:31:14.000000000,2013-07-18 18:46:27.000000000,2013-07-18 18:46:27.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6944}, {'_account_id': 8092}]","[{'number': 1, 'created': '2013-07-17 16:31:14.000000000', 'files': ['marconi/tests/system/queue/test_queue.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1649f9f58cc2d5481503a14b77784c0695eabf28', 'message': 'Add Test for Health endpoint.\n\nThis patch adds test for the health endpoint.\n\nChange-Id: I5475e5ad8bf3c3ad5125fadc4b6f221747982b48\n'}]",0,37522,1649f9f58cc2d5481503a14b77784c0695eabf28,8,5,1,6971,,,0,"Add Test for Health endpoint.

This patch adds test for the health endpoint.

Change-Id: I5475e5ad8bf3c3ad5125fadc4b6f221747982b48
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/22/37522/1 && git format-patch -1 --stdout FETCH_HEAD,['marconi/tests/system/queue/test_queue.py'],1,1649f9f58cc2d5481503a14b77784c0695eabf28,health-test," def test_022_check_health(self): """"""Test health endpoint."""""" url = self.cfg.base_url + '/health' result = http.get(url, self.header) self.assertEqual(result.status_code, 204) test_022_check_health.tags = ['positive'] ",,9,0
openstack%2Fzaqar~master~I2c473bb158c68fe87671e4dea19f9063e33b3f58,openstack/zaqar,master,I2c473bb158c68fe87671e4dea19f9063e33b3f58,feat(wsgi): check for client media type support,MERGED,2013-07-16 19:24:20.000000000,2013-07-18 18:45:39.000000000,2013-07-18 18:45:39.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 7044}]","[{'number': 1, 'created': '2013-07-16 19:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e681c1d7a81142e28ae10172a50f36c1c166056c', 'message': 'feat(wsgi): check for client media type support\n\nChange-Id: I2c473bb158c68fe87671e4dea19f9063e33b3f58\nFixes: bug #1177947\n'}, {'number': 2, 'created': '2013-07-17 19:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d37924f7b65afec011f190f3afb047868b58eda8', 'message': 'feat(wsgi): check for client media type support\n\nChange-Id: I2c473bb158c68fe87671e4dea19f9063e33b3f58\nFixes: bug #1177947\n'}, {'number': 3, 'created': '2013-07-17 20:41:34.000000000', 'files': ['marconi/transport/wsgi/driver.py', 'marconi/tests/transport/wsgi/test_media_type.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/4fc292513d822a36db0794042c3dd8bd7c0d9ad7', 'message': 'feat(wsgi): check for client media type support\n\nChange-Id: I2c473bb158c68fe87671e4dea19f9063e33b3f58\nFixes: bug #1177947\n'}]",2,37306,4fc292513d822a36db0794042c3dd8bd7c0d9ad7,12,5,3,6943,,,0,"feat(wsgi): check for client media type support

Change-Id: I2c473bb158c68fe87671e4dea19f9063e33b3f58
Fixes: bug #1177947
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/06/37306/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/transport/wsgi/driver.py', 'marconi/tests/transport/wsgi/test_media_type.py']",2,e681c1d7a81142e28ae10172a50f36c1c166056c,bug/1177947,"# Copyright (c) 2013 Rackspace, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import falcon from falcon import testing from marconi.tests.transport.wsgi import base class TestWSGIMediaType(base.TestBase): config_filename = 'wsgi_sqlite.conf' def test_json_only_endpoints(self): headers = {'Client-ID': '30387f00', 'Accept': 'application/xml'} endpoints = [ ('GET', '/v1/queues'), ('GET', '/v1/queues/nonexistent'), ('GET', '/v1/queues/nonexistent/stats'), ('POST', '/v1/queues/nonexistent/messages'), ('GET', '/v1/queues/nonexistent/messages/deadbeaf'), ('POST', '/v1/queues/nonexistent/claims'), ('GET', '/v1/queues/nonexistent/claims/0ad'), ('GET', '/v1/health'), ] for method, endpoint in endpoints: env = testing.create_environ(endpoint, method=method, headers=headers) self.app(env, self.srmock) self.assertEquals(self.srmock.status, falcon.HTTP_406) ",,58,1
openstack%2Fkeystone~milestone-proposed~I15ff67490acbbacc9eefc7eee253400475704b04,openstack/keystone,milestone-proposed,I15ff67490acbbacc9eefc7eee253400475704b04,Support token_format for backward compatibility,MERGED,2013-07-18 16:19:28.000000000,2013-07-18 18:41:36.000000000,2013-07-18 18:41:35.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 308}, {'_account_id': 1916}, {'_account_id': 5046}]","[{'number': 1, 'created': '2013-07-18 16:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f9d0fca426ac1fd3993715862a4cc8cbb8215394', 'message': 'Support token_format for backward compatibility\n\nThe provider property in the [token] section will be unset by default. If\nprovider is not set, we will us token_format in the [signing] section to\ndetermine to provider. If provider is set, it must agree with the token_format.\n\nfixed bug 1202651\n\nChange-Id: I15ff67490acbbacc9eefc7eee253400475704b04\n'}, {'number': 2, 'created': '2013-07-18 16:42:08.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/token/provider.py', 'keystone/common/config.py', 'tests/test_token_provider.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/43213e5df24950a5c6f2a43b4426becafc6ad25a', 'message': 'Support token_format for backward compatibility\n\nThe provider property in the [token] section will be unset by default. If\nprovider is not set, we will use token_format in the [signing] section to\ndetermine to provider. If provider is set, it must agree with the token_format.\n\nfixed bug 1202651\n\nChange-Id: I15ff67490acbbacc9eefc7eee253400475704b04\n'}]",0,37711,43213e5df24950a5c6f2a43b4426becafc6ad25a,11,5,2,4,,,0,"Support token_format for backward compatibility

The provider property in the [token] section will be unset by default. If
provider is not set, we will use token_format in the [signing] section to
determine to provider. If provider is set, it must agree with the token_format.

fixed bug 1202651

Change-Id: I15ff67490acbbacc9eefc7eee253400475704b04
",git fetch https://review.opendev.org/openstack/keystone refs/changes/11/37711/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/token/provider.py', 'keystone/common/config.py', 'tests/test_token_provider.py']",4,f9d0fca426ac1fd3993715862a4cc8cbb8215394,bug/1202651,"from keystone import exception provider=token.provider.PKI_PROVIDER) except exception.UnexpectedError: provider=token.provider.UUID_PROVIDER) except exception.UnexpectedError: provider=token.provider.PKI_PROVIDER) provider=token.provider.UUID_PROVIDER) provider=token.provider.PKI_PROVIDER) def test_default_token_format(self): self.assertEqual(token.provider.Manager.check_and_get_token_provider(), token.provider.PKI_PROVIDER) def test_uuid_token_format_and_no_provider(self): self.opt_in_group('signing', token_format='UUID') self.assertEqual(token.provider.Manager.check_and_get_token_provider(), token.provider.UUID_PROVIDER) def test_unsupported_token_format(self): self.opt_in_group('signing', token_format='CUSTOM') self.assertRaises(exception.UnexpectedError, token.provider.Manager.check_and_get_token_provider) def test_provider_override_token_format(self): self.opt_in_group('token', provider='keystone.token.providers.pki.Test') self.assertRaises(exception.UnexpectedError, token.provider.Manager.check_and_get_token_provider) self.opt_in_group('signing', token_format='UUID') self.opt_in_group('token', provider=token.provider.UUID_PROVIDER) self.assertEqual(token.provider.Manager.check_and_get_token_provider(), token.provider.UUID_PROVIDER) self.opt_in_group('signing', token_format='PKI') self.opt_in_group('token', provider=token.provider.PKI_PROVIDER) self.assertEqual(token.provider.Manager.check_and_get_token_provider(), token.provider.PKI_PROVIDER) self.opt_in_group('signing', token_format='CUSTOM') self.opt_in_group('token', provider='my.package.MyProvider') self.assertEqual(token.provider.Manager.check_and_get_token_provider(), 'my.package.MyProvider')", provider='keystone.token.providers.pki.Provider') except ValueError: provider='keystone.token.providers.uuid.Provider') except ValueError: provider='keystone.token.providers.pki.Provider') provider='keystone.token.providers.uuid.Provider') provider='keystone.token.providers.pki.Provider'),85,18
openstack%2Fswift~master~If90e38a0ba36f6b59016d4a1374f4100f0bbee7b,openstack/swift,master,If90e38a0ba36f6b59016d4a1374f4100f0bbee7b,Add example Apache config files,MERGED,2013-06-15 20:20:18.000000000,2013-07-18 18:37:58.000000000,2013-06-21 08:20:29.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 866}, {'_account_id': 917}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 2649}, {'_account_id': 2828}, {'_account_id': 4108}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-06-15 20:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e18e85f59f822f2b97f53dd4d611def1ce0076ce', 'message': 'Add example Apache config files\n\nCreated examples dir\n\nMoved etc to examples dir\n\nAdded apache config example to the examples/etc dir\n\nAdded apache config template for devstack inan examples/devstack dir\n\nAdded wsgi files for web servers to run a/c/o/proxy to\nexamples/var-wwwa dir\n\nFixes: Bug #1191388\n\nChange-Id: If90e38a0ba36f6b59016d4a1374f4100f0bbee7b\n'}, {'number': 2, 'created': '2013-06-17 22:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fd55bb5b1c8aaee37978cf6b30a9d5477e74dd90', 'message': 'Add example Apache config files\n\nCreated examples dir\n\nAdded apache config example to the examples/etc dir\n\nAdded apache config template for devstack in examples/devstack dir\n\nAdded wsgi files for web servers to run a/c/o/proxy to\nexamples/var-www dir\n\nFixes: Bug #1191388\n\nChange-Id: If90e38a0ba36f6b59016d4a1374f4100f0bbee7b\n'}, {'number': 3, 'created': '2013-06-20 10:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/de1307fb8cb1f6dd6f1bd91b61e6645faf5e936a', 'message': 'Add example Apache config files\n\nThis patch is needed in 1.9 as a dependency for adding swift/apache\nto devstack.\nzhang-hare is working in parallel on a devstack patch that depend\non this patch.\n\nAs part of this patch we add examples dir.\nIn this dir we add template config files that can be used either by\na script (as will be done by devstack) or serve a an example to the\nadmin.\n\nApache2 vhost files were added under examples/apache2\nWsgi files were added under examples/wsgi\n\nFixes: Bug #1191388\n\nChange-Id: If90e38a0ba36f6b59016d4a1374f4100f0bbee7b\n'}, {'number': 4, 'created': '2013-06-20 10:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a73ab6758cdcb9fdd0bad4e85bb1cda47824bd98', 'message': 'Add example Apache config files\n\nThis patch is needed in 1.9 as a dependency for adding swift/apache\nto devstack.\nzhang-hare is working in parallel on a devstack patch that depend\non this patch.\n\nAs part of this patch we add examples dir.\nIn this dir we add template config files that can be used either by\na script (as will be done by devstack) or serve a an example to the\nadmin.\n\nApache2 vhost files were added under examples/apache2\nWsgi files were added under examples/wsgi\n\nFixes: Bug #1191388\n\nChange-Id: If90e38a0ba36f6b59016d4a1374f4100f0bbee7b\n'}, {'number': 5, 'created': '2013-06-20 18:57:28.000000000', 'files': ['examples/wsgi/account-server.wsgi.template', 'examples/wsgi/container-server.wsgi.template', 'examples/apache2/object-server.template', 'examples/wsgi/proxy-server.wsgi.template', 'examples/apache2/container-server.template', 'examples/apache2/proxy-server.template', 'examples/wsgi/object-server.wsgi.template', 'examples/apache2/account-server.template'], 'web_link': 'https://opendev.org/openstack/swift/commit/e872e54c2af962d1726121b7467b7140d8d60149', 'message': 'Add example Apache config files\n\nThis patch is needed in 1.9 as a dependency for adding swift/apache\nto devstack.\nzhang-hare is working in parallel on a devstack patch that depend\non this patch.\n\nAs part of this patch we add examples dir.\nIn this dir we add template config files that can be used either by\na script (as will be done by devstack) or serve a an example to the\nadmin.\n\nApache2 vhost files were added under examples/apache2\nWsgi files were added under examples/wsgi\n\nFixes: Bug #1191388\n\nChange-Id: If90e38a0ba36f6b59016d4a1374f4100f0bbee7b\n'}]",6,33169,e872e54c2af962d1726121b7467b7140d8d60149,37,10,5,4108,,,0,"Add example Apache config files

This patch is needed in 1.9 as a dependency for adding swift/apache
to devstack.
zhang-hare is working in parallel on a devstack patch that depend
on this patch.

As part of this patch we add examples dir.
In this dir we add template config files that can be used either by
a script (as will be done by devstack) or serve a an example to the
admin.

Apache2 vhost files were added under examples/apache2
Wsgi files were added under examples/wsgi

Fixes: Bug #1191388

Change-Id: If90e38a0ba36f6b59016d4a1374f4100f0bbee7b
",git fetch https://review.opendev.org/openstack/swift refs/changes/69/33169/3 && git format-patch -1 --stdout FETCH_HEAD,"['examples/var-www/container-server.wsgi', 'examples/etc/dispersion.conf-sample', 'examples/etc/drive-audit.conf-sample', 'examples/devstack/swift-apache2-wsgi.template', 'examples/etc/proxy-server.conf-sample', 'examples/etc/swift.conf-sample', 'examples/etc/memcache.conf-sample', 'examples/var-www/object-server.wsgi', 'examples/etc/account-server.conf-sample', 'examples/etc/object-server.conf-sample', 'examples/etc/container-server.conf-sample', 'examples/etc/swift-apache2-wsgi.conf-sample', 'examples/etc/rsyncd.conf-sample', 'examples/etc/swift-bench.conf-sample', 'examples/etc/mime.types-sample', 'examples/var-www/account-server.wsgi', 'examples/etc/object-expirer.conf-sample', 'examples/var-www/proxy-server.wsgi']",18,e18e85f59f822f2b97f53dd4d611def1ce0076ce,bug/1191388,"from swift.common.wsgi import init_request_processor application, conf, logger, log_name = \ init_request_processor('/etc/swift/proxy-server.conf','proxy-server') ",,136,0
openstack%2Freviewstats~master~Ic7ca0e49620fa23f21078bd13ee3cea47067daf9,openstack/reviewstats,master,Ic7ca0e49620fa23f21078bd13ee3cea47067daf9,Fixing trove repository,MERGED,2013-07-18 17:33:05.000000000,2013-07-18 17:56:58.000000000,2013-07-18 17:56:58.000000000,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2013-07-18 17:33:05.000000000', 'files': ['projects/trove.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/4b444d18c9bea8ffc55448659b1b77a322f9b51a', 'message': 'Fixing trove repository\n\nChange-Id: Ic7ca0e49620fa23f21078bd13ee3cea47067daf9\n'}]",0,37727,4b444d18c9bea8ffc55448659b1b77a322f9b51a,5,2,1,739,,,0,"Fixing trove repository

Change-Id: Ic7ca0e49620fa23f21078bd13ee3cea47067daf9
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/27/37727/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/trove.json'],1,4b444d18c9bea8ffc55448659b1b77a322f9b51a,,"{""name"": ""trove"", ""subprojects"": [""openstack/trove"", ""openstack/python-troveclient""], ""core-team"": [""tim-simpson"", ""vipuls"", ""hubcap"", ""slicknik""]}","{""name"": ""trove"", ""subprojects"": [""stackforge/trove"", ""stackforge/python-troveclient""], ""core-team"": [""tim-simpson"", ""vipuls"", ""hubcap"", ""slicknik""]}",1,1
openstack%2Fswift~master~I3962202c07c4b2fbfc26f9776c8a5c96292ae199,openstack/swift,master,I3962202c07c4b2fbfc26f9776c8a5c96292ae199,Forklift the DiskFile interface into it's own module,MERGED,2013-07-18 15:00:25.000000000,2013-07-18 17:45:35.000000000,2013-07-18 17:45:34.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-07-18 15:00:25.000000000', 'files': ['test/unit/obj/test_auditor.py', 'swift/obj/server.py', 'swift/obj/auditor.py', 'test/unit/obj/test_server.py', 'test/unit/obj/test_diskfile.py', 'test/probe/test_object_failures.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c9de9f2b8da23538b82f23c724b482404d0ea916', 'message': ""Forklift the DiskFile interface into it's own module\n\n * new module swift.obj.diskfile\n\nI parameterized two constants from obj.server into the DiskFile's __init__\n\n * DATADIR -> obj_dir\n * DISALLOWED_HEADERS -> disallowed_metadata_keys\n\nI'm not sure if this is the right long term abstraction but for now it avoids\ncircular imports.\n\nChange-Id: I3962202c07c4b2fbfc26f9776c8a5c96292ae199\n""}]",0,37691,c9de9f2b8da23538b82f23c724b482404d0ea916,8,5,1,1179,,,0,"Forklift the DiskFile interface into it's own module

 * new module swift.obj.diskfile

I parameterized two constants from obj.server into the DiskFile's __init__

 * DATADIR -> obj_dir
 * DISALLOWED_HEADERS -> disallowed_metadata_keys

I'm not sure if this is the right long term abstraction but for now it avoids
circular imports.

Change-Id: I3962202c07c4b2fbfc26f9776c8a5c96292ae199
",git fetch https://review.opendev.org/openstack/swift refs/changes/91/37691/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_auditor.py', 'swift/obj/server.py', 'swift/obj/auditor.py', 'test/unit/obj/test_server.py', 'test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py', 'test/probe/test_object_failures.py']",7,c9de9f2b8da23538b82f23c724b482404d0ea916,forklift-df,"from swift.obj.diskfile import write_metadata, read_metadata","from swift.obj.server import write_metadata, read_metadata",883,803
openstack%2Fpython-glanceclient~master~Ifbef582aa4e64a2e7a46db43a9cc6cf8c3531dbd,openstack/python-glanceclient,master,Ifbef582aa4e64a2e7a46db43a9cc6cf8c3531dbd,Pass all identity headers received to glance,MERGED,2013-07-15 14:26:17.000000000,2013-07-18 17:45:34.000000000,2013-07-18 17:45:33.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 7780}]","[{'number': 1, 'created': '2013-07-15 14:26:17.000000000', 'files': ['glanceclient/common/http.py', 'tests/test_http.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/95810ef1d2184b33902a56dfe7d14c12cb0869ef', 'message': 'Pass all identity headers received to glance\n\nThere is an upcoming patch in nova which passes identity\nheaders to glance client. We want to ensure that these get\npassed to glance, which in turn with help the no auth\noption in glance.\n\nResolves bug 1200761\n\nChange-Id: Ifbef582aa4e64a2e7a46db43a9cc6cf8c3531dbd\n'}]",0,37062,95810ef1d2184b33902a56dfe7d14c12cb0869ef,10,8,1,4463,,,0,"Pass all identity headers received to glance

There is an upcoming patch in nova which passes identity
headers to glance client. We want to ensure that these get
passed to glance, which in turn with help the no auth
option in glance.

Resolves bug 1200761

Change-Id: Ifbef582aa4e64a2e7a46db43a9cc6cf8c3531dbd
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/62/37062/1 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/common/http.py', 'tests/test_http.py']",2,95810ef1d2184b33902a56dfe7d14c12cb0869ef,bug/1200761," def test_identity_headers_and_token(self): identity_headers = { 'X-Auth-Token': 'auth_token', 'X-User-Id': 'user', 'X-Tenant-Id': 'tenant', 'X-Roles': 'roles', 'X-Identity-Status': 'Confirmed', 'X-Service-Catalog': 'service_catalog', } #with token kwargs = {'token': u'fake-token', 'identity_headers': identity_headers} http_client_object = http.HTTPClient(self.endpoint, **kwargs) self.assertEquals(http_client_object.auth_token, 'auth_token') self.assertTrue(http_client_object.identity_headers. get('X-Auth-Token') is None) def test_identity_headers_and_no_token_in_header(self): identity_headers = { 'X-User-Id': 'user', 'X-Tenant-Id': 'tenant', 'X-Roles': 'roles', 'X-Identity-Status': 'Confirmed', 'X-Service-Catalog': 'service_catalog', } #without X-Auth-Token in identity headers kwargs = {'token': u'fake-token', 'identity_headers': identity_headers} http_client_object = http.HTTPClient(self.endpoint, **kwargs) self.assertEquals(http_client_object.auth_token, u'fake-token') self.assertTrue(http_client_object.identity_headers. get('X-Auth-Token') is None) ",,42,0
openstack%2Fkeystone~master~I15ff67490acbbacc9eefc7eee253400475704b04,openstack/keystone,master,I15ff67490acbbacc9eefc7eee253400475704b04,Support token_format for backward compatibility,MERGED,2013-07-18 15:29:02.000000000,2013-07-18 17:45:27.000000000,2013-07-18 17:45:26.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5046}]","[{'number': 1, 'created': '2013-07-18 15:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c09726d44a81450bcab7eb7658dec5653fccf001', 'message': 'Support token_format for backward compatibility\n\nThe provider property in the [token] section will be unset by default. If\nprovider is not set, we will us token_format in the [signing] section to\ndetermine to provider. If provider is set, it must agree with the token_format.\n\nfixed bug 1202651\n\nChange-Id: I15ff67490acbbacc9eefc7eee253400475704b04\n'}, {'number': 2, 'created': '2013-07-18 16:07:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/06e373b9ffbc45f89130884bdf82cc69d8178c6b', 'message': 'Support token_format for backward compatibility\n\nThe provider property in the [token] section will be unset by default. If\nprovider is not set, we will us token_format in the [signing] section to\ndetermine to provider. If provider is set, it must agree with the token_format.\n\nfixed bug 1202651\n\nChange-Id: I15ff67490acbbacc9eefc7eee253400475704b04\n'}, {'number': 3, 'created': '2013-07-18 16:28:53.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/token/provider.py', 'keystone/common/config.py', 'tests/test_token_provider.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e63501d305c67b898821ad65ec744adf6851236a', 'message': 'Support token_format for backward compatibility\n\nThe provider property in the [token] section will be unset by default. If\nprovider is not set, we will use token_format in the [signing] section to\ndetermine to provider. If provider is set, it must agree with the token_format.\n\nfixed bug 1202651\n\nChange-Id: I15ff67490acbbacc9eefc7eee253400475704b04\n'}]",13,37702,e63501d305c67b898821ad65ec744adf6851236a,19,6,3,1916,,,0,"Support token_format for backward compatibility

The provider property in the [token] section will be unset by default. If
provider is not set, we will use token_format in the [signing] section to
determine to provider. If provider is set, it must agree with the token_format.

fixed bug 1202651

Change-Id: I15ff67490acbbacc9eefc7eee253400475704b04
",git fetch https://review.opendev.org/openstack/keystone refs/changes/02/37702/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/token/provider.py', 'keystone/common/config.py', 'tests/test_token_provider.py']",4,c09726d44a81450bcab7eb7658dec5653fccf001,bug/1202651," def test_default_token_format(self): self.assertEqual(token.provider.Manager.check_and_get_token_provider(), 'keystone.token.providers.pki.Provider') def test_uuid_token_format_and_no_provider(self): self.opt_in_group('signing', token_format='UUID') self.assertEqual(token.provider.Manager.check_and_get_token_provider(), 'keystone.token.providers.uuid.Provider') def test_unsupported_token_format(self): self.opt_in_group('signing', token_format='CUSTOM') self.assertRaises(ValueError, token.provider.Manager.check_and_get_token_provider) def test_provider_override_token_format(self): self.opt_in_group('token', provider='keystone.token.providers.pki.Test') self.assertRaises(ValueError, token.provider.Manager.check_and_get_token_provider) self.opt_in_group('signing', token_format='UUID') self.opt_in_group('token', provider='keystone.token.providers.uuid.Provider') self.assertEqual(token.provider.Manager.check_and_get_token_provider(), 'keystone.token.providers.uuid.Provider') self.opt_in_group('signing', token_format='PKI') self.opt_in_group('token', provider='keystone.token.providers.pki.Provider') self.assertEqual(token.provider.Manager.check_and_get_token_provider(), 'keystone.token.providers.pki.Provider') self.opt_in_group('signing', token_format='CUSTOM') self.opt_in_group('token', provider='my.package.MyProvider') self.assertEqual(token.provider.Manager.check_and_get_token_provider(), 'my.package.MyProvider')",,73,11
openstack%2Ftempest~master~Id0f9784a64f3bf53ea91a67452a78d17389d7f51,openstack/tempest,master,Id0f9784a64f3bf53ea91a67452a78d17389d7f51,run_stress.py -h doesn't work without a connection,MERGED,2013-07-16 06:59:56.000000000,2013-07-18 17:45:20.000000000,2013-07-18 17:45:20.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}, {'_account_id': 5997}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-07-16 06:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8a7cb8ac2bc3e2cfb433f5fb7d3194b5d9963358', 'message': ""run_stress.py -h doesn't work without a connection\n\nrun_stress.py tries to connect to openstack even though it's just a\n--help / -h call. Just moved the import to the corresponding function.\n\nChange-Id: Id0f9784a64f3bf53ea91a67452a78d17389d7f51\n""}, {'number': 2, 'created': '2013-07-17 06:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e9e828f9dc87aab974f88bed137523a9f3084a6d', 'message': ""run_stress.py -h doesn't work without a connection\n\nrun_stress.py tries to connect to openstack even though it's just a\n--help / -h call. Just moved the import to the corresponding function.\n\nImplements: blueprint stress-tests\n\nChange-Id: Id0f9784a64f3bf53ea91a67452a78d17389d7f51\n""}, {'number': 3, 'created': '2013-07-18 15:59:54.000000000', 'files': ['tempest/stress/run_stress.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/fa399e762404b49011b33ea89eb61d01d686ad66', 'message': ""run_stress.py -h doesn't work without a connection\n\nrun_stress.py tries to connect to openstack even though it's just a\n--help / -h call. Just moved the import to the corresponding function.\n\nImplements: blueprint stress-tests\n\nChange-Id: Id0f9784a64f3bf53ea91a67452a78d17389d7f51\n""}]",0,37180,fa399e762404b49011b33ea89eb61d01d686ad66,13,5,3,7872,,,0,"run_stress.py -h doesn't work without a connection

run_stress.py tries to connect to openstack even though it's just a
--help / -h call. Just moved the import to the corresponding function.

Implements: blueprint stress-tests

Change-Id: Id0f9784a64f3bf53ea91a67452a78d17389d7f51
",git fetch https://review.opendev.org/openstack/tempest refs/changes/80/37180/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/stress/run_stress.py'],1,8a7cb8ac2bc3e2cfb433f5fb7d3194b5d9963358,bp/stress-tests, from tempest.stress import driver,from tempest.stress import driver ,1,2
openstack%2Fmurano-deployment~master~I959da6319d6f3b70eabf52783fcea571cbc96fc5,openstack/murano-deployment,master,I959da6319d6f3b70eabf52783fcea571cbc96fc5,Insall-SqlServer sequence updated.,MERGED,2013-07-18 17:07:37.000000000,2013-07-18 17:11:12.000000000,2013-07-18 17:11:12.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-18 17:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/5f566da48c14f2282541a0a570f385bdf2bf5987', 'message': 'Insall-SqlServer sequence updated.\n\nA few fixes were added to run installaer from system service account.\n\nChange-Id: I959da6319d6f3b70eabf52783fcea571cbc96fc5\n'}, {'number': 2, 'created': '2013-07-18 17:10:43.000000000', 'files': ['ExecutionPlan/InstallSQL/ExecutionPlan.yaml.json', 'WindowsPowerShell/Functions/SQLServerOptionParsers.ps1', 'WindowsPowerShell/Functions/Install-SQLServer.ps1', 'WindowsPowerShell/Functions/OptionParser.ps1'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/d5f7356a2e4062e2c8085d63db317a4bb1777556', 'message': 'Insall-SqlServer sequence updated.\n\nA few fixes were added to run installaer from system service account.\n\nChange-Id: I959da6319d6f3b70eabf52783fcea571cbc96fc5\n'}]",0,37722,d5f7356a2e4062e2c8085d63db317a4bb1777556,7,2,2,7562,,,0,"Insall-SqlServer sequence updated.

A few fixes were added to run installaer from system service account.

Change-Id: I959da6319d6f3b70eabf52783fcea571cbc96fc5
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/22/37722/2 && git format-patch -1 --stdout FETCH_HEAD,"['ExecutionPlan/InstallSQL/ExecutionPlan.yaml.json', 'WindowsPowerShell/Functions/SQLServerOptionParsers.ps1', 'WindowsPowerShell/Functions/Install-SQLServer.ps1', 'WindowsPowerShell/Functions/OptionParser.ps1']",4,5f566da48c14f2282541a0a570f385bdf2bf5987,," Write-Log ""Executing: $($Binary.FullName) $($CommandLine -join ' ')"""," Write-Host ""Executing: $($Binary.FullName) $($CommandLine -join ' ')""",61,16
openstack%2Fsahara~master~Ia2f04a29681986b302bef69179d011497f2c9110,openstack/sahara,master,Ia2f04a29681986b302bef69179d011497f2c9110,Cluster scaling improvement,MERGED,2013-07-18 15:52:18.000000000,2013-07-18 17:03:25.000000000,2013-07-18 17:03:24.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-18 15:52:18.000000000', 'files': ['savanna/plugins/vanilla/scaling.py', 'savanna/service/instances.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/805a5810a67816155ccff7951a44e0b80d4c5273', 'message': 'Cluster scaling improvement\n\nAdd sleep for decommissioning\nUpdate cluster status with ""model_update""\n\nChange-Id: Ia2f04a29681986b302bef69179d011497f2c9110\n'}]",0,37707,805a5810a67816155ccff7951a44e0b80d4c5273,7,4,1,7478,,,0,"Cluster scaling improvement

Add sleep for decommissioning
Update cluster status with ""model_update""

Change-Id: Ia2f04a29681986b302bef69179d011497f2c9110
",git fetch https://review.opendev.org/openstack/sahara refs/changes/07/37707/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/plugins/vanilla/scaling.py', 'savanna/service/instances.py']",2,805a5810a67816155ccff7951a44e0b80d4c5273,scaling_new_version," context.model_update(cluster, status='Error') else: context.model_update(cluster, status='Active')", cluster.status = 'Error' else: cluster.status = 'Active',3,2
openstack%2Fheat~master~If2e0dd60e19073a0de2710f9e29d0116cdc367af,openstack/heat,master,If2e0dd60e19073a0de2710f9e29d0116cdc367af,Rename quantum to neutron in heat,ABANDONED,2013-07-18 16:33:55.000000000,2013-07-18 16:59:21.000000000,,[{'_account_id': 7385}],"[{'number': 1, 'created': '2013-07-18 16:33:55.000000000', 'files': ['heat/engine/resources/route_table.py', 'README.rst', 'heat/engine/resources/instance.py', 'heat/tests/test_security_group.py', 'heat/engine/resources/security_group.py', 'requirements.txt', 'heat/engine/resources/subnet.py', 'heat/tests/templates/Neutron.template', 'heat/engine/resources/neutron/port.py', 'heat/engine/resources/rackspace/rackspace_resource.py', 'heat/engine/resources/neutron/subnet.py', 'heat/tests/test_vpc.py', 'heat/engine/resources/network_interface.py', 'heat/engine/resources/neutron/floatingip.py', 'heat/engine/resources/neutron/net.py', 'heat/engine/resources/neutron/__init__.py', 'heat/engine/clients.py', 'heat/tests/templates/Neutron.yaml', 'heat/engine/resources/internet_gateway.py', 'heat/engine/resources/neutron/neutron.py', 'heat/tests/test_template_format.py', 'heat/tests/test_quantum.py', 'heat/engine/resources/neutron/router.py', 'heat/tests/test_instance_network.py', 'heat/engine/resource.py', 'heat/engine/resources/vpc.py', 'doc/docbkx/heat-cli-guide/src/heat_cli_howto.xml'], 'web_link': 'https://opendev.org/openstack/heat/commit/faa3c40356a54799162e1645fbfecc2a17f4c898', 'message': 'Rename quantum to neutron in heat\n\nRelated to blueprint: remove-use-of-quantum\nFixes bug 1174005\n\nChange-Id: If2e0dd60e19073a0de2710f9e29d0116cdc367af\n'}]",0,37714,faa3c40356a54799162e1645fbfecc2a17f4c898,2,1,1,6873,,,0,"Rename quantum to neutron in heat

Related to blueprint: remove-use-of-quantum
Fixes bug 1174005

Change-Id: If2e0dd60e19073a0de2710f9e29d0116cdc367af
",git fetch https://review.opendev.org/openstack/heat refs/changes/14/37714/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/route_table.py', 'README.rst', 'heat/engine/resources/instance.py', 'heat/tests/test_security_group.py', 'heat/engine/resources/security_group.py', 'requirements.txt', 'heat/engine/resources/subnet.py', 'heat/tests/templates/Neutron.template', 'heat/engine/resources/neutron/port.py', 'heat/engine/resources/rackspace/rackspace_resource.py', 'heat/engine/resources/neutron/subnet.py', 'heat/tests/test_vpc.py', 'heat/engine/resources/network_interface.py', 'heat/engine/resources/neutron/floatingip.py', 'heat/engine/resources/neutron/net.py', 'heat/engine/resources/neutron/__init__.py', 'heat/engine/clients.py', 'heat/tests/templates/Neutron.yaml', 'heat/engine/resources/internet_gateway.py', 'heat/engine/resources/neutron/neutron.py', 'heat/tests/test_template_format.py', 'heat/tests/test_quantum.py', 'heat/engine/resources/neutron/router.py', 'heat/tests/test_instance_network.py', 'heat/engine/resource.py', 'heat/engine/resources/vpc.py', 'doc/docbkx/heat-cli-guide/src/heat_cli_howto.xml']",27,faa3c40356a54799162e1645fbfecc2a17f4c898,rename-quantum-to-neutron," xml:id=""neutron-cli-reference"">"," xml:id=""quantum-cli-reference"">",433,433
openstack%2Fcinder~master~Ic8d4a398f57d751f1ceae0d0b0b08d76093ebfc3,openstack/cinder,master,Ic8d4a398f57d751f1ceae0d0b0b08d76093ebfc3,Unpin keystoneclient (bug 1194921),ABANDONED,2013-07-05 17:18:47.000000000,2013-07-18 16:45:49.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}]","[{'number': 1, 'created': '2013-07-05 17:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/515b94ddfb795d7945805876fbb65085aae842f5', 'message': 'Unpin keystoneclient (bug 1194921)\n\nChange-Id: Ic8d4a398f57d751f1ceae0d0b0b08d76093ebfc3\n'}, {'number': 2, 'created': '2013-07-05 17:18:47.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0c252f0de9f95ce6fec334680fe99a1655b5a807', 'message': 'Unpin keystoneclient (bug 1194921)\n\nChange-Id: Ic8d4a398f57d751f1ceae0d0b0b08d76093ebfc3\n'}]",0,35844,0c252f0de9f95ce6fec334680fe99a1655b5a807,9,3,2,4,,,0,"Unpin keystoneclient (bug 1194921)

Change-Id: Ic8d4a398f57d751f1ceae0d0b0b08d76093ebfc3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/44/35844/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,515b94ddfb795d7945805876fbb65085aae842f5,bug/1194921,python-keystoneclient>=0.2,"python-keystoneclient>=0.2,<0.3",1,1
openstack%2Foslo-incubator~master~I898afac5d306b424e28451606189dcb2e36b7234,openstack/oslo-incubator,master,I898afac5d306b424e28451606189dcb2e36b7234,Adds virtualenv flag to sample config file generator,ABANDONED,2013-07-16 17:14:52.000000000,2013-07-18 16:42:52.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-16 17:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/47221a71d37a4ef188888bcafe67f47e74f2c2cb', 'message': 'tmp\n\nChange-Id: I898afac5d306b424e28451606189dcb2e36b7234\n'}, {'number': 2, 'created': '2013-07-17 00:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/585105c7d3d9ab02c44c53df468075f336e9f3a4', 'message': 'tmp\n\nChange-Id: I898afac5d306b424e28451606189dcb2e36b7234\n'}, {'number': 3, 'created': '2013-07-17 04:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d2dcb7b52e7343abea25d40a4c21d8244237439e', 'message': 'Use virtualenv when generating sample config files\n\nNow that the generator file is placed in Oslo, sample files of all projects\nwould be generated in one machine. This patch prevents from contaminating\nthe global python path with dependencies of all projects by creating\na virtualenv.\n\nChange-Id: I898afac5d306b424e28451606189dcb2e36b7234\n'}, {'number': 4, 'created': '2013-07-18 03:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d60e17db6257e28822bb7eaa579e5ec1117be53d', 'message': 'Adds virtualenv flag to sample config file generator\n\nThe standard way to create sample config files for each project is to\nrun the generate_sample.sh file under each projects virtualenv created by\ntox or run_tests.sh. However this method has problems with projects\nusing openstack.nose because the openstack package from openstack.nose will\nshadow the openstack package located in the base directory of oslo-incubator.\nThis patch provides a flag to enable virtualenv creation on oslo to avoid\nthese kind of problem.\n\nChange-Id: I898afac5d306b424e28451606189dcb2e36b7234\n'}, {'number': 5, 'created': '2013-07-18 04:26:51.000000000', 'files': ['tools/config/generate_sample.sh'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/872c8a36fb52bb0ee5a549e4975fe9a21d010cba', 'message': 'Adds virtualenv flag to sample config file generator\n\nThe standard way to create the sample config file for each project\nis to run the generate_sample.sh file under each project\'s virtualenv\ncreated by tox or run_tests.sh. However this method has a problem\nwith projects using openstack.nose because the ""openstack"" package\nfrom openstack.nose will shadow the ""openstack"" package located\nin the base directory of oslo-incubator since the virtualenv\nhas higher priority. This patch provides a flag to enable virtualenv\ncreation on oslo to avoid this problem.\n\nChange-Id: I898afac5d306b424e28451606189dcb2e36b7234\n'}]",0,37292,872c8a36fb52bb0ee5a549e4975fe9a21d010cba,20,5,5,1994,,,0,"Adds virtualenv flag to sample config file generator

The standard way to create the sample config file for each project
is to run the generate_sample.sh file under each project's virtualenv
created by tox or run_tests.sh. However this method has a problem
with projects using openstack.nose because the ""openstack"" package
from openstack.nose will shadow the ""openstack"" package located
in the base directory of oslo-incubator since the virtualenv
has higher priority. This patch provides a flag to enable virtualenv
creation on oslo to avoid this problem.

Change-Id: I898afac5d306b424e28451606189dcb2e36b7234
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/92/37292/4 && git format-patch -1 --stdout FETCH_HEAD,['tools/config/generate_sample.sh'],1,47221a71d37a4ef188888bcafe67f47e74f2c2cb,confgen_venv,"VENV=.update-venv # -qq gets rid of the deprecation warning, in time we can # remove --no-site-packages as it's the default now [ -d $VENV ] || virtualenv -qq --no-site-packages $VENV . $VENV/bin/activate # need oslo-config for bootstrapping, be quiet for UX reasons pip install -r $BASEDIR/requirements.txt ",,11,0
openstack%2Fnova~master~Iacc42d8e0cab218258c3029d5395e02fddb75197,openstack/nova,master,Iacc42d8e0cab218258c3029d5395e02fddb75197,Disable ssl layer compression for glance requests.,MERGED,2013-06-11 12:53:53.000000000,2013-07-18 16:32:19.000000000,2013-07-18 16:32:16.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 455}, {'_account_id': 679}, {'_account_id': 1007}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5652}, {'_account_id': 6896}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-06-11 12:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b63258e6fa6db89cf3555bfc570e99d00b20b074', 'message': ""Allow disabling ssl compression for glance client\n\nAdd a new parameter 'glance_api_ssl_compression' which allows\ndisabling ssl layer compression negotiation for glance requests.\n\nThis may improve data throughput, eg when high network bandwidth is\navailable and you are using already compressed image formats such as\nqcow2 .\n\nAddresses bug 1189887.\n\nChange-Id: Iacc42d8e0cab218258c3029d5395e02fddb75197\n""}, {'number': 2, 'created': '2013-06-17 11:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea9bb364eec05be55b72c06ea6477511ad7c3df7', 'message': ""Allow disabling ssl compression for glance client\n\nAdd a new parameter 'glance_api_ssl_compression' which allows\ndisabling ssl layer compression negotiation for glance requests.\n\nThis may improve data throughput, eg when high network bandwidth is\navailable and you are using already compressed image formats such as\nqcow2 .\n\nAddresses bug 1189887. DocImpact.\n\nChange-Id: Iacc42d8e0cab218258c3029d5395e02fddb75197\n""}, {'number': 3, 'created': '2013-07-17 15:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b14f6748895682ea6d0435aa3e0d99b61ba54a1', 'message': ""Allow disabling ssl compression for glance client\n\nAdd a new parameter 'glance_api_ssl_compression' which allows\ndisabling ssl layer compression negotiation for glance requests.\n\nThis may improve data throughput, eg when high network bandwidth is\navailable and you are using already compressed image formats such as\nqcow2 .\n\nAddresses bug 1189887.\n\nDocImpact.\n\nChange-Id: Iacc42d8e0cab218258c3029d5395e02fddb75197\n""}, {'number': 4, 'created': '2013-07-17 15:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/394c3740e199161bced9f166c8bf2a7eb0aab935', 'message': 'Disable ssl layer compression for glance requests.\n\nThis may improve data throughput, eg when high network bandwidth is\navailable and you are using already compressed image formats such as\nqcow2 .\n\nAddresses bug 1189887.\n\nDocImpact.\n\nChange-Id: Iacc42d8e0cab218258c3029d5395e02fddb75197\n'}, {'number': 5, 'created': '2013-07-17 16:02:17.000000000', 'files': ['nova/image/glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/583addcac70fdb02c8101c8aeeb1949f39be2225', 'message': 'Disable ssl layer compression for glance requests.\n\nThis may improve data throughput, eg when high network bandwidth is\navailable and you are using already compressed image formats such as\nqcow2 .\n\nAddresses bug 1189887.\n\nChange-Id: Iacc42d8e0cab218258c3029d5395e02fddb75197\n'}]",9,32562,583addcac70fdb02c8101c8aeeb1949f39be2225,52,12,5,455,,,0,"Disable ssl layer compression for glance requests.

This may improve data throughput, eg when high network bandwidth is
available and you are using already compressed image formats such as
qcow2 .

Addresses bug 1189887.

Change-Id: Iacc42d8e0cab218258c3029d5395e02fddb75197
",git fetch https://review.opendev.org/openstack/nova refs/changes/62/32562/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/nova/nova.conf.sample', 'nova/image/glance.py']",2,b63258e6fa6db89cf3555bfc570e99d00b20b074,bug/1189887," cfg.BoolOpt('glance_api_ssl_compression', default=False, help='Whether to attempt to negotiate SSL layer compression ' 'when using SSL (https) requests. Set to False to ' 'disable SSL layer compression. In some cases disabling ' 'this may improve data throughput, eg when high network ' 'bandwidth is available and you are using already ' 'compressed image formats such as qcow2 .'), params = {} # https specific params params['insecure'] = CONF.glance_api_insecure params['ssl_compression'] = CONF.glance_api_ssl_compression", params = {} params['insecure'] = CONF.glance_api_insecure,20,2
openstack%2Fnova~master~Id699135a8ec4c603671b16f0127d0b2cd2a55855,openstack/nova,master,Id699135a8ec4c603671b16f0127d0b2cd2a55855,xenapi: no glance upload retry on 401 error,MERGED,2013-07-09 17:53:22.000000000,2013-07-18 16:24:52.000000000,2013-07-18 16:24:50.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 475}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 2166}, {'_account_id': 2537}, {'_account_id': 4463}, {'_account_id': 5044}, {'_account_id': 5441}, {'_account_id': 7780}]","[{'number': 1, 'created': '2013-07-09 17:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14402bf6861b89d4129960bf25fbd08785e3502f', 'message': 'xenapi: no glance upload retry on 401 error\n\nIt is possible for a token to expire during a very long image upload.\nIf this happens, there is little point in retrying the upload, as it\nis most likely to fail again for the same reason.\n\nFixes bug 1199454\n\nChange-Id: Id699135a8ec4c603671b16f0127d0b2cd2a55855\n'}, {'number': 3, 'created': '2013-07-09 17:56:16.000000000', 'files': ['plugins/xenserver/xenapi/etc/xapi.d/plugins/glance'], 'web_link': 'https://opendev.org/openstack/nova/commit/8e81e069a18e09562abfc4b18c5c7e57020aee66', 'message': 'xenapi: no glance upload retry on 401 error\n\nIt is possible for a token to expire during a very long image upload.\nIf this happens, there is little point in retrying the upload, as it\nis most likely to fail again for the same reason.\n\nFixes bug 1199454\n\nChange-Id: Id699135a8ec4c603671b16f0127d0b2cd2a55855\n'}, {'number': 2, 'created': '2013-07-09 17:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74b0671c3e5d5e7f8335798e131676a65c850104', 'message': 'xenapi: no glance upload retry on 401 error\n\nIt is possible for a token to expire during a very long image upload.\nIf this happens, there is little point in retrying the upload, as it\nis most likely to fail again for the same reason.\n\nFixes bug 1199454\n\nChange-Id: Id699135a8ec4c603671b16f0127d0b2cd2a55855\n'}]",4,36308,8e81e069a18e09562abfc4b18c5c7e57020aee66,27,11,3,782,,,0,"xenapi: no glance upload retry on 401 error

It is possible for a token to expire during a very long image upload.
If this happens, there is little point in retrying the upload, as it
is most likely to fail again for the same reason.

Fixes bug 1199454

Change-Id: Id699135a8ec4c603671b16f0127d0b2cd2a55855
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/36308/1 && git format-patch -1 --stdout FETCH_HEAD,['plugins/xenserver/xenapi/etc/xapi.d/plugins/glance'],1,14402bf6861b89d4129960bf25fbd08785e3502f,bug/1199454," if resp.status == httplib.OK: return logging.error(""Unexpected response while writing image data to %s: "" ""Response Status: %i, Response body: %s"" % (url, resp.status, resp.read())) if resp.status == httplib.UNAUTHORIZED # NOTE(johngarbutt): little point in retrying when token invalid raise PluginError(""Unauthorized error while uploading "" ""image [%s] "" ""to glance host [%s:%s]"" % (image_id, glance_host, glance_port)) else:"," if resp.status != httplib.OK: logging.error(""Unexpected response while writing image data to %s: "" ""Response Status: %i, Response body: %s"" % (url, resp.status, resp.read()))",14,4
openstack%2Fnova~master~I86df10a4ce1fc88e7dd47764e4ea0cdeababd389,openstack/nova,master,I86df10a4ce1fc88e7dd47764e4ea0cdeababd389,Remove unnecessary comments for instance rebuild tests.,MERGED,2013-07-17 07:48:13.000000000,2013-07-18 16:24:32.000000000,2013-07-18 16:24:30.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1501}, {'_account_id': 1812}, {'_account_id': 2069}, {'_account_id': 2166}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-07-17 07:48:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f2aca96ad1cb20905d8cb45539ad97f4e65f4f6', 'message': ""Fix typo for test_rebuild() method.\n\nThis method is actually for rebuilding instance in 'active' status.\n\nChange-Id: I86df10a4ce1fc88e7dd47764e4ea0cdeababd389\n""}, {'number': 2, 'created': '2013-07-17 14:11:44.000000000', 'files': ['nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c8c048b20dfe30df90cec4d6b163093699a4562b', 'message': 'Remove unnecessary comments for instance rebuild tests.\n\nJust remove the unnecessary comments which may be confused.\n\nChange-Id: I86df10a4ce1fc88e7dd47764e4ea0cdeababd389\n'}]",0,37417,c8c048b20dfe30df90cec4d6b163093699a4562b,14,7,2,2069,,,0,"Remove unnecessary comments for instance rebuild tests.

Just remove the unnecessary comments which may be confused.

Change-Id: I86df10a4ce1fc88e7dd47764e4ea0cdeababd389
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/37417/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/compute/test_compute.py'],1,9f2aca96ad1cb20905d8cb45539ad97f4e65f4f6,uptream_devel, # Test we can rebuild an instance in the Active State, # Test we can rebuild an instance in the Error State,1,1
openstack%2Fnova~master~I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50,openstack/nova,master,I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50,Create key manager interface,MERGED,2013-05-30 00:00:06.000000000,2013-07-18 16:24:11.000000000,2013-07-18 16:24:09.000000000,"[{'_account_id': 3}, {'_account_id': 428}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1007}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2417}, {'_account_id': 4992}, {'_account_id': 6783}, {'_account_id': 6802}, {'_account_id': 6804}, {'_account_id': 7063}, {'_account_id': 7354}, {'_account_id': 7370}, {'_account_id': 7747}, {'_account_id': 7764}, {'_account_id': 7789}]","[{'number': 1, 'created': '2013-05-30 00:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4501821c9728dcb1f7a741b70537ffa03e3e53a0', 'message': 'Create key manager interface\n\nThe key manager interface is used by the volume encryption code to retrieve\nkeys for volumes.\n\nImplements: blueprint encrypt-cinder-volumes\nChange-Id: I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50\nSecurityImpact\n'}, {'number': 2, 'created': '2013-06-21 15:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab0b6fa93efa16eea80a3f4a3817794420d5415f', 'message': 'Create key manager interface\n\nThis interface provides a thin wrapper around an underlying key management\nimplementation such as Barbican or a KMIP server. The key manager interface is\nused by the volume encryption code to retrieve keys for volumes.\n\nImplements: blueprint encrypt-cinder-volumes\nChange-Id: I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50\nSecurityImpact\n'}, {'number': 3, 'created': '2013-06-28 17:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95649f5ad28fa3fad6950964f93abc2795bbf7bf', 'message': 'Create key manager interface\n\nThis interface provides a thin wrapper around an underlying key management\nimplementation such as Barbican or a KMIP server. The key manager interface is\nused by the volume encryption code to retrieve keys for volumes.\n\nImplements: blueprint encrypt-cinder-volumes\nChange-Id: I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50\nSecurityImpact\n'}, {'number': 4, 'created': '2013-07-08 15:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/123611b45b472ee20fd3bae4cf240f4db704e84e', 'message': 'Create key manager interface\n\nThis interface provides a thin wrapper around an underlying key management\nimplementation such as Barbican or a KMIP server. The key manager interface is\nused by the volume encryption code to retrieve keys for volumes.\n\nImplements: blueprint encrypt-cinder-volumes\nChange-Id: I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50\nSecurityImpact\n'}, {'number': 5, 'created': '2013-07-16 13:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d92b06b468cce49962d678d08d521597d5faa25f', 'message': 'Create key manager interface\n\nThis interface provides a thin wrapper around an underlying key management\nimplementation such as Barbican or a KMIP server. The key manager interface is\nused by the volume encryption code to retrieve keys for volumes.\n\nImplements: blueprint encrypt-cinder-volumes\nChange-Id: I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50\nSecurityImpact\n'}, {'number': 6, 'created': '2013-07-17 13:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c365135c1cdd335de4a78bb0fc5307d403cd442', 'message': 'Create key manager interface\n\nThis interface provides a thin wrapper around an underlying key management\nimplementation such as Barbican or a KMIP server. The key manager interface is\nused by the volume encryption code to retrieve keys for volumes.\n\nImplements: blueprint encrypt-cinder-volumes\nChange-Id: I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50\nSecurityImpact\n'}, {'number': 7, 'created': '2013-07-17 19:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e8185e41dee9e39344af92a13aef5a26eb0ed81', 'message': 'Create key manager interface\n\nThis interface provides a thin wrapper around an underlying key management\nimplementation such as Barbican or a KMIP server. The key manager interface is\nused by the volume encryption code to retrieve keys for volumes.\n\nImplements: blueprint encrypt-cinder-volumes\nChange-Id: I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50\nSecurityImpact\n'}, {'number': 8, 'created': '2013-07-17 21:18:18.000000000', 'files': ['nova/tests/keymgr/mock_key_mgr.py', 'nova/tests/keymgr/test_key_mgr.py', 'nova/tests/keymgr/__init__.py', 'nova/keymgr/__init__.py', 'nova/tests/keymgr/test_key.py', 'nova/keymgr/key_mgr.py', 'nova/keymgr/key.py', 'nova/tests/keymgr/test_mock_key_mgr.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fc8cb355db01032d808608d991ca04fa5f008286', 'message': 'Create key manager interface\n\nThis interface provides a thin wrapper around an underlying key management\nimplementation such as Barbican or a KMIP server. The key manager interface is\nused by the volume encryption code to retrieve keys for volumes.\n\nImplements: blueprint encrypt-cinder-volumes\nChange-Id: I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50\nSecurityImpact\n'}]",24,30973,fc8cb355db01032d808608d991ca04fa5f008286,56,18,8,6802,,,0,"Create key manager interface

This interface provides a thin wrapper around an underlying key management
implementation such as Barbican or a KMIP server. The key manager interface is
used by the volume encryption code to retrieve keys for volumes.

Implements: blueprint encrypt-cinder-volumes
Change-Id: I9b0dcb7d648ee6809185c71ba457c8a8a6c90d50
SecurityImpact
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/30973/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/keymgr/mock_key_mgr.py', 'nova/tests/keymgr/__init__.py', 'nova/keymgr/__init__.py', 'nova/keymgr/key_mgr.py', 'nova/keymgr/key.py', 'nova/tests/keymgr/test_mock_key_mgr.py']",6,4501821c9728dcb1f7a741b70537ffa03e3e53a0,bp/encrypt-cinder-volumes,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (c) 2013 The Johns Hopkins University/Applied Physics Laboratory # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import array from nova import context from nova import exception from nova.keymgr import key from nova import test from nova.tests.keymgr import mock_key_mgr """""" Test cases for the mock key manager. """""" class MockKeyManagerTestCase(test.TestCase): def setUp(self): super(MockKeyManagerTestCase, self).setUp() self.key_mgr = mock_key_mgr.MockKeyManager() self.ctxt = context.RequestContext('fake', 'fake') self.key_id = '00000000-0000-0000-0000-000000000000' self.key = key.SymmetricKey('AES', array.array('B', ('0' * 64).decode(""hex"")).tolist()) def test_create_key(self): key_id = self.key_mgr.create_key(self.ctxt) self.assertEquals(self.key_id, key_id) def test_create_null_context(self): self.assertRaises(exception.NotAuthorized, self.key_mgr.create_key, None) def test_get_key(self): key = self.key_mgr.get_key(self.ctxt, self.key_id) self.assertEquals(self.key.get_encoded(), key.get_encoded()) def test_get_null_context(self): self.assertRaises(exception.NotAuthorized, self.key_mgr.get_key, None, self.key_id) def test_get_unknown_key(self): self.assertRaises(KeyError, self.key_mgr.get_key, self.ctxt, '00000000-0000-0000-0000-000000000001') def test_delete_key(self): self.key_mgr.delete_key(self.ctxt, self.key_id) def test_delete_null_context(self): self.assertRaises(exception.NotAuthorized, self.key_mgr.delete_key, None, self.key_id) def test_delete_unknown_key(self): self.assertRaises(KeyError, self.key_mgr.delete_key, self.ctxt, '00000000-0000-0000-0000-000000000001') ",,351,0
openstack%2Foslo-incubator~master~Ib7074cf3777529afb8f100da1dc87516b4cd8011,openstack/oslo-incubator,master,Ib7074cf3777529afb8f100da1dc87516b4cd8011,Add decorator to make ABCs out of classes.,ABANDONED,2013-07-18 01:09:15.000000000,2013-07-18 16:22:31.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6944}]","[{'number': 1, 'created': '2013-07-18 01:09:15.000000000', 'files': ['openstack/common/abcutils.py', 'tests/unit/test_abcutils.py', 'tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/7f58fd0c0f8ea871e62175772f5efe098cf3be95', 'message': 'Add decorator to make ABCs out of classes.\n\nRationale:\n\nCreating abstract base classes in a way that works correctly for both\nPython 2 and Python 3 has not yet been addressed. This module adds a\nsimple decorator that can be applied to any class and sets the\nmetaclass of that class to be abc.ABCMeta.\n\nTests are provided that demonstrate expected behavior for all\nsupported platforms.\n\n*Note*: Running the tests on Python 3 took some finagling. I had to:\n\n1. Create a py3.3 virtualenv\n2. Removes several deps from requirements.txt and test-requirements.txt\n3. Install nose.\n4. Run `nose tests/unit/test_abcutils`\n\nUntil python 3 is working for all of the oslo dependencies, running\nautomated tests on abcutils is going to be a challenge.\n\nChange-Id: Ib7074cf3777529afb8f100da1dc87516b4cd8011\n'}]",0,37599,7f58fd0c0f8ea871e62175772f5efe098cf3be95,5,3,1,6944,,,0,"Add decorator to make ABCs out of classes.

Rationale:

Creating abstract base classes in a way that works correctly for both
Python 2 and Python 3 has not yet been addressed. This module adds a
simple decorator that can be applied to any class and sets the
metaclass of that class to be abc.ABCMeta.

Tests are provided that demonstrate expected behavior for all
supported platforms.

*Note*: Running the tests on Python 3 took some finagling. I had to:

1. Create a py3.3 virtualenv
2. Removes several deps from requirements.txt and test-requirements.txt
3. Install nose.
4. Run `nose tests/unit/test_abcutils`

Until python 3 is working for all of the oslo dependencies, running
automated tests on abcutils is going to be a challenge.

Change-Id: Ib7074cf3777529afb8f100da1dc87516b4cd8011
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/99/37599/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/abcutils.py', 'tests/__init__.py', 'tests/unit/test_abcutils.py']",3,7f58fd0c0f8ea871e62175772f5efe098cf3be95,py3k_abc,"# Copyright (c) 2013 Openstack Foundation. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import abc import unittest from openstack.common import abcutils @abcutils.abstractbase class MetaX(object): @abc.abstractproperty def x(self): raise NotImplementedError() @abc.abstractmethod def morex(self): raise NotImplementedError() class GoodX(MetaX): def __init__(self, x): self._x = x @property def x(self): return self._x def morex(self): self._x += 1 class BadX(MetaX): pass class AbcUtilsGoodClassTest(unittest.TestCase): def setUp(self): super(AbcUtilsGoodClassTest, self).setUp() self.obj = GoodX(1) def test_object_type_matches_base_class(self): self.assertTrue(type(self.obj) is GoodX) def test_derived_class_is_subclass_of_abc(self): self.assertTrue(issubclass(GoodX, MetaX)) def test_object_is_instance_of_derived_class(self): self.assertTrue(isinstance(self.obj, GoodX)) def test_derived_class_hasattr_register(self): self.assertTrue(hasattr(GoodX, 'register')) class AbcUtilsBadClassTest(unittest.TestCase): def test_non_conforming_child_raises_type_error(self): self.assertRaises(TypeError, BadX) ",,118,1
openstack%2Fmurano-dashboard~master~I005f2e8fa7e3b1dd3069b26e8aeb1d6f726b9bde,openstack/murano-dashboard,master,I005f2e8fa7e3b1dd3069b26e8aeb1d6f726b9bde,Disable input field sa_password when mexedAuth is off,MERGED,2013-07-18 15:02:33.000000000,2013-07-18 15:49:20.000000000,2013-07-18 15:49:20.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7549}]","[{'number': 1, 'created': '2013-07-18 15:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/9a5ab854f5bf138dd281fdcd768d192f9f7370a7', 'message': 'Disable sa_password when mexedAuth is off\n\nChange-Id: I005f2e8fa7e3b1dd3069b26e8aeb1d6f726b9bde\n'}, {'number': 2, 'created': '2013-07-18 15:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/513fbf978eef95d51b34c70cddf7b7a9e67f09a9', 'message': 'Disable sa_password when mexedAuth is off\n\nChange-Id: I005f2e8fa7e3b1dd3069b26e8aeb1d6f726b9bde\n'}, {'number': 3, 'created': '2013-07-18 15:34:08.000000000', 'files': ['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/forms.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/0847cc0bd9b29efc54c6be935b76bc8bdd1850f0', 'message': 'Disable input field sa_password when mexedAuth is off\n\nChange-Id: I005f2e8fa7e3b1dd3069b26e8aeb1d6f726b9bde\n'}]",0,37693,0847cc0bd9b29efc54c6be935b76bc8bdd1850f0,10,3,3,7549,,,0,"Disable input field sa_password when mexedAuth is off

Change-Id: I005f2e8fa7e3b1dd3069b26e8aeb1d6f726b9bde
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/93/37693/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/forms.py']",3,9a5ab854f5bf138dd281fdcd768d192f9f7370a7,disable_sa_if_checked," initial=True, if not mixed_mode: for i in xrange(1, 3, 1): self.fields['password_field' + str(i)].required = False if self.errors.get('password_field'+str(i)): del self.errors['password_field' + str(i)] "," required=False, required=False, if mixed_mode: self.fields['password_field'].required = True",25,11
openstack%2Fsahara~master~I4d6969d1d3a18b20347582efcf535483da400c13,openstack/sahara,master,I4d6969d1d3a18b20347582efcf535483da400c13,Cluster scaling bug fixing,MERGED,2013-07-18 12:40:40.000000000,2013-07-18 15:43:21.000000000,2013-07-18 15:43:21.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7213}, {'_account_id': 7478}]","[{'number': 1, 'created': '2013-07-18 12:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d6b1fdd012dfb2c3257878d715422fd897c684ce', 'message': 'Cluster scaling bug fixing\n\nBesides the bug it fixes unit tests\n\nFixes: bug #1202622\n\nChange-Id: I4d6969d1d3a18b20347582efcf535483da400c13\n'}, {'number': 2, 'created': '2013-07-18 13:23:34.000000000', 'files': ['savanna/plugins/vanilla/scaling.py', 'savanna/plugins/vanilla/plugin.py', 'savanna/tests/unit/plugins/test_dfsadmin_parsing.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/b876b5de00e63d2a4e094261742d6ef21bd529ad', 'message': 'Cluster scaling bug fixing\n\nBesides the bug it fixes unit tests\n\nFixes: bug #1202622\n\nChange-Id: I4d6969d1d3a18b20347582efcf535483da400c13\n'}]",3,37672,b876b5de00e63d2a4e094261742d6ef21bd529ad,11,5,2,7478,,,0,"Cluster scaling bug fixing

Besides the bug it fixes unit tests

Fixes: bug #1202622

Change-Id: I4d6969d1d3a18b20347582efcf535483da400c13
",git fetch https://review.opendev.org/openstack/sahara refs/changes/72/37672/2 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/plugins/vanilla/scaling.py', 'savanna/plugins/vanilla/plugin.py', 'savanna/tests/unit/plugins/test_dfsadmin_parsing.py']",3,d6b1fdd012dfb2c3257878d715422fd897c684ce,bug/1202622, big_string = '' while True: c = ins.read(1) big_string += c if not c: break res = sc.parse_dfs_report(big_string) big_string = '' while True: c = ins.read(1) big_string += c if not c: break res = sc.parse_dfs_report(big_string) big_string = '' while True: c = ins.read(1) big_string += c if not c: break res = sc.parse_dfs_report(big_string), array = [] for line in ins: array.append(line) res = sc.parse_dfs_report(array) array = [] for line in ins: array.append(line) res = sc.parse_dfs_report(array) array = [] for line in ins: array.append(line) res = sc.parse_dfs_report(array),42,28
openstack%2Fmurano-deployment~master~I2b53418e740cbf5635f076dcb1a463c61a22a415,openstack/murano-deployment,master,I2b53418e740cbf5635f076dcb1a463c61a22a415,InstallSQL execution plan updated.,MERGED,2013-07-18 14:46:01.000000000,2013-07-18 15:04:35.000000000,2013-07-18 15:04:35.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-18 14:46:01.000000000', 'files': ['ExecutionPlan/InstallSQL/ExecutionPlan.yaml.json', 'WindowsPowerShell/Functions/Install-SQLServer.ps1'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/46e84f80290a0b62e7ac512d71b7a07dc256947b', 'message': 'InstallSQL execution plan updated.\n\nChange-Id: I2b53418e740cbf5635f076dcb1a463c61a22a415\n'}]",0,37688,46e84f80290a0b62e7ac512d71b7a07dc256947b,5,2,1,7562,,,0,"InstallSQL execution plan updated.

Change-Id: I2b53418e740cbf5635f076dcb1a463c61a22a415
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/88/37688/1 && git format-patch -1 --stdout FETCH_HEAD,"['ExecutionPlan/InstallSQL/ExecutionPlan.yaml.json', 'WindowsPowerShell/Functions/Install-SQLServer.ps1']",2,46e84f80290a0b62e7ac512d71b7a07dc256947b,install-sqlserver-fix," [String] $MixedModeAuth = $false try { $MixedModeAuth = [System.Convert]::ToBoolean($MixedModeAuth) } catch { $MixedModeAuth = $false } if ($SAPassword -eq '') { throw(""SAPassword must be set when MixedModeAuth is requisted!"") }", [Boolean] $MixedModeAuth = $false,11,2
openstack%2Fapi-site~master~I2840aa69d85e515689346cbf43423723850fe96f,openstack/api-site,master,I2840aa69d85e515689346cbf43423723850fe96f,Add Neutron chapter to API reference page,MERGED,2013-07-12 18:14:13.000000000,2013-07-18 15:04:35.000000000,2013-07-18 15:04:35.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 6414}]","[{'number': 1, 'created': '2013-07-12 18:14:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/89e5f5b96fb2085b468a68cafd3e063edd94a2ef', 'message': 'Add Neutron chapter to API reference page\n\nAll wadls and samples were there, just needed to modify the\napi-ref.xml file to show new sections.\nBuilds OK locally.\n\nFixes bug 1200718\n\nChange-Id: I2840aa69d85e515689346cbf43423723850fe96f\n'}, {'number': 2, 'created': '2013-07-12 18:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/2c1809fec4bc0060746228303340d9da58a6a8d7', 'message': ""Add Neutron chapter to API reference page\n\nAll wadls and samples were there, just needed to modify the\napi-ref.xml file to show new sections. Also replaced 'quantum'\n instances to 'neutron'.\nBuilds OK locally.\n\nFixes bug 1200718\n\nChange-Id: I2840aa69d85e515689346cbf43423723850fe96f\n""}, {'number': 3, 'created': '2013-07-17 20:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/7cf5d23979506385ea568fd596ae68e34283d843', 'message': ""Add Neutron chapter to API reference page\n\nAll wadls and samples were there, just needed to modify the\napi-ref.xml file to show new sections. Also replaced 'quantum'\ninstances with 'neutron'.\nBuilds OK locally.\n\nFixes bug 1200718\n\nChange-Id: I2840aa69d85e515689346cbf43423723850fe96f\n""}, {'number': 4, 'created': '2013-07-18 14:14:58.000000000', 'files': ['api-ref/src/wadls/netconn-api/src/os-ports.wadl', 'api-ref/src/wadls/netconn-api/src/os-networks.wadl', 'api-ref/src/wadls/netconn-api/src/os-subnets.wadl', 'api-ref/src/docbkx/api-ref.xml'], 'web_link': 'https://opendev.org/openstack/api-site/commit/cd9ae4eae58b67de305fd2691d2f3787aa60d067', 'message': ""Add Neutron chapter to API reference page\n\nAll wadls and samples were there, just needed to modify the\napi-ref.xml file to show new sections. Also replaced 'quantum'\ninstances with 'neutron'.\nBuilds OK locally.\npatchset 4 - diane fleming - fixed merge conflict in api-ref.xml\n\nFixes bug 1200718\n\nChange-Id: I2840aa69d85e515689346cbf43423723850fe96f\n""}]",18,36873,cd9ae4eae58b67de305fd2691d2f3787aa60d067,13,3,4,6414,,,0,"Add Neutron chapter to API reference page

All wadls and samples were there, just needed to modify the
api-ref.xml file to show new sections. Also replaced 'quantum'
instances with 'neutron'.
Builds OK locally.
patchset 4 - diane fleming - fixed merge conflict in api-ref.xml

Fixes bug 1200718

Change-Id: I2840aa69d85e515689346cbf43423723850fe96f
",git fetch https://review.opendev.org/openstack/api-site refs/changes/73/36873/4 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/docbkx/api-ref.xml'],1,89e5f5b96fb2085b468a68cafd3e063edd94a2ef,bug/1200718," <link xlink:href=""#volumes-api"">Block Storage Service API v2</link>, <link xlink:href=""#netconn-api"">Network Service API v2</link>, and <chapter xml:id=""netconn-api""> <title>Network Service API 2.0</title> <para>Provides virtual networking services among devices that are managed by the OpenStack compute service. The Network API v2.0 combines the v1.1 API with some essential Internet Protocol Address Management (IPAM). Enables Network API v2.0 users to associate IP address blocks and other network configuration settings with a neutron network. You can choose a specific IP address from the block or let neutron choose the first available IP address. For further information concerning networking API extensions, visit <link xlink:href=""http://docs.openstack.org/api/openstack-network/2.0/content/"" >OpenStack Networking API v2.0 Reference</link> </para> <section xml:id=""networks""> <title>Networks</title> <para>Lists, creates, deletes, and updates neutron networks.</para> <wadl:resources href=""../wadls/netconn-api/src/os-networks.wadl"" xmlns:wadl=""http://wadl.dev.java.net/2009/02""/> </section> <section xml:id=""subnets""> <title>Subnets</title> <para>Lists, creates, removes, and updates subnet resources.</para> <wadl:resources href=""../wadls/netconn-api/src/os-subnets.wadl"" xmlns:wadl=""http://wadl.dev.java.net/2009/02""/> </section> <section xml:id=""ports""> <title>Ports</title> <para>Lists, creates, removes, and updates ports.</para> <wadl:resources href=""../wadls/netconn-api/src/os-ports.wadl"" xmlns:wadl=""http://wadl.dev.java.net/2009/02""/> </section> </chapter>"," <link xlink:href=""#volumes-api"">Block Storage Service API v2</link>, and ",36,1
openstack%2Fcinder~master~I71bcb713fc49faea2e1e442f08087800e0ea417a,openstack/cinder,master,I71bcb713fc49faea2e1e442f08087800e0ea417a,Imported Translations from Transifex,MERGED,2013-07-16 18:10:25.000000000,2013-07-18 15:04:28.000000000,2013-07-18 15:04:28.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}]","[{'number': 1, 'created': '2013-07-16 18:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6deb025a065c58195569b680b08dab0fe8867e2a', 'message': 'Imported Translations from Transifex\n\nChange-Id: I71bcb713fc49faea2e1e442f08087800e0ea417a\n'}, {'number': 2, 'created': '2013-07-17 18:10:25.000000000', 'files': ['cinder/locale/ko/LC_MESSAGES/cinder.po', 'cinder/locale/hu/LC_MESSAGES/cinder.po', 'cinder/locale/tr/LC_MESSAGES/cinder.po', 'cinder/locale/en_US/LC_MESSAGES/cinder.po', 'cinder/locale/fi_FI/LC_MESSAGES/cinder.po', 'cinder/locale/pt_BR/LC_MESSAGES/cinder.po', 'cinder/locale/tr_TR/LC_MESSAGES/cinder.po', 'cinder/locale/ca/LC_MESSAGES/cinder.po', 'cinder/locale/cinder.pot', 'cinder/locale/nb/LC_MESSAGES/cinder.po', 'cinder/locale/it/LC_MESSAGES/cinder.po', 'cinder/locale/zh_CN/LC_MESSAGES/cinder.po', 'cinder/locale/ko_KR/LC_MESSAGES/cinder.po', 'cinder/locale/ms/LC_MESSAGES/cinder.po', 'cinder/locale/nl_NL/LC_MESSAGES/cinder.po', 'cinder/locale/zh_HK/LC_MESSAGES/cinder.po', 'cinder/locale/es/LC_MESSAGES/cinder.po', 'cinder/locale/cs/LC_MESSAGES/cinder.po', 'cinder/locale/pt/LC_MESSAGES/cinder.po', 'cinder/locale/sw_KE/LC_MESSAGES/cinder.po', 'cinder/locale/tl/LC_MESSAGES/cinder.po', 'cinder/locale/en_GB/LC_MESSAGES/cinder.po', 'cinder/locale/ru_RU/LC_MESSAGES/cinder.po', 'cinder/locale/bg_BG/LC_MESSAGES/cinder.po', 'cinder/locale/uk/LC_MESSAGES/cinder.po', 'cinder/locale/en_AU/LC_MESSAGES/cinder.po', 'cinder/locale/fr/LC_MESSAGES/cinder.po', 'cinder/locale/id/LC_MESSAGES/cinder.po', 'cinder/locale/da/LC_MESSAGES/cinder.po', 'cinder/locale/ru/LC_MESSAGES/cinder.po', 'cinder/locale/vi_VN/LC_MESSAGES/cinder.po', 'cinder/locale/hr/LC_MESSAGES/cinder.po', 'cinder/locale/pl_PL/LC_MESSAGES/cinder.po', 'cinder/locale/ro/LC_MESSAGES/cinder.po', 'cinder/locale/ja/LC_MESSAGES/cinder.po', 'cinder/locale/ka_GE/LC_MESSAGES/cinder.po', 'cinder/locale/zh_TW/LC_MESSAGES/cinder.po', 'cinder/locale/sl_SI/LC_MESSAGES/cinder.po', 'cinder/locale/it_IT/LC_MESSAGES/cinder.po', 'cinder/locale/de/LC_MESSAGES/cinder.po', 'cinder/locale/bs/LC_MESSAGES/cinder.po'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cff3e6eaf2fe4f5ddf31233a2c3f4cee757c549d', 'message': 'Imported Translations from Transifex\n\nChange-Id: I71bcb713fc49faea2e1e442f08087800e0ea417a\n'}]",0,37298,cff3e6eaf2fe4f5ddf31233a2c3f4cee757c549d,9,3,2,3,,,0,"Imported Translations from Transifex

Change-Id: I71bcb713fc49faea2e1e442f08087800e0ea417a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/98/37298/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/locale/ko/LC_MESSAGES/cinder.po', 'cinder/locale/hu/LC_MESSAGES/cinder.po', 'cinder/locale/tr/LC_MESSAGES/cinder.po', 'cinder/locale/en_US/LC_MESSAGES/cinder.po', 'cinder/locale/fi_FI/LC_MESSAGES/cinder.po', 'cinder/locale/pt_BR/LC_MESSAGES/cinder.po', 'cinder/locale/tr_TR/LC_MESSAGES/cinder.po', 'cinder/locale/ca/LC_MESSAGES/cinder.po', 'cinder/locale/cinder.pot', 'cinder/locale/nb/LC_MESSAGES/cinder.po', 'cinder/locale/it/LC_MESSAGES/cinder.po', 'cinder/locale/zh_CN/LC_MESSAGES/cinder.po', 'cinder/locale/ko_KR/LC_MESSAGES/cinder.po', 'cinder/locale/ms/LC_MESSAGES/cinder.po', 'cinder/locale/nl_NL/LC_MESSAGES/cinder.po', 'cinder/locale/zh_HK/LC_MESSAGES/cinder.po', 'cinder/locale/es/LC_MESSAGES/cinder.po', 'cinder/locale/cs/LC_MESSAGES/cinder.po', 'cinder/locale/pt/LC_MESSAGES/cinder.po', 'cinder/locale/sw_KE/LC_MESSAGES/cinder.po', 'cinder/locale/tl/LC_MESSAGES/cinder.po', 'cinder/locale/en_GB/LC_MESSAGES/cinder.po', 'cinder/locale/ru_RU/LC_MESSAGES/cinder.po', 'cinder/locale/bg_BG/LC_MESSAGES/cinder.po', 'cinder/locale/uk/LC_MESSAGES/cinder.po', 'cinder/locale/en_AU/LC_MESSAGES/cinder.po', 'cinder/locale/fr/LC_MESSAGES/cinder.po', 'cinder/locale/id/LC_MESSAGES/cinder.po', 'cinder/locale/da/LC_MESSAGES/cinder.po', 'cinder/locale/ru/LC_MESSAGES/cinder.po', 'cinder/locale/vi_VN/LC_MESSAGES/cinder.po', 'cinder/locale/hr/LC_MESSAGES/cinder.po', 'cinder/locale/pl_PL/LC_MESSAGES/cinder.po', 'cinder/locale/ro/LC_MESSAGES/cinder.po', 'cinder/locale/ja/LC_MESSAGES/cinder.po', 'cinder/locale/ka_GE/LC_MESSAGES/cinder.po', 'cinder/locale/zh_TW/LC_MESSAGES/cinder.po', 'cinder/locale/sl_SI/LC_MESSAGES/cinder.po', 'cinder/locale/it_IT/LC_MESSAGES/cinder.po', 'cinder/locale/de/LC_MESSAGES/cinder.po', 'cinder/locale/bs/LC_MESSAGES/cinder.po']",41,6deb025a065c58195569b680b08dab0fe8867e2a,transifex/translations,"""POT-Creation-Date: 2013-07-16 18:10+0000\n""#: cinder/volume/drivers/nexenta/volume.py:306#: cinder/volume/drivers/coraid.py:385 cinder/volume/drivers/rbd.py:568#: cinder/volume/drivers/rbd.py:189#: cinder/volume/drivers/rbd.py:240#: cinder/volume/drivers/rbd.py:246#: cinder/volume/drivers/rbd.py:311 cinder/volume/drivers/sheepdog.py:172#: cinder/volume/drivers/rbd.py:351#: cinder/volume/drivers/rbd.py:357#: cinder/volume/drivers/rbd.py:439#: cinder/volume/drivers/rbd.py:448#: cinder/volume/drivers/rbd.py:452#: cinder/volume/drivers/rbd.py:455msgid ""not cloneable: %s"" msgstr """" #: cinder/volume/drivers/rbd.py:471 #, python-format#: cinder/volume/drivers/rbd.py:483#: cinder/volume/drivers/rbd.py:573 msgid ""Extend volume from %(old_size) to %(new_size)"" msgstr """" #: cinder/volume/drivers/solidfire.py:136#: cinder/volume/drivers/solidfire.py:143 #, python-format msgid """" ""Failed to make httplib connection SolidFire Cluster: %s (verify san_ip "" ""settings)"" msgstr """" #: cinder/volume/drivers/solidfire.py:146 #, python-format msgid ""Failed to make httplib connection: %s"" msgstr """" #: cinder/volume/drivers/solidfire.py:153 #, python-format msgid """" ""Request to SolidFire cluster returned bad status: %(status)s / %(reason)s"" "" (check san_login/san_password settings)"" msgstr """" #: cinder/volume/drivers/solidfire.py:158 #, python-format msgid ""HTTP request failed, with status: %(status)s and reason: %(reason)s"" msgstr """" #: cinder/volume/drivers/solidfire.py:169#: cinder/volume/drivers/solidfire.py:175#: cinder/volume/drivers/solidfire.py:179#: cinder/volume/drivers/solidfire.py:181#: cinder/volume/drivers/solidfire.py:187#: cinder/volume/drivers/solidfire.py:194 #: cinder/volume/drivers/solidfire.py:261 #: cinder/volume/drivers/solidfire.py:350#: cinder/volume/drivers/solidfire.py:214#: cinder/volume/drivers/solidfire.py:243#: cinder/volume/drivers/solidfire.py:305#: cinder/volume/drivers/solidfire.py:380#: cinder/volume/drivers/solidfire.py:392 #, python-format msgid ""Failed volume create: %s"" msgstr """" #: cinder/volume/drivers/solidfire.py:407#: cinder/volume/drivers/solidfire.py:432 #, python-format msgid ""Failed to get SolidFire Volume: %s"" msgstr """" #: cinder/volume/drivers/solidfire.py:441#: cinder/volume/drivers/solidfire.py:450#: cinder/volume/drivers/solidfire.py:453#: cinder/volume/drivers/solidfire.py:520msgid ""Account for Volume ID %s was not found on the SolidFire Cluster!"" msgstr """" #: cinder/volume/drivers/solidfire.py:526 msgid ""This usually means the volume was never succesfully created."" msgstr """" #: cinder/volume/drivers/solidfire.py:539 #, python-format msgid ""Failed to delete SolidFire Volume: %s"" msgstr """" #: cinder/volume/drivers/solidfire.py:542 #: cinder/volume/drivers/solidfire.py:613 #, python-format#: cinder/volume/drivers/solidfire.py:545#: cinder/volume/drivers/solidfire.py:549#: cinder/volume/drivers/solidfire.py:554#: cinder/volume/drivers/solidfire.py:605 msgid ""Entering SolidFire extend_volume..."" msgstr """" #: cinder/volume/drivers/solidfire.py:627 msgid ""Leaving SolidFire extend_volume"" msgstr """" #: cinder/volume/drivers/solidfire.py:632#: cinder/volume/drivers/solidfire.py:640#~ msgid ""Update SolidFire Cluster stats failed: %s""","""POT-Creation-Date: 2013-07-15 18:10+0000\n""#: cinder/volume/drivers/nexenta/volume.py:318#: cinder/volume/drivers/coraid.py:385#: cinder/volume/drivers/rbd.py:188#: cinder/volume/drivers/rbd.py:239#: cinder/volume/drivers/rbd.py:245#: cinder/volume/drivers/rbd.py:310 cinder/volume/drivers/sheepdog.py:172#: cinder/volume/drivers/rbd.py:350#: cinder/volume/drivers/rbd.py:356#: cinder/volume/drivers/rbd.py:435#: cinder/volume/drivers/rbd.py:444#: cinder/volume/drivers/rbd.py:448#: cinder/volume/drivers/rbd.py:451#: cinder/volume/drivers/rbd.py:463 #, python-format msgid ""not cloneable: %s"" msgstr """" #: cinder/volume/drivers/rbd.py:479#: cinder/volume/drivers/solidfire.py:91 cinder/volume/drivers/solidfire.py:581 #, python-format msgid ""Update SolidFire Cluster stats failed: %s"" msgstr """" #: cinder/volume/drivers/solidfire.py:138#: cinder/volume/drivers/solidfire.py:156#: cinder/volume/drivers/solidfire.py:162#: cinder/volume/drivers/solidfire.py:166#: cinder/volume/drivers/solidfire.py:168#: cinder/volume/drivers/solidfire.py:174#: cinder/volume/drivers/solidfire.py:181#: cinder/volume/drivers/solidfire.py:201#: cinder/volume/drivers/solidfire.py:230#: cinder/volume/drivers/solidfire.py:291#: cinder/volume/drivers/solidfire.py:365#: cinder/volume/drivers/solidfire.py:391#: cinder/volume/drivers/solidfire.py:424#: cinder/volume/drivers/solidfire.py:433#: cinder/volume/drivers/solidfire.py:436#: cinder/volume/drivers/solidfire.py:503#: cinder/volume/drivers/solidfire.py:507 #, python-format msgid ""Account for Volume ID %s was not found on the SolidFire Cluster!"" msgstr """" #: cinder/volume/drivers/solidfire.py:509 msgid ""This usually means the volume was never succesfully created."" msgstr """" #: cinder/volume/drivers/solidfire.py:527#: cinder/volume/drivers/solidfire.py:531#: cinder/volume/drivers/solidfire.py:536#: cinder/volume/drivers/solidfire.py:590#: cinder/volume/drivers/solidfire.py:598#~ msgid ""already detached""",4212,2203
openstack%2Fcinder~master~I72bb7ef137223381c9daa613e61f1fde4c3bc8ae,openstack/cinder,master,I72bb7ef137223381c9daa613e61f1fde4c3bc8ae,Tidy up the SSH call to avoid injection attacks in storwize_svc,MERGED,2013-07-17 13:39:49.000000000,2013-07-18 15:04:27.000000000,2013-07-18 15:04:27.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 7063}, {'_account_id': 7593}]","[{'number': 1, 'created': '2013-07-17 13:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c53cf9dcc4d2c4e6cebb865a7e59a935756a1c31', 'message': 'Tidy up the SSH call to avoid injection attacks in volumn.drivers.storwize_svc\n\nLet the command and arguments form up a list and avoid the extra arguments\nattackers inserted to the command string\n\nfix bug 1192971\n\nChange-Id: I72bb7ef137223381c9daa613e61f1fde4c3bc8ae\n'}, {'number': 2, 'created': '2013-07-17 15:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5365d5d5b74e97f9eae364390d931a06253375cb', 'message': 'Tidy up the SSH call to avoid injection attacks in storwize_svc\n\nLet the command and arguments form up a list and avoid the extra arguments\nattackers inserted to the command string\n\nfix bug 1192971\n\nChange-Id: I72bb7ef137223381c9daa613e61f1fde4c3bc8ae\n'}, {'number': 3, 'created': '2013-07-17 16:06:23.000000000', 'files': ['cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/storwize_svc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6be79a8e3b4607adbbe6a26ee565156cd0fb36b0', 'message': 'Tidy up the SSH call to avoid injection attacks in storwize_svc\n\nLet the command and arguments form up a list and avoid the extra arguments\nattackers inserted to the command string\n\nfix bug 1192971\n\nChange-Id: I72bb7ef137223381c9daa613e61f1fde4c3bc8ae\n'}]",2,37469,6be79a8e3b4607adbbe6a26ee565156cd0fb36b0,15,7,3,7593,,,0,"Tidy up the SSH call to avoid injection attacks in storwize_svc

Let the command and arguments form up a list and avoid the extra arguments
attackers inserted to the command string

fix bug 1192971

Change-Id: I72bb7ef137223381c9daa613e61f1fde4c3bc8ae
",git fetch https://review.opendev.org/openstack/cinder refs/changes/69/37469/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/storwize_svc.py']",2,c53cf9dcc4d2c4e6cebb865a7e59a935756a1c31,bug/1192971," generator = self._port_conf_generator(['svcinfo', 'lsportip']) ssh_cmd = ['svcinfo', 'lsnode', '-delim', '!', node['id']] ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-delim', '!', '-nohdr'] ssh_cmd = ['svcinfo', 'lslicense', '-delim', '!'] ssh_cmd = ['svcinfo', 'lsnode', '-delim', '!'] ssh_cmd = ['svctask', 'chhost', '-chapsecret', chap_secret, host_name] ssh_cmd = ['svcinfo', 'lsiscsiauth', '-delim', '!'] ssh_cmd = ['svcinfo', 'lsfabric', '-wwpn', wwpn, '-delim', '!'] ssh_cmd = ['svcinfo', 'lshost', '-delim', '!', host] ssh_cmd = ['svcinfo', 'lshost', '-delim', '!'] arg_name, arg_val = port1.split() ssh_cmd = ['svctask', 'mkhost', '-force', arg_name, arg_val, '-name', '""%s""' % host_name] arg_name, arg_val = port.split() ssh_cmd = ['svctask', 'addhostport', '-force', arg_name, arg_val, host_name] ssh_cmd = ['svcinfo', 'lshostvdiskmap', '-delim', '!', host_name] ssh_cmd = ['svctask', 'mkvdiskhostmap', '-host', host_name, '-scsi', result_lun, volume_name] for i in range(len(ssh_cmd)): if ssh_cmd[i] == 'mkvdiskhostmap': ssh_cmd.insert(i + 1, '-force') ssh_cmd = ['svctask', 'rmhost', host_name] cmd = ['svcinfo', 'lsfabric', '-host', host_name] ssh_cmd = ['svctask', 'rmvdiskhostmap', '-host', host_name, vol_name] ssh_cmd = ['svcinfo', 'lsvdisk', '-bytes', '-delim', '!', vdisk_name] ssh_cmd = ['svcinfo', 'lsvdiskfcmappings', '-nohdr', vdisk_name] easytier = 'on' if opts['easytier'] else 'off' ssh_cmd_se_opt = [] else: ssh_cmd_se_opt = ['-rsize', str(opts['rsize']), '-autoexpand', '-warning', str(opts['warning'])] if not opts['autoexpand']: ssh_cmd_se_opt.remove('-autoexpand') if opts['compression']: ssh_cmd_se_opt.append('-compressed') else: ssh_cmd_se_opt.extend(['-grainsize', str(opts['grainsize'])]) ssh_cmd = ['svctask', 'mkvdisk', '-name', name, '-mdiskgrp', self.configuration.storwize_svc_volpool_name, '-iogrp', '0', '-size', size, '-unit', units, '-easytier', easytier] + ssh_cmd_se_opt fc_map_cli_cmd = ['svctask', 'mkfcmap', '-source', source, '-target', target, '-autodelete'] if full_copy: fc_map_cli_cmd.extend(['-copyrate', '0']) out, err = self._run_ssh(['svctask', 'prestartfcmap', fc_map_id]) out, err = self._run_ssh(['svctask', 'startfcmap', fc_map_id]) fc_ls_map_cmd = ['svcinfo', 'lsfcmap', '-filtervalue', 'id=%s' % fc_map_id, '-delim', '!'] ssh_cmd = ['svctask', 'chfcmap', '-copyrate', '50', '-autodelete', 'on', map_id] self._run_ssh(['svctask', 'stopfcmap', map_id]) self._run_ssh(['svctask', 'rmfcmap', '-force', map_id]) self._run_ssh(['svctask', 'stopfcmap', map_id]) self._run_ssh(['svctask', 'rmfcmap', '-force', map_id]) self._run_ssh(['svctask', 'rmfcmap', '-force', map_id]) ssh_cmd = ['svctask', 'rmvdisk', '-force', name] if not force: ssh_cmd.remove('-force') ssh_cmd = ['svcinfo', 'lssystem', '-delim', '!'] ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-bytes', '-delim', '!', pool] ssh_cmd = cmd + ['-delim', '!'] ' command %s') % str(ssh_cmd)) % {'cmd': str(ssh_cmd),"," generator = self._port_conf_generator('svcinfo lsportip') ssh_cmd = 'svcinfo lsnode -delim ! %s' % node['id'] ssh_cmd = 'svcinfo lsmdiskgrp -delim ! -nohdr' ssh_cmd = 'svcinfo lslicense -delim !' ssh_cmd = 'svcinfo lsnode -delim !' ssh_cmd = ('svctask chhost -chapsecret ""%(chap_secret)s"" %(host_name)s' % {'chap_secret': chap_secret, 'host_name': host_name}) ssh_cmd = 'svcinfo lsiscsiauth -delim !' ssh_cmd = 'svcinfo lsfabric -wwpn %s -delim !' % wwpn ssh_cmd = 'svcinfo lshost -delim ! %s' % host ssh_cmd = 'svcinfo lshost -delim !' ssh_cmd = ('svctask mkhost -force %(port1)s -name ""%(host_name)s""' % {'port1': port1, 'host_name': host_name}) ssh_cmd = ('svctask addhostport -force %s %s' % (port, host_name)) ssh_cmd = 'svcinfo lshostvdiskmap -delim ! %s' % host_name ssh_cmd = ('svctask mkvdiskhostmap -host %(host_name)s -scsi ' '%(result_lun)s %(volume_name)s' % {'host_name': host_name, 'result_lun': result_lun, 'volume_name': volume_name}) ssh_cmd = ssh_cmd.replace('mkvdiskhostmap', 'mkvdiskhostmap -force') ssh_cmd = 'svctask rmhost %s ' % host_name cmd = 'svcinfo lsfabric -host %s' % host_name ssh_cmd = 'svctask rmvdiskhostmap -host %s %s' % \ (host_name, vol_name) ssh_cmd = 'svcinfo lsvdisk -bytes -delim ! %s ' % vdisk_name ssh_cmd = 'svcinfo lsvdiskfcmappings -nohdr %s' % vdisk_name autoex = '-autoexpand' if opts['autoexpand'] else '' easytier = '-easytier on' if opts['easytier'] else '-easytier off' ssh_cmd_se_opt = '' else: ssh_cmd_se_opt = ( '-rsize %(rsize)d%% %(autoex)s -warning %(warn)d%%' % {'rsize': opts['rsize'], 'autoex': autoex, 'warn': opts['warning']}) if opts['compression']: ssh_cmd_se_opt = ssh_cmd_se_opt + ' -compressed' else: ssh_cmd_se_opt = ssh_cmd_se_opt + ( ' -grainsize %d' % opts['grainsize']) ssh_cmd = ('svctask mkvdisk -name %(name)s -mdiskgrp %(mdiskgrp)s ' '-iogrp 0 -size %(size)s -unit ' '%(unit)s %(easytier)s %(ssh_cmd_se_opt)s' % {'name': name, 'mdiskgrp': self.configuration.storwize_svc_volpool_name, 'size': size, 'unit': units, 'easytier': easytier, 'ssh_cmd_se_opt': ssh_cmd_se_opt}) copyflag = '' if full_copy else '-copyrate 0' fc_map_cli_cmd = ('svctask mkfcmap -source %(src)s -target %(tgt)s ' '-autodelete %(copyflag)s' % {'src': source, 'tgt': target, 'copyflag': copyflag}) out, err = self._run_ssh('svctask prestartfcmap %s' % fc_map_id) out, err = self._run_ssh('svctask startfcmap %s' % fc_map_id) fc_ls_map_cmd = 'svcinfo lsfcmap -filtervalue id=%s -delim !' % \ fc_map_id ssh_cmd = ('svctask chfcmap -copyrate 50 ' '-autodelete on %s' % map_id) self._run_ssh('svctask stopfcmap %s' % map_id) self._run_ssh('svctask rmfcmap -force %s' % map_id) self._run_ssh('svctask stopfcmap %s' % map_id) self._run_ssh('svctask rmfcmap -force %s' % map_id) self._run_ssh('svctask rmfcmap -force %s' % map_id) forceflag = '-force' if force else '' cmd_params = {'frc': forceflag, 'name': name} ssh_cmd = 'svctask rmvdisk %(frc)s %(name)s' % cmd_params ssh_cmd = 'svcinfo lssystem -delim !' ssh_cmd = 'svcinfo lsmdiskgrp -bytes -delim ! %s' % pool ssh_cmd = '%s -delim !' % cmd ' command %s') % ssh_cmd) % {'cmd': ssh_cmd,",70,76
openstack%2Fdiskimage-builder~master~I9822362cf722b904d9806dbbb4bb07cfe2b33437,openstack/diskimage-builder,master,I9822362cf722b904d9806dbbb4bb07cfe2b33437,Cache repository-sources data.,MERGED,2013-07-18 14:53:54.000000000,2013-07-18 14:53:54.000000000,2013-07-18 14:53:54.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 6488}]","[{'number': 2, 'created': '2013-07-18 14:53:54.000000000', 'files': ['elements/source-repositories/extra-data.d/99-getsources', 'elements/source-repositories/element-deps'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/79ca4d901cd5a41fca700b1ca1f7837dd3c62ee5', 'message': ""Cache repository-sources data.\n\nCloning large repositories over the internet can take considerable\ntime.  Caching them locally makes repeated image builds significantly\nfaster, so lets do that.\n\nWhen users override the element source they will often be using a\nlocal repository, so in those cases I don't cache - but we could\neasily change our minds on that in the future.\n\nChange-Id: I9822362cf722b904d9806dbbb4bb07cfe2b33437\n""}, {'number': 1, 'created': '2013-07-18 14:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ea0f1604a0f884e7722d04571a59bb03e283684a', 'message': ""Cache repository-sources data.\n\nCloning large repositories over the internet can take considerable\ntime.  Caching them locally makes repeated image builds significantly\nfaster, so lets do that.\n\nWhen users override the element source they will often be using a\nlocal repository, so in those cases I don't cache - but we could\neasily change our minds on that in the future.\n\nChange-Id: I9822362cf722b904d9806dbbb4bb07cfe2b33437\n""}]",4,37612,79ca4d901cd5a41fca700b1ca1f7837dd3c62ee5,10,4,2,4190,,,0,"Cache repository-sources data.

Cloning large repositories over the internet can take considerable
time.  Caching them locally makes repeated image builds significantly
faster, so lets do that.

When users override the element source they will often be using a
local repository, so in those cases I don't cache - but we could
easily change our minds on that in the future.

Change-Id: I9822362cf722b904d9806dbbb4bb07cfe2b33437
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/12/37612/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/source-repositories/extra-data.d/99-getsources', 'elements/source-repositories/element-deps']",2,79ca4d901cd5a41fca700b1ca1f7837dd3c62ee5,,cache-url ,,33,3
openstack%2Fswift~master~I462fafa2638dcbdc628a1fa710e98bae04e8b4dc,openstack/swift,master,I462fafa2638dcbdc628a1fa710e98bae04e8b4dc,Forklift the DiskFile interface into it's own module,ABANDONED,2013-07-18 05:40:41.000000000,2013-07-18 14:43:52.000000000,,"[{'_account_id': 6198}, {'_account_id': 6968}]","[{'number': 1, 'created': '2013-07-18 05:40:41.000000000', 'files': ['test/unit/obj/test_auditor.py', 'swift/obj/server.py', 'swift/obj/auditor.py', 'test/unit/obj/test_server.py', 'test/probe/test_object_failures.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/25b7852a1873decce39c4f20d872c6a6c8c52908', 'message': ""Forklift the DiskFile interface into it's own module\n\n * new module swift.obj.diskfile\n\nI parameterized two constants from obj.server into the DiskFile class\n\n * DATADIR -> obj_dir\n * DISALLOWED_HEADERS -> disallowed_metadata_keys\n\nI'm not sure if this is the right long term extraction but for now it avoids\ncircular imports.\n\nChange-Id: I462fafa2638dcbdc628a1fa710e98bae04e8b4dc\n""}]",0,37622,25b7852a1873decce39c4f20d872c6a6c8c52908,2,2,1,1179,,,0,"Forklift the DiskFile interface into it's own module

 * new module swift.obj.diskfile

I parameterized two constants from obj.server into the DiskFile class

 * DATADIR -> obj_dir
 * DISALLOWED_HEADERS -> disallowed_metadata_keys

I'm not sure if this is the right long term extraction but for now it avoids
circular imports.

Change-Id: I462fafa2638dcbdc628a1fa710e98bae04e8b4dc
",git fetch https://review.opendev.org/openstack/swift refs/changes/22/37622/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_auditor.py', 'swift/obj/server.py', 'swift/obj/auditor.py', 'test/unit/obj/test_server.py', 'test/probe/test_object_failures.py']",5,25b7852a1873decce39c4f20d872c6a6c8c52908,fork-lift-df,"from swift.obj.diskfile import write_metadata, read_metadata","from swift.obj.server import write_metadata, read_metadata",41,800
openstack%2Fnova~master~Iec795ce6bf9c9d71521c0d775ed3ac69be16d44e,openstack/nova,master,Iec795ce6bf9c9d71521c0d775ed3ac69be16d44e,Remove sample config file generator,ABANDONED,2013-07-16 16:23:29.000000000,2013-07-18 14:36:43.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-16 16:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca73511f75e1dd510d7583cc4cf244cd3eb38e87', 'message': 'tmp\n\nChange-Id: Iec795ce6bf9c9d71521c0d775ed3ac69be16d44e\n'}, {'number': 2, 'created': '2013-07-17 04:44:35.000000000', 'files': ['tools/conf/generate_sample.sh', 'tools/conf/README'], 'web_link': 'https://opendev.org/openstack/nova/commit/c153fd24f30e850a1e32bff6194ed132595e1ca4', 'message': 'Remove sample config file generator\n\nThe script has move to Oslo.\nhttps://github.com/openstack/oslo-incubator/blob/master/tools/config/generate_sample.sh\n\nChange-Id: Iec795ce6bf9c9d71521c0d775ed3ac69be16d44e\n'}]",0,37282,c153fd24f30e850a1e32bff6194ed132595e1ca4,13,5,2,1994,,,0,"Remove sample config file generator

The script has move to Oslo.
https://github.com/openstack/oslo-incubator/blob/master/tools/config/generate_sample.sh

Change-Id: Iec795ce6bf9c9d71521c0d775ed3ac69be16d44e
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/37282/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/conf/generate_sample.sh', 'tools/conf/README']",2,ca73511f75e1dd510d7583cc4cf244cd3eb38e87,remove_confgen,,"This generate_sample.sh tool is used to generate etc/nova/nova.conf.sample Run it from the top-level working directory i.e. $> ./tools/conf/generate_sample.sh Watch out for warnings about modules like libvirt, qpid and zmq not being found - these warnings are significant because they result in options not appearing in the generated config file. ",0,40
openstack%2Fnova~master~Ia904e75bce152fb1ee9c3929f7a0e2289781dfbb,openstack/nova,master,Ia904e75bce152fb1ee9c3929f7a0e2289781dfbb,Change EC2 client tokens to use system_metadata,ABANDONED,2013-07-18 14:11:39.000000000,2013-07-18 14:21:42.000000000,,[],"[{'number': 1, 'created': '2013-07-18 14:11:39.000000000', 'files': ['nova/tests/fake_policy.py', 'nova/api/ec2/cloud.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9830eca431b8837b08e0f0911bf7150a836d5d2a', 'message': ""Change EC2 client tokens to use system_metadata\n\nAn EC2 client token is created as a result of RunInstances. The initial\nimplementation called create_tags which uses per-instance metadata.\nHowever, we can't update per-instance metadata while an instance is still\nbuilding because put the metadata updates in the messaging queue.\n\nWe avoid this problem by using system_metadata instead of per-instance\nmetadata. As an added bonus, users can't tamper with the token via the tags\nAPI.\n\nFixes bug #1202404\n\nChange-Id: Ia904e75bce152fb1ee9c3929f7a0e2289781dfbb\n""}]",0,37684,9830eca431b8837b08e0f0911bf7150a836d5d2a,1,0,1,6661,,,0,"Change EC2 client tokens to use system_metadata

An EC2 client token is created as a result of RunInstances. The initial
implementation called create_tags which uses per-instance metadata.
However, we can't update per-instance metadata while an instance is still
building because put the metadata updates in the messaging queue.

We avoid this problem by using system_metadata instead of per-instance
metadata. As an added bonus, users can't tamper with the token via the tags
API.

Fixes bug #1202404

Change-Id: Ia904e75bce152fb1ee9c3929f7a0e2289781dfbb
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/37684/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fake_policy.py', 'nova/api/ec2/cloud.py', 'nova/compute/api.py']",3,9830eca431b8837b08e0f0911bf7150a836d5d2a,bug/1202404," return self._get_all_instance_metadata( context, search_filts, metadata_type='metadata') def get_all_system_metadata(self, context, search_filts): return self._get_all_instance_metadata( context, search_filts, metadata_type='system_metadata') def _get_all_instance_metadata(self, context, search_filts, metadata_type): check_policy(context, 'get_all_instance_%s' % metadata_type, instance) metadata = instance.get(metadata_type, {})"," check_policy(context, 'get_all_instance_metadata', instance) metadata = instance.get('metadata', {})",26,16
openstack%2Fneutron~master~Iaa9fd710f20802ffee05d4662971c0a37470a5d7,openstack/neutron,master,Iaa9fd710f20802ffee05d4662971c0a37470a5d7,set minimum version of dnsmasq to 2.45,ABANDONED,2013-07-18 13:28:43.000000000,2013-07-18 14:14:58.000000000,,"[{'_account_id': 3}, {'_account_id': 167}]","[{'number': 1, 'created': '2013-07-18 13:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6898a9302d1cb4a91238b8fb63736f3e152903bf', 'message': 'set minimum version of dnsmasq to 2.45\n\nChange Ia7d2b1c0 adds support for dnsmasq version 2.48. Version 2.45 is\nalso working fine.\n\nfixes bug #1202675\n\nChange-Id: Iaa9fd710f20802ffee05d4662971c0a37470a5d7\n'}, {'number': 2, 'created': '2013-07-18 13:32:24.000000000', 'files': ['neutron/agent/linux/dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/84c7e01c878bc1bd211897c1e6aa492e9d5dd0ce', 'message': 'set minimum version of dnsmasq to 2.45\n\nChange Ia7d2b1c0adb477159ce146bcd4323d4b2795bff5 adds support for dnsmasq\nversion 2.48. Version 2.45 is also working fine.\n\nfixes bug #1202675\n\nChange-Id: Iaa9fd710f20802ffee05d4662971c0a37470a5d7\n'}]",0,37681,84c7e01c878bc1bd211897c1e6aa492e9d5dd0ce,4,2,2,167,,,0,"set minimum version of dnsmasq to 2.45

Change Ia7d2b1c0adb477159ce146bcd4323d4b2795bff5 adds support for dnsmasq
version 2.48. Version 2.45 is also working fine.

fixes bug #1202675

Change-Id: Iaa9fd710f20802ffee05d4662971c0a37470a5d7
",git fetch https://review.opendev.org/openstack/neutron refs/changes/81/37681/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/dhcp.py'],1,6898a9302d1cb4a91238b8fb63736f3e152903bf,bug/1202675, MINIMUM_VERSION = 2.45, MINIMUM_VERSION = 2.59,1,1
openstack%2Fdevstack~master~Ie0bc642873585ab02083aed543720b4a9b17cb02,openstack/devstack,master,Ie0bc642873585ab02083aed543720b4a9b17cb02,Configure tempauth along keystoneauth.,MERGED,2013-07-17 15:14:51.000000000,2013-07-18 14:04:22.000000000,2013-07-18 14:04:21.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-17 15:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/92d2a7c031760c00c7170eb4ab5a2598b54aa261', 'message': 'Configure tempauth along keystoneauth.\n\n- This would help testing the two auth server for functional testing.\n- Fixes bug 1202233.\n\nChange-Id: Ie0bc642873585ab02083aed543720b4a9b17cb02\n'}, {'number': 2, 'created': '2013-07-17 15:30:09.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5cac378cde0074ad9f7fe50507800e28c6997418', 'message': 'Configure tempauth along keystoneauth.\n\n- This would help testing the two auth server for functional testing.\n- Fixes bug 1202233.\n\nChange-Id: Ie0bc642873585ab02083aed543720b4a9b17cb02\n'}]",0,37495,5cac378cde0074ad9f7fe50507800e28c6997418,10,4,2,866,,,0,"Configure tempauth along keystoneauth.

- This would help testing the two auth server for functional testing.
- Fixes bug 1202233.

Change-Id: Ie0bc642873585ab02083aed543720b4a9b17cb02
",git fetch https://review.opendev.org/openstack/devstack refs/changes/95/37495/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,92d2a7c031760c00c7170eb4ab5a2598b54aa261,bug/1202233," # By default Swift will be installed with keystone and tempauth middleware # and add the swift3 middleware if its configured for it. The token for # tempauth would be prefixed with the reseller_prefix setting TEMPAUTH_ the # token for keystoneauth would have the standard reseller_prefix AUTH_ if is_service_enabled swift3;then swift_pipeline="" swift3 s3token "" swift_pipeline+="" authtoken keystoneauth tempauth "" iniuncomment ${SWIFT_CONFIG_PROXY_SERVER} filter:tempauth account_autocreate iniuncomment ${SWIFT_CONFIG_PROXY_SERVER} filter:tempauth reseller_prefix iniset ${SWIFT_CONFIG_PROXY_SERVER} filter:tempauth reseller_prefix ""TEMPAUTH"" "," if is_service_enabled swift3;then swift_auth_server=""s3token "" fi # By default Swift will be installed with the tempauth middleware # which has some default username and password if you have # configured keystone it will checkout the directory. if is_service_enabled key; then swift_auth_server+=""authtoken keystoneauth"" else swift_auth_server=tempauth fi # By default Swift will be installed with the tempauth middleware # which has some default username and password if you have # configured keystone it will configure swift with it. if is_service_enabled key;then if is_service_enabled swift3;then swift_pipeline="" swift3 s3token "" fi swift_pipeline+="" authtoken keystoneauth "" else if is_service_enabled swift3;then swift_pipeline="" swift3 "" fi swift_pipeline+="" tempauth """,11,26
openstack%2Fceilometer~master~I550efa0f82bcc8f7d8236ba6c1dc4be43fa410f1,openstack/ceilometer,master,I550efa0f82bcc8f7d8236ba6c1dc4be43fa410f1,Renamed storage base file,ABANDONED,2013-07-18 13:19:07.000000000,2013-07-18 13:58:50.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-18 13:19:07.000000000', 'files': ['tests/storage/test_scenarios.py', 'tests/storage/test_impl_hbase.py', 'tests/storage/test_impl_sqlalchemy.py', 'tests/storage/test_impl_mongodb.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a05b2b1c96c7c6dec2d864430d7be8816dc0a639', 'message': 'Renamed storage base file\n\nThis rename is needed to make tests loader work with test scenarios\nsince it works with files starting with test_*\n\nRelated to blueprint db-tests-with-scenarios\n\nChange-Id: I550efa0f82bcc8f7d8236ba6c1dc4be43fa410f1\n'}]",0,37677,a05b2b1c96c7c6dec2d864430d7be8816dc0a639,2,1,1,7763,,,0,"Renamed storage base file

This rename is needed to make tests loader work with test scenarios
since it works with files starting with test_*

Related to blueprint db-tests-with-scenarios

Change-Id: I550efa0f82bcc8f7d8236ba6c1dc4be43fa410f1
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/77/37677/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/storage/test_scenarios.py', 'tests/storage/test_impl_hbase.py', 'tests/storage/test_impl_sqlalchemy.py', 'tests/storage/test_impl_mongodb.py']",4,a05b2b1c96c7c6dec2d864430d7be8816dc0a639,bp/db-tests-with-scenarios,from tests.storage import test_scenarios as base,from tests.storage import base,3,3
openstack%2Fneutron~master~I7a47222a047776621523f3c6c8c5b13e5b588aef,openstack/neutron,master,I7a47222a047776621523f3c6c8c5b13e5b588aef,Fix quantum rename for filters_path in rootwrap.conf,ABANDONED,2013-07-17 13:53:17.000000000,2013-07-18 13:55:26.000000000,,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 4395}]","[{'number': 1, 'created': '2013-07-17 13:53:17.000000000', 'files': ['etc/rootwrap.conf'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad36b6962af59db08fd149c6358f846f6d1e24ad', 'message': 'Fix quantum rename for filters_path in rootwrap.conf\n\nNeed to rename quantum to neutron for the filters_path property in\nrootwrap.conf.\n\nRelated to bug 1199794\n\nChange-Id: I7a47222a047776621523f3c6c8c5b13e5b588aef\n'}]",0,37476,ad36b6962af59db08fd149c6358f846f6d1e24ad,6,3,1,6873,,,0,"Fix quantum rename for filters_path in rootwrap.conf

Need to rename quantum to neutron for the filters_path property in
rootwrap.conf.

Related to bug 1199794

Change-Id: I7a47222a047776621523f3c6c8c5b13e5b588aef
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/37476/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/rootwrap.conf'],1,ad36b6962af59db08fd149c6358f846f6d1e24ad,bug/1199794,"filters_path=/etc/neutron/rootwrap.d,/usr/share/neutron/rootwrap","filters_path=/etc/quantum/rootwrap.d,/usr/share/quantum/rootwrap",1,1
openstack%2Fopenstack-manuals~stable%2Fgrizzly~Ic8c57b2107c1e334acb1adfe3498d33fde7b435d,openstack/openstack-manuals,stable/grizzly,Ic8c57b2107c1e334acb1adfe3498d33fde7b435d,Remove Costs from the 'Weights and Costs' Chapter,MERGED,2013-07-12 16:05:39.000000000,2013-07-18 13:55:21.000000000,2013-07-18 13:55:21.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 6414}]","[{'number': 1, 'created': '2013-07-12 16:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e2605c8baf66e24ce9ef79088a1c3bac8d894fd5', 'message': ""Remove Costs from the 'Weights and Costs' Chapter\n\nCosts are no longer used in the scheduler, so Weights chapter is\nupdated with the remaining ram_weight_multiplier option.\n\nFixes bug 1172264\n\nCherry-picked from https://review.openstack.org/#/c/30970\n\nChange-Id: Ic8c57b2107c1e334acb1adfe3498d33fde7b435d\n""}, {'number': 2, 'created': '2013-07-12 16:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/133ecf28b1fe1647d236778b1a79d644145c1a48', 'message': ""Remove Costs from the 'Weights and Costs' Chapter\n\nCosts are no longer used in the scheduler, so Weights chapter is\nupdated with the remaining ram_weight_multiplier option.\n\nFixes bug 1172264\n\nCherry-picked from https://review.openstack.org/#/c/30970\n\nChange-Id: Ic8c57b2107c1e334acb1adfe3498d33fde7b435d\n""}, {'number': 3, 'created': '2013-07-17 02:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a4532574afbce3e7df1a741c155fa68f355d28db', 'message': ""Remove Costs from the 'Weights and Costs' Chapter\n\nCosts are no longer used in the scheduler, so Weights chapter is\nupdated with the remaining ram_weight_multiplier option.\n\nFixes bug 1172264\n\nCherry-picked from https://review.openstack.org/#/c/30970\n\nChange-Id: Ic8c57b2107c1e334acb1adfe3498d33fde7b435d\n""}, {'number': 4, 'created': '2013-07-17 03:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8d830bee1127459bf4151538a6ba3b8ecdfafe23', 'message': ""Remove Costs from the 'Weights and Costs' Chapter\n\nCosts are no longer used in the scheduler, so Weights chapter is\nupdated with the remaining ram_weight_multiplier option.\n\nFixes bug 1172264\n\nCherry-picked from https://review.openstack.org/#/c/30970\n\nChange-Id: Ic8c57b2107c1e334acb1adfe3498d33fde7b435d\n""}, {'number': 5, 'created': '2013-07-17 04:08:46.000000000', 'files': ['doc/src/docbkx/openstack-compute-admin/computescheduler.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ec9cb1cde695cad9edd5f0873331171b3d65b18e', 'message': ""Remove Costs from the 'Weights and Costs' Chapter\n\nCosts are no longer used in the scheduler, so Weights chapter is\nupdated with the remaining ram_weight_multiplier option.\n\nFixes bug 1172264\n\nCherry-picked from https://review.openstack.org/#/c/30970\n\nChange-Id: Ic8c57b2107c1e334acb1adfe3498d33fde7b435d\n""}]",3,36852,ec9cb1cde695cad9edd5f0873331171b3d65b18e,16,3,5,6414,,,0,"Remove Costs from the 'Weights and Costs' Chapter

Costs are no longer used in the scheduler, so Weights chapter is
updated with the remaining ram_weight_multiplier option.

Fixes bug 1172264

Cherry-picked from https://review.openstack.org/#/c/30970

Change-Id: Ic8c57b2107c1e334acb1adfe3498d33fde7b435d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/52/36852/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-compute-admin/computescheduler.xml'],1,e2605c8baf66e24ce9ef79088a1c3bac8d894fd5,bug/1172264,"volume_scheduler_driver=nova.scheduler.chance.ChanceSchedulerscheduler_weight_classes=nova.scheduler.weights.all_weighers ram_weight_multiplier=1.0 <para>The volume scheduler is configured by default as a Chance Scheduler, which picks a host at random that has the <command>cinder-volume</command> service running.</para><<<<<<< HEAD======= >>>>>>> faee88b... Remove Costs from the 'Weights and Costs' Chapter decide which hosts to use for that request, described in the <link linkend=""weights"">Weights</link> section. <figure xml:id=""filter-figure""> <section xml:id=""weights""> <title>Weights</title> <para>The Filter Scheduler weighs hosts based on the config option <literal>scheduler_weight_classes</literal>, this defaults to <literal>nova.scheduler.weights.all_weighers</literal>, which selects the only weigher available -- the RamWeigher. Hosts are then weighed and sorted with the largest weight winning. </para>scheduler_weight_classes=nova.scheduler.weights.all_weighers ram_weight_multiplier=1.0 </programlisting> <para> The default is to spread instances across all hosts evenly. Set the <literal>ram_weight_multiplier</literal> option to a negative number if you prefer stacking instead of spreading. </para> ","least_cost_functions=nova.scheduler.least_cost.compute_fill_first_cost_fn compute_fill_first_cost_fn_weight=-1.0 decide which hosts to use for that request, described in the <link linkend=""costs-and-weights"">costs and weight </link> section. <figure xml:id=""filter-figure""> <section xml:id=""costs-and-weights""> <title>Costs and Weights</title> <para> <figure xml:id=""cost-figure""> <title>Computing weighted costs</title> <mediaobject> <imageobject> <imagedata fileref=""figures/filteringWorkflow2.png "" scale=""80""/> </imageobject> </mediaobject> </figure></para> <para> The Filter Scheduler takes the hosts that remain after the filters have been applied and applies one or more cost function to each host to get numerical scores for each host. Each cost score is multiplied by a weighting constant specified in the <filename>nova.conf</filename> config file. The weighting constant configuration option is the name of the cost function, with the <literal>_weight</literal> string appended. Here is an example of specifying a cost function and its corresponding weight:</para>least_cost_functions=nova.scheduler.least_cost.compute_fill_first_cost_fn compute_fill_first_cost_fn_weight=-1.0 </programlisting> <para> Multiple cost functions can be specified in the <literal>least_cost_functions</literal> configuration option, separated by commas. For example:</para> <programlisting> least_cost_functions=nova.scheduler.least_cost.compute_fill_first_cost_fn,nova.scheduler.least_cost.noop_cost_fn compute_fill_first_cost_fn_weight=-1.0 noop_cost_fn_weight=1.0 </programlisting> <para> If there are multiple cost functions, then the weighted cost scores are added together. The scheduler selects the host that has the minimum weighted cost.</para> <para> The Compute service comes with three cost functions: </para> <section xml:id=""compute_fill_first_cost_fn""> <title>nova.scheduler.least_cost.compute_fill_first_cost_fn</title> <para>This cost function calculates the amount of free memory (RAM) available on the node. Because the scheduler minimizes cost, if this cost function is used as a weight of +1, by doing: <programlisting> compute_fill_first_cost_fn_weight=1.0 </programlisting> then the scheduler will tend to ""fill up"" hosts, scheduling virtual machine instances to the same host until there is no longer sufficient RAM to service the request, and then moving to the next node</para> <para>If the user specifies a weight of -1 by doing: <programlisting> compute_fill_first_cost_fn_weight=-1.0 </programlisting> then the scheduler will favor hosts that have the most amount of available RAM, leading to a ""spread-first"" behavior.</para> </section> <section xml:id=""compute_retry_host_cost_fn""> <title>nova.scheduler.least_cost.retry_host_cost_fn</title> <para>This cost function adds additional cost for retrying scheduling a host that was already used for a previous scheduling attempt. </para> <para> The normal method of using this function is to set <literal>retry_host_cost_fn_weight</literal> to a positive value, so that hosts which consistently encounter build failures will be used less often.</para> </section> <section xml:id=""noop_cost_fn""> <title>nova.scheduler.least_cost.noop_cost_fn</title> <para>This cost function returns 1 for all hosts. It is a ""no-op"" cost function (i.e., it does not do anything to discriminate among hosts). In practice, this cost function is never used.</para> </section> <section xml:id=""compute-scheduler-config-ref""> <title>Configuration Reference</title> <xi:include href=""../common/tables/nova-scheduling.xml""/> </section>",28,87
openstack%2Fmurano~master~Ib70f7bfac23c4210c533ebc075b65acf4f15f4ca,openstack/murano,master,Ib70f7bfac23c4210c533ebc075b65acf4f15f4ca,Fixed injectinit function,MERGED,2013-07-18 13:43:22.000000000,2013-07-18 13:50:04.000000000,2013-07-18 13:50:04.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-18 13:43:22.000000000', 'files': ['setup-centos.sh'], 'web_link': 'https://opendev.org/openstack/murano/commit/de84824a8811e3a39475be8dbef98d16a58295e1', 'message': 'Fixed injectinit function\n\nChange-Id: Ib70f7bfac23c4210c533ebc075b65acf4f15f4ca\n'}]",0,37682,de84824a8811e3a39475be8dbef98d16a58295e1,5,2,1,7613,,,0,"Fixed injectinit function

Change-Id: Ib70f7bfac23c4210c533ebc075b65acf4f15f4ca
",git fetch https://review.opendev.org/openstack/murano refs/changes/82/37682/1 && git format-patch -1 --stdout FETCH_HEAD,['setup-centos.sh'],1,de84824a8811e3a39475be8dbef98d16a58295e1,setup-scripts,,"ln -s /lib/init/upstart-job /etc/init.d/$SERVICE_SRV_NAME if [ $? -ne 0 ]; then log ""Can't create symlink, please run \""$(basename ""$0"") purge-init\"" before \""$(basename ""$0"") inject-init\"", exiting"" exit 1 fi",0,5
openstack%2Fmurano-dashboard~master~I78cd2b4c5b7f2efaf952ab9be59b234918777da3,openstack/murano-dashboard,master,I78cd2b4c5b7f2efaf952ab9be59b234918777da3,Set optinal sa_password depends on checkbox,MERGED,2013-07-18 13:19:42.000000000,2013-07-18 13:43:57.000000000,2013-07-18 13:43:57.000000000,"[{'_account_id': 3}, {'_account_id': 7226}]","[{'number': 1, 'created': '2013-07-18 13:19:42.000000000', 'files': ['muranodashboard/templates/_create_service_wizard.html'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/7b4ed70e68024fad4ed02e48976e49b79b12a193', 'message': 'Set optinal sa_password depends on checkbox\n\nChange-Id: I78cd2b4c5b7f2efaf952ab9be59b234918777da3\n'}]",0,37679,7b4ed70e68024fad4ed02e48976e49b79b12a193,5,2,1,7549,,,0,"Set optinal sa_password depends on checkbox

Change-Id: I78cd2b4c5b7f2efaf952ab9be59b234918777da3
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/79/37679/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/templates/_create_service_wizard.html'],1,7b4ed70e68024fad4ed02e48976e49b79b12a193,add_new_js," $(""#id_msSqlServer-mixed_mode"").change(function(){ if ($(""#id_msSqlServer-mixed_mode"").prop('checked')){ $('#id_msSqlServer-password_field1').removeAttr('placeholder') $('#id_msSqlServer-password_field2').removeAttr('placeholder') } else { $('#id_msSqlServer-password_field1').attr('placeholder', 'Optional') $('#id_msSqlServer-password_field2').attr('placeholder', 'Optional') } })",,9,0
openstack%2Fceilometer~master~Ib2cef7d0d19d01ae996b8ef1721d01455d668e49,openstack/ceilometer,master,Ib2cef7d0d19d01ae996b8ef1721d01455d668e49,Refactored storage tests to use testscenarios,ABANDONED,2013-07-09 15:27:00.000000000,2013-07-18 13:20:23.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 6172}, {'_account_id': 6537}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-07-09 15:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e8223f29b5e869ce7bbbca86efcc4ef51389e73f', 'message': 'Refactored storage tests to use testscenarios\n\nReplaced empty inheritance hierarchy with testscrenarios\n\nImplements blueprint db-tests-with-scenarios\n\nChange-Id: Ib2cef7d0d19d01ae996b8ef1721d01455d668e49\n'}, {'number': 2, 'created': '2013-07-09 16:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/69cfd420d3ffd00392b4b8c5cd45eedffff10763', 'message': 'Refactored storage tests to use testscenarios\n\nReplaced empty inheritance hierarchy with testscrenarios\n\nImplements blueprint db-tests-with-scenarios\n\nChange-Id: Ib2cef7d0d19d01ae996b8ef1721d01455d668e49\n'}, {'number': 3, 'created': '2013-07-11 08:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6bf0502a29e7273a825b7e80218e77240237a3d3', 'message': 'Refactored storage tests to use testscenarios\n\nReplaced empty inheritance hierarchy with testscrenarios\n\nImplements blueprint db-tests-with-scenarios\n\nChange-Id: Ib2cef7d0d19d01ae996b8ef1721d01455d668e49\n'}, {'number': 4, 'created': '2013-07-11 08:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3d88e5a7ee1198a2cb1195d1283b1f6f05666794', 'message': 'Refactored storage tests to use testscenarios\n\nReplaced empty inheritance hierarchy with testscrenarios\n\nImplements blueprint db-tests-with-scenarios\n\nChange-Id: Ib2cef7d0d19d01ae996b8ef1721d01455d668e49\n'}, {'number': 5, 'created': '2013-07-15 08:15:29.000000000', 'files': ['tests/storage/base.py', 'tests/storage/test_impl_hbase.py', 'tests/storage/test_impl_sqlalchemy.py', 'tests/storage/test_storage.py', 'tests/storage/test_impl_mongodb.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f06776cbc89b47c9412b593f6406952c67ffe5a7', 'message': 'Refactored storage tests to use testscenarios\n\nReplaced empty inheritance hierarchy with testscrenarios\n\nImplements blueprint db-tests-with-scenarios\n\nChange-Id: Ib2cef7d0d19d01ae996b8ef1721d01455d668e49\n'}]",7,36237,f06776cbc89b47c9412b593f6406952c67ffe5a7,19,6,5,7763,,,0,"Refactored storage tests to use testscenarios

Replaced empty inheritance hierarchy with testscrenarios

Implements blueprint db-tests-with-scenarios

Change-Id: Ib2cef7d0d19d01ae996b8ef1721d01455d668e49
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/37/36237/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/storage/base.py', 'test-requirements.txt', 'tests/storage/test_impl_hbase.py', 'tests/storage/test_impl_sqlalchemy.py', 'tests/storage/test_storage.py', 'tests/storage/test_impl_mongodb.py']",6,e8223f29b5e869ce7bbbca86efcc4ef51389e73f,bp/db-tests-with-scenarios,,"from ceilometer.storage.impl_mongodb import require_map_reduceclass UserTest(base.UserTest, MongoDBEngineTestBase): pass class ProjectTest(base.ProjectTest, MongoDBEngineTestBase): pass class ResourceTest(base.ResourceTest, MongoDBEngineTestBase): pass class MeterTest(base.MeterTest, MongoDBEngineTestBase): pass class RawSampleTest(base.RawSampleTest, MongoDBEngineTestBase): pass class StatisticsTest(base.StatisticsTest, MongoDBEngineTestBase): def setUp(self): super(StatisticsTest, self).setUp() require_map_reduce(self.conn) class AlarmTest(base.AlarmTest, MongoDBEngineTestBase): pass class CounterDataTypeTest(base.CounterDataTypeTest, MongoDBEngineTestBase): pass",892,783
openstack%2Foslo-incubator~master~I96b2ee84da5a2dcd7f0bd469f8a1e52b74e50c75,openstack/oslo-incubator,master,I96b2ee84da5a2dcd7f0bd469f8a1e52b74e50c75,Move synchronized body to a first-class function,MERGED,2013-06-10 13:48:24.000000000,2013-07-18 13:11:19.000000000,2013-07-18 13:11:19.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1994}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6849}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-06-10 13:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/07a2959c9ef12f20cd94669544830539f2613834', 'message': 'Move synchronized body to a first-class function\n\nsynchronized is being widely used throughout OpenStack for managing\nlocks by decorating methods / functions. However, it\'s funcionality is\ntrapped within that decorator definition and makes it difficult to\nmanage locks by using it in other cases (like w/o decorating).\n\nThis patch moves decorator\'s body into a first-class function called\nlock which is intended to be used as a context manager type (with\nstatement).\n\nSome examples:\n\n    with lockutils.lock(""test"") as sem:\n        print(\'Inside the lock\')\n\nThings I\'m not 100% convinced:\n\n    * The `lock` function yields a Semaphore when external is False and\n    an InterProcessLock instance otherwise. Although it is not \'good\' to\n    yield different values depending on the input parameters, it\'s\n    pretty explicit (by reading the documentation) that external locks\n    are handled differently. Other options for this case are:\n\n        1. Always yield a Semaphore instance\n        2. Don\'t yield anything\n\nThe patch doesn\'t break backward compatibility so no change is needed to\nexisting projects.\n\nThis patch is needed as part of the blueprint cache-backend-abstraction\n\nChange-Id: I96b2ee84da5a2dcd7f0bd469f8a1e52b74e50c75\n'}, {'number': 2, 'created': '2013-06-11 08:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/fc73fd73284f6b20a8c8dbc80d78efdf79d5d4e2', 'message': 'Move synchronized body to a first-class function\n\nsynchronized is being widely used throughout OpenStack for managing\nlocks by decorating methods / functions. However, it\'s funcionality is\ntrapped within that decorator definition and makes it difficult to\nmanage locks by using it in other cases (like w/o decorating).\n\nThis patch moves decorator\'s body into a first-class function called\nlock which is intended to be used as a context manager type (with\nstatement).\n\nSome examples:\n\n    with lockutils.lock(""test"") as sem:\n        print(\'Inside the lock\')\n\nThings I\'m not 100% convinced:\n\n    * The `lock` function yields a Semaphore when external is False and\n    an InterProcessLock instance otherwise. Although it is not \'good\' to\n    yield different values depending on the input parameters, it\'s\n    pretty explicit (by reading the documentation) that external locks\n    are handled differently. Other options for this case are:\n\n        1. Always yield a Semaphore instance\n        2. Don\'t yield anything\n\nThe patch doesn\'t break backward compatibility so no change is needed to\nexisting projects.\n\nImplements blueprint cache-backend-abstraction\n\nChange-Id: I96b2ee84da5a2dcd7f0bd469f8a1e52b74e50c75\n'}, {'number': 3, 'created': '2013-06-11 10:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f59226b4a106d467043f4b6aef0e650f5b4284fe', 'message': 'Move synchronized body to a first-class function\n\nsynchronized is being widely used throughout OpenStack for managing\nlocks by decorating methods / functions. However, it\'s funcionality is\ntrapped within that decorator definition and makes it difficult to\nmanage locks by using it in other cases (like w/o decorating).\n\nThis patch moves decorator\'s body into a first-class function called\nlock which is intended to be used as a context manager type (with\nstatement).\n\nSome examples:\n\n    with lockutils.lock(""test"") as sem:\n        print(\'Inside the lock\')\n\nThings I\'m not 100% convinced:\n\n    * The `lock` function yields a Semaphore when external is False and\n    an InterProcessLock instance otherwise. Although it is not \'good\' to\n    yield different values depending on the input parameters, it\'s\n    pretty explicit (by reading the documentation) that external locks\n    are handled differently. Other options for this case are:\n\n        1. Always yield a Semaphore instance\n        2. Don\'t yield anything\n\nThe patch doesn\'t break backward compatibility so no change is needed to\nexisting projects.\n\nImplements blueprint cache-backend-abstraction\n\nChange-Id: I96b2ee84da5a2dcd7f0bd469f8a1e52b74e50c75\n'}, {'number': 4, 'created': '2013-06-11 18:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/56d0cbbda2fc8e92e0b06cfb47982f32456c32a1', 'message': 'Move synchronized body to a first-class function\n\nsynchronized is being widely used throughout OpenStack for managing\nlocks by decorating methods / functions. However, it\'s funcionality is\ntrapped within that decorator definition and makes it difficult to\nmanage locks by using it in other cases (like w/o decorating).\n\nThis patch moves decorator\'s body into a first-class function called\nlock which is intended to be used as a context manager type (with\nstatement).\n\nSome examples:\n\n    with lockutils.lock(""test"") as sem:\n        print(\'Inside the lock\')\n\nThings I\'m not 100% convinced:\n\n    * The `lock` function yields a Semaphore when external is False and\n    an InterProcessLock instance otherwise. Although it is not \'good\' to\n    yield different values depending on the input parameters, it\'s\n    pretty explicit (by reading the documentation) that external locks\n    are handled differently. Other options for this case are:\n\n        1. Always yield a Semaphore instance\n        2. Don\'t yield anything\n\nThe patch doesn\'t break backward compatibility so no change is needed to\nexisting projects.\n\nImplements blueprint cache-backend-abstraction\n\nChange-Id: I96b2ee84da5a2dcd7f0bd469f8a1e52b74e50c75\n'}, {'number': 5, 'created': '2013-07-15 15:33:18.000000000', 'files': ['openstack/common/lockutils.py', 'tests/unit/test_lockutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/27d4b4121e0c982c693e98ed5ac3bfe1d026fef5', 'message': 'Move synchronized body to a first-class function\n\nsynchronized is being widely used throughout OpenStack for managing\nlocks by decorating methods / functions. However, it\'s functionality is\ntrapped within that decorator definition and makes it difficult to\nmanage locks by using it in other cases (like w/o decorating).\n\nThis patch moves decorator\'s body into a first-class function called\nlock which is intended to be used as a context manager type (with\nstatement).\n\nSome examples:\n\n    with lockutils.lock(""test"") as sem:\n        print(\'Inside the lock\')\n\nThings I\'m not 100% convinced:\n\n    * The `lock` function yields a Semaphore when external is False and\n    an InterProcessLock instance otherwise. Although it is not \'good\' to\n    yield different values depending on the input parameters, it\'s\n    pretty explicit (by reading the documentation) that external locks\n    are handled differently. Other options for this case are:\n\n        1. Always yield a Semaphore instance\n        2. Don\'t yield anything\n\nThe patch doesn\'t break backward compatibility so no change is needed to\nexisting projects.\n\nImplements blueprint cache-backend-abstraction\n\nChange-Id: I96b2ee84da5a2dcd7f0bd469f8a1e52b74e50c75\n'}]",10,32400,27d4b4121e0c982c693e98ed5ac3bfe1d026fef5,23,7,5,6159,,,0,"Move synchronized body to a first-class function

synchronized is being widely used throughout OpenStack for managing
locks by decorating methods / functions. However, it's functionality is
trapped within that decorator definition and makes it difficult to
manage locks by using it in other cases (like w/o decorating).

This patch moves decorator's body into a first-class function called
lock which is intended to be used as a context manager type (with
statement).

Some examples:

    with lockutils.lock(""test"") as sem:
        print('Inside the lock')

Things I'm not 100% convinced:

    * The `lock` function yields a Semaphore when external is False and
    an InterProcessLock instance otherwise. Although it is not 'good' to
    yield different values depending on the input parameters, it's
    pretty explicit (by reading the documentation) that external locks
    are handled differently. Other options for this case are:

        1. Always yield a Semaphore instance
        2. Don't yield anything

The patch doesn't break backward compatibility so no change is needed to
existing projects.

Implements blueprint cache-backend-abstraction

Change-Id: I96b2ee84da5a2dcd7f0bd469f8a1e52b74e50c75
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/00/32400/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/lockutils.py', 'tests/unit/test_lockutils.py']",2,07a2959c9ef12f20cd94669544830539f2613834,bp/cache-backend-abstraction,"from eventlet import semaphore def test_contextlock(self): lock_dir = tempfile.mkdtemp() # Note(flaper87): Lock is not external, which means # a semaphore will be yielded with lockutils.lock(""test"") as sem: self.assertTrue(isinstance(sem, semaphore.Semaphore)) # NOTE(flaper87): Lock is external so an InterProcessLock # will be yielded. with lockutils.lock(""test2"", external=True, lock_path=lock_dir): path = os.path.join(lock_dir, ""test2"") self.assertTrue(os.path.exists(path)) with lockutils.lock(""test1"", external=True, lock_path=lock_dir) as lock1: self.assertTrue(isinstance(lock1, lockutils.InterProcessLock)) def test_contextlock_unlocks(self): lock_dir = tempfile.mkdtemp() sem = None with lockutils.lock(""test"") as sem: self.assertTrue(isinstance(sem, semaphore.Semaphore)) with lockutils.lock(""test2"", external=True, lock_path=lock_dir): path = os.path.join(lock_dir, ""test2"") self.assertTrue(os.path.exists(path)) # NOTE(flaper87): Lock should be free with lockutils.lock(""test2"", external=True, lock_path=lock_dir): path = os.path.join(lock_dir, ""test2"") self.assertTrue(os.path.exists(path)) # NOTE(flaper87): Lock should be free # but semaphore should already exist. with lockutils.lock(""test"") as sem2: self.assertEqual(sem, sem2)",,137,96
openstack%2Foslo-incubator~master~I3a8eb1ba5b2fb2859169299d37ae6eeb9bb4cac0,openstack/oslo-incubator,master,I3a8eb1ba5b2fb2859169299d37ae6eeb9bb4cac0,python3: Add basic compatibility support.,MERGED,2013-07-12 17:53:00.000000000,2013-07-18 13:10:48.000000000,2013-07-18 13:10:48.000000000,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 1994}, {'_account_id': 5638}, {'_account_id': 6159}]","[{'number': 1, 'created': '2013-07-12 17:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/39e66dd29db99d45645c22226148e67ac97ceee4', 'message': 'python3: Add basic compatibility support.\n\nAdd python2/python3 compatibility support:\n\n- Change basestring to use six.string_type so that\nsix will either use str() or basestring().\n- Use six.iteritems to replace dictionary.iteritems() on\npython2 or dictionary.items() on python3.\n\nChange-Id: I3a8eb1ba5b2fb2859169299d37ae6eeb9bb4cac0\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}, {'number': 2, 'created': '2013-07-15 18:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/8615dc68ff7a7bd4eb01f1e715bc4baff7a5e781', 'message': 'python3: Add basic compatibility support.\n\nAdd python2/python3 compatibility support:\n\n- Change basestring to use six.string_type so that\nsix will either use str() or basestring().\n- Use six.iteritems to replace dictionary.iteritems() on\npython2 or dictionary.items() on python3.\n\nChange-Id: I3a8eb1ba5b2fb2859169299d37ae6eeb9bb4cac0\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}, {'number': 3, 'created': '2013-07-17 20:30:25.000000000', 'files': ['openstack/common/scheduler/filters/json_filter.py', 'openstack/common/scheduler/filters/capabilities_filter.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c0d052a743b7f35c229b1024cbdc47be142658d5', 'message': 'python3: Add basic compatibility support.\n\nAdd python2/python3 compatibility support:\n\n- Change basestring to use six.string_type so that\nsix will either use str() or basestring().\n- Use six.iteritems to replace dictionary.iteritems() on\npython2 or dictionary.items() on python3.\n\nChange-Id: I3a8eb1ba5b2fb2859169299d37ae6eeb9bb4cac0\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",4,36867,c0d052a743b7f35c229b1024cbdc47be142658d5,14,5,3,24,,,0,"python3: Add basic compatibility support.

Add python2/python3 compatibility support:

- Change basestring to use six.string_type so that
six will either use str() or basestring().
- Use six.iteritems to replace dictionary.iteritems() on
python2 or dictionary.items() on python3.

Change-Id: I3a8eb1ba5b2fb2859169299d37ae6eeb9bb4cac0
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/67/36867/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/scheduler/filters/json_filter.py', 'openstack/common/scheduler/filters/capabilities_filter.py']",2,39e66dd29db99d45645c22226148e67ac97ceee4,(detached,"import six for key, req in six.iteritems(extra_specs):"," for key, req in extra_specs.iteritems():",6,3
openstack%2Foslo.config~master~I3ac149345561a5bb99e017022ba2e2be10154584,openstack/oslo.config,master,I3ac149345561a5bb99e017022ba2e2be10154584,Add Python 3 support,MERGED,2013-07-16 15:42:30.000000000,2013-07-18 13:10:40.000000000,2013-07-18 13:10:40.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 5638}]","[{'number': 1, 'created': '2013-07-16 15:42:30.000000000', 'files': ['oslo/config/cfg.py', 'test-requirements-py3.txt', 'tox.ini', 'tests/test_cfg.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/305ecd817836a90a8f5e495cbf6a770dcea1f7e8', 'message': 'Add Python 3 support\n\nThese are the final changes needed to have the full py33 tox environment\nrunning and passing all tests.\n\nChange-Id: I3ac149345561a5bb99e017022ba2e2be10154584\n'}]",0,37276,305ecd817836a90a8f5e495cbf6a770dcea1f7e8,8,4,1,1669,,,0,"Add Python 3 support

These are the final changes needed to have the full py33 tox environment
running and passing all tests.

Change-Id: I3ac149345561a5bb99e017022ba2e2be10154584
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/76/37276/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/config/cfg.py', 'test-requirements-py3.txt', 'tox.ini', 'tests/test_cfg.py']",4,305ecd817836a90a8f5e495cbf6a770dcea1f7e8,jd/python3,"import six self.assertRaises(AttributeError, getattr, self.conf, 'foo') self.assertRaises(cfg.NoSuchOptError, self.conf._get, 'foo') self.assertRaises(AttributeError, getattr, self.conf, 'foo') self.assertRaises(cfg.ConfigFileValueError, self.conf._get, 'foo') AttributeError, getattr, self.conf, 'bar') self.assertRaises( cfg.TemplateSubstitutionError, self.conf._get, 'bar') tmpfile.write(six.b('foo = bar')) self.assertRaises(cfg.ConfigFileValueError, self.conf._get, 'foo') self.assertRaises(AttributeError, getattr, self.conf, 'foo')"," self.assertRaises(cfg.NoSuchOptError, getattr, self.conf, 'foo') self.assertRaises(cfg.ConfigFileValueError, getattr, self.conf, 'foo') cfg.TemplateSubstitutionError, getattr, self.conf, 'bar') tmpfile.write('foo = bar') self.assertRaises(cfg.ConfigFileValueError, getattr, self.conf, 'foo')",50,7
openstack%2Fmurano-dashboard~master~I602e37eeec9b35eb81103891dc57a06d917f5ec8,openstack/murano-dashboard,master,I602e37eeec9b35eb81103891dc57a06d917f5ec8,Add flavor to service creation parameter.,MERGED,2013-07-18 11:36:55.000000000,2013-07-18 12:52:51.000000000,2013-07-18 12:52:51.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7549}]","[{'number': 1, 'created': '2013-07-18 11:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/db20f58b6770fb5b05217bec099f97098c483516', 'message': 'Add flavor to service creation parameter\n\nChange-Id: I602e37eeec9b35eb81103891dc57a06d917f5ec8\n'}, {'number': 2, 'created': '2013-07-18 11:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/a9ebb309cd23b3b5dc8722d511c955e7e0fb271f', 'message': 'Add flavor to service creation parameter.\n\nChange-Id: I602e37eeec9b35eb81103891dc57a06d917f5ec8\n'}, {'number': 3, 'created': '2013-07-18 12:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/d127fdc642c7282ea2468c2fdfa2229d41690ce8', 'message': 'Add flavor to service creation parameter.\n\nChange-Id: I602e37eeec9b35eb81103891dc57a06d917f5ec8\n'}, {'number': 4, 'created': '2013-07-18 12:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/48c0a99f2ee9cbde09bdea106fc201c996c6cf06', 'message': 'Add flavor to service creation parameter.\n\nChange-Id: I602e37eeec9b35eb81103891dc57a06d917f5ec8\n'}, {'number': 5, 'created': '2013-07-18 12:46:51.000000000', 'files': ['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/forms.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f55d61f8b5fa2e0516db2980a6c3fbf7b2b4fffc', 'message': 'Add flavor to service creation parameter.\n\nChange-Id: I602e37eeec9b35eb81103891dc57a06d917f5ec8\n'}]",0,37663,f55d61f8b5fa2e0516db2980a6c3fbf7b2b4fffc,13,3,5,7549,,,0,"Add flavor to service creation parameter.

Change-Id: I602e37eeec9b35eb81103891dc57a06d917f5ec8
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/63/37663/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/forms.py']",3,db20f58b6770fb5b05217bec099f97098c483516,add_flavor_to_params,"class ServiceConfigurationForm(forms.Form): def clean(self): def compare(pwd1, pwd2, admin=True): if pwd1 != pwd2: pwd_type = 'Administrator' if not admin: pwd_type = 'Recovery' raise forms.ValidationError( _(' %s passwords don\'t match' % pwd_type)) form_data = self.cleaned_data admin_pwd1 = form_data.get('adm_password') admin_pwd2 = form_data.get('adm_password2') compare(admin_pwd1, admin_pwd2) second_pwd1 = form_data.get('password_field') if second_pwd1: second_pwd2 = form_data.get('password_field2') compare(second_pwd1, second_pwd2, admin=False) return self.cleaned_data class WizardFormADConfiguration(ServiceConfigurationForm,class WizardFormIISConfiguration(ServiceConfigurationForm,class WebFarmExtension(ServiceConfigurationForm): #TODO: uncomment this when custom filter for valid template will be created # try: # # public filter removed # public_images, _more = glance.image_list_detailed(request) # except: # public_images = [] # exceptions.handle(request, # _(""Unable to retrieve public images."")) # # choices = [(image.id, image.name) # for image in public_images # if image.properties.get(""image_type"", '') != ""snapshot""] # if choices: # choices.insert(0, ("""", _(""Select Image""))) # else: # choices.insert(0, ("""", _(""No images available.""))) # # self.fields['image'].choices = choices","class WizardFormADConfiguration(forms.Form, def clean(self): def compare(pwd1, pwd2, admin=True): if pwd1 != pwd2: pwd_type = 'Administrator' if not admin: pwd_type = 'Recovery' raise forms.ValidationError( _(' %s passwords don\'t match' % pwd_type)) form_data = self.cleaned_data admin_pwd1 = form_data.get('adm_password') admin_pwd2 = form_data.get('adm_password2') compare(admin_pwd1, admin_pwd2) second_pwd1 = form_data.get('password_field') if second_pwd1: second_pwd2 = form_data.get('password_field2') compare(second_pwd1, second_pwd2, admin=False) return self.cleaned_data class WizardFormIISConfiguration(forms.Form,class WebFarmExtension(forms.Form): def clean(self): form_data = self.cleaned_data mixed_mode = form_data.get('mixed_mode') if mixed_mode: self.fields['password_field'].required = True try: # public filter removed public_images, _more = glance.image_list_detailed(request) except: public_images = [] exceptions.handle(request, _(""Unable to retrieve public images."")) choices = [(image.id, image.name) for image in public_images if image.properties.get(""image_type"", '') != ""snapshot""] if choices: choices.insert(0, ("""", _(""Select Image""))) else: choices.insert(0, ("""", _(""No images available.""))) self.fields['image'].choices = choices",47,47
openstack%2Fnova~master~I61ed9a26b10b0cd8c8623ea7c3aeeb3c744accff,openstack/nova,master,I61ed9a26b10b0cd8c8623ea7c3aeeb3c744accff,Regenerate nova.conf.sample,ABANDONED,2013-07-17 02:19:51.000000000,2013-07-18 12:51:52.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-07-17 02:19:51.000000000', 'files': ['etc/nova/nova.conf.sample'], 'web_link': 'https://opendev.org/openstack/nova/commit/605316a3ececf2435f210d4a4b28e61403910be2', 'message': 'Regenerate nova.conf.sample\n\nChange-Id: I61ed9a26b10b0cd8c8623ea7c3aeeb3c744accff\n'}]",0,37375,605316a3ececf2435f210d4a4b28e61403910be2,3,3,1,1994,,,0,"Regenerate nova.conf.sample

Change-Id: I61ed9a26b10b0cd8c8623ea7c3aeeb3c744accff
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/37375/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/nova/nova.conf.sample'],1,605316a3ececf2435f210d4a4b28e61403910be2,conf_update,"# whether to use per-user rate limiting for the api. (boolean # value)# Options defined in nova.api.openstack.compute.plugins.v3.hide_server_addresses # # List of instance states that should hide network info (list # value) #osapi_hide_server_address_states=building ## Options defined in nova.cells.opts # # The full class name of the compute API class to use # (deprecated) (string value) #compute_api_class=nova.compute.api.API ## Number of times to retry network allocation on failures # (integer value) #network_allocate_retries=0 # Interval in seconds for polling shelved instances to offload # (integer value) #shelved_poll_interval=3600 # Time in seconds before a shelved instance is eligible for # removing from a host. -1 never offload, 0 offload when # shelved (integer value) #shelved_offload_time=0 # DEPRECATED. A logging.Formatter log message format string # which may use any of the available logging.LogRecord # attributes. This option is deprecated. Please use#default_publisher_id=<None># Virtual CPU to physical CPU allocation ratio which affects # all CPU filters. This configuration specifies a global ratio # for CoreFilter. For AggregateCoreFilter, it will fall back # to this configuration value if no per-aggregate setting # found. (floating point value)# Virtual ram to physical ram allocation ratio which affects # all ram filters. This configuration specifies a global ratio # for RamFilter. For AggregateRamFilter, it will fall back to # this configuration value if no per-aggregate setting found. # (floating point value)# Number of seconds after which a lack of capability and # capacity updates signals the child cell is to be treated as # a mute. (integer value) #mute_child_interval=300 # Seconds between bandwidth updates for cells. (integer value) #bandwidth_update_interval=600 # Configuration file from which to read cells configuration. # If given, overrides reading cells from the database. (string # value) #cells_config=<None> # If set, pass the network configuration details to the # initramfs via cmdline. (boolean value) #pxe_network_config=false [upgrade_levels] # # Options defined in nova.baserpc # # Set a version cap for messages sent to the base api in any # service (string value) #baseapi=<None> # # Options defined in nova.cells.rpc_driver # # Set a version cap for messages sent between cells services # (string value) #intercell=<None> # # Options defined in nova.cells.rpcapi # # Set a version cap for messages sent to local cells services # (string value) #cells=<None> # # Options defined in nova.cert.rpcapi # # Set a version cap for messages sent to cert services (string # value) #cert=<None> # # Options defined in nova.compute.rpcapi # # Set a version cap for messages sent to compute services # (string value) #compute=<None> # # Options defined in nova.conductor.rpcapi # # Set a version cap for messages sent to conductor services # (string value) #conductor=<None> # # Options defined in nova.console.rpcapi # # Set a version cap for messages sent to console services # (string value) #console=<None> # # Options defined in nova.consoleauth.rpcapi # # Set a version cap for messages sent to consoleauth services # (string value) #consoleauth=<None> # # Options defined in nova.network.rpcapi # # Set a version cap for messages sent to network services # (string value) #network=<None> # # Options defined in nova.scheduler.rpcapi # # Set a version cap for messages sent to scheduler services # (string value) #scheduler=<None> [matchmaker_ring] # # Options defined in nova.openstack.common.rpc.matchmaker_ring # # Matchmaker ring file (JSON) (string value) #ringfile=/etc/oslo/matchmaker_ring.json # Total option count: 623",# whether to rate limit the api (boolean value)# Options defined in nova.api.openstack.compute.contrib.hide_server_addresses # # List of instance states that should hide network info (list # value) #osapi_hide_server_address_states=building ## Options defined in nova.compute # # The full class name of the compute API class to use # (deprecated) (string value) #compute_api_class=nova.compute.api.API ## A logging.Formatter log message format string which may use # any of the available logging.LogRecord attributes. This # option is deprecated. Please use#default_publisher_id=$host# Options defined in nova.openstack.common.rpc.amqp # # Enable a fast single reply queue if using AMQP based RPC # like RabbitMQ or Qpid. (boolean value) #amqp_rpc_single_reply_queue=false ## Matchmaker ring file (JSON) (string value) #matchmaker_ringfile=/etc/nova/matchmaker_ring.json # Virtual CPU to Physical CPU allocation ratio (floating point # value)# virtual ram to physical ram allocation ratio (floating point # value)# Number of seconds after which a lack of capability and # capacity updates signals the child cell is to be treated as # a mute. (integer value) #mute_child_interval=300 # Total option count: 608,167,45
openstack%2Foslo-incubator~master~I61e961248241014380ec464429f2585a9497333b,openstack/oslo-incubator,master,I61e961248241014380ec464429f2585a9497333b,python3: Add basic python3 compatibility.,MERGED,2013-07-12 18:32:32.000000000,2013-07-18 12:36:45.000000000,2013-07-18 12:36:45.000000000,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 6159}]","[{'number': 1, 'created': '2013-07-12 18:32:32.000000000', 'files': ['openstack/common/gettextutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/45e0cbe52d0a29ad54105cfebd1b8d347cef7cfa', 'message': 'python3: Add basic python3 compatibility.\n\nUse six.text_type to replace unicode() in python2\nand str in python3.\n\nChange-Id: I61e961248241014380ec464429f2585a9497333b\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",0,36878,45e0cbe52d0a29ad54105cfebd1b8d347cef7cfa,7,3,1,24,,,0,"python3: Add basic python3 compatibility.

Use six.text_type to replace unicode() in python2
and str in python3.

Change-Id: I61e961248241014380ec464429f2585a9497333b
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/78/36878/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/gettextutils.py'],1,45e0cbe52d0a29ad54105cfebd1b8d347cef7cfa,,import six return six.text_type(full_msg), return unicode(full_msg),3,1
openstack%2Foslo-incubator~master~Id3d08c23f7791bfef9739f1f65af844fd429777c,openstack/oslo-incubator,master,Id3d08c23f7791bfef9739f1f65af844fd429777c,Remove the unused notifier.add_driver() API,MERGED,2013-06-19 06:19:51.000000000,2013-07-18 12:35:19.000000000,2013-07-18 12:35:19.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-06-19 06:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3dd1866255f0361b2a74ddfb94d0b88e5963cb8f', 'message': 'Remove the unused notifier.add_driver() API\n\nThis was only needed to support the plugins framework which is now\nremoved.\n\nChange-Id: Id3d08c23f7791bfef9739f1f65af844fd429777c\n'}, {'number': 2, 'created': '2013-06-19 07:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/6f161468bdb569890bf1854134127cbc8d62e617', 'message': 'Remove the unused notifier.add_driver() API\n\nThis was only needed to support the plugins framework which is now\nremoved.\n\nChange-Id: Id3d08c23f7791bfef9739f1f65af844fd429777c\n'}, {'number': 3, 'created': '2013-07-08 22:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/20233d1690d66b5a935f4c3ed53fc74d6fcc29ae', 'message': 'Remove the unused notifier.add_driver() API\n\nThis was only needed to support the plugins framework which is now\nremoved.\n\nChange-Id: Id3d08c23f7791bfef9739f1f65af844fd429777c\n'}, {'number': 4, 'created': '2013-07-08 22:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/1c295343b921dfd00465c10ec69b689f6ca7f2a5', 'message': 'Remove the unused notifier.add_driver() API\n\nThis was only needed to support the plugins framework which is now\nremoved.\n\nChange-Id: Id3d08c23f7791bfef9739f1f65af844fd429777c\n'}, {'number': 5, 'created': '2013-07-16 15:09:47.000000000', 'files': ['tests/unit/test_notifier.py', 'openstack/common/notifier/api.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/593aa3db3d94a1cd8024a64b7af865387483c21e', 'message': 'Remove the unused notifier.add_driver() API\n\nThis was only needed to support the plugins framework which is now\nremoved.\n\nChange-Id: Id3d08c23f7791bfef9739f1f65af844fd429777c\n'}]",4,33598,593aa3db3d94a1cd8024a64b7af865387483c21e,22,7,5,1247,,,0,"Remove the unused notifier.add_driver() API

This was only needed to support the plugins framework which is now
removed.

Change-Id: Id3d08c23f7791bfef9739f1f65af844fd429777c
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/98/33598/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_notifier.py', 'openstack/common/notifier/api.py']",2,3dd1866255f0361b2a74ddfb94d0b88e5963cb8f,, _add_driver(notification_driver)def _add_driver(notification_driver):, add_driver(notification_driver)def add_driver(notification_driver):,2,39
openstack%2Fmurano-deployment~master~I4dc89779e38de5d075411f143706a51a8087dbd3,openstack/murano-deployment,master,I4dc89779e38de5d075411f143706a51a8087dbd3,"wpi,ps1 for WS 2012 STD updated.",MERGED,2013-07-18 12:03:18.000000000,2013-07-18 12:32:28.000000000,2013-07-18 12:32:28.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-18 12:03:18.000000000', 'files': ['image-builder/share/scripts/ws-2012-std/wpi.ps1'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/05ed0a9eea51c283b71755f10a35fb94aa30dfb5', 'message': 'wpi,ps1 for WS 2012 STD updated.\n\nChange-Id: I4dc89779e38de5d075411f143706a51a8087dbd3\n'}]",0,37668,05ed0a9eea51c283b71755f10a35fb94aa30dfb5,5,2,1,7562,,,0,"wpi,ps1 for WS 2012 STD updated.

Change-Id: I4dc89779e38de5d075411f143706a51a8087dbd3
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/68/37668/1 && git format-patch -1 --stdout FETCH_HEAD,['image-builder/share/scripts/ws-2012-std/wpi.ps1'],1,05ed0a9eea51c283b71755f10a35fb94aa30dfb5,ws-2012-std-scripts-update,,,0,0
openstack%2Fdevstack~master~Ic1369cc05861686daae36ec8e5f96b687cac728c,openstack/devstack,master,Ic1369cc05861686daae36ec8e5f96b687cac728c,Remove notify_on_any_change,MERGED,2013-07-17 14:27:34.000000000,2013-07-18 12:32:22.000000000,2013-07-18 12:32:22.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-17 14:27:34.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/4594eb9271e9e3b71a304f61af8c35e82a7059be', 'message': 'Remove notify_on_any_change\n\nThis option has been removed from Nova.\n\nChange-Id: Ic1369cc05861686daae36ec8e5f96b687cac728c\n'}]",0,37484,4594eb9271e9e3b71a304f61af8c35e82a7059be,6,3,1,1669,,,0,"Remove notify_on_any_change

This option has been removed from Nova.

Change-Id: Ic1369cc05861686daae36ec8e5f96b687cac728c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/84/37484/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,4594eb9271e9e3b71a304f61af8c35e82a7059be,jd/remove-notify-on-any-chance,," iniset $NOVA_CONF DEFAULT notify_on_any_change ""True""",0,1
openstack%2Fsahara~master~If41e76474c29f764898a824ab324889c6cf2e85b,openstack/sahara,master,If41e76474c29f764898a824ab324889c6cf2e85b,Fix sqlalchemy CompileError,MERGED,2013-07-17 14:30:54.000000000,2013-07-18 12:00:14.000000000,2013-07-18 12:00:14.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-17 14:30:54.000000000', 'files': ['savanna/utils/sqlatypes.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/881006f638dd648db3d1f9681c33c6d2bc6a30b8', 'message': 'Fix sqlalchemy CompileError\n\nThis bug was replicated to mysql database.\n\nChange-Id: If41e76474c29f764898a824ab324889c6cf2e85b\nFixes: bug #1201438\n'}]",0,37485,881006f638dd648db3d1f9681c33c6d2bc6a30b8,9,3,1,7710,,,0,"Fix sqlalchemy CompileError

This bug was replicated to mysql database.

Change-Id: If41e76474c29f764898a824ab324889c6cf2e85b
Fixes: bug #1201438
",git fetch https://review.opendev.org/openstack/sahara refs/changes/85/37485/1 && git format-patch -1 --stdout FETCH_HEAD,['savanna/utils/sqlatypes.py'],1,881006f638dd648db3d1f9681c33c6d2bc6a30b8,bug/1201438, impl = st.TEXT, impl = st.VARCHAR,1,1
openstack%2Fmurano~master~Ifdf8b4ed0b2aba71fafd03431e66f1937fea66fa,openstack/murano,master,Ifdf8b4ed0b2aba71fafd03431e66f1937fea66fa,"Modified pip search, garbage deleted",MERGED,2013-07-18 11:48:22.000000000,2013-07-18 11:52:59.000000000,2013-07-18 11:52:59.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-18 11:48:22.000000000', 'files': ['setup-centos.sh'], 'web_link': 'https://opendev.org/openstack/murano/commit/6a88489524550847a2301cf55b7997d6f3d1f6eb', 'message': 'Modified pip search, garbage deleted\n\nChange-Id: Ifdf8b4ed0b2aba71fafd03431e66f1937fea66fa\n'}]",0,37665,6a88489524550847a2301cf55b7997d6f3d1f6eb,5,2,1,7613,,,0,"Modified pip search, garbage deleted

Change-Id: Ifdf8b4ed0b2aba71fafd03431e66f1937fea66fa
",git fetch https://review.opendev.org/openstack/murano refs/changes/65/37665/1 && git format-patch -1 --stdout FETCH_HEAD,['setup-centos.sh'],1,6a88489524550847a2301cf55b7997d6f3d1f6eb,setup-scripts,"PIPAPPS=""pip python-pip pip-python"" PIPCMD="""" exit 1# find pip find_pip() { for cmd in $PIPAPPS do _cmd=$(which $cmd 2>/dev/null) if [ $? -eq 0 ];then break fi done if [ -z $_cmd ];then echo ""Can't find \""pip\"" in system, please install it first, exiting!"" exit 1 else PIPCMD=$_cmd fi } # Find python pip find_pip log ""$MRN_CND_SPY output:_____________________________________________________________"" rm -rf $SERVICE_CONTENT_DIRECTORY/*.egg-info $PIPCMD install $SERVICE_CONTENT_DIRECTORY/dist/$TRBL_FILE log ""$PIPCMD install \""$TRBL_FILE\"" FAILS, exiting!!!"" log ""Reloading initctl"" initctl reload-configuration rm -f /etc/init/$SERVICE_SRV_NAME.conf log ""Reloading initctl"" initctl reload-configuration find_pip _pkg=$($PIPCMD freeze | grep $PYPKG) $PIPCMD uninstall $_pkg --yes echo -e ""Usage: $(basename ""$0"") command \nCommands:\n\tinstall - Install $SERVICE_SRV_NAME software\n\tuninstall - Uninstall $SERVICE_SRV_NAME software\n\tinject-init - Add $SERVICE_SRV_NAME to the system start-up\n\tpurge-init - Remove $SERVICE_SRV_NAME from the system start-up"""," exit #MRN_CND_SPY=$GIT_CLONE_DIR/$SERVICE_SRV_NAME/setup.py log ""$MRN_CND_SPY output:_____________________________________________________________"" #cd $GIT_CLONE_DIR/$SERVICE_SRV_NAME && $MRN_CND_SPY install #if [ $? -ne 0 ]; then # log ""\""$MRN_CND_SPY\"" python setup FAILS, exiting!"" # exit 1 #fi #cd $GIT_CLONE_DIR/$SERVICE_SRV_NAME && $MRN_CND_SPY sdist rm -rf $SERVICE_CONTENT_DIRECTORY/*.egg-info #TRBL_FILE=$(basename `ls $GIT_CLONE_DIR/$SERVICE_SRV_NAME/dist/*.tar.gz`) #pip install $GIT_CLONE_DIR/$SERVICE_SRV_NAME/dist/$TRBL_FILE pip install $SERVICE_CONTENT_DIRECTORY/dist/$TRBL_FILE log ""pip install \""$TRBL_FILE\"" FAILS, exiting!!!"" #for file in `ls $GIT_CLONE_DIR/$SERVICE_SRV_NAME/etc` #cp -f ""$GIT_CLONE_DIR/$SERVICE_SRV_NAME/etc/$file"" ""$ETC_CFG_DIR/$file.sample""log ""Reloading initctl"" initctl reload-configuration rm -f /etc/init.d/$SERVICE_SRV_NAME rm -f /etc/init/$SERVICE_SRV_NAME.conf log ""Reloading initctl"" initctl reload-configuration pip freeze | grep $PYPKG pip uninstall $PYPKG --yes echo ""Usage: $(basename ""$0"") command \nCommands:\n\tinstall - Install $SERVICE_SRV_NAME software\n\tuninstall - Uninstall $SERVICE_SRV_NAME software\n\tinject-init - Add $SERVICE_SRV_NAME to the system start-up\n\tpurge-init - Remove $SERVICE_SRV_NAME from the system start-up""",36,26
openstack%2Fsahara~master~I5c10fbdfed4d7aeedaa70d5ea06790342326ae90,openstack/sahara,master,I5c10fbdfed4d7aeedaa70d5ea06790342326ae90,Documents typo fixes,MERGED,2013-07-18 11:40:19.000000000,2013-07-18 11:47:14.000000000,2013-07-18 11:47:14.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-18 11:40:19.000000000', 'files': ['doc/source/userdoc/rest_api_v1.0.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/bbc107e1f9f81b62db262f969416ec37d19a5577', 'message': 'Documents typo fixes\n\n* Fixed url for get cluster list\n* default_image_id typo fixes\n\nChange-Id: I5c10fbdfed4d7aeedaa70d5ea06790342326ae90\n'}]",0,37664,bbc107e1f9f81b62db262f969416ec37d19a5577,6,3,1,7125,,,0,"Documents typo fixes

* Fixed url for get cluster list
* default_image_id typo fixes

Change-Id: I5c10fbdfed4d7aeedaa70d5ea06790342326ae90
",git fetch https://review.opendev.org/openstack/sahara refs/changes/64/37664/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/userdoc/rest_api_v1.0.rst'],1,bbc107e1f9f81b62db262f969416ec37d19a5577,doc-improvements,".. http:get:: /v1.0/{tenant_id}/clusters ""default_image_id"": ""db12c199-d0b5-47d3-8a97-e95eeaeae615"", ""default_image_id"": ""db12c199-d0b5-47d3-8a97-e95eeaeae615"",",".. http:get:: /v1.0/{tenant_id}/cluster-templates ""default_iamge_id"": ""db12c199-d0b5-47d3-8a97-e95eeaeae615"", ""default_iamge_id"": ""db12c199-d0b5-47d3-8a97-e95eeaeae615"",",3,3
openstack%2Fsahara~master~Ifeb1c75c4fc220528568db1a6c10ceec84c4cfb4,openstack/sahara,master,Ifeb1c75c4fc220528568db1a6c10ceec84c4cfb4,Unit tests for scaling validation,MERGED,2013-07-15 14:06:44.000000000,2013-07-18 11:31:31.000000000,2013-07-18 11:31:30.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7478}, {'_account_id': 7729}]","[{'number': 1, 'created': '2013-07-15 14:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4d789c717a4515e2d4fdbe4545d2da42e5e1037b', 'message': 'Unit tests for scaling validation\n\nChange-Id: Ifeb1c75c4fc220528568db1a6c10ceec84c4cfb4\n'}, {'number': 2, 'created': '2013-07-16 10:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9e0c9341a87477c2bf0b9cd53713f59c151c7497', 'message': 'Unit tests for scaling validation\n\nChange-Id: Ifeb1c75c4fc220528568db1a6c10ceec84c4cfb4\n'}, {'number': 3, 'created': '2013-07-18 09:36:22.000000000', 'files': ['savanna/tests/unit/service/test_validation.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/337300b532a864554780c343ec6acf9d8843aeb3', 'message': 'Unit tests for scaling validation\n\nFixes: bug #1202567\n\nChange-Id: Ifeb1c75c4fc220528568db1a6c10ceec84c4cfb4\n'}]",7,37056,337300b532a864554780c343ec6acf9d8843aeb3,29,6,3,7729,,,0,"Unit tests for scaling validation

Fixes: bug #1202567

Change-Id: Ifeb1c75c4fc220528568db1a6c10ceec84c4cfb4
",git fetch https://review.opendev.org/openstack/sahara refs/changes/56/37056/3 && git format-patch -1 --stdout FETCH_HEAD,['savanna/tests/unit/service/test_validation.py'],1,4d789c717a4515e2d4fdbe4545d2da42e5e1037b,bug/1202567,"import savanna.db.models as m from savanna import exceptions as exfrom savanna.service.validations import clusters_scaling as c_sclass TestObjectCreatingValidation(unittest2.TestCase): class TestScalingValidation(unittest2.TestCase): def setUp(self): api.plugin_base.setup_plugins() @mock.patch('savanna.service.api.get_cluster') @mock.patch('savanna.plugins.base.PluginManager.get_plugin') def tryCheckScaling(self, get_plugin_p, get_cluster_p, data, cluster, expected_message): def _get_plugin(plugin_name): if plugin_name == 'vanilla': return plugin.VanillaProvider() return None get_cluster_p.return_value = cluster get_plugin_p.side_effect = _get_plugin with self.assertRaises(ex.InvalidException): try: c_s.check_cluster_scaling(data, cluster.id) except ex.InvalidException, e: self.assertEqual(expected_message, e.message) raise e def test_check_cluster_scaling_resize_ng(self): cluster = m.Cluster('test-cluster', 'tenant', 'vanilla', '1.2.2') cluster.status = 'Validating' ng = m.NodeGroup('ng', '42', ['namenode'], 1) cluster.node_groups.append(ng) self.tryCheckScaling(data={}, cluster=cluster, expected_message=""Cluster cannot be scaled "" ""not in 'Active' "" ""status. Cluster status: "" ""Validating"") cluster.status = 'Active' data = { 'resize_node_groups': [ { 'name': 'a', 'flavor_id': '42', 'node_processes': ['namenode'] } ], 'add_node_groups': [] } self.tryCheckScaling(data=data, cluster=cluster, expected_message=""Cluster doesn't contain "" ""node group with name 'a'"") data.update({'resize_node_groups': [ { 'name': 'a', 'flavor_id': '42', 'node_processes': ['namenode'] }, { 'name': 'a', 'flavor_id': '42', 'node_processes': ['namenode'] } ]}) self.tryCheckScaling(data=data, cluster=cluster, expected_message='Duplicates in node ' 'group names are detected') def test_check_cluster_scaling_add_ng(self): cluster = m.Cluster('test-cluster', 'tenant', 'vanilla', '1.2.2') ng = m.NodeGroup('ng', '42', ['namenode'], 1) cluster.node_groups.append(ng) cluster.status = 'Active' data = { 'resize_node_groups': [], 'add_node_groups': [ { 'name': 'a', 'flavor_id': '42', 'node_processes': ['namenode'] }, { 'name': 'a', 'flavor_id': '42', 'node_processes': ['namenode'] } ] } self.tryCheckScaling(data=data, cluster=cluster, expected_message='Duplicates in node ' 'group names are detected') data = { 'resize_node_groups': [], 'add_node_groups': [ { 'name': 'ng', 'flavor_id': '42', 'node_processes': ['namenode'] }, ] } self.tryCheckScaling(data=data, cluster=cluster, expected_message=""Can't add new nodegroup. "" ""Cluster already has nodegroup "" ""with name 'ng'"") def _assert_calls(self, mock, call_info): if not call_info: self.assertEqual(mock.call_count, 0) else: self.assertEqual(mock.call_count, call_info[0]) self.assertEqual(mock.call_args[0][0].code, call_info[1]) self.assertEqual(mock.call_args[0][0].message, call_info[2]) @mock.patch(""savanna.utils.api.request_data"") @mock.patch(""savanna.utils.api.bad_request"") def _assert_cluster_scaling_validation(self, bad_req, req_data, data, bad_req_i=None): m_func = mock.Mock() m_func.__name__ = ""m_func"" req_data.return_value = data v.validate(c_s.CLUSTER_SCALING_SCHEMA, self._create_object_fun)(m_func)(data=data) self.assertEqual(req_data.call_count, 1) self._assert_calls(bad_req, bad_req_i) def test_cluster_scaling_scheme_validation(self): self._create_object_fun = mock.Mock() data = { } self._assert_cluster_scaling_validation( data=data, bad_req_i=(1, 'VALIDATION_ERROR', u'{} is not valid under any of the given schemas') ) data = { 'resize_node_groups': [], 'add_node_groups': [] } self._assert_cluster_scaling_validation( data=_update_data(data, {'resize_node_groups': {}}), bad_req_i=(1, 'VALIDATION_ERROR', u""{} is not of type 'array'"") ) self._assert_cluster_scaling_validation( data=_update_data(data, { 'resize_node_groups': [], 'add_node_groups': {} }), bad_req_i=(1, 'VALIDATION_ERROR', u'[] is too short') ) data = { 'resize_node_groups': [ { } ] } self._assert_cluster_scaling_validation( data=data, bad_req_i=(1, 'VALIDATION_ERROR', u""'name' is a required property"") ) data = { 'resize_node_groups': [ { 'name': 'a' } ] } self._assert_cluster_scaling_validation( data=data, bad_req_i=(1, 'VALIDATION_ERROR', u""'count' is a required property"") ) data = { 'add_node_groups': [ { ""node_group_template_id"": ""5185a809-6bf7-"" ""44ed-9de3-618270550e2c"", } ] } self._assert_cluster_scaling_validation( data=data, bad_req_i=(1, 'VALIDATION_ERROR', ""{'node_group_template_id': "" ""'5185a809-6bf7-44ed-9de3-618270550e2c'} "" ""is not valid under any of the given schemas"") ) data = { 'add_node_groups': [ { ""node_group_template_id"": ""5185a809-6bf7-"" ""44ed-9de3-618270550e2c"", 'name': 'a' } ] } self._assert_cluster_scaling_validation( data=data, bad_req_i=(1, 'VALIDATION_ERROR', u""{'node_group_template_id': "" u""'5185a809-6bf7-44ed-9de3-618270550e2c', "" u""'name': 'a'} is not valid under any "" u""of the given schemas"") ) data = { 'add_node_groups': [ { ""node_group_template_id"": ""5185a809-6bf7-"" ""44ed-9de3-618270550e2c"", 'name': 'a', 'count': 3 } ] } self._assert_cluster_scaling_validation( data=data )",class TestValidation(unittest2.TestCase):,226,1
openstack%2Fmurano-deployment~master~Iad5a131cd361e6a84ac70d9da23b3a7057be8a1b,openstack/murano-deployment,master,Iad5a131cd361e6a84ac70d9da23b3a7057be8a1b,wpi.ps1 updated,MERGED,2013-07-18 10:47:38.000000000,2013-07-18 10:57:18.000000000,2013-07-18 10:57:18.000000000,"[{'_account_id': 3}, {'_account_id': 7562}, {'_account_id': 7613}]","[{'number': 1, 'created': '2013-07-18 10:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/e4f513da5cf6e9b7f9a83223affa1a04396b16bc', 'message': 'wpi.ps1 updated\n\nDebug function added.\n\nChange-Id: Iad5a131cd361e6a84ac70d9da23b3a7057be8a1b\n'}, {'number': 2, 'created': '2013-07-18 10:55:20.000000000', 'files': ['image-builder/share/scripts/wpi.ps1'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/c1c4a1b07727f8e2675087c85e1862ce81ac3283', 'message': 'wpi.ps1 updated\n\nDebug function added.\n\nChange-Id: Iad5a131cd361e6a84ac70d9da23b3a7057be8a1b\n'}]",0,37657,c1c4a1b07727f8e2675087c85e1862ce81ac3283,9,3,2,7562,,,0,"wpi.ps1 updated

Debug function added.

Change-Id: Iad5a131cd361e6a84ac70d9da23b3a7057be8a1b
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/57/37657/2 && git format-patch -1 --stdout FETCH_HEAD,['image-builder/share/scripts/wpi.ps1'],1,e4f513da5cf6e9b7f9a83223affa1a04396b16bc,wpi-ps1-update," Log ""Exception trapped:"" Log ($_ -as 'string') $srcDir = Join-Path $env:systemdrive ""Murano"" $srcPacksPath = Join-Path $srcDir ""Files"" $srcScriptsPath = Join-Path $srcDir ""Scripts"" $agentDir = Join-Path $srcDir ""Agent"" $modulesDir = Join-Path $srcDir ""Modules"" $sysIntDir = Join-Path ${Env:ProgramFiles(x86)} ""Sysinternals Suite"" $scriptLogFile = Join-Path $srcScriptsPath ""log.txt"" Function Show-Variable { param ( [String[]] $Name ) Log logHorSeparator foreach ($VarName in $Name) { try { $Var = Get-Variable -Name $VarName $VarType = $Var.Value.GetType() -as 'string' $Value = $Var.Value -as 'string' } catch { $VarType = '' $Value = '<NOT FOUND>' } Log ('[{0}] {1} = {2}' -f $VarType, $VarName, $Value) } Log logHorSeparator } Show-Variable srcDir, srcPacksPath, srcScriptsPath, agentDir, modulesDir, sysIntDir, scriptLogFile, LogLevel & reg add ""HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server"" /f /v ""fDenyTSConnections"" /t REG_DWORD /d 0 #Set-ItemProperty -Path 'HKLM:\System\CurrentControlSet\Control\Terminal Server'-name ""fDenyTSConnections"" -Value 0 #New-ItemProperty -Path 'HKLM:\System\CurrentControlSet\Control\Terminal Server'-name ""fDenyTSConnections"" -Value 0 -PropertyType dword & reg add ""HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp"" /f /v ""UserAuthentication"" /t REG_DWORD /d 0 #Set-ItemProperty -Path 'HKLM:\System\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp' -name ""UserAuthentication"" -Value 0 #New-ItemProperty -Path 'HKLM:\System\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp' -name ""UserAuthentication"" -Value 0 -PropertyType dword "," $_ $srcDir = [IO.Path]::Combine($env:systemdrive, ""Murano""); $srcPacksPath = [IO.Path]::Combine($srcDir, ""Files""); $srcScriptsPath = [IO.Path]::Combine($srcDir, ""Scripts""); $agentDir = [IO.Path]::Combine($srcDir,""Agent""); $modulesDir = [IO.Path]::Combine($srcDir,""Modules""); $sysIntDir = [IO.Path]::Combine(${Env:ProgramFiles(x86)},""Sysinternals Suite""); $scriptLogFile = [IO.Path]::Combine($srcScriptsPath, ""log.txt""); #& reg add ""HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server"" /f /v ""fDenyTSConnections"" /t REG_DWORD /d 0 Set-ItemProperty -Path 'HKLM:\System\CurrentControlSet\Control\Terminal Server'-name ""fDenyTSConnections"" -Value 0 New-ItemProperty -Path 'HKLM:\System\CurrentControlSet\Control\Terminal Server'-name ""fDenyTSConnections"" -Value 0 -PropertyType dword Set-ItemProperty -Path 'HKLM:\System\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp' -name ""UserAuthentication"" -Value 0 New-ItemProperty -Path 'HKLM:\System\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp' -name ""UserAuthentication"" -Value 0 -PropertyType dword # #Log ""Starting of Sysprep processes ...""; #Start-Process -FilePath powershell -ArgumentList ""-File $srcScriptsPath\Start-Sysprep.ps1 -BatchExecution""; ",42,17
openstack%2Fceilometer~master~I8bd79539c895eee30fbd24ab869b596d9a1c82c1,openstack/ceilometer,master,I8bd79539c895eee30fbd24ab869b596d9a1c82c1,doc: /statistics fields are not queryable (you cannot filter on them),MERGED,2013-07-17 17:01:56.000000000,2013-07-18 10:39:07.000000000,2013-07-18 10:39:06.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 7336}, {'_account_id': 7993}]","[{'number': 1, 'created': '2013-07-17 17:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e209ef184fe1302c324dd1b073fb303af555153c', 'message': 'doc: /statistics fields are not queryable (you cannot filter on them)\n\nChange-Id: I8bd79539c895eee30fbd24ab869b596d9a1c82c1\ndoc: /statistics fields are not queryable (you cannot filter on them)\n'}, {'number': 2, 'created': '2013-07-18 09:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/98c286f839d8bd60b67d3ae4d24d0aa5f79f4064', 'message': 'doc: /statistics fields are not queryable (you cannot filter on them)\n\nAdd precision on the way of filtering queries and corrected some typos.\n\nChange-Id: I8bd79539c895eee30fbd24ab869b596d9a1c82c1\n'}, {'number': 3, 'created': '2013-07-18 09:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0a16e4db1a64496c0d82fb9b147d0ca1ae7cccff', 'message': 'doc: /statistics fields are not queryable (you cannot filter on them)\n\nAdd precision on the way of filtering queries and corrected some typos.\n\nChange-Id: I8bd79539c895eee30fbd24ab869b596d9a1c82c1\n'}, {'number': 4, 'created': '2013-07-18 09:51:50.000000000', 'files': ['doc/source/webapi/v2.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8539cfbd905989b0a9ebd3c7ce3341ccc5981b21', 'message': 'doc: /statistics fields are not queryable (you cannot filter on them)\n\nAdd precision on the way of filtering queries and corrected some typos.\n\nChange-Id: I8bd79539c895eee30fbd24ab869b596d9a1c82c1\n'}]",0,37533,8539cfbd905989b0a9ebd3c7ce3341ccc5981b21,17,5,4,7993,,,0,"doc: /statistics fields are not queryable (you cannot filter on them)

Add precision on the way of filtering queries and corrected some typos.

Change-Id: I8bd79539c895eee30fbd24ab869b596d9a1c82c1
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/33/37533/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/webapi/v2.rst'],1,e209ef184fe1302c324dd1b073fb303af555153c,ff/api-v2-doc-improvement,"Get the list of samples about instances with *m1.tiny* flavor running for June 2013 for a particular project::about CPU utilisation of a given instance (identified by its *resource_id*)You can have statistics on the list of samples requested (*avg*, *sum*, *max*, *min*, *count*) computed on the full duration::","Get the list of samples about instances with m1.tiny flavor running for June 2013 for a particular project::about CPU utilisation of a given instance (identified by its ""resource_id"")You can have statistics on the list of samples requested (avg, sum, max, min, count) computed on the full duration)::",4,4
openstack%2Fmurano-dashboard~master~I3a25f37c87fbae50d78ad3cfddf74ee1d767e001,openstack/murano-dashboard,master,I3a25f37c87fbae50d78ad3cfddf74ee1d767e001,Update templtate due to new form was added,MERGED,2013-07-18 10:07:13.000000000,2013-07-18 10:11:36.000000000,2013-07-18 10:11:36.000000000,"[{'_account_id': 3}, {'_account_id': 7226}]","[{'number': 1, 'created': '2013-07-18 10:07:13.000000000', 'files': ['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/forms.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/bac51572ce70811a6942806f65f456aa12f24081', 'message': 'Update templtate due to new form was added\n\nChange-Id: I3a25f37c87fbae50d78ad3cfddf74ee1d767e001\n'}]",0,37655,bac51572ce70811a6942806f65f456aa12f24081,5,2,1,7549,,,0,"Update templtate due to new form was added

Change-Id: I3a25f37c87fbae50d78ad3cfddf74ee1d767e001
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/55/37655/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/forms.py']",3,bac51572ce70811a6942806f65f456aa12f24081,add_new_form," required = kwargs.get('required') if required is None: required = True required=required,class WizardFormADConfiguration(forms.Form, def clean(self): def compare(pwd1, pwd2, admin=True): if pwd1 != pwd2: pwd_type = 'Administrator' if not admin: pwd_type = 'Recovery' raise forms.ValidationError( _(' %s passwords don\'t match' % pwd_type)) form_data = self.cleaned_data admin_pwd1 = form_data.get('adm_password') admin_pwd2 = form_data.get('adm_password2') compare(admin_pwd1, admin_pwd2) second_pwd1 = form_data.get('password_field') if second_pwd1: second_pwd2 = form_data.get('password_field2') compare(second_pwd1, second_pwd2, admin=False) return self.cleaned_data class WizardFormIISConfiguration(forms.Form,class WebFarmExtension(forms.Form): required=False, required=False, def clean(self): form_data = self.cleaned_data mixed_mode = form_data.get('mixed_mode') if mixed_mode: self.fields['password_field'].required = True ","class ServiceConfigurationForm(forms.Form): def clean(self): def compare(pwd1, pwd2, admin=True): if pwd1 != pwd2: pwd_type = 'Administrator' if not admin: pwd_type = 'Recovery' raise forms.ValidationError( _(' %s passwords don\'t match' % pwd_type)) form_data = self.cleaned_data admin_pwd1 = form_data.get('adm_password') admin_pwd2 = form_data.get('adm_password2') compare(admin_pwd1, admin_pwd2) second_pwd1 = form_data.get('password_field') if second_pwd1: second_pwd2 = form_data.get('password_field2') compare(second_pwd1, second_pwd2, admin=False) return self.cleaned_data class WizardFormADConfiguration(ServiceConfigurationForm,class WizardFormIISConfiguration(ServiceConfigurationForm,class WebFarmExtension(ServiceConfigurationForm):",107,52
openstack%2Fneutron~master~Ia9c1ad3fb4b71796401ef5507f741f3cc024a4da,openstack/neutron,master,Ia9c1ad3fb4b71796401ef5507f741f3cc024a4da,Register agent schedulers options in one place,MERGED,2013-07-08 12:03:02.000000000,2013-07-18 10:05:44.000000000,2013-07-18 10:05:43.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-08 12:03:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf687132c39fd38e3cc997ebaa66db8ffe9544a2', 'message': 'Fix NeutronManagerTestCase.test_post_plugin_validation\n\nfixes test case when running separately by registering missing config option\n\nFixes bug 1198904\n\nChange-Id: Ia9c1ad3fb4b71796401ef5507f741f3cc024a4da\n'}, {'number': 2, 'created': '2013-07-09 09:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fcc50424102dab304e19c3b27ee435f3361c1086', 'message': 'Register agent schedulers options in one place\n\nCurrently agent schedulers options are defined in neutron.scheduler and\nevery plugin that supports scheduling should register them individually.\nIt is reasonable to define and register options in one place - agentschedulers_db.\n\nFixes NeutronManagerTestCase when running separately by importing missing config option\n\nFixes bug 1198904\n\nChange-Id: Ia9c1ad3fb4b71796401ef5507f741f3cc024a4da\n'}, {'number': 3, 'created': '2013-07-09 09:24:57.000000000', 'files': ['neutron/plugins/nicira/common/config.py', 'neutron/plugins/nec/common/config.py', 'neutron/plugins/brocade/NeutronPlugin.py', 'neutron/plugins/linuxbridge/common/config.py', 'neutron/plugins/ml2/config.py', 'neutron/plugins/openvswitch/common/config.py', 'neutron/db/agentschedulers_db.py', 'neutron/scheduler/__init__.py', 'neutron/tests/unit/test_neutron_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1761fce9ea94243abae0c1287312ca7ae3dd3f86', 'message': 'Register agent schedulers options in one place\n\nCurrently agent schedulers options are defined in neutron.scheduler and\nevery plugin that supports scheduling should register them individually.\nIt is reasonable to define and register options in one place - agentschedulers_db.\n\nFixes NeutronManagerTestCase when running separately by importing missing config option\n\nFixes bug 1198904\n\nChange-Id: Ia9c1ad3fb4b71796401ef5507f741f3cc024a4da\n'}]",3,36064,1761fce9ea94243abae0c1287312ca7ae3dd3f86,17,6,3,5948,,,0,"Register agent schedulers options in one place

Currently agent schedulers options are defined in neutron.scheduler and
every plugin that supports scheduling should register them individually.
It is reasonable to define and register options in one place - agentschedulers_db.

Fixes NeutronManagerTestCase when running separately by importing missing config option

Fixes bug 1198904

Change-Id: Ia9c1ad3fb4b71796401ef5507f741f3cc024a4da
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/36064/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/test_neutron_manager.py'],1,bf687132c39fd38e3cc997ebaa66db8ffe9544a2,bug/1198904," if 'dhcp_agents_per_network' not in cfg.CONF: cfg.CONF.register_opt(cfg.IntOpt('dhcp_agents_per_network', default=1)) ",,4,0
openstack%2Fneutron~master~I44d936afd8cd531a786c09c38bbc4702737ce99c,openstack/neutron,master,I44d936afd8cd531a786c09c38bbc4702737ce99c,Add status description field for lbaas objects,MERGED,2013-07-06 16:06:39.000000000,2013-07-18 10:05:36.000000000,2013-07-18 10:05:36.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6447}]","[{'number': 6, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ed2ddd0f296401c7edb07575826a01d1de51fa64', 'message': 'Add status description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}, {'number': 7, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0bb11d418e943b8c40bd190a6555e4ecbc9b040b', 'message': 'Add status description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b8d7f4df58b914eec53287f3cd6a6b6996ea241', 'message': 'Add error description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}, {'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/10a1365894550260abf0df1106ed51ac3f8c78e5', 'message': 'Add error description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2acd0a5c25de9ed7cab67f12cc6ca3b7f6159acf', 'message': 'Add error description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3926bca1cc8e7b878707b2466c98756eb1e5aea4', 'message': 'Add error description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d87d111ec6c45effeb13e26f2876d97e88e7347a', 'message': 'Add error description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}, {'number': 8, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d34c2bdaf65d6df9790229d71c3b480208bef07c', 'message': 'Add status description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}, {'number': 9, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b7a0403cd7dcf314a92d58df4c7bae76b221fe4f', 'message': 'Add status description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}, {'number': 10, 'created': '2013-07-08 12:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/618a97bfa1b2405e6960966741b49101796f9de1', 'message': 'Add status description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}, {'number': 11, 'created': '2013-07-10 14:05:37.000000000', 'files': ['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/db/migration/alembic_migrations/versions/2032abe8edac_lbaas_add_status_des.py', 'neutron/db/models_v2.py', 'neutron/extensions/loadbalancer.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/32e5b054d20083edc5e6bd255505757d5793d376', 'message': 'Add status description field for lbaas objects\n\nFixes bug 1166925\n\nChange-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c\n'}]",56,34209,32e5b054d20083edc5e6bd255505757d5793d376,65,6,11,5948,,,0,"Add status description field for lbaas objects

Fixes bug 1166925

Change-Id: I44d936afd8cd531a786c09c38bbc4702737ce99c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/09/34209/6 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/db/models_v2.py', 'quantum/extensions/loadbalancer.py', 'quantum/db/migration/alembic_migrations/versions/2032abe8edac_lbaas_add_status_des.py', 'quantum/db/loadbalancer/loadbalancer_db.py', 'quantum/tests/unit/db/loadbalancer/test_db_loadbalancer.py']",5,ed2ddd0f296401c7edb07575826a01d1de51fa64,bug/1166925," def test_update_status(self): with self.pool() as pool: self.assertEqual(pool['pool']['status'], 'PENDING_CREATE') self.assertFalse('status_description' in pool['pool']) self.plugin.update_status(context.get_admin_context(), ldb.Pool, pool['pool']['id'], 'ERROR', 'unknown') updated_pool = self.plugin.get_pool(context.get_admin_context(), pool['pool']['id']) self.assertEqual(updated_pool['status'], 'ERROR') self.assertTrue('status_description' in updated_pool) self.assertEqual(updated_pool['status_description'], 'unknown') # update status to ACTIVE, status_description should be cleared self.plugin.update_status(context.get_admin_context(), ldb.Pool, pool['pool']['id'], 'ACTIVE') updated_pool = self.plugin.get_pool(context.get_admin_context(), pool['pool']['id']) self.assertEqual(updated_pool['status'], 'ACTIVE') self.assertFalse('status_description' in pool['pool']) ",,129,14
openstack%2Fcinder~master~I23988d5133bbb95637dd9514813009ea8b460982,openstack/cinder,master,I23988d5133bbb95637dd9514813009ea8b460982,Fix duplicate config options,MERGED,2013-07-18 07:44:21.000000000,2013-07-18 10:05:29.000000000,2013-07-18 10:05:29.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 2759}, {'_account_id': 4355}]","[{'number': 1, 'created': '2013-07-18 07:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/11aa2f4d649a63fdfd00805c194ca009f2e93d1a', 'message': 'Fix duplicate config options\n\nThis is causing an error in the config file tool generator.\nImport the config options from cinder.api.common\n\nChange-Id: I23988d5133bbb95637dd9514813009ea8b460982\n'}, {'number': 2, 'created': '2013-07-18 08:07:50.000000000', 'files': ['cinder/common/config.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e909cfd67eceea396c63acd7563bed1f5f9979f4', 'message': 'Fix duplicate config options\n\nThis is causing an error in the config file tool generator.\nRemoved them since they are registered in cinder.api.common\n\nChange-Id: I23988d5133bbb95637dd9514813009ea8b460982\n'}]",5,37636,e909cfd67eceea396c63acd7563bed1f5f9979f4,15,6,2,1994,,,0,"Fix duplicate config options

This is causing an error in the config file tool generator.
Removed them since they are registered in cinder.api.common

Change-Id: I23988d5133bbb95637dd9514813009ea8b460982
",git fetch https://review.opendev.org/openstack/cinder refs/changes/36/37636/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/common/config.py'],1,11aa2f4d649a63fdfd00805c194ca009f2e93d1a,osapi_opts,"CONF.import_opt('osapi_max_limit', 'cinder.api.common') CONF.import_opt('osapi_volume_base_URL', 'cinder.api.common')"," cfg.StrOpt('osapi_volume_base_URL', default=None, help='Base URL that will be presented to users in links ' 'to the OpenStack Volume API', deprecated_name='osapi_compute_link_prefix'), cfg.IntOpt('osapi_max_limit', default=1000, help='the maximum number of items returned in a single ' 'response from a collection resource'),",2,9
openstack%2Fmurano-dashboard~master~Ie0402c76c93f5fe06aa93548fa7cbef93f5539d8,openstack/murano-dashboard,master,Ie0402c76c93f5fe06aa93548fa7cbef93f5539d8,Add CentOS setup shell script,MERGED,2013-07-18 09:46:16.000000000,2013-07-18 09:49:33.000000000,2013-07-18 09:49:33.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-18 09:46:16.000000000', 'files': ['setup-centos.sh'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/6379e3b63158fa893ae058d79ffe152ae042fa12', 'message': 'Add CentOS setup shell script\n\nChange-Id: Ie0402c76c93f5fe06aa93548fa7cbef93f5539d8\n'}]",0,37652,6379e3b63158fa893ae058d79ffe152ae042fa12,5,2,1,7613,,,0,"Add CentOS setup shell script

Change-Id: Ie0402c76c93f5fe06aa93548fa7cbef93f5539d8
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/52/37652/1 && git format-patch -1 --stdout FETCH_HEAD,['setup-centos.sh'],1,6379e3b63158fa893ae058d79ffe152ae042fa12,setup-scripts,"#!/bin/sh # Copyright (c) 2013 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # CentOS script. LOGLVL=1 SERVICE_CONTENT_DIRECTORY=`cd $(dirname ""$0"") && pwd` PREREQ_PKGS=""wget make git python-pip mysql-connector-python python-devel"" PIPAPPS=""pip python-pip pip-python"" PIPCMD="""" SERVICE_SRV_NAME=""murano-dashboard"" GIT_CLONE_DIR=`echo $SERVICE_CONTENT_DIRECTORY | sed -e ""s/$SERVICE_SRV_NAME//""` HORIZON_CONFIGS=""/opt/stack/horizon/openstack_dashboard/settings.py,/usr/share/openstack-dashboard/openstack_dashboard/settings.py"" # Functions # Loger function log() { MSG=$1 if [ $LOGLVL -gt 0 ]; then echo ""LOG:> $MSG"" fi } # Check or install package in_sys_pkg() { PKG=$1 rpm -q $PKG > /dev/null 2>&1 if [ $? -eq 0 ]; then log ""Package \""$PKG\"" already installed"" else log ""Installing \""$PKG\""..."" yum install $PKG --assumeyes > /dev/null 2>&1 if [ $? -ne 0 ];then log ""installation fails, exiting!!!"" exit fi fi } # find pip find_pip() { for cmd in $PIPAPPS do _cmd=$(which $cmd 2>/dev/null) if [ $? -eq 0 ];then break fi done if [ -z $_cmd ];then echo ""Can't find \""pip\"" in system, please install it first, exiting!"" exit 1 else PIPCMD=$_cmd fi } # git clone gitclone() { FROM=$1 CLONEROOT=$2 log ""Cloning from \""$FROM\"" repo to \""$CLONEROOT\"""" cd $CLONEROOT && git clone $FROM > /dev/null 2>&1 if [ $? -ne 0 ];then log ""cloning from \""$FROM\"" fails, exiting!!!"" exit fi } # horizon part modify_horizon_config() { REMOVE=$2 if [ -f $1 ]; then lines=$(sed -ne '/^#START_MURANO_DASHBOARD/,/^#END_MURANO_DASHBOARD/ =' $1) if [ -n ""$lines"" ]; then if [ ! -z $REMOVE ]; then log ""Removing our data from \""$1\""..."" sed -e '/^#START_MURANO_DASHBOARD/,/^#END_MURANO_DASHBOARD/ d' -i $1 if [ $? -ne 0 ];then log ""Can't modify \""$1\"", check permissions or something else, exiting!!!"" exit fi else log ""\""$1\"" already has our data, you can change it manualy and restart apache2 service"" fi else if [ -z $REMOVE ];then log ""Adding our data into \""$1\""..."" cat >> $1 << ""EOF"" #START_MURANO_DASHBOARD from muranoclient.common import exceptions as muranoclient RECOVERABLE_EXC = (muranoclient.HTTPException, muranoclient.CommunicationError, muranoclient.Forbidden) EXTENDED_RECOVERABLE_EXCEPTIONS = tuple( exceptions.RECOVERABLE + RECOVERABLE_EXC) NOT_FOUND_EXC = (muranoclient.HTTPNotFound, muranoclient.EndpointNotFound) EXTENDED_NOT_FOUND_EXCEPTIONS = tuple(exceptions.NOT_FOUND + NOT_FOUND_EXC) UNAUTHORIZED_EXC = (muranoclient.HTTPUnauthorized, ) EXTENDED_UNAUTHORIZED_EXCEPTIONS = tuple(exceptions.UNAUTHORIZED + UNAUTHORIZED_EXC) HORIZON_CONFIG['exceptions']['recoverable'] = EXTENDED_RECOVERABLE_EXCEPTIONS HORIZON_CONFIG['exceptions']['not_found'] = EXTENDED_NOT_FOUND_EXCEPTIONS HORIZON_CONFIG['exceptions']['unauthorized'] = EXTENDED_UNAUTHORIZED_EXCEPTIONS HORIZON_CONFIG['customization_module'] = 'muranodashboard.panel.overrides' INSTALLED_APPS += ('muranodashboard',) #INSTALLED_APPS = ('muranodashboard',) #END_MURANO_DASHBOARD EOF if [ $? -ne 0 ];then log ""Can't modify \""$1\"", check permissions or something else, exiting!!!"" fi fi fi else echo ""File \""$1\"" not found, exiting!!!"" exit 1 fi } find_horizon_config() { FOUND=0 for cfg_file in $(echo $HORIZON_CONFIGS | sed 's/,/ /g' ) do if [ -e $cfg_file ];then log ""Horizon config found at \""$cfg_file\"""" modify_horizon_config $cfg_file $1 FOUND=1 fi done if [ $FOUND -eq 0 ];then log ""Horizon config not found or openstack-dashboard non installed or set proper \""HORIZON_CONFIGS\"" varable, exiting!!!"" exit fi } # preinstall checks preinst() { # check openstack-dashboard installed from system packages _PKG=openstack-dashboard rpm -q $_PKG > /dev/null 2>&1 if [ $? -ne 0 ]; then log ""Package \""$_PKG\"" is not installed."" fi # python-muranoclient _PREREQ=python-muranoclient $PIPCMD freeze | grep $_PREREQ if [ $? -ne 0 ]; then log ""\""$_PREREQ\"" package not found, please install it first from (\""https://github.com/stackforge/python-muranoclient\""), exiting!!!"" exit 1 else log ""\""$_PREREQ\"" found, doing next steps...."" fi } # postinstall postinst() { sleep 2 service httpd restart } # install inst() { CLONE_FROM_GIT=$1 # Checking packages for PKG in $PREREQ_PKGS do in_sys_pkg $PKG done # Find python pip find_pip preinst # If clone from git set if [ ! -z $CLONE_FROM_GIT ]; then # Preparing clone root directory if [ ! -d $GIT_CLONE_DIR ];then log ""Creting $GIT_CLONE_DIR direcory..."" mkdir -p $GIT_CLONE_DIR if [ $? -ne 0 ];then log ""Can't create $GIT_CLONE_DIR, exiting!!!"" exit fi fi # Cloning from GIT GIT_WEBPATH_PRFX=""https://github.com/stackforge/"" gitclone ""$GIT_WEBPATH_PRFX$SERVICE_SRV_NAME.git"" $GIT_CLONE_DIR # End clone from git section fi # Setupping... log ""Running setup.py"" MRN_CND_SPY=$SERVICE_CONTENT_DIRECTORY/setup.py if [ -e $MRN_CND_SPY ]; then chmod +x $MRN_CND_SPY log ""$MRN_CND_SPY output:_____________________________________________________________"" ## Setup through pip # Creating tarball rm -rf $SERVICE_CONTENT_DIRECTORY/*.egg-info cd $SERVICE_CONTENT_DIRECTORY && python $MRN_CND_SPY egg_info if [ $? -ne 0 ];then log ""\""$MRN_CND_SPY\"" egg info creation FAILS, exiting!!!"" exit 1 fi rm -rf $SERVICE_CONTENT_DIRECTORY/dist cd $SERVICE_CONTENT_DIRECTORY && python $MRN_CND_SPY sdist if [ $? -ne 0 ];then log ""\""$MRN_CND_SPY\"" tarball creation FAILS, exiting!!!"" exit 1 fi # Running tarball install TRBL_FILE=$(basename `ls $SERVICE_CONTENT_DIRECTORY/dist/*.tar.gz`) $PIPCMD install $SERVICE_CONTENT_DIRECTORY/dist/$TRBL_FILE if [ $? -ne 0 ];then log ""$PIPCMD install \""$TRBL_FILE\"" FAILS, exiting!!!"" exit 1 fi else log ""$MRN_CND_SPY not found!"" fi } # uninstall uninst() { # Uninstall trough pip find_pip # looking up for python package installed PYPKG=`echo $SERVICE_SRV_NAME | tr -d '-'` _pkg=$($PIPCMD freeze | grep $PYPKG) if [ $? -eq 0 ]; then log ""Removing package \""$PYPKG\"" with pip"" $PIPCMD uninstall $_pkg --yes else log ""Python package \""$PYPKG\"" not found"" fi } # Command line args' COMMAND=""$1"" case $COMMAND in testinstall ) find_horizon_config postinst ;; testuninstall ) find_horizon_config remove postinst ;; install ) inst find_horizon_config postinst ;; installfromgit ) inst ""yes"" find_horizon_config postinst ;; uninstall ) log ""Uninstalling \""$SERVICE_SRV_NAME\"" from system..."" uninst find_horizon_config remove postinst ;; * ) echo -e ""Usage: $(basename ""$0"") command \nCommands:\n\tinstall - Install $SERVICE_SRV_NAME software\n\tuninstall - Uninstall $SERVICE_SRV_NAME software"" exit 1 ;; esac ",,291,0
openstack%2Fpython-muranoclient~master~I42977d781d34564f82845047dcef40a54f78be21,openstack/python-muranoclient,master,I42977d781d34564f82845047dcef40a54f78be21,Add CentOS setup shell script,MERGED,2013-07-18 09:34:12.000000000,2013-07-18 09:46:23.000000000,2013-07-18 09:46:23.000000000,"[{'_account_id': 3}, {'_account_id': 7562}, {'_account_id': 7613}]","[{'number': 1, 'created': '2013-07-18 09:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/aa4749be4d9632885895d714b3c1edc9f672079c', 'message': 'Add CentOS setup shell script\n\nChange-Id: I42977d781d34564f82845047dcef40a54f78be21\n'}, {'number': 2, 'created': '2013-07-18 09:43:26.000000000', 'files': ['setup-centos.sh'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/265807d9e9174bb16b0c2126b2f73d5eedaab8f8', 'message': 'Add CentOS setup shell script\n\nChange-Id: I42977d781d34564f82845047dcef40a54f78be21\n'}]",0,37650,265807d9e9174bb16b0c2126b2f73d5eedaab8f8,7,3,2,7613,,,0,"Add CentOS setup shell script

Change-Id: I42977d781d34564f82845047dcef40a54f78be21
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/50/37650/1 && git format-patch -1 --stdout FETCH_HEAD,['setup-centos.sh'],1,aa4749be4d9632885895d714b3c1edc9f672079c,setup-scripts,"#!/bin/sh # Copyright (c) 2013 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # CentOS script. LOGLVL=1 SERVICE_CONTENT_DIRECTORY=`cd $(dirname ""$0"") && pwd` PREREQ_PKGS=""wget make git python-pip python-devel"" PIPAPPS=""pip,python-pip,pip-python"" PIPCMD="""" SERVICE_SRV_NAME=""python-muranoclient"" GIT_CLONE_DIR=`echo $SERVICE_CONTENT_DIRECTORY | sed -e ""s/$SERVICE_SRV_NAME//""` # Functions # Loger function log() { MSG=$1 if [ $LOGLVL -gt 0 ]; then echo ""LOG:> $MSG"" fi } # Check or install package in_sys_pkg() { PKG=$1 rpm -q $PKG > /dev/null 2>&1 if [ $? -eq 0 ]; then log ""Package \""$PKG\"" already installed"" else log ""Installing \""$PKG\""..."" yum install $PKG --assumeyes > /dev/null 2>&1 if [ $? -ne 0 ];then log ""installation fails, exiting!!!"" exit fi fi } # find pip find_pip() { for cmd in $(echo $PIPAPPS | sed 's/,/ /g') do _cmd=$(which $cmd 2>/dev/null) if [ $? -eq 0 ];then break fi done if [ -z $_cmd ];then echo ""Can't find \""pip\"" in system, please install it first, exiting!"" exit 1 else PIPCMD=$_cmd fi } # git clone gitclone() { FROM=$1 CLONEROOT=$2 log ""Cloning from \""$FROM\"" repo to \""$CLONEROOT\"""" cd $CLONEROOT && git clone $FROM > /dev/null 2>&1 if [ $? -ne 0 ];then log ""cloning from \""$FROM\"" fails, exiting!!!"" exit fi } # install inst() { CLONE_FROM_GIT=$1 # Checking packages for PKG in $PREREQ_PKGS do in_sys_pkg $PKG done # Find python pip find_pip # If clone from git set if [ ! -z $CLONE_FROM_GIT ]; then # Preparing clone root directory if [ ! -d $GIT_CLONE_DIR ];then log ""Creting $GIT_CLONE_DIR direcory..."" mkdir -p $GIT_CLONE_DIR if [ $? -ne 0 ];then log ""Can't create $GIT_CLONE_DIR, exiting!!!"" exit fi fi # Cloning from GIT GIT_WEBPATH_PRFX=""https://github.com/stackforge/"" gitclone ""$GIT_WEBPATH_PRFX$SERVICE_SRV_NAME.git"" $GIT_CLONE_DIR # End clone from git section fi # Setupping... log ""Running setup.py"" MRN_CND_SPY=$SERVICE_CONTENT_DIRECTORY/setup.py if [ -e $MRN_CND_SPY ]; then chmod +x $MRN_CND_SPY log ""$MRN_CND_SPY output:_____________________________________________________________"" ## Setup through pip # Creating tarball rm -rf $SERVICE_CONTENT_DIRECTORY/*.egg-info cd $SERVICE_CONTENT_DIRECTORY && python $MRN_CND_SPY egg_info if [ $? -ne 0 ];then log ""\""$MRN_CND_SPY\"" egg info creation FAILS, exiting!!!"" exit 1 fi rm -rf $SERVICE_CONTENT_DIRECTORY/dist/* cd $SERVICE_CONTENT_DIRECTORY && python $MRN_CND_SPY sdist if [ $? -ne 0 ];then log ""\""$MRN_CND_SPY\"" tarball creation FAILS, exiting!!!"" exit 1 fi # Running tarball install TRBL_FILE=$(basename `ls $SERVICE_CONTENT_DIRECTORY/dist/*.tar.gz`) $PIPCMD install $SERVICE_CONTENT_DIRECTORY/dist/$TRBL_FILE if [ $? -ne 0 ];then log ""$PIPCMD install \""$TRBL_FILE\"" FAILS, exiting!!!"" exit 1 fi else log ""$MRN_CND_SPY not found!"" fi } # uninstall uninst() { # Uninstall trough pip find_pip # looking up for python package installed PYPKG=$SERVICE_SRV_NAME _pkg=$($PIPCMD freeze | grep $PYPKG) if [ $? -eq 0 ]; then log ""Removing package \""$PYPKG\"" with pip"" $PIPCMD uninstall $_pkg --yes else log ""Python package \""$PYPKG\"" not found"" fi } # Command line args' COMMAND=""$1"" case $COMMAND in install ) inst ;; installfromgit ) inst ""yes"" ;; uninstall ) log ""Uninstalling \""$SERVICE_SRV_NAME\"" from system..."" uninst ;; * ) echo -e ""Usage: $(basename ""$0"") command \nCommands:\n\tinstall - Install $SERVICE_SRV_NAME software\n\tuninstall - Uninstall $SERVICE_SRV_NAME software"" exit 1 ;; esac ",,178,0
openstack%2Fheat~master~I1d98ac21d44ff05183db38d49cbb3599e2812511,openstack/heat,master,I1d98ac21d44ff05183db38d49cbb3599e2812511,Put pre-created resources in state INIT COMPLETE.,MERGED,2013-07-10 03:10:41.000000000,2013-07-18 09:44:41.000000000,2013-07-18 09:44:41.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7714}]","[{'number': 1, 'created': '2013-07-10 03:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e952db1cc71d0add5933a44721c8812a5c68315f', 'message': 'Put pre-created resources in state INIT COMPLETE.\n\nDefines an INIT action, and make the resourse state\nINIT COMPLETE before they are first created.\n\nCalls to list resources will now include resource that have\nnot been created yet. This change allows resource topoligies\nto be displayed throughout the creation of the stack.\n\nImplements blueprint build-heat-graph\n\nChange-Id: I1d98ac21d44ff05183db38d49cbb3599e2812511\n'}, {'number': 2, 'created': '2013-07-17 22:53:15.000000000', 'files': ['heat/engine/service.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c148cbc8d85aa29d85f40925a3da840e216d0fb9', 'message': 'Put pre-created resources in state INIT COMPLETE.\n\nDefines an INIT action, and make the resourse state\nINIT COMPLETE before they are first created.\n\nCalls to list resources will now include resource that have\nnot been created yet. This change allows resource topologies\nto be displayed throughout the creation of the stack.\n\nImplements blueprint build-heat-graph\n\nChange-Id: I1d98ac21d44ff05183db38d49cbb3599e2812511\n'}]",6,36385,c148cbc8d85aa29d85f40925a3da840e216d0fb9,15,7,2,4571,,,0,"Put pre-created resources in state INIT COMPLETE.

Defines an INIT action, and make the resourse state
INIT COMPLETE before they are first created.

Calls to list resources will now include resource that have
not been created yet. This change allows resource topologies
to be displayed throughout the creation of the stack.

Implements blueprint build-heat-graph

Change-Id: I1d98ac21d44ff05183db38d49cbb3599e2812511
",git fetch https://review.opendev.org/openstack/heat refs/changes/85/36385/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resource.py', 'heat/engine/service.py', 'heat/tests/test_resource.py']",3,e952db1cc71d0add5933a44721c8812a5c68315f,bp/build-heat-graph," self.assertEqual(res.state, (res.INIT, res.COMPLETE))"," self.assertEqual(res.state, (None, None))",11,8
openstack%2Fsahara~master~I5786278575a93fc731d5b47341beafb79337973b,openstack/sahara,master,I5786278575a93fc731d5b47341beafb79337973b,Cluster scaling bug fixing,MERGED,2013-07-18 09:28:10.000000000,2013-07-18 09:37:01.000000000,2013-07-18 09:37:01.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7478}]","[{'number': 1, 'created': '2013-07-18 09:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a592dee3b1c3f78c8f5fdbe619f854d3299dc10f', 'message': 'Cluster scaling bug fixing\n\nAnd a little code improvement\n\nChange-Id: I5786278575a93fc731d5b47341beafb79337973b\nFixes: bug #1202562\n'}, {'number': 2, 'created': '2013-07-18 09:32:23.000000000', 'files': ['savanna/plugins/vanilla/scaling.py', 'savanna/service/api.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4e8404ee469c166da573dd1749a67f88901fe6d6', 'message': 'Cluster scaling bug fixing\n\nAnd a little code improvement\n\nFixes: bug #1202562\n\nChange-Id: I5786278575a93fc731d5b47341beafb79337973b\n'}]",1,37648,4e8404ee469c166da573dd1749a67f88901fe6d6,11,4,2,7478,,,0,"Cluster scaling bug fixing

And a little code improvement

Fixes: bug #1202562

Change-Id: I5786278575a93fc731d5b47341beafb79337973b
",git fetch https://review.opendev.org/openstack/sahara refs/changes/48/37648/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/plugins/vanilla/scaling.py', 'savanna/service/api.py']",2,a592dee3b1c3f78c8f5fdbe619f854d3299dc10f,bug/1202562, tmpl_id = ng.get('node_group_template_id'), tmpl_id = ng['node_group_template_id'],2,3
openstack%2Fneutron~master~Ic959d167c3c43e9be6686c42f359506ca481adde,openstack/neutron,master,Ic959d167c3c43e9be6686c42f359506ca481adde,gre/vxlan validate_provider_segment return None,ABANDONED,2013-07-18 09:16:27.000000000,2013-07-18 09:36:19.000000000,,"[{'_account_id': 105}, {'_account_id': 2888}]","[{'number': 1, 'created': '2013-07-18 09:16:27.000000000', 'files': ['neutron/plugins/ml2/drivers/type_vxlan.py', 'neutron/plugins/ml2/drivers/type_gre.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/36b322f35127a8efe83b9b86a98a71931d61379a', 'message': 'gre/vxlan validate_provider_segment return None\n\nAccording to driver api, validate_provider_segment\nshould return the validated segment.\n\nChange-Id: Ic959d167c3c43e9be6686c42f359506ca481adde\n'}]",0,37644,36b322f35127a8efe83b9b86a98a71931d61379a,1,2,1,7170,,,0,"gre/vxlan validate_provider_segment return None

According to driver api, validate_provider_segment
should return the validated segment.

Change-Id: Ic959d167c3c43e9be6686c42f359506ca481adde
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/37644/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/type_vxlan.py', 'neutron/plugins/ml2/drivers/type_gre.py']",2,36b322f35127a8efe83b9b86a98a71931d61379a,master, return segment ,,4,0
openstack%2Fsahara-dashboard~master~I25816e7b04d3f59959d04eee6fa7b37dd27bdcb2,openstack/sahara-dashboard,master,I25816e7b04d3f59959d04eee6fa7b37dd27bdcb2,Links on hadoop services are opening in new tab now,MERGED,2013-07-18 09:17:25.000000000,2013-07-18 09:34:48.000000000,2013-07-18 09:34:48.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7700}]","[{'number': 1, 'created': '2013-07-18 09:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/b3759e1513771dfaf41cdbb87fa85cf9fe46bca0', 'message': 'Links on hadoop services is opening in new tab now\n\nChange-Id: I25816e7b04d3f59959d04eee6fa7b37dd27bdcb2\nFixes: bug #1200327\n'}, {'number': 2, 'created': '2013-07-18 09:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/2ad26e7191302a9924601d70a9b0d499f9c8887f', 'message': 'Links on hadoop services are opening in new tab now\n\nChange-Id: I25816e7b04d3f59959d04eee6fa7b37dd27bdcb2\nFixes: bug #1200327\n'}, {'number': 3, 'created': '2013-07-18 09:28:10.000000000', 'files': ['savannadashboard/clusters/tabs.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/ecde75e43ce093c58525deb256fa66827162f8c2', 'message': 'Links on hadoop services are opening in new tab now\n\nFixes: bug #1200327\n\nChange-Id: I25816e7b04d3f59959d04eee6fa7b37dd27bdcb2\n'}]",2,37645,ecde75e43ce093c58525deb256fa66827162f8c2,16,5,3,7700,,,0,"Links on hadoop services are opening in new tab now

Fixes: bug #1200327

Change-Id: I25816e7b04d3f59959d04eee6fa7b37dd27bdcb2
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/45/37645/1 && git format-patch -1 --stdout FETCH_HEAD,['savannadashboard/clusters/tabs.py'],1,b3759e1513771dfaf41cdbb87fa85cf9fe46bca0,bug/1200327," return ""<a href='"" + url + ""' target=\""_blank\"">"" + url + ""</a>"""," return ""<a href='"" + url + ""'>"" + url + ""</a>""",1,1
openstack%2Fpython-ceilometerclient~master~Ib33a5fd162d760efa23a2fc496c1d11d79484491,openstack/python-ceilometerclient,master,Ib33a5fd162d760efa23a2fc496c1d11d79484491,Add support for creating samples,MERGED,2013-07-17 07:10:49.000000000,2013-07-18 09:33:12.000000000,2013-07-18 09:33:12.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-07-17 07:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/775556196209d23b8eaf836103c1d2ad1498c963', 'message': 'Add support for creating samples\n\nChange-Id: Ib33a5fd162d760efa23a2fc496c1d11d79484491\n'}, {'number': 2, 'created': '2013-07-17 23:41:39.000000000', 'files': ['ceilometerclient/tests/v2/test_samples.py', 'ceilometerclient/v2/samples.py', 'ceilometerclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/3010ebcc75ea271c46351ef68d00482f0fbacb85', 'message': 'Add support for creating samples\n\nChange-Id: Ib33a5fd162d760efa23a2fc496c1d11d79484491\n'}]",3,37410,3010ebcc75ea271c46351ef68d00482f0fbacb85,11,4,2,4715,,,0,"Add support for creating samples

Change-Id: Ib33a5fd162d760efa23a2fc496c1d11d79484491
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/10/37410/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/tests/v2/test_samples.py', 'ceilometerclient/v2/samples.py', 'ceilometerclient/v2/shell.py']",3,775556196209d23b8eaf836103c1d2ad1498c963,master,"import json @utils.arg('--project-id', metavar='<PROJECT_ID>', help='Tenant to associate with alarm ' '(only settable by admin users)') @utils.arg('--user-id', metavar='<USER_ID>', help='User to associate with alarm ' '(only settable by admin users)') @utils.arg('-r', '--resource-id', metavar='<RESOURCE_ID>', help='ID of the resource.') @utils.arg('-m', '--counter-name', metavar='<METRIC>', help='counter name') @utils.arg('--counter-type', metavar='<COUNTER_NAME>', help='counter type') @utils.arg('--counter-unit', metavar='<COUNTER_UNIT>', help='counter unit') @utils.arg('--counter-volume', metavar='<COUNTER_VOLUME>', help='counter volume') @utils.arg('--resource-metadata', metavar='<RESOURCE_METADATA>', help='resource metadata') def do_sample_create(cc, args={}): '''Create a sample.''' fields = dict(filter(lambda x: not (x[1] is None), vars(args).items())) if args.resource_metadata is not None: fields['resource_metadata'] = json.loads(args.resource_metadata) cc.samples.create(**fields) ",,84,17
openstack%2Fnova~master~Ibc15181e15434ccf8304f80fc468861023b03162,openstack/nova,master,Ibc15181e15434ccf8304f80fc468861023b03162,Tidy up authorization for quota_sets API v3,ABANDONED,2013-06-25 14:11:30.000000000,2013-07-18 09:31:28.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2166}, {'_account_id': 5754}]","[{'number': 1, 'created': '2013-06-25 14:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d037d38c28f644f962889441f28f72198d4dbc31', 'message': 'Use policy instead of authorize_project_context for quota_sets API v3\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Ibc15181e15434ccf8304f80fc468861023b03162\n'}, {'number': 2, 'created': '2013-06-27 07:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39dfa9fb0f4a84d2a67ad24bf44da8493d482f26', 'message': 'Use policy instead of authorize_project_context for quota_sets API v3\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Ibc15181e15434ccf8304f80fc468861023b03162\n'}, {'number': 3, 'created': '2013-07-15 06:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74c249def4765a7927cb87c8e9d354bb91d52876', 'message': 'Tidy up authorization for quota_sets API v3\n\n* Use policy instead of authorize_project_context\n* Tide up\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Ibc15181e15434ccf8304f80fc468861023b03162\n'}, {'number': 4, 'created': '2013-07-15 07:23:38.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_quota_sets.py', 'nova/tests/fake_policy.py', 'nova/api/openstack/compute/plugins/v3/quota_sets.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/36763a068fb6cbce6bbe649378b467cf06832b0b', 'message': 'Tidy up authorization for quota_sets API v3\n\n* Use policy instead of authorize_project_context\n* Tide up\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Ibc15181e15434ccf8304f80fc468861023b03162\n'}]",7,34404,36763a068fb6cbce6bbe649378b467cf06832b0b,15,4,4,5754,,,0,"Tidy up authorization for quota_sets API v3

* Use policy instead of authorize_project_context
* Tide up

Partially implements bp v3-api-extension-versioning

Change-Id: Ibc15181e15434ccf8304f80fc468861023b03162
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/34404/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_quota_sets.py', 'nova/tests/fake_policy.py', 'nova/api/openstack/compute/plugins/v3/quota_sets.py']",3,d037d38c28f644f962889441f28f72198d4dbc31,bp/v3-api-extension-versioning," target = {'project_id': id} authorize_show(context, target=target) return self._format_quota_set(id, self._get_quotas(context, id)) project_quota = self._get_quotas(context, id, True) except exception.AdminRequired:"," authorize_show(context) try: nova.context.authorize_project_context(context, id) return self._format_quota_set(id, self._get_quotas(context, id)) except exception.NotAuthorized: raise webob.exc.HTTPForbidden() try: project_quota = self._get_quotas(context, id, True) except exception.NotAuthorized: raise webob.exc.HTTPForbidden() nova.context.authorize_project_context(context, id) except exception.NotAuthorized:",16,20
openstack%2Fsahara~master~I2096cfdc5bda656a33df969b427d8b7df7d7c83b,openstack/sahara,master,I2096cfdc5bda656a33df969b427d8b7df7d7c83b,Skipping non-existing instances while deletion,MERGED,2013-07-18 08:24:47.000000000,2013-07-18 09:25:00.000000000,2013-07-18 09:25:00.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-18 08:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8acfb24b926d2742507f3300509b4e2f1509fd71', 'message': 'Skipping non-existing instances while deletion\n\nChange-Id: I2096cfdc5bda656a33df969b427d8b7df7d7c83b\nFixes: bug #1201821\n'}, {'number': 2, 'created': '2013-07-18 08:36:17.000000000', 'files': ['savanna/service/instances.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/c9af9e5da4490a7936d05ef798d64732798e6dde', 'message': 'Skipping non-existing instances while deletion\n\nChange-Id: I2096cfdc5bda656a33df969b427d8b7df7d7c83b\nFixes: bug #1201821\n'}]",0,37639,c9af9e5da4490a7936d05ef798d64732798e6dde,9,5,2,7132,,,0,"Skipping non-existing instances while deletion

Change-Id: I2096cfdc5bda656a33df969b427d8b7df7d7c83b
Fixes: bug #1201821
",git fetch https://review.opendev.org/openstack/sahara refs/changes/39/37639/2 && git format-patch -1 --stdout FETCH_HEAD,['savanna/service/instances.py'],1,8acfb24b926d2742507f3300509b4e2f1509fd71,bug/1201821,from nova import exception as nova_exception try: nova.client().servers.delete(instance.instance_id) except nova_exception.NotFound: #Just ignore non-existing instances pass , nova.client().servers.delete(instance.instance_id),8,1
openstack%2Fdesignate~master~Ie84e77ce891cf17a32930326961d16a377850da0,openstack/designate,master,Ie84e77ce891cf17a32930326961d16a377850da0,Implement a Quota management API extension,MERGED,2013-07-10 17:11:40.000000000,2013-07-18 09:20:35.000000000,2013-07-18 09:20:34.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 6494}]","[{'number': 1, 'created': '2013-07-10 17:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/1163266158028e83f794a594c7d1285136389526', 'message': 'Implement a Quota management API extension\n\nAdditionally, this adds the prerequisite plumbing\n\nFixes bug #1199025\n\nChange-Id: Ie84e77ce891cf17a32930326961d16a377850da0\n'}, {'number': 2, 'created': '2013-07-11 12:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/ae54fb992a113305cebd1e1e5d074a369b881c95', 'message': 'Implement a Quota management API extension\n\nAdditionally, this adds the prerequisite plumbing\n\nFixes bug #1199025\n\nChange-Id: Ie84e77ce891cf17a32930326961d16a377850da0\n'}, {'number': 3, 'created': '2013-07-16 08:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/1de25ce8a32c2b4269d474a5c21d0f401adfb6d5', 'message': 'Implement a Quota management API extension\n\nAdditionally, this adds the prerequisite plumbing\n\nFixes bug #1199025\n\nChange-Id: Ie84e77ce891cf17a32930326961d16a377850da0\n'}, {'number': 4, 'created': '2013-07-16 08:44:10.000000000', 'files': ['etc/designate/policy.json', 'designate/central/service.py', 'designate/api/v1/extensions/quotas.py', 'designate/quota/base.py', 'etc/designate/designate.conf.sample', 'designate/quota/impl_storage.py', 'designate/quota/__init__.py', 'designate/storage/api.py', 'designate/tests/test_quota/test_noop.py', 'designate/central/rpcapi.py', 'designate/quota/impl_noop.py', 'designate/tests/test_quota/test_storage.py', 'designate/quota/impl_config.py', 'designate/central/__init__.py', 'designate/tests/test_quota/__init__.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/designate/commit/2e65d271e92c75f59a4443268153db6a04482cca', 'message': 'Implement a Quota management API extension\n\nAdditionally, this adds the prerequisite plumbing\n\nFixes bug #1199025\n\nChange-Id: Ie84e77ce891cf17a32930326961d16a377850da0\n'}]",6,36508,2e65d271e92c75f59a4443268153db6a04482cca,20,3,4,741,,,0,"Implement a Quota management API extension

Additionally, this adds the prerequisite plumbing

Fixes bug #1199025

Change-Id: Ie84e77ce891cf17a32930326961d16a377850da0
",git fetch https://review.opendev.org/openstack/designate refs/changes/08/36508/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/central/service.py', 'designate/api/v1/extensions/quotas.py', 'designate/quota/base.py', 'designate/quota/impl_storage.py', 'designate/quota/__init__.py', 'designate/storage/api.py', 'designate/tests/test_quota/test_noop.py', 'designate/central/rpcapi.py', 'designate/quota/impl_noop.py', 'designate/tests/test_quota/test_storage.py', 'designate/central/__init__.py', 'designate/tests/test_quota/__init__.py', 'setup.cfg']",13,1163266158028e83f794a594c7d1285136389526,bug/1199025, quotas = designate.api.v1.extensions.quotas:blueprint noop = designate.quota.impl_noop:NoopQuota, config = designate.quota.impl_config:ConfigQuota,237,41
openstack%2Fsahara-dashboard~master~Ie6fbd0e08675fc795ffbbcedc1b74f0fe177b4ab,openstack/sahara-dashboard,master,Ie6fbd0e08675fc795ffbbcedc1b74f0fe177b4ab,Cluster creation w/o user keypair,MERGED,2013-07-18 07:26:30.000000000,2013-07-18 09:06:11.000000000,2013-07-18 09:06:11.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-18 07:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/589545fead38e80221aedbe55724cd50c3b188ce', 'message': 'Cluster creation w/o user keypair\n\nChange-Id: Ie6fbd0e08675fc795ffbbcedc1b74f0fe177b4ab\nFixes: bug #1200160\n'}, {'number': 2, 'created': '2013-07-18 09:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/d20a89b13f12d6a4d7b56a505d9513a5b7c395ca', 'message': 'Cluster creation w/o user keypair\n\nFxes: bug #1200160\n\nChange-Id: Ie6fbd0e08675fc795ffbbcedc1b74f0fe177b4ab\n'}, {'number': 3, 'created': '2013-07-18 09:04:21.000000000', 'files': ['savannadashboard/clusters/workflows/create.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/d27340a4ebbb24228a3f523b87bc7e290d3efb7c', 'message': 'Cluster creation w/o user keypair\n\nFixes: bug #1200160\n\nChange-Id: Ie6fbd0e08675fc795ffbbcedc1b74f0fe177b4ab\n'}]",1,37633,d27340a4ebbb24228a3f523b87bc7e290d3efb7c,13,4,3,7132,,,0,"Cluster creation w/o user keypair

Fixes: bug #1200160

Change-Id: Ie6fbd0e08675fc795ffbbcedc1b74f0fe177b4ab
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/33/37633/1 && git format-patch -1 --stdout FETCH_HEAD,['savannadashboard/clusters/workflows/create.py'],1,589545fead38e80221aedbe55724cd50c3b188ce,bug/1200160," keypair_list.insert(0, ("""", ""No keypair"")) user_keypair = context[""general_keypair""] or None user_keypair_id=user_keypair)"," user_keypair_id=context[""general_keypair""])",3,1
openstack%2Fsahara-dashboard~master~I1b84cd813de1d2e5b2437cdf7d8f0e7aa20f4399,openstack/sahara-dashboard,master,I1b84cd813de1d2e5b2437cdf7d8f0e7aa20f4399,Links in Image Registry added,MERGED,2013-07-18 07:43:59.000000000,2013-07-18 08:54:51.000000000,2013-07-18 08:54:51.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-18 07:43:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/0c8423e288ecea9008fed0ae6fa8e4af130f5f00', 'message': 'Links in Image Registry added\n\nImplements bluerint dashboard-image-registry-links\n\nChange-Id: I1b84cd813de1d2e5b2437cdf7d8f0e7aa20f4399\n'}, {'number': 2, 'created': '2013-07-18 08:26:09.000000000', 'files': ['savannadashboard/image_registry/tables.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/42d419525c265a4ccac578a15cd3bceb3ae4ccbb', 'message': 'Links in Image Registry added\n\nImplements blueprint dashboard-image-registry-links\n\nChange-Id: I1b84cd813de1d2e5b2437cdf7d8f0e7aa20f4399\n'}]",0,37635,42d419525c265a4ccac578a15cd3bceb3ae4ccbb,10,4,2,7132,,,0,"Links in Image Registry added

Implements blueprint dashboard-image-registry-links

Change-Id: I1b84cd813de1d2e5b2437cdf7d8f0e7aa20f4399
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/35/37635/2 && git format-patch -1 --stdout FETCH_HEAD,['savannadashboard/image_registry/tables.py'],1,0c8423e288ecea9008fed0ae6fa8e4af130f5f00,bp/dashboard-image-registry-links,"from savannadashboard.utils import compatibility verbose_name=_(""Image""), link=compatibility.convert_url( ""horizon:project:images_and_snapshots:"" ""images:detail""))"," verbose_name=_(""Image""))",5,1
openstack%2Fneutron~master~Ifc9ecad91324ce28399431ea77fe0865b6d8e523,openstack/neutron,master,Ifc9ecad91324ce28399431ea77fe0865b6d8e523,port-update fails when using SELECT FOR UPDATE lock,MERGED,2013-07-10 10:08:32.000000000,2013-07-18 08:33:44.000000000,2013-07-18 08:33:43.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 7135}]","[{'number': 1, 'created': '2013-07-10 10:08:32.000000000', 'files': ['neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9900c2334abf5e4b1ad09ee24ed88184c085349', 'message': 'port-update fails when using SELECT FOR UPDATE lock\n\nIn Postgresql, it will throw the bellow exception when\nusing SELECT FOR UPDATE lock combined with outer join.\n""SELECT FOR UPDATE/SHARE cannot be applied to the\n nullable side of an outer join""\n\nThe reason can refer http://www.postgresql.org/ \\\nmessage-id/21634.1160151923@sss.pgh.pa.us\n\nfor this issue, I don\'t think outer join is necessary，\nso I change it to use inner join.\n\nFixes bug #1191653\n\nChange-Id: Ifc9ecad91324ce28399431ea77fe0865b6d8e523\n'}]",0,36426,b9900c2334abf5e4b1ad09ee24ed88184c085349,7,5,1,2711,,,0,"port-update fails when using SELECT FOR UPDATE lock

In Postgresql, it will throw the bellow exception when
using SELECT FOR UPDATE lock combined with outer join.
""SELECT FOR UPDATE/SHARE cannot be applied to the
 nullable side of an outer join""

The reason can refer http://www.postgresql.org/ \
message-id/21634.1160151923@sss.pgh.pa.us

for this issue, I don't think outer join is necessary，
so I change it to use inner join.

Fixes bug #1191653

Change-Id: Ifc9ecad91324ce28399431ea77fe0865b6d8e523
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/36426/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,b9900c2334abf5e4b1ad09ee24ed88184c085349,bug/1191653," models_v2.IPAvailabilityRange).join( for range in results: allocation_pool_id=range['allocation_pool_id'],"," models_v2.IPAvailabilityRange, models_v2.IPAllocationPool).join( for (range, pool) in results: allocation_pool_id=pool['id'],",3,4
openstack%2Fneutron~master~I1a08636a6aa225da8b5d43a0bbcb9b59c057df42,openstack/neutron,master,I1a08636a6aa225da8b5d43a0bbcb9b59c057df42,Apply Oslo ModelBase to NeutronBase,MERGED,2013-07-06 16:06:39.000000000,2013-07-18 08:04:41.000000000,2013-07-18 08:04:40.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1994}, {'_account_id': 2031}, {'_account_id': 2271}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 5638}, {'_account_id': 6072}]","[{'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3c395ccb3c2c5e3ab590bd574f4499709aa68c92', 'message': ""Apply Oslo ModelBase to QuantumBase\n\nOslo.db has ModelBase which implements most of QuantumBase's code.\nTherefore QuantumBase should inherit from ModelBase to keep things DRY.\n\nFixes bug #1171055\n\nChange-Id: I1a08636a6aa225da8b5d43a0bbcb9b59c057df42\n""}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8c51dd70ec0d9b7f73868f534fa869e401ab7683', 'message': ""Apply Oslo ModelBase to QuantumBase\n\nOslo.db has ModelBase which implements most of QuantumBase's code.\nTherefore QuantumBase should inherit from ModelBase to keep things DRY.\n\nFixes bug #1171055\n\nChange-Id: I1a08636a6aa225da8b5d43a0bbcb9b59c057df42\n""}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/937aee06912eea67efaf1ae5e3fb46b578f2a1b4', 'message': ""Apply Oslo ModelBase to QuantumBase\n\nSync oslo's db.sqlalchemy package\nFix QuantumBase to inherit from ModelBase\n\nFixes bug #1171055\n\nChange-Id: I1a08636a6aa225da8b5d43a0bbcb9b59c057df42\n""}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/57cc11fb8d953b1ac105f01cc007be8409a0d0db', 'message': ""Apply Oslo ModelBase to QuantumBase\n\nSync oslo's db.sqlalchemy package\nFix QuantumBase to inherit from ModelBase\n\nFixes bug #1171055\n\nChange-Id: I1a08636a6aa225da8b5d43a0bbcb9b59c057df42\n""}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a7d8914303b46113cc0030b50de8a0f3f905c2ad', 'message': 'tmp\n\nChange-Id: I1a08636a6aa225da8b5d43a0bbcb9b59c057df42\n'}, {'number': 6, 'created': '2013-07-08 01:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/91d27c1e24feb1e1bd8083ee5ad7ab1c9ec8f186', 'message': ""Apply Oslo ModelBase to QuantumBase\n\nOslo.db has ModelBase which implements most of QuantumBase's code.\nTherefore QuantumBase should inherit from ModelBase to keep things DRY.\n\nFixes bug #1171055\n\nChange-Id: I1a08636a6aa225da8b5d43a0bbcb9b59c057df42\n""}, {'number': 7, 'created': '2013-07-08 01:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/406d1493643be9a9dc148d62c051c044225fa170', 'message': ""Apply Oslo ModelBase to NeutronBase\n\nOslo.db has ModelBase which implements most of QuantumBase's code.\nTherefore QuantumBase should inherit from ModelBase to keep things DRY.\n\nFixes bug #1171055\n\nChange-Id: I1a08636a6aa225da8b5d43a0bbcb9b59c057df42\n""}, {'number': 8, 'created': '2013-07-08 01:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c72b18e91dd3c0dcb81fc2df075dd466bf4bb4c9', 'message': ""Apply Oslo ModelBase to NeutronBase\n\nOslo.db has ModelBase which implements most of NeutronBase's code.\nTherefore NeutronBase should inherit from ModelBase to keep things DRY.\n\nFixes bug #1171055\n\nChange-Id: I1a08636a6aa225da8b5d43a0bbcb9b59c057df42\n""}, {'number': 9, 'created': '2013-07-08 02:14:08.000000000', 'files': ['neutron/db/model_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f4e8a3ccfc4db56823ae756b707b94e19236233', 'message': ""Apply Oslo ModelBase to NeutronBase\n\nOslo.db has ModelBase which implements most of NeutronBase's code.\nTherefore NeutronBase should inherit from ModelBase to keep things DRY.\n\nFixes bug #1171055\n\nChange-Id: I1a08636a6aa225da8b5d43a0bbcb9b59c057df42\n""}]",2,27196,1f4e8a3ccfc4db56823ae756b707b94e19236233,49,14,9,1994,,,0,"Apply Oslo ModelBase to NeutronBase

Oslo.db has ModelBase which implements most of NeutronBase's code.
Therefore NeutronBase should inherit from ModelBase to keep things DRY.

Fixes bug #1171055

Change-Id: I1a08636a6aa225da8b5d43a0bbcb9b59c057df42
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/27196/7 && git format-patch -1 --stdout FETCH_HEAD,['quantum/db/model_base.py'],1,3c395ccb3c2c5e3ab590bd574f4499709aa68c92,27196,from quantum.openstack.common.db.sqlalchemy import models class QuantumBase(models.ModelBase):," class QuantumBase(object): def __setitem__(self, key, value): setattr(self, key, value) def __getitem__(self, key): return getattr(self, key) def get(self, key, default=None): return getattr(self, key, default) def update(self, values): """"""Make the model object behave like a dict."""""" for k, v in values.iteritems(): setattr(self, k, v) def iteritems(self): """"""Make the model object behave like a dict. Includes attributes from joins. """""" local = dict(self) joined = dict([(k, v) for k, v in self.__dict__.iteritems() if not k[0] == '_']) local.update(joined) return local.iteritems() ",3,26
openstack%2Fnova~milestone-proposed~I3ff9001543b84b1037597da243422490bb611657,openstack/nova,milestone-proposed,I3ff9001543b84b1037597da243422490bb611657,Force reopening eventlet's hub after fork,MERGED,2013-07-17 15:39:32.000000000,2013-07-18 08:04:23.000000000,2013-07-18 08:04:21.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1653}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-07-17 15:39:32.000000000', 'files': ['nova/console/websocketproxy.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9315de02d67aaacc7e8da0de67ca477c2c0bc127', 'message': ""Force reopening eventlet's hub after fork\n\nWith this we reopen eventlet's hub after a fork (triggered from\nwebsockify when a new client connects) to prevent sharing epoll's fd\nwith the parent, which may cause erratic behaviour.\n\nThis caused novncproxy to stop working when it had more than two clients\nconnected.\n\nFixes bug #1193031\n\nChange-Id: I3ff9001543b84b1037597da243422490bb611657\n(cherry picked from commit cb25bc4530323aaa33d5c42eb01f998d463f2106)\n""}]",0,37507,9315de02d67aaacc7e8da0de67ca477c2c0bc127,6,4,1,1561,,,0,"Force reopening eventlet's hub after fork

With this we reopen eventlet's hub after a fork (triggered from
websockify when a new client connects) to prevent sharing epoll's fd
with the parent, which may cause erratic behaviour.

This caused novncproxy to stop working when it had more than two clients
connected.

Fixes bug #1193031

Change-Id: I3ff9001543b84b1037597da243422490bb611657
(cherry picked from commit cb25bc4530323aaa33d5c42eb01f998d463f2106)
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/37507/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/console/websocketproxy.py'],1,9315de02d67aaacc7e8da0de67ca477c2c0bc127,bug/1193031," # Reopen the eventlet hub to make sure we don't share an epoll # fd with parent and/or siblings, which would be bad from eventlet import hubs hubs.use_hub() ",,5,0
openstack%2Fcinder~master~I56c64c94eccf0a311e6f3d611738ad0403351971,openstack/cinder,master,I56c64c94eccf0a311e6f3d611738ad0403351971,Move copy_volume function to volume/utils.py.,MERGED,2013-07-17 13:40:48.000000000,2013-07-18 07:34:17.000000000,2013-07-18 07:34:16.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-17 13:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9dbd2a24cfd937729872a457e049cafcc9314899', 'message': 'Move copy_volume function to volume/utils.py.\n\nThere are several copy-pastes of running dd, so moved the most\ncorrect one (LVM) to volume/utils.py, and also updated\nBlockDeviceDriver to use it. Other drivers (e.g., NFS, GPFS, Scality)\nshould be updated as well. Volume migration for detached volumes\nis a future use case.\n\nChange-Id: I56c64c94eccf0a311e6f3d611738ad0403351971\n'}, {'number': 2, 'created': '2013-07-17 16:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/33e7679c2d1f25600301b4bb7ccce66defdf64f9', 'message': 'Move copy_volume function to volume/utils.py.\n\nThere are several copy-pastes of running dd, so moved the most\ncorrect one (LVM) to volume/utils.py, and also updated\nBlockDeviceDriver to use it. Other drivers (e.g., NFS, GPFS, Scality)\nshould be updated as well. Volume migration for detached volumes\nis a future use case.\n\nChange-Id: I56c64c94eccf0a311e6f3d611738ad0403351971\n'}, {'number': 3, 'created': '2013-07-18 05:49:20.000000000', 'files': ['cinder/volume/utils.py', 'cinder/tests/test_block_device.py', 'cinder/volume/drivers/block_device.py', 'cinder/tests/test_volume.py', 'cinder/tests/test_volume_utils.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/30397d8a0a22f3ecad0001ac50a084cc41f4a43d', 'message': 'Move copy_volume function to volume/utils.py.\n\nThere are several copy-pastes of running dd, so moved the most\ncorrect one (LVM) to volume/utils.py, and also updated\nBlockDeviceDriver to use it. Other drivers (e.g., NFS, GPFS, Scality)\nshould be updated as well. Volume migration for detached volumes\nis a future use case.\n\nChange-Id: I56c64c94eccf0a311e6f3d611738ad0403351971\n'}]",5,37470,30397d8a0a22f3ecad0001ac50a084cc41f4a43d,20,6,3,4355,,,0,"Move copy_volume function to volume/utils.py.

There are several copy-pastes of running dd, so moved the most
correct one (LVM) to volume/utils.py, and also updated
BlockDeviceDriver to use it. Other drivers (e.g., NFS, GPFS, Scality)
should be updated as well. Volume migration for detached volumes
is a future use case.

Change-Id: I56c64c94eccf0a311e6f3d611738ad0403351971
",git fetch https://review.opendev.org/openstack/cinder refs/changes/70/37470/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/utils.py', 'cinder/tests/test_block_device.py', 'cinder/volume/drivers/block_device.py', 'cinder/tests/test_volume.py', 'cinder/tests/test_volume_utils.py', 'cinder/volume/drivers/lvm.py']",6,9dbd2a24cfd937729872a457e049cafcc9314899,utils_cp_vol,"from cinder.volume import utils as volutils volutils.copy_volume(self.local_path(snapshot), self.local_path(volume), snapshot['volume_size'] * 1024, execute=self._execute) return volutils.copy_volume('/dev/zero', vol_path, size_in_g * 1024, sync=True, execute=self._execute) volutils.copy_volume(self.local_path(temp_snapshot), self.local_path(volume), src_vref['size'] * 1024, execute=self._execute)","from cinder.openstack.common import strutils from cinder import units cfg.StrOpt('volume_dd_blocksize', default='1M', help='The default block size used when clearing volumes'), def _calculate_count(self, blocksize, size_in_g): # Check if volume_dd_blocksize is valid try: # Rule out zero-sized/negative dd blocksize which # cannot be caught by strutils if blocksize.startswith(('-', '0')): raise ValueError bs = strutils.to_bytes(blocksize) except (ValueError, TypeError): msg = (_(""Incorrect value error: %(blocksize)s, "" ""it may indicate that \'volume_dd_blocksize\' "" ""was configured incorrectly. Fall back to default."") % {'blocksize': blocksize}) LOG.warn(msg) # Fall back to default blocksize CONF.clear_override('volume_dd_blocksize', self.configuration.config_group) blocksize = self.configuration.volume_dd_blocksize bs = strutils.to_bytes(blocksize) count = math.ceil(size_in_g * units.GiB / float(bs)) return blocksize, int(count) def _copy_volume(self, srcstr, deststr, size_in_g, clearing=False): # Use O_DIRECT to avoid thrashing the system buffer cache extra_flags = ['iflag=direct', 'oflag=direct'] # Check whether O_DIRECT is supported try: self._execute('dd', 'count=0', 'if=%s' % srcstr, 'of=%s' % deststr, *extra_flags, run_as_root=True) except exception.ProcessExecutionError: extra_flags = [] # If the volume is being unprovisioned then # request the data is persisted before returning, # so that it's not discarded from the cache. if clearing and not extra_flags: extra_flags.append('conv=fdatasync') blocksize = self.configuration.volume_dd_blocksize blocksize, count = self._calculate_count(blocksize, size_in_g) # Perform the copy self._execute('dd', 'if=%s' % srcstr, 'of=%s' % deststr, 'count=%d' % count, 'bs=%s' % blocksize, *extra_flags, run_as_root=True) self._copy_volume(self.local_path(snapshot), self.local_path(volume), snapshot['volume_size']) return self._copy_volume('/dev/zero', vol_path, size_in_g, clearing=True) self._copy_volume(self.local_path(temp_snapshot), self.local_path(volume), src_vref['size'])",128,125
openstack%2Fceilometer~milestone-proposed~Id1368c7ccf730bc62bc2b32247266e87482844cb,openstack/ceilometer,milestone-proposed,Id1368c7ccf730bc62bc2b32247266e87482844cb,Default to ctx user/project ID in sample POST API,MERGED,2013-07-17 21:24:56.000000000,2013-07-18 07:31:38.000000000,2013-07-18 07:31:37.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1669}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-07-17 21:24:56.000000000', 'files': ['tests/api/v2/post_samples.py', 'ceilometer/api/controllers/v2.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/64c499354fe751f7a71f20e6e5277701658d4e3e', 'message': ""Default to ctx user/project ID in sample POST API\n\nFixes bug #1202143\n\nAvoid RPC failure when project and user IDs not explicitly\nspecified in POST'd sample.\n\nInstead default to identity in current context.\n\nChange-Id: Id1368c7ccf730bc62bc2b32247266e87482844cb\n(cherry picked from commit 1d0b6397d468d8527ad3b388ee2f2b1714f3c38d)\n""}]",0,37574,64c499354fe751f7a71f20e6e5277701658d4e3e,7,4,1,2284,,,0,"Default to ctx user/project ID in sample POST API

Fixes bug #1202143

Avoid RPC failure when project and user IDs not explicitly
specified in POST'd sample.

Instead default to identity in current context.

Change-Id: Id1368c7ccf730bc62bc2b32247266e87482844cb
(cherry picked from commit 1d0b6397d468d8527ad3b388ee2f2b1714f3c38d)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/74/37574/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/api/v2/post_samples.py', 'ceilometer/api/controllers/v2.py']",2,64c499354fe751f7a71f20e6e5277701658d4e3e,, s.user_id = (s.user_id or pecan.request.headers.get('X-User-Id')) s.project_id = (s.project_id or pecan.request.headers.get('X-Project-Id')),,31,0
openstack%2Fnova~stable%2Fgrizzly~Ib25cb13273de807f9719bc1403684e81f5cb125e,openstack/nova,stable/grizzly,Ib25cb13273de807f9719bc1403684e81f5cb125e,Monkeypatch and reopen eventlet's hub in novnc,ABANDONED,2013-07-17 15:53:27.000000000,2013-07-18 07:28:12.000000000,,"[{'_account_id': 3}, {'_account_id': 1812}, {'_account_id': 5511}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-07-17 15:53:27.000000000', 'files': ['nova/console/websocketproxy.py', 'bin/nova-novncproxy'], 'web_link': 'https://opendev.org/openstack/nova/commit/26ec996a2c7cae6aa0afc70a7ddf35be799cbb27', 'message': ""Monkeypatch and reopen eventlet's hub in novnc\n\neventlet.monkeypatch was not done in nova-novncproxy, but we need it in\norder to do an rpc call and validate the token.\n\nAlso,With this we reopen eventlet's hub after a fork (triggered from\nwebsockify when a new client connects) to prevent sharing epoll's fd\nwith the parent, which may cause erratic behaviour.\n\nThis caused novncproxy to stop working when it had more than two\nclients connected.\n\nFixes bug #1193031\n\nChange-Id: Ib25cb13273de807f9719bc1403684e81f5cb125e\n""}]",0,37512,26ec996a2c7cae6aa0afc70a7ddf35be799cbb27,5,4,1,5511,,,0,"Monkeypatch and reopen eventlet's hub in novnc

eventlet.monkeypatch was not done in nova-novncproxy, but we need it in
order to do an rpc call and validate the token.

Also,With this we reopen eventlet's hub after a fork (triggered from
websockify when a new client connects) to prevent sharing epoll's fd
with the parent, which may cause erratic behaviour.

This caused novncproxy to stop working when it had more than two
clients connected.

Fixes bug #1193031

Change-Id: Ib25cb13273de807f9719bc1403684e81f5cb125e
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/37512/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/console/websocketproxy.py', 'bin/nova-novncproxy']",2,26ec996a2c7cae6aa0afc70a7ddf35be799cbb27,bug/1193031,import eventlet eventlet.monkey_patch(os=False) ,,8,0
openstack%2Fmurano~master~I0675cd584dabc845835101192316ddd206af708d,openstack/murano,master,I0675cd584dabc845835101192316ddd206af708d,Deployment description is not hidden anymore,MERGED,2013-07-17 16:20:19.000000000,2013-07-18 07:27:48.000000000,2013-07-18 07:27:48.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-07-17 16:20:19.000000000', 'files': ['muranoapi/db/models.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/0246fd06c60535ad4d7cd037b0d87ded6406fcbe', 'message': 'Deployment description is not hidden anymore\n\nDescription (i.e. the list of deployed services etc) is needed to display the configuration which was attempted to be deployed. So, this should be exposed by the API\n\nChange-Id: I0675cd584dabc845835101192316ddd206af708d\n'}]",0,37518,0246fd06c60535ad4d7cd037b0d87ded6406fcbe,5,2,1,8127,,,0,"Deployment description is not hidden anymore

Description (i.e. the list of deployed services etc) is needed to display the configuration which was attempted to be deployed. So, this should be exposed by the API

Change-Id: I0675cd584dabc845835101192316ddd206af708d
",git fetch https://review.opendev.org/openstack/murano refs/changes/18/37518/1 && git format-patch -1 --stdout FETCH_HEAD,['muranoapi/db/models.py'],1,0246fd06c60535ad4d7cd037b0d87ded6406fcbe,," # del dictionary[""description""]"," del dictionary[""description""]",1,1
openstack%2Fmurano-dashboard~master~I1d7ac2eccba9db2458889cc731eb3664eff0a4ec,openstack/murano-dashboard,master,I1d7ac2eccba9db2458889cc731eb3664eff0a4ec,After all updates form values are saved without using self.storage.,MERGED,2013-07-16 14:07:41.000000000,2013-07-18 07:27:00.000000000,2013-07-18 07:27:00.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}]","[{'number': 1, 'created': '2013-07-16 14:07:41.000000000', 'files': ['muranodashboard/panel/views.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/4afdc4e13935eef521267a87b2eea9092b9b4352', 'message': 'After all updates form values are saved without using self.storage.\n\nSo get rid of it.\n\nChange-Id: I1d7ac2eccba9db2458889cc731eb3664eff0a4ec\n'}]",0,37253,4afdc4e13935eef521267a87b2eea9092b9b4352,6,3,1,8040,,,0,"After all updates form values are saved without using self.storage.

So get rid of it.

Change-Id: I1d7ac2eccba9db2458889cc731eb3664eff0a4ec
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/53/37253/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/views.py'],1,4afdc4e13935eef521267a87b2eea9092b9b4352,bug/MRN-24," return self.initial_dict.get(step, {'request': self.request})"," step_data = self.storage.data['step_data'] if step in step_data: default = dict(step_data.items() + [('request', self.request)]) else: default = {'request': self.request} return self.initial_dict.get(step, default)",1,6
openstack%2Fcinder~master~I17543a82be370bed57d4165ad8756ccb390bc0d9,openstack/cinder,master,I17543a82be370bed57d4165ad8756ccb390bc0d9,Delete snapshot metadata when snapshot is deleted,MERGED,2013-07-17 17:58:27.000000000,2013-07-18 07:21:25.000000000,2013-07-18 07:21:24.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 4355}]","[{'number': 1, 'created': '2013-07-17 17:58:27.000000000', 'files': ['cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d8c193012adb5a4f08982324324260656752480b', 'message': 'Delete snapshot metadata when snapshot is deleted\n\nWhen a volume is deleted all rows in the volume_metadata table for that\nvolume are deleted as part of the database operation. This patch updates\nthe snapshot delete operation to delete corresponding rows in the\nsnapshot_metadata table.\n\nChange-Id: I17543a82be370bed57d4165ad8756ccb390bc0d9\n'}]",0,37544,d8c193012adb5a4f08982324324260656752480b,8,3,1,1773,,,0,"Delete snapshot metadata when snapshot is deleted

When a volume is deleted all rows in the volume_metadata table for that
volume are deleted as part of the database operation. This patch updates
the snapshot delete operation to delete corresponding rows in the
snapshot_metadata table.

Change-Id: I17543a82be370bed57d4165ad8756ccb390bc0d9
",git fetch https://review.opendev.org/openstack/cinder refs/changes/44/37544/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py']",2,d8c193012adb5a4f08982324324260656752480b,delete_snapshot_metadata," def _create_snapshot(volume_id, size='0', metadata=None): if metadata is not None: snap['metadata'] = metadata def test_create_delete_snapshot_with_metadata(self): """"""Test snapshot can be created with metadata and deleted."""""" test_meta = {'fake_key': 'fake_value'} volume = self._create_volume(0, None) volume_id = volume['id'] self.volume.create_volume(self.context, volume_id) snapshot = self._create_snapshot(volume['id'], metadata=test_meta) snapshot_id = snapshot['id'] result_meta = { snapshot.snapshot_metadata[0].key: snapshot.snapshot_metadata[0].value} self.assertEqual(result_meta, test_meta) self.volume.delete_snapshot(self.context, snapshot_id) self.assertRaises(exception.NotFound, db.snapshot_get, self.context, snapshot_id) "," def _create_snapshot(volume_id, size='0'):",27,1
openstack%2Fcinder~master~I7d6e01de7dbc542ebe8fc35c0776de7a099f91e6,openstack/cinder,master,I7d6e01de7dbc542ebe8fc35c0776de7a099f91e6,Fix indent in cincer/volume/configuration.py,MERGED,2013-07-17 05:10:10.000000000,2013-07-18 07:17:19.000000000,2013-07-18 07:17:19.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2166}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 5997}]","[{'number': 1, 'created': '2013-07-17 05:10:10.000000000', 'files': ['cinder/volume/configuration.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/041488406b0bb50b7e8c868975e4f225294d68e9', 'message': 'Fix indent in cincer/volume/configuration.py\n\nChange-Id: I7d6e01de7dbc542ebe8fc35c0776de7a099f91e6\n'}]",0,37394,041488406b0bb50b7e8c868975e4f225294d68e9,7,6,1,1994,,,0,"Fix indent in cincer/volume/configuration.py

Change-Id: I7d6e01de7dbc542ebe8fc35c0776de7a099f91e6
",git fetch https://review.opendev.org/openstack/cinder refs/changes/94/37394/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/configuration.py'],1,041488406b0bb50b7e8c868975e4f225294d68e9,configuration_indent," CONF.register_opts(volume_opts, group=self.config_group)"," CONF.register_opts(volume_opts, group=self.config_group)",1,2
openstack%2Fcinder~master~Id02ba23b233d348885250ccb8c14fcf04667adec,openstack/cinder,master,Id02ba23b233d348885250ccb8c14fcf04667adec,Fixes Opt type of use_multipath_for_image_xfer,MERGED,2013-07-17 05:39:54.000000000,2013-07-18 07:17:13.000000000,2013-07-18 07:17:12.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1773}, {'_account_id': 2166}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 5997}]","[{'number': 1, 'created': '2013-07-17 05:39:54.000000000', 'files': ['cinder/volume/driver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/36ab241f7cfc0049e1bd92835a219e72ddbf94b8', 'message': 'Fixes Opt type of use_multipath_for_image_xfer\n\nChanged use_multipath_for_image_xfer from StrOpt to BoolOpt\n\nChange-Id: Id02ba23b233d348885250ccb8c14fcf04667adec\n'}]",0,37398,36ab241f7cfc0049e1bd92835a219e72ddbf94b8,8,7,1,1994,,,0,"Fixes Opt type of use_multipath_for_image_xfer

Changed use_multipath_for_image_xfer from StrOpt to BoolOpt

Change-Id: Id02ba23b233d348885250ccb8c14fcf04667adec
",git fetch https://review.opendev.org/openstack/cinder refs/changes/98/37398/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/driver.py'],1,36ab241f7cfc0049e1bd92835a219e72ddbf94b8,volume_driver," cfg.BoolOpt('use_multipath_for_image_xfer', default=False, help='Do we attach/detach volumes in cinder using multipath ' 'for volume to image and image to volume transfers?'), ]"," cfg.StrOpt('use_multipath_for_image_xfer', default=False, help='Do we attach/detach volumes in cinder using multipath ' 'for volume to image and image to volume transfers?'), ]",4,4
openstack%2Fnova~master~I6f1aa507ffd297e56d9cfd23972bc3bb15ba181a,openstack/nova,master,I6f1aa507ffd297e56d9cfd23972bc3bb15ba181a,Port used limits extension to v3 API Part 2,MERGED,2013-07-10 01:45:18.000000000,2013-07-18 07:16:56.000000000,2013-07-18 07:16:54.000000000,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4690}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-10 01:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/deb0313ae0203f044eede7178b1c911f10693744', 'message': 'Port used limits extension to v3 API Part 2\n\nPorts the used limits extension and the corresponding unittests to\nthe v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I6f1aa507ffd297e56d9cfd23972bc3bb15ba181a\n'}, {'number': 2, 'created': '2013-07-10 03:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48bb865e78b949934693a78c35065fe6e677958b', 'message': 'Port used limits extension to v3 API Part 2\n\nPorts the used limits extension and the corresponding unittests to\nthe v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I6f1aa507ffd297e56d9cfd23972bc3bb15ba181a\n'}, {'number': 3, 'created': '2013-07-10 03:44:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5279017be51ae03566afca124629a7bf61e7489', 'message': 'Port used limits extension to v3 API Part 2\n\nPorts the used limits extension and the corresponding unittests to\nthe v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I6f1aa507ffd297e56d9cfd23972bc3bb15ba181a\n'}, {'number': 4, 'created': '2013-07-15 06:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f0bb6adf89a94d7badd935917f791fdbfdcab83', 'message': 'Port used limits extension to v3 API Part 2\n\nPorts the used limits extension and the corresponding unittests to\nthe v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I6f1aa507ffd297e56d9cfd23972bc3bb15ba181a\n'}, {'number': 5, 'created': '2013-07-16 00:01:18.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_used_limits.py', 'etc/nova/policy.json', 'nova/tests/fake_policy.py', 'setup.cfg', 'nova/api/openstack/compute/plugins/v3/used_limits.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ce09b8763cea71b7434723623627026cd644c4fe', 'message': 'Port used limits extension to v3 API Part 2\n\nPorts the used limits extension and the corresponding unittests to\nthe v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I6f1aa507ffd297e56d9cfd23972bc3bb15ba181a\n'}]",4,36373,ce09b8763cea71b7434723623627026cd644c4fe,20,6,5,4690,,,0,"Port used limits extension to v3 API Part 2

Ports the used limits extension and the corresponding unittests to
the v3 framework.

Partially implements blueprint nova-v3-api

Change-Id: I6f1aa507ffd297e56d9cfd23972bc3bb15ba181a
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/36373/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_used_limits.py', 'etc/nova/policy.json', 'nova/api/openstack/compute/plugins/v3/used_limits_for_admin.py', 'nova/tests/fake_policy.py', 'nova/api/openstack/compute/plugins/v3/used_limits.py']",5,deb0313ae0203f044eede7178b1c911f10693744,bp/nova-v3-api,"import stevedore from nova.api.openstack.compute.plugins.v3 import used_limits_for_adminXMLNS = ""http://docs.openstack.org/compute/ext/used_limits/api/v3""ALIAS_ADMIN = ""os-used-limits-for-admin"" authorize = extensions.soft_extension_authorizer('compute', 'v3:' + ALIAS) 'v3:' + ALIAS_ADMIN) def __init__(self, **kwargs): self.extension_info = kwargs.pop('extension_info') super(UsedLimitsController, self).__init__(**kwargs) self.ext_mgr = stevedore.enabled.EnabledExtensionManager( namespace='nova.api.v3.extensions', check_func=self._check_load_extension, invoke_on_load=True, invoke_kwds={""extension_info"": self.extension_info}) def _check_load_extension(self, ext): if isinstance(ext.obj, used_limits_for_admin.UsedLimitsForAdmin): return True return False if list(self.ext_mgr):class UsedLimits(extensions.V3APIExtensionBase): version = 1 controller = UsedLimitsController(extension_info=self.extension_info) def get_resources(self): return []","XMLNS = ""http://docs.openstack.org/compute/ext/used_limits/api/v1.1""authorize = extensions.soft_extension_authorizer('compute', 'used_limits') 'used_limits_for_admin') def __init__(self, ext_mgr): self.ext_mgr = ext_mgr if self.ext_mgr.is_loaded('os-used-limits-for-admin'):class Used_limits(extensions.ExtensionDescriptor): updated = ""2012-07-13T00:00:00+00:00"" controller = UsedLimitsController(self.ext_mgr)",77,32
openstack%2Fnova~master~I34214370f53d481346eb11fec6b8fd0ddeb42918,openstack/nova,master,I34214370f53d481346eb11fec6b8fd0ddeb42918,Port used limits extension to v3 API Part 1,MERGED,2013-07-02 22:17:46.000000000,2013-07-18 07:16:36.000000000,2013-07-18 07:16:34.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4690}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-02 22:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3d2286418da520e95a12199fe2529276973779a', 'message': 'Port used limits extension to v3 API Part 1\n\nThis changeset only copies the v2 implementation file into the\nappropriate v3 directory unchanged. The copy as-is will not be\nloaded by either the v2 or v3 extension loaders. The second\nchangeset will then make the changes required for it to work as a\nv3 extension.\n\nThis is being done in order to make reviewing of extension porting\neasier as gerrit will display only what is actually changed for v3\nrather than entirely new files.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I34214370f53d481346eb11fec6b8fd0ddeb42918\n'}, {'number': 2, 'created': '2013-07-07 16:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d6c378083d7de5f0a817833aeee731b5424dac4', 'message': 'Port used limits extension to v3 API Part 1\n\nThis changeset only copies the v2 implementation file into the\nappropriate v3 directory unchanged. The copy as-is will not be\nloaded by either the v2 or v3 extension loaders. The second\nchangeset will then make the changes required for it to work as a\nv3 extension.\n\nThis is being done in order to make reviewing of extension porting\neasier as gerrit will display only what is actually changed for v3\nrather than entirely new files.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I34214370f53d481346eb11fec6b8fd0ddeb42918\n'}, {'number': 3, 'created': '2013-07-10 01:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/212ef315dab20510ea0d937bbb27c41618ccb48d', 'message': 'Port used limits extension to v3 API Part 1\n\nThis changeset only copies the v2 implementation file into the\nappropriate v3 directory unchanged. The copy as-is will not be\nloaded by either the v2 or v3 extension loaders. The second\nchangeset will then make the changes required for it to work as a\nv3 extension.\n\nThis is being done in order to make reviewing of extension porting\neasier as gerrit will display only what is actually changed for v3\nrather than entirely new files.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I34214370f53d481346eb11fec6b8fd0ddeb42918\n'}, {'number': 4, 'created': '2013-07-10 03:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2521d1fa6438a89adb15e38bd25b37a81d41b42a', 'message': 'Port used limits extension to v3 API Part 1\n\nThis changeset only copies the v2 implementation file into the\nappropriate v3 directory unchanged. The copy as-is will not be\nloaded by either the v2 or v3 extension loaders. The second\nchangeset will then make the changes required for it to work as a\nv3 extension.\n\nThis is being done in order to make reviewing of extension porting\neasier as gerrit will display only what is actually changed for v3\nrather than entirely new files.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I34214370f53d481346eb11fec6b8fd0ddeb42918\n'}, {'number': 5, 'created': '2013-07-15 06:48:45.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_used_limits.py', 'nova/api/openstack/compute/plugins/v3/used_limits.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0f67835da50cb5380e199aef6a92ac7afea80768', 'message': 'Port used limits extension to v3 API Part 1\n\nThis changeset only copies the v2 implementation file into the\nappropriate v3 directory unchanged. The copy as-is will not be\nloaded by either the v2 or v3 extension loaders. The second\nchangeset will then make the changes required for it to work as a\nv3 extension.\n\nThis is being done in order to make reviewing of extension porting\neasier as gerrit will display only what is actually changed for v3\nrather than entirely new files.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I34214370f53d481346eb11fec6b8fd0ddeb42918\n'}]",0,35400,0f67835da50cb5380e199aef6a92ac7afea80768,20,5,5,4690,,,0,"Port used limits extension to v3 API Part 1

This changeset only copies the v2 implementation file into the
appropriate v3 directory unchanged. The copy as-is will not be
loaded by either the v2 or v3 extension loaders. The second
changeset will then make the changes required for it to work as a
v3 extension.

This is being done in order to make reviewing of extension porting
easier as gerrit will display only what is actually changed for v3
rather than entirely new files.

Partially implements blueprint nova-v3-api

Change-Id: I34214370f53d481346eb11fec6b8fd0ddeb42918
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/35400/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_used_limits.py', 'nova/api/openstack/compute/plugins/v3/used_limits.py']",2,d3d2286418da520e95a12199fe2529276973779a,bp/nova-v3-api,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova.api.openstack import extensions from nova.api.openstack import wsgi from nova.api.openstack import xmlutil from nova import quota QUOTAS = quota.QUOTAS XMLNS = ""http://docs.openstack.org/compute/ext/used_limits/api/v1.1"" ALIAS = ""os-used-limits"" authorize = extensions.soft_extension_authorizer('compute', 'used_limits') authorize_for_admin = extensions.extension_authorizer('compute', 'used_limits_for_admin') class UsedLimitsTemplate(xmlutil.TemplateBuilder): def construct(self): root = xmlutil.TemplateElement('limits', selector='limits') root.set('{%s}usedLimits' % XMLNS, '%s:usedLimits' % ALIAS) return xmlutil.SlaveTemplate(root, 1, nsmap={ALIAS: XMLNS}) class UsedLimitsController(wsgi.Controller): def __init__(self, ext_mgr): self.ext_mgr = ext_mgr @staticmethod def _reserved(req): try: return int(req.GET['reserved']) except (ValueError, KeyError): return False @wsgi.extends def index(self, req, resp_obj): resp_obj.attach(xml=UsedLimitsTemplate()) context = req.environ['nova.context'] project_id = self._project_id(context, req) quotas = QUOTAS.get_project_quotas(context, project_id, usages=True) quota_map = { 'totalRAMUsed': 'ram', 'totalCoresUsed': 'cores', 'totalInstancesUsed': 'instances', 'totalFloatingIpsUsed': 'floating_ips', 'totalSecurityGroupsUsed': 'security_groups', } used_limits = {} for display_name, quota in quota_map.iteritems(): if quota in quotas: reserved = (quotas[quota]['reserved'] if self._reserved(req) else 0) used_limits[display_name] = quotas[quota]['in_use'] + reserved resp_obj.obj['limits']['absolute'].update(used_limits) def _project_id(self, context, req): if self.ext_mgr.is_loaded('os-used-limits-for-admin'): if 'tenant_id' in req.GET: tenant_id = req.GET.get('tenant_id') target = { 'project_id': tenant_id, 'user_id': context.user_id } authorize_for_admin(context, target=target) return tenant_id return context.project_id class Used_limits(extensions.ExtensionDescriptor): """"""Provide data on limited resources that are being used."""""" name = ""UsedLimits"" alias = ALIAS namespace = XMLNS updated = ""2012-07-13T00:00:00+00:00"" def get_controller_extensions(self): controller = UsedLimitsController(self.ext_mgr) limits_ext = extensions.ControllerExtension(self, 'limits', controller=controller) return [limits_ext] ",,350,0
openstack%2Fmurano-dashboard~master~Ice2ca4eca53401bc80386f10349193e7a8013dae,openstack/murano-dashboard,master,Ice2ca4eca53401bc80386f10349193e7a8013dae,Add MS SQL form,MERGED,2013-07-17 16:01:06.000000000,2013-07-18 07:03:08.000000000,2013-07-18 07:03:08.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7549}]","[{'number': 1, 'created': '2013-07-17 16:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/cad263809831ce561113024667b5b8a09b1739b5', 'message': 'Add MS SQL form\n\nChange-Id: Ice2ca4eca53401bc80386f10349193e7a8013dae\n'}, {'number': 2, 'created': '2013-07-18 06:53:58.000000000', 'files': ['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/consts.py', 'muranodashboard/panel/forms.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/aaea34dea107e67229f8987fe67b566b5fcafd61', 'message': 'Add MS SQL form\n\nChange-Id: Ice2ca4eca53401bc80386f10349193e7a8013dae\n'}]",0,37515,aaea34dea107e67229f8987fe67b566b5fcafd61,10,3,2,7549,,,0,"Add MS SQL form

Change-Id: Ice2ca4eca53401bc80386f10349193e7a8013dae
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/15/37515/2 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/consts.py', 'muranodashboard/panel/forms.py']",4,cad263809831ce561113024667b5b8a09b1739b5,add_new_form," ms_sql_service = (MSSQL_NAME, 'MS SQL Server') asp_farm_service, ms_sql_service service_name = forms.CharField(class WizardFormMSSQLConfiguration(WizardFormIISConfiguration, CommonPropertiesExtension): mixed_mode = forms.BooleanField( label=_('Mixed-mode Authentication '), required=False) recovery_password = PasswordField( _('SA password'), help_text=_('SQL server System Administrator account')) recovery_password2 = PasswordField( _('Confirm password'), error_messages=CONFIRM_ERR_DICT, help_text=_('Retype your password')) instance_count = forms.IntegerField( label=_('Instance Count'), min_value=1, max_value=100, initial=1, help_text=_('Enter an integer value between 1 and 100')) def __init__(self, *args, **kwargs): super(WizardFormMSSQLConfiguration, self).__init__(*args, **kwargs) CommonPropertiesExtension.__init__(self) (MSSQL_NAME, WizardFormMSSQLConfiguration),", asp_farm_service iis_name = forms.CharField(,60,8
openstack%2Fnova~master~I5a03f509c91de080d3753bf351d891d06600e84b,openstack/nova,master,I5a03f509c91de080d3753bf351d891d06600e84b,Fix duplicate osapi_hide_server_address_states config option,MERGED,2013-07-17 01:51:37.000000000,2013-07-18 06:57:37.000000000,2013-07-18 06:57:34.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1849}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-17 01:51:37.000000000', 'files': ['nova/api/openstack/compute/contrib/hide_server_addresses.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/66334ca765d7b88c5752e22e343a745489fa4f49', 'message': 'Fix duplicate osapi_hide_server_address_states config option\n\nThis is causing an error in the config file tool generator.\nImport the config option from the v3 API copy of this code.\n\nChange-Id: I5a03f509c91de080d3753bf351d891d06600e84b\n'}]",0,37371,66334ca765d7b88c5752e22e343a745489fa4f49,10,7,1,1994,,,0,"Fix duplicate osapi_hide_server_address_states config option

This is causing an error in the config file tool generator.
Import the config option from the v3 API copy of this code.

Change-Id: I5a03f509c91de080d3753bf351d891d06600e84b
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/37371/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/contrib/hide_server_addresses.py'],1,66334ca765d7b88c5752e22e343a745489fa4f49,osapi_hide,"CONF.import_opt('osapi_hide_server_address_states', 'nova.api.openstack.compute.plugins.v3.hide_server_addresses')","opts = [ cfg.ListOpt('osapi_hide_server_address_states', default=[vm_states.BUILDING], help='List of instance states that should hide network info'), ] CONF.register_opts(opts)",2,7
openstack%2Ftempest~master~Ibc9c6d772a173b4316db388e4ae7340c413fe7b9,openstack/tempest,master,Ibc9c6d772a173b4316db388e4ae7340c413fe7b9,"Added Swift testcase, create/remove empty object",ABANDONED,2013-06-18 14:50:04.000000000,2013-07-18 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 6796}, {'_account_id': 6847}, {'_account_id': 7028}]","[{'number': 1, 'created': '2013-06-18 14:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/48430a2f8025963ae42067c3c3af60051c303483', 'message': 'Added Swift testcase, create/remove empty object\n\nChange-Id: Ibc9c6d772a173b4316db388e4ae7340c413fe7b9\n'}, {'number': 2, 'created': '2013-06-18 14:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b077c15b263521b6332e679193157258803af7f7', 'message': 'Added Swift testcase, create/remove empty object\n\nChange-Id: Ibc9c6d772a173b4316db388e4ae7340c413fe7b9\n'}, {'number': 3, 'created': '2013-06-18 14:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7a667adb065f2760aea982847baea434b416932e', 'message': 'Added Swift testcase, create/remove empty object\n\nChange-Id: Ibc9c6d772a173b4316db388e4ae7340c413fe7b9\n'}, {'number': 4, 'created': '2013-06-19 11:20:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1f6e0665fbc9ecc9af939f62dbd0f8f3c5c1caa6', 'message': 'Added Swift testcase, create/remove empty object\n\nChange-Id: Ibc9c6d772a173b4316db388e4ae7340c413fe7b9\n'}, {'number': 5, 'created': '2013-06-24 21:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3ee521f00c7c449d61068bc125f87b72f5b673c8', 'message': ""Added Swift testcase, create/remove empty object\n\nThe test case uploads an empty object, looks if it's in the container listing\nand deletes it.\n\nChange-Id: Ibc9c6d772a173b4316db388e4ae7340c413fe7b9\n""}, {'number': 6, 'created': '2013-07-04 12:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/61817ceb81e3c0e6a1f7fa1462f596fd4d26af8b', 'message': ""Added Swift testcase, create/remove empty object\n\nThe test case uploads an empty object, looks if it's in the container listing\nand deletes it.\n\nChange-Id: Ibc9c6d772a173b4316db388e4ae7340c413fe7b9\n""}, {'number': 7, 'created': '2013-07-04 16:02:29.000000000', 'files': ['tempest/api/object_storage/test_object_services.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b6738015e2c9005e28714d445822823aa26b207c', 'message': ""Added Swift testcase, create/remove empty object\n\nThe test case uploads an empty object, looks if it's in the container listing\nand deletes it.\n\nChange-Id: Ibc9c6d772a173b4316db388e4ae7340c413fe7b9\n""}]",8,33451,b6738015e2c9005e28714d445822823aa26b207c,31,8,7,6847,,,0,"Added Swift testcase, create/remove empty object

The test case uploads an empty object, looks if it's in the container listing
and deletes it.

Change-Id: Ibc9c6d772a173b4316db388e4ae7340c413fe7b9
",git fetch https://review.opendev.org/openstack/tempest refs/changes/51/33451/6 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/object_storage/test_object_services.py'],1,48430a2f8025963ae42067c3c3af60051c303483,fix_segmented," def test_create_and_delete_empty_object(self): object_name = rand_name(name='TestObject') data = '' resp, _ = self.object_client.create_object(self.container_name, object_name, data) objlist = self.container_client.list_all_container_objects( self.container_name) self.assertIn(object_name, [obj['name'] for obj in objlist]) self.assertEqual(resp['status'], '201') resp, _ = self.object_client.delete_object(self.container_name, object_name) self.assertEqual(resp['status'], '204') ",,14,0
openstack%2Fceilometer~master~Iae3ef6f628c589dcd684abc23ce385029d97c21e,openstack/ceilometer,master,Iae3ef6f628c589dcd684abc23ce385029d97c21e,Allow Keystoneclient 0.3.x,ABANDONED,2013-07-07 12:04:24.000000000,2013-07-18 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6537}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-07-07 12:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7344f45435da6dd1214e14aee4cb44550dc84ea1', 'message': 'Allow Keystoneclient 0.3.x\n\nAccept newer versions of Keystoneclient as well.\n\nChange-Id: Iae3ef6f628c589dcd684abc23ce385029d97c21e\n'}, {'number': 2, 'created': '2013-07-10 07:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4450fe086060a895d1e9b4f3a86faff4f833e704', 'message': 'Allow Keystoneclient 0.3.x\n\nAccept newer versions of Keystoneclient as well. Needs\nnewest version from ceilometerclient in order to not have\na version conflict.\n\nChange-Id: Iae3ef6f628c589dcd684abc23ce385029d97c21e\n'}, {'number': 3, 'created': '2013-07-10 12:40:13.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/81f72715362191176e34191a7f9235a4130494a5', 'message': 'Allow Keystoneclient 0.3.x\n\nAccept newer versions of Keystoneclient as well. Needs\nnewest version from ceilometerclient in order to not have\na version conflict.\n\nChange-Id: Iae3ef6f628c589dcd684abc23ce385029d97c21e\n'}]",0,35992,81f72715362191176e34191a7f9235a4130494a5,15,4,3,6593,,,0,"Allow Keystoneclient 0.3.x

Accept newer versions of Keystoneclient as well. Needs
newest version from ceilometerclient in order to not have
a version conflict.

Change-Id: Iae3ef6f628c589dcd684abc23ce385029d97c21e
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/92/35992/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,7344f45435da6dd1214e14aee4cb44550dc84ea1,keystoneclient_3,"python-keystoneclient>=0.2.1,<0.4","python-keystoneclient>=0.2,<0.3",1,1
openstack%2Fpbr~master~I7203a3e511328281d63c99f5734a83f04c474aa0,openstack/pbr,master,I7203a3e511328281d63c99f5734a83f04c474aa0,Move sphinx autoindex to oslo.sphinx.,ABANDONED,2013-07-05 19:16:17.000000000,2013-07-18 06:03:04.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-05 19:16:17.000000000', 'files': ['pbr/packaging.py', 'doc/source/index.rst', 'test-requirements.txt', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/c1464e97fa4f001ad2c61b6bc210c5d6e3a32024', 'message': 'Move sphinx autoindex to oslo.sphinx.\n\nChange-Id: I7203a3e511328281d63c99f5734a83f04c474aa0\n'}]",0,35865,c1464e97fa4f001ad2c61b6bc210c5d6e3a32024,4,1,1,2,,,0,"Move sphinx autoindex to oslo.sphinx.

Change-Id: I7203a3e511328281d63c99f5734a83f04c474aa0
",git fetch https://review.opendev.org/openstack/pbr refs/changes/65/35865/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'pbr/packaging.py', 'test-requirements.txt', 'doc/source/conf.py']",4,c1464e97fa4f001ad2c61b6bc210c5d6e3a32024,jd/override-via-env,"extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'oslo.sphinx', 'oslo.sphinx.autoindex']","extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx']",14,60
openstack%2Fhorizon~master~I49dd14388447c22f8761e0fd03cd8a3812801f80,openstack/horizon,master,I49dd14388447c22f8761e0fd03cd8a3812801f80,Add an initial focus in login screen form,ABANDONED,2013-07-04 09:49:53.000000000,2013-07-18 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1816}, {'_account_id': 1941}, {'_account_id': 6966}, {'_account_id': 7553}, {'_account_id': 7699}, {'_account_id': 7976}]","[{'number': 1, 'created': '2013-07-04 09:49:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/71b8d759011bbae6907c0476a229c5e06e8c00df', 'message': 'Add an initial focus in login screen form\n\nFixes bug #1185713\n\nChange-Id: I49dd14388447c22f8761e0fd03cd8a3812801f80\n'}, {'number': 2, 'created': '2013-07-09 11:55:26.000000000', 'files': ['horizon/templates/splash.html', 'horizon/static/horizon/js/horizon.forms.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/27207268d4f3d1f6ca9442d7d372169c0700ccb8', 'message': 'Add an initial focus in login screen form\n\nThe patch will select the first visible input, textarea, select or\nbutton and put a focus on it in every form of horizon.\n\nFixes bug #1185713\n\nChange-Id: I49dd14388447c22f8761e0fd03cd8a3812801f80\n'}]",0,35622,27207268d4f3d1f6ca9442d7d372169c0700ccb8,23,8,2,7976,,,0,"Add an initial focus in login screen form

The patch will select the first visible input, textarea, select or
button and put a focus on it in every form of horizon.

Fixes bug #1185713

Change-Id: I49dd14388447c22f8761e0fd03cd8a3812801f80
",git fetch https://review.opendev.org/openstack/horizon refs/changes/22/35622/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/auth/_login.html'],1,71b8d759011bbae6907c0476a229c5e06e8c00df,bug/1185713," <script type=""text/javascript""> document.getElementById('id_username').focus() </script>",,3,0
openstack%2Fkeystone~master~I273006afb00a9147e8dbb6712a6b50b0ad7dfc88,openstack/keystone,master,I273006afb00a9147e8dbb6712a6b50b0ad7dfc88,Rework dependency injection.,ABANDONED,2013-07-03 07:56:57.000000000,2013-07-18 06:03:03.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-07-03 07:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fb8c14d4afeff61e2e69eb81ebb17e4ed86f1dde', 'message': 'Rework dependency injection.\n\nThis will allow use of dependant apis from class functions as well as\nputting them on the instance.\n\nChange-Id: I273006afb00a9147e8dbb6712a6b50b0ad7dfc88\n'}, {'number': 2, 'created': '2013-07-09 05:11:49.000000000', 'files': ['tests/test_injection.py', 'keystone/common/dependency.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/787257f19609c92c3a2ddf68ce01080d9ee2a0cb', 'message': 'Rework dependency injection.\n\nThis will allow use of dependant apis from class functions as well as\nputting them on the instance. This changes the contract of dependencies\nsuch that they are checked for when they are first accessed rather than\nwhen the object is initialized.\n\nChange-Id: I273006afb00a9147e8dbb6712a6b50b0ad7dfc88\n'}]",3,35461,787257f19609c92c3a2ddf68ce01080d9ee2a0cb,11,5,2,7191,,,0,"Rework dependency injection.

This will allow use of dependant apis from class functions as well as
putting them on the instance. This changes the contract of dependencies
such that they are checked for when they are first accessed rather than
when the object is initialized.

Change-Id: I273006afb00a9147e8dbb6712a6b50b0ad7dfc88
",git fetch https://review.opendev.org/openstack/keystone refs/changes/61/35461/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_injection.py', 'keystone/common/dependency.py']",2,fb8c14d4afeff61e2e69eb81ebb17e4ed86f1dde,dependencies," """"""Inject specified dependencies from the registry into the instance. For a dependency 'dep_api' creates a class level function: - cls.get_dep_api() and a instance level property - self.dep_api On class init it will also guarantee that all dependencies are met """""" def class_prop(name): @classmethod def func(cls): try: return REGISTRY[name] except KeyError: raise UnresolvableDependencyException(name) return func def inst_prop(name): @property def func(self): return getattr(self, name)() return func def wrap_init(init): # this is not really needed except for consistency with the old way def __wrapped_init__(self, *args, **kwargs): for dep in dependencies: getattr(self, dep) init(self, *args, **kwargs) return __wrapped_init__ for dep in dependencies: name = 'get_%s' % dep setattr(cls, name, class_prop(dep)) setattr(cls, dep, inst_prop(name)) cls.__init__ = wrap_init(cls.__init__)"," """"""Inject specified dependencies from the registry into the instance."""""" def wrapper(self, *args, **kwargs): """"""Inject each dependency from the registry."""""" self.__wrapped_init__(*args, **kwargs) for dependency in self._dependencies: if dependency not in REGISTRY: raise UnresolvableDependencyException(dependency) setattr(self, dependency, REGISTRY[dependency]) """"""Note the required dependencies on the object for later injection. The dependencies of the parent class are combined with that of the child class to create a new set of dependencies. """""" existing_dependencies = getattr(cls, '_dependencies', set()) cls._dependencies = existing_dependencies.union(dependencies) if not hasattr(cls, '__wrapped_init__'): cls.__wrapped_init__ = cls.__init__ cls.__init__ = wrapper",39,28
openstack%2Ftrove~master~I7a711375bf22475100604471b43960ee9540cc3f,openstack/trove,master,I7a711375bf22475100604471b43960ee9540cc3f,Allow for null values in specific API param values,ABANDONED,2013-07-17 17:00:55.000000000,2013-07-18 05:24:38.000000000,,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 6156}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-07-17 17:00:55.000000000', 'files': ['trove/tests/unittests/backup/test_backup_controller.py', 'trove/common/apischema.py', 'trove/tests/unittests/instance/test_instance_controller.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/d0dbe62bf355fd65da7dbfd2ced847fcac86955e', 'message': 'Allow for null values in specific API param values\n\n    Allow for null in instance.users.host\n    Allow for null in backup.description\n\nFixes: bug 1201990\n\nChange-Id: I7a711375bf22475100604471b43960ee9540cc3f\n'}]",2,37532,d0dbe62bf355fd65da7dbfd2ced847fcac86955e,5,4,1,6156,,,0,"Allow for null values in specific API param values

    Allow for null in instance.users.host
    Allow for null in backup.description

Fixes: bug 1201990

Change-Id: I7a711375bf22475100604471b43960ee9540cc3f
",git fetch https://review.opendev.org/openstack/trove refs/changes/32/37532/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/tests/unittests/backup/test_backup_controller.py', 'trove/common/apischema.py', 'trove/tests/unittests/instance/test_instance_controller.py']",3,d0dbe62bf355fd65da7dbfd2ced847fcac86955e,bug/1201990," def test_validate_create_complete_with_host(self): body = self.instance body['instance']['users'][0]['host'] = 'www.test.com' schema = self.controller.get_schema('create', body) validator = jsonschema.Draft4Validator(schema) self.assertTrue(validator.is_valid(body)) def test_validate_create_complete_with_null_host(self): body = self.instance body['instance']['users'][0]['host'] = None schema = self.controller.get_schema('create', body) validator = jsonschema.Draft4Validator(schema) self.assertTrue(validator.is_valid(body)) def test_validate_create_complete_with_invalid_host(self): body = self.instance body['instance']['users'][0]['host'] = 1 schema = self.controller.get_schema('create', body) validator = jsonschema.Draft4Validator(schema) self.assertFalse(validator.is_valid(body)) errors = sorted(validator.iter_errors(body), key=lambda e: e.path) self.assertThat(errors[0].path.pop(), Equals('host')) self.assertThat(len(errors[0].context), Equals(2)) self.assertThat(errors[0].context[1].message, Equals(""1 is not of type 'null'"")) self.assertThat(errors[0].context[0].message, Equals(""1 is not of type 'string'"")) ",,74,2
openstack%2Fopenstack-manuals~master~I4fbe158e06238fc8e3b42bb14e76d1813d5124aa,openstack/openstack-manuals,master,I4fbe158e06238fc8e3b42bb14e76d1813d5124aa,Replace all references from quantum to neutron,MERGED,2013-07-09 18:55:37.000000000,2013-07-18 05:24:07.000000000,2013-07-18 05:24:07.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 612}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 964}, {'_account_id': 2031}, {'_account_id': 2448}, {'_account_id': 6414}]","[{'number': 1, 'created': '2013-07-09 18:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/034b9c8715be5762f0ad5d21942794e255d47a58', 'message': 'Replace all references from quantum to neutron\nVerify paths for all config files\n\nFix bug 1198464\n\nChange-Id: I4fbe158e06238fc8e3b42bb14e76d1813d5124aa\n'}, {'number': 2, 'created': '2013-07-10 16:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/681cd4e5dc46a2c8e979fcbeb47ec1d61c5d8bd5', 'message': 'Replace all references from quantum to neutron\nVerify paths for all config files\nInclude www/sitemap.xml\n\nFix bug 1198464\n\nChange-Id: I4fbe158e06238fc8e3b42bb14e76d1813d5124aa\n'}, {'number': 3, 'created': '2013-07-12 19:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d45ed3af58aabe9af28515e737212e2f0f2720a0', 'message': 'Replace all references from quantum to neutron\nVerify paths for all config files\nInclude www/sitemap.xml\nInclude Install Guide\n\nFix bug 1198464\n\nChange-Id: I4fbe158e06238fc8e3b42bb14e76d1813d5124aa\n'}, {'number': 4, 'created': '2013-07-16 00:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c903277cf6910b6f5499bdf041498a003144b379', 'message': 'Replace all references from quantum to neutron\n\nVerify paths for all config files\nInclude www/sitemap.xml\nInclude Install Guide\n\nFix bug 1198464\n\nChange-Id: I4fbe158e06238fc8e3b42bb14e76d1813d5124aa\n'}, {'number': 5, 'created': '2013-07-17 06:32:27.000000000', 'files': ['doc/src/docbkx/openstack-network-connectivity-admin/app_demo_flat.xml', 'doc/src/docbkx/openstack-install/locale/openstack-install.pot', 'doc/src/docbkx/openstack-network-connectivity-admin/app_demo_routers_with_private_networks.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_limitations.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_core.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/pom.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_config.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_overview.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_features.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_install.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_config.xml', 'doc/src/docbkx/openstack-install/ap_installingfolsom.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_demo_single_router.xml', 'doc/src/docbkx/openstack-install/compute-scripted-ubuntu-install.xml', 'doc/src/docbkx/openstack-install/samples/ubuntu_dependencies.txt', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_using.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_operational_features.xml', 'www/sitemap.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_demo_multi_dhcp_agents.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/bk-networking-admin-guide.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_high_avail.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_under_the_hood.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/800517b8c4ea93c0236fe89370a5677d456ab6af', 'message': 'Replace all references from quantum to neutron\n\nVerify paths for all config files\nInclude www/sitemap.xml\nInclude Install Guide\n\nFix bug 1198464\n\nChange-Id: I4fbe158e06238fc8e3b42bb14e76d1813d5124aa\n'}]",9,36322,800517b8c4ea93c0236fe89370a5677d456ab6af,28,9,5,704,,,0,"Replace all references from quantum to neutron

Verify paths for all config files
Include www/sitemap.xml
Include Install Guide

Fix bug 1198464

Change-Id: I4fbe158e06238fc8e3b42bb14e76d1813d5124aa
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/22/36322/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-network-connectivity-admin/app_demo_flat.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_demo_routers_with_private_networks.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_limitations.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_core.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/pom.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_config.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_overview.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_features.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_install.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_config.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_preface.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_demo_single_router.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_using.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_adv_operational_features.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/app_demo_multi_dhcp_agents.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/bk-networking-admin-guide.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_high_avail.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/ch_under_the_hood.xml']",18,034b9c8715be5762f0ad5d21942794e255d47a58,bug/1198464," <para>This example uses VLAN isolation on the switches to isolate tenant networks. This configuration labels the physical network associated with the public network as <literal>physnet1</literal>, and the physical network associated with the data network as <literal>physnet2</literal>, which leads to the following configuration options in <filename>ovs_neutron_plugin.ini</filename>:<programlisting>[ovs]<prompt>$</prompt> <userinput>neutron router-create router01</userinput> <prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant public01 \<prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name public01_subnet01 \<prompt>$</prompt> <userinput>neutron router-gateway-set router01 public01</userinput></screen></para><prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant net01 \<prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name net01_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>neutron router-interface-add router01 net01_subnet01</userinput></screen></para> switch:<screen><prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant net02 \ <prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name net02_subnet01 net02 192.168.102.0/24</userinput> <prompt>$</prompt> <userinput>neutron router-interface-add router01 net02_subnet01</userinput></screen></para> <para>Recall that the network host runs the neutron-openvswitch-plugin-agent, the neutron-dhcp-agent, neutron-l3-agent, and neutron-metadata-agent services.</para> <filename>ovs_neutron_plugin.ini</filename>:<programlisting>[ovs] The following figure shows the network devices on the network host:</para> the neutron-openvswitch-plugin-agent configures the ports on both switches to do<prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant public01 \<prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name public01_subnet01 \<prompt>$</prompt> <userinput>neutron router-create --tenant-id $tenant router01</userinput> <prompt>$</prompt> <userinput>neutron router-gateway-set router01 public01</userinput></screen> <screen><prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant net01 \<prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name net01_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>neutron router-interface-add router01 net01_subnet01</userinput></screen></para><prompt>$</prompt> <userinput>neutron router-create --tenant-id $tenant router02</userinput> <prompt>$</prompt> <userinput>neutron router-gateway-set router02 public01</userinput> <prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant net02 \<prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name net02_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>neutron router-interface-add router02 net02_subnet01</userinput></screen></para><prompt>$</prompt> <userinput>neutron router-create router01</userinput> <prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant public01 \<prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name public01_subnet01 \<prompt>$</prompt> <userinput>neutron router-gateway-set router01 public01</userinput></screen></para> <literal>net01</literal> and corresponding subnet, and connect it to the <literal>router01</literal> router. Configure it to use VLAN ID 101 on the<prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant net01 \<prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name net01_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>neutron router-interface-add router01 net01_subnet01</userinput></screen></para> switch:<screen><prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant net02 \ <prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name net02_subnet01 net02 192.168.102.0/24</userinput> <prompt>$</prompt> <userinput>neutron router-interface-add router01 net02_subnet01</userinput></screen></para><prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant public01 \<prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name public01_subnet01 \<prompt>$</prompt> <userinput>neutron router-create --tenant-id $tenant router01</userinput> <prompt>$</prompt> <userinput>neutron router-gateway-set router01 public01</userinput></screen> <screen><prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant net01 \<prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name net01_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>neutron router-interface-add router01 net01_subnet01</userinput></screen></para><prompt>$</prompt> <userinput>neutron router-create --tenant-id $tenant router02</userinput> <prompt>$</prompt> <userinput>neutron router-gateway-set router02 public01</userinput> <prompt>$</prompt> <userinput>neutron net-create --tenant-id $tenant net02 \<prompt>$</prompt> <userinput>neutron subnet-create --tenant-id $tenant --name net02_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>neutron router-interface-add router02 net02_subnet01</userinput></screen></para>"," <para>This example uses VLAN isolation on the switches to isolate tenant networks. This configuration labels the physical network associated with the public network as <literal>physnet1</literal>, and the physical network associated with the data network as <literal>physnet2</literal>, which leads to the following configuration options in <filename>ovs_quantum_plugin.ini</filename>:<programlisting>[ovs]<prompt>$</prompt> <userinput>quantum router-create router01</userinput> <prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant public01 \<prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name public01_subnet01 \<prompt>$</prompt> <userinput>quantum router-gateway-set router01 public01</userinput></screen></para><prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant net01 \<prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name net01_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>quantum router-interface-add router01 net01_subnet01</userinput></screen></para> switch:<screen><prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant net02 \ <prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name net02_subnet01 net02 192.168.102.0/24</userinput> <prompt>$</prompt> <userinput>quantum router-interface-add router01 net02_subnet01</userinput></screen></para> <para>Recall that the network host runs the quantum-openvswitch-plugin-agent, the quantum-dhcp-agent, quantum-l3-agent, and quantum-metadata-agent services.</para> <filename>ovs_quantum_plugin.ini</filename>:<programlisting>[ovs] The following figure shows the network devices on the network host:</para> the quantum-openvswitch-plugin-agent configures the ports on both switches to do<prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant public01 \<prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name public01_subnet01 \<prompt>$</prompt> <userinput>quantum router-create --tenant-id $tenant router01</userinput> <prompt>$</prompt> <userinput>quantum router-gateway-set router01 public01</userinput></screen> <screen><prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant net01 \<prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name net01_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>quantum router-interface-add router01 net01_subnet01</userinput></screen></para><prompt>$</prompt> <userinput>quantum router-create --tenant-id $tenant router02</userinput> <prompt>$</prompt> <userinput>quantum router-gateway-set router02 public01</userinput> <prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant net02 \<prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name net02_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>quantum router-interface-add router02 net02_subnet01</userinput></screen></para><prompt>$</prompt> <userinput>quantum router-create router01</userinput> <prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant public01 \<prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name public01_subnet01 \<prompt>$</prompt> <userinput>quantum router-gateway-set router01 public01</userinput></screen></para> <literal>net01</literal> and corresponding subnet, and connect it to the <literal>router01</literal> router. Configure it to use VLAN ID 101 on the<prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant net01 \<prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name net01_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>quantum router-interface-add router01 net01_subnet01</userinput></screen></para> switch:<screen><prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant net02 \ <prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name net02_subnet01 net02 192.168.102.0/24</userinput> <prompt>$</prompt> <userinput>quantum router-interface-add router01 net02_subnet01</userinput></screen></para><prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant public01 \<prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name public01_subnet01 \<prompt>$</prompt> <userinput>quantum router-create --tenant-id $tenant router01</userinput> <prompt>$</prompt> <userinput>quantum router-gateway-set router01 public01</userinput></screen> <screen><prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant net01 \<prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name net01_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>quantum router-interface-add router01 net01_subnet01</userinput></screen></para><prompt>$</prompt> <userinput>quantum router-create --tenant-id $tenant router02</userinput> <prompt>$</prompt> <userinput>quantum router-gateway-set router02 public01</userinput> <prompt>$</prompt> <userinput>quantum net-create --tenant-id $tenant net02 \<prompt>$</prompt> <userinput>quantum subnet-create --tenant-id $tenant --name net02_subnet01 net01 192.168.101.0/24</userinput> <prompt>$</prompt> <userinput>quantum router-interface-add router02 net02_subnet01</userinput></screen></para>",901,1094
openstack%2Fcinder~master~I637f406c2592b158a7941da3657a0517972b0996,openstack/cinder,master,I637f406c2592b158a7941da3657a0517972b0996,Implement validate_connector for Storwize/SVC.,MERGED,2013-07-17 03:48:49.000000000,2013-07-18 04:57:21.000000000,2013-07-18 04:57:21.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6604}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-17 03:48:49.000000000', 'files': ['cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/storwize_svc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/aca3a197d96db8b2a4efc94c3eeb3c5976d6703d', 'message': 'Implement validate_connector for Storwize/SVC.\n\nImplement the new validate_connector API for the Storwize/SVC driver.\n\nChange-Id: I637f406c2592b158a7941da3657a0517972b0996\n'}]",0,37385,aca3a197d96db8b2a4efc94c3eeb3c5976d6703d,11,7,1,4355,,,0,"Implement validate_connector for Storwize/SVC.

Implement the new validate_connector API for the Storwize/SVC driver.

Change-Id: I637f406c2592b158a7941da3657a0517972b0996
",git fetch https://review.opendev.org/openstack/cinder refs/changes/85/37385/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/storwize_svc.py']",2,aca3a197d96db8b2a4efc94c3eeb3c5976d6703d,svc-validate_connector," def validate_connector(self, connector): """"""Check connector for at least one enabled protocol (iSCSI/FC)."""""" valid = False if 'iSCSI' in self._enabled_protocols and 'initiator' in connector: valid = True if 'FC' in self._enabled_protocols and 'wwpns' in connector: valid = True if not valid: err_msg = (_('The connector does not contain the required ' 'information.')) LOG.error(err_msg) raise exception.VolumeBackendAPIException(data=err_msg) ",,42,0
openstack%2Fpython-neutronclient~master~I6ef6f9a9e257104f676dde7ec26be98417ec70e0,openstack/python-neutronclient,master,I6ef6f9a9e257104f676dde7ec26be98417ec70e0,raise better exception for duplicate match,MERGED,2013-07-11 17:59:58.000000000,2013-07-18 04:56:26.000000000,2013-07-18 04:56:26.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4395}]","[{'number': 1, 'created': '2013-07-11 17:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/748535928670a705f0dfb3cd5b3c02a4c01a27c4', 'message': 'raise better exception for duplicate match\n\nWhen a duplicate match is found the client previously raised a\nNeutronClientException which made it hard for programs using the client\nto handle errors. This patch now  makes it raise a\nNeutronClientNoUniqueMatch  exception instead.\n\nFixes bug: 1200323\n\nChange-Id: I6ef6f9a9e257104f676dde7ec26be98417ec70e0\n'}, {'number': 2, 'created': '2013-07-16 20:46:06.000000000', 'files': ['tests/unit/test_name_or_id.py', 'neutronclient/neutron/v2_0/__init__.py', 'neutronclient/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/04178517bcccf41e78ec2623b8db954921c84f48', 'message': 'raise better exception for duplicate match\n\nWhen a duplicate match is found the client previously raised a\nNeutronClientException which made it hard for programs using the client\nto handle errors. This patch now  makes it raise a\nNeutronClientNoUniqueMatch  exception instead.\n\nFixes bug: 1200323\n\nChange-Id: I6ef6f9a9e257104f676dde7ec26be98417ec70e0\n'}]",2,36703,04178517bcccf41e78ec2623b8db954921c84f48,13,8,2,4395,,,0,"raise better exception for duplicate match

When a duplicate match is found the client previously raised a
NeutronClientException which made it hard for programs using the client
to handle errors. This patch now  makes it raise a
NeutronClientNoUniqueMatch  exception instead.

Fixes bug: 1200323

Change-Id: I6ef6f9a9e257104f676dde7ec26be98417ec70e0
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/03/36703/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/__init__.py', 'neutronclient/common/exceptions.py']",2,748535928670a705f0dfb3cd5b3c02a4c01a27c4,bug/1200323, class NeutronClientNoUniqueMatch(NeutronClientException): pass,,5,1
openstack%2Fneutron~master~Ib83e58008fc53b57c4063057ce4c5707b55f0ff2,openstack/neutron,master,Ib83e58008fc53b57c4063057ce4c5707b55f0ff2,rename quantum into neutron,MERGED,2013-07-12 04:34:43.000000000,2013-07-18 04:08:24.000000000,2013-07-18 04:08:23.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-07-12 04:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a3fb2f1c22a90f6438c8077e5258fa668d51c37a', 'message': 'rename quantum into neutron\n\nBug #1200474\n\nChange-Id: Ib83e58008fc53b57c4063057ce4c5707b55f0ff2\n'}, {'number': 2, 'created': '2013-07-13 01:45:08.000000000', 'files': ['etc/neutron/plugins/nec/nec.ini', 'etc/neutron/plugins/hyperv/hyperv_neutron_plugin.ini', 'etc/neutron/plugins/brocade/brocade.ini', 'etc/neutron/plugins/ml2/ml2_conf.ini', 'etc/neutron.conf', 'etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini', 'etc/neutron/plugins/plumgrid/plumgrid.ini', 'etc/neutron/plugins/linuxbridge/linuxbridge_conf.ini', 'etc/rootwrap.conf', 'etc/neutron/plugins/metaplugin/metaplugin.ini', 'etc/neutron/plugins/bigswitch/restproxy.ini', 'etc/neutron/plugins/nicira/nvp.ini', 'etc/neutron/plugins/ryu/ryu.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4a01e35f3f190fe0cef13b2cf81e561e7285dd49', 'message': 'rename quantum into neutron\n\nBug #1200474\n\nChange-Id: Ib83e58008fc53b57c4063057ce4c5707b55f0ff2\n'}]",4,36779,4a01e35f3f190fe0cef13b2cf81e561e7285dd49,16,8,2,2874,,,0,"rename quantum into neutron

Bug #1200474

Change-Id: Ib83e58008fc53b57c4063057ce4c5707b55f0ff2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/36779/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron/plugins/nec/nec.ini', 'etc/neutron/plugins/hyperv/hyperv_neutron_plugin.ini', 'etc/neutron/plugins/brocade/brocade.ini', 'etc/neutron/plugins/ml2/ml2_conf.ini', 'etc/neutron.conf', 'etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini', 'etc/neutron/plugins/plumgrid/plumgrid.ini', 'etc/neutron/plugins/linuxbridge/linuxbridge_conf.ini', 'etc/rootwrap.conf', 'etc/neutron/plugins/metaplugin/metaplugin.ini', 'etc/neutron/plugins/bigswitch/restproxy.ini', 'etc/neutron/plugins/nicira/nvp.ini', 'etc/neutron/plugins/ryu/ryu.ini']",13,a3fb2f1c22a90f6438c8077e5258fa668d51c37a,bug/1200474,# Firewall driver for realizing neutron security group function # firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver,# Firewall driver for realizing quantum security group function # firewall_driver = quantum.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver,49,49
openstack%2Fcinder~master~I69d5cefd888044b5544e41b34ab4f8974efb0a14,openstack/cinder,master,I69d5cefd888044b5544e41b34ab4f8974efb0a14,Fixes default value of use_default_quota_class,MERGED,2013-07-17 05:20:57.000000000,2013-07-18 03:53:28.000000000,2013-07-18 03:53:28.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1773}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 5997}]","[{'number': 1, 'created': '2013-07-17 05:20:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2519f1215685abd7a69de1f75db8fa9cecc6a790', 'message': ""Fixes default value of use_default_quota_class\n\nChanged 'True' to True\n\nChange-Id: I69d5cefd888044b5544e41b34ab4f8974efb0a14\n""}, {'number': 2, 'created': '2013-07-18 00:23:01.000000000', 'files': ['cinder/quota.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b23cad10780dcdaaac50497726f7de07831084a2', 'message': ""Fixes default value of use_default_quota_class\n\nChanged 'True' to True\n\nChange-Id: I69d5cefd888044b5544e41b34ab4f8974efb0a14\n""}]",1,37395,b23cad10780dcdaaac50497726f7de07831084a2,13,8,2,1994,,,0,"Fixes default value of use_default_quota_class

Changed 'True' to True

Change-Id: I69d5cefd888044b5544e41b34ab4f8974efb0a14
",git fetch https://review.opendev.org/openstack/cinder refs/changes/95/37395/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/cinder.conf.sample', 'cinder/quota.py']",2,2519f1215685abd7a69de1f75db8fa9cecc6a790,use_default_quota_class," default=True,"," default='True',",2,2
openstack%2Fheat~master~If31974d7ef7fdbf85a88e950ff06c60ccbd6c31d,openstack/heat,master,If31974d7ef7fdbf85a88e950ff06c60ccbd6c31d,Update oslo.notifier and always register options,MERGED,2013-07-10 15:46:25.000000000,2013-07-18 03:20:03.000000000,2013-07-18 01:06:15.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-07-10 15:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e934bf2bdb73d988470a70056d3bab39254a3ee', 'message': ""Always register options\n\nThis avoids registering multiple times the option if the registering\nfunctions are called multiple path by different code paths. It's necessary\nfor the default configuration sample generator to have options only\nregistered once.\n\nChange-Id: If31974d7ef7fdbf85a88e950ff06c60ccbd6c31d\nSigned-off-by: Julien Danjou <julien@danjou.info>\n""}, {'number': 2, 'created': '2013-07-11 13:50:04.000000000', 'files': ['heat/db/api.py', 'heat/common/wsgi.py', 'heat/tests/test_waitcondition.py', 'heat/engine/resources/__init__.py', 'heat/tests/test_user.py', 'heat/api/__init__.py', 'heat/openstack/common/notifier/api.py', 'heat/openstack/common/notifier/rpc_notifier2.py', 'heat/tests/test_loadbalancer.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_rpc_client.py', 'heat/openstack/common/notifier/rpc_notifier.py', 'heat/tests/test_heatclient.py', 'bin/heat-engine', 'heat/common/config.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f2ef092d8ca73ee4cae8745f5985d5c0f108dac8', 'message': ""Update oslo.notifier and always register options\n\nThis avoids registering multiple times the option if the registering\nfunctions are called multiple path by different code paths. It's\nnecessary for the default configuration sample generator to have options\nonly registered once.\n\nThe update of oslo.notifier is needed to avoid it using the inexistant\n$host option.\n\nChange-Id: If31974d7ef7fdbf85a88e950ff06c60ccbd6c31d\nSigned-off-by: Julien Danjou <julien@danjou.info>\n""}]",5,36493,f2ef092d8ca73ee4cae8745f5985d5c0f108dac8,18,6,2,1669,,,0,"Update oslo.notifier and always register options

This avoids registering multiple times the option if the registering
functions are called multiple path by different code paths. It's
necessary for the default configuration sample generator to have options
only registered once.

The update of oslo.notifier is needed to avoid it using the inexistant
$host option.

Change-Id: If31974d7ef7fdbf85a88e950ff06c60ccbd6c31d
Signed-off-by: Julien Danjou <julien@danjou.info>
",git fetch https://review.opendev.org/openstack/heat refs/changes/93/36493/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/db/api.py', 'heat/common/wsgi.py', 'heat/tests/test_waitcondition.py', 'heat/engine/resources/__init__.py', 'heat/tests/test_user.py', 'heat/api/__init__.py', 'heat/openstack/common/notifier/api.py', 'heat/tests/test_loadbalancer.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_rpc_client.py', 'heat/tests/test_heatclient.py', 'bin/heat-engine', 'heat/common/config.py']",13,3e934bf2bdb73d988470a70056d3bab39254a3ee,jd/clean-config-for-generator,"cfg.CONF.register_opts(db_opts) cfg.CONF.register_opts(engine_opts) cfg.CONF.register_opts(service_opts) cfg.CONF.register_opts(rpc_opts) cfg.CONF.register_group(paste_deploy_group) cfg.CONF.register_opts(paste_deploy_opts, group=paste_deploy_group) def rpc_set_default():","bind_opts = [ cfg.IntOpt('bind_port', default=8000), cfg.StrOpt('bind_host', default='127.0.0.1')] def register_api_opts(): cfg.CONF.register_opts(bind_opts) cfg.CONF.register_opts(rpc_opts)def register_db_opts(): cfg.CONF.register_opts(db_opts) def register_engine_opts(): cfg.CONF.register_opts(engine_opts) cfg.CONF.register_opts(service_opts) cfg.CONF.register_opts(rpc_opts) rpc.set_defaults(control_exchange='heat') def _register_paste_deploy_opts(): """""" Idempotent registration of paste_deploy option group """""" cfg.CONF.register_group(paste_deploy_group) cfg.CONF.register_opts(paste_deploy_opts, group=paste_deploy_group) _register_paste_deploy_opts() _register_paste_deploy_opts()",25,55
openstack%2Fdevstack-gate~master~I7882e18c76f9939edbf89f6bd59c856a17aedba6,openstack/devstack-gate,master,I7882e18c76f9939edbf89f6bd59c856a17aedba6,Add oslo projects to the cache list,MERGED,2013-07-16 17:32:32.000000000,2013-07-18 01:51:19.000000000,2013-07-18 01:51:18.000000000,"[{'_account_id': 1}, {'_account_id': 3}]","[{'number': 1, 'created': '2013-07-16 17:32:32.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/7b5ce2c45ebb3f5580055d7bbcba92a701b68568', 'message': 'Add oslo projects to the cache list\n\nChange-Id: I7882e18c76f9939edbf89f6bd59c856a17aedba6\n'}]",0,37294,7b5ce2c45ebb3f5580055d7bbcba92a701b68568,5,2,1,2,,,0,"Add oslo projects to the cache list

Change-Id: I7882e18c76f9939edbf89f6bd59c856a17aedba6
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/94/37294/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,7b5ce2c45ebb3f5580055d7bbcba92a701b68568,,"PROJECTS=""openstack/oslo.config $PROJECTS"" PROJECTS=""openstack/oslo.messaging $PROJECTS""",,2,0
openstack%2Fdevstack-gate~master~I60e3ca48e8f4196503b09711997bd70e641bd16c,openstack/devstack-gate,master,I60e3ca48e8f4196503b09711997bd70e641bd16c,Add testr run and use subunit2html with testr,MERGED,2013-07-12 20:48:42.000000000,2013-07-18 01:36:58.000000000,2013-07-18 01:36:58.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-12 20:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/a0c51b26291329341e8bec8c738a042be069b5aa', 'message': 'Add testr run and use subunit2html with testr\n\nThis commits adds a new run option DEVSTACK_GATE_TEMPEST_TESTR_FULL\nwhich is used to run the same tests as DEVSTACK_GATE_TEMPEST_FULL\nbut using testr --parallel instead of nose. This is going to eventually\nbe removed when using testr with tempest gets stable enough to gate\nprojects. But for now it will be a separate option. This also adds\nsupport for running subunit2html on all testr runs to get pretty html\noutput from the testr runs. (smoke, coverage, testr-full)\n\nChange-Id: I60e3ca48e8f4196503b09711997bd70e641bd16c\n'}, {'number': 2, 'created': '2013-07-12 21:14:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/e724f03d92d03b5e537be4aa7771cbd942a220ee', 'message': 'Add testr run and use subunit2html with testr\n\nThis commits adds a new run option DEVSTACK_GATE_TEMPEST_TESTR_FULL\nwhich is used to run the same tests as DEVSTACK_GATE_TEMPEST_FULL\nbut using testr --parallel instead of nose. This is going to eventually\nbe removed when using testr with tempest gets stable enough to gate\nprojects. But for now it will be a separate option. This also adds\nsupport for running subunit2html on all testr runs to get pretty html\noutput from the testr runs. (smoke, coverage, testr-full)\n\nChange-Id: I60e3ca48e8f4196503b09711997bd70e641bd16c\n'}, {'number': 3, 'created': '2013-07-17 23:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ea8152dc1ccce1e66cb629cdcca370238b45cad4', 'message': 'Add testr run and use subunit2html with testr\n\nThis commits adds a new run option DEVSTACK_GATE_TEMPEST_TESTR_FULL\nwhich is used to run the same tests as DEVSTACK_GATE_TEMPEST_FULL\nbut using testr --parallel instead of nose. This is going to eventually\nbe removed when using testr with tempest gets stable enough to gate\nprojects. But for now it will be a separate option. This also adds\nsupport for running subunit2html on all testr runs to get pretty html\noutput from the testr runs.\n\nChange-Id: I60e3ca48e8f4196503b09711997bd70e641bd16c\n'}, {'number': 4, 'created': '2013-07-17 23:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8b95a1a558e81d3aa745ec86d1a222bb3ddf8d18', 'message': 'Add testr run and use subunit2html with testr\n\nThis commits adds a new run option DEVSTACK_GATE_TEMPEST_TESTR_FULL\nwhich is used to run the same tests as DEVSTACK_GATE_TEMPEST_FULL\nbut using testr --parallel instead of nose. This is going to eventually\nbe removed when using testr with tempest gets stable enough to gate\nprojects. But for now it will be a separate option. This also adds\nsupport for running subunit2html on all testr runs to get pretty html\noutput from the testr runs.\n\nChange-Id: I60e3ca48e8f4196503b09711997bd70e641bd16c\n'}, {'number': 5, 'created': '2013-07-17 23:12:33.000000000', 'files': ['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/67b1caa739bd906d857b620a1d9cbccd29b63b6b', 'message': 'Add testr run and use subunit2html with testr\n\nThis commits adds a new run option DEVSTACK_GATE_TEMPEST_TESTR_FULL\nwhich is used to run the same tests as DEVSTACK_GATE_TEMPEST_FULL\nbut using testr --parallel instead of nose. This is going to eventually\nbe removed when using testr with tempest gets stable enough to gate\nprojects. But for now it will be a separate option. This also adds\nsupport for running subunit2html on all testr runs to get pretty html\noutput from the testr runs.\n\nChange-Id: I60e3ca48e8f4196503b09711997bd70e641bd16c\n'}]",2,36899,67b1caa739bd906d857b620a1d9cbccd29b63b6b,18,6,5,5196,,,0,"Add testr run and use subunit2html with testr

This commits adds a new run option DEVSTACK_GATE_TEMPEST_TESTR_FULL
which is used to run the same tests as DEVSTACK_GATE_TEMPEST_FULL
but using testr --parallel instead of nose. This is going to eventually
be removed when using testr with tempest gets stable enough to gate
projects. But for now it will be a separate option. This also adds
support for running subunit2html on all testr runs to get pretty html
output from the testr runs.

Change-Id: I60e3ca48e8f4196503b09711997bd70e641bd16c
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/99/36899/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh']",2,a0c51b26291329341e8bec8c738a042be069b5aa,testr," #Copy and compress testr_results and subunit log if [ $DEVSTACK_GATE_TEMPEST_TESTR_FULL -eq ""1"" || $DEVSTACK_GATE_TEMPEST_COVERAGE -eq ""1"" ] ; then sudo cp $BASE/new/tempest/testr_results.html $WORKSPACE/ sudo cp $BASE/new/tempest/subunit_log.txt $WORKSPACE/ sudo gzip -9 $WORKSPACE/subunit_log.txt sudo gzip -9 $WORKSPACE/testr_results.html fi # Set to enable running full tempest with testr: export DEVSTACK_GATE_TEMPEST_TESTR_FULL=${DEVSTACK_GATE_TEMPEST_TESTR_FULL:-0} ",,22,0
openstack%2Fdiskimage-builder~master~Ib92a9d419bb485c8861da041066827e8d6aac0b7,openstack/diskimage-builder,master,Ib92a9d419bb485c8861da041066827e8d6aac0b7,Update the Fedora element to honour --offline.,MERGED,2013-07-18 01:35:04.000000000,2013-07-18 01:35:04.000000000,2013-07-18 01:35:04.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4190}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-18 01:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/de9c8bc14b12349ed8496f484546a23f480ad33d', 'message': 'Update the Fedora element to honour --offline.\n\nSimilar to the Ubuntu element the Fedora element had not been updated\nto honour --offline. Also similarly we only check for the existence of\nthe final cached file rather than the image we directly download,\nbecause they are generated separately.\n\nChange-Id: Ib92a9d419bb485c8861da041066827e8d6aac0b7\n'}, {'number': 3, 'created': '2013-07-18 01:35:04.000000000', 'files': ['elements/fedora/root.d/10-fedora-cloud-image'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b8d08006db275d917751a0aaf22064bb2532c6b6', 'message': 'Update the Fedora element to honour --offline.\n\nSimilar to the Ubuntu element the Fedora element had not been updated\nto honour --offline. Also similarly we only check for the existence of\nthe final cached file rather than the image we directly download,\nbecause they are generated separately.\n\nThe -u change is just hygiene to detect future buggy changes.\n\nChange-Id: Ib92a9d419bb485c8861da041066827e8d6aac0b7\n'}, {'number': 2, 'created': '2013-07-18 01:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7d645982511b96aa034d65ecc0ba07cf767ec5a5', 'message': 'Update the Fedora element to honour --offline.\n\nSimilar to the Ubuntu element the Fedora element had not been updated\nto honour --offline. Also similarly we only check for the existence of\nthe final cached file rather than the image we directly download,\nbecause they are generated separately.\n\nThe -u change is just hygiene to detect future buggy changes.\n\nChange-Id: Ib92a9d419bb485c8861da041066827e8d6aac0b7\n'}]",0,37588,b8d08006db275d917751a0aaf22064bb2532c6b6,11,4,3,4190,,,0,"Update the Fedora element to honour --offline.

Similar to the Ubuntu element the Fedora element had not been updated
to honour --offline. Also similarly we only check for the existence of
the final cached file rather than the image we directly download,
because they are generated separately.

The -u change is just hygiene to detect future buggy changes.

Change-Id: Ib92a9d419bb485c8861da041066827e8d6aac0b7
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/88/37588/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/fedora/root.d/10-fedora-cloud-image'],1,de9c8bc14b12349ed8496f484546a23f480ad33d,,"CACHED_TAR=$IMG_PATH/$BASE_IMAGE_TAR if [ -n ""$DIB_OFFLINE"" -a -f ""$CACHED_TAR"" ] ; then echo ""Not checking freshness of cached $CACHED_TAR."" else echo ""Fetching Base Image"" $TMP_HOOKS_PATH/bin/cache-url $DIB_CLOUD_IMAGES/$BASE_IMAGE_FILE $IMG_PATH/$BASE_IMAGE_FILE if [ ! -f $CACHED_TAR -o \ $IMG_PATH/$BASE_IMAGE_FILE -nt $CACHED_TAR ] ; then echo ""Repacking base image as tarball."" WORKING=$(mktemp -d) EACTION=""rm -r $WORKING"" trap ""$EACTION"" EXIT echo ""Working in $WORKING"" RAW_FILE=$(basename $BASE_IMAGE_FILE) RAW_FILE=${RAW_FILE#.qcow2}.raw qemu-img convert -f qcow2 -O raw $IMG_PATH/$BASE_IMAGE_FILE $WORKING/$RAW_FILE # WARNING: The mattdm image has the root filesystem on the second # partition (p2). If he changes the image the MAGIC_BIT # might also need to change. # UPDATE to above warning alluding to Fedora18: # F19 images have the rootfs partition on p1 MAGIC_BIT=p1 # XXX: Parsing stdout is dangerous, would like a better way to discover # the device used for the image. # NOTE: On F17 (parted-3.0-10.fc17.x86_64), partprobe of # /dev/loop0 does not create /dev/loop0p2, while kpartx at # least creates /dev/mapper/loop0p2. LOOPDEV=$(sudo kpartx -avr $WORKING/$RAW_FILE | awk ""/loop[0-9]+$MAGIC_BIT/ {print \$3}"") if ! timeout 5 sh -c ""while ! [ -e /dev/mapper/$LOOPDEV ]; do sleep 1; done""; then echo ""Error: Could not find /dev/mapper/$LOOPDEV"" exit 1 fi EACTION=""sudo kpartx -d $WORKING/$RAW_FILE;$EACTION"" trap ""$EACTION"" EXIT mkdir $WORKING/mnt sudo mount /dev/mapper/$LOOPDEV $WORKING/mnt EACTION=""sudo umount -f $WORKING/mnt;$EACTION"" trap ""$EACTION"" EXIT # Chroot in so that we get the correct uid/gid sudo chroot $WORKING/mnt bin/tar -cz . > $WORKING/tmp.tar mv $WORKING/tmp.tar $IMG_PATH/$BASE_IMAGE_TAR"," echo ""Fetching Base Image"" $TMP_HOOKS_PATH/bin/cache-url $DIB_CLOUD_IMAGES/$BASE_IMAGE_FILE $IMG_PATH/$BASE_IMAGE_FILE if [ ! -f $IMG_PATH/$BASE_IMAGE_TAR -o \ $IMG_PATH/$BASE_IMAGE_FILE -nt $IMG_PATH/$BASE_IMAGE_TAR ] ; then echo ""Repacking base image as tarball."" WORKING=$(mktemp -d) EACTION=""rm -r $WORKING"" trap ""$EACTION"" EXIT echo ""Working in $WORKING"" RAW_FILE=$(basename $BASE_IMAGE_FILE) RAW_FILE=${RAW_FILE#.qcow2}.raw qemu-img convert -f qcow2 -O raw $IMG_PATH/$BASE_IMAGE_FILE $WORKING/$RAW_FILE # WARNING: The mattdm image has the root filesystem on the second # partition (p2). If he changes the image the MAGIC_BIT # might also need to change. # UPDATE to above warning alluding to Fedora18: # F19 images have the rootfs partition on p1 MAGIC_BIT=p1 # XXX: Parsing stdout is dangerous, would like a better way to discover # the device used for the image. # NOTE: On F17 (parted-3.0-10.fc17.x86_64), partprobe of # /dev/loop0 does not create /dev/loop0p2, while kpartx at # least creates /dev/mapper/loop0p2. LOOPDEV=$(sudo kpartx -avr $WORKING/$RAW_FILE | awk ""/loop[0-9]+$MAGIC_BIT/ {print \$3}"") if ! timeout 5 sh -c ""while ! [ -e /dev/mapper/$LOOPDEV ]; do sleep 1; done""; then echo ""Error: Could not find /dev/mapper/$LOOPDEV"" exit 1 EACTION=""sudo kpartx -d $WORKING/$RAW_FILE;$EACTION"" trap ""$EACTION"" EXIT mkdir $WORKING/mnt sudo mount /dev/mapper/$LOOPDEV $WORKING/mnt EACTION=""sudo umount -f $WORKING/mnt;$EACTION"" trap ""$EACTION"" EXIT # Chroot in so that we get the correct uid/gid sudo chroot $WORKING/mnt bin/tar -cz . > $WORKING/tmp.tar mv $WORKING/tmp.tar $IMG_PATH/$BASE_IMAGE_TAR",41,36
openstack%2Fdiskimage-builder~master~If1a0366b51951a73b7a3ffe23a29a3d910b08938,openstack/diskimage-builder,master,If1a0366b51951a73b7a3ffe23a29a3d910b08938,Enable --offline support for Ubuntu root images.,MERGED,2013-07-18 01:34:56.000000000,2013-07-18 01:34:56.000000000,2013-07-18 01:34:56.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4190}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-18 01:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/76771281268f95d6ec90e22ff455ce6dcc69eeea', 'message': 'Enable --offline support for Ubuntu root images.\n\nWhen --offline is set elements should not revalidate cached data. The\nubuntu element had not been updated to match this. SHA checking is\nalso skipped as we only move a new cached file into place when the\nhash matches, and we might download a new hash before updating the\nimage cache, which would cause persistent --offline failures.\n\nChange-Id: If1a0366b51951a73b7a3ffe23a29a3d910b08938\n'}, {'number': 2, 'created': '2013-07-18 01:34:56.000000000', 'files': ['elements/ubuntu/root.d/10-cache-ubuntu-tarball'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/d7379df8b8c9161e780b84626ce0e44f50d4a9eb', 'message': 'Enable --offline support for Ubuntu root images.\n\nWhen --offline is set elements should not revalidate cached data. The\nubuntu element had not been updated to match this. SHA checking is\nalso skipped as we only move a new cached file into place when the\nhash matches, and we might download a new hash before updating the\nimage cache, which would cause persistent --offline failures.\n\nChange-Id: If1a0366b51951a73b7a3ffe23a29a3d910b08938\n'}]",0,37587,d7379df8b8c9161e780b84626ce0e44f50d4a9eb,11,4,2,4190,,,0,"Enable --offline support for Ubuntu root images.

When --offline is set elements should not revalidate cached data. The
ubuntu element had not been updated to match this. SHA checking is
also skipped as we only move a new cached file into place when the
hash matches, and we might download a new hash before updating the
image cache, which would cause persistent --offline failures.

Change-Id: If1a0366b51951a73b7a3ffe23a29a3d910b08938
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/87/37587/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/ubuntu/root.d/10-cache-ubuntu-tarball'],1,76771281268f95d6ec90e22ff455ce6dcc69eeea,,"set -euCACHED_FILE=$IMG_PATH/$BASE_IMAGE_FILE if [ -n ""$DIB_OFFLINE"" -a -f ""$CACHED_FILE"" ] ; then echo ""Not checking freshness of cached $CACHED_FILE."" else echo ""Fetching Base Image"" $TMP_HOOKS_PATH/bin/cache-url $SHA256SUMS $IMG_PATH/SHA256SUMS.ubuntu.$DIB_RELEASE.$ARCH $TMP_HOOKS_PATH/bin/cache-url $DIB_CLOUD_IMAGES/$DIB_RELEASE/current/$BASE_IMAGE_FILE $CACHED_FILE pushd $IMG_PATH grep ""$BASE_IMAGE_FILE"" SHA256SUMS.ubuntu.$DIB_RELEASE.$ARCH | sha256sum --check - popd fi","set -e echo ""Fetching Base Image"" $TMP_HOOKS_PATH/bin/cache-url $SHA256SUMS $IMG_PATH/SHA256SUMS.ubuntu.$DIB_RELEASE.$ARCH $TMP_HOOKS_PATH/bin/cache-url $DIB_CLOUD_IMAGES/$DIB_RELEASE/current/$BASE_IMAGE_FILE $IMG_PATH/$BASE_IMAGE_FILE pushd $IMG_PATH grep ""$BASE_IMAGE_FILE"" SHA256SUMS.ubuntu.$DIB_RELEASE.$ARCH | sha256sum --check - popd",12,7
openstack%2Fdiskimage-builder~master~I133a691909d38e834c204950276a57f4884fc4ed,openstack/diskimage-builder,master,I133a691909d38e834c204950276a57f4884fc4ed,Fix the DIB_OFFLINE setting to actually work.,MERGED,2013-07-18 01:34:55.000000000,2013-07-18 01:34:55.000000000,2013-07-18 01:34:55.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 6609}]","[{'number': 1, 'created': '2013-07-18 01:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b7c332667eb8c600c199c6df38b391849de32f6e', 'message': 'Fix the DIB_OFFLINE setting to actually work.\n\nI missed the getopt parameter and forgot defaults are imported after\noption processing. Untested code is broken code!\n\nChange-Id: I133a691909d38e834c204950276a57f4884fc4ed\n'}, {'number': 2, 'created': '2013-07-18 01:34:55.000000000', 'files': ['bin/disk-image-create', 'lib/common-defaults'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f7f6cb45ee3c400748f42d20fb73ebd8468060b5', 'message': 'Fix the DIB_OFFLINE setting to actually work.\n\nI missed the getopt parameter and forgot defaults are imported after\noption processing. Untested code is broken code!\n\nChange-Id: I133a691909d38e834c204950276a57f4884fc4ed\n'}]",2,37586,f7f6cb45ee3c400748f42d20fb73ebd8468060b5,10,5,2,4190,,,0,"Fix the DIB_OFFLINE setting to actually work.

I missed the getopt parameter and forgot defaults are imported after
option processing. Untested code is broken code!

Change-Id: I133a691909d38e834c204950276a57f4884fc4ed
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/86/37586/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/disk-image-create', 'lib/common-defaults']",2,b7c332667eb8c600c199c6df38b391849de32f6e,,export DIB_OFFLINE==${DIB_OFFLINE:-''},export DIB_OFFLINE='',2,2
openstack%2Fnova~master~Icb3075e5a3a936a205f24a91593bed6c74aa6b96,openstack/nova,master,Icb3075e5a3a936a205f24a91593bed6c74aa6b96,Fixes typo 'limists' to 'limits',ABANDONED,2013-07-15 22:54:50.000000000,2013-07-18 01:23:43.000000000,,"[{'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 4601}, {'_account_id': 5441}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-07-15 22:54:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d8d7e562bb4c5ed2a2f41b30b91341978f25c66', 'message': ""Fixes typo 'limists' to 'limits'\n\nChange-Id: Icb3075e5a3a936a205f24a91593bed6c74aa6b96\n""}, {'number': 2, 'created': '2013-07-15 23:25:01.000000000', 'files': ['nova/tests/scheduler/test_chance_scheduler.py', 'nova/tests/scheduler/test_filter_scheduler.py', 'nova/scheduler/filter_scheduler.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6db5aa73c2d2fae2d462e27959b43a5a7653488a', 'message': ""Fixes typo 'limists' to 'limits'\n\nChange-Id: Icb3075e5a3a936a205f24a91593bed6c74aa6b96\n""}]",0,37146,6db5aa73c2d2fae2d462e27959b43a5a7653488a,9,6,2,4601,,,0,"Fixes typo 'limists' to 'limits'

Change-Id: Icb3075e5a3a936a205f24a91593bed6c74aa6b96
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/37146/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/filter_scheduler.py'],1,7d8d7e562bb4c5ed2a2f41b30b91341978f25c66,typo, limits=host.obj.limits) for host in selected_hosts], limists=host.obj.limits) for host in selected_hosts],1,1
openstack%2Fopenstack-manuals~master~I665dc68e41729ecada5d5de35a4f441222c162e2,openstack/openstack-manuals,master,I665dc68e41729ecada5d5de35a4f441222c162e2,Add account quota md section for swift,MERGED,2013-07-17 16:21:54.000000000,2013-07-18 00:07:50.000000000,2013-07-18 00:07:50.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 3153}, {'_account_id': 6889}]","[{'number': 1, 'created': '2013-07-17 16:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/59547aee0c5e948a734773fc4290d40838f2d4df', 'message': 'Add account quota md section for swift\n\nAdd the missing section in openstack-\nobject-storage-admin guide about\naccount quota middleware.\n\nChange-Id: I665dc68e41729ecada5d5de35a4f441222c162e2\nFixes: bug #1202284\n'}, {'number': 2, 'created': '2013-07-17 16:33:58.000000000', 'files': ['doc/src/docbkx/openstack-object-storage-admin/objectstorageadmin.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/010c0c578f7a0a691e6138cc3f0edd16e761ec71', 'message': 'Add account quota md section for swift\n\nAdd the missing section in openstack-\nobject-storage-admin guide about\naccount quota middleware.\n\nChange-Id: I665dc68e41729ecada5d5de35a4f441222c162e2\nFixes: bug #1202284\n'}]",2,37519,010c0c578f7a0a691e6138cc3f0edd16e761ec71,9,4,2,6889,,,0,"Add account quota md section for swift

Add the missing section in openstack-
object-storage-admin guide about
account quota middleware.

Change-Id: I665dc68e41729ecada5d5de35a4f441222c162e2
Fixes: bug #1202284
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/19/37519/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-object-storage-admin/objectstorageadmin.xml'],1,59547aee0c5e948a734773fc4290d40838f2d4df,bug/1202284," <section xml:id=""object-storage-account-quotas""> <title>Account Quotas</title> <para>The account_quotas middleware aims to block write requests (PUT, POST) if a given account quota (in bytes) is exceeded while DELETE requests are still allowed.</para> <para>The x-account-meta-quota-bytes metadata entry must be set to store and enable the quota. Write requests to this metadata entry are only permitted for resellers. There isn't any account quota limitation on a reseller account even if x-account-meta-quota-bytes is set.</para> <para>Any object PUT operations that exceed the quota return a 413 response (request entity too large) with a descriptive body.</para> <para>The following command use an admin account that own the Reseller role to set a quota on the test account: <programlisting>swift -A http://127.0.0.1:8080/auth/v1.0 -U admin:admin -K admin --os-storage-url=http://127.0.0.1:8080/v1/AUTH_test post -m quota-bytes:10000</programlisting> Here is the stat listing of an account where quota has been set: <programlisting>swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing stat Account: AUTH_test Containers: 0 Objects: 0 Bytes: 0 Meta Quota-Bytes: 10000 X-Timestamp: 1374075958.37454 X-Trans-Id: tx602634cf478546a39b1be-0051e6bc7a </programlisting> The command below remove the account quota: <programlisting>swift -A http://127.0.0.1:8080/auth/v1.0 -U admin:admin -K admin --os-storage-url=http://127.0.0.1:8080/v1/AUTH_test post -m quota-bytes: </programlisting></para> </section>",,31,1
openstack%2Fopenstack-manuals~stable%2Fgrizzly~I1993051a8d67cc5e9b3ffda2b7e90e35f597794d,openstack/openstack-manuals,stable/grizzly,I1993051a8d67cc5e9b3ffda2b7e90e35f597794d,bug 1197117 KVM section was not OS specific,MERGED,2013-07-17 10:02:23.000000000,2013-07-18 00:06:18.000000000,2013-07-18 00:06:18.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2013-07-17 10:02:23.000000000', 'files': ['doc/src/docbkx/common/kvm.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8740985b4fd4c394e9adcb92dfd86cfc15bcc18b', 'message': 'bug 1197117 KVM section was not OS specific\n\nChange-Id: I1993051a8d67cc5e9b3ffda2b7e90e35f597794d\n'}]",0,37440,8740985b4fd4c394e9adcb92dfd86cfc15bcc18b,5,2,1,7166,,,0,"bug 1197117 KVM section was not OS specific

Change-Id: I1993051a8d67cc5e9b3ffda2b7e90e35f597794d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/40/37440/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/common/kvm.xml'],1,8740985b4fd4c394e9adcb92dfd86cfc15bcc18b,grizzly-bug/1197117," <para>The processors of your compute host need to support virtualization technology (VT) (mainly Intel <emphasis role=""italic"">VT -x</emphasis> or AMD <emphasis role=""italic"" >AMD-v</emphasis> technologies) to use KVM. </para> <para>In order to check if your processor has VT support (which has to be enabled in the BIOS), issue as root:<screen os=""ubuntu""> <prompt>#</prompt> <userinput>apt-get install cpu</userinput> <prompt>#</prompt> <userinput>kvm-ok</userinput></screen> <screen os=""rhel;fedora;centos""> <prompt>$</prompt> <userinput>egrep '(vmx|svm)' --color=always /proc/cpuinfo</userinput></screen> </para> <para>If KVM is supported, the output should look something like:<screen os=""ubuntu""> <computeroutput>INFO: /dev/kvm exists KVM acceleration can be used</computeroutput></screen> <screen os=""rhel;fedora;centos""> <computeroutput>flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 popcnt lahf_lm arat dtherm tpr_shadow vnmi flexpriority ept vpid</computeroutput> </screen> </para> <para os=""ubuntu"">If KVM is not supported, the output should look something <para os=""rhel;fedora;centos"">If KVM is not supported, you should get no output.</para> <note><para>Some systems require that you enable VT support in the system BIOS. If you believe your processor supports hardware acceleration but the above command produced no output, you may need to reboot your machine, enter the system BIOS, and enable the VT option.</para></note> "," <para>The processors of your compute host need to support virtualization technology (VT) to use KVM. </para> <para>If you are running on Ubuntu, install the cpu package and use the <command>kvm-ok</command> command to check if your processor has VT support, it is enabled in the BIOS, and KVM is installed properly, as root:<screen> <prompt>#</prompt> <userinput>apt-get install cpu</userinput> <prompt>#</prompt> <userinput>kvm-ok</userinput></screen></para> <para>If KVM is enabled, the output should look something like:<screen><computeroutput>INFO: /dev/kvm exists KVM acceleration can be used</computeroutput></screen></para> <para>If KVM is not enabled, the output should look something <para>On distributions that don't have <command>kvm-ok</command>, you can check if your processor has VT support by looking at the processor flags in the <filename>/proc/cpuinfo</filename> file. For Intel processors, look for the <literal>vmx</literal> flag, and for AMD processors, look for the <literal>svm</literal> flag. A simple way to check is to run the following command and see if there is any output:<screen><prompt>$</prompt> <userinput>egrep '(vmx|svm)' --color=always /proc/cpuinfo</userinput></screen></para> <para>Some systems require that you enable VT support in the system BIOS. If you believe your processor supports hardware acceleration but the above command produced no output, you may need to reboot your machine, enter the system BIOS, and enable the VT option.</para>",26,24
openstack%2Fopenstack-manuals~master~I0297ec84e2272abb1c3d18f4857e0ef98a6bd8fd,openstack/openstack-manuals,master,I0297ec84e2272abb1c3d18f4857e0ef98a6bd8fd,Doc change for multiple iSCSI port support in 3PAR,MERGED,2013-07-16 22:07:04.000000000,2013-07-18 00:05:55.000000000,2013-07-18 00:05:54.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6772}, {'_account_id': 7389}]","[{'number': 1, 'created': '2013-07-16 22:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/af0c55d90939c4464c479bc983944177722a6815', 'message': 'Doc change for multiple iSCSI port support in 3PAR\n\nDocumentation for DocImpact in https://review.openstack.org/#/c/36535/\n\nChange-Id: I0297ec84e2272abb1c3d18f4857e0ef98a6bd8fd\n'}, {'number': 2, 'created': '2013-07-16 22:38:16.000000000', 'files': ['doc/src/docbkx/openstack-block-storage-admin/drivers/hp-3par-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/32a122595a3c662d83f068a4763f372aea8dc4f6', 'message': 'Doc change for multiple iSCSI port support in 3PAR\n\nDocumentation for DocImpact in https://review.openstack.org/#/c/36535/\n\nFixes: bug 1200372\n\nChange-Id: I0297ec84e2272abb1c3d18f4857e0ef98a6bd8fd\n'}]",0,37340,32a122595a3c662d83f068a4763f372aea8dc4f6,14,4,2,7389,,,0,"Doc change for multiple iSCSI port support in 3PAR

Documentation for DocImpact in https://review.openstack.org/#/c/36535/

Fixes: bug 1200372

Change-Id: I0297ec84e2272abb1c3d18f4857e0ef98a6bd8fd
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/40/37340/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-block-storage-admin/drivers/hp-3par-driver.xml'],1,af0c55d90939c4464c479bc983944177722a6815,,"# iSCSI (uncomment the next line to enable the iSCSI driver and # hp3par_iscsi_ips or iscsi_ip_address) #volume_driver=cinder.volume.drivers.san.hp.hp_3par_iscsi.HP3PARISCSIDriver # iSCSI multiple port configuration # hp3par_iscsi_ips=10.10.220.253:3261,10.10.222.234 # Still available for single port iSCSI configuration #iscsi_ip_address=10.10.220.253 <emphasis role=""bold"">## OPTIONAL SETTINGS</emphasis> <note> <para>One or more iSCSI addresses may be configured using hp3par_iscsi_ips. When multiple addresses are configured, the driver will select the iSCSI port with the fewest active volumes at attach time. The IP address may include an IP port by using a colon ‘:’ to separate the address from port. If no IP port is defined, the default port 3260 will be used. IP addresses should be separated using a comma ’,’. iscsi_ip_address/iscsi_port may still be used, as an alternative to hp3par_iscsi_ips for single port iSCSI configuration.</para> </note> ","# iSCSI (uncomment the next line to enable the iSCSI driver and the iscsi_ip_address) # volume_driver=cinder.volume.drivers.san.hp.hp_3par_iscsi.HP3PARISCSIDriver # The port that the iSCSI daemon is listening on #iscsi_ip_address=""10.10.220.253"" <emphasis role=""bold"">## OPTIONAL SETTING</emphasis>",19,5
openstack%2Fopenstack-manuals~stable%2Fgrizzly~Id2450f5c59449499befabad44d17ed9031721736,openstack/openstack-manuals,stable/grizzly,Id2450f5c59449499befabad44d17ed9031721736,Fix typo in Network Guide,MERGED,2013-07-17 17:30:29.000000000,2013-07-18 00:05:18.000000000,2013-07-18 00:05:18.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6414}]","[{'number': 1, 'created': '2013-07-17 17:30:29.000000000', 'files': ['doc/src/docbkx/openstack-network-connectivity-admin/ch_under_the_hood.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cda8bb10192b5063a7e2e930ac1cedaaddd40921', 'message': ""Fix typo in Network Guide\n\n'qcbXXX' should be 'qvbXXX'.\n\nFixes bug 1201779\n\nCherry picked from https://review.openstack.org/#/c/37378/\n\nChange-Id: Id2450f5c59449499befabad44d17ed9031721736\n""}]",0,37537,cda8bb10192b5063a7e2e930ac1cedaaddd40921,7,3,1,6414,,,0,"Fix typo in Network Guide

'qcbXXX' should be 'qvbXXX'.

Fixes bug 1201779

Cherry picked from https://review.openstack.org/#/c/37378/

Change-Id: Id2450f5c59449499befabad44d17ed9031721736
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/37/37537/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-network-connectivity-admin/ch_under_the_hood.xml'],1,cda8bb10192b5063a7e2e930ac1cedaaddd40921,bug/1201779," <literal>(qvb<replaceable>XXX</replaceable>,"," <literal>(qcb<replaceable>XXX</replaceable>,",1,1
openstack%2Fglance~master~Ie72dcd9f41f7a3b7405cda9fe28e1e468fcc1bef,openstack/glance,master,Ie72dcd9f41f7a3b7405cda9fe28e1e468fcc1bef,Fix 'glance-cache-manage list-cached' for xattr,MERGED,2013-07-03 11:02:09.000000000,2013-07-17 23:46:56.000000000,2013-07-17 23:46:56.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1390}, {'_account_id': 2166}, {'_account_id': 6159}]","[{'number': 1, 'created': '2013-07-03 11:02:09.000000000', 'files': ['glance/tests/functional/test_cache_middleware.py', 'glance/image_cache/drivers/xattr.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/fd9b4cd43d5533dd8051cf68d1b27cf70cd2f3cd', 'message': ""Fix 'glance-cache-manage list-cached' for xattr\n\nThe xattr driver for the caching middleware was returning it's\nlast_modified/last_accessed times in iso8601 format rather than a\ntimestamp.\n\nThis was inconsistent with the sqlite driver and caused the\nglance-cache-manage command to fall over when using the xattr driver.\n\nFixes bug 1197360\n\nChange-Id: Ie72dcd9f41f7a3b7405cda9fe28e1e468fcc1bef\n""}]",0,35474,fd9b4cd43d5533dd8051cf68d1b27cf70cd2f3cd,9,5,1,1390,,,0,"Fix 'glance-cache-manage list-cached' for xattr

The xattr driver for the caching middleware was returning it's
last_modified/last_accessed times in iso8601 format rather than a
timestamp.

This was inconsistent with the sqlite driver and caused the
glance-cache-manage command to fall over when using the xattr driver.

Fixes bug 1197360

Change-Id: Ie72dcd9f41f7a3b7405cda9fe28e1e468fcc1bef
",git fetch https://review.opendev.org/openstack/glance refs/changes/74/35474/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/test_cache_middleware.py', 'glance/image_cache/drivers/xattr.py']",2,fd9b4cd43d5533dd8051cf68d1b27cf70cd2f3cd,bug/1197360, entry['last_modified'] = file_info[stat.ST_MTIME] entry['last_accessed'] = file_info[stat.ST_ATIME], entry['last_modified'] = iso8601_from_timestamp( file_info[stat.ST_MTIME]) entry['last_accessed'] = iso8601_from_timestamp( file_info[stat.ST_ATIME]) def iso8601_from_timestamp(timestamp): return datetime.datetime.utcfromtimestamp(timestamp).isoformat(),13,8
openstack%2Fcinder~master~Ib422445394b929910d694fe848e9912adcb804a3,openstack/cinder,master,Ib422445394b929910d694fe848e9912adcb804a3,Removes redundant string cast of StrOpts,ABANDONED,2013-07-17 12:04:49.000000000,2013-07-17 23:40:14.000000000,,"[{'_account_id': 3}, {'_account_id': 1107}, {'_account_id': 1773}, {'_account_id': 2166}, {'_account_id': 4355}]","[{'number': 1, 'created': '2013-07-17 12:04:49.000000000', 'files': ['cinder/backup/drivers/ceph.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/348e0587ea3a6a6feaf1d195c49cc578ad88a0f9', 'message': 'Removes redundant string cast of StrOpts\n\nChange-Id: Ib422445394b929910d694fe848e9912adcb804a3\n'}]",0,37455,348e0587ea3a6a6feaf1d195c49cc578ad88a0f9,5,5,1,1994,,,0,"Removes redundant string cast of StrOpts

Change-Id: Ib422445394b929910d694fe848e9912adcb804a3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/55/37455/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/backup/drivers/ceph.py'],1,348e0587ea3a6a6feaf1d195c49cc578ad88a0f9,redundant_cast, self._ceph_user = CONF.backup_ceph_user self._ceph_pool = CONF.backup_ceph_pool self._ceph_conf = CONF.backup_ceph_conf, self._ceph_user = str(CONF.backup_ceph_user) self._ceph_pool = str(CONF.backup_ceph_pool) self._ceph_conf = str(CONF.backup_ceph_conf),3,3
openstack%2Fdjango_openstack_auth~master~I2bd101e3ed2dd37da86f84773c2b9dafc0717d3b,openstack/django_openstack_auth,master,I2bd101e3ed2dd37da86f84773c2b9dafc0717d3b,Fix issue with V3 Authentication.,MERGED,2013-07-17 20:47:22.000000000,2013-07-17 23:23:51.000000000,2013-07-17 23:23:51.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 1941}, {'_account_id': 5623}]","[{'number': 1, 'created': '2013-07-17 20:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/0eb4fdb548498721abc85fc92381d9e956e68b4c', 'message': 'Fix issue with V3 Authentication.\n\nUnscoped token does not have a roles attribute in it. Fix the\ncode to handle non-existent of roles in the Auth Token.\n\nFixed bug/1202385\n\nChange-Id: I2bd101e3ed2dd37da86f84773c2b9dafc0717d3b\n'}, {'number': 2, 'created': '2013-07-17 20:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/0bc056825ae0ad76a5f0923ef120d58abfa8601c', 'message': 'Fix issue with V3 Authentication.\n\nUnscoped token does not have a roles attribute in it. Fix the\ncode to handle non-existent of roles in the Auth Token.\n\nFixed bug/1202385\n\nChange-Id: I2bd101e3ed2dd37da86f84773c2b9dafc0717d3b\n'}, {'number': 3, 'created': '2013-07-17 20:50:30.000000000', 'files': ['openstack_auth/user.py', 'openstack_auth/tests/data_v3.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/047f7b5ff1809f984ccfd6622dbfc84513eb8ab2', 'message': 'Fix issue with V3 Authentication.\n\nUnscoped token does not have a roles attribute in it. Fix the\ncode to handle non-existent of roles in the Auth Token.\n\nFixes: bug #1202385\n\nChange-Id: I2bd101e3ed2dd37da86f84773c2b9dafc0717d3b\n'}]",0,37563,047f7b5ff1809f984ccfd6622dbfc84513eb8ab2,10,4,3,1941,,,0,"Fix issue with V3 Authentication.

Unscoped token does not have a roles attribute in it. Fix the
code to handle non-existent of roles in the Auth Token.

Fixes: bug #1202385

Change-Id: I2bd101e3ed2dd37da86f84773c2b9dafc0717d3b
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/63/37563/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_auth/user.py', 'openstack_auth/tests/data_v3.py']",2,0eb4fdb548498721abc85fc92381d9e956e68b4c,bug/1202385,," 'roles': [role_dict], 'roles': [role_dict],",2,4
openstack%2Fcinder~master~I83aef90706474e8a079ab5247b72b33c7a2c8472,openstack/cinder,master,I83aef90706474e8a079ab5247b72b33c7a2c8472,Rename SolidFire driver for consistency,MERGED,2013-07-17 02:16:29.000000000,2013-07-17 23:23:36.000000000,2013-07-17 23:23:36.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-07-17 02:16:29.000000000', 'files': ['cinder/tests/test_drivers_compatibility.py', 'cinder/volume/manager.py', 'cinder/volume/drivers/solidfire.py', 'cinder/tests/test_solidfire.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fd139faaf3d3fc96825bbaf3397a529e5762d92c', 'message': 'Rename SolidFire driver for consistency\n\nRename driver to SolidFireDriver for consistency.\n\nFixes: bug #1136081\nChange-Id: I83aef90706474e8a079ab5247b72b33c7a2c8472\n'}]",3,37373,fd139faaf3d3fc96825bbaf3397a529e5762d92c,9,4,1,7156,,,0,"Rename SolidFire driver for consistency

Rename driver to SolidFireDriver for consistency.

Fixes: bug #1136081
Change-Id: I83aef90706474e8a079ab5247b72b33c7a2c8472
",git fetch https://review.opendev.org/openstack/cinder refs/changes/73/37373/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_drivers_compatibility.py', 'cinder/volume/manager.py', 'cinder/volume/drivers/solidfire.py', 'cinder/tests/test_solidfire.py']",4,fd139faaf3d3fc96825bbaf3397a529e5762d92c,bug/1136081,"from cinder.volume.drivers.solidfire import SolidFireDriver self.stubs.Set(SolidFireDriver, '_issue_api_request', self.stubs.Set(SolidFireDriver, '_issue_api_request', self.stubs.Set(SolidFireDriver, '_set_qos_by_volume_type', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_update_cluster_status', self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_update_cluster_status', self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_update_cluster_status', self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration) self.stubs.Set(SolidFireDriver, '_update_cluster_status', self.stubs.Set(SolidFireDriver, '_issue_api_request', sfv = SolidFireDriver(configuration=self.configuration)","from cinder.volume.drivers.solidfire import SolidFire self.stubs.Set(SolidFire, '_issue_api_request', self.stubs.Set(SolidFire, '_issue_api_request', self.stubs.Set(SolidFire, '_set_qos_by_volume_type', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_update_cluster_status', self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_update_cluster_status', self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_update_cluster_status', self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration) self.stubs.Set(SolidFire, '_update_cluster_status', self.stubs.Set(SolidFire, '_issue_api_request', sfv = SolidFire(configuration=self.configuration)",54,48
openstack%2Fcinder~master~I30a0b4d905b41f00e6450bc5cbfbf0c4d8593ab3,openstack/cinder,master,I30a0b4d905b41f00e6450bc5cbfbf0c4d8593ab3,Fixes Opt types in cinder/backup/drivers/ceph.py,MERGED,2013-07-17 05:33:11.000000000,2013-07-17 23:23:30.000000000,2013-07-17 23:23:29.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1773}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 4355}]","[{'number': 1, 'created': '2013-07-17 05:33:11.000000000', 'files': ['cinder/backup/drivers/ceph.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c8a0320d8ee043cf94c8ff44ba77a0b8a77b4038', 'message': 'Fixes Opt types in cinder/backup/drivers/ceph.py\n\nChanged backup_ceph_chunk_size, backup_ceph_stripe_unit and\nbackup_ceph_stripe_count from StrOpt to IntOpt.\n\nChange-Id: I30a0b4d905b41f00e6450bc5cbfbf0c4d8593ab3\n'}]",2,37396,c8a0320d8ee043cf94c8ff44ba77a0b8a77b4038,10,6,1,1994,,,0,"Fixes Opt types in cinder/backup/drivers/ceph.py

Changed backup_ceph_chunk_size, backup_ceph_stripe_unit and
backup_ceph_stripe_count from StrOpt to IntOpt.

Change-Id: I30a0b4d905b41f00e6450bc5cbfbf0c4d8593ab3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/96/37396/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/backup/drivers/ceph.py'],1,c8a0320d8ee043cf94c8ff44ba77a0b8a77b4038,backup_ceph_opts," cfg.IntOpt('backup_ceph_chunk_size', default=(units.MiB * 128), cfg.IntOpt('backup_ceph_stripe_unit', default=0, cfg.IntOpt('backup_ceph_stripe_count', default=0, self.rbd_stripe_unit = CONF.backup_ceph_stripe_unit self.rbd_stripe_count = CONF.backup_ceph_stripe_count"," cfg.StrOpt('backup_ceph_chunk_size', default=(units.MiB * 128), cfg.StrOpt('backup_ceph_stripe_unit', default=0, cfg.StrOpt('backup_ceph_stripe_count', default=0, self.rbd_stripe_unit = int(CONF.backup_ceph_stripe_unit) self.rbd_stripe_count = int(CONF.backup_ceph_stripe_count)",5,5
openstack%2Fnova~master~I79a2db66544e0662e48445505a818ff62f765569,openstack/nova,master,I79a2db66544e0662e48445505a818ff62f765569,Fix shelve's use of system_metadata,MERGED,2013-07-16 23:50:08.000000000,2013-07-17 23:21:39.000000000,2013-07-17 23:21:36.000000000,"[{'_account_id': 3}, {'_account_id': 191}, {'_account_id': 2711}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-16 23:50:08.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1807b665a7914105abcd6ad0163edb04a529bc87', 'message': ""Fix shelve's use of system_metadata\n\nThe shelve patches needed to include a hack to make the changes\nto system_metadata get saved properly. Now that it's fixed,\nclean that up.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I79a2db66544e0662e48445505a818ff62f765569\n""}]",0,37355,1807b665a7914105abcd6ad0163edb04a529bc87,10,4,1,4393,,,0,"Fix shelve's use of system_metadata

The shelve patches needed to include a hack to make the changes
to system_metadata get saved properly. Now that it's fixed,
clean that up.

Related to blueprint unified-object-model

Change-Id: I79a2db66544e0662e48445505a818ff62f765569
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/37355/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,1807b665a7914105abcd6ad0163edb04a529bc87,bp/unified-object-model, instance.system_metadata['shelved_at'] = timeutils.strtime() instance.system_metadata['shelved_image_id'] = image_id instance.system_metadata['shelved_host'] = self.host, sys_meta = instance.system_metadata sys_meta['shelved_at'] = timeutils.strtime() sys_meta['shelved_image_id'] = image_id sys_meta['shelved_host'] = self.host instance.system_metadata = sys_meta,3,5
openstack%2Fnova~master~I40b72274cd24034b03c8e07af56e7c8d49b6b898,openstack/nova,master,I40b72274cd24034b03c8e07af56e7c8d49b6b898,Fix Instance object handling of implied fields,MERGED,2013-07-16 01:58:15.000000000,2013-07-17 23:21:18.000000000,2013-07-17 23:21:16.000000000,"[{'_account_id': 3}, {'_account_id': 191}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 4573}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-16 01:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5654d920863d8885147dfec12855cd6197bae247', 'message': 'Fix Instance object handling of implied fields\n\nThe situation around info_cache and security_groups is a bit\nconfusing and inconsistent at the moment. Since some of the\n""all"" queries don\'t join info_cache and security_groups,\navoid assuming that they are there, either triggering an\nunintentional lazy load, or a KeyError in a few cases where the\nDB API returns a dict.\n\nAlso, don\'t ever allow us to recurse into another instance object\nlooking for a loaded attribute in case it fails to load from the\nget query.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I40b72274cd24034b03c8e07af56e7c8d49b6b898\n'}, {'number': 2, 'created': '2013-07-16 23:43:20.000000000', 'files': ['nova/objects/instance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3569168437c732d4cb33fbf3023d0c0ea85f3258', 'message': 'Fix Instance object handling of implied fields\n\nThe situation around info_cache and security_groups is a bit\nconfusing and inconsistent at the moment. Since some of the\n""all"" queries don\'t join info_cache and security_groups,\navoid assuming that they are there, either triggering an\nunintentional lazy load, or a KeyError in a few cases where the\nDB API returns a dict.\n\nAlso, don\'t ever allow us to recurse into another instance object\nlooking for a loaded attribute in case it fails to load from the\nget query.\n\nRelated to blueprint unified-object-model\n\nChange-Id: I40b72274cd24034b03c8e07af56e7c8d49b6b898\n'}]",0,37157,3569168437c732d4cb33fbf3023d0c0ea85f3258,13,6,2,4393,,,0,"Fix Instance object handling of implied fields

The situation around info_cache and security_groups is a bit
confusing and inconsistent at the moment. Since some of the
""all"" queries don't join info_cache and security_groups,
avoid assuming that they are there, either triggering an
unintentional lazy load, or a KeyError in a few cases where the
DB API returns a dict.

Also, don't ever allow us to recurse into another instance object
looking for a loaded attribute in case it fails to load from the
get query.

Related to blueprint unified-object-model

Change-Id: I40b72274cd24034b03c8e07af56e7c8d49b6b898
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/37157/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/instance.py'],1,5654d920863d8885147dfec12855cd6197bae247,bp/unified-object-model," # NOTE(danms): info_cache and security_groups are almost # always joined in the DB layer right now, so check to see if # they are asked for and are present in the resulting object if 'info_cache' in expected_attrs and db_inst.get('info_cache'): if ('security_groups' in expected_attrs and db_inst.get('security_groups')): expected_attrs = ['info_cache', 'security_groups'] expected_attrs = ['info_cache', 'security_groups'] for field in INSTANCE_DEFAULT_FIELDS: # NOTE(danms): Never allow us to recursively-load if hasattr(instance, base.get_attrname(attrname)): self[attrname] = instance[attrname] else: raise Exception('Cannot load ""%s"" from instance' % attrname)"," # NOTE(danms): info_cache and security_groups are almost always joined # in the DB layer right now, so check to see if they're filled instead # of looking at expected_attrs if db_inst['info_cache']: if db_inst['security_groups']: expected_attrs = [] expected_attrs = [] for field in INSTANCE_OPTIONAL_FIELDS: self[attrname] = instance[attrname]",15,9
openstack%2Fnova~master~I3df462645979742379a41060cda5bb5084fddb20,openstack/nova,master,I3df462645979742379a41060cda5bb5084fddb20,Make Instance object properly update *metadata,MERGED,2013-07-15 20:51:00.000000000,2013-07-17 23:10:57.000000000,2013-07-17 23:10:54.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-15 20:51:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5a9cf2e85e4caf74975f74ba764de2ee80ae321', 'message': ""Make Instance object properly update *metadata\n\nCurrently, the Instance object won't notice when metadata or\nsystem_metadata has changed and thus won't include it in updates it\nmakes to the database.\n\nWe could make these two dicts full-fledged objects, but that's a bit\noverkill for this purpose. Stash a copy of them every time we reset\nour changes so that we can detect changes in save().\n\nRelated to blueprint unified-object-model\n\nChange-Id: I3df462645979742379a41060cda5bb5084fddb20\n""}, {'number': 2, 'created': '2013-07-16 23:43:19.000000000', 'files': ['nova/tests/objects/test_instance.py', 'nova/objects/instance.py', 'nova/tests/compute/test_shelve.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7a20e5581f7b33b730397c85ceed2f7825c6580d', 'message': ""Make Instance object properly update *metadata\n\nCurrently, the Instance object won't notice when metadata or\nsystem_metadata has changed and thus won't include it in updates it\nmakes to the database.\n\nWe could make these two dicts full-fledged objects, but that's a bit\noverkill for this purpose. Stash a copy of them every time we reset\nour changes so that we can detect changes in save().\n\nNote that this includes tests to some shelve tests which are now\nwrong because they modify the instance's sys_meta prematurely.\nTurns out, these are the tests that pointed out the need for\nthis tracking :)\n\nRelated to blueprint unified-object-model\nFixes bug 1201776\n\nChange-Id: I3df462645979742379a41060cda5bb5084fddb20\n""}]",0,37128,7a20e5581f7b33b730397c85ceed2f7825c6580d,12,5,2,4393,,,0,"Make Instance object properly update *metadata

Currently, the Instance object won't notice when metadata or
system_metadata has changed and thus won't include it in updates it
makes to the database.

We could make these two dicts full-fledged objects, but that's a bit
overkill for this purpose. Stash a copy of them every time we reset
our changes so that we can detect changes in save().

Note that this includes tests to some shelve tests which are now
wrong because they modify the instance's sys_meta prematurely.
Turns out, these are the tests that pointed out the need for
this tracking :)

Related to blueprint unified-object-model
Fixes bug 1201776

Change-Id: I3df462645979742379a41060cda5bb5084fddb20
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/37128/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_instance.py', 'nova/objects/instance.py']",2,a5a9cf2e85e4caf74975f74ba764de2ee80ae321,bp/unified-object-model," def __init__(self, *args, **kwargs): super(Instance, self).__init__(*args, **kwargs) self.obj_reset_changes() def obj_reset_changes(self, fields=None): super(Instance, self).obj_reset_changes(fields) self._orig_system_metadata = (dict(self.system_metadata) if 'system_metadata' in self else {}) self._orig_metadata = (dict(self.metadata) if 'metadata' in self else {}) def obj_what_changed(self): changes = super(Instance, self).obj_what_changed() if 'metadata' in self and self.metadata != self._orig_metadata: changes.add('metadata') if 'system_metadata' in self and (self.system_metadata != self._orig_system_metadata): changes.add('system_metadata') return changes ",,36,0
openstack%2Fdesignate~master~I3d307568230f61d105908540ae809d583b347e56,openstack/designate,master,I3d307568230f61d105908540ae809d583b347e56,Add 'Getting Started' Doc,MERGED,2013-07-17 21:23:39.000000000,2013-07-17 22:59:19.000000000,2013-07-17 22:59:19.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 2096}, {'_account_id': 8094}, {'_account_id': 8174}]","[{'number': 1, 'created': '2013-07-17 21:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/fc9ceefc903aaae2d83ba7d7ab5ca5ac8a4216c7', 'message': ""Add 'Getting Started' Doc\n\nAdd a 'Getting Started' page to the Documentation under\ndoc/source/gettingstarted.rst. Added a sample configuration file\nthat's referenced in the file under doc/examples.\n\nBug: 1201490\nChange-Id: I3d307568230f61d105908540ae809d583b347e56\n""}, {'number': 2, 'created': '2013-07-17 22:29:31.000000000', 'files': ['doc/examples/basic-config-sample.conf', 'doc/source/index.rst', 'doc/source/gettingstarted.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/5f2b5fe2668ed5c8bb86b60f9b69e7aba0ba23bd', 'message': ""Add 'Getting Started' Doc\n\nAdd a 'Getting Started' page to the Documentation under\ndoc/source/gettingstarted.rst. Added a sample configuration file\nthat's referenced in the file under doc/examples.\n\nBug: 1201490\nChange-Id: I3d307568230f61d105908540ae809d583b347e56\n""}]",1,37573,5f2b5fe2668ed5c8bb86b60f9b69e7aba0ba23bd,10,5,2,8174,,,0,"Add 'Getting Started' Doc

Add a 'Getting Started' page to the Documentation under
doc/source/gettingstarted.rst. Added a sample configuration file
that's referenced in the file under doc/examples.

Bug: 1201490
Change-Id: I3d307568230f61d105908540ae809d583b347e56
",git fetch https://review.opendev.org/openstack/designate refs/changes/73/37573/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/examples/basic-config-sample.conf', 'doc/source/gettingstarted.rst']",2,fc9ceefc903aaae2d83ba7d7ab5ca5ac8a4216c7,bug/1201490,".. Copyright 2013 Rackspace Hosting Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. .. _gettingstarted: ======================== Getting Started ======================== Designate provides DNS As A Service (DNSaaS) for OpenStack: - REST API for domain/record management - Multi-tenant - Integrated with Keystone for authentication - Framework in place to integrate with Nova and Quantum notifications (for auto-generated records) - Support for PowerDNS and Bind9 out of the box Designate is comprised of three components. For more info see :doc:`architecture`. This guide will show how to install a simple development environment for Designate, with a PowerDNS backend. You will be able to see Designate in action, although not to its full potential. For this guide you will need access to an Ubuntu Server (12.04). Development Environment +++++++++++++++++++++++ Installing Designate ==================== .. index:: double: install; designate 1. Install system package dependencies (Ubuntu) :: $ apt-get install python-pip python-virtualenv $ apt-get install rabbitmq-server $ apt-get build-dep python-lxml 2. Clone the Designate repo off of Stackforge :: $ git clone https://github.com/stackforge/designate.git $ cd designate 3. Setup virtualenv .. note:: This is to not interfere with system packages etc. :: $ virtualenv --no-site-packages .venv $ . .venv/bin/activate 4. Install Designate and its dependencies :: $ pip install -r requirements.txt -r test-requirements.txt $ python setup.py develop .. note:: Everything from here on out should take place in or below your designate/etc folder 5. Copy sample config files to edit :: $ cd etc/designate $ ls *.sample | while read f; do cp $f $(echo $f | sed ""s/.sample$//g""); done 6. Install the DNS server, PowerDNS :: $ DEBIAN_FRONTEND=noninteractive apt-get install pdns-server pdns-backend-sqlite3 #Update path to SQLite database to /root/designate/powerdns.sqlite or wherever your top level designate directory resides $ editor /etc/powerdns/pdns.d/pdns.local.gsqlite3 #Change the corresponding line in the config file to mirror: gsqlite3-database=/root/designate/powerdns.sqlite #Restart PowerDNS: $ service pdns restart 7. If you intend to run Designate as a non-root user, then sudo permissions need to be granted :: $ echo ""designate ALL=(ALL) NOPASSWD:ALL"" | sudo tee -a /etc/sudoers.d/90-designate $ sudo chmod 0440 /etc/sudoers.d/90-designate Configure Designate =================== .. index:: double: configure; designate :: $ editor designate.conf Copy or mirror the configuration from this sample file here: .. literalinclude:: ../examples/basic-config-sample.conf Initialize & Start the Central Service ====================================== .. index:: double: install; central :: #Initialize and sync the Designate database: $ designate-manage database-init $ designate-manage database-sync #Initialize and sync the PowerDNS database: $ designate-manage powerdns database-init $ designate-manage powerdns database-sync #Start the central service: $ designate-central .. note:: If you get an error of the form: ERROR [designate.openstack.common.rpc.common] AMQP server on localhost:5672 is unreachable: Socket closed Run the following command: :: $ rabbitmqctl change_password guest guest #Then try starting the service again $ designate-central You'll now be seeing the log from the central service. Initialize & Start the API Service ================================== .. index:: double: install; api Open up a new ssh window and log in to your server (or however you’re communicating with your server). :: $ cd root/designate #Make sure your virtualenv is sourced $ . .venv/bin/activate $ cd etc/designate #Start the API Service $ designate-api #You may have to run root/designate/bin/designate-api You’ll now be seeing the log from the API service. Exercising the API ================== Using a web browser, curl statement, or a Rest client calls can be made to the Designate API using the following format where “command” is any of the commands listed in the Designate Documentation_. .. _Documentation: http://designate.readthedocs.org/en/latest/rest.html http://IP.Address:9001/v1/command You can find the IP Address of your server by running :: wget http://ipecho.net/plain -O - -q ; echo If you’d like to see an instance in action, go here: http://166.78.183.212:9001/ A couple of notes on the API: - Before Domains are created, you must create a server. - On GET requests for domains, servers, records, etc be sure not to append a ‘/’ to the end of the request. For example …:9001/v1/servers/ ",,352,0
openstack%2Fkeystone~master~Ide8ab4ebf28d589c876940cf5cdc915e992a7d59,openstack/keystone,master,Ide8ab4ebf28d589c876940cf5cdc915e992a7d59,Match identity driver authenticate_user signature,ABANDONED,2013-07-02 17:56:23.000000000,2013-07-17 22:45:26.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-07-02 17:56:23.000000000', 'files': ['keystone/identity/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3b6ac9a94c721983624c835cf16d23f0cc13f611', 'message': 'Match identity driver authenticate_user signature\n\nThe identity driver base class defined authenticate_user like\n\n def authenticate_user(self, user_id, password):\n\nbut all the subclasses define it like\n\n def authenticate_user(self, user_id=None, password=None):\n\nThis change makes the base definition the same as the subclasses\nto help avoid confusion for those implementing their own driver.\n\nChange-Id: Ide8ab4ebf28d589c876940cf5cdc915e992a7d59\n'}]",0,35346,3b6ac9a94c721983624c835cf16d23f0cc13f611,8,6,1,6486,,,0,"Match identity driver authenticate_user signature

The identity driver base class defined authenticate_user like

 def authenticate_user(self, user_id, password):

but all the subclasses define it like

 def authenticate_user(self, user_id=None, password=None):

This change makes the base definition the same as the subclasses
to help avoid confusion for those implementing their own driver.

Change-Id: Ide8ab4ebf28d589c876940cf5cdc915e992a7d59
",git fetch https://review.opendev.org/openstack/keystone refs/changes/46/35346/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/identity/core.py'],1,3b6ac9a94c721983624c835cf16d23f0cc13f611,signature_match," def authenticate_user(self, user_id=None, password=None):"," def authenticate_user(self, user_id, password):",1,1
openstack%2Fkeystone~master~Ia534b0e2ad67c3a2924f55a43655e2925f01d06f,openstack/keystone,master,Ia534b0e2ad67c3a2924f55a43655e2925f01d06f,Match identity driver authorize_for_project signature,ABANDONED,2013-07-02 17:45:11.000000000,2013-07-17 22:34:40.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-07-02 17:45:11.000000000', 'files': ['keystone/identity/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c0bce1d3d8fa227c8079f32e80123fd50b14b647', 'message': 'Match identity driver authorize_for_project signature\n\nThe identity driver base class defined authorize_for_project like\n\n def authorize_for_project(self, tenant_id, user_ref):\n\nbut all the subclasses define it like\n\n def authorize_for_project(self, user_ref, tenant_id=None):\n\nThis change makes the base definition the same as the subclasses\nto help avoid confusion for those implementing their own driver.\n\nChange-Id: Ia534b0e2ad67c3a2924f55a43655e2925f01d06f\n'}]",2,35342,c0bce1d3d8fa227c8079f32e80123fd50b14b647,8,6,1,6486,,,0,"Match identity driver authorize_for_project signature

The identity driver base class defined authorize_for_project like

 def authorize_for_project(self, tenant_id, user_ref):

but all the subclasses define it like

 def authorize_for_project(self, user_ref, tenant_id=None):

This change makes the base definition the same as the subclasses
to help avoid confusion for those implementing their own driver.

Change-Id: Ia534b0e2ad67c3a2924f55a43655e2925f01d06f
",git fetch https://review.opendev.org/openstack/keystone refs/changes/42/35342/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/identity/core.py'],1,c0bce1d3d8fa227c8079f32e80123fd50b14b647,signature_match," def authorize_for_project(self, user_ref, tenant_id=None):"," def authorize_for_project(self, tenant_id, user_ref):",1,1
openstack%2Fcinder~master~I668fd659830bd6d410be64a1f5116377b08a9e96,openstack/cinder,master,I668fd659830bd6d410be64a1f5116377b08a9e96,Fix extend_volume error handling.,MERGED,2013-07-17 11:39:36.000000000,2013-07-17 22:24:01.000000000,2013-07-17 22:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2166}, {'_account_id': 2243}]","[{'number': 1, 'created': '2013-07-17 11:39:36.000000000', 'files': ['cinder/volume/manager.py', 'cinder/tests/test_volume.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/74960fb8de3a84d0f3a5a56f15143647b4182f01', 'message': 'Fix extend_volume error handling.\n\nIf the async call to the manager/driver failed, the API still updated\nthe quota and volume size in the DB. Solution is to move these tasks\ndown to the manager, where we know if the extend succeeded.\n\nChange-Id: I668fd659830bd6d410be64a1f5116377b08a9e96\nFixes: bug 1201814\n'}]",0,37450,74960fb8de3a84d0f3a5a56f15143647b4182f01,7,4,1,4355,,,0,"Fix extend_volume error handling.

If the async call to the manager/driver failed, the API still updated
the quota and volume size in the DB. Solution is to move these tasks
down to the manager, where we know if the extend succeeded.

Change-Id: I668fd659830bd6d410be64a1f5116377b08a9e96
Fixes: bug 1201814
",git fetch https://review.opendev.org/openstack/cinder refs/changes/50/37450/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/tests/test_volume.py', 'cinder/volume/api.py']",3,74960fb8de3a84d0f3a5a56f15143647b4182f01,bug/1201814," self.volume_rpcapi.extend_volume(context, volume, new_size)"," try: reservations = QUOTAS.reserve(context, gigabytes=+size_increase) except exception.OverQuota as exc: overs = exc.kwargs['overs'] usages = exc.kwargs['usages'] quotas = exc.kwargs['quotas'] def _consumed(name): return (usages[name]['reserved'] + usages[name]['in_use']) if 'gigabytes' in overs: msg = _(""Quota exceeded for %(s_pid)s, "" ""tried to extend volume by "" ""%(s_size)sG, (%(d_consumed)dG of %(d_quota)dG "" ""already consumed)"") LOG.warn(msg % {'s_pid': context.project_id, 's_size': size_increase, 'd_consumed': _consumed('gigabytes'), 'd_quota': quotas['gigabytes']}) raise exception.VolumeSizeExceedsAvailableQuota() try: self.volume_rpcapi.extend_volume(context, volume, new_size) except Exception: with excutils.save_and_reraise_exception(): try: self.update(context, volume, {'status': 'error_extending'}) finally: QUOTAS.rollback(context, reservations) self.update(context, volume, {'size': new_size}) QUOTAS.commit(context, reservations) self.update(context, volume, {'status': 'available'})",89,41
openstack%2Fnova~master~I4901fb937160e955df7c97c37265783e844fdbef,openstack/nova,master,I4901fb937160e955df7c97c37265783e844fdbef,Update instance.node on evacuate,MERGED,2013-07-05 18:21:12.000000000,2013-07-17 22:07:42.000000000,2013-07-17 22:07:40.000000000,"[{'_account_id': 3}, {'_account_id': 191}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 5046}, {'_account_id': 5511}, {'_account_id': 6873}]","[{'number': 1, 'created': '2013-07-05 18:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d00e707eca052399eb6e9856d81d699212e62e7d', 'message': ""Instance node not updated on evacuate\n\nThe evacuate API works like a migration from a dead node. As part of\nmigration, the instance.node property is updated to reflect the target\nnode that the instance is migrating to. This is later used when the\nmigration is confirmed/reverted.  The problem is when an instance is\nbeing evacuated, the node property isn't getting updated and the\ninstance will have the old (dead) node value set on it after it's\nevacuated.  This patch updates instance.node when the instance is\nevacuated.\n\nFixes bug 1198284\n\nChange-Id: I4901fb937160e955df7c97c37265783e844fdbef\n""}, {'number': 2, 'created': '2013-07-06 01:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8573ba48e924f18a71c28721b17c6eb2bd01fce2', 'message': ""Update instance.node on evacuate\n\nThe evacuate API works like a migration from a dead node. As part of\nmigration, the instance.node property is updated to reflect the target\nnode that the instance is migrating to. This is later used when the\nmigration is confirmed/reverted. The problem is when an instance is\nbeing evacuated, the node property isn't getting updated and the\ninstance will have the old (dead) node value set on it after it's\nevacuated. This patch updates instance.node when the instance is\nevacuated.\n\nFixes bug 1198284\n\nChange-Id: I4901fb937160e955df7c97c37265783e844fdbef\n""}, {'number': 3, 'created': '2013-07-06 20:18:58.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3da3dfb733237ed2c908d8770961d8d6656ea1a3', 'message': ""Update instance.node on evacuate\n\nThe evacuate API works like a migration from a dead node. As part of\nmigration, the instance.node property is updated to reflect the target\nnode that the instance is migrating to. This is later used when the\nmigration is confirmed/reverted. The problem is when an instance is\nbeing evacuated, the node property isn't getting updated and the\ninstance will have the old (dead) node value set on it after it's\nevacuated. This patch updates instance.node when the instance is\nevacuated.\n\nFixes bug 1198284\n\nChange-Id: I4901fb937160e955df7c97c37265783e844fdbef\n""}]",2,35851,3da3dfb733237ed2c908d8770961d8d6656ea1a3,19,7,3,6873,,,0,"Update instance.node on evacuate

The evacuate API works like a migration from a dead node. As part of
migration, the instance.node property is updated to reflect the target
node that the instance is migrating to. This is later used when the
migration is confirmed/reverted. The problem is when an instance is
being evacuated, the node property isn't getting updated and the
instance will have the old (dead) node value set on it after it's
evacuated. This patch updates instance.node when the instance is
evacuated.

Fixes bug 1198284

Change-Id: I4901fb937160e955df7c97c37265783e844fdbef
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/35851/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,d00e707eca052399eb6e9856d81d699212e62e7d,bug/1198284," context, instance['uuid'], host=self.host, node=self.driver.get_available_nodes()[0])"," context, instance['uuid'], host=self.host)",2,1
openstack%2Ftempest~master~Iedc9bd92b8f8471c60c614c7d7c05046d7b32743,openstack/tempest,master,Iedc9bd92b8f8471c60c614c7d7c05046d7b32743,Switch to using testr as the test runner for everything non-gating.,MERGED,2013-07-11 17:54:23.000000000,2013-07-17 22:07:37.000000000,2013-07-17 22:07:37.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-07-11 17:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3edad257dde5c71d2d957f1c1d4d22809fa8615f', 'message': ""Switch to using testr as the test runner for everything non-gating.\n\nThis commit switches the test runner in tempest to testr from nose for all\njobs that aren't gating. This will allow the usage of parallel testing with\nthe use of a group_regex in testr. Group_regex will ensure that the classes\nget scheduled together and the run times are tracked together. Than the\ntools/run_test_classes.py script will filter the test_ids and pass only the\nclasses to subunit.run to ensure we are only running setupClass once.\n\nIt also adds a testr-full tox job so we can have a tracking non-voting job\nthat runs the same tests as the gate but with testr.\n\nChange-Id: Iedc9bd92b8f8471c60c614c7d7c05046d7b32743\n""}, {'number': 2, 'created': '2013-07-11 20:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ee09c9cd005da5310e215519ab7380b75fcabeb1', 'message': ""Switch to using testr as the test runner for everything non-gating.\n\nThis commit switches the test runner in tempest to testr from nose for all\njobs that aren't gating. This will allow the usage of parallel testing with\nthe use of a group_regex in testr. Group_regex will ensure that the classes\nget scheduled together and the run times are tracked together. Than the\ntools/run_test_classes.py script will filter the test_ids and pass only the\nclasses to subunit.run to ensure we are only running setupClass once.\n\nIt also adds a testr-full tox job so we can have a tracking non-voting job\nthat runs the same tests as the gate but with testr.\n\nImplements: blueprint speed-up-tempest\n\nChange-Id: Iedc9bd92b8f8471c60c614c7d7c05046d7b32743\n""}, {'number': 3, 'created': '2013-07-17 13:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fce7b48def01d8db74596a778cc48d2f1b5db198', 'message': ""Switch to using testr as the test runner for everything non-gating.\n\nThis commit switches the test runner in tempest to testr from nose for all\njobs that aren't gating. This will allow the usage of parallel testing with\nthe use of a group_regex in testr. Group_regex will ensure that the classes\nget scheduled together and the run times are tracked together. Than the\ntools/run_test_classes.py script will filter the test_ids and pass only the\nclasses to subunit.run to ensure we are only running setupClass once.\n\nIt also adds a testr-full tox job so we can have a tracking non-voting job\nthat runs the same tests as the gate but with testr.\n\nImplements: blueprint speed-up-tempest\n\nChange-Id: Iedc9bd92b8f8471c60c614c7d7c05046d7b32743\n""}, {'number': 4, 'created': '2013-07-17 17:35:40.000000000', 'files': ['run_tests.sh', 'tools/run_test_classes.py', '.testr.conf', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/87af1bbfb27085d7c9dce3bcf21d0422d7a22bc1', 'message': ""Switch to using testr as the test runner for everything non-gating.\n\nThis commit switches the test runner in tempest to testr from nose for all\njobs that aren't gating. This will allow the usage of parallel testing with\nthe use of a group_regex in testr. Group_regex will ensure that the classes\nget scheduled together and the run times are tracked together. Than the\ntools/run_test_classes.py script will filter the test_ids and pass only the\nclasses to subunit.run to ensure we are only running setupClass once.\n\nThis commit also adds a new option to run_tests.sh. -t/--with-testr can be\nused to optionally run tempest in parallel with testr. Once running with\ntestr gets stable enough this will become the default for run_tests.\n\nIt also adds a testr-full tox job so we can have a tracking non-voting job\nthat runs the same tests as the gate but with testr.\n\nImplements: blueprint speed-up-tempest\n\nChange-Id: Iedc9bd92b8f8471c60c614c7d7c05046d7b32743\n""}]",1,36702,87af1bbfb27085d7c9dce3bcf21d0422d7a22bc1,19,5,4,5196,,,0,"Switch to using testr as the test runner for everything non-gating.

This commit switches the test runner in tempest to testr from nose for all
jobs that aren't gating. This will allow the usage of parallel testing with
the use of a group_regex in testr. Group_regex will ensure that the classes
get scheduled together and the run times are tracked together. Than the
tools/run_test_classes.py script will filter the test_ids and pass only the
classes to subunit.run to ensure we are only running setupClass once.

This commit also adds a new option to run_tests.sh. -t/--with-testr can be
used to optionally run tempest in parallel with testr. Once running with
testr gets stable enough this will become the default for run_tests.

It also adds a testr-full tox job so we can have a tracking non-voting job
that runs the same tests as the gate but with testr.

Implements: blueprint speed-up-tempest

Change-Id: Iedc9bd92b8f8471c60c614c7d7c05046d7b32743
",git fetch https://review.opendev.org/openstack/tempest refs/changes/02/36702/4 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', '.testr.conf', 'tools/run_test_classes.py', 'tox.ini']",4,3edad257dde5c71d2d957f1c1d4d22809fa8615f,bp/speed-up-tempest, LANG=en_US.UTF-8 LANGUAGE=en_US:en LC_ALL=C testr run --parallel [testenv:testr-full] sitepackages = True setenv = VIRTUAL_ENV={envdir} commands = testr run --parallel tempest.api tempest.scenario tempest.thirdparty tempest.cli testr run --parallel smoke testr run --parallel tempest.api tempest.scenario tempest.thirdparty tempest.cli, NOSE_WITH_OPENSTACK=1 NOSE_OPENSTACK_COLOR=1 NOSE_OPENSTACK_RED=15 NOSE_OPENSTACK_YELLOW=3 NOSE_OPENSTACK_SHOW_ELAPSED=1 NOSE_OPENSTACK_STDOUT=1 NOSE_WITH_OPENSTACK=1 NOSE_OPENSTACK_COLOR=1 NOSE_OPENSTACK_RED=15 NOSE_OPENSTACK_YELLOW=3 NOSE_OPENSTACK_SHOW_ELAPSED=1 NOSE_OPENSTACK_STDOUT=1 nosetests --logging-format '%(asctime)-15s %(message)s' --with-xunit --xunit-file=nosetests-all.xml -sv tempest NOSE_WITH_OPENSTACK=1 NOSE_OPENSTACK_COLOR=1 NOSE_OPENSTACK_RED=15 NOSE_OPENSTACK_YELLOW=3 NOSE_OPENSTACK_SHOW_ELAPSED=1 NOSE_OPENSTACK_STDOUT=1 nosetests --logging-format '%(asctime)-15s %(message)s' --with-xunit -sv --attr=type=smoke --xunit-file=nosetests-smoke.xml tempest NOSE_WITH_OPENSTACK=1 NOSE_OPENSTACK_COLOR=1 NOSE_OPENSTACK_RED=15 NOSE_OPENSTACK_YELLOW=3 NOSE_OPENSTACK_SHOW_ELAPSED=1 NOSE_OPENSTACK_STDOUT=1 nosetests --logging-format '%(asctime)-15s %(message)s' --with-xunit --xunit-file=nosetests-full.xml -sv tempest/api tempest/scenario tempest/thirdparty tempest/cli,92,54
openstack%2Ftempest~master~Idadf08e0cc3f01650e72ca078a223781a0f1669a,openstack/tempest,master,Idadf08e0cc3f01650e72ca078a223781a0f1669a,Fix stress-tox-job.json action file.,MERGED,2013-07-17 17:43:42.000000000,2013-07-17 22:07:36.000000000,2013-07-17 22:07:36.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-07-17 17:43:42.000000000', 'files': ['tempest/stress/etc/stress-tox-job.json'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4909379765552c2599590659b211ce66a9056521', 'message': 'Fix stress-tox-job.json action file.\n\nChange I39b8a1d38f70ddda4867126b58bb7053b45654d6 changed how the\nactions are called, but stress-tox-job.json was merged at the same\ntime. This commit updates the json definition to use the new paths\nso that the tox job will work again.\n\nPart of: blueprint stress-tests\n\nChange-Id: Idadf08e0cc3f01650e72ca078a223781a0f1669a\n'}]",0,37541,4909379765552c2599590659b211ce66a9056521,7,4,1,5196,,,0,"Fix stress-tox-job.json action file.

Change I39b8a1d38f70ddda4867126b58bb7053b45654d6 changed how the
actions are called, but stress-tox-job.json was merged at the same
time. This commit updates the json definition to use the new paths
so that the tox job will work again.

Part of: blueprint stress-tests

Change-Id: Idadf08e0cc3f01650e72ca078a223781a0f1669a
",git fetch https://review.opendev.org/openstack/tempest refs/changes/41/37541/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/stress/etc/stress-tox-job.json'],1,4909379765552c2599590659b211ce66a9056521,bp/stress-tests,"[{""action"": ""tempest.stress.actions.create_destroy_server.CreateDestroyServerTest"", {""action"": ""tempest.stress.actions.volume_create_delete.CreateDeleteTest"",","[{""action"": ""tempest.stress.actions.create_destroy_server.create_destroy"", {""action"": ""tempest.stress.actions.volume_create_delete.create_delete"",",2,2
openstack%2Fnova~master~I91e083b412428f90f62c40eb8f47523b48830322,openstack/nova,master,I91e083b412428f90f62c40eb8f47523b48830322,Remove duplicate cells_rpcapi test.,MERGED,2013-07-17 19:58:17.000000000,2013-07-17 21:58:37.000000000,2013-07-17 21:58:35.000000000,"[{'_account_id': 3}, {'_account_id': 191}, {'_account_id': 679}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-07-17 19:58:17.000000000', 'files': ['nova/tests/cells/test_cells_rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9b06817fe0ec8ab1d7de2bde405345589fbadcd5', 'message': 'Remove duplicate cells_rpcapi test.\n\nThe same test was defined twice.  This removes the second instance of\nit.\n\nChange-Id: I91e083b412428f90f62c40eb8f47523b48830322\n'}]",0,37558,9b06817fe0ec8ab1d7de2bde405345589fbadcd5,7,4,1,5441,,,0,"Remove duplicate cells_rpcapi test.

The same test was defined twice.  This removes the second instance of
it.

Change-Id: I91e083b412428f90f62c40eb8f47523b48830322
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/37558/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/cells/test_cells_rpcapi.py'],1,9b06817fe0ec8ab1d7de2bde405345589fbadcd5,duplicate_test,," def test_cell_delete(self): call_info = self._stub_rpc_method('call', 'fake_response') result = self.cells_rpcapi.cell_delete(self.fake_context, 'cell_name') expected_args = {'cell_name': 'cell_name'} self._check_result(call_info, 'cell_delete', expected_args, version='1.13') self.assertEqual(result, 'fake_response') ",0,11
openstack%2Fneutron~master~I93e642a3669423e4e1b173d258af21796ef11e93,openstack/neutron,master,I93e642a3669423e4e1b173d258af21796ef11e93,temp backup,ABANDONED,2013-07-16 23:25:36.000000000,2013-07-17 21:46:47.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}]","[{'number': 1, 'created': '2013-07-16 23:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f7242f4606299879f6a6c974d795ad935b2485e', 'message': 'temp backup\n\nChange-Id: I93e642a3669423e4e1b173d258af21796ef11e93\n'}, {'number': 2, 'created': '2013-07-17 19:29:18.000000000', 'files': ['etc/neutron/rootwrap.d/dhcp.filters', 'neutron/agent/dhcp_agent.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/models_v2.py', 'neutron/db/dhcp_rpc_base.py', 'neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py', 'neutron/tests/unit/test_dhcp_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d78eda68c0479aed9b578ea52853732b06af80b', 'message': 'temp backup\n\nChange-Id: I93e642a3669423e4e1b173d258af21796ef11e93\n'}]",0,37349,7d78eda68c0479aed9b578ea52853732b06af80b,6,2,2,4395,,,0,"temp backup

Change-Id: I93e642a3669423e4e1b173d258af21796ef11e93
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/37349/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron/rootwrap.d/dhcp.filters', 'neutron/agent/dhcp_agent.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/models_v2.py', 'neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py', 'neutron/tests/unit/test_dhcp_agent.py']",8,2f7242f4606299879f6a6c974d795ad935b2485e,master," with mock.patch.object(sys, 'argv') as sys_argv: sys_argv.return_value = [ 'dhcp', '--config-file', etcdir('neutron.conf.test')] cfg.CONF.register_opts(dhcp_agent.DhcpAgent.OPTS) config.register_agent_state_opts_helper(cfg.CONF) config.register_root_helper(cfg.CONF) cfg.CONF.register_opts( dhcp_agent.DeviceManager.OPTS) cfg.CONF.register_opts(dhcp.OPTS) cfg.CONF.register_opts(interface.OPTS) cfg.CONF(project='neutron') agent_mgr = DhcpAgentWithStateReport('testhost') eventlet.greenthread.sleep(1) agent_mgr.after_start() mock_sync_state.assert_called_once_with(agent_mgr) mock_periodic_resync.assert_called_once_with(agent_mgr) state_rpc.assert_has_calls( [mock.call(mock.ANY), mock.call().report_state(mock.ANY, mock.ANY, mock.ANY)]) ['sync_state', 'periodic_resync']]) mock.ANY, None) mock.ANY, None)# def test_port_delete_end(self): # payload = dict(port_id=fake_port2.id) # self.cache.get_network_by_id.return_value = fake_network # self.cache.get_port_by_id.return_value = fake_port2 # # self.dhcp.port_delete_end(None, payload) # # self.cache.assert_has_calls( # [mock.call.get_port_by_id(fake_port2.id), # mock.call.get_network_by_id(fake_network.id), # mock.call.remove_port(fake_port2)]) # self.call_driver.assert_called_once_with('release_lease', # fake_network) # self.call_driver.assert_called_once_with('reload_allocations', # fake_network)","import socketfrom neutron.openstack.common import jsonutils lease_relay_str = 'neutron.agent.dhcp_agent.DhcpLeaseRelay' with mock.patch(lease_relay_str) as mock_lease_relay: with mock.patch.object(sys, 'argv') as sys_argv: sys_argv.return_value = [ 'dhcp', '--config-file', etcdir('neutron.conf.test')] cfg.CONF.register_opts(dhcp_agent.DhcpAgent.OPTS) config.register_agent_state_opts_helper(cfg.CONF) config.register_root_helper(cfg.CONF) cfg.CONF.register_opts( dhcp_agent.DeviceManager.OPTS) cfg.CONF.register_opts( dhcp_agent.DhcpLeaseRelay.OPTS) cfg.CONF.register_opts(dhcp.OPTS) cfg.CONF.register_opts(interface.OPTS) cfg.CONF(project='neutron') agent_mgr = DhcpAgentWithStateReport('testhost') eventlet.greenthread.sleep(1) agent_mgr.after_start() mock_sync_state.assert_called_once_with(agent_mgr) mock_periodic_resync.assert_called_once_with( agent_mgr) state_rpc.assert_has_calls( [mock.call(mock.ANY), mock.call().report_state(mock.ANY, mock.ANY, mock.ANY)]) mock_lease_relay.assert_has_calls( [mock.call(mock.ANY), mock.call().start()]) ['sync_state', 'lease_relay', 'periodic_resync']]) mocks['lease_relay'].assert_has_mock_calls( [mock.call.start()]) mock.ANY) mock.ANY) def test_update_lease(self): with mock.patch('neutron.agent.dhcp_agent.DhcpPluginApi') as plug: dhcp = dhcp_agent.DhcpAgent(HOSTNAME) dhcp.update_lease('net_id', '192.168.1.1', 120) plug.assert_has_calls( [mock.call().update_lease_expiration( 'net_id', '192.168.1.1', 120)]) def test_update_lease_failure(self): with mock.patch('neutron.agent.dhcp_agent.DhcpPluginApi') as plug: plug.return_value.update_lease_expiration.side_effect = Exception with mock.patch.object(dhcp_agent.LOG, 'exception') as log: dhcp = dhcp_agent.DhcpAgent(HOSTNAME) dhcp.update_lease('net_id', '192.168.1.1', 120) plug.assert_has_calls( [mock.call().update_lease_expiration( 'net_id', '192.168.1.1', 120)]) self.assertTrue(log.called) self.assertTrue(dhcp.needs_resync) cfg.CONF.register_opts(dhcp_agent.DhcpLeaseRelay.OPTS) def test_port_delete_end(self): payload = dict(port_id=fake_port2.id) self.cache.get_network_by_id.return_value = fake_network self.cache.get_port_by_id.return_value = fake_port2 self.dhcp.port_delete_end(None, payload) self.cache.assert_has_calls( [mock.call.get_port_by_id(fake_port2.id), mock.call.get_network_by_id(fake_network.id), mock.call.remove_port(fake_port2)]) self.call_driver.assert_called_once_with('reload_allocations', fake_network) def test_update_lease_expiration(self): with mock.patch.object(self.proxy, 'cast') as mock_cast: self.proxy.update_lease_expiration('netid', 'ipaddr', 1) self.assertTrue(mock_cast.called) self.make_msg.assert_called_once_with('update_lease_expiration', network_id='netid', ip_address='ipaddr', lease_remaining=1, host='foo') class TestDhcpLeaseRelay(base.BaseTestCase): def setUp(self): super(TestDhcpLeaseRelay, self).setUp() cfg.CONF.register_opts(dhcp_agent.DhcpLeaseRelay.OPTS) self.unlink_p = mock.patch('os.unlink') self.unlink = self.unlink_p.start() def tearDown(self): self.unlink_p.stop() super(TestDhcpLeaseRelay, self).tearDown() def test_init_relay_socket_path_no_prev_socket(self): with mock.patch('os.path.exists') as exists: exists.return_value = False self.unlink.side_effect = OSError dhcp_agent.DhcpLeaseRelay(None) self.unlink.assert_called_once_with( cfg.CONF.dhcp_lease_relay_socket) exists.assert_called_once_with(cfg.CONF.dhcp_lease_relay_socket) def test_init_relay_socket_path_prev_socket_exists(self): with mock.patch('os.path.exists') as exists: exists.return_value = False dhcp_agent.DhcpLeaseRelay(None) self.unlink.assert_called_once_with( cfg.CONF.dhcp_lease_relay_socket) self.assertFalse(exists.called) def test_init_relay_socket_path_prev_socket_unlink_failure(self): self.unlink.side_effect = OSError with mock.patch('os.path.exists') as exists: exists.return_value = True with testtools.ExpectedException(OSError): dhcp_agent.DhcpLeaseRelay(None) self.unlink.assert_called_once_with( cfg.CONF.dhcp_lease_relay_socket) exists.assert_called_once_with( cfg.CONF.dhcp_lease_relay_socket) def test_handler_valid_data(self): network_id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' ip_address = '192.168.1.9' lease_remaining = 120 json_rep = jsonutils.dumps(dict(network_id=network_id, lease_remaining=lease_remaining, ip_address=ip_address)) handler = mock.Mock() mock_sock = mock.Mock() mock_sock.recv.return_value = json_rep relay = dhcp_agent.DhcpLeaseRelay(handler) relay._handler(mock_sock, mock.Mock()) mock_sock.assert_has_calls([mock.call.recv(1024), mock.call.close()]) handler.called_once_with(network_id, ip_address, lease_remaining) def test_handler_invalid_data(self): network_id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' ip_address = '192.168.x.x' lease_remaining = 120 json_rep = jsonutils.dumps( dict(network_id=network_id, lease_remaining=lease_remaining, ip_address=ip_address)) handler = mock.Mock() mock_sock = mock.Mock() mock_sock.recv.return_value = json_rep relay = dhcp_agent.DhcpLeaseRelay(handler) with mock.patch('neutron.openstack.common.' 'uuidutils.is_uuid_like') as validate: validate.return_value = False with mock.patch.object(dhcp_agent.LOG, 'warn') as log: relay._handler(mock_sock, mock.Mock()) mock_sock.assert_has_calls( [mock.call.recv(1024), mock.call.close()]) self.assertFalse(handler.called) self.assertTrue(log.called) def test_handler_other_exception(self): handler = mock.Mock() mock_sock = mock.Mock() mock_sock.recv.side_effect = Exception relay = dhcp_agent.DhcpLeaseRelay(handler) with mock.patch.object(dhcp_agent.LOG, 'exception') as log: relay._handler(mock_sock, mock.Mock()) mock_sock.assert_has_calls([mock.call.recv(1024)]) self.assertFalse(handler.called) self.assertTrue(log.called) def test_start(self): with mock.patch.object(dhcp_agent, 'eventlet') as mock_eventlet: handler = mock.Mock() relay = dhcp_agent.DhcpLeaseRelay(handler) relay.start() mock_eventlet.assert_has_calls( [mock.call.listen(cfg.CONF.dhcp_lease_relay_socket, family=socket.AF_UNIX), mock.call.spawn(mock_eventlet.serve, mock.call.listen.return_value, relay._handler)]) ",76,459
openstack%2Fpuppet-cinder~master~I87693a2d767e6b319489eaa76fbf85fdc86c951a,openstack/puppet-cinder,master,I87693a2d767e6b319489eaa76fbf85fdc86c951a,Fix cinder::rabbitmq rspec tests,MERGED,2013-07-17 21:29:22.000000000,2013-07-17 21:44:48.000000000,2013-07-17 21:44:48.000000000,"[{'_account_id': 3}, {'_account_id': 2265}]","[{'number': 1, 'created': '2013-07-17 21:29:22.000000000', 'files': ['spec/classes/cinder_rabbitmq_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/86cc398cc2e8e3ec88409f1d0f970acec4ec63ba', 'message': 'Fix cinder::rabbitmq rspec tests\n\n$::osfamily fact is now required by puppetlabs-rabbitmq.\n\nChange-Id: I87693a2d767e6b319489eaa76fbf85fdc86c951a\n'}]",0,37577,86cc398cc2e8e3ec88409f1d0f970acec4ec63ba,5,2,1,7156,,,0,"Fix cinder::rabbitmq rspec tests

$::osfamily fact is now required by puppetlabs-rabbitmq.

Change-Id: I87693a2d767e6b319489eaa76fbf85fdc86c951a
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/77/37577/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/cinder_rabbitmq_spec.rb'],1,86cc398cc2e8e3ec88409f1d0f970acec4ec63ba,fix_rabbitmq_tests," { :puppetversion => '2.7', :osfamily => 'Debian', }", {:puppetversion => '2.7'},3,1
openstack%2Fdiskimage-builder~master~I27f5de6ceaa4e9c6390721b7c434fe0908df84f5,openstack/diskimage-builder,master,I27f5de6ceaa4e9c6390721b7c434fe0908df84f5,Document an interface for offline operation.,MERGED,2013-07-17 21:40:46.000000000,2013-07-17 21:40:46.000000000,2013-07-17 21:40:46.000000000,"[{'_account_id': 3}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-17 21:40:46.000000000', 'files': ['bin/disk-image-create', 'lib/common-defaults', 'README.md'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b2f1d4e2af01c60e24980ef885355d676959c0a1', 'message': ""Document an interface for offline operation.\n\nComplex image builds can download hundreds of MB of data from the\ninternet with many separate lookups. It would be nice to allow users\nto ask for a fast build where those lookups are entirely avoided,\nusing locally cached resources (where possible). This new interface\nallows users to signal to elements that they wish to operate without\nupdating cached resources, which will in turn allow us to avoid\nchecking for stale data at all.\n\nAs part of this I've also documented where we cache data, so that\nthings like the ccache cache dir and image cache files are not a\nsurprise to users.\n\nChange-Id: I27f5de6ceaa4e9c6390721b7c434fe0908df84f5\n""}]",3,37572,b2f1d4e2af01c60e24980ef885355d676959c0a1,6,2,1,4190,,,0,"Document an interface for offline operation.

Complex image builds can download hundreds of MB of data from the
internet with many separate lookups. It would be nice to allow users
to ask for a fast build where those lookups are entirely avoided,
using locally cached resources (where possible). This new interface
allows users to signal to elements that they wish to operate without
updating cached resources, which will in turn allow us to avoid
checking for stale data at all.

As part of this I've also documented where we cache data, so that
things like the ccache cache dir and image cache files are not a
surprise to users.

Change-Id: I27f5de6ceaa4e9c6390721b7c434fe0908df84f5
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/72/37572/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/disk-image-create', 'lib/common-defaults', 'README.md']",3,b2f1d4e2af01c60e24980ef885355d676959c0a1,,"Caches and offline mode ======================= Since retrieving and transforming operating system image files, git repositories, Python or Ruby packages, and so on can be a significant overhead, we cache many of the inputs to the build process in ~/.cache/image-create/. The writing an element documention describes the interface within disk-image-builder for caching. When invoking disk-image-builder the --offline option will instruct disk-image-builder to not refresh cached resources. Note that we don't maintain operating system package caches, instead depending on your local infrastructure (e.g. Squid cache, or an APT or Yum proxy) to facilitate caching of that layer, so you need to arrange independently for offline mode. Global image-build variables ---------------------------- * DIB\_OFFLINE : this is always set. When not empty, any operations that perform remote data access should avoid it if possible. If not possible the operation should still be attempted as the user may have an external cache able to keep the operation functional. ",,26,0
openstack%2Fnova~master~Id262c297cdd3c12f74395fcae645c2ed34f09664,openstack/nova,master,Id262c297cdd3c12f74395fcae645c2ed34f09664,Remove duplicate option osapi_hide_server_address_states,ABANDONED,2013-07-17 09:23:37.000000000,2013-07-17 21:38:31.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-07-17 09:23:37.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/hide_server_addresses.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/04eb065dffa02706859361f9a48ec94f2d11449b', 'message': 'Remove duplicate option osapi_hide_server_address_states\n\nChange-Id: Id262c297cdd3c12f74395fcae645c2ed34f09664\n'}]",0,37433,04eb065dffa02706859361f9a48ec94f2d11449b,4,3,1,1669,,,0,"Remove duplicate option osapi_hide_server_address_states

Change-Id: Id262c297cdd3c12f74395fcae645c2ed34f09664
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/37433/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/plugins/v3/hide_server_addresses.py'],1,04eb065dffa02706859361f9a48ec94f2d11449b,jd/check-config-uptodate,"CONF.import_opt('osapi_hide_server_address_states', 'nova.api.openstack.compute.contrib.hide_server_addresses')","opts = [ cfg.ListOpt('osapi_hide_server_address_states', default=[vm_states.BUILDING], help='List of instance states that should hide network info'), ] CONF.register_opts(opts)",2,8
openstack%2Fceilometer~master~I0fcdc1944ea12d0e997627c5740b57a0bd58dbe8,openstack/ceilometer,master,I0fcdc1944ea12d0e997627c5740b57a0bd58dbe8,Standardize on X-Project-Id over X-Tenant-Id.,MERGED,2013-07-17 15:35:36.000000000,2013-07-17 21:26:05.000000000,2013-07-17 21:26:05.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-07-17 15:35:36.000000000', 'files': ['tests/api/v1/list_events.py', 'tests/api/v1/list_projects.py', 'tests/api/v1/max_resource_volume.py', 'ceilometer/api/acl.py', 'tests/api/v1/sum_project_volume.py', 'tests/api/v1/list_resources.py', 'tests/api/v1/sum_resource_volume.py', 'tests/api/v2/acl.py', 'tests/api/v2/post_samples.py', 'tests/api/v1/list_users.py', 'tests/api/v2/list_resources.py', 'tests/api/v1/max_project_volume.py', 'tests/api/v1/list_meters.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/80afaac4b6e7a2da926189c220f4fbda92a458b9', 'message': 'Standardize on X-Project-Id over X-Tenant-Id.\n\nBoth X-Project-Id and X-Tenant-Id headers are set to the\nsame value by the keystoneclient authtoken middleware.\n\nHowever the latter is deprecated, so instead of referring to\na mix of the two headers, we standardize on X-Project-Id.\n\nChange-Id: I0fcdc1944ea12d0e997627c5740b57a0bd58dbe8\n'}]",0,37501,80afaac4b6e7a2da926189c220f4fbda92a458b9,6,3,1,2284,,,0,"Standardize on X-Project-Id over X-Tenant-Id.

Both X-Project-Id and X-Tenant-Id headers are set to the
same value by the keystoneclient authtoken middleware.

However the latter is deprecated, so instead of referring to
a mix of the two headers, we standardize on X-Project-Id.

Change-Id: I0fcdc1944ea12d0e997627c5740b57a0bd58dbe8
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/01/37501/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/api/v1/list_events.py', 'tests/api/v1/list_projects.py', 'tests/api/v1/max_resource_volume.py', 'ceilometer/api/acl.py', 'tests/api/v1/sum_project_volume.py', 'tests/api/v1/list_resources.py', 'tests/api/v1/sum_resource_volume.py', 'tests/api/v2/acl.py', 'tests/api/v2/post_samples.py', 'tests/api/v1/list_users.py', 'tests/api/v2/list_resources.py', 'tests/api/v1/max_project_volume.py', 'tests/api/v1/list_meters.py']",13,80afaac4b6e7a2da926189c220f4fbda92a458b9,," ""X-Project-Id"": ""project-id""}) ""X-Project-Id"": ""project-id2""}) ""X-Project-Id"": ""project-id""}) ""X-Project-Id"": ""project666""}) ""X-Project-Id"": ""project-id2""}) ""X-Project-Id"": ""project-id""}) ""X-Project-Id"": ""project-id""}) ""X-Project-Id"": ""project-666""}) ""X-Project-Id"": ""project-id2""}) ""X-Project-Id"": ""project-666""})"," ""X-Tenant-Id"": ""project-id""}) ""X-Tenant-Id"": ""project-id2""}) ""X-Tenant-Id"": ""project-id""}) ""X-Tenant-Id"": ""project666""}) ""X-Tenant-Id"": ""project-id2""}) ""X-Tenant-Id"": ""project-id""}) ""X-Tenant-Id"": ""project-id""}) ""X-Tenant-Id"": ""project-666""}) ""X-Tenant-Id"": ""project-id2""}) ""X-Tenant-Id"": ""project-666""})",54,54
openstack%2Fos-apply-config~master~I7b0c5fe18e27e16b5db73e30480de865a332b8d2,openstack/os-apply-config,master,I7b0c5fe18e27e16b5db73e30480de865a332b8d2,Fix relative imports and namespace issues.,MERGED,2013-07-17 21:07:56.000000000,2013-07-17 21:07:56.000000000,2013-07-17 21:07:56.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-17 21:07:56.000000000', 'files': ['os_apply_config/tests/test_apply_config.py', 'os_apply_config/apply_config.py'], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/ddac4ae180e5552fb591da378efd97bd3a486d69', 'message': 'Fix relative imports and namespace issues.\n\nos_apply_config.os_apply_config caused confusing import problems.\nRenaming it to os_apply_config.apply_config solves this. Now we can be\nexplicit about all imports.\n\nChange-Id: I7b0c5fe18e27e16b5db73e30480de865a332b8d2\n'}]",0,37559,ddac4ae180e5552fb591da378efd97bd3a486d69,5,2,1,6488,,,0,"Fix relative imports and namespace issues.

os_apply_config.os_apply_config caused confusing import problems.
Renaming it to os_apply_config.apply_config solves this. Now we can be
explicit about all imports.

Change-Id: I7b0c5fe18e27e16b5db73e30480de865a332b8d2
",git fetch https://review.opendev.org/openstack/os-apply-config refs/changes/59/37559/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_apply_config/tests/test_apply_config.py', 'os_apply_config/apply_config.py']",2,ddac4ae180e5552fb591da378efd97bd3a486d69,FIX-NAMING,"from os_apply_config import config_exception as exc from os_apply_config import renderers from os_apply_config import value_types raise exc.ConfigException( value_types.ensure_type(config, type_name) raise exc.ConfigException( raise exc.ConfigException( r = renderers.JsonRenderer(missing_tags='ignore') raise exc.ConfigException( raise exc.ConfigException(""invalid metadata file: %s"" % path) raise exc.ConfigException(""No metadata found."") raise exc.ConfigException( raise exc.ConfigException('missing option --templates') except exc.ConfigException as e:","from config_exception import ConfigException from renderers import JsonRenderer from value_types import ensure_type raise ConfigException( ensure_type(config, type_name) raise ConfigException( raise ConfigException( r = JsonRenderer(missing_tags='ignore') raise ConfigException( raise ConfigException(""invalid metadata file: %s"" % path) raise ConfigException(""No metadata found."") raise ConfigException( raise ConfigException('missing option --templates') except ConfigException as e:",45,42
openstack%2Fos-apply-config~master~I9ba5b2c1eda349b26d24833ebd5cbd5244584311,openstack/os-apply-config,master,I9ba5b2c1eda349b26d24833ebd5cbd5244584311,Adding MANIFEST.in and fixing .gitreview,MERGED,2013-07-17 21:07:56.000000000,2013-07-17 21:07:56.000000000,2013-07-17 21:07:56.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-17 21:07:56.000000000', 'files': ['.gitreview', 'MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/40f7da49ed2707b3563f4b8c58685ddf6bb91a32', 'message': 'Adding MANIFEST.in and fixing .gitreview\n\nBit-rot from no development going on has led to some problems. The\n.gitrview file points at the old named repo. MANIFEST.in is needed to\nmake sure we have README.md to satisfy setup.cfg using it for the long\ndescription.\n\nChange-Id: I9ba5b2c1eda349b26d24833ebd5cbd5244584311\n'}]",0,37427,40f7da49ed2707b3563f4b8c58685ddf6bb91a32,7,3,1,6488,,,0,"Adding MANIFEST.in and fixing .gitreview

Bit-rot from no development going on has led to some problems. The
.gitrview file points at the old named repo. MANIFEST.in is needed to
make sure we have README.md to satisfy setup.cfg using it for the long
description.

Change-Id: I9ba5b2c1eda349b26d24833ebd5cbd5244584311
",git fetch https://review.opendev.org/openstack/os-apply-config refs/changes/27/37427/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'MANIFEST.in']",2,40f7da49ed2707b3563f4b8c58685ddf6bb91a32,,include AUTHORS include ChangeLog include README.md exclude .gitignore exclude .gitreview global-exclude *.pyc ,,8,1
openstack%2Fpuppet-swift~master~I0da9696499bce281ad258cbf0e88bd57f7dde76f,openstack/puppet-swift,master,I0da9696499bce281ad258cbf0e88bd57f7dde76f,Use @ notation for ERB template variables,MERGED,2013-07-17 18:34:50.000000000,2013-07-17 20:49:06.000000000,2013-07-17 20:49:06.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 6758}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-07-17 18:34:50.000000000', 'files': ['templates/swift-bench.conf.erb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/c8936fea9b1f70c20dc1bdb192e8a3553ed73708', 'message': 'Use @ notation for ERB template variables\n\nFix Puppet 3.2 deprecation warnings (see Puppet #19058)\n\nChange-Id: I0da9696499bce281ad258cbf0e88bd57f7dde76f\n'}]",0,37550,c8936fea9b1f70c20dc1bdb192e8a3553ed73708,8,5,1,7156,,,0,"Use @ notation for ERB template variables

Fix Puppet 3.2 deprecation warnings (see Puppet #19058)

Change-Id: I0da9696499bce281ad258cbf0e88bd57f7dde76f
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/50/37550/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/swift-bench.conf.erb'],1,c8936fea9b1f70c20dc1bdb192e8a3553ed73708,fix_template_variables,auth = <%= @auth_url %> user = <%= @swift_user %> key = <%= @swift_key %> auth_version = <%= @auth_version %> log-level = <%= @log_level %> timeout = <%= @test_timeout %>put_concurrency = <%= @put_concurrency %> get_concurrency = <%= @get_concurrency %> del_concurrency = <%= @del_concurrency %>lower_object_size = <%= @lower_object_size %> upper_object_size = <%= @upper_object_size %>object_size = <%= @object_size %> num_objects = <%= @num_objects %> num_gets = <%= @num_gets %> num_containers = <%= @num_containers %>delete = <%= @delete %>,auth = <%= auth_url %> user = <%= swift_user %> key = <%= swift_key %> auth_version = <%= auth_version %> log-level = <%= log_level %> timeout = <%= test_timeout %>put_concurrency = <%= put_concurrency %> get_concurrency = <%= get_concurrency %> del_concurrency = <%= del_concurrency %>lower_object_size = <%= lower_object_size %> upper_object_size = <%= upper_object_size %>object_size = <%= object_size %> num_objects = <%= num_objects %> num_gets = <%= num_gets %> num_containers = <%= num_containers %>delete = <%= delete %>,16,16
openstack%2Fopenstack-manuals~master~Ied9be78fcfce4ccfae2a5d4e4d284d0d34b2947b,openstack/openstack-manuals,master,Ied9be78fcfce4ccfae2a5d4e4d284d0d34b2947b,Modifies Security Guide for final Lulu print capability:,MERGED,2013-07-17 19:52:11.000000000,2013-07-17 20:45:39.000000000,2013-07-17 20:45:38.000000000,"[{'_account_id': 3}, {'_account_id': 2807}]","[{'number': 1, 'created': '2013-07-17 19:52:11.000000000', 'files': ['doc/src/docbkx/openstack-security/pom.xml', 'www/sec/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3a79c299ef1ff208bdc34acc5fd4828d52317f42', 'message': 'Modifies Security Guide for final Lulu print capability:\n\nedit pom.xml to make the PDF crown quarto page size without a front cover\nedit index.html landing page for security guide so people can buy it\n\nChange-Id: Ied9be78fcfce4ccfae2a5d4e4d284d0d34b2947b\n'}]",0,37556,3a79c299ef1ff208bdc34acc5fd4828d52317f42,5,2,1,964,,,0,"Modifies Security Guide for final Lulu print capability:

edit pom.xml to make the PDF crown quarto page size without a front cover
edit index.html landing page for security guide so people can buy it

Change-Id: Ied9be78fcfce4ccfae2a5d4e4d284d0d34b2947b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/56/37556/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-security/pom.xml', 'www/sec/index.html']",2,3a79c299ef1ff208bdc34acc5fd4828d52317f42,add-lulu-link-sec-guide,"<p>You can get the <a href=""openstack-security-guide.pdf"" onClick=""recordOutboundLink(this, 'Outbound Links', 'openstack-security-guide.pdf');return false;"" >PDF</a> to print yourself. If you'd like a bound copy, <a href=""http://www.lulu.com/commerce/index.php?fBuyContent=13956188"" onClick=""recordOutboundLink(this, 'Outbound Links', 'securitylulu.com');return false;"">buy it from Lulu</a> and all proceeds go to the Foundation to support more book sprints efforts like this one.</p> <a href=""http://www.lulu.com/commerce/index.php?fBuyContent=13956188""><img src=""http://static.lulu.com/images/services/buy_now_buttons/us/blue2.gif?20130702092152"" border=""0"" alt=""Support independent publishing: Buy this book on Lulu.""></a>"," <!-- <p>You can get the <a href=""openstack-security-guide.pdf"" onClick=""recordOutboundLink(this, 'Outbound Links', 'openstack-security-guide.pdf');return false;"" >PDF</a> to print yourself. If you'd like a bound copy, <a href=""http://www.lulu.com/content/paperback-book/openstack-security-guide/XXXXXXXXXX"" onClick=""recordOutboundLink(this, 'Outbound Links', 'lulu.com');return false;"">buy it from Lulu</a> and all proceeds go to the Foundation to support more book sprints efforts like this one.</p> <a href=""http://www.lulu.com/content/paperback-book/openstack-security-guide/XXXXXXXXXX"" onClick=""recordOutboundLink(this, 'Outbound Links', 'lulu.com');return false;""><img src=""http://static.lulu.com/images/services/buy_now_buttons/us/book_blue2.gif?20130214104738"" border=""0"" alt=""Support independent publishing: Buy this book on Lulu.""></a>-->",7,7
openstack%2Fpython-openstackclient~master~I842916af9f7c0a76c4d3e27e419bf0fec059ec78,openstack/python-openstackclient,master,I842916af9f7c0a76c4d3e27e419bf0fec059ec78,Add --catalog to service show,MERGED,2013-07-03 22:19:11.000000000,2013-07-17 20:11:00.000000000,2013-07-17 20:11:00.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 6482}]","[{'number': 1, 'created': '2013-07-03 22:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b0c5a430ecbf8ed0c5710963ac9256c4546fbe8a', 'message': 'Add --catalog to service show\n\nPulls from the service catalog rather than the system services\n\nChange-Id: I842916af9f7c0a76c4d3e27e419bf0fec059ec78\n'}, {'number': 2, 'created': '2013-07-16 16:31:38.000000000', 'files': ['openstackclient/identity/v2_0/service.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/bbb71e7ce2cb8bc81318858823018ff494c61a40', 'message': 'Add --catalog to service show\n\nShows endpoints from the service catalog rather than the system services.\n\nChange-Id: I842916af9f7c0a76c4d3e27e419bf0fec059ec78\n'}]",5,35558,bbb71e7ce2cb8bc81318858823018ff494c61a40,12,4,2,970,,,0,"Add --catalog to service show

Shows endpoints from the service catalog rather than the system services.

Change-Id: I842916af9f7c0a76c4d3e27e419bf0fec059ec78
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/58/35558/2 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/identity/v2_0/service.py'],1,b0c5a430ecbf8ed0c5710963ac9256c4546fbe8a,identity-catalog," """"""Show cloud service information"""""" '--catalog', action='store_true', default=False, help='Show service catalog information', ) parser.add_argument( if parsed_args.catalog: try: endpoints = identity_client.service_catalog.get_endpoints( service_type=parsed_args.service) for (service, service_endpoints) in endpoints.iteritems(): if len(service_endpoints) > 0: info = {""type"": parsed_args.service} for ep in service_endpoints: info.update(ep) return zip(*sorted(info.iteritems())) except Exception as ex: msg = (""No service catalog with a type, name or ID of '%s' "" ""exists. %s"" % (parsed_args.service, ex)) else: try: # search for the usual ID or name service = utils.find_resource( identity_client.services, parsed_args.service, ) except exceptions.CommandError: try: # search for service type service = identity_client.services.find( type=parsed_args.service) # FIXME(dtroyer): This exception should eventually come from # common client exceptions except identity_exc.NotFound: msg = (""No service with a type, name or ID of '%s' exists."" % parsed_args.service) raise exceptions.CommandError(msg)"," """"""Show service command"""""" try: # search for the usual ID or name service = utils.find_resource(identity_client.services, parsed_args.service) except exceptions.CommandError: try: # search for service type service = identity_client.services.find( type=parsed_args.service) # FIXME(dtroyer): This exception should eventually come from # common client exceptions except identity_exc.NotFound: msg = ""No service with exists."" # TODO(mordred): Where does name_or_id come from? # msg = (""No service with a type, name or ID of '%s' exists."" % # name_or_id)",38,16
openstack%2Fdjango_openstack_auth~master~I11c89c3902d974e94f4fee29211970546579f29e,openstack/django_openstack_auth,master,I11c89c3902d974e94f4fee29211970546579f29e,Add tox.ini file and flake8 ignores,MERGED,2013-07-17 18:43:52.000000000,2013-07-17 20:08:25.000000000,2013-07-17 20:08:25.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 1941}]","[{'number': 1, 'created': '2013-07-17 18:43:52.000000000', 'files': ['.gitignore', 'openstack_auth/user.py', 'docs/conf.py', 'openstack_auth/backend.py', 'openstack_auth/tests/data_v3.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/546716c5856a3f76bfc58f24a8222aa1cd1919f7', 'message': 'Add tox.ini file and flake8 ignores\n\nChange-Id: I11c89c3902d974e94f4fee29211970546579f29e\n'}]",0,37551,546716c5856a3f76bfc58f24a8222aa1cd1919f7,6,3,1,2,,,0,"Add tox.ini file and flake8 ignores

Change-Id: I11c89c3902d974e94f4fee29211970546579f29e
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/51/37551/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'openstack_auth/user.py', 'docs/conf.py', 'openstack_auth/backend.py', 'openstack_auth/tests/data_v3.py', 'tox.ini']",6,546716c5856a3f76bfc58f24a8222aa1cd1919f7,,"[tox] envlist = py26,py27,py27dj14,pep8,py33 [testenv] setenv = VIRTUAL_ENV={envdir} NOSE_WITH_OPENSTACK=1 NOSE_OPENSTACK_COLOR=1 NOSE_OPENSTACK_RED=0.05 NOSE_OPENSTACK_YELLOW=0.025 NOSE_OPENSTACK_SHOW_ELAPSED=1 deps = mox commands = python setup.py test [testenv:pep8] commands = flake8 [testenv:venv] commands = {posargs} [tox:jenkins] downloadcache = ~/cache/pip [flake8] builtins = _ exclude = .venv,.git,.tox,dist,doc,*openstack/common*,*lib/python*,*egg,build,panel_template,dash_template,local_settings.py # E121 continuation line indentation is not a multiple of four # E126 continuation line over-indented for hanging indent # E127 continuation line over-indented for visual indent # E128 continuation line under-indented for visual indent # F401 '<smth>' imported but unused # F403 'from <smth> import *' used; unable to detect undefined names # F841 local variable '<smth>' is assigned to but never used # F999 syntax error in doctest # H201 no 'except:' at least use 'except Exception:' # H302 import only modules.'from optparse import make_option' does not import a module # H303 No wildcard (*) import. # H304 No relative imports. 'from .views import IndexView' is a relative import # H4xx docstrings # H701 empty localization string # H702 Formatting operation should be outside of localization method call ignore = E121,E126,E127,E128,E501,E502,F403,F841,F999,H201,H301,H306,H302,H303,H304,H4,H701,H702 ",,58,15
openstack%2Fpython-openstackclient~master~I2bd181cd0d098f7143360ae67944c2f221379af5,openstack/python-openstackclient,master,I2bd181cd0d098f7143360ae67944c2f221379af5,Add show limits command,MERGED,2013-07-09 22:16:56.000000000,2013-07-17 20:07:43.000000000,2013-07-17 20:07:43.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 6482}]","[{'number': 1, 'created': '2013-07-09 22:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/343416c5b041ff924a2eb53428476103bd5e0652', 'message': ""Add show limits command\n\n* This is a combination of the compute and volume API limits as they are\n  very similar.  As such, the command lives in a new command group\n  'openstack.common' that is unversioned.\n* Implements 'limits show [--absolute|--rate]\n\nChange-Id: I2bd181cd0d098f7143360ae67944c2f221379af5\n""}, {'number': 2, 'created': '2013-07-09 22:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0b1117325d4d857fdf6b655a238c074440f497ae', 'message': ""Add show limits command\n\n* This is a combination of the compute and volume API limits as they are\n  very similar.  As such, the command lives in a new command group\n  'openstack.common' that is unversioned.\n* Implements 'limits show [--absolute|--rate]\n\nBug: 1172057\n\nChange-Id: I2bd181cd0d098f7143360ae67944c2f221379af5\n""}, {'number': 3, 'created': '2013-07-12 17:13:35.000000000', 'files': ['openstackclient/common/limits.py', 'openstackclient/shell.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/75dcdb0c6637afe5c14e5c60f7719182bda7ab4a', 'message': ""Add show limits command\n\n* This is a combination of the compute and volume API limits as they are\n  very similar.  As such, the command lives in a new command group\n  'openstack.common' that is unversioned.\n* Implements 'limits show [--absolute|--rate]\n\nUpdated for https://review.openstack.org/#/c/36772/\n\nBug: 1172057\n\nChange-Id: I2bd181cd0d098f7143360ae67944c2f221379af5\n""}]",5,36352,75dcdb0c6637afe5c14e5c60f7719182bda7ab4a,16,4,3,970,,,0,"Add show limits command

* This is a combination of the compute and volume API limits as they are
  very similar.  As such, the command lives in a new command group
  'openstack.common' that is unversioned.
* Implements 'limits show [--absolute|--rate]

Updated for https://review.openstack.org/#/c/36772/

Bug: 1172057

Change-Id: I2bd181cd0d098f7143360ae67944c2f221379af5
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/52/36352/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/common/limits.py', 'openstackclient/shell.py', 'setup.cfg']",3,343416c5b041ff924a2eb53428476103bd5e0652,bug/1172057,openstack.common = limits_show = openstackclient.common.limits:ShowLimits ,,87,0
openstack%2Fnova~master~I6bdec31861b43ce39981dcaf7be8862ec0e07d45,openstack/nova,master,I6bdec31861b43ce39981dcaf7be8862ec0e07d45,Fix cells parse_transport_url for python 2.7.3+,ABANDONED,2013-07-17 16:37:59.000000000,2013-07-17 20:02:11.000000000,,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 679}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-07-17 16:37:59.000000000', 'files': ['nova/cells/rpc_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cbb61f8662acc56df6f2fa37adc0cb9da9623227', 'message': 'Fix cells parse_transport_url for python 2.7.3+\n\nbug 1202263\n\nChange-Id: I6bdec31861b43ce39981dcaf7be8862ec0e07d45\n'}]",0,37523,cbb61f8662acc56df6f2fa37adc0cb9da9623227,4,4,1,2835,,,0,"Fix cells parse_transport_url for python 2.7.3+

bug 1202263

Change-Id: I6bdec31861b43ce39981dcaf7be8862ec0e07d45
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/37523/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/cells/rpc_driver.py'],1,cbb61f8662acc56df6f2fa37adc0cb9da9623227,bug/1202263," # NOTE(belliott) - python 2.7.3 parses the query stringinto the 'query' # field, earlier # versions use the 'path' field. if parsed.query or '?' in parsed.path:", if '?' in parsed.path:,4,1
openstack%2Fdjango_openstack_auth~master~I42b0dc944cc6c838f0dd2eabcf90b133311f9159,openstack/django_openstack_auth,master,I42b0dc944cc6c838f0dd2eabcf90b133311f9159,Add OpenStack .gitreview file,MERGED,2013-07-17 18:22:51.000000000,2013-07-17 20:02:08.000000000,2013-07-17 20:02:08.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 1941}]","[{'number': 1, 'created': '2013-07-17 18:22:51.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/afad771fff6bf74e3591e9c5a7ca78c8a524a2dd', 'message': 'Add OpenStack .gitreview file\n\nChange-Id: I42b0dc944cc6c838f0dd2eabcf90b133311f9159\n'}]",0,37546,afad771fff6bf74e3591e9c5a7ca78c8a524a2dd,6,3,1,2,,,0,"Add OpenStack .gitreview file

Change-Id: I42b0dc944cc6c838f0dd2eabcf90b133311f9159
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/46/37546/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,afad771fff6bf74e3591e9c5a7ca78c8a524a2dd,,[gerrit] host=review.openstack.org port=29418 project=openstack/django_openstack_auth.git ,,4,0
openstack%2Fnova~master~Idb005b7227447308a8d060be7aa9ff5c70b5ff44,openstack/nova,master,Idb005b7227447308a8d060be7aa9ff5c70b5ff44,Change get_all_instance_metadata to use _get_instances_by_filters,MERGED,2013-07-09 15:37:41.000000000,2013-07-17 19:44:04.000000000,2013-07-17 09:01:14.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1313}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 6172}, {'_account_id': 6624}, {'_account_id': 6661}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-07-09 15:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/459ffa265494c772a6ac0b50266db5a22e64756a', 'message': ""Change get_all_instance_metadata to use _get_instances_by_filters\n\nWe need an instance list for invoking check_policy against when calling\nget_all_instance_metadata. Since the get_instances call also returns\nthe associated instance metadata, we can reuse this code.\n\nThe filters passed from DescribeTags are transformed to ones that\n_get_instances_by_filters understands. By including 'remove_metadata'\nin the filter, _get_instances_by_filters will not only filter\nout instances that don't pass the metadata filter, but also remove\nthe associated instance metadata, which is what the higher-level DescribeTags\ncall would need.\n\nWe then loop through the instances and return the already-filtered metadata\nfor the instances that pass the policy check.\n\nFixes bug #1192715\n\nChange-Id: Idb005b7227447308a8d060be7aa9ff5c70b5ff44\n""}, {'number': 2, 'created': '2013-07-09 17:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/41cf1e99f171e9f452e2bdca987bb0a1a2a779bd', 'message': ""Change get_all_instance_metadata to use _get_instances_by_filters\n\nWe need an instance list for invoking check_policy against when calling\nget_all_instance_metadata. Since the get_instances call also returns\nthe associated instance metadata, we can reuse this code.\n\nThe filters passed from DescribeTags are transformed to ones that\n_get_instances_by_filters understands. By including 'remove_metadata'\nin the filter, _get_instances_by_filters will not only filter\nout instances that don't pass the metadata filter, but also remove\nthe associated instance metadata, which is what the higher-level DescribeTags\ncall would need.\n\nWe then loop through the instances and return the already-filtered metadata\nfor the instances that pass the policy check.\n\nFixes bug #1192715\n\nChange-Id: Idb005b7227447308a8d060be7aa9ff5c70b5ff44\n""}, {'number': 3, 'created': '2013-07-11 04:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07caae5884e99ccc97773b005c639b04c484a61a', 'message': 'Change get_all_instance_metadata to use _get_instances_by_filters\n\nWe need an instance list for invoking check_policy against when calling\nget_all_instance_metadata. Since the _get_instances_by_filters\ncall also returns associated instance metadata, we can use this and\nremove the db.sqlalchemy.api.get_all_instance_metadata call (and\nits helper _get_all_instance_metadata_query).\n\nFixes bug #1192715\n\nChange-Id: Idb005b7227447308a8d060be7aa9ff5c70b5ff44\n'}, {'number': 4, 'created': '2013-07-11 16:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c2602c7efe3d4658f3bf5a92aaa0155c879d21b', 'message': 'Change get_all_instance_metadata to use _get_instances_by_filters\n\nWe need an instance list for invoking check_policy against when calling\nget_all_instance_metadata. Since the _get_instances_by_filters\ncall also returns associated instance metadata, we can use this instead\nof db.api.get_all_instance_metadata.\n\nFixes bug #1192715\n\nChange-Id: Idb005b7227447308a8d060be7aa9ff5c70b5ff44\n'}, {'number': 5, 'created': '2013-07-16 21:46:16.000000000', 'files': ['nova/tests/api/ec2/test_cloud.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b48789f14b41b7f017f84a5d832e9283a0808ef4', 'message': 'Change get_all_instance_metadata to use _get_instances_by_filters\n\nWe need an instance list for invoking check_policy against when calling\nget_all_instance_metadata. Since the _get_instances_by_filters\ncall also returns associated instance metadata, we can use this instead\nof db.api.get_all_instance_metadata.\n\nFixes bug #1192715\n\nChange-Id: Idb005b7227447308a8d060be7aa9ff5c70b5ff44\n'}]",12,36244,b48789f14b41b7f017f84a5d832e9283a0808ef4,33,10,5,6661,,,0,"Change get_all_instance_metadata to use _get_instances_by_filters

We need an instance list for invoking check_policy against when calling
get_all_instance_metadata. Since the _get_instances_by_filters
call also returns associated instance metadata, we can use this instead
of db.api.get_all_instance_metadata.

Fixes bug #1192715

Change-Id: Idb005b7227447308a8d060be7aa9ff5c70b5ff44
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/36244/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/ec2/test_cloud.py', 'nova/tests/db/test_db_api.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py', 'nova/db/sqlalchemy/api.py']",5,459ffa265494c772a6ac0b50266db5a22e64756a,bug/1192715,"def _instances_fill_metadata(context, instances, manual_joins=None, filters=None): for row in _instance_metadata_get_multi(context, uuids, filters=filters): 'remove_metadata' - remove instance metadata that doesn't pass the specified metadata tag filters return _instances_fill_metadata(context, query_prefix.all(), manual_joins, filters)def _instance_metadata_get_multi(context, instance_uuids, session=None, filters=None): query = model_query(context, models.InstanceMetadata, session=session).filter( models.InstanceMetadata.instance_uuid.in_(instance_uuids)) if filters and 'remove_metadata' in filters: query = filter_metadata_by_tag(query, models.InstanceMetadata, filters) return query","def _instances_fill_metadata(context, instances, manual_joins=None): for row in _instance_metadata_get_multi(context, uuids): return _instances_fill_metadata(context, query_prefix.all(), manual_joins)def _instance_metadata_get_multi(context, instance_uuids, session=None): return model_query(context, models.InstanceMetadata, session=session).\ filter( models.InstanceMetadata.instance_uuid.in_(instance_uuids))def _instance_metadata_get_all_query(context, session=None, read_deleted='no', search_filts=[]): or_query = None query = model_query(context, models.InstanceMetadata, session=session, read_deleted=read_deleted) # We want to incrementally build an OR query out of the search filters. # So: # {'filter': # [{'resource_id': 'i-0000001'}], # [{'key': 'foo', 'value': 'bar'}]} # Should produce: # AND ((instance_metadata.uuid IN ('1')) OR # (instance_metadata.key IN ('foo')) OR # (instance_metadata.value IN ('bar'))) def make_tuple(item): if isinstance(item, dict): item = item.values() if not isinstance(item, (tuple, list, set)): item = (item,) return item for search_filt in search_filts: subq = None if search_filt.get('resource_id'): uuid = make_tuple(search_filt['resource_id']) subq = models.InstanceMetadata.instance_uuid.in_(uuid) elif search_filt.get('key'): key = make_tuple(search_filt['key']) subq = models.InstanceMetadata.key.in_(key) elif search_filt.get('value'): value = make_tuple(search_filt['value']) subq = models.InstanceMetadata.value.in_(value) if subq is not None: if or_query is None: or_query = subq else: or_query = or_(or_query, subq) if or_query is not None: query = query.filter(or_query) return query def instance_metadata_get_all(context, search_filts=[], read_deleted=""no""): rows = _instance_metadata_get_all_query(context, read_deleted=read_deleted, search_filts=search_filts).all() return [{'key': row['key'], 'value': row['value'], 'instance_id': row['instance_uuid']} for row in rows] @require_context",114,91
openstack%2Fkeystone~master~I45c8e94ede892a4d5412ac43aae9c4e131907c89,openstack/keystone,master,I45c8e94ede892a4d5412ac43aae9c4e131907c89,update requires to prevent version cap,MERGED,2013-07-11 15:33:01.000000000,2013-07-17 19:26:20.000000000,2013-07-17 19:26:19.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1816}, {'_account_id': 1941}, {'_account_id': 2166}, {'_account_id': 6486}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-07-11 15:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6493ef337bdcc83150d56dd6b397fef8bd405be2', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group mails\n\nChange-Id: I45c8e94ede892a4d5412ac43aae9c4e131907c89\n'}, {'number': 2, 'created': '2013-07-11 15:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e9a29f9ac867361d78d5d313112fbf0f4637323e', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group mails\n\nfixes bug #1200214\nChange-Id: I45c8e94ede892a4d5412ac43aae9c4e131907c89\n'}, {'number': 3, 'created': '2013-07-11 17:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f6c9c4c415130c01db78d70d74ff2baace51b296', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group\nmails(http://lists.openstack.org/pipermail/openstack-dev/2013-July/011660.html)\n\nfixes bug #1200214\nChange-Id: I45c8e94ede892a4d5412ac43aae9c4e131907c89\n'}, {'number': 4, 'created': '2013-07-12 04:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e2e85e907e99a3a9700b0ad016c28667533ad688', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group\nmails(http://lists.openstack.org/pipermail/openstack-dev/2013-July/011660.html)\n\ncancel the upper bound of keystoneclient now\n\nfixes bug #1200214\nChange-Id: I45c8e94ede892a4d5412ac43aae9c4e131907c89\n'}, {'number': 5, 'created': '2013-07-13 04:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/141f45fe307b62876c502ef4fa3924024f9d1748', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group\nmails(http://lists.openstack.org/pipermail/openstack-dev/2013-July/011660.html)\n\nnew conclusion: to uncap all the clients, with the exception\nof neutron client, because they need to make some incompatible\nchanges on their next major release.\n\nfixes bug #1200214\nChange-Id: I45c8e94ede892a4d5412ac43aae9c4e131907c89\n'}, {'number': 6, 'created': '2013-07-15 16:28:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/aaff2fa36bcb2c07f6710d493747d6f859c812a7', 'message': 'update requires to prevent version cap\n\nupdate requires to prevent version cap\n\nOpenStack clients. None of these should have an upper bound\nas that has implications for testing in the gate. An exception\nis currently being made for neutron client because of the\nneed for an incompatible change in their next release.\n\nhttps://github.com/openstack/requirements\n\nfixes bug #1200214\n\nfixes bug #1200214\nChange-Id: I45c8e94ede892a4d5412ac43aae9c4e131907c89\n'}, {'number': 7, 'created': '2013-07-16 00:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3a4b70cc97f0a4f71e438eb802e9287a6dd8a476', 'message': 'update requires to prevent version cap\n\nOpenStack clients requirements should not have an upper bound\nas that has implications for testing in the gate.\n\nref: https://github.com/openstack/requirements\n\nfixes bug #1200214\nChange-Id: I45c8e94ede892a4d5412ac43aae9c4e131907c89\n'}, {'number': 8, 'created': '2013-07-17 13:33:06.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/bd23cf25e2eeb139c6f3b35abf1e644a4270c0f2', 'message': 'update requires to prevent version cap\n\nOpenStack clients requirements should not have an upper bound\nas that has implications for testing in the gate.\n\nref: https://github.com/openstack/requirements\n\nfixes bug #1200214\nChange-Id: I45c8e94ede892a4d5412ac43aae9c4e131907c89\n'}]",4,36680,bd23cf25e2eeb139c6f3b35abf1e644a4270c0f2,40,7,8,6835,,,0,"update requires to prevent version cap

OpenStack clients requirements should not have an upper bound
as that has implications for testing in the gate.

ref: https://github.com/openstack/requirements

fixes bug #1200214
Change-Id: I45c8e94ede892a4d5412ac43aae9c4e131907c89
",git fetch https://review.opendev.org/openstack/keystone refs/changes/80/36680/6 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6493ef337bdcc83150d56dd6b397fef8bd405be2,bug/1200214,"python-keystoneclient>=0.2.1,<0.4 oslo.config>=1.1.0,<2.0","python-keystoneclient>=0.2.1,<0.3 oslo.config>=1.1.0",2,2
openstack%2Fnova~master~I156ca3422ca4e6c4afe2eaa1aec10f0bb86238d6,openstack/nova,master,I156ca3422ca4e6c4afe2eaa1aec10f0bb86238d6,Alwas set model = 'netfront' for xen over libvirt.,ABANDONED,2013-07-17 18:25:54.000000000,2013-07-17 19:17:49.000000000,,"[{'_account_id': 2166}, {'_account_id': 7243}]","[{'number': 1, 'created': '2013-07-17 18:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d8629bc66b5780b987633bb3135208bf5f6507b', 'message': ""Alwas set model = 'netfront' for xen over libvirt.\n\nThis will prevent emulated network driver to be attached to virtual machine.\nEmulated network driver is not working for xen over libvirt as tap interface\nname is suffixed by xen with '-emu' which makes this interface name to long.\n\nAdditionaly security groups will not also work for this interface as openstack\nis setting up filters on interface without -emu suffix.\n\nChange-Id: I156ca3422ca4e6c4afe2eaa1aec10f0bb86238d6\nFixes: bug #1202199\n""}, {'number': 2, 'created': '2013-07-17 19:15:48.000000000', 'files': ['nova/virt/libvirt/vif.py', 'nova/tests/virt/libvirt/test_libvirt_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/20b145b345af5095b66e74bdaeebe00d30e05a2c', 'message': ""Alwas set model = 'netfront' for xen over libvirt.\n\nThis will prevent emulated network driver to be attached to virtual machine.\nEmulated network driver is not working for xen over libvirt as tap interface\nname is suffixed by xen with '-emu' which makes this interface name to long.\n\nAdditionaly security groups will not also work for this interface as openstack\nis setting up filters on interface without -emu suffix.\n\nChange-Id: I156ca3422ca4e6c4afe2eaa1aec10f0bb86238d6\nFixes: bug #1202199\n""}]",0,37547,20b145b345af5095b66e74bdaeebe00d30e05a2c,3,2,2,7243,,,0,"Alwas set model = 'netfront' for xen over libvirt.

This will prevent emulated network driver to be attached to virtual machine.
Emulated network driver is not working for xen over libvirt as tap interface
name is suffixed by xen with '-emu' which makes this interface name to long.

Additionaly security groups will not also work for this interface as openstack
is setting up filters on interface without -emu suffix.

Change-Id: I156ca3422ca4e6c4afe2eaa1aec10f0bb86238d6
Fixes: bug #1202199
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/37547/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/vif.py', 'nova/tests/virt/libvirt/test_libvirt_vif.py']",2,2d8629bc66b5780b987633bb3135208bf5f6507b,bug/1202199," self.assertEqual(len(ret), 'netfront')"," self.assertEqual(len(ret), 0)",7,1
openstack%2Fpython-glanceclient~master~If1426b7938457014ef27a86d3902d53854161627,openstack/python-glanceclient,master,If1426b7938457014ef27a86d3902d53854161627,Expose checksum index image property in client,MERGED,2013-07-03 06:43:55.000000000,2013-07-17 19:00:48.000000000,2013-07-17 19:00:48.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 4463}, {'_account_id': 7701}, {'_account_id': 7780}]","[{'number': 1, 'created': '2013-07-03 06:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/d2fd42f979e1ed1aafadc7eb9354bff839c858cd', 'message': 'Expose checksum index image property in client\n\nImplement checksum image index property in the python-glanceclient\n\nChange-Id: If1426b7938457014ef27a86d3902d53854161627\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 2, 'created': '2013-07-10 04:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/2c695176f6a7790fca2a00ece5e705547df4bdf7', 'message': 'Expose checksum index image property in client\n\nImplement checksum image index property in the python-glanceclient\n\nChange-Id: If1426b7938457014ef27a86d3902d53854161627\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 3, 'created': '2013-07-11 06:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/16f6d3e9d2c6e66a83283ca3893ca325ec1eb711', 'message': 'Expose checksum index image property in client\n\nImplement checksum image index property in the python-glanceclient\n\nChange-Id: If1426b7938457014ef27a86d3902d53854161627\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 4, 'created': '2013-07-12 09:35:39.000000000', 'files': ['tests/v2/test_images.py', 'glanceclient/v2/shell.py', 'tests/v2/test_shell_v2.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/09b29aac12b2988db41834798f509b8a54500ab6', 'message': 'Expose checksum index image property in client\n\nImplement checksum image index property in the python-glanceclient\n\nChange-Id: If1426b7938457014ef27a86d3902d53854161627\nImplements: blueprint index-using-checksum-image-property\n'}]",8,35455,09b29aac12b2988db41834798f509b8a54500ab6,23,7,4,7701,,,0,"Expose checksum index image property in client

Implement checksum image index property in the python-glanceclient

Change-Id: If1426b7938457014ef27a86d3902d53854161627
Implements: blueprint index-using-checksum-image-property
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/55/35455/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/v2/test_images.py', 'glanceclient/v2/shell.py', 'tests/v2/test_shell_v2.py']",3,d2fd42f979e1ed1aafadc7eb9354bff839c858cd,bp/index-using-checksum-image-property, self.checksum = 'fake_checksum',,23,1
openstack%2Fcinder~master~I3a4f2585ea9e6f70b6f6f9889e900f19559b8176,openstack/cinder,master,I3a4f2585ea9e6f70b6f6f9889e900f19559b8176,Fixes race condition in LVMVolumeDriver create_cloned_volume method,MERGED,2013-07-17 10:24:15.000000000,2013-07-17 18:58:54.000000000,2013-07-17 18:58:54.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2166}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 4523}]","[{'number': 1, 'created': '2013-07-17 10:24:15.000000000', 'files': ['cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/201890c17e0f29d1ec8e5040206ecd1be09e22f7', 'message': 'Fixes race condition in LVMVolumeDriver create_cloned_volume method\n\nWhen we create a clone volume, LVMVolumeDriver will firstly create a temp\nsnapshot for copying, the temp snapshot name is\n""clone-snap-%s"" % source_volume[\'id\']. When we create multiple clone volumes\nof the same volume simultaneously, which would trigger the race issuse.\n\nI changes the temp snapshot name template to ""clone-snap-%s"" % volume[\'id\'],\nso temp snapshot name will be unique.\n\nFixes bug #1202139\n\nChange-Id: I3a4f2585ea9e6f70b6f6f9889e900f19559b8176\n'}]",0,37444,201890c17e0f29d1ec8e5040206ecd1be09e22f7,9,6,1,2481,,,0,"Fixes race condition in LVMVolumeDriver create_cloned_volume method

When we create a clone volume, LVMVolumeDriver will firstly create a temp
snapshot for copying, the temp snapshot name is
""clone-snap-%s"" % source_volume['id']. When we create multiple clone volumes
of the same volume simultaneously, which would trigger the race issuse.

I changes the temp snapshot name template to ""clone-snap-%s"" % volume['id'],
so temp snapshot name will be unique.

Fixes bug #1202139

Change-Id: I3a4f2585ea9e6f70b6f6f9889e900f19559b8176
",git fetch https://review.opendev.org/openstack/cinder refs/changes/44/37444/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/lvm.py'],1,201890c17e0f29d1ec8e5040206ecd1be09e22f7,bug/1202139," temp_id = 'tmp-snap-%s' % volume['id'] 'name': 'clone-snap-%s' % volume['id'],"," temp_id = 'tmp-snap-%s' % src_vref['id'] 'name': 'clone-snap-%s' % src_vref['id'],",2,2
openstack%2Fnova~master~I1fb74186886283a9b6763abb665b8ce42e4bb24c,openstack/nova,master,I1fb74186886283a9b6763abb665b8ce42e4bb24c,Prompt error message when creating aggregate without aggregate name,MERGED,2013-06-06 10:05:54.000000000,2013-07-17 18:41:17.000000000,2013-07-17 18:41:15.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 5652}, {'_account_id': 6722}, {'_account_id': 6981}, {'_account_id': 7148}, {'_account_id': 7282}]","[{'number': 1, 'created': '2013-06-06 10:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6a4d935f810c8072fabdb8b1468ade5708d2b96', 'message': 'Prompt error message when creating aggregate without aggregate name\n\nWhen using API to create an availability zone via aggregate, the\nprompt message will be ""There was a conflict when trying to complete\nyour request"" if the request body looks like below.\n{""aggregate"": {""name"": """", ""availability_zone"": ""zy1_zone53335""}}\n\nThe message is not accurate, aggregate name should not be null.\n\nFixes bug 1188032\nChange-Id: I1fb74186886283a9b6763abb665b8ce42e4bb24c\n'}, {'number': 2, 'created': '2013-06-08 07:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1e9e7f81f9b681bf6cc4f666d012d78ef0fc961', 'message': 'Prompt error message when creating aggregate without aggregate name\n\nWhen using API to create an availability zone via aggregate, the\nprompt message will be ""There was a conflict when trying to complete\nyour request"" if the request body looks like below.\n{""aggregate"": {""name"": """", ""availability_zone"": ""zy1_zone53335""}}\n\nThe message is not accurate, aggregate name should not be null.\n\nFixes bug 1188032\nChange-Id: I1fb74186886283a9b6763abb665b8ce42e4bb24c\n'}, {'number': 3, 'created': '2013-07-12 08:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac797b92f49cf9b608687c879ca4324b36e025d8', 'message': 'Prompt error message when creating aggregate without aggregate name\n\nWhen using API to create an availability zone via aggregate, the\nprompt message will be ""There was a conflict when trying to complete\nyour request"" if the request body looks like below.\n{""aggregate"": {""name"": """", ""availability_zone"": ""zy1_zone53335""}}\n\nThe message is not accurate, aggregate name should not be null.\n\nFixes bug 1188032\nChange-Id: I1fb74186886283a9b6763abb665b8ce42e4bb24c\n'}, {'number': 4, 'created': '2013-07-15 05:22:50.000000000', 'files': ['nova/api/openstack/compute/contrib/aggregates.py', 'nova/tests/api/openstack/compute/contrib/test_aggregates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/43f9028f84ffec9b465bec10025ba75266c1bc22', 'message': 'Prompt error message when creating aggregate without aggregate name\n\nWhen using API to create an availability zone via aggregate, the\nprompt message will be ""There was a conflict when trying to complete\nyour request"" if the request body looks like below.\n{""aggregate"": {""name"": """", ""availability_zone"": ""zy1_zone53335""}}\n\nThe message is not accurate, aggregate name should not be null.\n\nFixes bug 1188032\nChange-Id: I1fb74186886283a9b6763abb665b8ce42e4bb24c\n'}]",2,31944,43f9028f84ffec9b465bec10025ba75266c1bc22,30,11,4,6981,,,0,"Prompt error message when creating aggregate without aggregate name

When using API to create an availability zone via aggregate, the
prompt message will be ""There was a conflict when trying to complete
your request"" if the request body looks like below.
{""aggregate"": {""name"": """", ""availability_zone"": ""zy1_zone53335""}}

The message is not accurate, aggregate name should not be null.

Fixes bug 1188032
Change-Id: I1fb74186886283a9b6763abb665b8ce42e4bb24c
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/31944/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/aggregates.py', 'nova/db/sqlalchemy/models.py']",2,b6a4d935f810c8072fabdb8b1468ade5708d2b96,bug/1188032," name = Column(String(255), nullable=False)", name = Column(String(255)),3,1
openstack%2Fnova~master~I434ab63eae4eb49a45aff671a79ba3c488220cea,openstack/nova,master,I434ab63eae4eb49a45aff671a79ba3c488220cea,Improve EC2 API error responses.,ABANDONED,2013-05-06 17:54:35.000000000,2013-07-17 18:37:03.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5046}, {'_account_id': 5371}, {'_account_id': 5511}, {'_account_id': 5803}, {'_account_id': 6717}]","[{'number': 1, 'created': '2013-05-06 17:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7289083c6786c54b071ef6736c111638928299ef', 'message': 'Improve EC2 API error responses.\n\nImplements blueprint ec2-error-codes\n\nProper EC2 error codes are returned where possible.\n\nRedundant logging code was united in new ec2_error_ex() helper function and\nall standard EC2 error responses are now uniformly logged on DEBUG log level\nbecause they are just responses to invalid client requests, not nova errors.\n\nUnexpected client/server errors are logged on ERROR/CRITICAL level and their\nexception name is used as error code - no more useless UnknownError. Error\ndescriptions are supressed for unexpected server errors as they might contain\nsensitive data.\n\nEC2APIError was removed and replaced by specific exceptions. New EC2\nexceptions were introduced with EC2 suffix, some of them contain\n_ (underscores) in place of . (dots) for automatic translation from exception\nname to EC2 error code. This way, no new exception arguments were needed.\n\nChange-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea\n'}, {'number': 2, 'created': '2013-05-06 18:25:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ba630257fab81720fd5947b478888a35dcfc53d', 'message': 'Improve EC2 API error responses.\n\nImplements blueprint ec2-error-codes\n\nProper EC2 error codes are returned where possible.\n\nRedundant logging code was united in new ec2_error_ex() helper function and\nall standard EC2 error responses are now uniformly logged on DEBUG log level\nbecause they are just responses to invalid client requests, not nova errors.\n\nUnexpected client/server errors are logged on ERROR/CRITICAL level and their\nexception name is used as error code - no more useless UnknownError. Error\ndescriptions are supressed for unexpected server errors as they might contain\nsensitive data.\n\nEC2APIError was removed and replaced by specific exceptions. New EC2\nexceptions were introduced with EC2 suffix, some of them contain\n_ (underscores) in place of . (dots) for automatic translation from exception\nname to EC2 error code. This way, no new exception arguments were needed.\n\nChange-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea\n'}, {'number': 3, 'created': '2013-05-06 19:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e1e24a5e1ff7cbf3b54be0263e8b9705a7920a9', 'message': 'Improve EC2 API error responses.\n\nImplements blueprint ec2-error-codes\n\nProper EC2 error codes are returned where possible.\n\nRedundant logging code was united in new ec2_error_ex() helper function and\nall standard EC2 error responses are now uniformly logged on DEBUG log level\nbecause they are just responses to invalid client requests, not nova errors.\n\nUnexpected client/server errors are logged on ERROR/CRITICAL level and their\nexception name is used as error code - no more useless UnknownError. Error\ndescriptions are supressed for unexpected server errors as they might contain\nsensitive data.\n\nEC2APIError was removed and replaced by specific exceptions. New EC2\nexceptions were introduced with EC2 suffix, some of them contain\n_ (underscores) in place of . (dots) for automatic translation from exception\nname to EC2 error code. This way, no new exception arguments were needed.\n\nChange-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea\n'}, {'number': 4, 'created': '2013-06-06 12:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f1b76319f007abdb9f7541684cafe73ef53e83e', 'message': 'Improve EC2 API error responses.\n\nImplements blueprint ec2-error-codes\n\nProper EC2 error codes are returned where possible.\n\nRedundant logging code was united in new ec2_error_ex() helper function and\nall standard EC2 error responses are now uniformly logged on DEBUG log level\nbecause they are just responses to invalid client requests, not nova errors.\n\nUnexpected client/server errors are logged on ERROR/CRITICAL level and their\nexception name is used as error code - no more useless UnknownError. Error\ndescriptions are supressed for unexpected server errors as they might contain\nsensitive data.\n\nEC2APIError was removed and replaced by specific exceptions. New EC2\nexceptions were introduced with EC2 suffix, some of them contain\n_ (underscores) in place of . (dots) for automatic translation from exception\nname to EC2 error code. This way, no new exception arguments were needed.\n\nChange-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea\n'}, {'number': 5, 'created': '2013-06-12 11:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0382d788860073ecc02fec8284d0fa6e561de32d', 'message': 'Improve EC2 API error responses.\n\nImplements blueprint ec2-error-codes\n\nProper EC2 error codes are returned where possible.\n\nRedundant logging code was united in new ec2_error_ex() helper function and\nall standard EC2 error responses are now uniformly logged on DEBUG log level\nbecause they are just responses to invalid client requests, not nova errors.\n\nUnexpected client/server errors are logged on ERROR/CRITICAL level and their\nexception name is used as error code - no more useless UnknownError. Error\ndescriptions are supressed for unexpected server errors as they might contain\nsensitive data.\n\nEC2APIError was removed and replaced by specific exceptions. New EC2\nexceptions were introduced with EC2 suffix, some of them contain\n_ (underscores) in place of . (dots) for automatic translation from exception\nname to EC2 error code. This way, no new exception arguments were needed.\n\nChange-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea\n'}, {'number': 6, 'created': '2013-06-12 11:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9350373f764f2e303fba513401188607ffca2a8', 'message': 'Improve EC2 API error responses.\n\nImplements blueprint ec2-error-codes\n\nProper EC2 error codes are returned where possible.\n\nRedundant logging code was united in new ec2_error_ex() helper function and\nall standard EC2 error responses are now uniformly logged on DEBUG log level\nbecause they are just responses to invalid client requests, not nova errors.\n\nUnexpected client/server errors are logged on ERROR/CRITICAL level and their\nexception name is used as error code - no more useless UnknownError. Error\ndescriptions are supressed for unexpected server errors as they might contain\nsensitive data.\n\nEC2APIError was removed and replaced by specific exceptions. New EC2\nexceptions were introduced with EC2 suffix, some of them contain\n_ (underscores) in place of . (dots) for automatic translation from exception\nname to EC2 error code. This way, no new exception arguments were needed.\n\nChange-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea\n'}, {'number': 7, 'created': '2013-06-12 11:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22038cbee8ec54554d9136f9b269f2dae9b73e2e', 'message': 'Improve EC2 API error responses.\n\nImplements blueprint ec2-error-codes\n\nProper EC2 error codes are returned where possible.\n\nRedundant logging code was united in new ec2_error_ex() helper function and\nall standard EC2 error responses are now uniformly logged on DEBUG log level\nbecause they are just responses to invalid client requests, not nova errors.\n\nUnexpected client/server errors are logged on ERROR/CRITICAL level and their\nexception name is used as error code - no more useless UnknownError. Error\ndescriptions are supressed for unexpected server errors as they might contain\nsensitive data.\n\nEC2APIError was removed and replaced by specific exceptions. New EC2\nexceptions were introduced with EC2 suffix, some of them contain\n_ (underscores) in place of . (dots) for automatic translation from exception\nname to EC2 error code. This way, no new exception arguments were needed.\n\nChange-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea\n'}, {'number': 8, 'created': '2013-06-27 20:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb52c1e2f5ae4686cba87c2596dc5c7d2d9c4855', 'message': 'Improve EC2 API error responses.\n\nImplements blueprint ec2-error-codes\n\nProper EC2 error codes are returned where possible.\n\nRedundant logging code was united in new ec2_error_ex() helper function\nand all standard EC2 error responses are now uniformly logged on DEBUG\nlog level because they are just responses to invalid client requests,\nnot nova errors.\n\nUnexpected client/server errors are logged on ERROR/CRITICAL level and\ntheir exception name is used as error code - no more useless\nUnknownError. Error descriptions are supressed for unexpected server\nerrors as they might contain sensitive information.\n\nEC2APIError was removed and replaced by specific exceptions. New EC2\nexceptions were introduced with ec2_code attribute providing the EC2\nerror code.\n\nAlso fixed malformed error message in compute/api.py that broke the\ntests.\n\nChange-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea\n'}, {'number': 9, 'created': '2013-07-01 19:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6fbc789e579fa9b17daf3ce8ec0971d5ce8d7042', 'message': 'Improve EC2 API error responses.\n\nImplements blueprint ec2-error-codes\n\nProper EC2 error codes are returned where possible.\n\nRedundant logging code was united in new ec2_error_ex() helper function\nand all standard EC2 error responses are now uniformly logged on DEBUG\nlog level because they are just responses to invalid client requests,\nnot nova errors. New unit tests are provided.\n\nUnexpected client/server errors are logged on ERROR/CRITICAL level and\ntheir exception name is used as error code - no more useless\nUnknownError. Error descriptions are supressed for unexpected server\nerrors as they might contain sensitive information.\n\nEC2APIError was removed and replaced by specific exceptions. New EC2\nexceptions were introduced with ec2_code attribute providing the EC2\nerror code.\n\nAlso fixed malformed error message in compute/api.py that broke the\ntests.\n\nChange-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea\n'}, {'number': 10, 'created': '2013-07-03 17:40:47.000000000', 'files': ['nova/api/ec2/__init__.py', 'nova/tests/api/ec2/test_error_response.py', 'nova/exception.py', 'nova/tests/api/ec2/test_api.py', 'nova/api/ec2/faults.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py', 'nova/tests/api/ec2/test_ec2_validate.py', 'nova/compute/api.py', 'nova/tests/test_exception.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8ebf3c29e7934821ccdb3339bb500800c7688bd3', 'message': 'Improve EC2 API error responses.\n\nImplements blueprint ec2-error-codes\n\nProper EC2 error codes are returned where possible.\n\nRedundant logging code was united in new ec2_error_ex() helper function\nand all standard EC2 error responses are now uniformly logged on DEBUG\nlog level because they are just responses to invalid client requests,\nnot nova errors. New unit tests are provided.\n\nUnexpected client/server errors are logged on ERROR/CRITICAL level and\ntheir exception name is used as error code - no more useless\nUnknownError. Error descriptions are supressed for unexpected server\nerrors as they might contain sensitive information.\n\nEC2APIError was removed and replaced by specific exceptions. New EC2\nexceptions were introduced with ec2_code attribute providing the EC2\nerror code.\n\nAlso fixed malformed error message in compute/api.py that broke the\ntests.\n\nChange-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea\n'}]",15,28330,8ebf3c29e7934821ccdb3339bb500800c7688bd3,55,10,10,6717,,,0,"Improve EC2 API error responses.

Implements blueprint ec2-error-codes

Proper EC2 error codes are returned where possible.

Redundant logging code was united in new ec2_error_ex() helper function
and all standard EC2 error responses are now uniformly logged on DEBUG
log level because they are just responses to invalid client requests,
not nova errors. New unit tests are provided.

Unexpected client/server errors are logged on ERROR/CRITICAL level and
their exception name is used as error code - no more useless
UnknownError. Error descriptions are supressed for unexpected server
errors as they might contain sensitive information.

EC2APIError was removed and replaced by specific exceptions. New EC2
exceptions were introduced with ec2_code attribute providing the EC2
error code.

Also fixed malformed error message in compute/api.py that broke the
tests.

Change-Id: I434ab63eae4eb49a45aff671a79ba3c488220cea
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/28330/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_api.py', 'nova/api/ec2/__init__.py', 'nova/exception.py', 'nova/api/ec2/faults.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py', 'nova/tests/api/ec2/test_ec2_validate.py', 'nova/compute/api.py', 'nova/tests/test_exception.py']",9,7289083c6786c54b071ef6736c111638928299ef,bp/ec2-error-codes,,"class EC2APIErrorTestCase(test.TestCase): def test_return_valid_error(self): # without 'code' arg err = exception.EC2APIError('fake error') self.assertEqual(err.__str__(), 'fake error') self.assertEqual(err.code, None) self.assertEqual(err.msg, 'fake error') # with 'code' arg err = exception.EC2APIError('fake error', 'blah code') self.assertEqual(err.code, 'blah code') self.assertEqual(err.msg, 'fake error') ",279,230
openstack%2Fpuppet-swift~master~Iafb67f116a9403bba96328be7c9c09d21a65a74c,openstack/puppet-swift,master,Iafb67f116a9403bba96328be7c9c09d21a65a74c,Add swift::bench to manage swift-bench.conf,MERGED,2013-06-08 16:05:51.000000000,2013-07-17 18:16:41.000000000,2013-07-17 18:16:41.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 6967}, {'_account_id': 7156}, {'_account_id': 8049}]","[{'number': 1, 'created': '2013-06-08 16:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/d9ad55b6b915aee19090fbc7b14be3f98e5c9463', 'message': 'Add swift::bench to manage swift-bench.conf\n\nThis patch adds a conf file swift-bench.conf\nfor swift performance bench.\n\nFixed bug 1188968\n\nChange-Id: Iafb67f116a9403bba96328be7c9c09d21a65a74c\n'}, {'number': 2, 'created': '2013-06-15 03:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/a266d0c25fccbe546b3d41af9c3b3701fd334d95', 'message': 'Add swift::bench to manage swift-bench.conf\n\nThis patch adds a conf file swift-bench.conf\nfor swift performance bench.\n\nFixed bug 1188968\n\nChange-Id: Iafb67f116a9403bba96328be7c9c09d21a65a74c\n'}, {'number': 3, 'created': '2013-06-17 12:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/9c83ef2e611f69e2ae22796aa3110a7eccf7e7bd', 'message': 'Add swift::bench to manage swift-bench.conf\n\nThis patch adds a conf file swift-bench.conf\nfor swift performance bench, and add a spec\ntest for it.\n\nFixed bug 1188968\n\nChange-Id: Iafb67f116a9403bba96328be7c9c09d21a65a74c\n'}, {'number': 4, 'created': '2013-07-05 03:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/9e67f850c33cfb21b5dc092d449af21802c69e93', 'message': 'Add swift::bench to manage swift-bench.conf\n\nThis patch adds a conf file swift-bench.conf\nfor swift performance bench, and add a spec\ntest for it.\n\nFixed bug 1188968\n\nChange-Id: Iafb67f116a9403bba96328be7c9c09d21a65a74c\n'}, {'number': 5, 'created': '2013-07-17 02:54:10.000000000', 'files': ['templates/swift-bench.conf.erb', 'manifests/bench.pp', 'spec/classes/swift_bench_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/45cec2d3fbc6910eb9ffc1470317e515e532aead', 'message': 'Add swift::bench to manage swift-bench.conf\n\nThis patch adds a conf file swift-bench.conf\nfor swift performance bench, and add a spec\ntest for it.\n\nFixed bug 1188968\n\nChange-Id: Iafb67f116a9403bba96328be7c9c09d21a65a74c\n'}]",6,32270,45cec2d3fbc6910eb9ffc1470317e515e532aead,28,7,5,1607,,,0,"Add swift::bench to manage swift-bench.conf

This patch adds a conf file swift-bench.conf
for swift performance bench, and add a spec
test for it.

Fixed bug 1188968

Change-Id: Iafb67f116a9403bba96328be7c9c09d21a65a74c
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/70/32270/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/swift-bench.conf.erb', 'manifests/bench.pp']",2,d9ad55b6b915aee19090fbc7b14be3f98e5c9463,bug/1188968,"# Configure swift-bench.conf for swift performance bench class swift::bench ( $auth_url = 'http://localhost:8080/auth/v1.0', $swift_user = 'test:tester', $swift_key = 'testing', $auth_version = '1.0', ){ file {'/etc/swift/swift-bench.conf': ensure => present, mode => 0650, content => template('swift/swift-bench.conf.erb') } } ",,74,0
openstack%2Fpython-swiftclient~master~I727537177849d08bb9603aa884152bdebc62fb85,openstack/python-swiftclient,master,I727537177849d08bb9603aa884152bdebc62fb85,Added log statements in swift client,MERGED,2013-07-16 21:44:35.000000000,2013-07-17 18:00:50.000000000,2013-07-17 18:00:50.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 2622}, {'_account_id': 2696}, {'_account_id': 4463}, {'_account_id': 8158}]","[{'number': 1, 'created': '2013-07-16 21:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/b82afb8403e6e7009dd5ec3fea9ebb34f3ec5241', 'message': 'Added log statements in swift client\n\nAdded log statements in swiftclient/client.py:_retry where exceptions\nare being raised.\n\nFixes bug# 1783\n\nChange-Id: I727537177849d08bb9603aa884152bdebc62fb85\n'}, {'number': 2, 'created': '2013-07-17 14:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/e2acfdadbe7a86a96a6baa28880d2946a4ac35d6', 'message': 'Added log statements in swift client\n\nAdded log statements in swiftclient/client.py:_retry where exceptions\nare being raised.\n\nFixes bug# 1202229\n\nChange-Id: I727537177849d08bb9603aa884152bdebc62fb85\n'}, {'number': 3, 'created': '2013-07-17 15:11:34.000000000', 'files': ['swiftclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/2f84a4e76b03863fe2e62515f150580b09dc20d1', 'message': 'Added log statements in swift client\n\nAdded log statements in swiftclient/client.py:_retry where exceptions\nare being raised.\n\nFixes bug# 1202229\n\nChange-Id: I727537177849d08bb9603aa884152bdebc62fb85\n'}]",2,37336,2f84a4e76b03863fe2e62515f150580b09dc20d1,16,6,3,8158,,,0,"Added log statements in swift client

Added log statements in swiftclient/client.py:_retry where exceptions
are being raised.

Fixes bug# 1202229

Change-Id: I727537177849d08bb9603aa884152bdebc62fb85
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/36/37336/3 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/client.py'],1,b82afb8403e6e7009dd5ec3fea9ebb34f3ec5241,bug/1202229," except (socket.error, HTTPException) as e: logger.exception(e) logger.exception(err)"," except (socket.error, HTTPException):",3,1
openstack%2Fpython-cinderclient~master~I6c0047adbc33d0d6b5890f11853974578c36c78c,openstack/python-cinderclient,master,I6c0047adbc33d0d6b5890f11853974578c36c78c,"Revert ""Use exceptions from oslo""",MERGED,2013-07-15 16:30:19.000000000,2013-07-17 17:54:03.000000000,2013-07-17 17:54:03.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-07-15 16:30:19.000000000', 'files': ['cinderclient/client.py', 'cinderclient/exceptions.py', 'cinderclient/base.py', 'cinderclient/tests/test_base.py', 'cinderclient/tests/test_utils.py', 'cinderclient/tests/test_http.py', 'cinderclient/openstack/common/apiclient/__init__.py', 'cinderclient/tests/v2/test_auth.py', 'cinderclient/shell.py', 'cinderclient/v1/shell.py', 'cinderclient/tests/v1/test_auth.py', 'cinderclient/openstack/common/apiclient/exceptions.py', 'cinderclient/v2/shell.py', 'cinderclient/tests/utils.py', 'cinderclient/utils.py', 'cinderclient/tests/test_service_catalog.py', 'cinderclient/tests/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/3d30126e93b66488b5c680578f6078201cdedc15', 'message': 'Revert ""Use exceptions from oslo""\n\nThis reverts commit a7cce08eab5e2e42275b84bd56127bd09b00f5bf\n\nChange-Id: I6c0047adbc33d0d6b5890f11853974578c36c78c\n'}]",0,37089,3d30126e93b66488b5c680578f6078201cdedc15,7,3,1,2243,,,0,"Revert ""Use exceptions from oslo""

This reverts commit a7cce08eab5e2e42275b84bd56127bd09b00f5bf

Change-Id: I6c0047adbc33d0d6b5890f11853974578c36c78c
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/89/37089/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/client.py', 'cinderclient/exceptions.py', 'cinderclient/base.py', 'cinderclient/tests/test_base.py', 'cinderclient/tests/test_utils.py', 'cinderclient/tests/test_http.py', 'cinderclient/openstack/common/apiclient/__init__.py', 'cinderclient/tests/v2/test_auth.py', 'cinderclient/shell.py', 'cinderclient/v1/shell.py', 'cinderclient/tests/v1/test_auth.py', 'cinderclient/openstack/common/apiclient/exceptions.py', 'cinderclient/v2/shell.py', 'cinderclient/tests/utils.py', 'cinderclient/utils.py', 'cinderclient/tests/test_service_catalog.py', 'cinderclient/tests/test_shell.py']",17,3d30126e93b66488b5c680578f6078201cdedc15,37086,from cinderclient import exceptions,from cinderclient.openstack.common.apiclient import exceptions,182,498
openstack%2Fmurano-deployment~master~I6a93f335f5058e66864a3d8f58bb57972b555ab3,openstack/murano-deployment,master,I6a93f335f5058e66864a3d8f58bb57972b555ab3,Encoding changed.,MERGED,2013-07-17 17:22:05.000000000,2013-07-17 17:37:58.000000000,2013-07-17 17:37:58.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-17 17:22:05.000000000', 'files': ['image-builder/share/scripts/wpi.ps1', 'image-builder/share/scripts/Start-Sysprep.ps1'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/1e6df74e03fac4b88698039b34807461ad7572c1', 'message': 'Encoding changed.\n\nChange-Id: I6a93f335f5058e66864a3d8f58bb57972b555ab3\n'}]",0,37536,1e6df74e03fac4b88698039b34807461ad7572c1,5,2,1,7562,,,0,"Encoding changed.

Change-Id: I6a93f335f5058e66864a3d8f58bb57972b555ab3
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/36/37536/1 && git format-patch -1 --stdout FETCH_HEAD,"['image-builder/share/scripts/wpi.ps1', 'image-builder/share/scripts/Start-Sysprep.ps1']",2,1e6df74e03fac4b88698039b34807461ad7572c1,image-builder-update,,,0,0
openstack%2Fneutron~master~I33c0b9b079f320b0a3e741c93a7735547cb61b7d,openstack/neutron,master,I33c0b9b079f320b0a3e741c93a7735547cb61b7d,Reference driver implementation (IPsec) for VPNaaS,ABANDONED,2013-07-17 17:34:46.000000000,2013-07-17 17:37:53.000000000,,[],"[{'number': 1, 'created': '2013-07-17 17:34:46.000000000', 'files': ['neutron/db/vpn/vpn_db.py', 'neutron/agent/l3_agent.py', 'neutron/services/vpn/agent.py', 'neutron/services/vpn/device_drivers/template/ipsec.secret.template', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'requirements.txt', 'neutron/tests/unit/nicira/test_nicira_plugin.py', 'neutron/tests/unit/test_agent_netns_wrapper.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/agent/linux/netns_wrapper.py', 'neutron/services/vpn/common/topics.py', 'etc/vpn_agent.ini', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/services/vpn/device_drivers/strongswan.py', 'neutron/tests/unit/services/vpn/device_drivers/__init__.py', 'neutron/services/vpn/device_drivers/template/ipsec.conf.template', 'neutron/tests/unit/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron/tests/unit/services/vpn/device_drivers/test_strongswan.py', 'neutron/services/vpn/plugin.py', 'neutron/services/vpn/device_drivers/template/strongswan.conf.template', 'neutron/common/config.py', 'neutron/tests/unit/metaplugin/test_basic.py', 'neutron/services/vpn/device_drivers/__init__.py', 'neutron/services/vpn/service_drivers/ipsec.py', 'setup.cfg', 'etc/neutron/rootwrap.d/vpnaas.filters', 'neutron/services/vpn/common/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f9d2ee2821026eae0e222d3cf854d6e93b2c6807', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nReference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nVPN connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I33c0b9b079f320b0a3e741c93a7735547cb61b7d\n'}]",0,37538,f9d2ee2821026eae0e222d3cf854d6e93b2c6807,1,0,1,2031,,,0,"Reference driver implementation (IPsec) for VPNaaS

Implements blueprint ipsec-vpn-reference

Reference driver implementation (IPsec) for VPNaaS

Implements blueprint ipsec-vpn-reference

This patch implements reference driver implementation for VPNaaS.
The driver uses strongswan to manage vpn connections.

Future work:
VPN connection status update by actual status
Support ikepolicy and ipsec update
Support multiple driver
Support service type framework

This patch will add Jinja2 for dependencies. Jinja2 is a template library
used to generate strongswan config files.

This patch introduces neutron-netns-wrapper command.
- Multiple instances of Strongswan cannot be launched in the same host ""as is"",
  because the locations of its configuration,  pid and control socket file
  are hard coded.
  In addition,  since Strongswan will be launched in a network namespace
  using ""ip netns"" command,  it needs to run in a mount namespace created
  by this command.
- The solution is to use a wrapper that bind-mount the required directories
  in a separate folder. This mount will only affect the subprocess launched
  by the wrapper.
- This wrapper also enforces rootwrap filter validation to make sure it can't
  be used to run unauthorized commands as root.
- The wrapper can be launched as follow:

ip netns exec test_ns neutron-netns-wrapper -d \
  --cmd ""ipsec,start"" \
  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \
  --rootwrap_config /etc/neutron/rootwrap.conf

Change-Id: I33c0b9b079f320b0a3e741c93a7735547cb61b7d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/38/37538/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/vpn/vpn_db.py', 'neutron/agent/l3_agent.py', 'neutron/services/vpn/agent.py', 'neutron/services/vpn/device_drivers/template/ipsec.secret.template', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'requirements.txt', 'neutron/tests/unit/nicira/test_nicira_plugin.py', 'neutron/tests/unit/test_agent_netns_wrapper.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/agent/linux/netns_wrapper.py', 'neutron/services/vpn/common/topics.py', 'etc/vpn_agent.ini', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/services/vpn/device_drivers/strongswan.py', 'neutron/tests/unit/services/vpn/device_drivers/__init__.py', 'neutron/services/vpn/device_drivers/template/ipsec.conf.template', 'neutron/tests/unit/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron/tests/unit/services/vpn/device_drivers/test_strongswan.py', 'neutron/services/vpn/plugin.py', 'neutron/services/vpn/device_drivers/template/strongswan.conf.template', 'neutron/common/config.py', 'neutron/tests/unit/metaplugin/test_basic.py', 'neutron/services/vpn/device_drivers/__init__.py', 'neutron/services/vpn/service_drivers/ipsec.py', 'setup.cfg', 'etc/neutron/rootwrap.d/vpnaas.filters', 'neutron/services/vpn/common/__init__.py']",30,f9d2ee2821026eae0e222d3cf854d6e93b2c6807,ipsec_driver,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Copyright 2013, Nachi Ueno, NTT I3, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",,2003,14
openstack%2Fdevstack~master~Icf08409c9443ec703e5f1da4531aa34c326f3642,openstack/devstack,master,Icf08409c9443ec703e5f1da4531aa34c326f3642,Only create swift account if swift enabled,MERGED,2013-07-17 11:05:07.000000000,2013-07-17 17:33:07.000000000,2013-07-17 17:33:07.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 6473}]","[{'number': 1, 'created': '2013-07-17 11:05:07.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0ff314c01dc1184fc443a85f4110615f32ec8d90', 'message': 'Only create swift account if swift enabled\n\nOnly call the swift account creation function if swift is enabled,\notherwise the endpoints are created in keystone even though swift\nisn\'t running.\n\nThis causes failures when tempest queries keystone and thinks swift is\nthere; it starts running tests against it that fail with unhelpful\n""connection refused"" errors.\n\nChange-Id: Icf08409c9443ec703e5f1da4531aa34c326f3642\n'}]",2,37447,0ff314c01dc1184fc443a85f4110615f32ec8d90,11,6,1,7118,,,0,"Only create swift account if swift enabled

Only call the swift account creation function if swift is enabled,
otherwise the endpoints are created in keystone even though swift
isn't running.

This causes failures when tempest queries keystone and thinks swift is
there; it starts running tests against it that fail with unhelpful
""connection refused"" errors.

Change-Id: Icf08409c9443ec703e5f1da4531aa34c326f3642
",git fetch https://review.opendev.org/openstack/devstack refs/changes/47/37447/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,0ff314c01dc1184fc443a85f4110615f32ec8d90,swift-acc, if is_service_enabled swift || is_service_enabled s-proxy; then create_swift_accounts fi , create_swift_accounts,4,1
openstack%2Ftripleo-image-elements~master~I7c66c594d373219b3843590608d3ce4d088dbfc1,openstack/tripleo-image-elements,master,I7c66c594d373219b3843590608d3ce4d088dbfc1,Use source-repository interface in clients element,MERGED,2013-07-17 17:32:29.000000000,2013-07-17 17:32:29.000000000,2013-07-17 17:32:29.000000000,"[{'_account_id': 3}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-17 17:32:29.000000000', 'files': ['elements/openstack-clients/source-repository-clients', 'elements/openstack-clients/install.d/51-openstack-clients'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5494cdd18f3d139b472ade00ba33c6da7fd459c9', 'message': 'Use source-repository interface in clients element\n\nChange-Id: I7c66c594d373219b3843590608d3ce4d088dbfc1\n'}]",0,37531,5494cdd18f3d139b472ade00ba33c6da7fd459c9,5,2,1,1926,,,0,"Use source-repository interface in clients element

Change-Id: I7c66c594d373219b3843590608d3ce4d088dbfc1
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/31/37531/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/openstack-clients/source-repository-clients', 'elements/openstack-clients/install.d/51-openstack-clients']",2,5494cdd18f3d139b472ade00ba33c6da7fd459c9,source-repository,, git clone --depth 1 https://github.com/openstack/$repo.git /opt/stack/$repo ,5,2
openstack%2Ftripleo-image-elements~master~Ie98457275fb3842d84360ea65af51fff6d0171c4,openstack/tripleo-image-elements,master,Ie98457275fb3842d84360ea65af51fff6d0171c4,Use source-repository interface in novnc element,MERGED,2013-07-17 17:32:29.000000000,2013-07-17 17:32:29.000000000,2013-07-17 17:32:29.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-17 17:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0dab9ac77876169678a21d992e15a52a385a2326', 'message': 'Use source-repository interface in novnv element\n\nChange-Id: Ie98457275fb3842d84360ea65af51fff6d0171c4\n'}, {'number': 3, 'created': '2013-07-17 17:32:29.000000000', 'files': ['elements/novnc/element-deps', 'elements/novnc/source-repository-novnc', 'elements/novnc/install.d/50-install-novnc'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5237287ed20d53f8da42b7ff5f5b1be3a9c96052', 'message': 'Use source-repository interface in novnc element\n\nChange-Id: Ie98457275fb3842d84360ea65af51fff6d0171c4\n'}, {'number': 2, 'created': '2013-07-17 17:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/43c8a0ac6313142a7bf52514a32a827703147c55', 'message': 'Use source-repository interface in novnv element\n\nChange-Id: Ie98457275fb3842d84360ea65af51fff6d0171c4\n'}]",1,36053,5237287ed20d53f8da42b7ff5f5b1be3a9c96052,11,3,3,1926,,,0,"Use source-repository interface in novnc element

Change-Id: Ie98457275fb3842d84360ea65af51fff6d0171c4
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/53/36053/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/novnc/element-deps', 'elements/novnc/source-repository-novnc', 'elements/novnc/install.d/50-install-novnc']",3,0dab9ac77876169678a21d992e15a52a385a2326,source-repository,,git clone --depth=1 https://github.com/kanaka/noVNC.git /opt/stack/novnc,2,1
openstack%2Ftripleo-image-elements~master~I208ceb1c62d7718375ffb5a4d11eaebb1e176131,openstack/tripleo-image-elements,master,I208ceb1c62d7718375ffb5a4d11eaebb1e176131,Use source-repository interface in devstack element,MERGED,2013-07-17 17:32:27.000000000,2013-07-17 17:32:27.000000000,2013-07-17 17:32:27.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-17 17:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/70091158e8bcb5f07c56543f8f26cc9d469955bb', 'message': 'Use source-repository interface in devstack element\n\nChange-Id: I208ceb1c62d7718375ffb5a4d11eaebb1e176131\n'}, {'number': 2, 'created': '2013-07-17 17:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/94b8610cb004828744e7d61a0cb4c81486652c75', 'message': 'Use source-repository interface in devstack element\n\nChange-Id: I208ceb1c62d7718375ffb5a4d11eaebb1e176131\n'}, {'number': 3, 'created': '2013-07-17 17:32:27.000000000', 'files': ['elements/devstack/install.d/52-image-toolchain', 'elements/devstack/element-deps', 'elements/devstack/install.d/53-devstack', 'elements/devstack/source-repository-devstack', 'elements/devstack/source-repository-incubator'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/70fbc1839553b722bff64aac919d6cde41daca38', 'message': 'Use source-repository interface in devstack element\n\nChange-Id: I208ceb1c62d7718375ffb5a4d11eaebb1e176131\n'}]",0,36054,70fbc1839553b722bff64aac919d6cde41daca38,10,3,3,1926,,,0,"Use source-repository interface in devstack element

Change-Id: I208ceb1c62d7718375ffb5a4d11eaebb1e176131
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/54/36054/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/devstack/install.d/52-image-toolchain', 'elements/devstack/element-deps', 'elements/devstack/install.d/53-devstack', 'elements/devstack/source-repository-devstack', 'elements/devstack/source-repository-incubator']",5,70091158e8bcb5f07c56543f8f26cc9d469955bb,source-repository,incubator git ~stack/incubator https://github.com/tripleo/incubator-bootstrap.git ,,7,2
openstack%2Ftripleo-image-elements~master~I5d50cec88acc1f2e407a7d9f8fee0dbbdd34abdb,openstack/tripleo-image-elements,master,I5d50cec88acc1f2e407a7d9f8fee0dbbdd34abdb,Use source-repository interface in orc element,MERGED,2013-07-17 17:32:21.000000000,2013-07-17 17:32:21.000000000,2013-07-17 17:32:21.000000000,"[{'_account_id': 3}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-17 17:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0eb3cf080b85c4be7c8cd6d54206566635eb373d', 'message': 'Use source-repository interface in orc element\n\nChange-Id: I5d50cec88acc1f2e407a7d9f8fee0dbbdd34abdb\n'}, {'number': 2, 'created': '2013-07-17 17:32:21.000000000', 'files': ['elements/os-refresh-config/source-repository-os-refresh-config', 'elements/os-refresh-config/element-deps', 'elements/os-refresh-config/install.d/01-os-refresh-config'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/84cd541e0466c84e86b95c3762ed60a6bf3b625c', 'message': 'Use source-repository interface in orc element\n\nChange-Id: I5d50cec88acc1f2e407a7d9f8fee0dbbdd34abdb\n'}]",0,36057,84cd541e0466c84e86b95c3762ed60a6bf3b625c,7,2,2,1926,,,0,"Use source-repository interface in orc element

Change-Id: I5d50cec88acc1f2e407a7d9f8fee0dbbdd34abdb
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/57/36057/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/os-refresh-config/source-repository-os-refresh-config', 'elements/os-refresh-config/element-deps', 'elements/os-refresh-config/install.d/01-os-refresh-config']",3,0eb3cf080b85c4be7c8cd6d54206566635eb373d,source-repository,pip install /opt/stack/os-refresh-config,pip install git+https://github.com/stackforge/os-refresh-config.git,3,1
openstack%2Fnova~master~Ia8603c321839b959b120af1d018f061f438155c7,openstack/nova,master,Ia8603c321839b959b120af1d018f061f438155c7,Fix accessing to '/' of metadata server without any checks to work,MERGED,2013-07-12 04:07:08.000000000,2013-07-17 17:31:56.000000000,2013-07-17 17:31:53.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 6678}]","[{'number': 1, 'created': '2013-07-12 04:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/634029030922448a8368d0d70a67bd62d4bd0a84', 'message': ""Fix accessing to '/' of metadata server without any checks to work\n\nAccessing to '/' of metadata server to get version information should\nbe allowed without any checks. Due to the wrong comparison condition,\nit failed.\n\nChange-Id: Ia8603c321839b959b120af1d018f061f438155c7\nFixes: bug #1192774\n""}, {'number': 2, 'created': '2013-07-17 02:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfc411410058c7442eceedf8e22520c84f60cb4d', 'message': ""Fix accessing to '/' of metadata server without any checks to work\n\nAccessing to '/' of metadata server to get version information should\nbe allowed without any checks. Due to the wrong comparison condition,\nit failed.\n\nChange-Id: Ia8603c321839b959b120af1d018f061f438155c7\nFixes: bug #1192774\n""}, {'number': 3, 'created': '2013-07-17 02:59:29.000000000', 'files': ['nova/api/metadata/handler.py', 'nova/tests/test_metadata.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/64bdf2a163bca0505541903229e1072a36bba87f', 'message': ""Fix accessing to '/' of metadata server without any checks to work\n\nAccessing to '/' of metadata server to get version information should\nbe allowed without any checks. Due to the wrong comparison condition,\nit failed.\n\nChange-Id: Ia8603c321839b959b120af1d018f061f438155c7\nFixes: bug #1192774\n""}]",1,36775,64bdf2a163bca0505541903229e1072a36bba87f,16,6,3,6678,,,0,"Fix accessing to '/' of metadata server without any checks to work

Accessing to '/' of metadata server to get version information should
be allowed without any checks. Due to the wrong comparison condition,
it failed.

Change-Id: Ia8603c321839b959b120af1d018f061f438155c7
Fixes: bug #1192774
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/36775/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/metadata/handler.py', 'nova/tests/test_metadata.py']",2,634029030922448a8368d0d70a67bd62d4bd0a84,bug/1192774," def test_root_metadata_proxy_enabled(self): CONF.set_override(""service_quantum_metadata_proxy"", True) expected = ""\n"".join(base.VERSIONS) + ""\nlatest"" response = fake_request(self.stubs, self.mdinst, ""/"") self.assertEqual(response.body, expected) response = fake_request(self.stubs, self.mdinst, ""/foo/../"") self.assertEqual(response.body, expected) ",,11,1
openstack%2Fbarbican~master~I9df8ec52c96c6cbe63c1f1af85e9a60ef507ff69,openstack/barbican,master,I9df8ec52c96c6cbe63c1f1af85e9a60ef507ff69,Restrict use of 'plain_text' to 'text/plain' MIME,MERGED,2013-07-16 21:58:06.000000000,2013-07-17 17:21:59.000000000,2013-07-17 17:21:59.000000000,"[{'_account_id': 3}, {'_account_id': 7789}, {'_account_id': 8133}]","[{'number': 1, 'created': '2013-07-16 21:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/9438c19bb4bb76180eea8030d10104f9513793d6', 'message': 'Handle exceptions caused by invalid plain text\n\nWhen creating a secret of \'mime_type\' ""application/octet-stream""\nwith supplied \'plain_text\', a ValueError would be thrown during\nthe encryption step. This resulted in a 500 HTTP status. Now, the\nexception is properly handled and 415 status code is returned.\n\nFixes: bug #1200659\nChange-Id: I9df8ec52c96c6cbe63c1f1af85e9a60ef507ff69\n'}, {'number': 2, 'created': '2013-07-17 16:56:33.000000000', 'files': ['barbican/common/validators.py', 'barbican/tests/api/validators_test.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/b7508ebf292f16428c35498371e44366378c8bf2', 'message': ""Restrict use of 'plain_text' to 'text/plain' MIME\n\nWhen creating a secret with a non 'text/plain' MIME type with\nsupplied 'plain_text', a ValueError would be thrown during the\nencryption step. This resulted in a 500 HTTP status. Now when\na create secret request is sent with a 'plain_text' field\nprovided and a non 'text/plain' MIME type, a 400 HTTP status\nis returned.\n\nFixes: bug #1200659\nChange-Id: I9df8ec52c96c6cbe63c1f1af85e9a60ef507ff69\n""}]",4,37338,b7508ebf292f16428c35498371e44366378c8bf2,8,3,2,8133,,,0,"Restrict use of 'plain_text' to 'text/plain' MIME

When creating a secret with a non 'text/plain' MIME type with
supplied 'plain_text', a ValueError would be thrown during the
encryption step. This resulted in a 500 HTTP status. Now when
a create secret request is sent with a 'plain_text' field
provided and a non 'text/plain' MIME type, a 400 HTTP status
is returned.

Fixes: bug #1200659
Change-Id: I9df8ec52c96c6cbe63c1f1af85e9a60ef507ff69
",git fetch https://review.opendev.org/openstack/barbican refs/changes/38/37338/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/api/resources.py', 'barbican/common/resources.py']",2,9438c19bb4bb76180eea8030d10104f9513793d6,bug/1200659," try: new_datum = crypto_manager.encrypt(data['plain_text'], new_secret, tenant) except ValueError: raise exception.Invalid() "," new_datum = crypto_manager.encrypt(data['plain_text'], new_secret, tenant)",21,3
openstack%2Fpython-novaclient~master~I8ff689c3a2f20d489286f80112c6dc95c97f2f31,openstack/python-novaclient,master,I8ff689c3a2f20d489286f80112c6dc95c97f2f31,Fix and enable gating on H402,MERGED,2013-06-29 10:10:03.000000000,2013-07-17 17:10:19.000000000,2013-07-17 17:10:18.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5638}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-06-29 10:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/1c9adea75eaa324dcf770fbe74bea6739f8ba8b9', 'message': 'Fix and enable gating on H402\n\nEnd one-line docstrings with punctuation.\nChange them to command style where necessary.\n\nChange-Id: I8ff689c3a2f20d489286f80112c6dc95c97f2f31\n'}, {'number': 2, 'created': '2013-07-17 13:44:12.000000000', 'files': ['novaclient/v1_1/limits.py', 'novaclient/v1_1/agents.py', 'novaclient/v1_1/hosts.py', 'novaclient/v1_1/shell.py', 'novaclient/utils.py', 'novaclient/v1_1/contrib/baremetal.py', 'novaclient/v1_1/floating_ip_dns.py', 'novaclient/v1_1/flavor_access.py', 'tox.ini', 'novaclient/tests/test_utils.py', 'novaclient/v1_1/services.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/af7ca70e3e676bbd8cd20c3847233e6e25a71fde', 'message': 'Fix and enable gating on H402\n\nEnd one-line docstrings with punctuation.\nChange them to command style where necessary.\n\nChange-Id: I8ff689c3a2f20d489286f80112c6dc95c97f2f31\n'}]",0,34990,af7ca70e3e676bbd8cd20c3847233e6e25a71fde,15,5,2,6593,,,0,"Fix and enable gating on H402

End one-line docstrings with punctuation.
Change them to command style where necessary.

Change-Id: I8ff689c3a2f20d489286f80112c6dc95c97f2f31
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/90/34990/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/v1_1/limits.py', 'novaclient/v1_1/agents.py', 'novaclient/v1_1/shell.py', 'novaclient/utils.py', 'novaclient/v1_1/contrib/baremetal.py', 'novaclient/v1_1/flavor_access.py', 'novaclient/tests/test_utils.py', 'novaclient/v1_1/hosts.py', 'tools/install_venv.py', 'novaclient/v1_1/floating_ip_dns.py', 'tox.ini', 'novaclient/v1_1/services.py']",12,1c9adea75eaa324dcf770fbe74bea6739f8ba8b9,H402," """"""Enable the service specified by hostname and binary."""""" """"""Disable the service specified by hostname and binary."""""""," """"""Enable the service specified by hostname and binary"""""" """"""Enable the service specified by hostname and binary""""""",58,58
openstack%2Fcinder~master~Id2523cfaaf61c7d6dec51c0daf6255d9de5d50f3,openstack/cinder,master,Id2523cfaaf61c7d6dec51c0daf6255d9de5d50f3,Checks the volume_clear flag and just return if it is none,MERGED,2013-07-17 08:59:17.000000000,2013-07-17 17:07:48.000000000,2013-07-17 17:07:48.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 4355}, {'_account_id': 4523}]","[{'number': 1, 'created': '2013-07-17 08:59:17.000000000', 'files': ['cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f04600a5f545baa3c947c3acadb72d14fd2ef758', 'message': 'Checks the volume_clear flag and just return if it is none\n\nRefactors the clear_volume method in LVMVolumeDriver, checks the\nvolume_clear flag firstly and return directly if it is none.\n\nChange-Id: Id2523cfaaf61c7d6dec51c0daf6255d9de5d50f3\n'}]",0,37428,f04600a5f545baa3c947c3acadb72d14fd2ef758,8,4,1,2481,,,0,"Checks the volume_clear flag and just return if it is none

Refactors the clear_volume method in LVMVolumeDriver, checks the
volume_clear flag firstly and return directly if it is none.

Change-Id: Id2523cfaaf61c7d6dec51c0daf6255d9de5d50f3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/28/37428/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/lvm.py'],1,f04600a5f545baa3c947c3acadb72d14fd2ef758,check_volume_clear_flag, if self.configuration.volume_clear == 'none': return , if self.configuration.volume_clear == 'none': return ,3,3
openstack%2Fceilometer~master~Id1368c7ccf730bc62bc2b32247266e87482844cb,openstack/ceilometer,master,Id1368c7ccf730bc62bc2b32247266e87482844cb,Default to ctx user/project ID in sample POST API,MERGED,2013-07-17 11:37:34.000000000,2013-07-17 16:55:49.000000000,2013-07-17 16:55:49.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 4715}, {'_account_id': 5055}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-17 11:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/43b70f4bab90308c1370759a91e8815e640c26c5', 'message': ""Default to ctx user/project ID in sample POST API\n\nFixes bug #1202143\n\nAvoid RPC failure when project and user IDs not explicitly\nspecified in POST'd sample.\n\nInstead default to identity in current context.\n\nChange-Id: Id1368c7ccf730bc62bc2b32247266e87482844cb\n""}, {'number': 2, 'created': '2013-07-17 15:16:50.000000000', 'files': ['tests/api/v2/post_samples.py', 'ceilometer/api/controllers/v2.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1d0b6397d468d8527ad3b388ee2f2b1714f3c38d', 'message': ""Default to ctx user/project ID in sample POST API\n\nFixes bug #1202143\n\nAvoid RPC failure when project and user IDs not explicitly\nspecified in POST'd sample.\n\nInstead default to identity in current context.\n\nChange-Id: Id1368c7ccf730bc62bc2b32247266e87482844cb\n""}]",0,37449,1d0b6397d468d8527ad3b388ee2f2b1714f3c38d,14,7,2,2284,,,0,"Default to ctx user/project ID in sample POST API

Fixes bug #1202143

Avoid RPC failure when project and user IDs not explicitly
specified in POST'd sample.

Instead default to identity in current context.

Change-Id: Id1368c7ccf730bc62bc2b32247266e87482844cb
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/49/37449/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/api/v2/post_samples.py', 'ceilometer/api/controllers/v2.py']",2,43b70f4bab90308c1370759a91e8815e640c26c5,, s.user_id = s.user_id or pecan.request.headers.get('X-User-Id') s.project_id = (s.project_id or pecan.request.headers.get('X-Project-Id')) ,,30,0
openstack%2Fsahara~master~Ie1bfaa421fce22efd3115ba13758932b6b592d7a,openstack/sahara,master,Ie1bfaa421fce22efd3115ba13758932b6b592d7a,Cluster scaling: deletion,MERGED,2013-07-09 16:36:02.000000000,2013-07-17 16:53:51.000000000,2013-07-17 16:53:51.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7478}]","[{'number': 1, 'created': '2013-07-09 16:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7f6f8252f19c745dff0efee0f425c780b4c202b0', 'message': 'Cluster scaling: deletion\n\nInmplemented:\n* exclude/include files mechanism is implemented\n* adding instances was change\n* removing instances works ok\n\nTODOs:\n* validation for deleting\n\nImplements blueprint delete-instances\n\nChange-Id: Ie1bfaa421fce22efd3115ba13758932b6b592d7a\n'}, {'number': 2, 'created': '2013-07-10 08:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1c49032f98a7037074c343feaee99a964c961990', 'message': 'Cluster scaling: deletion\n\nInmplemented:\n* exclude/include files mechanism is implemented\n* adding instances was change\n* removing instances works ok\n\nTODOs:\n* validation for deleting\n* Plugin refactoring\n\nImplements blueprint delete-instances\n\nChange-Id: Ie1bfaa421fce22efd3115ba13758932b6b592d7a\n'}, {'number': 3, 'created': '2013-07-10 09:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/fe5a87bb9b27c899779c97b6b13f67eb1284eaea', 'message': 'Cluster scaling: deletion\n\nInmplemented:\n* exclude/include files mechanism is implemented\n* adding instances was change\n* removing instances works ok\n\nTODOs:\n* validation for deleting\n* Plugin refactoring\n\nImplements blueprint delete-instances\n\nChange-Id: Ie1bfaa421fce22efd3115ba13758932b6b592d7a\n'}, {'number': 4, 'created': '2013-07-15 15:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/105750a95f48c45f186e39adc22d99af2f63390c', 'message': 'Cluster scaling: deletion\n\nInmplemented:\n* exclude/include files mechanism is implemented\n* adding instances was change\n* removing instances works ok\n* ""slaves"" and ""masters"" are deleted\n\nImplements blueprint delete-instances\n\nChange-Id: Ie1bfaa421fce22efd3115ba13758932b6b592d7a\n'}, {'number': 5, 'created': '2013-07-15 16:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/dc1fbf5a2284dc78cafc7e2806a1a5731c3e3989', 'message': 'Cluster scaling: deletion\n\nInmplemented:\n* exclude/include files mechanism is implemented\n* adding instances was change\n* removing instances works ok\n* ""slaves"" and ""masters"" are deleted\n\nImplements blueprint delete-instances\n\nChange-Id: Ie1bfaa421fce22efd3115ba13758932b6b592d7a\n'}, {'number': 6, 'created': '2013-07-16 15:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/54334b0218fb125f8e5c1eb589fe88fa73e2b3af', 'message': 'Cluster scaling: deletion\n\nInmplemented:\n* exclude/include files mechanism is implemented\n* adding instances was change\n* removing instances works ok\n* ""slaves"" and ""masters"" are deleted\n\nImplements blueprint delete-instances\nImplements blueprint get-rid-of-slaves-file\nFixes: bug #1199884\n\nChange-Id: Ie1bfaa421fce22efd3115ba13758932b6b592d7a\n'}, {'number': 7, 'created': '2013-07-17 13:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/405da726b807541a88ff5d07daeefa64142151fd', 'message': 'Cluster scaling: deletion\n\nInmplemented:\n* exclude/include files mechanism is implemented\n* adding instances was change\n* removing instances works ok\n* ""slaves"" and ""masters"" are deleted\n\nImplements blueprint delete-instances\nImplements blueprint get-rid-of-slaves-file\nFixes: bug #1199884\n\nChange-Id: Ie1bfaa421fce22efd3115ba13758932b6b592d7a\n'}, {'number': 8, 'created': '2013-07-17 15:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a7cdb8740f6e8b0829e68f19e833a90ba542288a', 'message': 'Cluster scaling: deletion\n\nInmplemented:\n* exclude/include files mechanism is implemented\n* adding instances was change\n* removing instances works ok\n* ""slaves"" and ""masters"" are deleted\n\nImplements blueprint delete-instances\nImplements blueprint get-rid-of-slaves-file\nFixes: bug #1199884\n\nChange-Id: Ie1bfaa421fce22efd3115ba13758932b6b592d7a\n'}, {'number': 9, 'created': '2013-07-17 15:36:16.000000000', 'files': ['savanna/tests/unit/resources/dfs_admin_3_nodes.txt', 'savanna/plugins/vanilla/run_scripts.py', 'savanna/plugins/vanilla/scaling.py', 'savanna/service/validations/clusters_scaling.py', 'savanna/plugins/vanilla/plugin.py', 'savanna/tests/unit/plugins/test_dfsadmin_parsing.py', 'savanna/plugins/vanilla/utils.py', 'setup.py', 'savanna/service/api.py', 'savanna/service/instances.py', 'savanna/db/models.py', 'savanna/plugins/vanilla/config_helper.py', 'savanna/tests/unit/resources/dfs_admin_1_nodes.txt', 'savanna/plugins/provisioning.py', 'savanna/tests/unit/resources/dfs_admin_0_nodes.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a4f27a88de089d58a0138af2cc132b0202892562', 'message': 'Cluster scaling: deletion\n\nInmplemented:\n* exclude/include files mechanism is implemented\n* adding instances was change\n* removing instances works ok\n* ""slaves"" and ""masters"" are deleted\n\nImplements blueprint delete-instances\nImplements blueprint get-rid-of-slaves-file\nFixes: bug #1199884\n\nChange-Id: Ie1bfaa421fce22efd3115ba13758932b6b592d7a\n'}]",54,36288,a4f27a88de089d58a0138af2cc132b0202892562,61,6,9,7478,,,0,"Cluster scaling: deletion

Inmplemented:
* exclude/include files mechanism is implemented
* adding instances was change
* removing instances works ok
* ""slaves"" and ""masters"" are deleted

Implements blueprint delete-instances
Implements blueprint get-rid-of-slaves-file
Fixes: bug #1199884

Change-Id: Ie1bfaa421fce22efd3115ba13758932b6b592d7a
",git fetch https://review.opendev.org/openstack/sahara refs/changes/88/36288/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/plugins/vanilla/config_helper.py', 'savanna/plugins/vanilla/plugin.py', 'savanna/plugins/vanilla/utils.py', 'savanna/service/api.py', 'savanna/plugins/provisioning.py', 'savanna/service/instances.py', 'savanna/db/models.py']",7,7f6f8252f19c745dff0efee0f425c780b4c202b0,bug/1199884," backref='node_group', order_by=""Instance.instance_name"")", backref='node_group'),172,55
openstack%2Ftripleo-image-elements~master~I03d564a8fe4fba050b0cafe036d7af6a4fd91462,openstack/tripleo-image-elements,master,I03d564a8fe4fba050b0cafe036d7af6a4fd91462,Use source-repository interface in cinder element,MERGED,2013-07-17 16:53:06.000000000,2013-07-17 16:53:06.000000000,2013-07-17 16:53:06.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6449}]","[{'number': 2, 'created': '2013-07-17 16:53:06.000000000', 'files': ['elements/cinder/install.d/72-cinder', 'elements/cinder/source-repository-cinder', 'elements/cinder/element-deps'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/99ec70b18f3f612c08aa0d4e8a84da192d9672a0', 'message': 'Use source-repository interface in cinder element\n\nChange-Id: I03d564a8fe4fba050b0cafe036d7af6a4fd91462\n'}, {'number': 1, 'created': '2013-07-17 16:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e1af916af4e83bf6a180d86f5e206760cbf8a5f9', 'message': 'Use source-repository interface in cinder element\n\nChange-Id: I03d564a8fe4fba050b0cafe036d7af6a4fd91462\n'}]",0,36048,99ec70b18f3f612c08aa0d4e8a84da192d9672a0,10,3,2,1926,,,0,"Use source-repository interface in cinder element

Change-Id: I03d564a8fe4fba050b0cafe036d7af6a4fd91462
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/48/36048/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/cinder/install.d/72-cinder', 'elements/cinder/source-repository-cinder', 'elements/cinder/element-deps']",3,99ec70b18f3f612c08aa0d4e8a84da192d9672a0,source-repository,source-repositories,,3,1
openstack%2Ftripleo-image-elements~master~I1f8994f94598acba897065a46ce1a87d9de1eeea,openstack/tripleo-image-elements,master,I1f8994f94598acba897065a46ce1a87d9de1eeea,Use source-repository interface in heat element,MERGED,2013-07-17 16:52:14.000000000,2013-07-17 16:52:14.000000000,2013-07-17 16:52:14.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 2, 'created': '2013-07-17 16:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/aea6bdea20d320f9735cab557cc90d5d9f79e160', 'message': 'Use source-repository interface in heat element\n\nChange-Id: I1f8994f94598acba897065a46ce1a87d9de1eeea\n'}, {'number': 3, 'created': '2013-07-17 16:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4df4ed5255c8942ab27e5ba57454fe70b8908d75', 'message': 'Use source-repository interface in heat element\n\nChange-Id: I1f8994f94598acba897065a46ce1a87d9de1eeea\n'}, {'number': 1, 'created': '2013-07-17 16:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/73716293d5cbffa2030ee3a0e6b1b560b7e41874', 'message': 'Use source-repository interface in heat element\n\nChange-Id: I1f8994f94598acba897065a46ce1a87d9de1eeea\n'}, {'number': 4, 'created': '2013-07-17 16:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/333f89a6639b1b0cd391a218e2f4d28c0ef7b1b7', 'message': 'Use source-repository interface in heat element\n\nChange-Id: I1f8994f94598acba897065a46ce1a87d9de1eeea\n'}, {'number': 5, 'created': '2013-07-17 16:52:14.000000000', 'files': ['elements/heat/source-repository-heat', 'elements/heat/install.d/05-heat', 'elements/heat/element-deps'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1e565b60c494ba6ccd0b76e1df979647657682c5', 'message': 'Use source-repository interface in heat element\n\nChange-Id: I1f8994f94598acba897065a46ce1a87d9de1eeea\n'}]",0,36049,1e565b60c494ba6ccd0b76e1df979647657682c5,17,4,5,1926,,,0,"Use source-repository interface in heat element

Change-Id: I1f8994f94598acba897065a46ce1a87d9de1eeea
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/49/36049/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/heat/source-repository-heat', 'elements/heat/install.d/05-heat', 'elements/heat/element-deps']",3,aea6bdea20d320f9735cab557cc90d5d9f79e160,source-repository,source-repositories,,3,1
openstack%2Fceilometer~master~I68c731f65d198d4fa1220f75752f242e74355dfe,openstack/ceilometer,master,I68c731f65d198d4fa1220f75752f242e74355dfe,Multiple dispatcher enablement,MERGED,2013-06-25 04:09:10.000000000,2013-07-17 16:51:28.000000000,2013-07-17 16:51:28.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2860}, {'_account_id': 6537}, {'_account_id': 7336}]","[{'number': 1, 'created': '2013-06-25 04:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1b0b7cf86bb8a89e9fdb0cd27e3d76a19955128f', 'message': 'Multiple dispatcher enablment\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 2, 'created': '2013-06-25 21:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5fd46b8de2eec53c1e16cdcf0ed1411441503ecb', 'message': 'Multiple dispatcher enablment\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 4, 'created': '2013-06-26 15:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fc86abfb63ec2ae5dab9c6616715ce8fef9911b2', 'message': 'Multiple dispatcher enablment\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 3, 'created': '2013-06-26 15:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/18262ccb21e84333045a35804c4298ebbef006d1', 'message': 'Multiple dispatcher enablment\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 6, 'created': '2013-07-05 21:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c7526b23b085d3888e02fc468965ec1a285ffd86', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 5, 'created': '2013-07-05 21:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6d976394547b5e7ac9c370a4978fcea5ee9be442', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 7, 'created': '2013-07-09 22:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5e959480d0203d006f4d40ab1bda3b431bbca32a', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 8, 'created': '2013-07-09 22:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/77ef27440e19f57df438f4e5c73ccf56b9612557', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 9, 'created': '2013-07-11 15:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bae63db280b2858b4f185f4e24dd744368444734', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 10, 'created': '2013-07-11 20:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/67e6e04700b963e1ea40356c3e674ad7694b0584', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 12, 'created': '2013-07-12 21:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f80259640874bcf69f8a872a898f11ea173cb0a4', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 11, 'created': '2013-07-12 21:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5cf8bba6badbf945c23a299160287835dde0fb2e', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 13, 'created': '2013-07-15 15:27:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9d07917677b8c5584968f44dc30e3a97bc7e2ae2', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 14, 'created': '2013-07-16 03:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dbb2c02896f1aca591ac4666176031744bf5566c', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 15, 'created': '2013-07-16 12:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4ab22bd6f0b5fc724e08e668a3ba82b96ed9130c', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 16, 'created': '2013-07-16 19:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/763408ad3fcf3f97455e7144dffafaa8b718279c', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 17, 'created': '2013-07-17 13:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/68e377f9e716873dad35f7ed1e0e3772a7d75419', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 18, 'created': '2013-07-17 13:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5770647b300100a0457a3a9598ab4273e89849d3', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}, {'number': 19, 'created': '2013-07-17 14:00:28.000000000', 'files': ['doc/source/install/manual.rst', 'doc/source/configuration.rst', 'tests/collector/dispatcher/test_db.py', 'tests/collector/dispatcher/__init__.py', 'etc/ceilometer/ceilometer.conf.sample', 'tests/collector/dispatcher/test_file.py', 'ceilometer/collector/dispatcher/__init__.py', 'setup.cfg', 'ceilometer/collector/service.py', 'ceilometer/collector/dispatcher/database.py', 'ceilometer/collector/dispatcher/file.py', 'tests/collector/test_service.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/70226205fd03e4a53ec6f6009291481ca46026f6', 'message': 'Multiple dispatcher enablement\n\nCeilometer does not allow multiple dispatchers to be configured.\nWith this implementation, a deployment can be configured to have\nmultiple dispatchers to direct the meters to database and other\noutlet.\n\nblueprint multi-dispatcher-enablement\n\nChange-Id: I68c731f65d198d4fa1220f75752f242e74355dfe\n'}]",79,34301,70226205fd03e4a53ec6f6009291481ca46026f6,71,8,19,2860,,,0,"Multiple dispatcher enablement

Ceilometer does not allow multiple dispatchers to be configured.
With this implementation, a deployment can be configured to have
multiple dispatchers to direct the meters to database and other
outlet.

blueprint multi-dispatcher-enablement

Change-Id: I68c731f65d198d4fa1220f75752f242e74355dfe
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/01/34301/18 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/dispatcher/dispatcher_log.py', 'ceilometer/dispatcher/dispatcher_db.py', 'setup.cfg', 'ceilometer/collector/service.py', 'ceilometer/dispatcher/__init__.py']",5,1b0b7cf86bb8a89e9fdb0cd27e3d76a19955128f,bp/multi-dispatcher-enablement,"# -*- encoding: utf-8 -*- # # Copyright © 2013 IBM # # Author: Tong Li <litong01@us.ibm.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import abc class _Base(object): __metaclass__ = abc.ABCMeta @abc.abstractmethod def record_metering_data(self, context, data): """"""recording metering data from the collector services"""""" ",,145,37
openstack%2Ftripleo-image-elements~master~I2cb11b073fddd223ba0c30cc2ae89677cf68b6ac,openstack/tripleo-image-elements,master,I2cb11b073fddd223ba0c30cc2ae89677cf68b6ac,Use source-repository interface in keystone element,MERGED,2013-07-17 16:29:52.000000000,2013-07-17 16:29:52.000000000,2013-07-17 16:29:52.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 4, 'created': '2013-07-17 16:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e1e8d06ed66a5932717902292a4cd2d170c3eb6a', 'message': 'Use source-repository interface in keystone element\n\nChange-Id: I2cb11b073fddd223ba0c30cc2ae89677cf68b6ac\n'}, {'number': 5, 'created': '2013-07-17 16:29:52.000000000', 'files': ['elements/keystone/install.d/05-keystone', 'elements/keystone/install.d/70-keystone', 'elements/keystone/element-deps', 'elements/keystone/source-repository-keystone'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/76381d289e83cfb61f3c26b9e0f314fd4cd65611', 'message': 'Use source-repository interface in keystone element\n\nChange-Id: I2cb11b073fddd223ba0c30cc2ae89677cf68b6ac\n'}, {'number': 2, 'created': '2013-07-17 16:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/58be64488d88c936095c8583e1acc7c8ad730ecc', 'message': 'Use source-repository interface in keystone element\n\nChange-Id: I2cb11b073fddd223ba0c30cc2ae89677cf68b6ac\n'}, {'number': 3, 'created': '2013-07-17 16:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e36f27f3fe3e20822eec48bf0713f26a60a96edc', 'message': 'Use source-repository interface in keystone element\n\nChange-Id: I2cb11b073fddd223ba0c30cc2ae89677cf68b6ac\n'}, {'number': 1, 'created': '2013-07-17 16:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8dd7e6b7ea674913b0fd114c2b097a26ed90d3d6', 'message': 'Use source-repository interface in keystone element\n\nChange-Id: I2cb11b073fddd223ba0c30cc2ae89677cf68b6ac\n'}]",0,36047,76381d289e83cfb61f3c26b9e0f314fd4cd65611,17,4,5,1926,,,0,"Use source-repository interface in keystone element

Change-Id: I2cb11b073fddd223ba0c30cc2ae89677cf68b6ac
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/47/36047/4 && git format-patch -1 --stdout FETCH_HEAD,"['elements/keystone/install.d/05-keystone', 'elements/keystone/install.d/70-keystone', 'elements/keystone/element-deps', 'elements/keystone/source-repository-keystone']",4,e1e8d06ed66a5932717902292a4cd2d170c3eb6a,source-repository,keystone git /opt/stack/keystone https://github.com/openstack/keystone.git ,,4,2
openstack%2Fdevstack-gate~master~I052172eb34b35ab18499b325929afac7451850ff,openstack/devstack-gate,master,I052172eb34b35ab18499b325929afac7451850ff,Print IP information at start of run,MERGED,2013-07-11 00:02:02.000000000,2013-07-17 16:28:29.000000000,2013-07-17 16:28:28.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2976}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-11 00:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/828a21c739b6e4e8717c79c426e946df5f525ce6', 'message': 'Print IP information at start of run\n\nChange-Id: I052172eb34b35ab18499b325929afac7451850ff\n'}, {'number': 2, 'created': '2013-07-11 19:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/089c94e37550c4dcf5a933581661db998f117820', 'message': 'Print IP information at start of run\n\nChange-Id: I052172eb34b35ab18499b325929afac7451850ff\n'}, {'number': 3, 'created': '2013-07-11 21:21:07.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f2e02b912256d847299af766a2845ae983ad69f2', 'message': 'Print IP information at start of run\n\nChange-Id: I052172eb34b35ab18499b325929afac7451850ff\n'}]",0,36590,f2e02b912256d847299af766a2845ae983ad69f2,15,5,3,1,,,0,"Print IP information at start of run

Change-Id: I052172eb34b35ab18499b325929afac7451850ff
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/90/36590/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,828a21c739b6e4e8717c79c426e946df5f525ce6,logging,"echo ""IP configuration of this host:"" ip -f inet addr show",,2,0
openstack%2Fdevstack-gate~master~If3945342e83dc7d05c6384244dd6306071c8eca0,openstack/devstack-gate,master,If3945342e83dc7d05c6384244dd6306071c8eca0,Add a check script,MERGED,2013-07-11 00:02:02.000000000,2013-07-17 16:27:50.000000000,2013-07-17 16:27:49.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-11 00:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/b85332956eff7796472a60de837a882b12efdc87', 'message': 'Add a check script\n\nIt can be used to periodically test that each node is reachable\nover ssh.  If not, the node is deleted.\n\nFixes bug: 1130414\n\nChange-Id: If3945342e83dc7d05c6384244dd6306071c8eca0\n'}, {'number': 2, 'created': '2013-07-11 19:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/209fed8b412997d2c54768144bbec04be2fca94f', 'message': 'Add a check script\n\nIt can be used to periodically test that each node is reachable\nover ssh.  If not, the node is deleted.\n\nFixes bug: 1130414\n\nChange-Id: If3945342e83dc7d05c6384244dd6306071c8eca0\n'}, {'number': 3, 'created': '2013-07-11 21:21:07.000000000', 'files': ['devstack-vm-check.py'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/69019d380e4ac7a7c9dcfa8b03d1a7cd68d16795', 'message': 'Add a check script\n\nIt can be used to periodically test that each node is reachable\nover ssh.  If not, the node is deleted.\n\nFixes bug: 1130414\n\nChange-Id: If3945342e83dc7d05c6384244dd6306071c8eca0\n'}]",2,36589,69019d380e4ac7a7c9dcfa8b03d1a7cd68d16795,14,4,3,1,,,0,"Add a check script

It can be used to periodically test that each node is reachable
over ssh.  If not, the node is deleted.

Fixes bug: 1130414

Change-Id: If3945342e83dc7d05c6384244dd6306071c8eca0
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/89/36589/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-check.py'],1,b85332956eff7796472a60de837a882b12efdc87,logging,"#!/usr/bin/env python # Remove old devstack VMs that have been given to developers. # Copyright (C) 2011-2012 OpenStack LLC. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # # See the License for the specific language governing permissions and # limitations under the License. import os import sys import time import getopt import traceback import ConfigParser import myjenkins import vmdatabase import utils PROVIDER_NAME = sys.argv[1] DEVSTACK_GATE_SECURE_CONFIG = os.environ.get('DEVSTACK_GATE_SECURE_CONFIG', os.path.expanduser( '~/devstack-gate-secure.conf')) SKIP_DEVSTACK_GATE_JENKINS = os.environ.get('SKIP_DEVSTACK_GATE_JENKINS', None) def check_machine(jenkins, machine): utils.log.debug(""Check ID: %s"" % machine.id) try: if utils.ssh_connect(machine.ip, 'jenkins'): return except: utils.log.exception(""Check failed ID: %s"" % machine.id) utils.log.debug(""Set deleted ID: %s old state: %s"" % ( machine.id, machine.state)) machine.state = vmdatabase.DELETE if jenkins: if machine.jenkins_name: if jenkins.node_exists(machine.jenkins_name): utils.log.debug(""Delete jenkins node ID: %s"" % machine.id) jenkins.delete_node(machine.jenkins_name) machine.delete() def main(): db = vmdatabase.VMDatabase() if not SKIP_DEVSTACK_GATE_JENKINS: config = ConfigParser.ConfigParser() config.read(DEVSTACK_GATE_SECURE_CONFIG) jenkins = myjenkins.Jenkins(config.get('jenkins', 'server'), config.get('jenkins', 'user'), config.get('jenkins', 'apikey')) jenkins.get_info() else: jenkins = None provider = db.getProvider(PROVIDER_NAME) print ""Working with provider %s"" % provider.name error = False for machine in provider.machines: print 'Checking machine', machine.name try: check_machine(jenkins, machine) except: error = True traceback.print_exc() utils.update_stats(provider) if error: sys.exit(1) if __name__ == '__main__': main() ",,89,0
openstack%2Fdevstack-gate~master~Ifab68c91b89edfc5b441cbcabd1035efdc3a148e,openstack/devstack-gate,master,Ifab68c91b89edfc5b441cbcabd1035efdc3a148e,Add logging and retry label change,MERGED,2013-07-11 00:02:01.000000000,2013-07-17 16:27:48.000000000,2013-07-17 16:27:48.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-11 00:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/b67a14518769db99a1b8b884062d4679649ad91b', 'message': 'Add logging\n\nChange-Id: Ifab68c91b89edfc5b441cbcabd1035efdc3a148e\n'}, {'number': 2, 'created': '2013-07-11 19:45:56.000000000', 'files': ['devstack-vm-launch.py', 'utils.py', 'devstack-vm-inprogress.py', 'devstack-vm-delete.py', 'devstack-vm-reap.py'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/cb9789cf26e0363fbd1b2c09f5504f30528d06e0', 'message': 'Add logging and retry label change\n\nSometimes the label change HTTP request can fail; in those cases,\ntry 3 times 5 seconds apart, and then log the error.\n\nChange-Id: Ifab68c91b89edfc5b441cbcabd1035efdc3a148e\n'}]",0,36588,cb9789cf26e0363fbd1b2c09f5504f30528d06e0,13,4,2,1,,,0,"Add logging and retry label change

Sometimes the label change HTTP request can fail; in those cases,
try 3 times 5 seconds apart, and then log the error.

Change-Id: Ifab68c91b89edfc5b441cbcabd1035efdc3a148e
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/88/36588/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-launch.py', 'utils.py', 'devstack-vm-delete.py', 'devstack-vm-inprogress.py', 'devstack-vm-reap.py']",5,b67a14518769db99a1b8b884062d4679649ad91b,logging," utils.log.debug(""Delete ID: %s"" % machine.id) utils.log.debug(""Delete jenkins node ID: %s"" % machine.id)",,52,11
openstack%2Fnova~master~I79fbd9d7d4fb7791ca599b136cf9945dec8996e2,openstack/nova,master,I79fbd9d7d4fb7791ca599b136cf9945dec8996e2,Fix blocking issue when powervm calculate checksum,MERGED,2013-07-09 08:30:30.000000000,2013-07-17 16:25:28.000000000,2013-07-17 16:25:26.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2711}, {'_account_id': 4393}, {'_account_id': 6722}, {'_account_id': 6873}]","[{'number': 1, 'created': '2013-07-09 08:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/835511e3e02478e257686ef40d5fcc350eee039f', 'message': 'Fix blocking other threads issue when copy file\n\nIn powervm driver, it takes long time to copy image file between\ncontrol node and IVM host and it also calculates file checksum before\nand after transferring image file. Because nova-compute is single\nthreaded, it wont process any other work at the same time. Here give\nother threads chance to run by using time.sleep(0), that acts as a\nyield of the thread for eventlet with harmless.\n\nFixes bug #1181895\n\nChange-Id: I79fbd9d7d4fb7791ca599b136cf9945dec8996e2\n'}, {'number': 2, 'created': '2013-07-10 07:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b2909752893b3256a1c120ae94b73e3fa3f11006', 'message': ""Fix blocking when powervm driver transfers file\n\nIn powervm driver, it takes long time to copy image file between\ncontrol node and IVM host and it also calculates file checksum before\nand after transferring image file. Because nova-compute is a single\nthread, it won't process any other work at the same time. Here give\nother threads chance to run by using time.sleep(0), that acts as a\nyield of the thread for eventlet with harmless.\n\nFixes bug #1181895\n\nChange-Id: I79fbd9d7d4fb7791ca599b136cf9945dec8996e2\n""}, {'number': 3, 'created': '2013-07-12 07:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18ef57b93ea4fbbedc743a603690ef623d47d190', 'message': ""Relieve blocking issue when calculate checksum\n\nIn powervm driver, it takes long time to copy image file between\ncontrol node and IVM host and it also calculates file checksum before\nand after transferring image file. Because nova-compute is a single\nthread, it won't process any other work at the same time. Here give\nother threads chance to run by using time.sleep(0), that acts as a\nyield of the thread for eventlet. This patch can't fix the block\nissue completely. It can't yield when transferring image file and\ncalculating remote file's checksum, only can yield between them.\n\nFixes bug #1181895\n\nChange-Id: I79fbd9d7d4fb7791ca599b136cf9945dec8996e2\n""}, {'number': 4, 'created': '2013-07-12 08:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f79d2dd209bb90108096e32cc5a8de75a1f926d', 'message': ""Relieve blocking issue when calculate checksum\n\nIn powervm driver, it takes long time to copy image file between\ncontrol node and IVM host and it also calculates file checksum before\nand after transferring image file. Because nova-compute is a single\nthread, it won't process any other work at the same time. Here give\nother threads chance to run by using time.sleep(0), that acts as a\nyield of the thread for eventlet. This patch can't fix the block\nissue completely. It can't yield when transferring image file and\ncalculating remote file's checksum, only can yield between them.\n\nFixes bug #1181895\n\nChange-Id: I79fbd9d7d4fb7791ca599b136cf9945dec8996e2\n""}, {'number': 5, 'created': '2013-07-15 01:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6cc69069c278ca8fb2cae7b174c3f637b6aed4c', 'message': ""Relieve blocking issue when calculate checksum\n\nIn powervm driver, it takes long time to copy image file between\ncontrol node and IVM host and it also calculates file checksum before\nand after transferring image file. Because nova-compute is a single\nthread, it won't process any other work at the same time. Here give\nother threads chance to run by using time.sleep(0), that acts as a\nyield of the thread for eventlet. This patch can't fix the block\nissue completely. It can't yield when transferring image file and\ncalculating remote file's checksum, only can yield between them.\n\nFixes bug #1181895\n\nChange-Id: I79fbd9d7d4fb7791ca599b136cf9945dec8996e2\n""}, {'number': 6, 'created': '2013-07-17 05:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5035109bfb39182160f5cd4017f164926e30a7c', 'message': ""Fix blocking issue when powervm calculate checksum\n\nIn powervm driver, it takes long time to calculate file checksum\nbefore and after transferring image file. Because nova-compute is\na single thread, it won't process any other work at the same time.\nHere give other threads chance to run by using time.sleep(0), that\nacts as a yield of the thread for eventlet.\n\nFixes bug #1181895\n\nChange-Id: I79fbd9d7d4fb7791ca599b136cf9945dec8996e2\n""}, {'number': 7, 'created': '2013-07-17 14:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eba9cf2813426030881e5e6cca38e92f150d4583', 'message': ""Fix blocking issue when powervm calculate checksum\n\nIn powervm driver, it takes long time to calculate file checksum\nbefore and after transferring image file. Because nova-compute is\na single thread, it won't process any other work at the same time.\nHere give other threads chance to run by using time.sleep(0), that\nacts as a yield of the thread for eventlet.\n\nFixes bug #1181895\n\nChange-Id: I79fbd9d7d4fb7791ca599b136cf9945dec8996e2\n""}, {'number': 8, 'created': '2013-07-17 14:28:15.000000000', 'files': ['nova/virt/powervm/blockdev.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c4dcc659419a371e0d7316b831c5ce21a0c3c947', 'message': ""Fix blocking issue when powervm calculate checksum\n\nIn powervm driver, it takes long time to calculate file checksum\nbefore and after transferring image file. Because nova-compute is\na single thread, it won't process any other work at the same time.\nHere give other threads chance to run by using time.sleep(0), that\nacts as a yield of the thread for eventlet.\n\nFixes bug #1181895\n\nChange-Id: I79fbd9d7d4fb7791ca599b136cf9945dec8996e2\n""}]",30,36196,c4dcc659419a371e0d7316b831c5ce21a0c3c947,44,9,8,6722,,,0,"Fix blocking issue when powervm calculate checksum

In powervm driver, it takes long time to calculate file checksum
before and after transferring image file. Because nova-compute is
a single thread, it won't process any other work at the same time.
Here give other threads chance to run by using time.sleep(0), that
acts as a yield of the thread for eventlet.

Fixes bug #1181895

Change-Id: I79fbd9d7d4fb7791ca599b136cf9945dec8996e2
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/36196/8 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/powervm/blockdev.py'],1,835511e3e02478e257686ef40d5fcc350eee039f,bug/1181895,import time # Give other threads a chance to run time.sleep(0) # Give other threads a chance to run time.sleep(0) # Give other threads a chance to run time.sleep(0) # Give other threads a chance to run time.sleep(0) ,,13,0
openstack%2Ftripleo-image-elements~master~I3246ca161a80004d6d9168c1bda8bf9c3c2ee4fa,openstack/tripleo-image-elements,master,I3246ca161a80004d6d9168c1bda8bf9c3c2ee4fa,Use source-repository interface in glance element,MERGED,2013-07-17 16:24:06.000000000,2013-07-17 16:24:06.000000000,2013-07-17 16:24:06.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 3, 'created': '2013-07-17 16:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/c4dec4dca646a7e060dbe772fb247adab75fbbdb', 'message': 'Use source-repository interface in glance element\n\nChange-Id: I3246ca161a80004d6d9168c1bda8bf9c3c2ee4fa\n'}, {'number': 2, 'created': '2013-07-17 16:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/cb802dfafcd41f19970738a6d7f2bbd90b5172b2', 'message': 'Use source-repository interface in glance element\n\nChange-Id: I3246ca161a80004d6d9168c1bda8bf9c3c2ee4fa\n'}, {'number': 1, 'created': '2013-07-17 16:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ef3f6025ac857369ab823c07a0d6d7d6272cf418', 'message': 'Use source-repository interface in glance element\n\nChange-Id: I3246ca161a80004d6d9168c1bda8bf9c3c2ee4fa\n'}, {'number': 5, 'created': '2013-07-17 16:24:06.000000000', 'files': ['elements/glance/install.d/75-glance', 'elements/glance/source-repository-glance', 'elements/glance/element-deps'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2421e15f3ebb6b13f624af2c62d86ac2deabbee6', 'message': 'Use source-repository interface in glance element\n\nChange-Id: I3246ca161a80004d6d9168c1bda8bf9c3c2ee4fa\n'}, {'number': 4, 'created': '2013-07-17 16:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5736a72e25ab58cc171f3afd9569d525685f1649', 'message': 'Use source-repository interface in glance element\n\nChange-Id: I3246ca161a80004d6d9168c1bda8bf9c3c2ee4fa\n'}]",0,36045,2421e15f3ebb6b13f624af2c62d86ac2deabbee6,17,4,5,1926,,,0,"Use source-repository interface in glance element

Change-Id: I3246ca161a80004d6d9168c1bda8bf9c3c2ee4fa
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/45/36045/3 && git format-patch -1 --stdout FETCH_HEAD,"['elements/glance/install.d/75-glance', 'elements/glance/source-repository-glance', 'elements/glance/element-deps']",3,c4dec4dca646a7e060dbe772fb247adab75fbbdb,source-repository,source-repositories,,3,1
openstack%2Fmurano-deployment~master~Ibc49ab160c92a8f77265cbeece0ac37b6163a6c1,openstack/murano-deployment,master,Ibc49ab160c92a8f77265cbeece0ac37b6163a6c1,Support for SQL Server added.,MERGED,2013-07-17 16:12:39.000000000,2013-07-17 16:18:25.000000000,2013-07-17 16:18:25.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-17 16:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/d5a97ea0df03b43251acc1c5541836c96917bc24', 'message': 'Support for SQL Server added.\n\nChange-Id: Ibc49ab160c92a8f77265cbeece0ac37b6163a6c1\n'}, {'number': 2, 'created': '2013-07-17 16:13:51.000000000', 'files': ['ExecutionPlan/InstallSQL/GenerateJSON.sh', 'WindowsPowerShell/Functions/SQLServerInstaller.ps1', 'ExecutionPlan/InstallSQL/ExecutionPlan.yaml.json', 'WindowsPowerShell/Functions/SQLServerOptionParsers.ps1', 'WindowsPowerShell/Functions/ImportCoreFunctions.ps1', 'WindowsPowerShell/Functions/Install-SQLServer.ps1', 'ExecutionPlan/InstallSQL/ExecutionPlan.yaml', 'WindowsPowerShell/Functions/OptionParser.ps1'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/5d94d3f5d9b5375241fbb16d59b80f81b67bdf14', 'message': 'Support for SQL Server added.\n\nChange-Id: Ibc49ab160c92a8f77265cbeece0ac37b6163a6c1\n'}]",0,37517,5d94d3f5d9b5375241fbb16d59b80f81b67bdf14,6,2,2,7562,,,0,"Support for SQL Server added.

Change-Id: Ibc49ab160c92a8f77265cbeece0ac37b6163a6c1
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/17/37517/2 && git format-patch -1 --stdout FETCH_HEAD,"['ExecutionPlan/InstallSQL/GenerateJSON.sh', 'ExecutionPlan/InstallSQL/ExecutionPlan.yaml.json', 'ExecutionPlan/InstallSQL/ExecutionPlan.yaml']",3,d5a97ea0df03b43251acc1c5541836c96917bc24,mssql-scripts,"Scripts: - ../../WindowsPowerShell/Functions/ImportCoreFunctions.ps1 - ../../WindowsPowerShell/Functions/OptionParser.ps1 - ../../WindowsPowerShell/Functions/SQLServerOptionParsers.ps1 - ../../WindowsPowerShell/Functions/SQLServerInstaller.ps1 - ../../WindowsPowerShell/Functions/Install-SQLServer.ps1 Commands: - Name: Install-SQLServer Arguments: MixedModeAuth: false SAPassword: """" RebootOnCompletion: 0 ",,37,0
openstack%2Fpython-zaqarclient~master~I0c895fffdd23e7190477ffc1cfa5663bc9b8a57d,openstack/python-zaqarclient,master,I0c895fffdd23e7190477ffc1cfa5663bc9b8a57d,Ignore *.egg files.,MERGED,2013-07-16 21:59:45.000000000,2013-07-17 16:14:52.000000000,2013-07-17 16:14:52.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-16 21:59:45.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/a46e57c6e27ec4e0129cd567de8b5ccffd1c2ea1', 'message': 'Ignore *.egg files.\n\nChange-Id: I0c895fffdd23e7190477ffc1cfa5663bc9b8a57d\n'}]",0,37339,a46e57c6e27ec4e0129cd567de8b5ccffd1c2ea1,6,4,1,6944,,,0,"Ignore *.egg files.

Change-Id: I0c895fffdd23e7190477ffc1cfa5663bc9b8a57d
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/39/37339/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,a46e57c6e27ec4e0129cd567de8b5ccffd1c2ea1,ignore_eggs,*.egg,,1,0
openstack%2Fnova~master~I63eeb18b8ede4b4263ee553d4e70633de463e0c4,openstack/nova,master,I63eeb18b8ede4b4263ee553d4e70633de463e0c4,Move resource usage sync functions to db backend,MERGED,2013-06-07 13:27:21.000000000,2013-07-17 16:10:18.000000000,2013-07-17 16:10:15.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 2889}, {'_account_id': 5652}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 7491}]","[{'number': 1, 'created': '2013-06-07 13:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2065b82fe07ecaaef5c13ce30f72e6577743f07', 'message': 'Move resource usage sync functions to db backend\n\nResource usage sync functions was declared in nova/quota.py, and\nusing db.api public methods. This functions was moved to database\nbackend implementation, so now this functions can use private\nmethods of database backend.\n\nBlueprint: db-session-cleanup\n\nwork-in-progress\n\nChange-Id: I63eeb18b8ede4b4263ee553d4e70633de463e0c4\n'}, {'number': 2, 'created': '2013-06-11 06:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae879417ab041a9ece1765ee4499cfd607a95fdd', 'message': 'Move resource usage sync functions to db backend\n\nResource usage sync functions was declared in nova/quota.py, and\nusing db.api public methods. This functions was moved to database\nbackend implementation, so now sync functions can use private\nmethods of database backend, and session attribute can be removed\nfrom this public methods. Even some methods can be removed.\n\nBlueprint: db-session-cleanup\n\nChange-Id: I63eeb18b8ede4b4263ee553d4e70633de463e0c4\n'}, {'number': 3, 'created': '2013-06-11 13:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2adf9dcbf904884e3bdf2710ecf03d521be4b579', 'message': 'Move resource usage sync functions to db backend\n\nResource usage sync functions was declared in nova/quota.py, and\nusing db.api public methods. This functions was moved to database\nbackend implementation, so now sync functions can use private\nmethods of database backend, and session attribute can be removed\nfrom this public methods. Even some methods can be removed.\n\nBlueprint: db-session-cleanup\n\nChange-Id: I63eeb18b8ede4b4263ee553d4e70633de463e0c4\n'}, {'number': 4, 'created': '2013-06-25 14:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4392e1e652047bc1ac48cfd8ef1814912c08a4e7', 'message': 'Move resource usage sync functions to db backend\n\nResource usage sync functions was declared in nova/quota.py, and\nusing db.api public methods. This functions was moved to database\nbackend implementation, so now sync functions can use private\nmethods of database backend, and session attribute can be removed\nfrom this public methods. Even some methods can be removed.\n\nBlueprint: db-session-cleanup\n\nChange-Id: I63eeb18b8ede4b4263ee553d4e70633de463e0c4\n'}, {'number': 5, 'created': '2013-07-03 11:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/583c5bd8bb418b01bda3ecbc94efc42da34b2be9', 'message': 'Move resource usage sync functions to db backend\n\nResource usage sync functions was declared in nova/quota.py, and\nusing db.api public methods. This functions was moved to database\nbackend implementation, so now sync functions can use private\nmethods of database backend, and session attribute can be removed\nfrom this public methods. Even some methods can be removed.\n\nBlueprint: db-session-cleanup\n\nChange-Id: I63eeb18b8ede4b4263ee553d4e70633de463e0c4\n'}, {'number': 6, 'created': '2013-07-04 15:18:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85e3c8cbee53ead838d549df0dbd7cafa231e531', 'message': 'Move resource usage sync functions to db backend\n\nResource usage sync functions was declared in nova/quota.py, and\nusing db.api public methods. This functions was moved to database\nbackend implementation, so now sync functions can use private\nmethods of database backend, and session attribute can be removed\nfrom this public methods. Even some methods can be removed.\n\nBlueprint: db-session-cleanup\n\nChange-Id: I63eeb18b8ede4b4263ee553d4e70633de463e0c4\n'}, {'number': 7, 'created': '2013-07-10 14:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b483c6a16ac954996fbd2c8cd9dddf9ed82241eb', 'message': 'Move resource usage sync functions to db backend\n\nResource usage sync functions was declared in nova/quota.py, and\nusing db.api public methods. This functions was moved to database\nbackend implementation, so now sync functions can use private\nmethods of database backend, and session attribute can be removed\nfrom this public methods, and even some public methods can be removed.\n\nBlueprint: db-session-cleanup\n\nChange-Id: I63eeb18b8ede4b4263ee553d4e70633de463e0c4\n'}, {'number': 8, 'created': '2013-07-10 15:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d506f9e9cedb6dbf9a457ebbda427fdc89ca3a7', 'message': 'Move resource usage sync functions to db backend\n\nResource usage sync functions was declared in nova/quota.py, and\nusing db.api public methods. This functions was moved to database\nbackend implementation, so now sync functions can use private\nmethods of database backend, and session attribute can be removed\nfrom this public methods, and even some public methods can be removed.\n\nBlueprint: db-session-cleanup\n\nChange-Id: I63eeb18b8ede4b4263ee553d4e70633de463e0c4\n'}, {'number': 9, 'created': '2013-07-17 05:39:37.000000000', 'files': ['nova/tests/test_quota.py', 'nova/quota.py', 'nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3bda4c05855c764697015ea4bfbb9edbfc83273e', 'message': 'Move resource usage sync functions to db backend\n\nResource usage sync functions was declared in nova/quota.py, and\nusing db.api public methods. This functions was moved to database\nbackend implementation, so now sync functions can use private\nmethods of database backend, and session attribute can be removed\nfrom this public methods, and even some public methods can be removed.\n\nBlueprint: db-session-cleanup\n\nChange-Id: I63eeb18b8ede4b4263ee553d4e70633de463e0c4\n'}]",0,32130,3bda4c05855c764697015ea4bfbb9edbfc83273e,46,9,9,7369,,,0,"Move resource usage sync functions to db backend

Resource usage sync functions was declared in nova/quota.py, and
using db.api public methods. This functions was moved to database
backend implementation, so now sync functions can use private
methods of database backend, and session attribute can be removed
from this public methods, and even some public methods can be removed.

Blueprint: db-session-cleanup

Change-Id: I63eeb18b8ede4b4263ee553d4e70633de463e0c4
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/32130/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_quota.py', 'nova/quota.py', 'nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py']",5,e2065b82fe07ecaaef5c13ce30f72e6577743f07,bp/db-session-cleanup," def _sync_instances(context, project_id, session): return dict(zip(('instances', 'cores', 'ram'), _instance_data_get_for_project( context, project_id, session))) def _sync_floating_ips(context, project_id, session): return dict(floating_ips=_floating_ip_count_by_project( context, project_id, session)) def _sync_fixed_ips(context, project_id, session): return dict(fixed_ips=_fixed_ip_count_by_project( context, project_id, session)) def _sync_security_groups(context, project_id, session): return dict(security_groups=_security_group_count_by_project( context, project_id, session)) QUOTA_SYNC_FUNCTIONS = { 'instances': _sync_instances, 'cores': _sync_instances, 'ram': _sync_instances, 'floating_ips': _sync_floating_ips, 'fixed_ips': _sync_fixed_ips, 'security_groups': _sync_security_groups, } def _floating_ip_count_by_project(context, project_id, session=None):def _fixed_ip_count_by_project(context, project_id, session=None):def _instance_data_get_for_project(context, project_id, session=None): sync = QUOTA_SYNC_FUNCTIONS[resources[resource].name]def _security_group_count_by_project(context, project_id, session=None):","@require_context def floating_ip_count_by_project(context, project_id, session=None):@require_context def fixed_ip_count_by_project(context, project_id, session=None): @require_admin_context def instance_data_get_for_project(context, project_id, session=None): sync = resources[resource].sync @require_context def security_group_count_by_project(context, project_id, session=None):",75,212
openstack%2Ftripleo-image-elements~master~I621028ca070fe52516bf0f8a568488e7a0c2576c,openstack/tripleo-image-elements,master,I621028ca070fe52516bf0f8a568488e7a0c2576c,Use source-repository interface in nova element,MERGED,2013-07-17 16:09:53.000000000,2013-07-17 16:09:53.000000000,2013-07-17 16:09:53.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-17 16:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/66873f082d65321932ab00b5e1a713cd0c849e7b', 'message': 'Use source-repository interface in nova element\n\nChange-Id: I621028ca070fe52516bf0f8a568488e7a0c2576c\n'}, {'number': 3, 'created': '2013-07-17 16:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ea0cb7778cddb943989e78b9685adb4989a114a4', 'message': 'Use source-repository interface in nova element\n\nChange-Id: I621028ca070fe52516bf0f8a568488e7a0c2576c\n'}, {'number': 2, 'created': '2013-07-17 16:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d8e335a2290b7f21a0f6be9436fd735d40668e01', 'message': 'Use source-repository interface in nova element\n\nChange-Id: I621028ca070fe52516bf0f8a568488e7a0c2576c\n'}, {'number': 5, 'created': '2013-07-17 16:09:53.000000000', 'files': ['elements/nova/source-repository-nova', 'elements/nova/element-deps', 'elements/nova/install.d/74-nova'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6a445609f10bd83c571ddaf726b12561878756fa', 'message': 'Use source-repository interface in nova element\n\nChange-Id: I621028ca070fe52516bf0f8a568488e7a0c2576c\n'}, {'number': 4, 'created': '2013-07-17 16:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6da074483cca81ffb02ba45b418200f8c05927db', 'message': 'Use source-repository interface in nova element\n\nChange-Id: I621028ca070fe52516bf0f8a568488e7a0c2576c\n'}]",0,36044,6a445609f10bd83c571ddaf726b12561878756fa,17,4,5,1926,,,0,"Use source-repository interface in nova element

Change-Id: I621028ca070fe52516bf0f8a568488e7a0c2576c
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/44/36044/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/nova/source-repository-nova', 'elements/nova/element-deps', 'elements/nova/install.d/74-nova']",3,66873f082d65321932ab00b5e1a713cd0c849e7b,source-repository,os-svc-install -n nova -u nova -r /opt/stack/nova,os-svc-install -n nova -u nova -r https://github.com/openstack/nova.git,3,1
openstack%2Fnova~master~I346b4d84a6e48d56f307349ed681355d26710ecd,openstack/nova,master,I346b4d84a6e48d56f307349ed681355d26710ecd,Add a VIF driver for IOVisor engine,MERGED,2013-07-05 05:52:18.000000000,2013-07-17 16:08:41.000000000,2013-07-17 16:08:39.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 704}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4395}, {'_account_id': 6830}]","[{'number': 1, 'created': '2013-07-05 05:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23b6caff68e393b81423e8edc76fe8608facf8c3', 'message': 'Add a VIF driver for IOVisor engine\n\nImplements blueprint iovisor-vif-driver\n\nUnit Test is included\nFollows the same structure that OVS and Qbh drivers\nIncludes the rootwrap config to allow calls to ifc-ctl for managing IOVisor engine.\n\nChange-Id: I346b4d84a6e48d56f307349ed681355d26710ecd\n'}, {'number': 2, 'created': '2013-07-05 05:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01a000bdd98b05799c894375bd68fa3e6c0fdc5b', 'message': 'Add a VIF driver for IOVisor engine\n\nImplements blueprint iovisor-vif-driver\n\nUnit Test is included\nFollows the same structure that OVS and Qbh drivers\nIncludes the rootwrap config to allow calls to ifc-ctl for managing IOVisor engine.\n\nChange-Id: I346b4d84a6e48d56f307349ed681355d26710ecd\n'}, {'number': 3, 'created': '2013-07-05 17:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2e31cd4590e2fdabe3c29ead2f21910e1bade3b', 'message': 'Add a VIF driver for IOVisor engine\n\nImplements blueprint iovisor-vif-driver\n\nUnit Test is included\nFollows the same structure that OVS and Qbh drivers\nIncludes the rootwrap config to allow calls to ifc-ctl for managing IOVisor engine.\n\nChange-Id: I346b4d84a6e48d56f307349ed681355d26710ecd\n'}, {'number': 4, 'created': '2013-07-09 05:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f53aaf2b7a074fe7a72ac06702591acd1c90505', 'message': 'Add a VIF driver for IOVisor engine\n\nImplements blueprint iovisor-vif-driver\n\nUnit Test is included\nFollows the same structure that OVS and Qbh drivers\nIncludes the rootwrap config to allow calls to ifc-ctl for managing IOVisor engine.\n\nChange-Id: I346b4d84a6e48d56f307349ed681355d26710ecd\n'}, {'number': 5, 'created': '2013-07-09 05:44:02.000000000', 'files': ['etc/nova/rootwrap.d/network.filters', 'nova/virt/libvirt/vif.py', 'nova/network/model.py', 'nova/tests/virt/libvirt/test_libvirt_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/06cebd34c6c42be6749bcc680282ee813b12055a', 'message': 'Add a VIF driver for IOVisor engine\n\nImplements blueprint iovisor-vif-driver\n\nUnit Test is included\nFollows the same structure that OVS and Qbh drivers\nIncludes the rootwrap config to allow calls to ifc-ctl for managing IOVisor engine.\n\nChange-Id: I346b4d84a6e48d56f307349ed681355d26710ecd\n'}]",12,35743,06cebd34c6c42be6749bcc680282ee813b12055a,32,10,5,704,,,0,"Add a VIF driver for IOVisor engine

Implements blueprint iovisor-vif-driver

Unit Test is included
Follows the same structure that OVS and Qbh drivers
Includes the rootwrap config to allow calls to ifc-ctl for managing IOVisor engine.

Change-Id: I346b4d84a6e48d56f307349ed681355d26710ecd
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/35743/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/nova/rootwrap.d/network.filters', 'nova/virt/libvirt/vif.py', 'nova/network/model.py', 'nova/tests/virt/libvirt/test_libvirt_vif.py']",4,23b6caff68e393b81423e8edc76fe8608facf8c3,bp/iovisor-vif-driver," net_iovisor = { 'cidr': '101.168.1.0/24', 'cidr_v6': '101:1db9::/64', 'gateway_v6': '101:1db9::1', 'netmask_v6': '64', 'netmask': '255.255.255.0', 'interface': 'eth0', 'vlan': 99, 'gateway': '101.168.1.1', 'broadcast': '101.168.1.255', 'dns1': '8.8.8.8', 'id': 'network-id-xxx-yyy-zzz' } mapping_iovisor = { 'mac': 'ca:fe:de:ad:be:ef', 'vif_uuid': 'vif-xxx-yyy-zzz', 'vif_devname': 'tap-xxx-yyy-zzz', 'vif_type': network_model.VIF_TYPE_IOVISOR, } def test_generic_iovisor_driver(self): def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) self.flags(firewall_driver=""nova.virt.firewall.NoopFirewallDriver"") xml = self._get_instance_xml(d, self.net_iovisor, self.mapping_iovisor) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] ret = node.findall(""filterref"") self.assertEqual(len(ret), 0) self.assertEqual(node.get(""type""), ""ethernet"") tap_name = node.find(""target"").get(""dev"") self.assertEqual(tap_name, self.mapping_iovisor['vif_devname']) mac = node.find(""mac"").get(""address"") self.assertEqual(mac, self.mapping_iovisor['mac']) ",,109,0
openstack%2Fpython-keystoneclient~master~I3fb4591259b1e7c8202365cbadc8967a1639254f,openstack/python-keystoneclient,master,I3fb4591259b1e7c8202365cbadc8967a1639254f,Fix and enable gating on H403,MERGED,2013-07-12 22:46:36.000000000,2013-07-17 16:08:35.000000000,2013-07-17 16:08:35.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-12 22:46:36.000000000', 'files': ['keystoneclient/openstack/common/memorycache.py', 'keystoneclient/v2_0/client.py', 'keystoneclient/exceptions.py', 'tests/test_auth_token_middleware.py', 'tests/test_shell.py', 'keystoneclient/openstack/common/timeutils.py', 'tox.ini', 'keystoneclient/service_catalog.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ad73bfd2c79d194c6819ae753f2b72af4e377550', 'message': 'Fix and enable gating on H403\n\nOnly a few occurrences of ""multiline docstrings\nshould end on a new line.""\n\nChange-Id: I3fb4591259b1e7c8202365cbadc8967a1639254f\n'}]",0,36916,ad73bfd2c79d194c6819ae753f2b72af4e377550,6,3,1,6593,,,0,"Fix and enable gating on H403

Only a few occurrences of ""multiline docstrings
should end on a new line.""

Change-Id: I3fb4591259b1e7c8202365cbadc8967a1639254f
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/16/36916/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/openstack/common/memorycache.py', 'keystoneclient/v2_0/client.py', 'keystoneclient/exceptions.py', 'tests/test_auth_token_middleware.py', 'tests/test_shell.py', 'keystoneclient/openstack/common/timeutils.py', 'tox.ini', 'keystoneclient/service_catalog.py']",8,ad73bfd2c79d194c6819ae753f2b72af4e377550,H403," from Keystone. """""" from Keystone. """""""," from Keystone."""""" from Keystone.""""""",17,10
openstack%2Fdiskimage-builder~master~I94067196e664b37c05fbd8882d259ffc3d95c50f,openstack/diskimage-builder,master,I94067196e664b37c05fbd8882d259ffc3d95c50f,Move end user docs higher up in README.md.,MERGED,2013-07-17 16:07:38.000000000,2013-07-17 16:07:38.000000000,2013-07-17 16:07:38.000000000,"[{'_account_id': 3}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-07-17 16:07:38.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/d1a24cab165977855cccf24e631899f4687fad56', 'message': ""Move end user docs higher up in README.md.\n\nMost folk probably don't need the massive design details, so they\nshould come later.\n\nChange-Id: I94067196e664b37c05fbd8882d259ffc3d95c50f\n""}]",0,37459,d1a24cab165977855cccf24e631899f4687fad56,5,2,1,4190,,,0,"Move end user docs higher up in README.md.

Most folk probably don't need the massive design details, so they
should come later.

Change-Id: I94067196e664b37c05fbd8882d259ffc3d95c50f
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/59/37459/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,d1a24cab165977855cccf24e631899f4687fad56,,"Installation ============ * Clone the repository locally, then add bin to your path. * Copy sudoers.d/\* into your /etc/sudoers.d/. (Warning, use visudo -c -f {filename} to check that each one parses successfully on your machine, so you don't break your machine). * Make sure you have qemu-img and kpartx installed. Invocation ========== The scripts can generally just be run. Options can be set on the command line or by exporting variables to override those present in lib/img-defaults. -h to get help. Using the variable ELEMENTS\_PATH will allow to specify multiple elements locations. It's a colon (:) separated path list, and it will work in a first path/element found, first served approach. The included elements tree is used when no path is supplied, and is added to the end of the path if a path is supplied. Requirements ============ If you have 4GB of available physical RAM\*, or more, diskimage-builder will create a tmpfs mount to build the image in. This will improve image build time by building in RAM. This can be disabled completely by passing --no-tmpfs to disk-image-create. ramdisk-image-create does not use a tmpfs mount. If tmpfs is not used, you will need enough room in /tmp to store two uncompressed cloud images. If you do have tmpfs, you will still need /tmp space for one uncompressed cloud image and about 20% of that for working files. \* As reported by /proc/meminfo MemTotal ","Installation ============ * Clone the repository locally, then add bin to your path. * Copy sudoers.d/\* into your /etc/sudoers.d/. (Warning, use visudo -c -f {filename} to check that each one parses successfully on your machine, so you don't break your machine). * Make sure you have qemu-img and kpartx installed. Invocation ========== The scripts can generally just be run. Options can be set on the command line or by exporting variables to override those present in lib/img-defaults. -h to get help. Using the variable ELEMENTS\_PATH will allow to specify multiple elements locations. It's a colon (:) separated path list, and it will work in a first path/element found, first served approach. The included elements tree is used when no path is supplied, and is added to the end of the path if a path is supplied. Requirements ============ If you have 4GB of available physical RAM\*, or more, diskimage-builder will create a tmpfs mount to build the image in. This will improve image build time by building in RAM. This can be disabled completely by passing --no-tmpfs to disk-image-create. ramdisk-image-create does not use a tmpfs mount. If tmpfs is not used, you will need enough room in /tmp to store two uncompressed cloud images. If you do have tmpfs, you will still need /tmp space for one uncompressed cloud image and about 20% of that for working files. \* As reported by /proc/meminfo MemTotal ",36,36
openstack%2Fdiskimage-builder~master~I664cfe4aa8d05c4cc53eeb2ee5f5a200f0d41110,openstack/diskimage-builder,master,I664cfe4aa8d05c4cc53eeb2ee5f5a200f0d41110,Remove excess whitespace in README.md.,MERGED,2013-07-17 16:04:44.000000000,2013-07-17 16:04:44.000000000,2013-07-17 16:04:44.000000000,"[{'_account_id': 3}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-07-17 16:04:44.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/1a172683a5906e308bdbb2ff8bf355b4532c2fbe', 'message': 'Remove excess whitespace in README.md.\n\nChange-Id: I664cfe4aa8d05c4cc53eeb2ee5f5a200f0d41110\n'}]",0,37458,1a172683a5906e308bdbb2ff8bf355b4532c2fbe,5,2,1,4190,,,0,"Remove excess whitespace in README.md.

Change-Id: I664cfe4aa8d05c4cc53eeb2ee5f5a200f0d41110
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/58/37458/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,1a172683a5906e308bdbb2ff8bf355b4532c2fbe,,,,0,1
openstack%2Fsahara-dashboard~master~I4718bea21609034f5a61bc58306cfab5dbdcb0cf,openstack/sahara-dashboard,master,I4718bea21609034f5a61bc58306cfab5dbdcb0cf,License file added,MERGED,2013-07-17 15:43:04.000000000,2013-07-17 15:56:49.000000000,2013-07-17 15:56:49.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-17 15:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/3c3b1d82d2a86aa2353739e5143fa9cc9d3bc7c3', 'message': 'License file added\n\nChange-Id: I4718bea21609034f5a61bc58306cfab5dbdcb0cf\nFixes: bug #1202219\n'}, {'number': 2, 'created': '2013-07-17 15:47:23.000000000', 'files': ['setup.py', 'LICENSE'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/812d22a7fef09c372e4d9b0252208ff5548cca40', 'message': 'License file added\n\nChange-Id: I4718bea21609034f5a61bc58306cfab5dbdcb0cf\nFixes: bug #1202219\n'}]",0,37508,812d22a7fef09c372e4d9b0252208ff5548cca40,8,4,2,7132,,,0,"License file added

Change-Id: I4718bea21609034f5a61bc58306cfab5dbdcb0cf
Fixes: bug #1202219
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/08/37508/1 && git format-patch -1 --stdout FETCH_HEAD,['LICENSE'],1,3c3b1d82d2a86aa2353739e5143fa9cc9d3bc7c3,bug/1202219," Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. ""License"" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. ""Licensor"" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. ""Legal Entity"" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, ""control"" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. ""You"" (or ""Your"") shall mean an individual or Legal Entity exercising permissions granted by this License. ""Source"" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. ""Object"" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. ""Work"" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). ""Derivative Works"" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. ""Contribution"" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, ""submitted"" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as ""Not a Contribution."" ""Contributor"" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a ""NOTICE"" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. ",,175,0
openstack%2Fsahara~master~I6ac629db331515ba8f5ef02b39852b6be9f592c9,openstack/sahara,master,I6ac629db331515ba8f5ef02b39852b6be9f592c9,Status description is set on errors,MERGED,2013-07-17 15:26:45.000000000,2013-07-17 15:33:55.000000000,2013-07-17 15:33:54.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}]","[{'number': 1, 'created': '2013-07-17 15:26:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2eb3974fe36243512e6ebcd43b9aaed0a4ed97ed', 'message': 'Status description is set on errors.\n\nIf cluster comes into Error state, status_description field would contain\ninformation about the error,\n\nImplements blueprint expose-cluster-errors-details\n\nChange-Id: I6ac629db331515ba8f5ef02b39852b6be9f592c9\n'}, {'number': 2, 'created': '2013-07-17 15:29:35.000000000', 'files': ['savanna/service/api.py', 'savanna/service/instances.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/c80b956307dbd1671b14247caf8d3d75ab9c4f98', 'message': 'Status description is set on errors\n\nIf cluster comes into Error state, status_description field would contain\ninformation about the error,\n\nImplements blueprint expose-cluster-errors-details\n\nChange-Id: I6ac629db331515ba8f5ef02b39852b6be9f592c9\n'}]",0,37498,c80b956307dbd1671b14247caf8d3d75ab9c4f98,7,3,2,7132,,,0,"Status description is set on errors

If cluster comes into Error state, status_description field would contain
information about the error,

Implements blueprint expose-cluster-errors-details

Change-Id: I6ac629db331515ba8f5ef02b39852b6be9f592c9
",git fetch https://review.opendev.org/openstack/sahara refs/changes/98/37498/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/service/api.py', 'savanna/service/instances.py']",2,2eb3974fe36243512e6ebcd43b9aaed0a4ed97ed,bp/expose-cluster-errors-details," context.model_update(cluster, status='Error', status_description=str(ex))"," context.model_update(cluster, status='Error')",5,3
openstack%2Fkeystone~master~Ie00e2e9040b6f71eff573b6f7d8dc12bd87b7c52,openstack/keystone,master,Ie00e2e9040b6f71eff573b6f7d8dc12bd87b7c52,grammar fixes in error messages,MERGED,2013-07-17 02:07:18.000000000,2013-07-17 15:09:01.000000000,2013-07-17 15:09:01.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5707}]","[{'number': 1, 'created': '2013-07-17 02:07:18.000000000', 'files': ['keystone/token/providers/uuid.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/fecb6c0d041753826ffd14544c44a108e93299ef', 'message': 'grammar fixes in error messages\n\nChange-Id: Ie00e2e9040b6f71eff573b6f7d8dc12bd87b7c52\n'}]",0,37372,fecb6c0d041753826ffd14544c44a108e93299ef,7,4,1,4,,,0,"grammar fixes in error messages

Change-Id: Ie00e2e9040b6f71eff573b6f7d8dc12bd87b7c52
",git fetch https://review.opendev.org/openstack/keystone refs/changes/72/37372/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/token/providers/uuid.py'],1,fecb6c0d041753826ffd14544c44a108e93299ef,(detached, _('Trustee has no delegated roles.')) msg = _('User %(user_id)s has no access ' msg = _('User %(user_id)s has no access ', _('Trustee have no delegated roles.')) msg = _('User %(user_id)s have no access ' msg = _('User %(user_id)s have no access ',3,3
openstack%2Fneutron~master~I84e2fbdb3e6368529c1d829d4e8134e6b0b54311,openstack/neutron,master,I84e2fbdb3e6368529c1d829d4e8134e6b0b54311,LBaaS: update DB pool stats received from lbaas agent,MERGED,2013-07-16 10:22:33.000000000,2013-07-17 14:50:02.000000000,2013-07-17 14:50:02.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2583}, {'_account_id': 2592}, {'_account_id': 6072}, {'_account_id': 6659}]","[{'number': 1, 'created': '2013-07-16 10:22:33.000000000', 'files': ['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dab95c486180bdd23ead4c916cbccece052b57fa', 'message': 'LBaaS: update DB pool stats received from lbaas agent\n\nFixes bug 1201401\n\nChange-Id: I84e2fbdb3e6368529c1d829d4e8134e6b0b54311\n'}]",0,37208,dab95c486180bdd23ead4c916cbccece052b57fa,9,6,1,5948,,,0,"LBaaS: update DB pool stats received from lbaas agent

Fixes bug 1201401

Change-Id: I84e2fbdb3e6368529c1d829d4e8134e6b0b54311
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/37208/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py']",3,dab95c486180bdd23ead4c916cbccece052b57fa,bug/1201401," self.plugin.update_pool_stats(ctx, pool_id) self.assertRaises(ValueError, self.plugin.update_pool_stats, self.plugin.update_pool_stats(ctx, pool_id, stats_data)"," self.plugin._update_pool_stats(ctx, pool_id) self.assertRaises(ValueError, self.plugin._update_pool_stats, self.plugin._update_pool_stats(ctx, pool_id, stats_data)",5,6
openstack%2Fnova~master~I3ff9001543b84b1037597da243422490bb611657,openstack/nova,master,I3ff9001543b84b1037597da243422490bb611657,Force reopening eventlet's hub after fork,MERGED,2013-07-17 08:09:34.000000000,2013-07-17 14:49:45.000000000,2013-07-17 14:49:40.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 2166}, {'_account_id': 5511}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-07-17 08:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/598ecdf8d42388b5a4def72ba74e15c2027d9096', 'message': ""Force reseting eventlet's epoll hub after fork\n\nWith this we recreate the hub after a fork when using epoll and prevent\nthe child process to inherit and use the epoll file descriptor from the\nparent process.\n\nThis caused that when more than two processes were sharing the same hub\n(and the same epoll fd), those processes weren't able to process the\nevents in the sockets as they should, causing the whole epoll system to\nwork erratically and, in this case, hang the VNC data flow.\n\nIt is recommended that when forking a epoll-based process to not share\nthe epoll instance between them to prevent such problems.\n\nFixes bug #1193031\n\nChange-Id: I3ff9001543b84b1037597da243422490bb611657\n""}, {'number': 2, 'created': '2013-07-17 12:54:10.000000000', 'files': ['nova/console/websocketproxy.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cb25bc4530323aaa33d5c42eb01f998d463f2106', 'message': ""Force reopening eventlet's hub after fork\n\nWith this we reopen eventlet's hub after a fork (triggered from\nwebsockify when a new client connects) to prevent sharing epoll's fd\nwith the parent, which may cause erratic behaviour.\n\nThis caused novncproxy to stop working when it had more than two clients\nconnected.\n\nFixes bug #1193031\n\nChange-Id: I3ff9001543b84b1037597da243422490bb611657\n""}]",0,37419,cb25bc4530323aaa33d5c42eb01f998d463f2106,13,8,2,7808,,,0,"Force reopening eventlet's hub after fork

With this we reopen eventlet's hub after a fork (triggered from
websockify when a new client connects) to prevent sharing epoll's fd
with the parent, which may cause erratic behaviour.

This caused novncproxy to stop working when it had more than two clients
connected.

Fixes bug #1193031

Change-Id: I3ff9001543b84b1037597da243422490bb611657
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/37419/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/console/websocketproxy.py'],1,598ecdf8d42388b5a4def72ba74e15c2027d9096,bug/1193031," from eventlet import hubs if hubs.get_default_hub() == hubs.epolls: hubs.use_hub(""epolls"") ",,4,0
openstack%2Fmurano-dashboard~master~I53f9a10ddc41fe2cb9ae724cb0a4968eb7a081e5,openstack/murano-dashboard,master,I53f9a10ddc41fe2cb9ae724cb0a4968eb7a081e5,New name for services. service_type -> type,MERGED,2013-07-17 11:21:59.000000000,2013-07-17 14:46:00.000000000,2013-07-17 14:46:00.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7549}]","[{'number': 1, 'created': '2013-07-17 11:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/d95ea7f341e5be3c709fc3e11edf27f6ff379e9c', 'message': 'New name for services. service_type -> type\n\nChange-Id: I53f9a10ddc41fe2cb9ae724cb0a4968eb7a081e5\n'}, {'number': 2, 'created': '2013-07-17 12:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/5942ca82b49883e6ab556236e85be83aee97a20f', 'message': 'New name for services. service_type -> type\n\nChange-Id: I53f9a10ddc41fe2cb9ae724cb0a4968eb7a081e5\n'}, {'number': 3, 'created': '2013-07-17 12:26:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/33fa95e78fd31c2754972c1b9b771715969ff291', 'message': 'New name for services. service_type -> type\n\nChange-Id: I53f9a10ddc41fe2cb9ae724cb0a4968eb7a081e5\n'}, {'number': 4, 'created': '2013-07-17 13:03:23.000000000', 'files': ['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/api.py', 'muranodashboard/panel/consts.py', 'muranodashboard/panel/tabs.py', 'muranodashboard/panel/tables.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/45100fc508cff9797a9526b03a20f0e16c2a4836', 'message': 'New name for services. service_type -> type\n\nChange-Id: I53f9a10ddc41fe2cb9ae724cb0a4968eb7a081e5\n'}]",0,37448,45100fc508cff9797a9526b03a20f0e16c2a4836,12,3,4,7549,,,0,"New name for services. service_type -> type

Change-Id: I53f9a10ddc41fe2cb9ae724cb0a4968eb7a081e5
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/48/37448/4 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/panel/views.py', 'muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/panel/api.py', 'muranodashboard/panel/consts.py', 'muranodashboard/panel/tabs.py', 'muranodashboard/panel/tables.py']",6,d95ea7f341e5be3c709fc3e11edf27f6ff379e9c,," _type = tables.Column('type',"," _type = tables.Column('service_type',",24,25
openstack%2Fheat~master~Id5fdfcde8541e83f68406c67250b815b35fbbf54,openstack/heat,master,Id5fdfcde8541e83f68406c67250b815b35fbbf54,Add tests for resource-data delete bug.,MERGED,2013-07-17 00:33:25.000000000,2013-07-17 14:42:34.000000000,2013-07-17 03:52:48.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-07-17 00:33:25.000000000', 'files': ['heat/db/api.py', 'heat/tests/test_nested_stack.py', 'heat/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5b9d98fb6fd1a0459474dad196b9f63c72ef6ee7', 'message': 'Add tests for resource-data delete bug.\n\nFixes bug 1201974\n\nChange-Id: Id5fdfcde8541e83f68406c67250b815b35fbbf54\n'}]",1,37363,5b9d98fb6fd1a0459474dad196b9f63c72ef6ee7,7,3,1,7256,,,0,"Add tests for resource-data delete bug.

Fixes bug 1201974

Change-Id: Id5fdfcde8541e83f68406c67250b815b35fbbf54
",git fetch https://review.opendev.org/openstack/heat refs/changes/63/37363/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/db/api.py', 'heat/tests/test_nested_stack.py', 'heat/db/sqlalchemy/api.py']",3,5b9d98fb6fd1a0459474dad196b9f63c72ef6ee7,," result = resource_data_get_by_key(resource.context, resource.id, key) return result.value def resource_data_get_by_key(context, resource_id, key): result = (model_query(context, models.ResourceData) .filter_by(resource_id=resource_id) .filter_by(key=key) .first()) if not result: raise exception.NotFound('No resource data found') if result.redact and result.value: result.value = crypt.decrypt(result.value) return result try: current = resource_data_get_by_key(resource.context, resource.id, key) except exception.NotFound: current = models.ResourceData() current.key = key current.resource_id = resource.id current.redact = redact current.value = value current.save() return current"," data_lst = filter(lambda x: x.key == key, resource.data) if not data_lst: return None assert len(data_lst) == 1 data = data_lst[0] if data.redact: return crypt.decrypt(data.value) else: return data.value data_lst = filter(lambda x: x.key == key, resource.data) if data_lst: # Key exists in db, so check value & replace if necessary assert len(data_lst) == 1 resource_data = data_lst[0] # If the new value is the same, do nothing if value == resource_data.value: return None # Otherwise, delete the old value for i, d in enumerate(resource.data): if d.key == key: index = i del(resource.data[index]) else: # Build a new key/value resource_data = models.ResourceData() resource_data.key = key resource_data.resource_id = resource.id resource_data.redact = True resource_data.value = value resource.data.append(resource_data) # Save to new key/value pair to database rs = model_query(resource.context, models.Resource).get(resource.id) rs.update_and_save({'data': resource.data})",75,39
openstack%2Fcinder~master~Ie4b46339423e6a1ad3d8ca699a2412b825206c0e,openstack/cinder,master,Ie4b46339423e6a1ad3d8ca699a2412b825206c0e,Make String column creation compatible with SQLAlchemy 0.8,MERGED,2013-07-09 17:35:23.000000000,2013-07-17 14:39:47.000000000,2013-07-10 06:46:17.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5652}]","[{'number': 1, 'created': '2013-07-09 17:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1d5158ddc5bfc7656a3d2be55efca9ca9ef5e3b3', 'message': 'Make String column creation compatible with SQLAlchemy 0.8\n\n3 migration scripts used the convert_unicode, unicode_error, and\n_warn_on_bytestring arguments when creating String columns.  These\nseem to cause problems with SQLAlchemy 0.8.  Nova excised all use\nof such arguments in commit 93dec58156e when squashing migrations\nfor Grizzly, and seems to have no problems with SQLAlchemy 0.8.\n\nChange-Id: Ie4b46339423e6a1ad3d8ca699a2412b825206c0e\n'}, {'number': 2, 'created': '2013-07-10 01:59:32.000000000', 'files': ['cinder/db/sqlalchemy/migrate_repo/versions/002_quota_class.py', 'cinder/db/sqlalchemy/migrate_repo/versions/010_add_transfers_table.py', 'cinder/db/sqlalchemy/migrate_repo/versions/008_add_backup.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f2dbeafb4746c89734d70e15601f24aeb22b0d8f', 'message': 'Make String column creation compatible with SQLAlchemy 0.8\n\n3 migration scripts used the convert_unicode, unicode_error, and\n_warn_on_bytestring arguments when creating String columns.  These\nseem to cause problems with SQLAlchemy 0.8.  Nova excised all use\nof such arguments in commit 93dec58156e when squashing migrations\nfor Grizzly, and seems to have no problems with SQLAlchemy 0.8.\n\nFixes bug 1199453\n\nChange-Id: Ie4b46339423e6a1ad3d8ca699a2412b825206c0e\n'}]",0,36302,f2dbeafb4746c89734d70e15601f24aeb22b0d8f,12,5,2,5652,,,0,"Make String column creation compatible with SQLAlchemy 0.8

3 migration scripts used the convert_unicode, unicode_error, and
_warn_on_bytestring arguments when creating String columns.  These
seem to cause problems with SQLAlchemy 0.8.  Nova excised all use
of such arguments in commit 93dec58156e when squashing migrations
for Grizzly, and seems to have no problems with SQLAlchemy 0.8.

Fixes bug 1199453

Change-Id: Ie4b46339423e6a1ad3d8ca699a2412b825206c0e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/02/36302/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/sqlalchemy/migrate_repo/versions/002_quota_class.py', 'cinder/db/sqlalchemy/migrate_repo/versions/010_add_transfers_table.py', 'cinder/db/sqlalchemy/migrate_repo/versions/008_add_backup.py']",3,1d5158ddc5bfc7656a3d2be55efca9ca9ef5e3b3,bug/1199453," Column('user_id', String(length=255)), Column('project_id', String(length=255)), Column('host', String(length=255)), Column('availability_zone', String(length=255)), Column('display_name', String(length=255)), Column('display_description', String(length=255)), Column('container', String(length=255)), Column('status', String(length=255)), Column('fail_reason', String(length=255)), Column('service_metadata', String(length=255)), Column('service', String(length=255)),"," Column('user_id', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)), Column('project_id', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)), Column('host', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)), Column('availability_zone', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)), Column('display_name', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)), Column('display_description', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)), Column('container', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)), Column('status', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)), Column('fail_reason', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)), Column('service_metadata', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)), Column('service', String(length=255, convert_unicode=False, unicode_error=None, _warn_on_bytestring=False)),",21,71
openstack%2Fnova~master~I03d1d3268c800dc6982ffa4b13f8b9489428b991,openstack/nova,master,I03d1d3268c800dc6982ffa4b13f8b9489428b991,Support scoped keys in aggregate extra specs filter,MERGED,2013-07-05 19:23:26.000000000,2013-07-17 14:27:30.000000000,2013-07-17 02:17:54.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2468}, {'_account_id': 6172}, {'_account_id': 6828}, {'_account_id': 7823}]","[{'number': 1, 'created': '2013-07-05 19:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9467a594df359b1263f9b605b8575f2a07323ce2', 'message': ""Support scoped keys in aggregate extra specs filter\n\nUpdate AggregateInstanceExtraSpecs to support scoped keys in flavor\nextra_specs.  Otherwise, you can't use this filter in combination with\nother filters that act on un-scoped extra specs, because they may\nconflict.\n\nThis recently came up on the mailing list:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-July/011421.html\n\nFix bug 1198290.\n\nChange-Id: I03d1d3268c800dc6982ffa4b13f8b9489428b991\n""}, {'number': 2, 'created': '2013-07-05 19:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/43993f4c72c2decf2377cacb627eb7f4d7456fc6', 'message': ""Support scoped keys in aggregate extra specs filter\n\nUpdate AggregateInstanceExtraSpecs to support scoped keys in flavor\nextra_specs.  Otherwise, you can't use this filter in combination with\nother filters that act on un-scoped extra specs, because they may\nconflict.\n\nThis recently came up on the mailing list:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-July/011421.html\n\nFix bug 1198290.\n\nDocImpact\n\nChange-Id: I03d1d3268c800dc6982ffa4b13f8b9489428b991\n""}, {'number': 3, 'created': '2013-07-05 20:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3679ef9efb867440971e0f77f35d953c5344601', 'message': ""Support scoped keys in aggregate extra specs filter\n\nUpdate AggregateInstanceExtraSpecs to support scoped keys in flavor\nextra_specs.  Otherwise, you can't use this filter in combination with\nother filters that act on un-scoped extra specs, because they may\nconflict.\n\nThis recently came up on the mailing list:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-July/011421.html\n\nFix bug 1198290.\n\nDocImpact\n\nChange-Id: I03d1d3268c800dc6982ffa4b13f8b9489428b991\n""}, {'number': 4, 'created': '2013-07-08 12:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3c905cd96e95a98c16cb6b8a3dc08c26ee77698', 'message': ""Support scoped keys in aggregate extra specs filter\n\nUpdate AggregateInstanceExtraSpecs to support scoped keys in flavor\nextra_specs.  Otherwise, you can't use this filter in combination with\nother filters that act on un-scoped extra specs, because they may\nconflict.\n\nThis recently came up on the mailing list:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-July/011421.html\n\nFix bug 1198290.\n\nDocImpact - See updates to filter_scheduler.rst.\n\nChange-Id: I03d1d3268c800dc6982ffa4b13f8b9489428b991\n""}, {'number': 5, 'created': '2013-07-16 16:11:20.000000000', 'files': ['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/aggregate_instance_extra_specs.py', 'doc/source/devref/filter_scheduler.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/fbedf60a432773716ddb02f990fc744380fee469', 'message': ""Support scoped keys in aggregate extra specs filter\n\nUpdate AggregateInstanceExtraSpecs to support scoped keys in flavor\nextra_specs.  Otherwise, you can't use this filter in combination with\nother filters that act on un-scoped extra specs, because they may\nconflict.\n\nThis recently came up on the mailing list:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-July/011421.html\n\nFix bug 1198290.\n\nDocImpact - See updates to filter_scheduler.rst.\n\nChange-Id: I03d1d3268c800dc6982ffa4b13f8b9489428b991\n""}]",14,35867,fbedf60a432773716ddb02f990fc744380fee469,33,11,5,1561,,,0,"Support scoped keys in aggregate extra specs filter

Update AggregateInstanceExtraSpecs to support scoped keys in flavor
extra_specs.  Otherwise, you can't use this filter in combination with
other filters that act on un-scoped extra specs, because they may
conflict.

This recently came up on the mailing list:

http://lists.openstack.org/pipermail/openstack-dev/2013-July/011421.html

Fix bug 1198290.

DocImpact - See updates to filter_scheduler.rst.

Change-Id: I03d1d3268c800dc6982ffa4b13f8b9489428b991
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/35867/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/aggregate_instance_extra_specs.py', 'doc/source/devref/filter_scheduler.rst']",3,9467a594df359b1263f9b605b8575f2a07323ce2,bug/1198941, have no scope or are scopd with 'aggregate_instance_extra_specs'). It passes hosts that can create the specified instance type., have no scope). It passes hosts that can create the specified instance type.,19,8
openstack%2Fmurano-deployment~master~I52e41836f2690d50aa3147f85d2a49fecb33b181,openstack/murano-deployment,master,I52e41836f2690d50aa3147f85d2a49fecb33b181,A few registry keys added.,MERGED,2013-07-17 14:21:49.000000000,2013-07-17 14:27:26.000000000,2013-07-17 14:27:26.000000000,"[{'_account_id': 3}, {'_account_id': 7562}]","[{'number': 1, 'created': '2013-07-17 14:21:49.000000000', 'files': ['image-builder/share/scripts/wpi.ps1'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/136d37ae81b3b8f8805251354d6d32cd30ab43a8', 'message': 'A few registry keys added.\n\n* Remote Desktop enabled\n* Open File Security Warning disable for several file types.\n\nChange-Id: I52e41836f2690d50aa3147f85d2a49fecb33b181\n'}]",0,37483,136d37ae81b3b8f8805251354d6d32cd30ab43a8,5,2,1,7562,,,0,"A few registry keys added.

* Remote Desktop enabled
* Open File Security Warning disable for several file types.

Change-Id: I52e41836f2690d50aa3147f85d2a49fecb33b181
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/83/37483/1 && git format-patch -1 --stdout FETCH_HEAD,['image-builder/share/scripts/wpi.ps1'],1,136d37ae81b3b8f8805251354d6d32cd30ab43a8,image-builder-fix,,,0,0
openstack%2Fmurano~master~I27f766dc37d5c891d4eb77e4eca082bfe88f8b8f,openstack/murano,master,I27f766dc37d5c891d4eb77e4eca082bfe88f8b8f,Added incremental deployment number,ABANDONED,2013-07-17 14:02:58.000000000,2013-07-17 14:22:12.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-17 14:02:58.000000000', 'files': ['muranoapi/db/migrate_repo/versions/012_add_num_column_to_deployment.py', 'muranoapi/db/services/sessions.py', 'muranoapi/db/models.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/9024065eff5902002a2dad29f0eb79ba25fa6171', 'message': 'Added incremental deployment number\n\nNeeded to display some deployment ""name"" for a given environment. Natural order should do fine for this\n\nChange-Id: I27f766dc37d5c891d4eb77e4eca082bfe88f8b8f\n'}]",0,37479,9024065eff5902002a2dad29f0eb79ba25fa6171,2,1,1,8127,,,0,"Added incremental deployment number

Needed to display some deployment ""name"" for a given environment. Natural order should do fine for this

Change-Id: I27f766dc37d5c891d4eb77e4eca082bfe88f8b8f
",git fetch https://review.opendev.org/openstack/murano refs/changes/79/37479/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranoapi/db/migrate_repo/versions/012_add_num_column_to_deployment.py', 'muranoapi/db/services/sessions.py', 'muranoapi/db/models.py']",3,9024065eff5902002a2dad29f0eb79ba25fa6171,feature-deploymentNumber," num = Column(BigInteger, nullable=False, default=1)",,35,0
openstack%2Fsahara-dashboard~master~I646bd03852d1f705742a763f915ae5e0741b8f83,openstack/sahara-dashboard,master,I646bd03852d1f705742a763f915ae5e0741b8f83,Error description  added to Cluster Details page,MERGED,2013-07-17 11:49:40.000000000,2013-07-17 14:18:23.000000000,2013-07-17 14:18:23.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-17 11:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/6373e8d25129fc31570af19b3dfb15952c83d134', 'message': 'Error tab added to Cluster Details page\n\nImplements blueprint handle-cluster-errors\n\nChange-Id: I646bd03852d1f705742a763f915ae5e0741b8f83\n'}, {'number': 2, 'created': '2013-07-17 12:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/8c2fab33c8d91b089cc8611d08ab7ddb708e5b74', 'message': 'Error tab added to Cluster Details page\n\nImplements blueprint handle-cluster-errors\n\nChange-Id: I646bd03852d1f705742a763f915ae5e0741b8f83\n'}, {'number': 3, 'created': '2013-07-17 14:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/5027be2f815422ca553e7d3e8e081d50fb2ac606', 'message': 'Error description  added to Cluster Details page\n\nImplements blueprint handle-cluster-errors\n\nChange-Id: I646bd03852d1f705742a763f915ae5e0741b8f83\n'}, {'number': 4, 'created': '2013-07-17 14:05:11.000000000', 'files': ['savannadashboard/templates/clusters/_details.html'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/672463b4b30c484fc749e9b736d10e2f10f25cc0', 'message': 'Error description  added to Cluster Details page\n\nImplements blueprint handle-cluster-errors\n\nChange-Id: I646bd03852d1f705742a763f915ae5e0741b8f83\n'}]",1,37453,672463b4b30c484fc749e9b736d10e2f10f25cc0,15,5,4,7132,,,0,"Error description  added to Cluster Details page

Implements blueprint handle-cluster-errors

Change-Id: I646bd03852d1f705742a763f915ae5e0741b8f83
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/53/37453/4 && git format-patch -1 --stdout FETCH_HEAD,"['savannadashboard/templates/clusters/_error_details.html', 'savannadashboard/savannadashboard', 'savannadashboard/clusters/tabs.py']",3,6373e8d25129fc31570af19b3dfb15952c83d134,bp/handle-cluster-errors,"class ErrorTab(tabs.Tab): name = _(""Errors"") slug = ""cluster_errors_tab"" template_name = ""clusters/_error_details.html"" def get_context_data(self, request): cluster_id = self.tab_group.kwargs['cluster_id'] savanna = savannaclient.Client(request) cluster = savanna.clusters.get(cluster_id) return {""cluster"": cluster} tabs = (GeneralTab, NodeGroupsTab, InstancesTab, ErrorTab, )"," tabs = (GeneralTab, NodeGroupsTab, InstancesTab, )",26,1
openstack%2Fheat~master~Ia6e744b7dfa9fab518050174bcff0dae50c95040,openstack/heat,master,Ia6e744b7dfa9fab518050174bcff0dae50c95040,Make sure that Tags on the InstanceGroup get passed to nova,MERGED,2013-07-15 01:10:41.000000000,2013-07-17 14:17:39.000000000,2013-07-17 14:17:39.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 7135}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-07-15 01:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/20a135d9ceeb3bd7dbd3d586d6a3df624d65044e', 'message': 'Make sure that Tags on the InstanceGroup get passed to nova\n\nThis is needed by the ceilometer alarmer.\n\nChange-Id: Ia6e744b7dfa9fab518050174bcff0dae50c95040\n'}, {'number': 2, 'created': '2013-07-15 05:59:45.000000000', 'files': ['heat/engine/resources/autoscaling.py', 'heat/tests/test_server_tags.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/76e3cbe79da9511c632716a69356c797c342a2dd', 'message': 'Make sure that Tags on the InstanceGroup get passed to nova\n\nThis is needed by the ceilometer alarmer.\n\nChange-Id: Ia6e744b7dfa9fab518050174bcff0dae50c95040\n'}]",2,37005,76e3cbe79da9511c632716a69356c797c342a2dd,13,7,2,4715,,,0,"Make sure that Tags on the InstanceGroup get passed to nova

This is needed by the ceilometer alarmer.

Change-Id: Ia6e744b7dfa9fab518050174bcff0dae50c95040
",git fetch https://review.opendev.org/openstack/heat refs/changes/05/37005/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/autoscaling.py', 'heat/tests/test_server_tags.py']",2,20a135d9ceeb3bd7dbd3d586d6a3df624d65044e,tags,"import moxfrom heat.engine.resources import autoscalinggroup_template = ''' { ""AWSTemplateFormatVersion"" : ""2010-09-09"", ""Description"" : ""WordPress"", ""Parameters"" : { ""KeyName"" : { ""Description"" : ""KeyName"", ""Type"" : ""String"", ""Default"" : ""test"" } }, ""Resources"" : { ""Config"": { ""Type"": ""AWS::AutoScaling::LaunchConfiguration"", ""Properties"": { ""ImageId"" : ""CentOS 5.2"", ""InstanceType"" : ""256 MB Server"", ""KeyName"" : ""test"", ""UserData"" : ""wordpress"" } }, ""WebServer"": { ""Type"": ""OS::Heat::InstanceGroup"", ""Properties"": { ""AvailabilityZones"" : [""nova""], ""LaunchConfigurationName"": ""Config"", ""Size"" : ""1"" } } } } ''' def _setup_test_group(self, intags=None, nova_tags=None): stack_name = 'tag_test' t = template_format.parse(group_template) template = parser.Template(t) stack = parser.Stack(None, stack_name, template, environment.Environment({'KeyName': 'test'}), stack_id=uuidutils.generate_uuid()) t['Resources']['WebServer']['Properties']['Tags'] = intags group = autoscaling.InstanceGroup('WebServer', t['Resources']['WebServer'], stack) self.m.StubOutWithMock(instances.Instance, 'nova') instances.Instance.nova().MultipleTimes().AndReturn(self.fc) group.t = group.stack.resolve_runtime_data(group.t) # need to resolve the template functions self.m.StubOutWithMock(self.fc.servers, 'create') self.fc.servers.create( image=1, flavor=1, key_name='test', name=mox.IgnoreArg(), security_groups=None, userdata=mox.IgnoreArg(), scheduler_hints=None, meta=nova_tags, nics=None, availability_zone=None).AndReturn( self.fc.servers.list()[1]) return group def test_group_tags(self): tags = [{'Key': 'Food', 'Value': 'yum'}] metadata = dict((tm['Key'], tm['Value']) for tm in tags) group = self._setup_test_group(intags=tags, nova_tags=metadata) self.m.ReplayAll() scheduler.TaskRunner(group.create)() # we are just using mock to verify that the tags get through to the # nova call. self.m.VerifyAll()",,81,0
openstack%2Fsahara-dashboard~master~If97c561c6e5771eb8d84edf0b468ddd475ff6e98,openstack/sahara-dashboard,master,If97c561c6e5771eb8d84edf0b468ddd475ff6e98,Creating cluter w/o cluster template fixed,MERGED,2013-07-17 12:26:06.000000000,2013-07-17 14:16:22.000000000,2013-07-17 14:16:22.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-17 12:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/f6464bb5b38e5d3b4abb0c73df3da158a6a77e49', 'message': 'Creating cluter w/o cluster template fixed\n\nNow user will recieve an error message, saying that Cluster\ncould not be created w/o node groups.\n\nFixes bug 1200601\n\nChange-Id: If97c561c6e5771eb8d84edf0b468ddd475ff6e98\n'}, {'number': 2, 'created': '2013-07-17 13:42:07.000000000', 'files': ['savannadashboard/clusters/workflows/create.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/15adfdf2dfacae6eb0802a03f237e64e163ff549', 'message': 'Creating cluter w/o cluster template fixed\n\nNow user will recieve an error message, saying that Cluster\ncould not be created w/o node groups.\n\nFixes bug 1200601\n\nChange-Id: If97c561c6e5771eb8d84edf0b468ddd475ff6e98\n'}]",1,37456,15adfdf2dfacae6eb0802a03f237e64e163ff549,11,5,2,7132,,,0,"Creating cluter w/o cluster template fixed

Now user will recieve an error message, saying that Cluster
could not be created w/o node groups.

Fixes bug 1200601

Change-Id: If97c561c6e5771eb8d84edf0b468ddd475ff6e98
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/56/37456/2 && git format-patch -1 --stdout FETCH_HEAD,['savannadashboard/clusters/workflows/create.py'],1,f6464bb5b38e5d3b4abb0c73df3da158a6a77e49,bug/1200601," cluster_template_id = context[""general_cluster_template""] if not cluster_template_id: cluster_template_id = None cluster_template_id=cluster_template_id,"," cluster_template_id=context[""general_cluster_template""],",5,1
openstack%2Fsahara~master~Ie1483de49e00ac578ed6853d2614e986a6194528,openstack/sahara,master,Ie1483de49e00ac578ed6853d2614e986a6194528,Add cinder validation,MERGED,2013-07-16 15:28:30.000000000,2013-07-17 14:10:12.000000000,2013-07-17 14:10:12.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}]","[{'number': 1, 'created': '2013-07-16 15:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ef9b45cc7e40fd55b14e555002c002d7587e4e4f', 'message': 'Add cinder validation\n\nChange-Id: Ie1483de49e00ac578ed6853d2614e986a6194528\nFixes: bug #1199871\n'}, {'number': 2, 'created': '2013-07-16 16:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/eb7bde2add42d6430cec3096ea0f5bef72130baa', 'message': 'Add cinder validation\n\nTODO:\n* Fix unit tests\n\nChange-Id: Ie1483de49e00ac578ed6853d2614e986a6194528\nFixes: bug #1199871\n'}, {'number': 3, 'created': '2013-07-17 10:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/cc2712ef71063d035f9a5758684a9973f73a64d8', 'message': 'Add cinder validation\n\nChange-Id: Ie1483de49e00ac578ed6853d2614e986a6194528\nFixes: bug #1199871\n'}, {'number': 4, 'created': '2013-07-17 12:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/041b003a4bebcb5edc3fea6b99205e6cabe2c3ef', 'message': 'Add cinder validation\n\nChange-Id: Ie1483de49e00ac578ed6853d2614e986a6194528\nFixes: bug #1199871\n'}, {'number': 5, 'created': '2013-07-17 12:16:15.000000000', 'files': ['savanna/service/validations/node_group_templates.py', 'savanna/utils/api_validator.py', 'savanna/utils/openstack/keystone.py', 'savanna/tests/unit/service/test_validation.py', 'savanna/service/validations/base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/d32998d611e1b80c65375ffc78bee70284f927d6', 'message': 'Add cinder validation\n\nChange-Id: Ie1483de49e00ac578ed6853d2614e986a6194528\nFixes: bug #1199871\n'}]",6,37274,d32998d611e1b80c65375ffc78bee70284f927d6,29,5,5,7710,,,0,"Add cinder validation

Change-Id: Ie1483de49e00ac578ed6853d2614e986a6194528
Fixes: bug #1199871
",git fetch https://review.opendev.org/openstack/sahara refs/changes/74/37274/3 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/service/validations/node_group_templates.py', 'savanna/utils/api_validator.py', 'savanna/utils/openstack/keystone.py', 'savanna/service/validations/base.py']",4,ef9b45cc7e40fd55b14e555002c002d7587e4e4f,bug/1199871,"import savanna.utils.openstack.keystone as keystone if ng.get('volumes_per_node'): if ng['volumes_per_node']: check_cinder_exists() ## Cinder def check_cinder_exists(): services = [service.name for service in keystone.client().services.list()] if 'cinder' not in services: raise ex.InvalidException(""Cinder is not suuport in this lab"")",,56,1
openstack%2Fsahara-dashboard~master~Icf8c48922244cb20ba68a4c784ae312c64773750,openstack/sahara-dashboard,master,Icf8c48922244cb20ba68a4c784ae312c64773750,Button 'Upload Template' correctly work now,MERGED,2013-07-17 11:39:56.000000000,2013-07-17 14:06:09.000000000,2013-07-17 14:06:09.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7700}]","[{'number': 1, 'created': '2013-07-17 11:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/330bde5b42d4adaef9f4c7a262b222f15777e9ba', 'message': ""Button 'Upload Template' correctly work now\n\nChange-Id: Icf8c48922244cb20ba68a4c784ae312c64773750\nFixes: bug #1200245\n""}, {'number': 2, 'created': '2013-07-17 11:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/e05395ac56742b44d20c2c1cb6b9587dd3d034e5', 'message': ""Button 'Upload Template' correctly work now\n\nFixes: bug #1200245\n\nChange-Id: Icf8c48922244cb20ba68a4c784ae312c64773750\n""}, {'number': 3, 'created': '2013-07-17 13:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/e83d5c24a62be820288b9c46532486791b86aef2', 'message': ""Button 'Upload Template' correctly work now\n\nFixes: bug #1200245\n\nChange-Id: Icf8c48922244cb20ba68a4c784ae312c64773750\n""}, {'number': 4, 'created': '2013-07-17 13:38:31.000000000', 'files': ['savannadashboard/cluster_templates/forms.py', 'AUTHORS'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/4136846866a479b4e37cc75c2188bea81317e4aa', 'message': ""Button 'Upload Template' correctly work now\n\nFixes: bug #1200245\n\nChange-Id: Icf8c48922244cb20ba68a4c784ae312c64773750\n""}]",0,37451,4136846866a479b4e37cc75c2188bea81317e4aa,17,6,4,7700,,,0,"Button 'Upload Template' correctly work now

Fixes: bug #1200245

Change-Id: Icf8c48922244cb20ba68a4c784ae312c64773750
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/51/37451/3 && git format-patch -1 --stdout FETCH_HEAD,['savannadashboard/cluster_templates/forms.py'],1,330bde5b42d4adaef9f4c7a262b222f15777e9ba,bug/1200245," except Exception as e: messages.error(request, str(e)) return True", except Exception: exceptions.handle(request),3,2
openstack%2Fheat~master~I1f89e068da3e47b94434cb71db87704f9665dea2,openstack/heat,master,I1f89e068da3e47b94434cb71db87704f9665dea2,Fix version and location of heat doc build,MERGED,2013-07-16 15:02:19.000000000,2013-07-17 14:05:54.000000000,2013-07-17 14:05:53.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7090}, {'_account_id': 7193}, {'_account_id': 7256}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-07-16 15:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/004f11ff0d718d446262f90ad66bd43cf0accbbb', 'message': 'Fix version and location of heat doc build\n\nChange-Id: I1f89e068da3e47b94434cb71db87704f9665dea2\n'}, {'number': 2, 'created': '2013-07-16 18:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/103e8ce76a19142e7b27157cc2fc59dc4709ebdf', 'message': 'Fix version and location of heat doc build\n\nChange-Id: I1f89e068da3e47b94434cb71db87704f9665dea2\n'}, {'number': 3, 'created': '2013-07-16 18:29:51.000000000', 'files': ['doc/source/conf.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/heat/commit/c7f313551e52e0bf8d79c774c4831ed3973d843f', 'message': 'Fix version and location of heat doc build\n\npbr injects version information as part of the build_sphinx command,\nso having it here is overkill.\n\nChange-Id: I1f89e068da3e47b94434cb71db87704f9665dea2\n'}]",2,37265,c7f313551e52e0bf8d79c774c4831ed3973d843f,15,7,3,2,,,0,"Fix version and location of heat doc build

pbr injects version information as part of the build_sphinx command,
so having it here is overkill.

Change-Id: I1f89e068da3e47b94434cb71db87704f9665dea2
",git fetch https://review.opendev.org/openstack/heat refs/changes/65/37265/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'setup.cfg']",2,004f11ff0d718d446262f90ad66bd43cf0accbbb,,output_file = heat/locale/heat.pot [build_sphinx] all_files = 1 build-dir = doc/build source-dir = doc/source ,output_file = heat/locale/heat.pot,6,7
openstack%2Fceilometer~master~Ib3550f26ac0507c781a5e82573a789b2513ae04c,openstack/ceilometer,master,Ib3550f26ac0507c781a5e82573a789b2513ae04c,storage: fix clear/upgrade order,MERGED,2013-07-12 16:16:18.000000000,2013-07-17 13:48:56.000000000,2013-07-17 13:48:56.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 7399}]","[{'number': 1, 'created': '2013-07-12 16:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a1912c9eddb96194db94763ee6d47c53b9ba5776', 'message': ""storage: fix clear/upgrade order\n\nWith the current order, when using MongoDB, the indexes are created on\nconnection, but clear() drop the database with the indexes just after,\nmeaning we have no indexes! Let's fix that by upgrading (so we're sure we\nhave tables or the like), then clearing data, then upgrading again so we're\nsure we have our tables or indexes.\n\nChange-Id: Ib3550f26ac0507c781a5e82573a789b2513ae04c\n""}, {'number': 2, 'created': '2013-07-12 16:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/37ea035ff506317d696deaa83c64202f625d4035', 'message': ""storage: fix clear/upgrade order\n\nWith the current order, when using MongoDB, the indexes are created on\nconnection, but clear() drop the database with the indexes just after,\nmeaning we have no indexes! Let's fix that by upgrading (so we're sure we\nhave tables or the like), then clearing data, then upgrading again so we're\nsure we have our tables or indexes.\n\nChange-Id: Ib3550f26ac0507c781a5e82573a789b2513ae04c\n""}, {'number': 3, 'created': '2013-07-15 15:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5cdd9a4e2a14d312b0564a8624d9fa3cbc1064b4', 'message': ""storage: fix clear/upgrade order\n\nWith the current order, when using MongoDB, the indexes are created on\nconnection, but clear() drop the database with the indexes just after,\nmeaning we have no indexes! Let's fix that by upgrading (so we're sure we\nhave tables or the like), then clearing data, then upgrading again so we're\nsure we have our tables or indexes.\n\nChange-Id: Ib3550f26ac0507c781a5e82573a789b2513ae04c\n""}, {'number': 4, 'created': '2013-07-17 12:12:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c03c54193e317b03e61bdf4d6d2359dad1a64b66', 'message': ""storage: fix clear/upgrade order\n\nWith the current order, when using MongoDB, the indexes are created on\nconnection, but clear() drop the database with the indexes just after,\nmeaning we have no indexes! Let's fix that by upgrading (so we're sure we\nhave tables or the like), then clearing data, then upgrading again so we're\nsure we have our tables or indexes.\n\nChange-Id: Ib3550f26ac0507c781a5e82573a789b2513ae04c\n""}, {'number': 5, 'created': '2013-07-17 12:37:54.000000000', 'files': ['ceilometer/storage/impl_mongodb.py', 'ceilometer/tests/db.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3c2475e9dd9d9a97a5eeb83deb8a0f218732db9f', 'message': ""storage: fix clear/upgrade order\n\nWith the current order, when using MongoDB, the indexes are created on\nconnection, but clear() drop the database with the indexes just after,\nmeaning we have no indexes! Let's fix that by upgrading (so we're sure we\nhave tables or the like), then clearing data, then upgrading again so we're\nsure we have our tables or indexes.\n\nChange-Id: Ib3550f26ac0507c781a5e82573a789b2513ae04c\n""}]",3,36854,3c2475e9dd9d9a97a5eeb83deb8a0f218732db9f,21,7,5,1669,,,0,"storage: fix clear/upgrade order

With the current order, when using MongoDB, the indexes are created on
connection, but clear() drop the database with the indexes just after,
meaning we have no indexes! Let's fix that by upgrading (so we're sure we
have tables or the like), then clearing data, then upgrading again so we're
sure we have our tables or indexes.

Change-Id: Ib3550f26ac0507c781a5e82573a789b2513ae04c
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/54/36854/5 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/impl_mongodb.py', 'ceilometer/tests/db.py']",2,a1912c9eddb96194db94763ee6d47c53b9ba5776,jd/fix-mongo-index, self.conn.upgrade(),,5,4
openstack%2Fopenstack-planet~master~Ib309e66813fc403d7b20b8d0b2678d335839f06d,openstack/openstack-planet,master,Ib309e66813fc403d7b20b8d0b2678d335839f06d,Added terriyu to Planet OpenStack,MERGED,2013-07-17 03:54:00.000000000,2013-07-17 13:43:04.000000000,2013-07-17 13:43:04.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2013-07-17 03:54:00.000000000', 'files': ['images/terriyu.png', 'planet.ini'], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/9d3fe1735db9df9f4aa4f3349227352919a06d37', 'message': 'Added terriyu to Planet OpenStack\n\nChange-Id: Ib309e66813fc403d7b20b8d0b2678d335839f06d\n'}]",0,37386,9d3fe1735db9df9f4aa4f3349227352919a06d37,5,2,1,7399,,,0,"Added terriyu to Planet OpenStack

Change-Id: Ib309e66813fc403d7b20b8d0b2678d335839f06d
",git fetch https://review.opendev.org/openstack/openstack-planet refs/changes/86/37386/1 && git format-patch -1 --stdout FETCH_HEAD,"['images/terriyu.png', 'planet.ini']",2,9d3fe1735db9df9f4aa4f3349227352919a06d37,master, [http://terriyu.info/blog/feeds/tag/openstack.atom.xml] name = Terri Yu face = terriyu.png nick = terriyu,,5,0
openstack%2Fcookbook-openstack-identity~master~If3749157881abd97c425b918ec4a4496fe8b2b40,openstack/cookbook-openstack-identity,master,If3749157881abd97c425b918ec4a4496fe8b2b40,database specific client bindings packages aren't used anywhere,ABANDONED,2013-07-17 13:36:58.000000000,2013-07-17 13:38:10.000000000,,[],"[{'number': 1, 'created': '2013-07-17 13:36:58.000000000', 'files': ['attributes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/ac1e40eca66a8de7ecbf6ea7feaeab2ff372ef4d', 'message': ""database specific client bindings packages aren't used anywhere\n\nChange-Id: If3749157881abd97c425b918ec4a4496fe8b2b40\n""}]",0,37466,ac1e40eca66a8de7ecbf6ea7feaeab2ff372ef4d,1,0,1,2340,,,0,"database specific client bindings packages aren't used anywhere

Change-Id: If3749157881abd97c425b918ec4a4496fe8b2b40
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/66/37466/1 && git format-patch -1 --stdout FETCH_HEAD,['attributes/default.rb'],1,ac1e40eca66a8de7ecbf6ea7feaeab2ff372ef4d,remove-db-specifics,," ""mysql_python_packages"" => [ ""MySQL-python"" ], ""postgresql_python_packages"" => [ ""python-psycopg2"" ], ""mysql_python_packages"" => [ ""python-mysql"" ], ""postgresql_python_packages"" => [ ""python-psycopg2"" ], ""mysql_python_packages"" => [ ""python-mysqldb"" ], ""postgresql_python_packages"" => [ ""python-psycopg2"" ],",0,6
openstack%2Fopenstack-manuals~master~Id2450f5c59449499befabad44d17ed9031721736,openstack/openstack-manuals,master,Id2450f5c59449499befabad44d17ed9031721736,Fix typo in Network Guide,MERGED,2013-07-17 02:56:27.000000000,2013-07-17 13:30:11.000000000,2013-07-17 13:30:10.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2013-07-17 02:56:27.000000000', 'files': ['doc/src/docbkx/openstack-network-connectivity-admin/ch_under_the_hood.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ca21964e06c7561d45879d56601667c1a57e3b8c', 'message': ""Fix typo in Network Guide\n\n'qcbXXX' should be 'qvbXXX'.\n\nFixes bug 1201779\n\nChange-Id: Id2450f5c59449499befabad44d17ed9031721736\n""}]",0,37378,ca21964e06c7561d45879d56601667c1a57e3b8c,6,3,1,6414,,,0,"Fix typo in Network Guide

'qcbXXX' should be 'qvbXXX'.

Fixes bug 1201779

Change-Id: Id2450f5c59449499befabad44d17ed9031721736
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/78/37378/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-network-connectivity-admin/ch_under_the_hood.xml'],1,ca21964e06c7561d45879d56601667c1a57e3b8c,bug/1201779," <literal>(qvb<replaceable>XXX</replaceable>,"," <literal>(qcb<replaceable>XXX</replaceable>,",1,1
openstack%2Fdevstack~master~I33058352f5abfb06f2a992890cbc7339cedc0ad3,openstack/devstack,master,I33058352f5abfb06f2a992890cbc7339cedc0ad3,Disable fallocate and set max_file_size to default,MERGED,2013-07-16 07:18:15.000000000,2013-07-17 13:20:02.000000000,2013-07-17 13:20:01.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2696}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-16 07:18:15.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/82c0996d48156465980efb6898764c2bb270faaf', 'message': 'Disable fallocate and set max_file_size to default\n\n- We used to set max_file_size to 10000 to get the functional tests\n  passing on devstack but this was the wrong way. We are now disabling\n  fallocate like done in saio to get the large objects test passing.\n- Fixes bug 1201077.\n\nChange-Id: I33058352f5abfb06f2a992890cbc7339cedc0ad3\n'}]",0,37182,82c0996d48156465980efb6898764c2bb270faaf,6,4,1,866,,,0,"Disable fallocate and set max_file_size to default

- We used to set max_file_size to 10000 to get the functional tests
  passing on devstack but this was the wrong way. We are now disabling
  fallocate like done in saio to get the large objects test passing.
- Fixes bug 1201077.

Change-Id: I33058352f5abfb06f2a992890cbc7339cedc0ad3
",git fetch https://review.opendev.org/openstack/devstack refs/changes/82/37182/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,82c0996d48156465980efb6898764c2bb270faaf,bug/1201077, iniuncomment ${swift_node_config} DEFAULT disable_fallocate iniset ${swift_node_config} DEFAULT disable_fallocate true , # Set maximum file size to 10000 bytes or our vm will fill up quickly with # the default 5gb size. iniuncomment ${testfile} func_test max_file_size iniset ${testfile} func_test max_file_size 10000 ,3,6
openstack%2Fmurano-dashboard~master~I62d8773726d4b73c1a689c665a1f6b64bb07615d,openstack/murano-dashboard,master,I62d8773726d4b73c1a689c665a1f6b64bb07615d,Fix Next/Create button label in Create Service forms.,MERGED,2013-07-17 12:45:57.000000000,2013-07-17 13:13:37.000000000,2013-07-17 13:13:37.000000000,"[{'_account_id': 3}, {'_account_id': 7549}, {'_account_id': 8040}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-07-17 12:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/38616ca4dcf8806d9ad54ea1a28af3346cf7451a', 'message': 'Fix Next/Create button label in Create Service forms.\n\nChange-Id: I62d8773726d4b73c1a689c665a1f6b64bb07615d\n'}, {'number': 2, 'created': '2013-07-17 13:04:23.000000000', 'files': ['muranodashboard/templates/_create_service_wizard.html', 'muranodashboard/templates/services.html'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/c0f41a7d5330509dabc9b4d7c6527900c6bdf6cc', 'message': 'Fix Next/Create button label in Create Service forms.\n\nChange-Id: I62d8773726d4b73c1a689c665a1f6b64bb07615d\n'}]",0,37460,c0f41a7d5330509dabc9b4d7c6527900c6bdf6cc,8,4,2,8040,,,0,"Fix Next/Create button label in Create Service forms.

Change-Id: I62d8773726d4b73c1a689c665a1f6b64bb07615d
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/60/37460/2 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/templates/_create_service_wizard.html'],1,38616ca4dcf8806d9ad54ea1a28af3346cf7451a,bug/MRN-24," {% if wizard.steps.index == 2 %} {% trans ""Create"" as next %} {% else %} {% trans ""Next"" as next %} {% endif %} <input type=""submit"" class=""btn btn-primary pull-right"" value=""{{ next }}""/> {{ next }}</button>"," <input type=""submit"" class=""btn btn-primary pull-right"" value=""{% trans 'Create' %}""/> {% trans ""Next >"" %}</button>",7,2
openstack%2Fdevstack~master~I802bbd0ced8f12064189db7d707fbb6ca09113bb,openstack/devstack,master,I802bbd0ced8f12064189db7d707fbb6ca09113bb,Fix vm_test_mode,MERGED,2013-07-16 07:36:11.000000000,2013-07-17 13:08:12.000000000,2013-07-17 13:08:12.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-07-16 07:36:11.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/35633f097ada2f16f7d4a052a26e729b6c14eaa2', 'message': 'Fix vm_test_mode\n\n- It was previously incorrectly generated.\n- Fixes bug 1201694.\n\nChange-Id: I802bbd0ced8f12064189db7d707fbb6ca09113bb\n'}]",0,37187,35633f097ada2f16f7d4a052a26e729b6c14eaa2,6,3,1,866,,,0,"Fix vm_test_mode

- It was previously incorrectly generated.
- Fixes bug 1201694.

Change-Id: I802bbd0ced8f12064189db7d707fbb6ca09113bb
",git fetch https://review.opendev.org/openstack/devstack refs/changes/87/37187/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,35633f097ada2f16f7d4a052a26e729b6c14eaa2,bug/1201694, local server_type=$4 generate_swift_config ${swift_node_config} ${node_number} $[OBJECT_PORT_BASE + 10 * (node_number - 1)] object generate_swift_config ${swift_node_config} ${node_number} $[CONTAINER_PORT_BASE + 10 * (node_number - 1)] container generate_swift_config ${swift_node_config} ${node_number} $[ACCOUNT_PORT_BASE + 10 * (node_number - 1)] account, generate_swift_config ${swift_node_config} ${node_number} $[OBJECT_PORT_BASE + 10 * (node_number - 1)] generate_swift_config ${swift_node_config} ${node_number} $[CONTAINER_PORT_BASE + 10 * (node_number - 1)] generate_swift_config ${swift_node_config} ${node_number} $[ACCOUNT_PORT_BASE + 10 * (node_number - 1)],4,3
openstack%2Fceilometer~master~I06e1f06340a2e7b782d3c7461ea86b629dadf05d,openstack/ceilometer,master,I06e1f06340a2e7b782d3c7461ea86b629dadf05d,Lose weight for Ceilometer log in verbose mode,MERGED,2013-07-17 10:20:19.000000000,2013-07-17 12:49:35.000000000,2013-07-17 12:49:35.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5055}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-17 10:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1a90abc29651de57b4c4621f84609974c1bf7e22', 'message': 'Lose weight for Ceilometer log in verbose mode\n\nWhen setting verbose=True, the log level will be set to INFO, so we\njust change the LOG method from info to debug in places where produce\nheavily output.\n\nIf want to get debug level logs, set debug=True in ceilometer.conf.\n\nChange-Id: I06e1f06340a2e7b782d3c7461ea86b629dadf05d\nFixes: bug 1192170\n'}, {'number': 2, 'created': '2013-07-17 10:52:48.000000000', 'files': ['ceilometer/pipeline.py', 'ceilometer/collector/service.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6cf57af498b1ef30c76d4a98c3266c9d191ae16f', 'message': 'Lose weight for Ceilometer log in verbose mode\n\nWhen setting verbose=True, the log level will be set to INFO, so we\njust change the LOG method from info to debug in places where produce\nheavily output.\n\nIf want to get debug level logs, set debug=True in ceilometer.conf.\n\nChange-Id: I06e1f06340a2e7b782d3c7461ea86b629dadf05d\nFixes: bug 1192170\n'}]",0,37443,6cf57af498b1ef30c76d4a98c3266c9d191ae16f,8,4,2,5055,,,0,"Lose weight for Ceilometer log in verbose mode

When setting verbose=True, the log level will be set to INFO, so we
just change the LOG method from info to debug in places where produce
heavily output.

If want to get debug level logs, set debug=True in ceilometer.conf.

Change-Id: I06e1f06340a2e7b782d3c7461ea86b629dadf05d
Fixes: bug 1192170
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/43/37443/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/pipeline.py', 'ceilometer/collector/service.py']",2,1a90abc29651de57b4c4621f84609974c1bf7e22,bug/1192170," LOG.debug('metering data %s for %s @ %s: %s',"," LOG.info('metering data %s for %s @ %s: %s',",2,2
openstack%2Fmurano-agent~master~I63d52d1a4c6628562354db62d0ac1562a2a73e5c,openstack/murano-agent,master,I63d52d1a4c6628562354db62d0ac1562a2a73e5c,typo,MERGED,2013-07-17 12:36:56.000000000,2013-07-17 12:40:09.000000000,2013-07-17 12:40:09.000000000,"[{'_account_id': 3}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-07-17 12:36:56.000000000', 'files': ['WindowsAgent/RabbitMqClient.cs'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/e82e2ca812734dc6799ba424f35dc053e0fcfa0d', 'message': 'typo\n\nChange-Id: I63d52d1a4c6628562354db62d0ac1562a2a73e5c\n'}]",0,37457,e82e2ca812734dc6799ba424f35dc053e0fcfa0d,5,2,1,7226,,,0,"typo

Change-Id: I63d52d1a4c6628562354db62d0ac1562a2a73e5c
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/57/37457/1 && git format-patch -1 --stdout FETCH_HEAD,['WindowsAgent/RabbitMqClient.cs'],1,e82e2ca812734dc6799ba424f35dc053e0fcfa0d,," //session.QueueDeclare(queueName, true, false, false, null);"," session.QueueDeclare(queueName, true, false, false, null);",1,1
openstack%2Fmurano-agent~master~Ie11e926e72ae1e2f2840468afb2a7d1652b3553d,openstack/murano-agent,master,Ie11e926e72ae1e2f2840468afb2a7d1652b3553d,Added support for RabbitMQ SSL-secured connections,MERGED,2013-07-17 07:37:56.000000000,2013-07-17 12:34:06.000000000,2013-07-17 12:34:06.000000000,"[{'_account_id': 3}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-07-17 07:37:56.000000000', 'files': ['WindowsAgent/Program.cs', 'WindowsAgent/RabbitMqClient.cs'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/a17e216a8711312819764600e562c90f83b00ef7', 'message': 'Added support for RabbitMQ SSL-secured connections\n\nChange-Id: Ie11e926e72ae1e2f2840468afb2a7d1652b3553d\n'}]",0,37412,a17e216a8711312819764600e562c90f83b00ef7,5,2,1,7226,,,0,"Added support for RabbitMQ SSL-secured connections

Change-Id: Ie11e926e72ae1e2f2840468afb2a7d1652b3553d
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/12/37412/1 && git format-patch -1 --stdout FETCH_HEAD,"['WindowsAgent/Program.cs', 'WindowsAgent/RabbitMqClient.cs']",2,a17e216a8711312819764600e562c90f83b00ef7,,"using System.Net.Security; using System.Security.Authentication; using System.Security.Cryptography.X509Certificates; var ssl = new SslOption { Enabled = bool.Parse(ConfigurationManager.AppSettings[""rabbitmq.ssl""] ?? ""false""), Version = SslProtocols.Default, AcceptablePolicyErrors = bool.Parse(ConfigurationManager.AppSettings[""rabbitmq.allowInvalidCA""] ?? ""true"") ? SslPolicyErrors.RemoteCertificateNameMismatch : SslPolicyErrors.None }; var sslServerName = ConfigurationManager.AppSettings[""rabbitmq.sslServerName""] ?? """"; ssl.ServerName = sslServerName; if (String.IsNullOrWhiteSpace(sslServerName)) { ssl.AcceptablePolicyErrors |= SslPolicyErrors.RemoteCertificateNameMismatch; } connectionFactory = new ConnectionFactory { Protocol = Protocols.DefaultProtocol, Port = int.Parse(ConfigurationManager.AppSettings[""rabbitmq.port""] ?? ""5672""), RequestedHeartbeat = 10, Ssl = ssl session.QueueDeclare(queueName, true, false, false, null);"," connectionFactory = new ConnectionFactory { Protocol = Protocols.FromEnvironment(), RequestedHeartbeat = 10 //session.QueueDeclare(queueName, true, false, false, null);",24,5
openstack%2Fsahara~master~Ie23e1d6910892c55f729153cf5a3b238a4d3c605,openstack/sahara,master,Ie23e1d6910892c55f729153cf5a3b238a4d3c605,REST API returns traceback fix,MERGED,2013-07-16 13:44:35.000000000,2013-07-17 12:34:00.000000000,2013-07-17 12:34:00.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7700}]","[{'number': 1, 'created': '2013-07-16 13:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/38ff05cc4b0878aa17362d473c46a4652a757c26', 'message': 'REST API returns traceback fix\n\nChange-Id: Ie23e1d6910892c55f729153cf5a3b238a4d3c605\n'}, {'number': 2, 'created': '2013-07-16 15:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/3ea7fef0f07314e09c08146f1e59461f037522ad', 'message': 'REST API returns traceback fix\n\nFixes: bug #1200245\nChange-Id: Ie23e1d6910892c55f729153cf5a3b238a4d3c605\n'}, {'number': 3, 'created': '2013-07-16 15:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ea22cec88c6eea7337dabe3f07d02cef8b1f1c1b', 'message': 'REST API returns traceback fix\nFixes: bug #1200245\n\nChange-Id: Ie23e1d6910892c55f729153cf5a3b238a4d3c605\n'}, {'number': 4, 'created': '2013-07-16 15:28:49.000000000', 'files': ['savanna/middleware/auth_valid.py', 'savanna/openstack/commons.py', 'AUTHORS'], 'web_link': 'https://opendev.org/openstack/sahara/commit/c23227411b98ab561a9d80b568ce932f073b0d46', 'message': 'REST API returns traceback fix\n\nFixes: bug #1200245\n\nChange-Id: Ie23e1d6910892c55f729153cf5a3b238a4d3c605\n'}]",6,37249,c23227411b98ab561a9d80b568ce932f073b0d46,24,6,4,7700,,,0,"REST API returns traceback fix

Fixes: bug #1200245

Change-Id: Ie23e1d6910892c55f729153cf5a3b238a4d3c605
",git fetch https://review.opendev.org/openstack/sahara refs/changes/49/37249/3 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/middleware/auth_valid.py', 'savanna/openstack/commons.py']",2,38ff05cc4b0878aa17362d473c46a4652a757c26,bug/1200245," return None, None, None", raise ValueError('Invalid path: %s' % path),2,3
openstack%2Fsahara~master~I195bc845133d3bffb58181926abd04c7987bdf02,openstack/sahara,master,I195bc845133d3bffb58181926abd04c7987bdf02,Added config tests,MERGED,2013-07-09 14:38:49.000000000,2013-07-17 12:19:41.000000000,2013-07-17 12:19:41.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7126}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7428}]","[{'number': 1, 'created': '2013-07-09 14:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/25b61b2023853de5e5d5043e3975a3be43b2af78', 'message': 'Added config tests\n\nAdded tests for hadoop config and tests for crud cluster with cluster templates\nRewrited hadoop test\n\nChange-Id: I195bc845133d3bffb58181926abd04c7987bdf02\n'}, {'number': 2, 'created': '2013-07-09 16:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/01464e7fbc78384f5838c62e5163016b04bb0380', 'message': 'Added config tests\n\nAdded tests for hadoop config and tests for crud cluster with cluster templates\nRewrited hadoop test\n\nChange-Id: I195bc845133d3bffb58181926abd04c7987bdf02\n'}, {'number': 3, 'created': '2013-07-12 11:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/fcb20d11c9e1e6b01b87170acd2ca983d8f74b69', 'message': 'Added config tests\n\nAdded tests for hadoop config and tests for crud cluster with cluster templates\nRewrited hadoop test\n\nChange-Id: I195bc845133d3bffb58181926abd04c7987bdf02\n'}, {'number': 4, 'created': '2013-07-12 13:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7a03f570f79aa9ee18dcf825ecc9a6d78bdcf380', 'message': 'Added config tests\n\nAdded tests for hadoop config and tests for crud cluster with cluster templates\nRewrited hadoop test\n\nChange-Id: I195bc845133d3bffb58181926abd04c7987bdf02\n'}, {'number': 5, 'created': '2013-07-16 11:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/dc1ef062c4719d3434faed8b946d00895df757cf', 'message': 'Added config tests\n\nAdded tests for hadoop config and tests for crud cluster with cluster templates\nRewrited hadoop test\n\nPartially implements blueprint itest-savanna-0-2\n\nChange-Id: I195bc845133d3bffb58181926abd04c7987bdf02\n'}, {'number': 6, 'created': '2013-07-16 13:31:59.000000000', 'files': ['savanna/tests/integration/test_config/config_test_script.sh', '.gitignore', 'savanna/tests/integration/configs/parameters.py', 'savanna/tests/integration/test_config/__init__.py', 'savanna/tests/integration/crud_tests/test_crud_cluster_cluster_templates.py', 'savanna/tests/integration/hadoop_test/hadoop_test_script.sh', 'savanna/tests/integration/base.py', 'savanna/tests/integration/test_config/test_cluster_config.py', 'savanna/tests/integration/hadoop_test/test_hadoop.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/f0545ccb6ca9d47bbd65f5d4396c7eb7538cd496', 'message': 'Added config tests\n\nAdded tests for hadoop config and tests for crud cluster with cluster templates\nRewrited hadoop test\n\nPartially implements blueprint itest-savanna-0-2\n\nChange-Id: I195bc845133d3bffb58181926abd04c7987bdf02\n'}]",7,36227,f0545ccb6ca9d47bbd65f5d4396c7eb7538cd496,55,8,6,7126,,,0,"Added config tests

Added tests for hadoop config and tests for crud cluster with cluster templates
Rewrited hadoop test

Partially implements blueprint itest-savanna-0-2

Change-Id: I195bc845133d3bffb58181926abd04c7987bdf02
",git fetch https://review.opendev.org/openstack/sahara refs/changes/27/36227/4 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/tests/integration/test_config/config_test_script.sh', '.gitignore', 'savanna/tests/integration/configs/parameters.py', 'savanna/tests/integration/crud_tests/test_crud_cluster_cluster_templates.py', 'savanna/tests/integration/test_config/__init__.py', 'savanna/tests/integration/hadoop_test/hadoop_test_script.sh', 'savanna/tests/integration/base.py', 'savanna/tests/integration/test_config/test_cluster_config.py', 'savanna/tests/integration/hadoop_test/test_hadoop.py']",9,25b61b2023853de5e5d5043e3975a3be43b2af78,bp/itest-savanna-0-2," cluster_id = self.create_cluster_and_get_id(clstr_body) ip_instances = self.get_instances_ip_and_node_processes_list( cluster_id) clstr_info = self.get_namenode_ip_and_tt_dn_count(ip_instances) namenode_ip = clstr_info['namenode_ip'] node_count = clstr_info['node_count'] self.await_active_workers_for_namenode(clstr_info) except Exception as e: self.fail(str(e)) self.transfer_script_to_node(key) try: self.execute_command( print(self.read_file_from(namenode_ip, '/tmp/outputTestMapReduce/log.txt')) job_name = self.execute_command( self.execute_command( self.execute_command( print(self.read_file_from(namenode_ip, '/tmp/outputTestMapReduce/log.txt'))","import contextlib import osfrom savanna.utils import remote def ssh_connection(host): return remote.setup_ssh_connection(host, param.NODE_USERNAME, open(param.PATH_TO_SSH).read()) def execute_command(host, cmd): with contextlib.closing(ssh_connection(host)) as ssh: return remote.execute_command(ssh, cmd) def write_file_to(host, remote_file, data): with contextlib.closing(ssh_connection(host)) as ssh: return remote.write_file_to(ssh.open_sftp(), remote_file, data) def read_file_from(host, remote_file): with contextlib.closing(ssh_connection(host)) as ssh: return remote.read_file_from(ssh.open_sftp(), remote_file) def _transfer_script_to_node(host, directory): write_file_to(str(host), 'script.sh', open('%s/integration/hadoop_test/hadoop_test_script.sh' % directory).read()) execute_command(str(host), 'chmod 777 script.sh') data = self.post_object(self.url_cluster, clstr_body, 202) data = data['cluster'] cluster_id = data.pop('id') get_data = self.get_object( self.url_cluster_with_slash, cluster_id, 200, True) get_data = get_data['cluster'] node_groups = get_data['node_groups'] ip_instances = {} for node_group in node_groups: instances = node_group['instances'] for instans in instances: management_ip = instans['management_ip'] ip_instances['%s' % management_ip] = node_group[ 'node_processes'] tasktracker_count = 0 datanode_count = 0 for key, value in ip_instances.items(): telnetlib.Telnet(key, '22') if 'namenode' in value: namenode_ip = key telnetlib.Telnet(key, '50070') if 'tasktracker' in value: tasktracker_count += 1 telnetlib.Telnet(key, '50060') if 'datanode' in value: datanode_count += 1 telnetlib.Telnet(key, '50075') if 'jobtracker' in value: telnetlib.Telnet(key, '50030') node_count += 1 except Exception as e: self.fail('telnet instances has failure: ' + str(e)) this_dir = os.getcwd() _transfer_script_to_node(key, this_dir) self.assertEqual(int(execute_command( namenode_ip, './script.sh lt -hd %s' % param.HADOOP_DIRECTORY)[1]), tasktracker_count, msg='compare number active trackers is failure: ') self.assertEqual(int(execute_command( namenode_ip, './script.sh ld -hd %s' % param.HADOOP_DIRECTORY)[1]), datanode_count, msg='compare number active datanodes is failure:') try: execute_command( print(read_file_from(namenode_ip, '/tmp/outputTestMapReduce/log.txt')) job_name = execute_command( execute_command( execute_command( print(read_file_from(namenode_ip, '/tmp/outputTestMapReduce/log.txt'))",521,124
openstack%2Fneutron~master~Ic9ec1f705a94a2e246d1a4985e72e9c58d48191d,openstack/neutron,master,Ic9ec1f705a94a2e246d1a4985e72e9c58d48191d,Improve lbaas haproxy plugin_driver test coverage,MERGED,2013-07-06 16:06:39.000000000,2013-07-17 12:16:02.000000000,2013-07-17 12:16:01.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1374eec13b047f20cd2723d408d7409e975a9721', 'message': 'Improve lbaas haproxy plugin_driver test coverage\n\n - also removes unnecessary delete_health_monitor() from haproxy plugin_driver\n\nFixes bug 1191007\n\nChange-Id: Ic9ec1f705a94a2e246d1a4985e72e9c58d48191d\n'}, {'number': 2, 'created': '2013-07-08 12:20:13.000000000', 'files': ['neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_plugin_driver.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8417fe12e6adfd82bcc8e9721fa19c500e4e51ef', 'message': 'Improve lbaas haproxy plugin_driver test coverage\n\n - also removes unnecessary delete_health_monitor() from haproxy plugin_driver\n\nFixes bug 1191007\n\nChange-Id: Ic9ec1f705a94a2e246d1a4985e72e9c58d48191d\n'}]",0,35146,8417fe12e6adfd82bcc8e9721fa19c500e4e51ef,9,4,2,5948,,,0,"Improve lbaas haproxy plugin_driver test coverage

 - also removes unnecessary delete_health_monitor() from haproxy plugin_driver

Fixes bug 1191007

Change-Id: Ic9ec1f705a94a2e246d1a4985e72e9c58d48191d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/35146/1 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/tests/unit/services/loadbalancer/drivers/haproxy/test_plugin_driver.py', 'quantum/services/loadbalancer/drivers/haproxy/plugin_driver.py']",2,1374eec13b047f20cd2723d408d7409e975a9721,bug/1191007,," def delete_health_monitor(self, context, healthmon_id, pool_id): # healthmon_id is not used in this driver self.agent_rpc.modify_pool(context, pool_id) ",116,6
openstack%2Fdesignate~master~I1b6d843eba5bc9f3a793f28392d0b675333cc17a,openstack/designate,master,I1b6d843eba5bc9f3a793f28392d0b675333cc17a,bug# 1198890 internal api tidy,MERGED,2013-07-12 14:53:50.000000000,2013-07-17 11:47:33.000000000,2013-07-17 11:47:33.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 6494}, {'_account_id': 8094}]","[{'number': 1, 'created': '2013-07-12 14:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c9b65175dc27fbf9839650af9038d20a3031e005', 'message': 'bug# 1198890\ninternal api tidy\n\nChange-Id: I1b6d843eba5bc9f3a793f28392d0b675333cc17a\n'}, {'number': 2, 'created': '2013-07-12 16:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/fc8c389c9f78423593b3ab59ccbdbb6672daee83', 'message': 'bug# 1198890\ninternal api tidy\n\nChange-Id: I1b6d843eba5bc9f3a793f28392d0b675333cc17a\n'}, {'number': 3, 'created': '2013-07-12 16:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/0ecb5a9c3d714f469641cc0c3170e731cd1cf094', 'message': 'bug# 1198890\ninternal api tidy\n\nChange-Id: I1b6d843eba5bc9f3a793f28392d0b675333cc17a\n'}, {'number': 4, 'created': '2013-07-15 16:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e5efedb340ed929421b1f437272c787368a845e8', 'message': 'bug# 1198890\ninternal api tidy\n\nChange-Id: I1b6d843eba5bc9f3a793f28392d0b675333cc17a\n'}, {'number': 5, 'created': '2013-07-16 10:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/07d9b67b0c245d3a477c281787fd3f284cc51f13', 'message': 'bug# 1198890\ninternal api tidy\n\nChange-Id: I1b6d843eba5bc9f3a793f28392d0b675333cc17a\n'}, {'number': 6, 'created': '2013-07-17 11:25:40.000000000', 'files': ['designate/tests/test_storage/__init__.py', 'designate/backend/impl_powerdns/__init__.py', 'designate/backend/impl_bind9.py', 'designate/tests/test_api/test_v1/test_servers.py', 'designate/tests/test_central/test_service.py', 'designate/api/v1/records.py', 'designate/backend/impl_dnsmasq.py', 'designate/storage/api.py', 'designate/tests/test_storage/test_api.py', 'designate/central/rpcapi.py', 'designate/notification_handler/base.py', 'designate/backend/impl_mysqlbind9.py', 'designate/storage/impl_sqlalchemy/__init__.py', 'designate/api/v1/tsigkeys.py', 'designate/tests/test_api/test_v1/test_domains.py', 'designate/tests/test_api/test_v1/test_records.py', 'etc/designate/policy.json', 'designate/central/service.py', 'designate/api/v1/extensions/reports.py', 'designate/api/v1/domains.py', 'designate/tests/test_notification_handler/test_nova.py', 'designate/storage/base.py', 'designate/tests/test_notification_handler/test_quantum.py', 'designate/api/v1/servers.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/496461b18adbe87c6e554ff61a75ec0c19c42232', 'message': 'bug# 1198890\ninternal api tidy\n\nChange-Id: I1b6d843eba5bc9f3a793f28392d0b675333cc17a\n'}]",11,36842,496461b18adbe87c6e554ff61a75ec0c19c42232,20,4,6,6494,,,0,"bug# 1198890
internal api tidy

Change-Id: I1b6d843eba5bc9f3a793f28392d0b675333cc17a
",git fetch https://review.opendev.org/openstack/designate refs/changes/42/36842/3 && git format-patch -1 --stdout FETCH_HEAD,"['designate/tests/test_storage/__init__.py', 'designate/central/service.py', 'designate/api/v1/extensions/reports.py', 'designate/api/v1/domains.py', 'designate/backend/impl_powerdns/__init__.py', 'designate/backend/impl_bind9.py', 'designate/tests/test_api/test_v1/test_servers.py', 'designate/storage/base.py', 'designate/tests/test_central/test_service.py', 'designate/backend/impl_dnsmasq.py', 'designate/storage/api.py', 'designate/tests/test_storage/test_api.py', 'designate/central/rpcapi.py', 'designate/backend/impl_mysqlbind9.py', 'designate/storage/impl_sqlalchemy/__init__.py', 'designate/api/v1/servers.py', 'designate/api/v1/tsigkeys.py', 'designate/tests/test_api/test_v1/test_domains.py']",18,c9b65175dc27fbf9839650af9038d20a3031e005,bug/1198890," @patch.object(central_service.Service, 'find_domains',"," @patch.object(central_service.Service, 'get_domains',",140,238
openstack%2Fceilometer~master~I41c9be9e1c760db1155711325434a1877e6dd7b2,openstack/ceilometer,master,I41c9be9e1c760db1155711325434a1877e6dd7b2,publisher.rpc: queing policies,MERGED,2013-07-04 07:55:37.000000000,2013-07-17 11:43:39.000000000,2013-07-17 11:43:39.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}]","[{'number': 1, 'created': '2013-07-04 07:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0c8c3ad8276f14c6adbc0e137127aac9b9b0ff74', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- block: wait until it comes back\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nThe default is block\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918\n""}, {'number': 2, 'created': '2013-07-04 08:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c0c34255221f850bb458961fa970a274ba77ea3e', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- block: wait until it comes back\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nThe default is block\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918\n""}, {'number': 3, 'created': '2013-07-04 08:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/56b859ee95818134891bdf6c17ae8f7e7f28c315', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- block: wait until it comes back\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nThe default is block\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918 bug#1189488\n""}, {'number': 4, 'created': '2013-07-04 08:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/57829b7aa75e132405c2d4c868cc3ab0501275cb', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- wait: wait until it comes back\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nThe default is wait\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918 bug#1189488\n""}, {'number': 5, 'created': '2013-07-04 13:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f992029a9ed188cf97db4f802e16899b55c94e2b', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- wait: wait until it comes back\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nThe default is wait\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918 bug#1189488\n""}, {'number': 6, 'created': '2013-07-05 08:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/44ff366c906e4a60d9b0568d813909711ef83e2b', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- default: wait until it comes back if rabbit_max_retries <= 0\n           raise a exception if rabbit_max_retries > 0\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918 bug#1189488\n""}, {'number': 7, 'created': '2013-07-05 08:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6b8479eba920e6b260309a068194a199454e3268', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- default: wait until it comes back if rabbit_max_retries <= 0\n           raise a exception if rabbit_max_retries > 0\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918 bug#1189488\n""}, {'number': 8, 'created': '2013-07-12 09:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2f2ad824cbbe54768ab547631624e250e10f4668', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- default: wait until it comes back if rabbit_max_retries <= 0\n           raise a exception if rabbit_max_retries > 0\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918 bug#1189488\n""}, {'number': 9, 'created': '2013-07-13 06:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6c86a810555f943111224bdc731fb57f80cecfa3', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- default: wait until it comes back if rabbit_max_retries <= 0\n           raise a exception if rabbit_max_retries > 0\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918 bug#1189488\n""}, {'number': 10, 'created': '2013-07-15 09:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d7c81601e309fc7457d18c38466de85d0639b834', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- default: wait until it comes back if rabbit_max_retries <= 0\n           raise a exception if rabbit_max_retries > 0\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918 bug#1189488\n""}, {'number': 11, 'created': '2013-07-17 10:12:20.000000000', 'files': ['tests/publisher/test_rpc_publisher.py', 'ceilometer/publisher/rpc.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3f044dd1ace2da3dba65fdb9017b878ce902a554', 'message': ""publisher.rpc: queing policies\n\nThis change allow to configure the behavior of rpc publisher\nwhen rabbitmq is down.\n\n3 policies are available:\n- default: wait until it comes back if rabbit_max_retries <= 0\n           raise a exception if rabbit_max_retries > 0\n- drop: don't publish the samples\n- queue: create a local queue of 'max_queue_length' samples\n\nConfiguration of the policy is done via the publisher url\nexample: rpc://?policy=queue&max_queue_length=100\n\nChange-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2\nFixes: bug#1192918 bug#1189488\n""}]",30,35604,3f044dd1ace2da3dba65fdb9017b878ce902a554,49,5,11,2813,,,0,"publisher.rpc: queing policies

This change allow to configure the behavior of rpc publisher
when rabbitmq is down.

3 policies are available:
- default: wait until it comes back if rabbit_max_retries <= 0
           raise a exception if rabbit_max_retries > 0
- drop: don't publish the samples
- queue: create a local queue of 'max_queue_length' samples

Configuration of the policy is done via the publisher url
example: rpc://?policy=queue&max_queue_length=100

Change-Id: I41c9be9e1c760db1155711325434a1877e6dd7b2
Fixes: bug#1192918 bug#1189488
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/04/35604/7 && git format-patch -1 --stdout FETCH_HEAD,"['tests/publisher/test_rpc_publisher.py', 'ceilometer/publisher/rpc.py']",2,0c8c3ad8276f14c6adbc0e137127aac9b9b0ff74,bug/1192918," self.msg_queue = [] self.policy = self.options.get('policy', ['wait'])[-1] if self.policy in ['queue', 'drop']: LOG.info('Publishing policy set to %s, \ override rabbit_max_retries to 1' % self.policy) cfg.CONF.set_override(""rabbit_max_retries"", 1) self.msg_queue.append((context, topic, msg)) self.msg_queue.append((context, topic_name, msg)) self.flush() def flush(self): while self.msg_queue: #note(sileht): Ugly, but when rabbitmq is unreachable # and rabbitmq_max_retries is not 0 # oslo.rpc do a sys.exit(1), so we catch it until a correct # behavior is implemented in oslo try: rpc.cast(*self.msg_queue[0]) except SystemExit: if self.policy == 'queue': LOG.warn(""Failed to publish counter, queue it"") queue_length = len(self.msg_queue) max_queue_length = int(self.options.get( 'max_queue_length', [0])[-1]) if queue_length > max_queue_length > 0: count = queue_length - max_queue_length self.msg_queue = self.msg_queue[count:] return elif self.policy == 'drop': self.msg_queue = [] LOG.warn( ""Failed to publish counter, dropping it"") return else: self.msg_queue = [] raise else: self.msg_queue.pop(0) "," rpc.cast(context, topic, msg) rpc.cast(context, topic_name, msg)",106,3
openstack%2Fdiskimage-builder~master~I0fec1bb938b2c91d22027f47b677f003a96f5715,openstack/diskimage-builder,master,I0fec1bb938b2c91d22027f47b677f003a96f5715,Add support to allow tilde's in REPOPATH,ABANDONED,2013-07-17 11:19:51.000000000,2013-07-17 11:19:51.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-17 11:19:51.000000000', 'files': ['elements/source-repositories/extra-data.d/99-getsources'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/e51dd8b4cbb6ec5e5176e409ef0c2518111a5727', 'message': ""Add support to allow tilde's in REPOPATH\n\nUp to now only paths begining in a ~ were supported as\nrepository destinations, this adds support to specify\na home directory.\n\nChange-Id: I0fec1bb938b2c91d22027f47b677f003a96f5715\n""}]",1,37445,e51dd8b4cbb6ec5e5176e409ef0c2518111a5727,3,2,1,1926,,,0,"Add support to allow tilde's in REPOPATH

Up to now only paths begining in a ~ were supported as
repository destinations, this adds support to specify
a home directory.

Change-Id: I0fec1bb938b2c91d22027f47b677f003a96f5715
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/45/37445/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/source-repositories/extra-data.d/99-getsources'],1,e51dd8b4cbb6ec5e5176e409ef0c2518111a5727,support-tilde," local REGEX=""^([^ ]+) (git|tar) ([/~][^ ]+) ([^ ]+) ?([^ ]*)$"" # Expand tilde's in REPOPATH eval REPOPATH=$REPOPATH "," local REGEX=""^([^ ]+) (git|tar) (/[^ ]+) ([^ ]+) ?([^ ]*)$""",5,1
openstack%2Fmurano-dashboard~master~I83f8ade5599a9e70081cf3982ff469cec5c24df0,openstack/murano-dashboard,master,I83f8ade5599a9e70081cf3982ff469cec5c24df0,Change last commit due to firefox behavior,MERGED,2013-07-17 10:49:11.000000000,2013-07-17 11:15:09.000000000,2013-07-17 11:15:09.000000000,"[{'_account_id': 3}, {'_account_id': 7549}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-07-17 10:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/651ada9aa6a9641a0ad3a65561f5e52e5be0ca28', 'message': 'Change last commit due to firefox behavior\n\nChange-Id: I83f8ade5599a9e70081cf3982ff469cec5c24df0\n'}, {'number': 2, 'created': '2013-07-17 10:54:24.000000000', 'files': ['muranodashboard/panel/views.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/0aa04a505436fc76a133e4bc0fb3854126fa5730', 'message': 'Change last commit due to firefox behavior\n\nChange-Id: I83f8ade5599a9e70081cf3982ff469cec5c24df0\n'}]",0,37446,0aa04a505436fc76a133e4bc0fb3854126fa5730,7,3,2,7549,,,0,"Change last commit due to firefox behavior

Change-Id: I83f8ade5599a9e70081cf3982ff469cec5c24df0
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/46/37446/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/views.py'],1,651ada9aa6a9641a0ad3a65561f5e52e5be0ca28,," exceptions.handle(self.request, escalate=True)", exceptions.handle(self.request),1,1
openstack%2Ftripleo-image-elements~master~Iec75370c21796b28c735be41022bd53fa36992a6,openstack/tripleo-image-elements,master,Iec75370c21796b28c735be41022bd53fa36992a6,Use source-repository interface in bootstack element,ABANDONED,2013-07-17 11:10:13.000000000,2013-07-17 11:10:13.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-17 11:10:13.000000000', 'files': ['elements/boot-stack/install.d/01-boot-stack', 'elements/boot-stack/element-deps', 'elements/boot-stack/source-repository-diskimage-builder'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/594a4adc5476371a64b78d15d96321de5794674f', 'message': 'Use source-repository interface in bootstack element\n\nChange-Id: Iec75370c21796b28c735be41022bd53fa36992a6\n'}]",0,36055,594a4adc5476371a64b78d15d96321de5794674f,2,1,1,1926,,,0,"Use source-repository interface in bootstack element

Change-Id: Iec75370c21796b28c735be41022bd53fa36992a6
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/55/36055/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/boot-stack/install.d/01-boot-stack', 'elements/boot-stack/element-deps', 'elements/boot-stack/source-repository-diskimage-builder']",3,594a4adc5476371a64b78d15d96321de5794674f,source-repository,# image toolchain diskimage-builder git /opt/stack/diskimage-builder https://github.com/stackforge/diskimage-builder.git ,,3,3
openstack%2Fcinder~master~I436592f958a6c14cd2a0b5d7e53362dd1a7c1a48,openstack/cinder,master,I436592f958a6c14cd2a0b5d7e53362dd1a7c1a48,Add Brick Fibre Channel attach/detach support.,MERGED,2013-07-10 22:56:30.000000000,2013-07-17 11:10:01.000000000,2013-07-17 03:52:25.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6549}]","[{'number': 1, 'created': '2013-07-10 22:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2e1196f9c810e828c6aeaa955ed2926fcecef1d', 'message': ""Add Brick Fibre Channel attach/detach support.\n\nThis patch adds the required code to do\nFibre Channel attach and detaches of volumes.\nThis code has been pulled over from Nova's\nimplementation of FC attach/detach.\n\nAlso adds a new driver config entry to enable\nmultipath support for iSCSI and FC attaches\nduring volume to image and image\nto volume transfers.\n\nblueprint cinder-refactor-attach\n\nChange-Id: I436592f958a6c14cd2a0b5d7e53362dd1a7c1a48\n""}, {'number': 2, 'created': '2013-07-11 22:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/620bc4d31e3db98396591fcb162b460d1958da56', 'message': ""Add Brick Fibre Channel attach/detach support.\n\nThis patch adds the required code to do\nFibre Channel attach and detaches of volumes.\nThis code has been pulled over from Nova's\nimplementation of FC attach/detach.\n\nAlso adds a new driver config entry to enable\nmultipath support for iSCSI and FC attaches\nduring volume to image and image\nto volume transfers.\n\nDocImpact\n\nblueprint cinder-refactor-attach\n\nChange-Id: I436592f958a6c14cd2a0b5d7e53362dd1a7c1a48\n""}, {'number': 3, 'created': '2013-07-15 16:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f4829c14f91dbfca73c643bfd8c77dc78f5c174b', 'message': ""Add Brick Fibre Channel attach/detach support.\n\nThis patch adds the required code to do\nFibre Channel attach and detaches of volumes.\nThis code has been pulled over from Nova's\nimplementation of FC attach/detach.\n\nAlso adds a new driver config entry to enable\nmultipath support for iSCSI and FC attaches\nduring volume to image and image\nto volume transfers.\n\nDocImpact\n\nblueprint cinder-refactor-attach\n\nChange-Id: I436592f958a6c14cd2a0b5d7e53362dd1a7c1a48\n""}, {'number': 4, 'created': '2013-07-16 15:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/77804a77bf8b8ad43e1221fb1002606e7bccf9ea', 'message': ""Add Brick Fibre Channel attach/detach support.\n\nThis patch adds the required code to do\nFibre Channel attach and detaches of volumes.\nThis code has been pulled over from Nova's\nimplementation of FC attach/detach.\n\nAlso adds a new driver config entry to enable\nmultipath support for iSCSI and FC attaches\nduring volume to image and image\nto volume transfers.\n\nDocImpact\n\nblueprint cinder-refactor-attach\n\nChange-Id: I436592f958a6c14cd2a0b5d7e53362dd1a7c1a48\n""}, {'number': 5, 'created': '2013-07-17 01:03:12.000000000', 'files': ['cinder/tests/brick/test_brick_linuxfc.py', 'cinder/tests/brick/test_brick_connector.py', 'etc/cinder/rootwrap.d/volume.filters', 'etc/cinder/cinder.conf.sample', 'cinder/brick/initiator/linuxfc.py', 'cinder/volume/driver.py', 'cinder/brick/initiator/connector.py', 'cinder/brick/initiator/linuxscsi.py', 'cinder/tests/brick/test_brick_linuxscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cb6faab4d99801e76195802659013a5ccdc6b5b5', 'message': ""Add Brick Fibre Channel attach/detach support.\n\nThis patch adds the required code to do\nFibre Channel attach and detaches of volumes.\nThis code has been pulled over from Nova's\nimplementation of FC attach/detach.\n\nAlso adds a new driver config entry to enable\nmultipath support for iSCSI and FC attaches\nduring volume to image and image\nto volume transfers.\n\nDocImpact\n\nblueprint cinder-refactor-attach\n\nChange-Id: I436592f958a6c14cd2a0b5d7e53362dd1a7c1a48\n""}]",14,36577,cb6faab4d99801e76195802659013a5ccdc6b5b5,28,6,5,5997,,,0,"Add Brick Fibre Channel attach/detach support.

This patch adds the required code to do
Fibre Channel attach and detaches of volumes.
This code has been pulled over from Nova's
implementation of FC attach/detach.

Also adds a new driver config entry to enable
multipath support for iSCSI and FC attaches
during volume to image and image
to volume transfers.

DocImpact

blueprint cinder-refactor-attach

Change-Id: I436592f958a6c14cd2a0b5d7e53362dd1a7c1a48
",git fetch https://review.opendev.org/openstack/cinder refs/changes/77/36577/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/brick/test_brick_linuxfc.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/brick/initiator/linuxfc.py', 'cinder/volume/driver.py', 'etc/cinder/cinder.conf.sample', 'cinder/brick/initiator/connector.py', 'cinder/brick/initiator/linuxscsi.py', 'cinder/tests/brick/test_brick_linuxscsi.py']",8,a2e1196f9c810e828c6aeaa955ed2926fcecef1d,bp/cinder-refactor-attach,"# (c) Copyright 2013 Hewlett-Packard Development Company, L.P. def test_echo_scsi_command(self): self.linuxscsi.echo_scsi_command(""/some/path"", ""1"") expected_commands = ['tee -a /some/path'] self.assertEquals(expected_commands, self.cmds) ","# Copyright 2011 Red Hat, Inc.from cinder.brick.initiator import connector from cinder.brick.initiator import host_driverclass ConnectorTestCase(test.TestCase): def setUp(self): super(ConnectorTestCase, self).setUp() self.cmds = [] self.stubs.Set(os.path, 'exists', lambda x: True) def fake_init(obj): return def fake_execute(self, *cmd, **kwargs): self.cmds.append(string.join(cmd)) return """", None def test_connect_volume(self): self.connector = connector.InitiatorConnector() self.assertRaises(NotImplementedError, self.connector.connect_volume, None) def test_disconnect_volume(self): self.connector = connector.InitiatorConnector() self.assertRaises(NotImplementedError, self.connector.connect_volume, None) class HostDriverTestCase(test.TestCase): def setUp(self): super(HostDriverTestCase, self).setUp() self.devlist = ['device1', 'device2'] self.stubs.Set(os, 'listdir', lambda x: self.devlist) def test_host_driver(self): expected = ['/dev/disk/by-path/' + dev for dev in self.devlist] driver = host_driver.HostDriver() actual = driver.get_all_block_devices() self.assertEquals(expected, actual) class ISCSIConnectorTestCase(ConnectorTestCase): def setUp(self): super(ISCSIConnectorTestCase, self).setUp() self.connector = connector.ISCSIConnector(execute=self.fake_execute) self.stubs.Set(self.connector._linuxscsi, 'get_name_from_path', lambda x: ""/dev/sdb"") def tearDown(self): super(ISCSIConnectorTestCase, self).tearDown() def iscsi_connection(self, volume, location, iqn): return { 'driver_volume_type': 'iscsi', 'data': { 'volume_id': volume['id'], 'target_portal': location, 'target_iqn': iqn, 'target_lun': 1, } } @test.testtools.skipUnless(os.path.exists('/dev/disk/by-path'), 'Test requires /dev/disk/by-path') def test_connect_volume(self): self.stubs.Set(os.path, 'exists', lambda x: True) location = '10.0.2.15:3260' name = 'volume-00000001' iqn = 'iqn.2010-10.org.openstack:%s' % name vol = {'id': 1, 'name': name} connection_info = self.iscsi_connection(vol, location, iqn) conf = self.connector.connect_volume(connection_info['data']) dev_str = '/dev/disk/by-path/ip-%s-iscsi-%s-lun-1' % (location, iqn) self.assertEquals(conf['type'], 'block') self.assertEquals(conf['path'], dev_str) self.connector.disconnect_volume(connection_info['data']) expected_commands = [('iscsiadm -m node -T %s -p %s' % (iqn, location)), ('iscsiadm -m session'), ('iscsiadm -m node -T %s -p %s --login' % (iqn, location)), ('iscsiadm -m node -T %s -p %s --op update' ' -n node.startup -v automatic' % (iqn, location)), ('tee -a /sys/block/sdb/device/delete'), ('iscsiadm -m node -T %s -p %s --op update' ' -n node.startup -v manual' % (iqn, location)), ('iscsiadm -m node -T %s -p %s --logout' % (iqn, location)), ('iscsiadm -m node -T %s -p %s --op delete' % (iqn, location)), ] LOG.debug(""self.cmds = %s"" % self.cmds) LOG.debug(""expected = %s"" % expected_commands) self.assertEqual(expected_commands, self.cmds)",720,108
openstack%2Ftempest~master~Ib1d489eb363cedaf3329b03f5c423dfd59b445f8,openstack/tempest,master,Ib1d489eb363cedaf3329b03f5c423dfd59b445f8,Add option to execute stress test in random order,ABANDONED,2013-07-17 08:48:31.000000000,2013-07-17 11:03:52.000000000,,"[{'_account_id': 3}, {'_account_id': 5803}, {'_account_id': 5997}]","[{'number': 1, 'created': '2013-07-17 08:48:31.000000000', 'files': ['tempest/stress/run_stress.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ffb2f04ebdbf890a2c3cf39927ecc110c4568574', 'message': 'Add option to execute stress test in random order\n\nA new option ""-r/--random"" introduced to execute json files in a\nrandom order.\n\nImplements: blueprint stress-tests\nChange-Id: Ib1d489eb363cedaf3329b03f5c423dfd59b445f8\n'}]",0,37424,ffb2f04ebdbf890a2c3cf39927ecc110c4568574,3,3,1,7872,,,0,"Add option to execute stress test in random order

A new option ""-r/--random"" introduced to execute json files in a
random order.

Implements: blueprint stress-tests
Change-Id: Ib1d489eb363cedaf3329b03f5c423dfd59b445f8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/24/37424/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/stress/run_stress.py'],1,ffb2f04ebdbf890a2c3cf39927ecc110c4568574,bp/stress-tests,"import globimport random if ns.random: files = glob.glob(ns.tests + ""/*.json"") random.seed() random.shuffle(files) for file in files: run_file(file, ns) else: run_file(ns.file, ns) def run_file(file, ns): tests = json.load(open(file, 'r'))parser.add_argument('-r', '--random', action='store_true', help=""Executes all json files within the "" + ""given directory in a random order."")"," tests = json.load(open(ns.tests, 'r'))",17,2
openstack%2Fzaqar~master~If136716834d9f0f8f0c51625f874f375d0eee316,openstack/zaqar,master,If136716834d9f0f8f0c51625f874f375d0eee316,Print caught exceptions in cli,MERGED,2013-07-15 19:48:50.000000000,2013-07-17 10:31:49.000000000,2013-07-17 10:31:49.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 7044}, {'_account_id': 7409}]","[{'number': 1, 'created': '2013-07-15 19:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9f55cba8c30fef85923e095c48e40418d5b02d69', 'message': 'Print caught exceptions in cli\n\nShow information about errors caused during\nthe marconi-server call.\n\nChange-Id: If136716834d9f0f8f0c51625f874f375d0eee316\nFix: bug #1201562\n'}, {'number': 2, 'created': '2013-07-15 19:50:16.000000000', 'files': ['marconi/common/cli.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b4f2b47a638910012df4c5a3e30e59980000a11c', 'message': 'Print caught exceptions in cli\n\nShow information about errors caused during\nthe marconi-server call.\n\nChange-Id: If136716834d9f0f8f0c51625f874f375d0eee316\nFix: bug #1201562\n'}]",3,37115,b4f2b47a638910012df4c5a3e30e59980000a11c,11,6,2,6413,,,0,"Print caught exceptions in cli

Show information about errors caused during
the marconi-server call.

Change-Id: If136716834d9f0f8f0c51625f874f375d0eee316
Fix: bug #1201562
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/15/37115/2 && git format-patch -1 --stdout FETCH_HEAD,['marconi/common/cli.py'],1,9f55cba8c30fef85923e095c48e40418d5b02d69,bug/1201562," print >> sys.stderr, ex _fail(1, ex)"," _fail(1, ex)",2,1
openstack%2Fnova~master~Ie07751b2db72c43af23936e2e8c00ee3c861428a,openstack/nova,master,Ie07751b2db72c43af23936e2e8c00ee3c861428a,Fix extensions os-remote-consoles to follow API v3 rules,MERGED,2013-07-12 08:23:59.000000000,2013-07-17 10:12:02.000000000,2013-07-17 10:12:00.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2166}, {'_account_id': 5292}]","[{'number': 1, 'created': '2013-07-12 08:23:59.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/remote_consoles.py', 'nova/tests/api/openstack/compute/plugins/v3/test_remote_consoles.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7a64beb0ee2664b932dc3e811dcf419373287e53', 'message': 'Fix extensions os-remote-consoles to follow API v3 rules\n\n* Add extensions.expected_errors decorator\n* Correct the action naming style\n* Catch exception ConsoleTypeInvalid explicit\n\nPartially implements bp v3-api-extension-versioning\n\nChange-Id: Ie07751b2db72c43af23936e2e8c00ee3c861428a\n'}]",0,36790,7a64beb0ee2664b932dc3e811dcf419373287e53,7,4,1,5754,,,0,"Fix extensions os-remote-consoles to follow API v3 rules

* Add extensions.expected_errors decorator
* Correct the action naming style
* Catch exception ConsoleTypeInvalid explicit

Partially implements bp v3-api-extension-versioning

Change-Id: Ie07751b2db72c43af23936e2e8c00ee3c861428a
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/36790/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/remote_consoles.py', 'nova/tests/api/openstack/compute/plugins/v3/test_remote_consoles.py']",2,7a64beb0ee2664b932dc3e811dcf419373287e53,bp/v3-api-extension-versioning, body = {'get_vnc_console': {'type': 'novnc'}} body = {'get_vnc_console': {'type': 'novnc'}} body = {'get_vnc_console': {}} body = {'get_vnc_console': {'type': 'novnc'}} body = {'get_vnc_console': {'type': 'novnc'}} body = {'get_vnc_console': {'type': 'invalid'}} body = {'get_spice_console': {'type': 'spice-html5'}} body = {'get_spice_console': {'type': 'spice-html5'}} body = {'get_spice_console': {}} body = {'get_spice_console': {'type': 'spice-html5'}} body = {'get_spice_console': {'type': 'spice-html5'}} body = {'get_spice_console': {'type': 'invalid'}}, body = {'os-getVNCConsole': {'type': 'novnc'}} body = {'os-getVNCConsole': {'type': 'novnc'}} body = {'os-getVNCConsole': {}} body = {'os-getVNCConsole': {'type': 'novnc'}} body = {'os-getVNCConsole': {'type': 'novnc'}} body = {'os-getVNCConsole': {'type': 'invalid'}} body = {'os-getSPICEConsole': {'type': 'spice-html5'}} body = {'os-getSPICEConsole': {'type': 'spice-html5'}} body = {'os-getSPICEConsole': {}} body = {'os-getSPICEConsole': {'type': 'spice-html5'}} body = {'os-getSPICEConsole': {'type': 'spice-html5'}} body = {'os-getSPICEConsole': {'type': 'invalid'}},25,20
openstack%2Fheat~master~I490675c18734a61d27625ed3c76fb228e3fd1a9d,openstack/heat,master,I490675c18734a61d27625ed3c76fb228e3fd1a9d,Add a test for customizing AWS::EC2::Instance,MERGED,2013-07-16 19:59:51.000000000,2013-07-17 10:06:37.000000000,2013-07-17 10:06:37.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 6800}]","[{'number': 1, 'created': '2013-07-16 19:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/857cfc00052234092ac3092fa14e6b49d4665eb3', 'message': 'Add a test for customizing AWS::EC2::Instance\n\nInstanceGroup explicitly supports ""custom"" versions of AWS::EC2::Instance\n(instead of directly using heat.engine.resources.instance.Instance)\nbut there was no unit test for that feature. Here we add one.\n\nChange-Id: I490675c18734a61d27625ed3c76fb228e3fd1a9d\n'}, {'number': 2, 'created': '2013-07-16 20:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8375d4266c404185a810fbaff1d3981780452b4b', 'message': 'Add a test for customizing AWS::EC2::Instance\n\nInstanceGroup explicitly supports ""custom"" versions of AWS::EC2::Instance\n(instead of directly using heat.engine.resources.instance.Instance)\nbut there was no unit test for that feature. Here we add one.\n\nChange-Id: I490675c18734a61d27625ed3c76fb228e3fd1a9d\n'}, {'number': 3, 'created': '2013-07-17 01:06:58.000000000', 'files': ['heat/engine/resources/autoscaling.py', 'heat/tests/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/1f1b66cbaeb1bb3d871cb8cb1ebbc3aa0487f2c8', 'message': 'Add a test for customizing AWS::EC2::Instance\n\nInstanceGroup explicitly supports ""custom"" versions of AWS::EC2::Instance\n(instead of directly using heat.engine.resources.instance.Instance)\nbut there was no unit test for that feature. Here we add one.\n\nChange-Id: I490675c18734a61d27625ed3c76fb228e3fd1a9d\n'}]",0,37317,1f1b66cbaeb1bb3d871cb8cb1ebbc3aa0487f2c8,9,4,3,6800,,,0,"Add a test for customizing AWS::EC2::Instance

InstanceGroup explicitly supports ""custom"" versions of AWS::EC2::Instance
(instead of directly using heat.engine.resources.instance.Instance)
but there was no unit test for that feature. Here we add one.

Change-Id: I490675c18734a61d27625ed3c76fb228e3fd1a9d
",git fetch https://review.opendev.org/openstack/heat refs/changes/17/37317/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/autoscaling.py', 'heat/tests/test_instance_group.py']",2,857cfc00052234092ac3092fa14e6b49d4665eb3,test-autoscaling-custom-resources,"from heat.engine import resources def _stub_create(self, num, instance_class=instance.Instance): """""" Expect creation of C{num} number of Instances. :param instance_class: The resource class to expect to be created instead of instance.Instance. """""" self.m.StubOutWithMock(instance_class, 'handle_create') self.m.StubOutWithMock(instance_class, 'check_create_complete') instance_class.handle_create().AndReturn(cookie) instance_class.check_create_complete(cookie).AndReturn(False) instance_class.check_create_complete( def test_instance_group_custom_resource(self): """""" If AWS::EC2::Instance is overridden, InstanceGroup will automatically use that overridden resource type. """""" # resources may need to be initialised if this is the first test run. resources.initialise() class MyInstance(instance.Instance): """"""A customized Instance resource"""""" original_instance = resource.get_class(""AWS::EC2::Instance"") resource._register_class(""AWS::EC2::Instance"", MyInstance) self.addCleanup(resource._register_class, ""AWS::EC2::Instance"", original_instance) t = template_format.parse(ig_template) stack = parse_stack(t) self._stub_create(1, instance_class=MyInstance) self.m.ReplayAll() rsrc = self.create_instance_group(t, stack, 'JobServerGroup') self.assertEqual('JobServerGroup', rsrc.FnGetRefId()) rsrc.delete() self.m.VerifyAll() "," def _stub_create(self, num): self.m.StubOutWithMock(instance.Instance, 'handle_create') self.m.StubOutWithMock(instance.Instance, 'check_create_complete') instance.Instance.handle_create().AndReturn(cookie) instance.Instance.check_create_complete(cookie).AndReturn(False) instance.Instance.check_create_complete(",44,9
openstack%2Fpython-neutronclient~master~Ifac96211c3d728d68cde21a2d1dd3714a9dcc5de,openstack/python-neutronclient,master,Ifac96211c3d728d68cde21a2d1dd3714a9dcc5de,let cliff install the right pyparsing,MERGED,2013-07-06 16:06:52.000000000,2013-07-17 10:06:35.000000000,2013-07-17 10:06:35.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2874}]","[{'number': 2, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/da4aa2d25c43099c5a52d47cd2820771b464fcd3', 'message': 'let cmd2 itself install the right pyparsing\n\nBug #1197083\n\nChange-Id: Ifac96211c3d728d68cde21a2d1dd3714a9dcc5de\n'}, {'number': 1, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/bcd11fab7a247d84df186fa16b246e30f76f806a', 'message': 'let cmd2 itself install the right pyparsing\n\nBug #1197083\n\nChange-Id: Ifac96211c3d728d68cde21a2d1dd3714a9dcc5de\n'}, {'number': 3, 'created': '2013-07-07 15:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/1c68806d7b38cc8bac3316cb8866aa0718c72289', 'message': 'let cliff and cmd2 install the right pyparsing\n\nBug #1197083\n\ncliff(>=1.4) reqires:\nPrettyTable>=0.6,<0.8\ncmd2>=0.6.4\npyparsing==1.5.7\n\ncmd2(>=0.6.4) requires:\npyparsing == 1.5.7\n\nChange-Id: Ifac96211c3d728d68cde21a2d1dd3714a9dcc5de\n'}, {'number': 4, 'created': '2013-07-15 22:28:42.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b25342d97b9bbe681b5f1e9ed1e7ddd179aad5ca', 'message': 'let cliff install the right pyparsing\n\nBug #1197083\n\ncliff(>=1.4) reqires:\nPrettyTable>=0.6,<0.8\ncmd2>=0.6.4\npyparsing==1.5.7\n\nChange-Id: Ifac96211c3d728d68cde21a2d1dd3714a9dcc5de\n'}]",0,35418,b25342d97b9bbe681b5f1e9ed1e7ddd179aad5ca,21,6,4,2874,,,0,"let cliff install the right pyparsing

Bug #1197083

cliff(>=1.4) reqires:
PrettyTable>=0.6,<0.8
cmd2>=0.6.4
pyparsing==1.5.7

Change-Id: Ifac96211c3d728d68cde21a2d1dd3714a9dcc5de
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/18/35418/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,da4aa2d25c43099c5a52d47cd2820771b464fcd3,bug/1197083,,"pyparsing>=1.5.6,<2.0",0,1
openstack%2Ftripleo-image-elements~master~I2d6e71112b5f924087caf29cbab620205fe5234a,openstack/tripleo-image-elements,master,I2d6e71112b5f924087caf29cbab620205fe5234a,Use source-repository interface in heat-cfntools,MERGED,2013-07-17 09:55:18.000000000,2013-07-17 09:55:18.000000000,2013-07-17 09:55:18.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-17 09:55:18.000000000', 'files': ['elements/heat-cfntools/element-deps', 'elements/heat-cfntools/install.d/05-heat-cfntools', 'elements/heat-cfntools/source-repository-heat-cfntools'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1e0e5f36761cb208bb47b866e757e9b1b69b587e', 'message': 'Use source-repository interface in heat-cfntools\n\nChange-Id: I2d6e71112b5f924087caf29cbab620205fe5234a\n'}]",0,36051,1e0e5f36761cb208bb47b866e757e9b1b69b587e,5,2,1,1926,,,0,"Use source-repository interface in heat-cfntools

Change-Id: I2d6e71112b5f924087caf29cbab620205fe5234a
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/51/36051/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/heat-cfntools/element-deps', 'elements/heat-cfntools/install.d/05-heat-cfntools', 'elements/heat-cfntools/source-repository-heat-cfntools']",3,1e0e5f36761cb208bb47b866e757e9b1b69b587e,source-repository,heat-cfntools git /opt/stack/heat-cfntools https://github.com/openstack/heat-cfntools.git ,,2,1
openstack%2Fnova~master~If7878361711f835247aaf64ce26f0058f8c4b5ba,openstack/nova,master,If7878361711f835247aaf64ce26f0058f8c4b5ba,Assert backing_file should exist before attempting to create it,MERGED,2013-07-16 16:58:37.000000000,2013-07-17 09:55:00.000000000,2013-07-17 09:54:57.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 1132}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-16 16:58:37.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/879565efe51f19bd6f4d69d1b430b995f62106c8', 'message': 'Assert backing_file should exist before attempting to create it\n\nFixes bug 1200249\n\nChange-Id: If7878361711f835247aaf64ce26f0058f8c4b5ba\n'}]",1,37290,879565efe51f19bd6f4d69d1b430b995f62106c8,9,6,1,1132,,,0,"Assert backing_file should exist before attempting to create it

Fixes bug 1200249

Change-Id: If7878361711f835247aaf64ce26f0058f8c4b5ba
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/37290/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,879565efe51f19bd6f4d69d1b430b995f62106c8,bug/1200249, elif info['backing_file']:, else:,1,1
openstack%2Fnova~master~I32d85ca09849b63b815cc3daba3bb02c31d92e8d,openstack/nova,master,I32d85ca09849b63b815cc3daba3bb02c31d92e8d,xenapi: enable attach volumes to non-running VM,MERGED,2013-07-09 18:19:24.000000000,2013-07-17 09:54:38.000000000,2013-07-17 09:54:36.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 6735}]","[{'number': 1, 'created': '2013-07-09 18:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd3d92a717e850a4d0fff4bf561bef0b50bb054d', 'message': 'xenapi: enable attach volumes to non-running VM\n\nWIP\n\nFixes bug 1199477\n\nChange-Id: I32d85ca09849b63b815cc3daba3bb02c31d92e8d\n'}, {'number': 2, 'created': '2013-07-10 10:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2f512e0ca9329cdbd2c76e9d8f58f96ee3f3b4f', 'message': 'xenapi: enable attach volumes to non-running VM\n\nSimilar to when detaching a volume, ensure we only attempt to\nplug a VBD when the server is running, otherwise it will fail.\nThis also fixes up the existing unit test that was not working.\n\nFixes bug 1199477\nChange-Id: I32d85ca09849b63b815cc3daba3bb02c31d92e8d\n'}, {'number': 3, 'created': '2013-07-10 10:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59f62a876fbb38cd9e6250f7e7da42a9054cd034', 'message': 'xenapi: enable attach volumes to non-running VM\n\nSimilar to when detaching a volume, ensure we only attempt to\nplug a VBD when the server is running, otherwise it will fail.\nThis also fixes up the existing unit test that was not working.\n\nFixes bug 1199477\nChange-Id: I32d85ca09849b63b815cc3daba3bb02c31d92e8d\n'}, {'number': 4, 'created': '2013-07-10 10:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a8eb22a532f4218bfeda1fa02b64c90006d0d83', 'message': 'xenapi: enable attach volumes to non-running VM\n\nSimilar to when detaching a volume, ensure we only attempt to\nplug a VBD when the server is running, otherwise it will fail.\nThis also fixes up the existing unit test that was not working.\n\nFixes bug 1199477\nChange-Id: I32d85ca09849b63b815cc3daba3bb02c31d92e8d\n'}, {'number': 5, 'created': '2013-07-11 16:45:56.000000000', 'files': ['nova/virt/xenapi/volumeops.py', 'nova/tests/virt/xenapi/test_volumeops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7902c6aeabaa61ebee873d192ec9ed3e94ee85f2', 'message': 'xenapi: enable attach volumes to non-running VM\n\nSimilar to when detaching a volume, ensure we only attempt to\nplug a VBD when the server is running, otherwise it will fail.\nThis also fixes up the existing unit test that was not working.\n\nFixes bug 1199477\nChange-Id: I32d85ca09849b63b815cc3daba3bb02c31d92e8d\n'}]",1,36313,7902c6aeabaa61ebee873d192ec9ed3e94ee85f2,17,6,5,782,,,0,"xenapi: enable attach volumes to non-running VM

Similar to when detaching a volume, ensure we only attempt to
plug a VBD when the server is running, otherwise it will fail.
This also fixes up the existing unit test that was not working.

Fixes bug 1199477
Change-Id: I32d85ca09849b63b815cc3daba3bb02c31d92e8d
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/36313/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/xenapi/volumeops.py'],1,cd3d92a717e850a4d0fff4bf561bef0b50bb054d,bug/1199477," running = not vm_utils.is_vm_shutdown(self._session, vm_ref) if hotplug and running: ", if hotplug:,2,1
openstack%2Fnova~master~Iac49c8b5c13d3807e8bb744151300418b121bd5c,openstack/nova,master,Iac49c8b5c13d3807e8bb744151300418b121bd5c,Passing volume ID as id to InvalidBDMVolume exception,MERGED,2013-07-12 11:02:37.000000000,2013-07-17 09:54:11.000000000,2013-07-17 09:54:08.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2711}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-07-12 11:02:37.000000000', 'files': ['nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a5a877df0e7e2003fffaeb2a67affea96fb97cc6', 'message': 'Passing volume ID as id to InvalidBDMVolume exception\n\nPassing volume ID as positional argument causes error\n when formatting exception message.\n\nFixes bug 1200584\n\nChange-Id: Iac49c8b5c13d3807e8bb744151300418b121bd5c\n'}]",0,36812,a5a877df0e7e2003fffaeb2a67affea96fb97cc6,10,7,1,7534,,,0,"Passing volume ID as id to InvalidBDMVolume exception

Passing volume ID as positional argument causes error
 when formatting exception message.

Fixes bug 1200584

Change-Id: Iac49c8b5c13d3807e8bb744151300418b121bd5c
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/36812/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,a5a877df0e7e2003fffaeb2a67affea96fb97cc6,bug/1200584, raise exception.InvalidBDMVolume(id=volume_id), raise exception.InvalidBDMVolume(volume_id),1,1
openstack%2Fmurano~master~I4dea1e4ac7ec81bf4161088fac16c143453aff49,openstack/murano,master,I4dea1e4ac7ec81bf4161088fac16c143453aff49,Fix jsonschema version in pip-requires,MERGED,2013-07-17 08:44:32.000000000,2013-07-17 09:42:14.000000000,2013-07-17 09:42:14.000000000,"[{'_account_id': 3}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-07-17 08:44:32.000000000', 'files': ['tools/pip-requires'], 'web_link': 'https://opendev.org/openstack/murano/commit/18c7a90b10a1267a422b3e819c0afb4aafaa4b9c', 'message': 'Fix jsonschema version in pip-requires\n\nChange-Id: I4dea1e4ac7ec81bf4161088fac16c143453aff49\n'}]",0,37423,18c7a90b10a1267a422b3e819c0afb4aafaa4b9c,5,2,1,7549,,,0,"Fix jsonschema version in pip-requires

Change-Id: I4dea1e4ac7ec81bf4161088fac16c143453aff49
",git fetch https://review.opendev.org/openstack/murano refs/changes/23/37423/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/pip-requires'],1,18c7a90b10a1267a422b3e819c0afb4aafaa4b9c,,jsonschema==2.0.0,jsonschema,1,1
openstack%2Fnova~master~I0b06a223b50f7d90007bb44ec7897174ed836ad4,openstack/nova,master,I0b06a223b50f7d90007bb44ec7897174ed836ad4,Makes _PATH_CELL_SEP a public global variable,MERGED,2013-07-15 02:38:23.000000000,2013-07-17 09:07:03.000000000,2013-07-17 09:07:00.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 2166}, {'_account_id': 2271}]","[{'number': 1, 'created': '2013-07-15 02:38:23.000000000', 'files': ['nova/tests/cells/fakes.py', 'nova/cells/manager.py', 'nova/tests/cells/test_cells_utils.py', 'nova/cells/utils.py', 'nova/cells/messaging.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6ca2f0319607e4a2fc1e869eed449b59f305c26e', 'message': 'Makes _PATH_CELL_SEP a public global variable\n\n_PATH_CELL_SEP is used outside of cells.utils so it should be not be private\n\nChange-Id: I0b06a223b50f7d90007bb44ec7897174ed836ad4\n'}]",0,37009,6ca2f0319607e4a2fc1e869eed449b59f305c26e,7,5,1,1994,,,0,"Makes _PATH_CELL_SEP a public global variable

_PATH_CELL_SEP is used outside of cells.utils so it should be not be private

Change-Id: I0b06a223b50f7d90007bb44ec7897174ed836ad4
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/37009/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/cells/fakes.py', 'nova/cells/manager.py', 'nova/tests/cells/test_cells_utils.py', 'nova/cells/utils.py', 'nova/cells/messaging.py']",5,6ca2f0319607e4a2fc1e869eed449b59f305c26e,path_cell_sep,_PATH_CELL_SEP = cells_utils.PATH_CELL_SEP,_PATH_CELL_SEP = cells_utils._PATH_CELL_SEP,6,6
openstack%2Fneutron~master~I90d2cdbe97daa2ec0a8c8b6c9686b6f76c4de9e4,openstack/neutron,master,I90d2cdbe97daa2ec0a8c8b6c9686b6f76c4de9e4,modernize quantum config in proper place,MERGED,2013-07-13 08:17:59.000000000,2013-07-17 09:06:29.000000000,2013-07-17 09:06:28.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4726}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-13 08:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/62690db82b3ec550b270adff56cb8d664fb4d1e9', 'message': 'modernize quantum config in proper place\n\nBug #1200558\n\nAt the beginning, we have not registered some configuration\nitems. To modernize these items, we must do it after we register\nthem.\n\nChange-Id: I90d2cdbe97daa2ec0a8c8b6c9686b6f76c4de9e4\n'}, {'number': 2, 'created': '2013-07-13 08:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/be988d9db6051b34151821799bd198c074549f0d', 'message': 'modernize quantum config in proper place\n\nBug #1200558\n\nAt the beginning, we have not registered some configuration\nitems. To modernize these items, we must do it after we register\nthem.\n\nChange-Id: I90d2cdbe97daa2ec0a8c8b6c9686b6f76c4de9e4\n'}, {'number': 3, 'created': '2013-07-16 15:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f921135f4b7f9d450500e0f1185c55b54f9f0166', 'message': 'modernize quantum config in proper place\n\nBug #1200558\n\nAt the beginning, we have not registered some configuration\nitems. To modernize these items, we must do it after we register\nthem.\n\nChange-Id: I90d2cdbe97daa2ec0a8c8b6c9686b6f76c4de9e4\n'}, {'number': 4, 'created': '2013-07-16 15:15:46.000000000', 'files': ['neutron/common/legacy.py', 'neutron/quota.py', 'neutron/manager.py', 'neutron/services/loadbalancer/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa3e64f9125e4c41de90213b75b2826bfd663527', 'message': 'modernize quantum config in proper place\n\nBug #1200558\n\nAt the beginning, we have not registered some configuration\nitems. To modernize these items, we must do it after we register\nthem.\n\nChange-Id: I90d2cdbe97daa2ec0a8c8b6c9686b6f76c4de9e4\n'}]",5,36931,aa3e64f9125e4c41de90213b75b2826bfd663527,25,8,4,2874,,,0,"modernize quantum config in proper place

Bug #1200558

At the beginning, we have not registered some configuration
items. To modernize these items, we must do it after we register
them.

Change-Id: I90d2cdbe97daa2ec0a8c8b6c9686b6f76c4de9e4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/31/36931/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/legacy.py', 'neutron/quota.py', 'neutron/agent/securitygroups_rpc.py']",3,62690db82b3ec550b270adff56cb8d664fb4d1e9,bug/1200558,"from neutron.common import legacylegacy.override_config(cfg.CONF, [('SECURITYGROUP', 'firewall_driver')])",,4,2
openstack%2Fneutron~master~I7c0b76afb603f1f078b28610181b16ce66225d37,openstack/neutron,master,I7c0b76afb603f1f078b28610181b16ce66225d37,Improve packet-filter test coverage in NEC Plugin,MERGED,2013-07-16 01:44:27.000000000,2013-07-17 09:06:20.000000000,2013-07-17 09:06:19.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1894}, {'_account_id': 2592}, {'_account_id': 2874}]","[{'number': 1, 'created': '2013-07-16 01:44:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/22a8b55169697dad580b45fb494a1e58d6493ede', 'message': ""Improve packet-filter test coverage in NEC Plugin\n\nblueprint nec-plugin-test-coverage\n\nThis commit adds unit tests for packet-filter in NEC Plugin.\n\nThis commit refactors packet-filter in NEC Plugin.\n- Put packet-filter classes and methods into nec/packet_filter.py (a) and\n  nec/db/packetfilter.py (b), NEC Plugin specific codes are in (a)\n- Change stateless methods to class methods in extenstions/packetfilter.py\n- Add 'convert_to' option to the attribute map of packet-filter to convert\n  some string parameter to int at the api layer\n\nAlso, this commit includes the following changes in packet-filter.\n- Fix attribute map of packet-filter; set in_port to allow_put=False\n- Add new methods to update attribute map properly\n- Make packet-filters ignore status of associated resource (network)\n\nChange-Id: I7c0b76afb603f1f078b28610181b16ce66225d37\n""}, {'number': 2, 'created': '2013-07-17 00:14:50.000000000', 'files': ['neutron/plugins/nec/common/exceptions.py', 'neutron/plugins/nec/db/models.py', 'neutron/plugins/nec/extensions/packetfilter.py', 'neutron/tests/unit/nec/test_packet_filter.py', 'neutron/plugins/nec/packet_filter.py', 'neutron/plugins/nec/nec_plugin.py', 'neutron/plugins/nec/db/packetfilter.py', 'neutron/plugins/nec/db/nec_plugin_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0043044f2e8ee3de8a9995bdbf51aad77f1a3fa9', 'message': ""Improve packet-filter test coverage in NEC Plugin\n\nblueprint nec-plugin-test-coverage\n\nThis commit adds unit tests for packet-filter in NEC Plugin.\n\nThis commit refactors packet-filter in NEC Plugin.\n- Put packet-filter classes and methods into nec/packet_filter.py (a) and\n  nec/db/packetfilter.py (b), NEC Plugin specific codes are in (a)\n- Change stateless methods to class methods in extenstions/packetfilter.py\n- Add 'convert_to' option to the attribute map of packet-filter to convert\n  some string parameter to int at the api layer\n\nAlso, this commit includes the following changes in packet-filter.\n- Fix attribute map of packet-filter; set in_port to allow_put=False\n- Add new methods to update attribute map properly\n- Make packet-filters ignore status of associated resource (network)\n\nChange-Id: I7c0b76afb603f1f078b28610181b16ce66225d37\n""}]",6,37155,0043044f2e8ee3de8a9995bdbf51aad77f1a3fa9,13,5,2,1894,,,0,"Improve packet-filter test coverage in NEC Plugin

blueprint nec-plugin-test-coverage

This commit adds unit tests for packet-filter in NEC Plugin.

This commit refactors packet-filter in NEC Plugin.
- Put packet-filter classes and methods into nec/packet_filter.py (a) and
  nec/db/packetfilter.py (b), NEC Plugin specific codes are in (a)
- Change stateless methods to class methods in extenstions/packetfilter.py
- Add 'convert_to' option to the attribute map of packet-filter to convert
  some string parameter to int at the api layer

Also, this commit includes the following changes in packet-filter.
- Fix attribute map of packet-filter; set in_port to allow_put=False
- Add new methods to update attribute map properly
- Make packet-filters ignore status of associated resource (network)

Change-Id: I7c0b76afb603f1f078b28610181b16ce66225d37
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/37155/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/nec/common/exceptions.py', 'neutron/plugins/nec/db/models.py', 'neutron/plugins/nec/extensions/packetfilter.py', 'neutron/tests/unit/nec/test_packet_filter.py', 'neutron/plugins/nec/packet_filter.py', 'neutron/plugins/nec/db/packetfilter.py', 'neutron/plugins/nec/nec_plugin.py', 'neutron/plugins/nec/db/nec_plugin_base.py']",8,22a8b55169697dad580b45fb494a1e58d6493ede,bp/nec-plugin-test-coverage,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2012 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # @author: Ryota MIBU from sqlalchemy.orm import exc from neutron.api.v2 import attributes from neutron.db import db_base_plugin_v2 from neutron.openstack.common import log as logging from neutron.openstack.common import uuidutils from neutron.plugins.nec.common import exceptions as q_exc from neutron.plugins.nec.db import models as nmodels LOG = logging.getLogger(__name__) class NECPluginV2Base(db_base_plugin_v2.NeutronDbPluginV2): """"""Base class of plugins that handle packet filters."""""" def _make_packet_filter_dict(self, packet_filter, fields=None): res = {'id': packet_filter['id'], 'name': packet_filter['name'], 'tenant_id': packet_filter['tenant_id'], 'network_id': packet_filter['network_id'], 'action': packet_filter['action'], 'priority': packet_filter['priority'], 'in_port': packet_filter['in_port'], 'src_mac': packet_filter['src_mac'], 'dst_mac': packet_filter['dst_mac'], 'eth_type': packet_filter['eth_type'], 'src_cidr': packet_filter['src_cidr'], 'dst_cidr': packet_filter['dst_cidr'], 'protocol': packet_filter['protocol'], 'src_port': packet_filter['src_port'], 'dst_port': packet_filter['dst_port'], 'admin_state_up': packet_filter['admin_state_up'], 'status': packet_filter['status']} return self._fields(res, fields) def _get_packet_filter(self, context, id): try: packet_filter = self._get_by_id(context, nmodels.PacketFilter, id) except exc.NoResultFound: raise q_exc.PacketFilterNotFound(id=id) return packet_filter def get_packet_filter(self, context, id, fields=None): packet_filter = self._get_packet_filter(context, id) return self._make_packet_filter_dict(packet_filter, fields) def get_packet_filters(self, context, filters=None, fields=None): return self._get_collection(context, nmodels.PacketFilter, self._make_packet_filter_dict, filters=filters, fields=fields) def create_packet_filter(self, context, packet_filter): pf = packet_filter['packet_filter'] tenant_id = self._get_tenant_id_for_create(context, pf) # validate network ownership super(NECPluginV2Base, self).get_network(context, pf['network_id']) if pf.get('in_port') is not attributes.ATTR_NOT_SPECIFIED: # validate port ownership super(NECPluginV2Base, self).get_port(context, pf['in_port']) params = {'tenant_id': tenant_id, 'id': pf.get('id') or uuidutils.generate_uuid(), 'name': pf['name'], 'network_id': pf['network_id'], 'priority': pf['priority'], 'action': pf['action'], 'admin_state_up': pf.get('admin_state_up', True), 'status': ""ACTIVE""} conditions = {'in_port': '', 'src_mac': '', 'dst_mac': '', 'eth_type': 0, 'src_cidr': '', 'dst_cidr': '', 'src_port': 0, 'dst_port': 0, 'protocol': ''} for key, default in conditions.items(): if pf.get(key) is attributes.ATTR_NOT_SPECIFIED: params.update({key: default}) else: params.update({key: pf.get(key)}) with context.session.begin(subtransactions=True): pf_entry = nmodels.PacketFilter(**params) context.session.add(pf_entry) return self._make_packet_filter_dict(pf_entry) def update_packet_filter(self, context, id, packet_filter): pf = packet_filter['packet_filter'] with context.session.begin(subtransactions=True): pf_entry = self._get_packet_filter(context, id) pf_entry.update(pf) return self._make_packet_filter_dict(pf_entry) def delete_packet_filter(self, context, id): with context.session.begin(subtransactions=True): packet_filter = self._get_packet_filter(context, id) context.session.delete(packet_filter) ",755,352
openstack%2Fneutron~master~I007a81003e343300836ad226c2dc64b95c5a3247,openstack/neutron,master,I007a81003e343300836ad226c2dc64b95c5a3247,Fixes argument mismatch in l3-agent,MERGED,2013-07-17 04:54:46.000000000,2013-07-17 09:06:11.000000000,2013-07-17 09:06:10.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 2874}, {'_account_id': 5948}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-17 04:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/995ff3a60acffb452375a29af07c3bc88031b274', 'message': 'Fixes arugment mismatch in l3-agent\n\nFixes bug 1202055\n\nChange-Id: I007a81003e343300836ad226c2dc64b95c5a3247\n'}, {'number': 2, 'created': '2013-07-17 04:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5ccf66d7cb252667a044006dfec947d5144b13b1', 'message': 'Fixes argument mismatch in l3-agent\n\nFixes bug 1202055\n\nChange-Id: I007a81003e343300836ad226c2dc64b95c5a3247\n'}, {'number': 3, 'created': '2013-07-17 05:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d0f6cbd602c2f59c3b95551eda4972ab9d52251', 'message': 'Fixes argument mismatch in l3-agent\n\nFixes bug 1202055\nAlso fixes deletion problem in snat rule\n\nChange-Id: I007a81003e343300836ad226c2dc64b95c5a3247\n'}, {'number': 4, 'created': '2013-07-17 06:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e790400e74f9c0c0e46a540ac1c0b7119e23adc', 'message': 'Fixes argument mismatch in l3-agent\n\nFixes bug 1202055\nAlso fixes deletion problem in snat rule\n\nChange-Id: I007a81003e343300836ad226c2dc64b95c5a3247\n'}, {'number': 5, 'created': '2013-07-17 06:34:35.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/28d6ca99277b5f8edf61d03af07da0658fee920e', 'message': 'Fixes argument mismatch in l3-agent\n\nFixes bug 1202055\nAlso fixes deletion problem in snat rule\n\nChange-Id: I007a81003e343300836ad226c2dc64b95c5a3247\n'}]",8,37393,28d6ca99277b5f8edf61d03af07da0658fee920e,28,8,5,2031,,,0,"Fixes argument mismatch in l3-agent

Fixes bug 1202055
Also fixes deletion problem in snat rule

Change-Id: I007a81003e343300836ad226c2dc64b95c5a3247
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/37393/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3_agent.py'],1,995ff3a60acffb452375a29af07c3bc88031b274,bug/1202055, self._router_removed(router_id)," self._router_removed(context, router_id)",1,1
openstack%2Fnova~master~I88d40db3c04355a752474217cdb184cd386d060c,openstack/nova,master,I88d40db3c04355a752474217cdb184cd386d060c,Support Client Token for EC2 RunInstances,MERGED,2013-06-06 23:11:11.000000000,2013-07-17 09:05:52.000000000,2013-07-17 09:05:49.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 5652}, {'_account_id': 6661}]","[{'number': 1, 'created': '2013-06-06 23:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a11658d1822d8173c3b25c558523fce047b2160', 'message': 'Support Client Token for EC2 RunInstances\n\nThe EC2 API allows users to provide a unique ClientToken in a RunInstances\ncall. Future invocations of RunInstances with the same ClientToken return\nthe same response but do not create new instances.\n\nFixes bug 1188327.\n\nChange-Id: I88d40db3c04355a752474217cdb184cd386d060c\n'}, {'number': 2, 'created': '2013-06-07 16:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c482a1a021a9dab206637076604b184cd46bb170', 'message': 'Support Client Token for EC2 RunInstances\n\nThe EC2 API allows users to provide a unique ClientToken in a RunInstances\ncall. Future invocations of RunInstances with the same ClientToken return\nthe same response but do not create new instances.\n\nFixes bug 1188327.\n\nChange-Id: I88d40db3c04355a752474217cdb184cd386d060c\n'}, {'number': 3, 'created': '2013-06-10 16:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac9db9321ea86b16ca05d49ae5a84e990645737d', 'message': 'Support Client Token for EC2 RunInstances\n\nThe EC2 API allows users to provide a unique ClientToken in a RunInstances\ncall. Future invocations of RunInstances with the same ClientToken return\nthe same response but do not create new instances.\n\nFixes bug 1188327.\n\nChange-Id: I88d40db3c04355a752474217cdb184cd386d060c\n'}, {'number': 4, 'created': '2013-06-14 05:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a8314170ae8e94a164c383cb04a799c3bace8bd', 'message': 'Support Client Token for EC2 RunInstances\n\nThe EC2 API allows users to provide a unique ClientToken in a RunInstances\ncall. Future invocations of RunInstances with the same ClientToken return\nthe same response but do not create new instances.\n\nFixes bug 1188327.\n\nChange-Id: I88d40db3c04355a752474217cdb184cd386d060c\n'}, {'number': 5, 'created': '2013-06-28 14:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/473463e594209d7ebf1bc8ed5b8c7c06cb262b39', 'message': 'Support Client Token for EC2 RunInstances\n\nThe EC2 API allows users to provide a unique ClientToken in a RunInstances\ncall. Future invocations of RunInstances with the same ClientToken return\nthe same response but do not create new instances.\n\nFixes bug 1188327.\n\nChange-Id: I88d40db3c04355a752474217cdb184cd386d060c\n'}, {'number': 6, 'created': '2013-06-28 16:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a44c3d556f8e44cff39ae8c697cdbfb8c6685ac', 'message': 'Support Client Token for EC2 RunInstances\n\nThe EC2 API allows users to provide a unique ClientToken in a RunInstances\ncall. Future invocations of RunInstances with the same ClientToken return\nthe same response but do not create new instances.\n\nFixes bug 1188327.\n\nChange-Id: I88d40db3c04355a752474217cdb184cd386d060c\n'}, {'number': 7, 'created': '2013-06-28 22:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe75cbb5f4526f19b5a7eaff7145b34188387d86', 'message': 'Support Client Token for EC2 RunInstances\n\nThe EC2 API allows users to provide a unique ClientToken in a RunInstances\ncall. Future invocations of RunInstances with the same ClientToken return\nthe same response but do not create new instances.\n\nFixes bug 1188327.\n\nChange-Id: I88d40db3c04355a752474217cdb184cd386d060c\n'}, {'number': 8, 'created': '2013-07-12 16:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/967f75274f1965b2fef26100c4888b74112d28c0', 'message': 'Support Client Token for EC2 RunInstances\n\nThe EC2 API allows users to provide a unique ClientToken in a RunInstances\ncall. Future invocations of RunInstances with the same ClientToken return\nthe same response but do not create new instances.\n\nFixes bug 1188327.\n\nChange-Id: I88d40db3c04355a752474217cdb184cd386d060c\n'}, {'number': 9, 'created': '2013-07-16 21:52:35.000000000', 'files': ['nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e29ecdbb85d8afd3dab0cbb566c564e2d9a6818d', 'message': 'Support Client Token for EC2 RunInstances\n\nThe EC2 API allows users to provide a unique ClientToken in a RunInstances\ncall. Future invocations of RunInstances with the same ClientToken return\nthe same response but do not create new instances.\n\nFixes bug 1188327.\n\nChange-Id: I88d40db3c04355a752474217cdb184cd386d060c\n'}]",8,32060,e29ecdbb85d8afd3dab0cbb566c564e2d9a6818d,55,6,9,6661,,,0,"Support Client Token for EC2 RunInstances

The EC2 API allows users to provide a unique ClientToken in a RunInstances
call. Future invocations of RunInstances with the same ClientToken return
the same response but do not create new instances.

Fixes bug 1188327.

Change-Id: I88d40db3c04355a752474217cdb184cd386d060c
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/32060/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py']",2,9a11658d1822d8173c3b25c558523fce047b2160,bug/1188327," self.client_token_lastpurge = time.time() self.client_token_list = {} self.client_token_expdate = {} client_token = kwargs.get('client_token') if client_token in self.client_token_list: resv_id = self.client_token_list[client_token] return self._format_run_instances(context, resv_id) self._add_client_token(client_token, resv_id) def _add_client_token(self, client_token, resv_id): """"""Add client token to reservation ID mapping."""""" if client_token: self.client_token_list[client_token] = resv_id self.client_token_expdate[time.time()] = client_token self._purge_old_client_tokens() return def _purge_old_client_tokens(self): """"""Purge old client tokens (> 24 h) once a day."""""" now = time.time() if (now - self.client_token_lastpurge) > 86400: expdates = self.client_token_expdate.keys() for expdate in expdates: if (now - expdate) > 86400: del self.client_token_expdate[expdate] return ",,75,0
openstack%2Fnova~master~Ifce53dbc9f0740337921491aa752900892f47052,openstack/nova,master,Ifce53dbc9f0740337921491aa752900892f47052,Allow ::/0 for IPv6 security group rules,MERGED,2013-07-10 21:16:58.000000000,2013-07-17 09:00:53.000000000,2013-07-17 09:00:50.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 986}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2592}]","[{'number': 1, 'created': '2013-07-10 21:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f5acc13bfd97268cbc010d1ddb15ec1f6e60a7d', 'message': 'Nova fails to create a security group rule if ::/0 is used as\nvalue for the cidr field\n\nFixes: bug #1199943\n\nChange-Id: Ifce53dbc9f0740337921491aa752900892f47052\nSigned-off-by: Rosario Di Somma <rosario.disomma@dreamhost.com>\n'}, {'number': 2, 'created': '2013-07-10 21:44:07.000000000', 'files': ['nova/api/openstack/compute/contrib/security_groups.py', 'nova/tests/api/openstack/compute/contrib/test_security_groups.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8e5fceb0411363313306183fd2cd5c177f3b8c24', 'message': 'Allow ::/0 for IPv6 security group rules\n\nNova fails to create a security group rule if ::/0 is used as\nvalue for the cidr field\n\nFixes: LP bug #1199943\n\nChange-Id: Ifce53dbc9f0740337921491aa752900892f47052\nSigned-off-by: Rosario Di Somma <rosario.disomma@dreamhost.com>\n'}]",0,36556,8e5fceb0411363313306183fd2cd5c177f3b8c24,10,6,2,986,,,0,"Allow ::/0 for IPv6 security group rules

Nova fails to create a security group rule if ::/0 is used as
value for the cidr field

Fixes: LP bug #1199943

Change-Id: Ifce53dbc9f0740337921491aa752900892f47052
Signed-off-by: Rosario Di Somma <rosario.disomma@dreamhost.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/36556/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/security_groups.py', 'nova/tests/api/openstack/compute/contrib/test_security_groups.py']",2,3f5acc13bfd97268cbc010d1ddb15ec1f6e60a7d,bug/1199943," def test_create_rule_cidr_ipv6_allow_all(self): rule = security_group_rule_template(cidr='::/0', parent_group_id=self.sg2['id']) req = fakes.HTTPRequest.blank('/v2/fake/os-security-group-rules') res_dict = self.controller.create(req, {'security_group_rule': rule}) security_group_rule = res_dict['security_group_rule'] self.assertNotEquals(security_group_rule['id'], 0) self.assertEquals(security_group_rule['parent_group_id'], self.parent_security_group['id']) self.assertEquals(security_group_rule['ip_range']['cidr'], ""::/0"") ",,15,1
openstack%2Fnova~master~I5c95187430e4e49489b4e2b66f95a05f23948f84,openstack/nova,master,I5c95187430e4e49489b4e2b66f95a05f23948f84,Patch sqlalchemy-migrate to fix UC bugs in SQLite,ABANDONED,2013-06-26 10:15:26.000000000,2013-07-17 08:41:25.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2472}, {'_account_id': 6172}, {'_account_id': 6849}]","[{'number': 1, 'created': '2013-06-26 10:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe89503c3dfc0ddfd839560899376e1196eeb2c7', 'message': 'WIP: sqlalchemy-migrate monkey-patch in Nova\n\nChange-Id: I5c95187430e4e49489b4e2b66f95a05f23948f84\n'}, {'number': 2, 'created': '2013-07-02 09:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/abf9cf5742e4eb3f730491e6c0e5760208d4e597', 'message': 'Patch sqlalchemy-migrate to fix UC bugs in SQLite\n\nNova and other projects use sqlalchemy-migrate for DB schema\nmigrations. Unfortunately, this project looks like to be dead,\nbut have some important bugs which makes lives of OpenStack\ndevelopers harder (e. g. creation of a new unique constraint\nin SQLite leads to deletion of all existing unique constraints).\n\nWe already have some workarounds for bugs and limitations of\nsqlalchemy-migrate, though it would be nice to have those directly\nin sqlalchemy-migrate (at least in form of a monkey-patch for now).\n\nLater, this can be put to Oslo and reused by other projects, which\nrelies on sqlalchemy-migrate for applying of DB schema migrations.\n\nThis patch:\n  - makes it possible to use the unified drop_unique_constraint()\n    function for SQLite backend\n  - fixes a bug in sqlalchemy-migrate that leads to deletion of\n    existing unique constraints of a table when a new one is added\n    (SQLite backend)\n\nChange-Id: I5c95187430e4e49489b4e2b66f95a05f23948f84\n'}, {'number': 3, 'created': '2013-07-11 15:15:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64048aa453ffe1db7c7186e99d55dec1c3ac9b66', 'message': 'Patch sqlalchemy-migrate to fix UC bugs in SQLite\n\nNova and other projects use sqlalchemy-migrate for DB schema\nmigrations. Unfortunately, this project looks like to be dead,\nbut have some important bugs which makes lives of OpenStack\ndevelopers harder (e. g. creation of a new unique constraint\nin SQLite leads to deletion of all existing unique constraints).\n\nWe already have some workarounds for bugs and limitations of\nsqlalchemy-migrate, though it would be nice to have those directly\nin sqlalchemy-migrate (at least in form of a monkey-patch for now).\n\nThis patch uses Oslo code that:\n  - makes it possible to use the unified drop_unique_constraint()\n    function for SQLite backend\n  - fixes a bug in sqlalchemy-migrate that leads to deletion of\n    existing unique constraints of a table when a new one is added\n    (SQLite backend)\n\nFixes bug 1200265.\n\nChange-Id: I5c95187430e4e49489b4e2b66f95a05f23948f84\n'}, {'number': 4, 'created': '2013-07-11 19:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a0c0a1bb2aa2d86594a2ce5621c979d3ee0c9ed', 'message': 'Patch sqlalchemy-migrate to fix UC bugs in SQLite\n\nNova and other projects use sqlalchemy-migrate for DB schema\nmigrations. Unfortunately, this project looks like to be dead,\nbut have some important bugs which makes lives of OpenStack\ndevelopers harder (e. g. creation of a new unique constraint\nin SQLite leads to deletion of all existing unique constraints).\n\nWe already have some workarounds for bugs and limitations of\nsqlalchemy-migrate, though it would be nice to have those directly\nin sqlalchemy-migrate (at least in form of a monkey-patch for now).\n\nThis patch uses Oslo code that:\n  - makes it possible to use the unified drop_unique_constraint()\n    function for SQLite backend\n  - fixes a bug in sqlalchemy-migrate that leads to deletion of\n    existing unique constraints of a table when a new one is added\n    (SQLite backend)\n\nFixes bug 1200265.\n\nChange-Id: I5c95187430e4e49489b4e2b66f95a05f23948f84\n'}, {'number': 5, 'created': '2013-07-11 19:01:37.000000000', 'files': ['nova/openstack/common/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f451bd2ad8c2bb79ea433e9139c2d167b295444a', 'message': 'Patch sqlalchemy-migrate to fix UC bugs in SQLite\n\nNova and other projects use sqlalchemy-migrate for DB schema\nmigrations. Unfortunately, this project looks like to be dead,\nbut have some important bugs which makes lives of OpenStack\ndevelopers harder (e. g. creation of a new unique constraint\nin SQLite leads to deletion of all existing unique constraints).\n\nWe already have some workarounds for bugs and limitations of\nsqlalchemy-migrate, though it would be nice to have those directly\nin sqlalchemy-migrate (at least in form of a monkey-patch for now).\n\nThis patch uses Oslo code that:\n  - makes it possible to use the unified drop_unique_constraint()\n    function for SQLite backend\n  - fixes a bug in sqlalchemy-migrate that leads to deletion of\n    existing unique constraints of a table when a new one is added\n    (SQLite backend)\n\nFixes bug 1200265.\n\nChange-Id: I5c95187430e4e49489b4e2b66f95a05f23948f84\n'}]",3,34526,f451bd2ad8c2bb79ea433e9139c2d167b295444a,25,5,5,6849,,,0,"Patch sqlalchemy-migrate to fix UC bugs in SQLite

Nova and other projects use sqlalchemy-migrate for DB schema
migrations. Unfortunately, this project looks like to be dead,
but have some important bugs which makes lives of OpenStack
developers harder (e. g. creation of a new unique constraint
in SQLite leads to deletion of all existing unique constraints).

We already have some workarounds for bugs and limitations of
sqlalchemy-migrate, though it would be nice to have those directly
in sqlalchemy-migrate (at least in form of a monkey-patch for now).

This patch uses Oslo code that:
  - makes it possible to use the unified drop_unique_constraint()
    function for SQLite backend
  - fixes a bug in sqlalchemy-migrate that leads to deletion of
    existing unique constraints of a table when a new one is added
    (SQLite backend)

Fixes bug 1200265.

Change-Id: I5c95187430e4e49489b4e2b66f95a05f23948f84
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/34526/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/openstack/common/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/utils.py']",3,fe89503c3dfc0ddfd839560899376e1196eeb2c7,bug/1200265," meta = MetaData() meta.bind = migrate_engine t = Table(table_name, meta, autoload=True) if migrate_engine.name == 'sqlite': override_cols = [ _get_not_supported_column(col_name_col_instance, col.name) for col in t.columns if isinstance(col.type, NullType) ] for col in override_cols: t.columns.replace(col) uc = UniqueConstraint(*columns, table=t, name=uc_name) uc.drop()","import re from sqlalchemy import schemadef _get_unique_constraints_in_sqlite(migrate_engine, table_name): regexp = ""CONSTRAINT (\w+) UNIQUE \(([^\)]+)\)"" meta = MetaData(bind=migrate_engine) table = Table(table_name, meta, autoload=True) sql_data = migrate_engine.execute( """"""SELECT sql FROM sqlite_master WHERE type = 'table' and name = '{0}';"""""" .format(table_name) ).fetchone()[0] uniques = set([ schema.UniqueConstraint( *[getattr(table.c, c.strip()) for c in cols.split("","")], name=name ) for name, cols in re.findall(regexp, sql_data) ]) return uniques def _drop_unique_constraint_in_sqlite(migrate_engine, table_name, uc_name, **col_name_col_instance): insp = reflection.Inspector.from_engine(migrate_engine) meta = MetaData(bind=migrate_engine) table = Table(table_name, meta, autoload=True) columns = [] for column in table.columns: if isinstance(column.type, NullType): new_column = _get_not_supported_column(col_name_col_instance, column.name) columns.append(new_column) else: columns.append(column.copy()) uniques = _get_unique_constraints_in_sqlite(migrate_engine, table_name) table.constraints.update(uniques) constraints = [constraint for constraint in table.constraints if not constraint.name == uc_name] new_table = Table(table_name + ""__tmp__"", meta, *(columns + constraints)) new_table.create() indexes = [] for index in insp.get_indexes(table_name): column_names = [new_table.c[c] for c in index['column_names']] indexes.append(Index(index[""name""], *column_names, unique=index[""unique""])) ins = InsertFromSelect(new_table, table.select()) migrate_engine.execute(ins) table.drop() [index.create(migrate_engine) for index in indexes] new_table.rename(table_name) if migrate_engine.name in [""mysql"", ""postgresql""]: meta = MetaData() meta.bind = migrate_engine t = Table(table_name, meta, autoload=True) uc = UniqueConstraint(*columns, table=t, name=uc_name) uc.drop() else: _drop_unique_constraint_in_sqlite(migrate_engine, table_name, uc_name, **col_name_col_instance)",153,74
openstack%2Fcookbook-openstack-ops-messaging~master~I2a10c551cb2176dadaee8842eeadfdfc8cb93e44,openstack/cookbook-openstack-ops-messaging,master,I2a10c551cb2176dadaee8842eeadfdfc8cb93e44,Configure rabbit and EPMD to bind to an address,MERGED,2013-07-13 21:38:55.000000000,2013-07-17 08:40:16.000000000,2013-07-17 08:40:16.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 216}, {'_account_id': 2340}, {'_account_id': 6530}, {'_account_id': 7572}]","[{'number': 1, 'created': '2013-07-13 21:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/034bc75d260b2b37708fb864b69a1dedcabac4c2', 'message': 'Configure rabbit and EPMD to bind to an address\n\nThis change integrates against a rabbitmq cookbook feature which\nis not yet merged upstream.  However, given the default code path\ndoes not change, felt okay to get this out there.  Especially b/c\nwe are dependant on it.  This feature allows one to run rabbit\nand clustering across a specific address.  For more details, see:\n  http://tickets.opscode.com/browse/COOK-3320\n\nChange-Id: I2a10c551cb2176dadaee8842eeadfdfc8cb93e44\n'}, {'number': 2, 'created': '2013-07-13 21:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/36d76ba159febf60e58cf05f24a38bf0478ad038', 'message': 'Configure rabbit and EPMD to bind to an address\n\nThis change integrates against a rabbitmq cookbook feature which\nis not yet merged upstream.  However, given the default code path\ndoes not change, felt okay to get this out there.  Especially b/c\nwe are dependant on it.  This feature allows one to run rabbit\nand clustering across a specific address.  For more details, see:\n  http://tickets.opscode.com/browse/COOK-3320\n\nChange-Id: I2a10c551cb2176dadaee8842eeadfdfc8cb93e44\n'}, {'number': 3, 'created': '2013-07-13 21:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/63071d32d35e69ec2038cc6d392502e7100caeab', 'message': 'Configure rabbit and EPMD to bind to an address\n\nThis change integrates against a rabbitmq cookbook feature which\nis not yet merged upstream.  However, given the default code path\ndoes not change, felt okay to get this out there.  Especially b/c\nwe are dependant on it.  This feature allows one to run rabbit\nand clustering across a specific address.  For more details, see:\n  http://tickets.opscode.com/browse/COOK-3320\n\nChange-Id: I2a10c551cb2176dadaee8842eeadfdfc8cb93e44\n'}, {'number': 4, 'created': '2013-07-15 04:01:09.000000000', 'files': ['recipes/rabbitmq-server.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/server_spec.rb', 'spec/rabbitmq-server_spec.rb', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/3b35ac204d7b117e86cc51d72bfc4a927183a92a', 'message': 'Configure rabbit and EPMD to bind to an address\n\nThis change integrates against a rabbitmq cookbook feature which\nis not yet merged upstream.  However, given the default code path\ndoes not change, felt okay to get this out there.  Especially b/c\nwe are dependant on it.  This feature allows one to run rabbit\nand clustering across a specific address.  For more details, see:\n  http://tickets.opscode.com/browse/COOK-3320\n\nChange-Id: I2a10c551cb2176dadaee8842eeadfdfc8cb93e44\n'}]",1,36958,3b35ac204d7b117e86cc51d72bfc4a927183a92a,13,6,4,216,,,0,"Configure rabbit and EPMD to bind to an address

This change integrates against a rabbitmq cookbook feature which
is not yet merged upstream.  However, given the default code path
does not change, felt okay to get this out there.  Especially b/c
we are dependant on it.  This feature allows one to run rabbit
and clustering across a specific address.  For more details, see:
  http://tickets.opscode.com/browse/COOK-3320

Change-Id: I2a10c551cb2176dadaee8842eeadfdfc8cb93e44
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-messaging refs/changes/58/36958/2 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/rabbitmq-server.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/server_spec.rb', 'spec/rabbitmq-server_spec.rb', 'README.md']",6,034bc75d260b2b37708fb864b69a1dedcabac4c2,epmd-bind,"* `openstack[""mq""][""erl_bind_networking""]` - whether or not to bind rabbit and epmd to the listen address determined by `openstack[""mq""][""bind_interface""]`",,57,3
openstack%2Fceilometer~master~Ic0c639224ba87c3e11f3e1eeba4915e3c8ba0e88,openstack/ceilometer,master,Ic0c639224ba87c3e11f3e1eeba4915e3c8ba0e88,api: build the storage connection once and for all,MERGED,2013-07-12 15:27:51.000000000,2013-07-17 08:16:22.000000000,2013-07-17 08:16:22.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-12 15:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/83f4a532fea038aede5c9d43908c47c7e06b88b7', 'message': 'api: build the storage connection once and for all\n\nChange-Id: Ic0c639224ba87c3e11f3e1eeba4915e3c8ba0e88\nFixes: bug#1178845\n'}, {'number': 2, 'created': '2013-07-16 16:12:25.000000000', 'files': ['ceilometer/api/app.py', 'ceilometer/api/hooks.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1c3c6a65142500b44e0c286887b2332de1994e8b', 'message': 'api: build the storage connection once and for all\n\nFixes: bug#1178845\n\nChange-Id: Ic0c639224ba87c3e11f3e1eeba4915e3c8ba0e88\n'}]",2,36849,1c3c6a65142500b44e0c286887b2332de1994e8b,10,4,2,1669,,,0,"api: build the storage connection once and for all

Fixes: bug#1178845

Change-Id: Ic0c639224ba87c3e11f3e1eeba4915e3c8ba0e88
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/49/36849/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/api/app.py', 'ceilometer/api/hooks.py']",2,83f4a532fea038aede5c9d43908c47c7e06b88b7,bug/1178845,,"from ceilometer import storageclass DBHook(hooks.PecanHook): def before(self, state): storage_engine = storage.get_engine(state.request.cfg) state.request.storage_engine = storage_engine state.request.storage_conn = storage_engine.get_connection( state.request.cfg) # def after(self, state): # print 'method:', state.request.method # print 'response:', state.response.status ",14,15
openstack%2Fcinder~master~Ie919b50ce4fb276f29ab2e0279f868a691ea7bef,openstack/cinder,master,Ie919b50ce4fb276f29ab2e0279f868a691ea7bef,Enable zero the snapshot when delete snapshot in LVMVolumeDriver,MERGED,2013-07-10 16:42:32.000000000,2013-07-17 08:13:59.000000000,2013-07-12 18:33:14.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2481}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-10 16:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/15031379a8af6f801a6610746cda7824e96ba8b8', 'message': ""Enable zero the snapshot when delete snapshot in LVMVolumeDriver\n\nBecause snapshot without 'size' field, So clear_volume method in\nLVMVolumeDriverwill will skip secure deleting. Add 'size' parameter to\nclear_volume method, So it can get the size of snapshot and zero the snapshot.\n\nFixes  bug/1198185\n\nChange-Id: Ie919b50ce4fb276f29ab2e0279f868a691ea7bef\n""}, {'number': 2, 'created': '2013-07-10 16:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/31c3293e37bbd58588cd56c774d0b36346cc497d', 'message': ""Enable zero the snapshot when delete snapshot in LVMVolumeDriver\n\nBecause snapshot without 'size' field, So clear_volume method in\nLVMVolumeDriverwill will skip secure deleting. Add 'size' parameter to\nclear_volume method, So it can get the size of snapshot and zero the snapshot.\n\nFixes  bug/1198185\n\nChange-Id: Ie919b50ce4fb276f29ab2e0279f868a691ea7bef\n""}, {'number': 3, 'created': '2013-07-10 16:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a69eadab769547989153656e53c93303b8672976', 'message': ""Enable zero the snapshot when delete snapshot in LVMVolumeDriver\n\nBecause snapshot without 'size' field, So clear_volume method in\nLVMVolumeDriverwill will skip secure deleting. Add 'size' parameter to\nclear_volume method, So it can get the size of snapshot and zero the snapshot.\n\nFixes  Bug #1198185\n\nChange-Id: Ie919b50ce4fb276f29ab2e0279f868a691ea7bef\n""}, {'number': 4, 'created': '2013-07-10 18:32:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c99bd05d598b8b1c56088814d6de7039cda36588', 'message': ""Enable zero the snapshot when delete snapshot in LVMVolumeDriver\n\nBecause snapshot without 'size' field, So clear_volume method in\nLVMVolumeDriver will skip secure deleting. Add 'size' parameter to\nclear_volume method, So it can get the size of snapshot and zero the snapshot.\n\nFixes  Bug #1198185\n\nChange-Id: Ie919b50ce4fb276f29ab2e0279f868a691ea7bef\n""}, {'number': 5, 'created': '2013-07-10 20:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0c83d70e35f22e4024d4d83477709931f1ce6aa5', 'message': ""Enable zero the snapshot when delete snapshot in LVMVolumeDriver\n\nBecause snapshot without 'size' field, So clear_volume method in\nLVMVolumeDriver will skip secure deleting. Get the size of snapshot from\n'volume_size' filed, So it can zero the snapshot.\n\nRemove the 'size_in_g' parameter in _delete_volume method, because it never\nused.\n\nFixes  Bug #1198185\n\nChange-Id: Ie919b50ce4fb276f29ab2e0279f868a691ea7bef\n""}, {'number': 6, 'created': '2013-07-10 20:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3b7f153db78805ee3b536cf043a325d1ebbe4c84', 'message': ""Enable zero the snapshot when delete snapshot in LVMVolumeDriver\n\nBecause snapshot without 'size' field, So clear_volume method in\nLVMVolumeDriver will skip secure deleting. Get the size of snapshot from\n'volume_size' filed, So it can zero the snapshot.\n\nRemove the 'size_in_g' parameter in _delete_volume method, because it never\nused.\n\nFixes  Bug #1198185\n\nChange-Id: Ie919b50ce4fb276f29ab2e0279f868a691ea7bef\n""}, {'number': 7, 'created': '2013-07-11 09:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c2250077cd93ac865175dd7fb54cade623ee9847', 'message': ""Enable zero the snapshot when delete snapshot in LVMVolumeDriver\n\nBecause snapshot without 'size' field, So clear_volume method in\nLVMVolumeDriver will skip secure deleting. Get the size of snapshot from\n'volume_size' filed, So it can zero the snapshot.\n\nRemove the 'size_in_g' parameter in _delete_volume method, because it never\nused. Add a unittest for clear_volume method.\n\nFixes  Bug #1198185\n\nChange-Id: Ie919b50ce4fb276f29ab2e0279f868a691ea7bef\n""}, {'number': 8, 'created': '2013-07-12 02:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/251af8834e19af923467d0ae346561623cf9b8ee', 'message': ""Enable zero the snapshot when delete snapshot in LVMVolumeDriver\n\nBecause snapshot without 'size' field, So clear_volume method in\nLVMVolumeDriver will skip secure deleting. Get the size of snapshot from\n'volume_size' filed, So it can zero the snapshot.\n\nRemove the 'size_in_g' parameter in _delete_volume method, because it never\nused. Add a unittest for clear_volume method.\n\nFixes  Bug #1198185\n\nChange-Id: Ie919b50ce4fb276f29ab2e0279f868a691ea7bef\n""}, {'number': 9, 'created': '2013-07-12 14:50:28.000000000', 'files': ['cinder/tests/test_volume.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0ee31073c5cb432a9cdd2648e99aa802b0ed0a17', 'message': ""Enable zero the snapshot when delete snapshot in LVMVolumeDriver\n\nBecause snapshot without 'size' field, So clear_volume method in\nLVMVolumeDriver will skip secure deleting. Get the size of snapshot from\n'volume_size' filed, So it can zero the snapshot.\n\nRemove the 'size_in_g' parameter in _delete_volume method, because it never\nused. Add a unittest for clear_volume method.\n\nFixes  Bug #1198185\n\nChange-Id: Ie919b50ce4fb276f29ab2e0279f868a691ea7bef\n""}]",16,36506,0ee31073c5cb432a9cdd2648e99aa802b0ed0a17,35,8,9,2481,,,0,"Enable zero the snapshot when delete snapshot in LVMVolumeDriver

Because snapshot without 'size' field, So clear_volume method in
LVMVolumeDriver will skip secure deleting. Get the size of snapshot from
'volume_size' filed, So it can zero the snapshot.

Remove the 'size_in_g' parameter in _delete_volume method, because it never
used. Add a unittest for clear_volume method.

Fixes  Bug #1198185

Change-Id: Ie919b50ce4fb276f29ab2e0279f868a691ea7bef
",git fetch https://review.opendev.org/openstack/cinder refs/changes/06/36506/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/lvm.py'],1,15031379a8af6f801a6610746cda7824e96ba8b8,bug/1198185," self.clear_volume(volume, size=size_in_g) def clear_volume(self, volume, size=None): if size_in_g is None: size_in_g = volume.get('size')"," self.clear_volume(volume) def clear_volume(self, volume): size_in_g = volume.get('size')",4,3
openstack%2Fceilometer~master~I515c7818350d39173f4435c4141b4e929c1a1a6c,openstack/ceilometer,master,I515c7818350d39173f4435c4141b4e929c1a1a6c,Remove useless mongodb connection pool comment,MERGED,2013-07-17 05:52:57.000000000,2013-07-17 08:13:44.000000000,2013-07-17 08:13:44.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2013-07-17 05:52:57.000000000', 'files': ['ceilometer/storage/impl_mongodb.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9a3e05688082994308bbfc4be06edf9ae6e92278', 'message': ""Remove useless mongodb connection pool comment\n\nAs connection pool feature has been delivered in 'Use a real MongoDB instance\nto run unit tests', remove the relevant comments in code.\n\nChange-Id: I515c7818350d39173f4435c4141b4e929c1a1a6c\n""}]",0,37400,9a3e05688082994308bbfc4be06edf9ae6e92278,6,3,1,7302,,,0,"Remove useless mongodb connection pool comment

As connection pool feature has been delivered in 'Use a real MongoDB instance
to run unit tests', remove the relevant comments in code.

Change-Id: I515c7818350d39173f4435c4141b4e929c1a1a6c
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/00/37400/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/storage/impl_mongodb.py'],1,9a3e05688082994308bbfc4be06edf9ae6e92278,master,," # FIXME(xingzhou): ceilometer-api will create a Connection object for # each request. As pymongo.Connection has already maintained a db # connection pool for client, it is better to use a cached Connection # object to connect to mongodb.",0,4
openstack%2Fnova~master~I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f,openstack/nova,master,I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f,Compact pre-Havana database migrations.,ABANDONED,2013-07-05 06:52:07.000000000,2013-07-17 08:12:28.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1313}, {'_account_id': 2166}, {'_account_id': 6172}, {'_account_id': 6507}]","[{'number': 1, 'created': '2013-07-05 06:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b6b5535bd7cf65083b1931a75092d4642e2fbd4', 'message': 'Compact pre-Grizzly database migrations.\n\nCompacts the pre-Grizzly database migrations into a single\nmigration (161_grizzly.py).\n\nPre-Havana users will need to upgrade to Grizzly before\nrunning any Havana migrations.\n\nChange-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f\n'}, {'number': 2, 'created': '2013-07-05 09:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a971ded4814877bcc20c41e23b2197ef224845d5', 'message': 'Compact pre-Grizzly database migrations.\n\nCompacts the pre-Grizzly database migrations into a single\nmigration (161_grizzly.py).\n\nPre-Havana users will need to upgrade to Grizzly before\nrunning any Havana migrations.\n\nChange-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f\n'}, {'number': 3, 'created': '2013-07-05 09:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07225752b4dac9b966eded2d4a3acec7e0fa879c', 'message': 'Compact pre-Havana database migrations.\n\nCompacts the pre-Havana database migrations into a single\nmigration (161_grizzly.py).\n\nPre-Havana users will need to upgrade to Grizzly before\nrunning any Havana migrations.\n\nChange-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f\n'}, {'number': 4, 'created': '2013-07-08 08:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1143a2e9d6e2a0fcdc13df5c80e61c7300e85d1e', 'message': 'Compact pre-Havana database migrations.\n\nCompacts the pre-Havana database migrations into a single\nmigration (161_grizzly.py).\n\nPre-Havana users will need to upgrade to Grizzly before\nrunning any Havana migrations.\n\nChange-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f\n'}, {'number': 5, 'created': '2013-07-08 10:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee1ceaf74d10f9fbe8afcbd7288baf0b672f43c5', 'message': 'Compact pre-Havana database migrations.\n\nCompacts the pre-Havana database migrations into a single\nmigration (161_grizzly.py).\n\nPre-Havana users will need to upgrade to Grizzly before\nrunning any Havana migrations.\n\nChange-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f\n'}, {'number': 6, 'created': '2013-07-08 15:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b03a86abe8dd4bc2b983a948286f51076ac5a407', 'message': 'Compact pre-Havana database migrations.\n\nCompacts the pre-Havana database migrations into a single\nmigration (161_grizzly.py).\n\nPre-Havana users will need to upgrade to Grizzly before\nrunning any Havana migrations.\n\nChange-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f\n'}, {'number': 7, 'created': '2013-07-09 11:13:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/67847dde9c16588c6e93c7e554b5cf2859c95320', 'message': 'Compact pre-Havana database migrations.\n\nCompacts the pre-Havana database migrations into a single\nmigration (161_grizzly.py).\n\nPre-Havana users will need to upgrade to Grizzly before\nrunning any Havana migrations.\n\nChange-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f\n'}, {'number': 8, 'created': '2013-07-09 11:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ecaed9c7249cd06ec2428730e85c474dd1cd8f1', 'message': 'Compact pre-Havana database migrations.\n\nCompacts the pre-Havana database migrations into a single\nmigration (161_grizzly.py).\n\nPre-Havana users will need to upgrade to Grizzly before\nrunning any Havana migrations.\n\nThis is a long term BP, and has been done by Dan Prince in\nFolsom and Grizzly.\n\nChange-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f\n'}, {'number': 9, 'created': '2013-07-09 15:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/add2541ba492b95fb7786e9e5263519338e703e1', 'message': 'Compact pre-Havana database migrations.\n\nCompacts the pre-Havana database migrations into a single\nmigration (161_grizzly.py).\n\nPre-Havana users will need to upgrade to Grizzly before\nrunning any Havana migrations.\n\nThis is a long term BP, and has been done by Dan Prince in\nFolsom and Grizzly.\n\nChange-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f\n'}, {'number': 10, 'created': '2013-07-13 10:42:11.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/134_add_counters_to_bw_usage_cache.py', 'nova/db/sqlalchemy/migrate_repo/versions/135_add_node_to_instances.py', 'nova/db/sqlalchemy/migrate_repo/versions/138_sqlite_downgrade.sql', 'nova/db/sqlalchemy/migrate_repo/versions/147_no_service_zones.py', 'nova/db/sqlalchemy/migrate_repo/versions/156_cidr_column_length.py', 'nova/db/sqlalchemy/migrate_repo/versions/138_sqlite_upgrade.sql', 'nova/db/sqlalchemy/migrate_repo/versions/159_sqlite_downgrade.sql', 'nova/tests/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/146_aggregate_zones.py', 'nova/db/sqlalchemy/migrate_repo/versions/144_add_node_to_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/143_rename_instance_info_cache_sequence.py', 'nova/db/sqlalchemy/migrate_repo/versions/157_add_security_group_default_rules.py', 'nova/db/sqlalchemy/migrate_repo/versions/149_inet_datatype_for_postgres.py', 'nova/db/sqlalchemy/migrate_repo/versions/137_add_indexes_to_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/153_instance_type_in_system_metadata.py', 'nova/db/sqlalchemy/migrate_repo/versions/142_add_migrations_instance_status_index.py', 'nova/db/sqlalchemy/migrate_repo/versions/161_fix_system_metadata_none_strings.py', 'nova/db/sqlalchemy/migrate_repo/versions/141_update_migrations_instance_uuid.py', 'nova/db/sqlalchemy/migrate_repo/versions/161_grizzly.py', 'nova/db/sqlalchemy/migrate_repo/versions/140_drop_unused_postgresql_volume_sequences.py', 'nova/db/sqlalchemy/migrate_repo/versions/160_fix_system_metadata_deleted.py', 'nova/db/sqlalchemy/migrate_repo/versions/159_revert_ip_column_length.py', 'nova/db/sqlalchemy/migrate_repo/versions/151_change_task_log_column_type.py', 'nova/db/sqlalchemy/migrate_repo/versions/152_change_type_of_deleted_column.py', 'nova/db/sqlalchemy/migrate_repo/versions/138_drop_server_name_from_instances.py', 'nova/db/sqlalchemy/migrate_repo/versions/158_add_networks_uc.py', 'nova/db/sqlalchemy/migrate_repo/versions/154_add_shadow_tables.py', 'nova/db/sqlalchemy/migrate_repo/versions/155_add_task_log_uc.py', 'nova/db/sqlalchemy/migrate_repo/versions/145_add_volume_usage_cache.py', 'nova/db/sqlalchemy/migrate_repo/versions/148_add_instance_actions.py', 'nova/db/sqlalchemy/migrate_repo/versions/150_add_host_to_instance_faults.py', 'nova/db/sqlalchemy/utils.py', 'nova/db/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/159_sqlite_upgrade.sql', 'nova/db/sqlalchemy/migrate_repo/versions/139_add_indexes_to_fixed_ips.py', 'nova/db/sqlalchemy/migrate_repo/versions/136_add_index_to_instances.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d6029959648a3ad95951f4284555751a7597cd24', 'message': 'Compact pre-Havana database migrations.\n\nCompacts the pre-Havana database migrations into a single\nmigration (161_grizzly.py), also removes related db migrate\ntests in test_migrations.py.\n\nPre-Havana users will need to upgrade to Grizzly before\nrunning any Havana migrations.\n\nThis is a long term BP, and has been done by Dan Prince in\nFolsom and Grizzly.\n\nImplements blueprint db-migration-cleanup\n\nChange-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f\n'}]",2,35748,d6029959648a3ad95951f4284555751a7597cd24,35,6,10,1313,,,0,"Compact pre-Havana database migrations.

Compacts the pre-Havana database migrations into a single
migration (161_grizzly.py), also removes related db migrate
tests in test_migrations.py.

Pre-Havana users will need to upgrade to Grizzly before
running any Havana migrations.

This is a long term BP, and has been done by Dan Prince in
Folsom and Grizzly.

Implements blueprint db-migration-cleanup

Change-Id: I9f8212fb1862fe8e29cbd3ea1dbf8da2a84ead8f
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/35748/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/versions/134_add_counters_to_bw_usage_cache.py', 'nova/db/sqlalchemy/migrate_repo/versions/135_add_node_to_instances.py', 'nova/db/sqlalchemy/migrate_repo/versions/138_sqlite_downgrade.sql', 'nova/db/sqlalchemy/migrate_repo/versions/147_no_service_zones.py', 'nova/db/sqlalchemy/migrate_repo/versions/156_cidr_column_length.py', 'nova/db/sqlalchemy/migrate_repo/versions/138_sqlite_upgrade.sql', 'nova/db/sqlalchemy/migrate_repo/versions/159_sqlite_downgrade.sql', 'nova/db/sqlalchemy/migrate_repo/versions/146_aggregate_zones.py', 'nova/db/sqlalchemy/migrate_repo/versions/144_add_node_to_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/143_rename_instance_info_cache_sequence.py', 'nova/db/sqlalchemy/migrate_repo/versions/157_add_security_group_default_rules.py', 'nova/db/sqlalchemy/migrate_repo/versions/149_inet_datatype_for_postgres.py', 'nova/db/sqlalchemy/migrate_repo/versions/137_add_indexes_to_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/153_instance_type_in_system_metadata.py', 'nova/db/sqlalchemy/migrate_repo/versions/142_add_migrations_instance_status_index.py', 'nova/db/sqlalchemy/migrate_repo/versions/161_fix_system_metadata_none_strings.py', 'nova/db/sqlalchemy/migrate_repo/versions/141_update_migrations_instance_uuid.py', 'nova/db/sqlalchemy/migrate_repo/versions/161_grizzly.py', 'nova/db/sqlalchemy/migrate_repo/versions/140_drop_unused_postgresql_volume_sequences.py', 'nova/db/sqlalchemy/migrate_repo/versions/160_fix_system_metadata_deleted.py', 'nova/db/sqlalchemy/migrate_repo/versions/159_revert_ip_column_length.py', 'nova/db/sqlalchemy/migrate_repo/versions/151_change_task_log_column_type.py', 'nova/db/sqlalchemy/migrate_repo/versions/152_change_type_of_deleted_column.py', 'nova/db/sqlalchemy/migrate_repo/versions/138_drop_server_name_from_instances.py', 'nova/db/sqlalchemy/migrate_repo/versions/158_add_networks_uc.py', 'nova/db/sqlalchemy/migrate_repo/versions/154_add_shadow_tables.py', 'nova/db/sqlalchemy/migrate_repo/versions/155_add_task_log_uc.py', 'nova/db/sqlalchemy/migrate_repo/versions/145_add_volume_usage_cache.py', 'nova/db/sqlalchemy/migrate_repo/versions/148_add_instance_actions.py', 'nova/db/sqlalchemy/migrate_repo/versions/150_add_host_to_instance_faults.py', 'nova/db/sqlalchemy/utils.py', 'nova/db/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/159_sqlite_upgrade.sql', 'nova/db/sqlalchemy/migrate_repo/versions/139_add_indexes_to_fixed_ips.py', 'nova/db/sqlalchemy/migrate_repo/versions/136_add_index_to_instances.py']",35,5b6b5535bd7cf65083b1931a75092d4642e2fbd4,bp/db-migration-cleanup,,"# Copyright 2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from sqlalchemy import MetaData, Table, Index INDEX_NAME = 'instances_host_node_deleted_idx' def upgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine instances = Table('instances', meta, autoload=True) # Based on instance_get_all_host_and_node # from: nova/db/sqlalchemy/api.py index = Index(INDEX_NAME, instances.c.host, instances.c.node, instances.c.deleted) index.create(migrate_engine) def downgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine instances = Table('instances', meta, autoload=True) index = Index(INDEX_NAME, instances.c.host, instances.c.node, instances.c.deleted) index.drop(migrate_engine) ",222,2580
openstack%2Fnova~master~I9809e654df8602c00a18cbb7be3a4cf4498b274b,openstack/nova,master,I9809e654df8602c00a18cbb7be3a4cf4498b274b,Unify duplicate code for powering on an instance,MERGED,2013-07-13 13:08:03.000000000,2013-07-17 08:08:11.000000000,2013-07-17 08:08:09.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 2271}]","[{'number': 1, 'created': '2013-07-13 13:08:03.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6e4c9d03371d190174ab3cc072e3c751ea925d16', 'message': 'Unify duplicate code for powering on an instance\n\nMoves duplicate code to a common method\n\nChange-Id: I9809e654df8602c00a18cbb7be3a4cf4498b274b\n'}]",0,36939,6e4c9d03371d190174ab3cc072e3c751ea925d16,7,4,1,1653,,,0,"Unify duplicate code for powering on an instance

Moves duplicate code to a common method

Change-Id: I9809e654df8602c00a18cbb7be3a4cf4498b274b
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/36939/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,6e4c9d03371d190174ab3cc072e3c751ea925d16,power-on," def _power_on(self, context, instance): network_info = self._get_instance_nw_info(context, instance) block_device_info = self._get_instance_volume_block_device_info( context, instance) self.driver.power_on(context, instance, self._legacy_nw_info(network_info), block_device_info) self._power_on(context, instance) self._power_on(context, instance)"," network_info = self._get_instance_nw_info(context, instance) block_device_info = self._get_instance_volume_block_device_info( context, instance) self.driver.power_on(context, instance, self._legacy_nw_info(network_info), block_device_info) network_info = self._get_instance_nw_info(context, instance) block_device_info = self._get_instance_volume_block_device_info( context, instance) self.driver.power_on(context, instance, self._legacy_nw_info(network_info), block_device_info)",10,14
openstack%2Fnova~master~I1abb257579da34c9dd7698543d8297268276bbc5,openstack/nova,master,I1abb257579da34c9dd7698543d8297268276bbc5,Remove unused recreate-db options from run_test.sh,MERGED,2013-07-13 16:19:33.000000000,2013-07-17 08:07:49.000000000,2013-07-17 08:07:47.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-07-13 16:19:33.000000000', 'files': ['run_tests.sh', 'doc/source/devref/unit_tests.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/1d38a9241df17179c875a450fcf0e7adf3b41a78', 'message': ""Remove unused recreate-db options from run_test.sh\n\nrun_tests.sh had an option to delete tests.sqlite, but that file is not\nused anymore so the run_test options don't do anything.\n\nChange-Id: I1abb257579da34c9dd7698543d8297268276bbc5\n""}]",0,36945,1d38a9241df17179c875a450fcf0e7adf3b41a78,8,5,1,1849,,,0,"Remove unused recreate-db options from run_test.sh

run_tests.sh had an option to delete tests.sqlite, but that file is not
used anymore so the run_test options don't do anything.

Change-Id: I1abb257579da34c9dd7698543d8297268276bbc5
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/36945/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'doc/source/devref/unit_tests.rst']",2,1d38a9241df17179c875a450fcf0e7adf3b41a78,cleanup,," -r, --recreate-db Recreate the test database (deprecated, as this is now the default). -n, --no-recreate-db Don't recreate the test database.",0,11
openstack%2Fnova~master~Ibb2619e8077ea8b8bd4796f9ffe89c2376d047f6,openstack/nova,master,Ibb2619e8077ea8b8bd4796f9ffe89c2376d047f6,Sort output for unit tests in test_describe_tags before compare,MERGED,2013-07-09 15:37:40.000000000,2013-07-17 08:07:28.000000000,2013-07-17 08:07:26.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1313}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 6172}, {'_account_id': 6624}, {'_account_id': 6661}]","[{'number': 1, 'created': '2013-07-09 15:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d520bdde24b266f3c0dcdcfcde16c5c2ba39caaa', 'message': ""Sort output for unit tests in test_describe_tags before compare\n\nThere's no guarantees on what order the output from describe_tags\ncomes back in, so it needs to be sorted.\n\nPartially fixes bug #1192715\n\nChange-Id: Ibb2619e8077ea8b8bd4796f9ffe89c2376d047f6\n""}, {'number': 2, 'created': '2013-07-09 17:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/806b43618aba98b6cdef4e7b024369feeda3a08a', 'message': ""Sort output for unit tests in test_describe_tags before compare\n\nThere's no guarantees on what order the output from describe_tags\ncomes back in, so it needs to be sorted.\n\nPartially fixes bug #1192715\n\nChange-Id: Ibb2619e8077ea8b8bd4796f9ffe89c2376d047f6\n""}, {'number': 3, 'created': '2013-07-11 04:44:15.000000000', 'files': ['nova/tests/api/ec2/test_cloud.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c43bc58aa1e2dfaf3c6787560ec2d09af0a819ae', 'message': ""Sort output for unit tests in test_describe_tags before compare\n\nThere's no guarantees on what order the output from describe_tags\ncomes back in, so it needs to be sorted.\n\nPartially fixes bug #1192715\n\nChange-Id: Ibb2619e8077ea8b8bd4796f9ffe89c2376d047f6\n""}]",0,36243,c43bc58aa1e2dfaf3c6787560ec2d09af0a819ae,19,8,3,6661,,,0,"Sort output for unit tests in test_describe_tags before compare

There's no guarantees on what order the output from describe_tags
comes back in, so it needs to be sorted.

Partially fixes bug #1192715

Change-Id: Ibb2619e8077ea8b8bd4796f9ffe89c2376d047f6
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/36243/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/ec2/test_cloud.py'],1,d520bdde24b266f3c0dcdcfcde16c5c2ba39caaa,bug/1192715," def assertEqualSorted(self, x, y): self.assertEqual(sorted(x), sorted(y)) self.assertEqualSorted(tags, [inst1_key_foo, inst2_key_foo, self.assertEqualSorted(tags, [inst1_key_foo, inst1_key_bax]) self.assertEqualSorted(tags, [inst1_key_foo, inst2_key_foo, self.assertEqualSorted(tags, [inst1_key_foo, inst2_key_foo]) self.assertEqualSorted(tags, [inst2_key_baz]) self.assertEqualSorted(tags, [inst1_key_foo, inst2_key_foo]) self.assertEqualSorted(tags, [inst2_key_baz, inst1_key_bax]) self.assertEqualSorted(tags, [inst2_key_baz, inst1_key_bax])"," self.assertEqual(tags, [inst1_key_foo, inst2_key_foo, self.assertEqual(tags, [inst1_key_foo, inst1_key_bax]) self.assertEqual(tags, [inst1_key_foo, inst2_key_foo, self.assertEqual(tags, [inst1_key_foo, inst2_key_foo]) self.assertEqual(tags, [inst2_key_baz]) self.assertEqual(tags, [inst1_key_foo, inst2_key_foo]) self.assertEqual(tags, [inst2_key_baz, inst1_key_bax]) self.assertEqual(tags, [inst2_key_baz, inst1_key_bax])",11,8
openstack%2Ftrove-integration~master~I70673cfcbe6041be4c6ebea9e2d68e33c7159ad2,openstack/trove-integration,master,I70673cfcbe6041be4c6ebea9e2d68e33c7159ad2,Redstack always overwrites the localrc file,MERGED,2013-07-05 08:23:45.000000000,2013-07-17 08:03:41.000000000,2013-07-17 08:03:41.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 1925}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8034}]","[{'number': 1, 'created': '2013-07-05 08:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/3f0daecc596e4995e96e12fa15d81d80f1c870da', 'message': 'Redstack overwrites the localrc file deploying always the latest version\nDevstack can be customized by creating a localrc file before the installation but redstack overwrites it without checkinf if the file already exists.\nFixes Bug1194793\n\nChange-Id: I70673cfcbe6041be4c6ebea9e2d68e33c7159ad2\n'}, {'number': 2, 'created': '2013-07-05 08:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/41fc60373c1ade752b556579118b6a77fea7b3a6', 'message': 'Redstack overwrites the localrc file deploying always the latest version\nDevstack can be customized by creating a localrc file before the installation but redstack overwrites it without checkinf if the file already exists.\nFixes Bug1194793\n\nChange-Id: I70673cfcbe6041be4c6ebea9e2d68e33c7159ad2\n'}, {'number': 3, 'created': '2013-07-05 08:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/1cfbd62f1fa1e9cd43d943053c9d9d4c714a94bb', 'message': 'Redstack overwrites the localrc file deploying always the latest version\nDevstack can be customized by creating a localrc file before the installation but redstack overwrites it without checkinf if the file already exists.\nFixes Bug1194793\n\nChange-Id: I70673cfcbe6041be4c6ebea9e2d68e33c7159ad2\n'}, {'number': 4, 'created': '2013-07-10 08:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/aa812cbe7d8a782fbd20307815282591cc3058f9', 'message': 'Redstack always overwrites the localrc file\nDevstack can be customized by creating a localrc file before the\ninstallation but redstack overwrites it without checking if the\nfile already exists.\nFixes Bug1194793\n\nChange-Id: I70673cfcbe6041be4c6ebea9e2d68e33c7159ad2\n'}, {'number': 5, 'created': '2013-07-10 09:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/63af18065782b48ff74c3dfe021d0e27a8118990', 'message': 'Redstack always overwrites the localrc file\nDevstack can be customized by creating a localrc file before the\ninstallation but redstack overwrites it without checking if the\nfile already exists.\nFixes Bug1194793\n\nChange-Id: I70673cfcbe6041be4c6ebea9e2d68e33c7159ad2\n'}, {'number': 6, 'created': '2013-07-16 07:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/59232e15c4da73b45b4f54bf36e50121fa24e779', 'message': 'Redstack always overwrites the localrc file\n\nDevstack can be customized by creating a localrc file before the\ninstallation but redstack overwrites it without checking if the\nfile already exists.\n\nFixes Bug1194793\n\nChange-Id: I70673cfcbe6041be4c6ebea9e2d68e33c7159ad2\n'}, {'number': 7, 'created': '2013-07-16 07:56:14.000000000', 'files': ['scripts/redstack'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/128d6dfe63c63cec756b401df3137b6f4bd078d7', 'message': 'Redstack always overwrites the localrc file\n\nDevstack can be customized by creating a localrc file before the\ninstallation but redstack overwrites it without checking if the\nfile already exists.\n\nFixes Bug1194793\n\nChange-Id: I70673cfcbe6041be4c6ebea9e2d68e33c7159ad2\n'}]",2,35756,128d6dfe63c63cec756b401df3137b6f4bd078d7,40,7,7,8034,,,0,"Redstack always overwrites the localrc file

Devstack can be customized by creating a localrc file before the
installation but redstack overwrites it without checking if the
file already exists.

Fixes Bug1194793

Change-Id: I70673cfcbe6041be4c6ebea9e2d68e33c7159ad2
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/56/35756/6 && git format-patch -1 --stdout FETCH_HEAD,['scripts/redstack'],1,3f0daecc596e4995e96e12fa15d81d80f1c870da,bug/1194793," localrcvars=""\n # Trove-integration\n # Set some arguments for devstack.\n # These passwords originally come from redstack.rc.\n MYSQL_PASSWORD=$MYSQL_PASSWORD\n RABBIT_PASSWORD=$RABBIT_PASSWORD\n SERVICE_TOKEN=$SERVICE_TOKEN\n ADMIN_PASSWORD=$ADMIN_PASSWORD\n SERVICE_PASSWORD=$SERVICE_PASSWORD\n FLAT_INTERFACE=br100\n TROVE_LOGDIR=$TROVE_LOGDIR\n TROVE_AUTH_CACHE_DIR=$TROVE_AUTH_CACHE_DIR\n # Enable Swift\n ENABLED_SERVICES+=,swift\n SWIFT_HASH=$SWIFT_HASH\n # Set Cinder Volume from Redstack so that later Redstack can help manage\n # reconnecting Volume Group to Backing File\n DEST=$DEST\n DATA_DIR=$DATA_DIR\n VOLUME_GROUP=${VOLUME_GROUP}\n VOLUME_BACKING_FILE=${VOLUME_BACKING_FILE}\n # The lock_path is by default /opt/stack/nova; if this path is a shared\n # folder in VirtualBox things seem to break. We fix it by setting EXTRA_OPS\n # to force lock_path to /tmp.\n EXTRA_OPTS=(lock_path=$USERHOME/nova_locks logdir=$TROVE_LOGDIR logfile_mode=660 rescan_timeout=180 resizefs_timeout=240 force_dhcp_release=False host=`hostname`.`hostname --domain`)\n \n"" if [ -f localrc ]; then #If localrc exist, check if the variables are already in it if [ $(grep ""# Trove-integration"" localrc | wc -l) -eq 0 ]; then #Otherwise append them to the existing file echo -e $params >> localrc fi else #If localrc doesn't exist, create it echo -e $params > localrc fi "," echo "" # Set some arguments for devstack. # These passwords originally come from redstack.rc. MYSQL_PASSWORD=$MYSQL_PASSWORD RABBIT_PASSWORD=$RABBIT_PASSWORD SERVICE_TOKEN=$SERVICE_TOKEN ADMIN_PASSWORD=$ADMIN_PASSWORD SERVICE_PASSWORD=$SERVICE_PASSWORD FLAT_INTERFACE=br100 TROVE_LOGDIR=$TROVE_LOGDIR TROVE_AUTH_CACHE_DIR=$TROVE_AUTH_CACHE_DIR # Enable Swift ENABLED_SERVICES+=,swift SWIFT_HASH=$SWIFT_HASH # Set Cinder Volume from Redstack so that later Redstack can help manage # reconnecting Volume Group to Backing File DEST=$DEST DATA_DIR=$DATA_DIR VOLUME_GROUP=${VOLUME_GROUP} VOLUME_BACKING_FILE=${VOLUME_BACKING_FILE} # The lock_path is by default /opt/stack/nova; if this path is a shared # folder in VirtualBox things seem to break. We fix it by setting EXTRA_OPS # to force lock_path to /tmp. EXTRA_OPTS=(lock_path=$USERHOME/nova_locks logdir=$TROVE_LOGDIR logfile_mode=660 rescan_timeout=180 resizefs_timeout=240 force_dhcp_release=False host=`hostname`.`hostname --domain`) "" > localrc",39,25
openstack%2Fkeystone~master~Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd,openstack/keystone,master,Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd,Implement Token Binding.,MERGED,2013-07-01 06:51:22.000000000,2013-07-17 06:31:33.000000000,2013-07-17 06:31:33.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 6460}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-07-01 06:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c66f936e6f95db6044e60159639a3e742508eef9', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 2, 'created': '2013-07-02 02:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8e90214b294ce345f59fb7b7d61f9e89349f128d', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 3, 'created': '2013-07-04 04:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d3d8f4573757fdf3f515c6162e3d252abd81848d', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 4, 'created': '2013-07-10 07:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b0cac118cbcd6e0270f46c5242d7d09d7eb760bf', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 5, 'created': '2013-07-10 22:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bb160e522ff10eb657643a9d916df4b899554dc5', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 6, 'created': '2013-07-11 04:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5be8be3587920f7894a3ba0187a6f8033af6db9f', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 7, 'created': '2013-07-12 04:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0732dd024d5f7b1083b0cc56223954a4ba828aed', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 8, 'created': '2013-07-12 22:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6eb304f2cede3ce11345bd228f71e7e4545cc45d', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 9, 'created': '2013-07-15 19:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7d23df92204703180c4fa9550f7d880c09b185e6', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 10, 'created': '2013-07-15 19:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/79e87c83d674808ae3c79b5ad690f51f37a31fe6', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 11, 'created': '2013-07-16 04:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/aa2cf49dc38ea97fd0f3b1a284e3cec4f7c4ba6f', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 13, 'created': '2013-07-16 18:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/743497783adb2b7b59f5ab1673b8a2856306bf0f', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 12, 'created': '2013-07-16 18:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/00236b1969fb634249815361d6dc8e966d45ec24', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 14, 'created': '2013-07-17 00:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2a4750d0d6e946ae0f5ecc4b2900b97c756154ae', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 15, 'created': '2013-07-17 02:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dcb130ef97704c3c04f63214e4a18577755b8ea9', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 16, 'created': '2013-07-17 03:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6d7783a852b742bbaa4501acfed3eb32d5fa690d', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 17, 'created': '2013-07-17 05:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4a251ef44fc8fdfb163d849a8f2cddcb2798ea7d', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 18, 'created': '2013-07-17 05:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5734855330ec126ee0bc114ef038db1b9e7cae7b', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}, {'number': 19, 'created': '2013-07-17 05:37:48.000000000', 'files': ['keystone/auth/controllers.py', 'keystone/common/config.py', 'keystone/auth/plugins/external.py', 'keystone/token/providers/uuid.py', 'doc/source/configuration.rst', 'keystone/auth/plugins/token.py', 'tests/test_v3_auth.py', 'tests/test_token_bind.py', 'keystone/common/wsgi.py', 'etc/keystone.conf.sample', 'tests/test_auth.py', 'keystone/token/controllers.py', 'keystone/common/controller.py', 'tests/auth_plugin_external_domain.conf'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2667c772a30c16ca147f8e38143b59ac53ec5b0c', 'message': 'Implement Token Binding.\n\nBrings token binding to keystone server. There are a number of places\nwhere the location or hardcoding of binding checks are not optimal\nhowever fixing them will require having a proper authentication plugin\nscheme so just assume that they will be moved when that happens.\n\nDocImpact\nImplements: blueprint authentication-tied-to-token\nChange-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd\n'}]",44,35093,2667c772a30c16ca147f8e38143b59ac53ec5b0c,68,9,19,7191,,,0,"Implement Token Binding.

Brings token binding to keystone server. There are a number of places
where the location or hardcoding of binding checks are not optimal
however fixing them will require having a proper authentication plugin
scheme so just assume that they will be moved when that happens.

DocImpact
Implements: blueprint authentication-tied-to-token
Change-Id: Ib34e5e0b6bd83837f6addbd45d4c5b828ce2f3bd
",git fetch https://review.opendev.org/openstack/keystone refs/changes/93/35093/9 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_auth.py', 'keystone/auth/controllers.py', 'keystone/token/controllers.py', 'keystone/common/config.py', 'keystone/auth/token_factory.py', 'keystone/common/controller.py', 'tests/test_v3_auth.py', 'tests/test_token_bind.py', 'keystone/common/wsgi.py']",9,c66f936e6f95db6044e60159639a3e742508eef9,bp/authentication-tied-to-token,"def validate_token_bind(context, token_ref): bind = token_ref.get('bind', {}) bind_mode = CONF.token.enforce_token_bind if bind_mode == 'disabled': return # permissive and strict modes don't require there to be a bind permissive = bind_mode in ('permissive', 'strict') # get the named mode if bind_mode is not one of the known name = None if permissive or bind_mode == 'required' else bind_mode if len(bind) == 0: if permissive: return else: LOG.info(""No bind information present in token"") raise exception.Unauthorized() if name and name not in bind: LOG.info(""Named bind mode %s not in bind information"", name) raise exception.Unauthorized() for bind_type, identifier in bind.iteritems(): if bind_type == 'kerberos': if not (context.get('AUTH_TYPE', '').lower() == 'negotiate' and context.get('REMOTE_USER') == identifier): LOG.info(""Kerberos credentials not present or do not match"") raise exception.Unauthorized() elif bind_mode == 'permissive': LOG.info(""Ignoring Unknown bind for permissive mode: "" ""{%s: %s}"", bind_type, identifier) else: LOG.info(""Couldn't verify unknown bind: {%s: %s}"", bind_type, identifier) raise exception.Unauthorized() for name in ['REMOTE_USER', 'AUTH_TYPE']: try: context[name] = req.environ[name] except KeyError: try: del context[name] except KeyError: pass validate_token_bind(context, user_token_ref)"," if 'REMOTE_USER' in req.environ: context['REMOTE_USER'] = req.environ['REMOTE_USER'] elif context.get('REMOTE_USER', None) is not None: del context['REMOTE_USER']",364,19
openstack%2Fkeystone~master~Icdc4400f08f4619a19e44129c78240800a3a1e75,openstack/keystone,master,Icdc4400f08f4619a19e44129c78240800a3a1e75,Implemented token creation without catalog response.,MERGED,2013-06-16 06:40:55.000000000,2013-07-17 06:23:47.000000000,2013-07-17 06:23:47.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 994}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 5971}, {'_account_id': 6486}, {'_account_id': 7052}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-06-16 06:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/43ffa8f69ad879511b4050ae3c3db4a2c72bd467', 'message': 'bp/catalog opt-out for token creation\n\nExtended the auth/token api to request a token without the\ncatalog to be returned.\nAdded a specific get v3/catalog method that only returns the\ncatalog\n\nAuthor: Fabio Giannetti (fabio.giannetti@hp.com)\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 2, 'created': '2013-06-16 06:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1bc519b2c3843ca1ee0854a0133c79fddc3d3100', 'message': 'bp/catalog opt-out for token creation\n\nExtended the auth/token api to request a token without the\ncatalog to be returned.\nAdded a specific get v3/catalog method that only returns the\ncatalog\n\nAuthor: Fabio Giannetti (fabio.giannetti@hp.com)\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 3, 'created': '2013-06-17 17:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/df3f1e43792e23275fa187389e8c4036154cdc7e', 'message': 'bp/catalog opt-out for token creation\n\nExtended the auth/token api to request a token without the\ncatalog to be returned.\nAdded a specific get v3/catalog method that only returns the\ncatalog\n\nAuthor: Fabio Giannetti (fabio.giannetti@hp.com)\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 4, 'created': '2013-06-17 17:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f92817282f38ee6e09196dece13d8785c02a8487', 'message': 'bp/catalog opt-out for token creation\n\nExtended the auth/token api to request a token without the\ncatalog to be returned.\nAdded a specific get v3/catalog method that only returns the\ncatalog\n\nAuthor: Fabio Giannetti (fabio.giannetti@hp.com)\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 5, 'created': '2013-06-18 23:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8446477da77ade553df9b646f9ec8d8907c262ac', 'message': 'bp/catalog opt-out for token creation\n\nExtended the auth/token api to request a token without the\ncatalog to be returned.\nAdded a specific get v3/catalog method that only returns the\ncatalog\n\nAuthor: Fabio Giannetti (fabio.giannetti@hp.com)\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 6, 'created': '2013-06-20 22:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5b8d01ff9a3031007b3ae901215bffec816be087', 'message': 'bp/catalog opt-out for token creation\n\nExtended the auth/token api to request a token without the\ncatalog to be returned.\nAdded a specific get v3/catalog method that only returns the\ncatalog\n\nAuthor: Fabio Giannetti (fabio.giannetti@hp.com)\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 7, 'created': '2013-06-25 21:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5a57c1bfe2e7b2b0fcf1474e185e6b954655e214', 'message': 'bp/catalog opt-out for token creation\n\nhttps://blueprints.launchpad.net/keystone/+spec/catalog-optional\n\nExtended the auth/token api to request a token without the\ncatalog to be returned.\nAdded a specific get v3/catalog method that only returns the\ncatalog\n\nAuthor: Fabio Giannetti (fabio.giannetti@hp.com)\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 8, 'created': '2013-06-25 23:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9a036c2e61645d727fce271d6895a600c1eaa944', 'message': 'bp/catalog opt-out for token creation\n\nhttps://blueprints.launchpad.net/keystone/+spec/catalog-optional\n\nExtended the auth/token api to request a token without the\ncatalog to be returned.\nAdded a specific get v3/catalog method that only returns the\ncatalog\n\nAuthor: Fabio Giannetti (fabio.giannetti@hp.com)\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 9, 'created': '2013-06-27 18:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/48f11fb5e9618d69c7d5047ba638c3d411eca31b', 'message': 'bp/catalog-optional\n\n   Implemented the methods changes introduced by the blueprint\n\n   Modified the token_factory to create token responses with\n   or without the catalog entry.\n\n   Added to the catalog router and controller new methods to\n   handle the GET /v3/catalog request. This request uses a token\n   to validate the requestor and gather both user_id and\n   project_id.\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 10, 'created': '2013-06-27 22:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9d7ad3b7b4306295d3b3f654a0dfc1608443f903', 'message': 'Implemented POST /v3/auth/tokens?no-catalog and GET /v3/catalog\nmethods.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nAdded to the catalog router and controller new methods to\nhandle the GET /v3/catalog request. This request uses a token\nto validate the requestor and gather both user_id and\nproject_id.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 11, 'created': '2013-06-27 23:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8a435dd7b0bae83f1f7c58512cd1c7629e2772c4', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nAdded to the catalog router and controller new methods to\nhandle the GET /v3/catalog request. This request uses a token\nto validate the requestor and gather both user_id and\nproject_id.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 12, 'created': '2013-07-05 17:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/771290cd57b960aac3925aa5a4a13f9c867ed563', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nAdded to the catalog router and controller new methods to\nhandle the GET /v3/catalog request. This request uses a token\nto validate the requestor and gather both user_id and\nproject_id.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 13, 'created': '2013-07-09 23:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3571dd7ddd326a6882369ebb48f989fc192d202d', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 14, 'created': '2013-07-10 20:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ab6e166c7a61fb172fbe359b1f48beca53721d0d', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 15, 'created': '2013-07-11 22:37:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3d5ef773750872465ce3a48dab9a19ec1f855ee3', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 16, 'created': '2013-07-12 21:04:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bce27e596ebe9be8ea469ff5312a898578b429c3', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 17, 'created': '2013-07-16 21:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0d04b740344d0b491ea1d142c6d29f6ef363517e', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 18, 'created': '2013-07-16 21:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/689a08a252bd55ca986808fe8f4af799e2911d6e', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 19, 'created': '2013-07-16 21:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d39551f85429d0de53cc2ac8c8197f3e0af45c3e', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 20, 'created': '2013-07-17 01:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e9198f63558900d2a412c6310e8953092790dd12', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 21, 'created': '2013-07-17 01:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2efe035bcb05e14846317e8f06b7673ce326d1b4', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 22, 'created': '2013-07-17 03:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/94609c0ec2f915794410efd8e188a1c6e9225dd2', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 23, 'created': '2013-07-17 03:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/94c9082a61540c5086ab9006c14a76d5aab29074', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}, {'number': 24, 'created': '2013-07-17 05:25:36.000000000', 'files': ['tests/test_auth.py', 'keystone/auth/controllers.py', 'tests/test_v3.py', 'keystone/token/providers/uuid.py', 'tests/test_v3_auth.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/53a03b53e7541367c07df6d4f6739173330f5353', 'message': 'Implemented token creation without catalog response.\n\nModified the token_factory to create token responses with\nor without the catalog entry.\n\nblueprint catalog-optional\n\nChange-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75\n'}]",44,33188,53a03b53e7541367c07df6d4f6739173330f5353,103,12,24,7052,,,0,"Implemented token creation without catalog response.

Modified the token_factory to create token responses with
or without the catalog entry.

blueprint catalog-optional

Change-Id: Icdc4400f08f4619a19e44129c78240800a3a1e75
",git fetch https://review.opendev.org/openstack/keystone refs/changes/88/33188/6 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/auth/token_factory.py', 'keystone/catalog/backends/sql.py', 'keystone/catalog/routers.py', 'etc/ec2rc', 'etc/keystone.conf~', 'keystone/identity/backends/sql.py~', 'keystone/auth/token_factory.py~', 'keystone/catalog/backends/sql.py~', 'keystone/catalog/controllers.py']",9,43ffa8f69ad879511b4050ae3c3db4a2c72bd467,bp/authentication-tied-to-token," def get_catalog(self, context): refs = self.catalog_api.get_v3_catalog(context) return { ""catalog"" : refs } @controller.protected",,1913,7
openstack%2Fcinder~master~I7d23a980f237c973538ca08215f77a1f69cc2517,openstack/cinder,master,I7d23a980f237c973538ca08215f77a1f69cc2517,Minor reorg for (array resource usage and backend options naming),MERGED,2013-07-12 01:35:33.000000000,2013-07-17 06:23:45.000000000,2013-07-17 06:23:45.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}]","[{'number': 1, 'created': '2013-07-12 01:35:33.000000000', 'files': ['etc/cinder/rootwrap.d/volume.filters', 'cinder/volume/drivers/hds/hus_backend.py', 'cinder/volume/drivers/hds/hds.py', 'cinder/tests/test_hds.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e25c105740bb8a10ad05b188f8262af940539baa', 'message': 'Minor reorg for (array resource usage and backend options naming)\n\n1. Use HUS target/initiator resources efficiently.\n2. Command options aligned with openStack scheme of using dashes.\n3. Self tests modified to accomodate #1 and #2.\n\nChange-Id: I7d23a980f237c973538ca08215f77a1f69cc2517\nFixes: bug 1200441\n'}]",0,36759,e25c105740bb8a10ad05b188f8262af940539baa,10,4,1,7447,,,0,"Minor reorg for (array resource usage and backend options naming)

1. Use HUS target/initiator resources efficiently.
2. Command options aligned with openStack scheme of using dashes.
3. Self tests modified to accomodate #1 and #2.

Change-Id: I7d23a980f237c973538ca08215f77a1f69cc2517
Fixes: bug 1200441
",git fetch https://review.opendev.org/openstack/cinder refs/changes/59/36759/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/rootwrap.d/volume.filters', 'cinder/volume/drivers/hds/hus_backend.py', 'cinder/volume/drivers/hds/hds.py', 'cinder/tests/test_hds.py']",4,e25c105740bb8a10ad05b188f8262af940539baa,bug/1200441," init_index = 0 # initiator index target_index = 0 # target index hlun = 0 # hlun index def get_version(self, cmd, ver, ip0, ip1, user, pw): def get_iscsi_info(self, cmd, ver, ip0, ip1, user, pw): def get_hdp_info(self, cmd, ver, ip0, ip1, user, pw): def create_lu(self, cmd, ver, ip0, ip1, user, pw, id, hdp, start, end, size): def delete_lu(self, cmd, ver, ip0, ip1, user, pw, id, lun): def create_dup(self, cmd, ver, ip0, ip1, user, pw, id, src_lun, def add_iscsi_conn(self, cmd, ver, ip0, ip1, user, pw, id, lun, ctl, port, iqn, initiator): conn = (self.hlun, lun, initiator, self.init_index, iqn, self.target_index, ctl, port) out = (""H-LUN: %d mapped. LUN: %s, iSCSI Initiator: %s @ index: %d, \ and Target: %s @ index %d is successfully paired @ CTL: %s, \ Port: %s"" % conn) self.init_index += 1 self.target_index += 1 self.hlun += 1 def del_iscsi_conn(self, cmd, ver, ip0, ip1, user, pw, id, lun, ctl, port, iqn, initiator, force): conn = () for connection in SimulatedHusBackend.connections: if (connection[1] == lun): conn = connection SimulatedHusBackend.connections.remove(connection) if conn is None: return (hlun, lun, initiator, init_index, iqn, target_index, ctl, port) = conn detail = (hlun, iqn) out = (""H-LUN: %d successfully deleted from target %s"" % detail) self.mox.StubOutWithMock(self.driver, '_update_vol_location') vol['provider_location'] = conn['data']['provider_location']"," def get_version(self, cmd, ip0, ip1, user, pw): def get_iscsi_info(self, cmd, ip0, ip1, user, pw): def get_hdp_info(self, cmd, ip0, ip1, user, pw): def create_lu(self, cmd, ip0, ip1, user, pw, id, hdp, start, end, size): def delete_lu(self, cmd, ip0, ip1, user, pw, id, lun): def create_dup(self, cmd, ip0, ip1, user, pw, id, src_lun, def add_iscsi_conn(self, cmd, ip0, ip1, user, pw, id, lun, ctl, port, iqn, tgt_alias, initiator, init_alias): conn = (initiator, iqn, ctl, port) out = (""iSCSI Initiator: %s, index: 26, and Target: %s, index 8 is \ successfully paired @ CTL: %s, Port: %s"" % conn) def del_iscsi_conn(self, cmd, ip0, ip1, user, pw, id, lun, ctl, port, iqn, initiator, force): conn = (initiator, iqn, ctl, port) out = (""iSCSI Initiator: %s, index: 26, and Target: %s, index 8 is \ successfully un-paired @ CTL: %s, Port: %s"" % conn) if conn in SimulatedHusBackend.connections: SimulatedHusBackend.connections.remove(conn)",100,60
openstack%2Fhorizon~master~Ie9f2040850df3d7f1fcefe68430e9103c972f80f,openstack/horizon,master,Ie9f2040850df3d7f1fcefe68430e9103c972f80f,Adding Heat Resource Topology to Horizon,MERGED,2013-07-09 22:12:11.000000000,2013-07-17 06:23:43.000000000,2013-07-17 06:23:42.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 1941}, {'_account_id': 2834}, {'_account_id': 4571}, {'_account_id': 5623}, {'_account_id': 6434}, {'_account_id': 6917}, {'_account_id': 7256}, {'_account_id': 7714}]","[{'number': 1, 'created': '2013-07-09 22:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c29880bd1442b75af75cd8287b950870983f216f', 'message': 'Adding Heat Resource Topology to Horizon\n\nChange-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f\nImplements: blueprint heat-ui-resource-topology\n'}, {'number': 2, 'created': '2013-07-10 19:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bf46ce402c6537e7116f3d139a83a2a577982b8e', 'message': 'Adding Heat Resource Topology to Horizon\n\nChange-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f\nImplements: blueprint heat-ui-resource-topology\n'}, {'number': 3, 'created': '2013-07-11 19:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c0263c36ae07c815275e744924eb5a7b38ece3fa', 'message': 'Adding Heat Resource Topology to Horizon\n\nChange-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f\nImplements: blueprint heat-ui-resource-topology\n'}, {'number': 4, 'created': '2013-07-11 19:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/41d8a9e2b159f3778d92055527cc0cd55972781e', 'message': 'Adding Heat Resource Topology to Horizon\n\nChange-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f\nImplements: blueprint heat-ui-resource-topology\n'}, {'number': 5, 'created': '2013-07-11 21:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ad4d2a880ccb768aaf83fc8b657c30ba64845eb6', 'message': 'Adding Heat Resource Topology to Horizon\n\nChange-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f\nImplements: blueprint heat-ui-resource-topology\n'}, {'number': 6, 'created': '2013-07-15 19:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/283f03815401934c822cf517bf6bc5109dfb4814', 'message': 'Adding Heat Resource Topology to Horizon\n\nChange-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f\nImplements: blueprint heat-ui-resource-topology\n'}, {'number': 7, 'created': '2013-07-15 20:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6fbcdc60a909560f9665d7c3ec0828fb2dbaddf7', 'message': 'Adding Heat Resource Topology to Horizon\n\nChange-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f\nImplements: blueprint heat-ui-resource-topology\n'}, {'number': 8, 'created': '2013-07-16 22:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5f56760636d680388c4c242c509bdb202e054171', 'message': 'Adding Heat Resource Topology to Horizon\n\nChange-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f\nImplements: blueprint heat-ui-resource-topology\n'}, {'number': 9, 'created': '2013-07-16 22:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ee4521cd5951e705a8f613d07a897ec02cde49be', 'message': 'Adding Heat Resource Topology to Horizon\n\nChange-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f\nImplements: blueprint heat-ui-resource-topology\n'}, {'number': 10, 'created': '2013-07-16 23:33:22.000000000', 'files': ['openstack_dashboard/static/dashboard/img/db-red.svg', 'openstack_dashboard/dashboards/project/stacks/sro.py', 'openstack_dashboard/static/dashboard/img/stack-gray.svg', 'openstack_dashboard/static/dashboard/img/unknown-gray.gif', 'openstack_dashboard/static/dashboard/img/server-red.svg', 'openstack_dashboard/dashboards/project/stacks/views.py', 'openstack_dashboard/dashboards/project/stacks/urls.py', 'openstack_dashboard/static/dashboard/img/server-gray.gif', 'openstack_dashboard/static/dashboard/img/db-gray.svg', 'openstack_dashboard/static/dashboard/img/stack-red.svg', 'openstack_dashboard/static/dashboard/img/server-green.svg', 'openstack_dashboard/static/dashboard/img/lb-gray.svg', 'horizon/static/horizon/js/horizon.heattop.js', 'openstack_dashboard/dashboards/project/stacks/tabs.py', 'openstack_dashboard/static/dashboard/img/stack-gray.gif', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/_stack_info.html', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/_detail_topology.html', 'openstack_dashboard/static/dashboard/img/unknown-green.svg', 'horizon/templates/horizon/_scripts.html', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/_resource_info.html', 'openstack_dashboard/static/dashboard/img/lb-red.svg', 'openstack_dashboard/static/dashboard/img/db-gray.gif', 'openstack_dashboard/static/dashboard/img/server-gray.svg', 'openstack_dashboard/static/dashboard/less/horizon.less', 'openstack_dashboard/static/dashboard/img/lb-green.svg', 'openstack_dashboard/static/dashboard/img/stack-green.svg', 'openstack_dashboard/static/dashboard/img/unknown-red.svg', 'openstack_dashboard/static/dashboard/img/db-green.svg', 'openstack_dashboard/static/dashboard/img/lb-gray.gif', 'openstack_dashboard/dashboards/project/stacks/api.py', 'openstack_dashboard/dashboards/project/stacks/mappings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8914ed95fc8fa44771f5f3ec827e325a5855b60a', 'message': 'Adding Heat Resource Topology to Horizon\n\nChange-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f\nImplements: blueprint heat-ui-resource-topology\n'}]",5,36351,8914ed95fc8fa44771f5f3ec827e325a5855b60a,43,10,10,7714,,,0,"Adding Heat Resource Topology to Horizon

Change-Id: Ie9f2040850df3d7f1fcefe68430e9103c972f80f
Implements: blueprint heat-ui-resource-topology
",git fetch https://review.opendev.org/openstack/horizon refs/changes/51/36351/8 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/dashboard/img/db-red.svg', 'openstack_dashboard/dashboards/project/resource_topology/api.py', 'openstack_dashboard/dashboards/project/resource_topology/templates/resource_topology/index.html', 'openstack_dashboard/static/dashboard/img/stack-gray.svg', 'openstack_dashboard/dashboards/project/resource_topology/views.py', 'openstack_dashboard/static/dashboard/img/server-red.svg', 'openstack_dashboard/dashboards/project/resource_topology/panel.py', 'openstack_dashboard/static/dashboard/img/server-gray.gif', 'openstack_dashboard/static/dashboard/img/stack-red.svg', 'openstack_dashboard/dashboards/project/resource_topology/templates/resource_topology/_resource_info.html', 'openstack_dashboard/static/dashboard/img/server-green.svg', 'openstack_dashboard/static/dashboard/img/lb-gray.svg', 'openstack_dashboard/dashboards/project/resource_topology/templates/resource_topology/_stack_info.html', 'horizon/static/horizon/js/horizon.heattop.js', 'openstack_dashboard/dashboards/project/dashboard.py', 'openstack_dashboard/static/dashboard/img/stack-gray.gif', 'openstack_dashboard/dashboards/project/resource_topology/__init__.py', 'horizon/templates/horizon/_scripts.html', 'openstack_dashboard/static/dashboard/img/lb-red.svg', 'openstack_dashboard/dashboards/project/resource_topology/sro.py', 'openstack_dashboard/static/dashboard/img/server-gray.svg', 'openstack_dashboard/static/dashboard/less/horizon.less', 'openstack_dashboard/static/dashboard/img/lb-green.svg', 'openstack_dashboard/static/dashboard/img/stack-green.svg', 'openstack_dashboard/dashboards/project/resource_topology/urls.py', 'openstack_dashboard/static/dashboard/img/lb-gray.gif']",26,c29880bd1442b75af75cd8287b950870983f216f,bp/heat-ui-resource-topology,,,1195,1
openstack%2Fnova~master~Ib5a593bd36c8d6a531b9494b9861cca9a40ed08a,openstack/nova,master,Ib5a593bd36c8d6a531b9494b9861cca9a40ed08a,Replace get_instance_metadata call in api.ec2.cloud._format_instances,MERGED,2013-07-09 15:37:37.000000000,2013-07-17 06:23:25.000000000,2013-07-17 06:23:22.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1313}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 6172}, {'_account_id': 6624}, {'_account_id': 6661}]","[{'number': 1, 'created': '2013-07-09 15:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49dc373044d9ab794507756c98fbd4fc75df1e43', 'message': 'Remove unnecessary get_instance_metadata call\n\nThe _format_instances method in api.ec2.cloud populates an instance\ndictionary from the sqlalchemy instance model objects, and populates the\nmetadata by calling compute.api.get_instance_metadata.\n\nThis is unnecessary, since the instance objects already have metadata\nattached. The helper class is needed until the migration to nova objects\nis complete.\n\nReplace get_instance_metadata call in api.ec2.cloud._format_instances\n\nPartially fixes bug #1192715\n\nChange-Id: Ib5a593bd36c8d6a531b9494b9861cca9a40ed08a\n'}, {'number': 2, 'created': '2013-07-09 15:40:24.000000000', 'files': ['nova/api/ec2/cloud.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/08559964bd209de823fd5e4738519514172d0b26', 'message': 'Replace get_instance_metadata call in api.ec2.cloud._format_instances\n\nThe _format_instances method in api.ec2.cloud populates an instance\ndictionary from the sqlalchemy instance model objects, and populates the\nmetadata by calling compute.api.get_instance_metadata.\n\nThis is unnecessary, since the instance objects already have metadata\nattached. The helper class is needed until the migration to nova objects\nis complete.\n\nPartially fixes bug #1192715\n\nChange-Id: Ib5a593bd36c8d6a531b9494b9861cca9a40ed08a\n'}]",0,36241,08559964bd209de823fd5e4738519514172d0b26,16,8,2,6661,,,0,"Replace get_instance_metadata call in api.ec2.cloud._format_instances

The _format_instances method in api.ec2.cloud populates an instance
dictionary from the sqlalchemy instance model objects, and populates the
metadata by calling compute.api.get_instance_metadata.

This is unnecessary, since the instance objects already have metadata
attached. The helper class is needed until the migration to nova objects
is complete.

Partially fixes bug #1192715

Change-Id: Ib5a593bd36c8d6a531b9494b9861cca9a40ed08a
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/36241/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/ec2/cloud.py'],1,49dc373044d9ab794507756c98fbd4fc75df1e43,bug/1192715," for k, v in utils.instance_meta(instance).iteritems():"," for k, v in self.compute_api.get_instance_metadata( context, instance).iteritems():",2,2
openstack%2Fcinder~master~I2b1701269bdf7c8737548e57bd940921a6256372,openstack/cinder,master,I2b1701269bdf7c8737548e57bd940921a6256372,remove improper assert usage,MERGED,2013-07-11 04:18:35.000000000,2013-07-17 06:23:14.000000000,2013-07-17 06:23:14.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-07-11 04:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6933c0b8d01c0b481220f41fb5a2a215f06a4333', 'message': ""remove improper assert usage\n\nThere're many talks about it. An assert should be used for `never\nhappen` cases, not common paramaters validating.\n\nWith grep, we could many all assert statement used in none-test codes:\n\ncinder/volume/drivers/san/solaris.py:110:\ncinder/volume/drivers/san/solaris.py:116:\ncinder/volume/drivers/san/solaris.py:161:\ncinder/volume/drivers/san/solaris.py:162:\ncinder/volume/drivers/san/solaris.py:163:\ncinder/volume/drivers/san/solaris.py:164:\ncinder/volume/drivers/san/solaris.py:170:\n    checking cmd output which should never changed, so leave it\ncinder/db/sqlalchemy/migration.py:113:\n    ensure file existence from impossible cases, so leave it\ncinder/utils.py:\n    used for functional flow, so use ValueError instead\n\nChange-Id: I2b1701269bdf7c8737548e57bd940921a6256372\n""}, {'number': 2, 'created': '2013-07-11 04:22:57.000000000', 'files': ['cinder/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/718a5293bc9ac36f5cbccb35296322fd7446f36d', 'message': ""remove improper assert usage\n\nThere're many talks about it. An assert should be used for `never\nhappen` cases, not common paramaters validating.\n\nWith grep, we could many all assert statement used in none-test codes:\n\ncinder/volume/drivers/san/solaris.py:110:\ncinder/volume/drivers/san/solaris.py:116:\ncinder/volume/drivers/san/solaris.py:161:\ncinder/volume/drivers/san/solaris.py:162:\ncinder/volume/drivers/san/solaris.py:163:\ncinder/volume/drivers/san/solaris.py:164:\ncinder/volume/drivers/san/solaris.py:170:\n    checking cmd output which should never changed, so leave it\ncinder/db/sqlalchemy/migration.py:113:\n    ensure file existence from impossible cases, so leave it\ncinder/utils.py:\n    used for functional flow, so use ValueError instead\n\nfixes bug #1199354\nChange-Id: I2b1701269bdf7c8737548e57bd940921a6256372\n""}]",0,36602,718a5293bc9ac36f5cbccb35296322fd7446f36d,16,5,2,6835,,,0,"remove improper assert usage

There're many talks about it. An assert should be used for `never
happen` cases, not common paramaters validating.

With grep, we could many all assert statement used in none-test codes:

cinder/volume/drivers/san/solaris.py:110:
cinder/volume/drivers/san/solaris.py:116:
cinder/volume/drivers/san/solaris.py:161:
cinder/volume/drivers/san/solaris.py:162:
cinder/volume/drivers/san/solaris.py:163:
cinder/volume/drivers/san/solaris.py:164:
cinder/volume/drivers/san/solaris.py:170:
    checking cmd output which should never changed, so leave it
cinder/db/sqlalchemy/migration.py:113:
    ensure file existence from impossible cases, so leave it
cinder/utils.py:
    used for functional flow, so use ValueError instead

fixes bug #1199354
Change-Id: I2b1701269bdf7c8737548e57bd940921a6256372
",git fetch https://review.opendev.org/openstack/cinder refs/changes/02/36602/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/utils.py'],1,6933c0b8d01c0b481220f41fb5a2a215f06a4333,bug/1199354," elif isinstance(value, str): return value else: raise ValueError(""%s is not a string"" % value) in items, looks up items[prop1][prop2][prop3]. Like XPath, if any of the"," Code is directly from the utf8 function in http://github.com/facebook/tornado/blob/master/tornado/escape.py assert isinstance(value, str) return value in items, looks up items[prop1][prop2][prop3]. Like XPath, if any of the",5,6
openstack%2Fnova~master~I088f3438c1cb4496bcac64069c047f2c8c58450d,openstack/nova,master,I088f3438c1cb4496bcac64069c047f2c8c58450d,PCI passthrough Libvirt layer WIP,ABANDONED,2013-04-18 19:01:33.000000000,2013-07-17 06:03:09.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 2667}, {'_account_id': 3217}, {'_account_id': 4393}, {'_account_id': 4573}, {'_account_id': 6172}, {'_account_id': 6904}, {'_account_id': 7543}, {'_account_id': 7854}]","[{'number': 1, 'created': '2013-04-18 19:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80282177e779f60ddf7d7f6b7fd744cf03d925f3', 'message': 'PCI Passthrough Base\n\nThe goal of this patch is to add base support for pci passthrough in Nova.\n\nThis patch was based on ISP RAS solution and after rebase and refactor I am not\nsure that there is no type/bugs, because I haven\'t enough time to run real\ndeployement and try to create instance with pci device..\n(But ISP RAS patch is well tested and concept works)\n\nHow it works?\nIt could be split in separated parts:\n    1)  Scheduler layer (filter)\n    2)  DB layer (store)\n    3)  CONF layer (input)\n    4)  Compute layer (save pci and instance state in DB)\n    5)  Virt layer (libvirt pci device passthrough)\n\n1) Scheduler layer (filter):\n\nThis is probably the main part and most complex for implementation.\n\nFirst of all what we have?\nA lot of compute nodes where we have a lot of devices that could be used\nfor pci passthrouhg. We should be able to filter compute nodes by devices that\nit has and that are in same time free (it is not used by any other VM).\n\nTo be able to slove it we should:\na) Store information about PCI devices on each host and availability status\nb) On different hosts same devices could have different addresses so we should\n   use some more abstract name. I\'ve called it labels.\nc) To store information about what pci devices are required for instance I used\n   InstanceTypeExtraSpecs pcipasthrouhg:labels that contains list of labels in\n   json\nd) Compute node should have information about pci devices\n\nIf we have all this things then algorithm of filtering hosts is pretty simple:\n    a) Get info about all hosts with all pci devices\n    b) Get labels from instance type that are required\n    c) filter all hosts that have required labels\n    d) consume info from selected host (now labels are used)\n    e) rpc to selected host run this instance\n\n2) DB layer (store)\nSo we should create new table for pci devices that should have next columns:\n\na) label (This is abstract name of device for example infiniband)\nb) adress (This is real pci address domain:slot:bus.function)\nc) status\nd) instance_uuid (instance that uses this device)\ne) host\nf) compute_id (compute_node_id on that has this device)\n\nSo there is only few method that we are actuilly use:\n1) destroy all on host devices\n2) attach to instance devices with labels from array\n3) create device\n\nAbout these methods I will tell later..\n\n3)  CONF layer (input)\nTo specify devices that are able on host I used nova.conf.\nAdd new parameter pci_passthrouhg_devices that has json string that contains\nlist of objects {""address"":string, ""label"":string}\n\nBut there is a big problem with storeing infromation about pci devices and\nupdating DB. It could be described by next situation:\n\n    a) specify pci device in nova.conf\n    b) run compute node and create specified pci device\n    c) run instance with this device\n\nAnd then you would like probably to modify this parameter...\n\nSo the algorithm is next:\nOn each periodic task sync_compute_node we are calling sync_pci_device.\nsync_pci_device make next thing:\nfirst time it makes:\n    a) delete all old pci_devices from host that are not used\n    b) for devices that are used we are changing status -> to_delete\n    c) trying to create all new devices from confing. Store info about created.\nother times:\n    d) try to create devices that wasn\'t created. Store info about new created.\n\nto_delete is special status of pci_devices that will be destroyed after\ninstance that used it.\n\nSo it will update all pci device after some time..\n\n4) Compute layer (save pci and instance state in DB)\nWhen scheduler choosed host we should update or pci_device entries in db.\n(that are on specified host and in list of specified labels)\nIt is done with only one call of our db.api so there is no race condition.\n\n5) Virt layer (libvirt pci device passthrough)\nIt is pretty simple, we have instance with pci_devices that has address, so we\nshould detach from host this device and do reset.\n\nWhen we are creating libvirt domain we should add specific XML for pci\npassthrouhg, node is called `hostdev`.\n\nAnd there are some small hacks..\nWe are not able to suspend machine with pci devices.. So we should detach it\nfrom nede and then on resume return it. Same problem with snapshoting.\n\nChange-Id: I088f3438c1cb4496bcac64069c047f2c8c58450d\n'}, {'number': 2, 'created': '2013-04-18 20:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8038157c7b207ed6296688d5a793fd165166d447', 'message': 'PCI Passthrough Base\n\nThe goal of this patch is to add base support for pci passthrough in Nova.\n\nThis patch was based on ISP RAS solution and after rebase and refactor I am not\nsure that there is no type/bugs, because I haven\'t enough time to run real\ndeployement and try to create instance with pci device..\n(But ISP RAS patch is well tested and concept works)\n\nHow it works?\nIt could be split in separated parts:\n    1)  Scheduler layer (filter)\n    2)  DB layer (store)\n    3)  CONF layer (input)\n    4)  Compute layer (save pci and instance state in DB)\n    5)  Virt layer (libvirt pci device passthrough)\n\n1) Scheduler layer (filter):\n\nThis is probably the main part and most complex for implementation.\n\nFirst of all what we have?\nA lot of compute nodes where we have a lot of devices that could be used\nfor pci passthrouhg. We should be able to filter compute nodes by devices that\nit has and that are in same time free (it is not used by any other VM).\n\nTo be able to slove it we should:\na) Store information about PCI devices on each host and availability status\nb) On different hosts same devices could have different addresses so we should\n   use some more abstract name. I\'ve called it labels.\nc) To store information about what pci devices are required for instance I used\n   InstanceTypeExtraSpecs pcipasthrouhg:labels that contains list of labels in\n   json\nd) Compute node should have information about pci devices\n\nIf we have all this things then algorithm of filtering hosts is pretty simple:\n    a) Get info about all hosts with all pci devices\n    b) Get labels from instance type that are required\n    c) filter all hosts that have required labels\n    d) consume info from selected host (now labels are used)\n    e) rpc to selected host run this instance\n\n2) DB layer (store)\nSo we should create new table for pci devices that should have next columns:\n\na) label (This is abstract name of device for example infiniband)\nb) adress (This is real pci address domain:slot:bus.function)\nc) status\nd) instance_uuid (instance that uses this device)\ne) host\nf) compute_id (compute_node_id on that has this device)\n\nSo there is only few method that we are actuilly use:\n1) destroy all on host devices\n2) attach to instance devices with labels from array\n3) create device\n\nAbout these methods I will tell later..\n\n3)  CONF layer (input)\nTo specify devices that are able on host I used nova.conf.\nAdd new parameter pci_passthrouhg_devices that has json string that contains\nlist of objects {""address"":string, ""label"":string}\n\nBut there is a big problem with storeing infromation about pci devices and\nupdating DB. It could be described by next situation:\n\n    a) specify pci device in nova.conf\n    b) run compute node and create specified pci device\n    c) run instance with this device\n\nAnd then you would like probably to modify this parameter...\n\nSo the algorithm is next:\nOn each periodic task sync_compute_node we are calling sync_pci_device.\nsync_pci_device make next thing:\nfirst time it makes:\n    a) delete all old pci_devices from host that are not used\n    b) for devices that are used we are changing status -> to_delete\n    c) trying to create all new devices from confing. Store info about created.\nother times:\n    d) try to create devices that wasn\'t created. Store info about new created.\n\nto_delete is special status of pci_devices that will be destroyed after\ninstance that used it.\n\nSo it will update all pci device after some time..\n\n4) Compute layer (save pci and instance state in DB)\nWhen scheduler choosed host we should update or pci_device entries in db.\n(that are on specified host and in list of specified labels)\nIt is done with only one call of our db.api so there is no race condition.\n\n5) Virt layer (libvirt pci device passthrough)\nIt is pretty simple, we have instance with pci_devices that has address, so we\nshould detach from host this device and do reset.\n\nWhen we are creating libvirt domain we should add specific XML for pci\npassthrouhg, node is called `hostdev`.\n\nAnd there are some small hacks..\nWe are not able to suspend machine with pci devices.. So we should detach it\nfrom nede and then on resume return it. Same problem with snapshoting.\n\nChange-Id: I088f3438c1cb4496bcac64069c047f2c8c58450d\n'}, {'number': 3, 'created': '2013-04-18 21:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc2494a827a71f91f81c2a6e30f1565480d247a3', 'message': 'PCI Passthrough Base\n\nThe goal of this patch is to add base support for pci passthrough in Nova.\n\nThis patch was based on ISP RAS solution and after rebase and refactor I am not\nsure that there is no type/bugs, because I haven\'t enough time to run real\ndeployement and try to create instance with pci device..\n(But ISP RAS patch is well tested and concept works)\n\nHow it works?\nIt could be split in separated parts:\n    1)  Scheduler layer (filter)\n    2)  DB layer (store)\n    3)  CONF layer (input)\n    4)  Compute layer (save pci and instance state in DB)\n    5)  Virt layer (libvirt pci device passthrough)\n\n1) Scheduler layer (filter):\n\nThis is probably the main part and most complex for implementation.\n\nFirst of all what we have?\nA lot of compute nodes where we have a lot of devices that could be used\nfor pci passthrouhg. We should be able to filter compute nodes by devices that\nit has and that are in same time free (it is not used by any other VM).\n\nTo be able to slove it we should:\na) Store information about PCI devices on each host and availability status\nb) On different hosts same devices could have different addresses so we should\n   use some more abstract name. I\'ve called it labels.\nc) To store information about what pci devices are required for instance I used\n   InstanceTypeExtraSpecs pcipasthrouhg:labels that contains list of labels in\n   json\nd) Compute node should have information about pci devices\n\nIf we have all this things then algorithm of filtering hosts is pretty simple:\n    a) Get info about all hosts with all pci devices\n    b) Get labels from instance type that are required\n    c) filter all hosts that have required labels\n    d) consume info from selected host (now labels are used)\n    e) rpc to selected host run this instance\n\n2) DB layer (store)\nSo we should create new table for pci devices that should have next columns:\n\na) label (This is abstract name of device for example infiniband)\nb) adress (This is real pci address domain:slot:bus.function)\nc) status\nd) instance_uuid (instance that uses this device)\ne) host\nf) compute_id (compute_node_id on that has this device)\n\nSo there is only few method that we are actuilly use:\n1) destroy all on host devices\n2) attach to instance devices with labels from array\n3) create device\n\nAbout these methods I will tell later..\n\n3)  CONF layer (input)\nTo specify devices that are able on host I used nova.conf.\nAdd new parameter pci_passthrouhg_devices that has json string that contains\nlist of objects {""address"":string, ""label"":string}\n\nBut there is a big problem with storeing infromation about pci devices and\nupdating DB. It could be described by next situation:\n\n    a) specify pci device in nova.conf\n    b) run compute node and create specified pci device\n    c) run instance with this device\n\nAnd then you would like probably to modify this parameter...\n\nSo the algorithm is next:\nOn each periodic task sync_compute_node we are calling sync_pci_device.\nsync_pci_device make next thing:\nfirst time it makes:\n    a) delete all old pci_devices from host that are not used\n    b) for devices that are used we are changing status -> to_delete\n    c) trying to create all new devices from confing. Store info about created.\nother times:\n    d) try to create devices that wasn\'t created. Store info about new created.\n\nto_delete is special status of pci_devices that will be destroyed after\ninstance that used it.\n\nSo it will update all pci device after some time..\n\n4) Compute layer (save pci and instance state in DB)\nWhen scheduler choosed host we should update or pci_device entries in db.\n(that are on specified host and in list of specified labels)\nIt is done with only one call of our db.api so there is no race condition.\n\n5) Virt layer (libvirt pci device passthrough)\nIt is pretty simple, we have instance with pci_devices that has address, so we\nshould detach from host this device and do reset.\n\nWhen we are creating libvirt domain we should add specific XML for pci\npassthrouhg, node is called `hostdev`.\n\nAnd there are some small hacks..\nWe are not able to suspend machine with pci devices.. So we should detach it\nfrom nede and then on resume return it. Same problem with snapshoting.\n\nChange-Id: I088f3438c1cb4496bcac64069c047f2c8c58450d\n'}, {'number': 4, 'created': '2013-06-27 00:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba693f6d9280ce9cb6b40f78216572ebe7174a77', 'message': 'PCI passthrough Libvirt layer WIP\n\nShould address all that said Daniel Berrange\nand write commit description =)\n\nblueprint pci-passthrough-libvirt\n\nChange-Id: I088f3438c1cb4496bcac64069c047f2c8c58450d\n'}, {'number': 5, 'created': '2013-07-01 11:37:28.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/exception.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_libvirt_config.py', 'nova/virt/libvirt/config.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6f1a29dd332f88f630173d60345b749a0a462e51', 'message': 'PCI passthrough Libvirt layer WIP\n\nShould address all that said Daniel Berrange\nand write commit description =)\n\nblueprint pci-passthrough-libvirt\n\nChange-Id: I088f3438c1cb4496bcac64069c047f2c8c58450d\n'}]",65,27130,6f1a29dd332f88f630173d60345b749a0a462e51,60,12,5,6172,,,0,"PCI passthrough Libvirt layer WIP

Should address all that said Daniel Berrange
and write commit description =)

blueprint pci-passthrough-libvirt

Change-Id: I088f3438c1cb4496bcac64069c047f2c8c58450d
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/27130/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/fakes.py', 'nova/tests/test_db_api.py', 'nova/tests/test_libvirt.py', 'nova/db/sqlalchemy/api.py', 'nova/virt/libvirt/driver.py', 'nova/scheduler/filter_scheduler.py', 'tools/pip-requires', 'nova/compute/manager.py', 'nova/db/api.py', 'nova/tests/test_pci_device.py', 'nova/conductor/api.py', 'nova/db/sqlalchemy/migrate_repo/versions/176_add_pci_devices.py', 'nova/virt/libvirt/config.py', 'nova/tests/scheduler/test_host_manager.py', 'nova/pci/__init__.py', 'nova/tests/compute/fake_resource_tracker.py', 'nova/scheduler/filters/pci_passthrough_filter.py', 'nova/conductor/rpcapi.py', 'nova/db/sqlalchemy/models.py', 'nova/exception.py', 'nova/tests/scheduler/test_host_filters.py', 'nova/tests/scheduler/test_filter_scheduler.py', 'nova/tests/test_libvirt_config.py', 'nova/conductor/manager.py', 'nova/compute/resource_tracker.py', 'nova/scheduler/host_manager.py']",26,80282177e779f60ddf7d7f6b7fd744cf03d925f3,bp/pci-passthrough-libvirt,"from nova import pci self.free_pci_labels = [] self.free_pci_labels = [dev['label'] for dev in compute.get('pci_devices', []) if dev['status'] == 'available'] inst_type = instance.get('instance_type') requested_pci_labels = pci.get_labels_from_instance_type(inst_type) for label in requested_pci_labels: self.free_pci_labels.remove(label) ",,1420,32
openstack%2Fnova~master~I42ad50cc64c065a0700ca6ae0dd8368fd6f20b66,openstack/nova,master,I42ad50cc64c065a0700ca6ae0dd8368fd6f20b66,PCI passthrough Compute layer,ABANDONED,2013-06-27 00:58:08.000000000,2013-07-17 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 2166}, {'_account_id': 6172}, {'_account_id': 7854}]","[{'number': 1, 'created': '2013-06-27 00:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93bf29c8f0375023a58f21cad90d103c2e8edd86', 'message': 'PCI passthrough Compute layer\n\ncompute.resource_tracker:\n  Use utils to sync pci devices in DB and nova.conf\n\ncompute.manger:\n  Bind to instance record in DB all required by label pci devices\n\nblueprint pci-passthrough-base\n\nChange-Id: I42ad50cc64c065a0700ca6ae0dd8368fd6f20b66\n'}, {'number': 2, 'created': '2013-07-01 11:37:34.000000000', 'files': ['nova/compute/manager.py', 'nova/compute/resource_tracker.py', 'nova/tests/compute/fake_resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3c2f81dc81c7799ec5f400ad290b04f0467b5551', 'message': 'PCI passthrough Compute layer\n\ncompute.resource_tracker:\n  Use utils to sync pci devices in DB and nova.conf\n\ncompute.manger:\n  Bind to instance record in DB all required by label pci devices\n\nblueprint pci-passthrough-base\n\nChange-Id: I42ad50cc64c065a0700ca6ae0dd8368fd6f20b66\n'}]",0,34648,3c2f81dc81c7799ec5f400ad290b04f0467b5551,10,5,2,6172,,,0,"PCI passthrough Compute layer

compute.resource_tracker:
  Use utils to sync pci devices in DB and nova.conf

compute.manger:
  Bind to instance record in DB all required by label pci devices

blueprint pci-passthrough-base

Change-Id: I42ad50cc64c065a0700ca6ae0dd8368fd6f20b66
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/34648/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/compute/resource_tracker.py', 'nova/tests/compute/fake_resource_tracker.py']",3,93bf29c8f0375023a58f21cad90d103c2e8edd86,bp/pci-passthrough-libvirt," values.setdefault('id', 1)",,20,0
openstack%2Fswift~master~I335727fa157c5254c2173effb033fa003d35129d,openstack/swift,master,I335727fa157c5254c2173effb033fa003d35129d,"Improve ""Multiple Server Swift Installation"" documentation",ABANDONED,2013-03-09 00:11:21.000000000,2013-07-17 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 866}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 2649}, {'_account_id': 2813}, {'_account_id': 2860}, {'_account_id': 3153}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-03-09 00:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8d35ef36a28356d3c2a64a91687560e7d9d182c9', 'message': 'Improve ""Multiple Server Swift Installation"" documentation\n\n- Reverse Proxy & Storage order (to keep same structure as admin doc)\n- Explain why we use ""/srv/node""\n\nFix bug #1147331\n\nChange-Id: I335727fa157c5254c2173effb033fa003d35129d\n'}, {'number': 2, 'created': '2013-03-09 00:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/aa3e27af6df35cdf91591997edf58acfaaa022c2', 'message': 'Improve ""Multiple Server Swift Installation"" documentation\n\n- Reverse Proxy & Storage order (to keep same structure as admin doc)\n- Explain why we use ""/srv/node""\n\nFix bug #1147331\n\nChange-Id: I335727fa157c5254c2173effb033fa003d35129d\n'}, {'number': 3, 'created': '2013-03-09 00:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e9a83c9d71028ddfeef0253b8ecedbb44526d4c8', 'message': 'Improve ""Multiple Server Swift Installation"" documentation\n\n- Reverse Proxy & Storage order (to keep same structure as admin doc)\n- Explain why we use ""/srv/node""\n\nFix bug #1147331\n\nChange-Id: I335727fa157c5254c2173effb033fa003d35129d\n'}, {'number': 4, 'created': '2013-06-05 11:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/669ed62b2e158ac5cc917af81f13b0b218364bb1', 'message': 'Improve ""Multiple Server Swift Installation"" documentation\n\n- Reverse Proxy & Storage order (to keep same structure as admin doc)\n- Explain why we use ""/srv/node""\n\nFix bug #1147331\n\nChange-Id: I335727fa157c5254c2173effb033fa003d35129d\n'}, {'number': 5, 'created': '2013-06-05 13:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7eadc4382ee8757c3842e97e2b423c35a51c27a1', 'message': 'Improve ""Multiple Server Swift Installation"" documentation\n\n- Reverse Proxy & Storage order (to keep same structure as admin doc)\n- Explain why we use ""/srv/node""\n\nFix bug #1147331\n\nChange-Id: I335727fa157c5254c2173effb033fa003d35129d\n'}, {'number': 6, 'created': '2013-06-06 13:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8738eb0b204456675ce5319cea831c6bf826a13f', 'message': 'Improve ""Multiple Server Swift Installation"" documentation\n\n- Reverse Proxy & Storage order (to keep same structure as admin doc)\n- Explain why we use ""/srv/node""\n\nFix bug #1147331\n\nChange-Id: I335727fa157c5254c2173effb033fa003d35129d\n'}, {'number': 7, 'created': '2013-06-06 13:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/37b214a9b7c6cb4a96fc70616421d074ae8afb50', 'message': 'Improve ""Multiple Server Swift Installation"" documentation\n\n- Reverse Proxy & Storage order (to keep same structure as admin doc)\n- Explain why we use ""/srv/node""\n\nFix bug #1147331\n\nChange-Id: I335727fa157c5254c2173effb033fa003d35129d\n'}, {'number': 8, 'created': '2013-06-06 13:54:36.000000000', 'files': ['doc/source/howto_installmultinode.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/e330ef58f75ceafa0bb764dd4439311e2f0e1694', 'message': 'Improve ""Multiple Server Swift Installation"" documentation\n\n- Reverse Proxy & Storage order (to keep same structure as admin doc)\n- Explain why we use ""/srv/node""\n\nFix bug #1147331\n\nChange-Id: I335727fa157c5254c2173effb033fa003d35129d\n'}]",23,23975,e330ef58f75ceafa0bb764dd4439311e2f0e1694,46,12,8,3153,,,0,"Improve ""Multiple Server Swift Installation"" documentation

- Reverse Proxy & Storage order (to keep same structure as admin doc)
- Explain why we use ""/srv/node""

Fix bug #1147331

Change-Id: I335727fa157c5254c2173effb033fa003d35129d
",git fetch https://review.opendev.org/openstack/swift refs/changes/75/23975/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/howto_installmultinode.rst', 'AUTHORS', 'doc/source/howto_installmultinode.rst~']",3,8d35ef36a28356d3c2a64a91687560e7d9d182c9,bug/1147331,"============================================================== Instructions for a Multiple Server Swift Installation (Ubuntu) ============================================================== Prerequisites ------------- * Ubuntu Server 10.04 LTS installation media .. note: Swift can run with other distros, but for this document we will focus on installing on Ubuntu Server, ypmv (your packaging may vary). Basic architecture and terms ---------------------------- - *node* - a host machine running one or more Swift services - *Storage node* - node that runs Account, Container, and Object services - *Proxy node* - node that runs Proxy services; also runs TempAuth - *ring* - a set of mappings of Swift data to physical devices This document shows a cluster using the following types of nodes: - one Proxy node - Runs the swift-proxy-server processes which proxy requests to the appropriate Storage nodes. The proxy server will also contain the TempAuth service as WSGI middleware. - five Storage nodes - Runs the swift-account-server, swift-container-server, and swift-object-server processes which control storage of the account databases, the container databases, as well as the actual stored objects. .. note:: Fewer Storage nodes can be used initially, but a minimum of 5 is recommended for a production cluster. This document describes each Storage node as a separate zone in the ring. It is recommended to have a minimum of 5 zones. A zone is a group of nodes that is as isolated as possible from other nodes (separate servers, network, power, even geography). The ring guarantees that every replica is stored in a separate zone. For more information about the ring and zones, see: :doc:`The Rings <overview_ring>`. To increase reliability, you may want to add additional Proxy servers for performance which is described in :ref:`add-proxy-server`. Network Setup Notes ------------------- This document refers to two networks. An external network for connecting to the Proxy server, and a storage network that is not accessibile from outside the cluster, to which all of the nodes are connected. All of the Swift services, as well as the rsync daemon on the Storage nodes are configured to listen on their STORAGE_LOCAL_NET IP addresses. .. note:: Run all commands as the root user General OS configuration and partitioning for each node ------------------------------------------------------- #. Install the baseline Ubuntu Server 10.04 LTS on all nodes. #. Install common Swift software prereqs:: apt-get install python-software-properties add-apt-repository ppa:swift-core/release apt-get update apt-get install swift python-swiftclient openssh-server #. Create and populate configuration directories:: mkdir -p /etc/swift chown -R swift:swift /etc/swift/ #. On the first node only, create /etc/swift/swift.conf:: cat >/etc/swift/swift.conf <<EOF [swift-hash] # random unique string that can never change (DO NOT LOSE) swift_hash_path_suffix = `od -t x8 -N 8 -A n </dev/random` EOF #. On the second and subsequent nodes: Copy that file over. It must be the same on every node in the cluster!:: scp firstnode.example.com:/etc/swift/swift.conf /etc/swift/ #. Publish the local network IP address for use by scripts found later in this documentation:: export STORAGE_LOCAL_NET_IP=10.1.2.3 export PROXY_LOCAL_NET_IP=10.1.2.4 .. note:: The random string of text in /etc/swift/swift.conf is used as a salt when hashing to determine mappings in the ring. .. _config-proxy: Configure the Storage nodes --------------------------- .. note:: Swift *should* work on any modern filesystem that supports Extended Attributes (XATTRS). We currently recommend XFS as it demonstrated the best overall performance for the swift use case after considerable testing and benchmarking at Rackspace. It is also the only filesystem that has been thoroughly tested. These instructions assume that you are going to devote /dev/sdb1 to an XFS filesystem. #. Install Storage node packages:: apt-get install swift-account swift-container swift-object xfsprogs #. For every device on the node you wish to use for storage, setup the XFS volume (/dev/sdb is used as an example). Use a single partition per drive. For example, in a server with 12 disks you may use one or two disks for the operating system which should not be touched in this step. The other 10 or 11 disks should be partitioned with a single partition, then formatted in XFS : fdisk /dev/sdb (set up a single partition) mkfs.xfs -i size=1024 /dev/sdb1 echo ""/dev/sdb1 /srv/node/sdb1 xfs noatime,nodiratime,nobarrier,logbufs=8 0 0"" >> /etc/fstab mkdir -p /srv/node/sdb1 mount /srv/node/sdb1 chown -R swift:swift /srv/node #. Create /etc/rsyncd.conf:: cat >/etc/rsyncd.conf <<EOF uid = swift gid = swift log file = /var/log/rsyncd.log pid file = /var/run/rsyncd.pid address = $STORAGE_LOCAL_NET_IP [account] max connections = 2 path = /srv/node/ read only = false lock file = /var/lock/account.lock [container] max connections = 2 path = /srv/node/ read only = false lock file = /var/lock/container.lock [object] max connections = 2 path = /srv/node/ read only = false lock file = /var/lock/object.lock EOF #. Edit the RSYNC_ENABLE= line in /etc/default/rsync:: perl -pi -e 's/RSYNC_ENABLE=false/RSYNC_ENABLE=true/' /etc/default/rsync #. Start rsync daemon:: service rsync start .. note:: The rsync daemon requires no authentication, so it should be run on a local, private network. #. Create /etc/swift/account-server.conf:: cat >/etc/swift/account-server.conf <<EOF [DEFAULT] bind_ip = $STORAGE_LOCAL_NET_IP workers = 2 [pipeline:main] pipeline = account-server [app:account-server] use = egg:swift#account [account-replicator] [account-auditor] [account-reaper] EOF #. Create /etc/swift/container-server.conf:: cat >/etc/swift/container-server.conf <<EOF [DEFAULT] bind_ip = $STORAGE_LOCAL_NET_IP workers = 2 [pipeline:main] pipeline = container-server [app:container-server] use = egg:swift#container [container-replicator] [container-updater] [container-auditor] [container-sync] EOF #. Create /etc/swift/object-server.conf:: cat >/etc/swift/object-server.conf <<EOF [DEFAULT] bind_ip = $STORAGE_LOCAL_NET_IP workers = 2 [pipeline:main] pipeline = object-server [app:object-server] use = egg:swift#object [object-replicator] [object-updater] [object-auditor] EOF #. Start the storage services. If you use this command, it will try to start every service for which a configuration file exists, and throw a warning for any configuration files which don't exist:: swift-init all start Or, if you want to start them one at a time, run them as below. Note that if the server program in question generates any output on its stdout or stderr, swift-init has already redirected the command's output to /dev/null. If you encounter any difficulty, stop the server and run it by hand from the command line. Any server may be started using ""swift-$SERVER-$SERVICE /etc/swift/$SERVER-config"", where $SERVER might be object, continer, or account, and $SERVICE might be server, replicator, updater, or auditor. :: swift-init object-server start swift-init object-replicator start swift-init object-updater start swift-init object-auditor start swift-init container-server start swift-init container-replicator start swift-init container-updater start swift-init container-auditor start swift-init account-server start swift-init account-replicator start swift-init account-auditor start Configure the Proxy node ------------------------ .. note:: It is assumed that all commands are run as the root user #. Install swift-proxy service:: apt-get install swift-proxy memcached #. Create self-signed cert for SSL:: cd /etc/swift openssl req -new -x509 -nodes -out cert.crt -keyout cert.key .. note:: If you don't create the cert files, Swift silently uses http internally rather than https. This document assumes that you have created these certs, so if you're following along step-by-step, create them. In a production cluster, you should terminate SSL before the proxy server. SSL support is provided for testing purposes only. #. Modify memcached to listen on the default interfaces. Preferably this should be on a local, non-public network. Edit the IP address in /etc/memcached.conf, for example:: perl -pi -e ""s/-l 127.0.0.1/-l $PROXY_LOCAL_NET_IP/"" /etc/memcached.conf #. Restart the memcached server:: service memcached restart #. Create /etc/swift/proxy-server.conf:: cat >/etc/swift/proxy-server.conf <<EOF [DEFAULT] cert_file = /etc/swift/cert.crt key_file = /etc/swift/cert.key bind_port = 8080 workers = 8 user = swift [pipeline:main] pipeline = healthcheck cache tempauth proxy-server [app:proxy-server] use = egg:swift#proxy allow_account_management = true account_autocreate = true [filter:tempauth] use = egg:swift#tempauth user_system_root = testpass .admin https://$PROXY_LOCAL_NET_IP:8080/v1/AUTH_system [filter:healthcheck] use = egg:swift#healthcheck [filter:cache] use = egg:swift#memcache memcache_servers = $PROXY_LOCAL_NET_IP:11211 EOF .. note:: If you run multiple memcache servers, put the multiple IP:port listings in the [filter:cache] section of the proxy-server.conf file like: `10.1.2.3:11211,10.1.2.4:11211`. Only the proxy server uses memcache. #. Create the account, container and object rings. The builder command is basically creating a builder file with a few parameters. The parameter with the value of 18 represents 2 ^ 18th, the value that the partition will be sized to. Set this ""partition power"" value based on the total amount of storage you expect your entire ring to use. The value of 3 represents the number of replicas of each object, with the last value being the number of hours to restrict moving a partition more than once. :: cd /etc/swift swift-ring-builder account.builder create 18 3 1 swift-ring-builder container.builder create 18 3 1 swift-ring-builder object.builder create 18 3 1 .. note:: For more information on building rings, see :doc:`overview_ring`. #. For every storage device in /srv/node on each node add entries to each ring:: export ZONE= # set the zone number for that storage device export STORAGE_LOCAL_NET_IP= # and the IP address export WEIGHT=100 # relative weight (higher for bigger/faster disks) export DEVICE=sdb1 swift-ring-builder account.builder add z$ZONE-$STORAGE_LOCAL_NET_IP:6002/$DEVICE $WEIGHT swift-ring-builder container.builder add z$ZONE-$STORAGE_LOCAL_NET_IP:6001/$DEVICE $WEIGHT swift-ring-builder object.builder add z$ZONE-$STORAGE_LOCAL_NET_IP:6000/$DEVICE $WEIGHT .. note:: Assuming there are 5 zones with 1 node per zone, ZONE should start at 1 and increment by one for each additional node. #. Verify the ring contents for each ring:: swift-ring-builder account.builder swift-ring-builder container.builder swift-ring-builder object.builder #. Rebalance the rings:: swift-ring-builder account.builder rebalance swift-ring-builder container.builder rebalance swift-ring-builder object.builder rebalance .. note:: Rebalancing rings can take some time. #. Copy the account.ring.gz, container.ring.gz, and object.ring.gz files to each of the Proxy and Storage nodes in /etc/swift. #. Make sure all the config files are owned by the swift user:: chown -R swift:swift /etc/swift #. Start Proxy services:: swift-init proxy start Create Swift admin account and test ----------------------------------- You run these commands from the Proxy node. #. Get an X-Storage-Url and X-Auth-Token:: curl -k -v -H 'X-Storage-User: system:root' -H 'X-Storage-Pass: testpass' https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 #. Check that you can HEAD the account:: curl -k -v -H 'X-Auth-Token: <token-from-x-auth-token-above>' <url-from-x-storage-url-above> #. Check that ``swift`` works (at this point, expect zero containers, zero objects, and zero bytes):: swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass stat #. Use ``swift`` to upload a few files named 'bigfile[1-2].tgz' to a container named 'myfiles':: swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass upload myfiles bigfile1.tgz swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass upload myfiles bigfile2.tgz #. Use ``swift`` to download all files from the 'myfiles' container:: swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass download myfiles #. Use ``swift`` to save a backup of your builder files to a container named 'builders'. Very important not to lose your builders!:: swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass upload builders /etc/swift/*.builder #. Use ``swift`` to list your containers:: swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass list #. Use ``swift`` to list the contents of your 'builders' container:: swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass list builders #. Use ``swift`` to download all files from the 'builders' container:: swift -A https://$PROXY_LOCAL_NET_IP:8080/auth/v1.0 -U system:root -K testpass download builders .. _add-proxy-server: Adding a Proxy Server --------------------- For reliability's sake you may want to have more than one proxy server. You can set up the additional proxy node in the same manner that you set up the first proxy node but with additional configuration steps. Once you have more than two proxies, you also want to load balance between the two, which means your storage endpoint also changes. You can select from different strategies for load balancing. For example, you could use round robin dns, or an actual load balancer (like pound) in front of the two proxies, and point your storage url to the load balancer. See :ref:`config-proxy` for the initial setup, and then follow these additional steps. #. Update the list of memcache servers in /etc/swift/proxy-server.conf for all the added proxy servers. If you run multiple memcache servers, use this pattern for the multiple IP:port listings: `10.1.2.3:11211,10.1.2.4:11211` in each proxy server's conf file.:: [filter:cache] use = egg:swift#memcache memcache_servers = $PROXY_LOCAL_NET_IP:11211 #. Change the storage url for any users to point to the load balanced url, rather than the first proxy server you created in /etc/swift/proxy-server.conf:: [filter:tempauth] use = egg:swift#tempauth user_system_root = testpass .admin http[s]://<LOAD_BALANCER_HOSTNAME>:<PORT>/v1/AUTH_system #. Next, copy all the ring information to all the nodes, including your new proxy nodes, and ensure the ring info gets to all the storage nodes as well. #. After you sync all the nodes, make sure the admin has the keys in /etc/swift and the ownership for the ring file is correct. Troubleshooting Notes --------------------- If you see problems, look in var/log/syslog (or messages on some distros). Also, at Rackspace we have seen hints at drive failures by looking at error messages in /var/log/kern.log. There are more debugging hints and tips in the :doc:`admin_guide`. ",,578,122
openstack%2Fswift~master~I8b86407808beea00625416333cb440fbfe91e035,openstack/swift,master,I8b86407808beea00625416333cb440fbfe91e035,Allow keystone url to be accessed via tenant_name,ABANDONED,2013-07-04 10:23:34.000000000,2013-07-17 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 860}, {'_account_id': 866}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2649}, {'_account_id': 2711}, {'_account_id': 5707}]","[{'number': 1, 'created': '2013-07-04 10:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/400cbd8e312f2335ab68b0b8e5064f626da5877d', 'message': 'Allow keystone url to be accessed via tenant_name\n\n- We allow URL access via AUTH_tenantName but still store internally as\n  UUID.\n- This should not conflict with domain since tenantId should be\n  differents even tho tenantName should be the same.\n- Implements blueprint keystoneauth-tenant-name-url.\n\nChange-Id: I8b86407808beea00625416333cb440fbfe91e035\n'}, {'number': 2, 'created': '2013-07-04 10:52:06.000000000', 'files': ['test/unit/common/middleware/test_keystoneauth.py', 'swift/common/middleware/keystoneauth.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/a9256e0b26e9217bd557f76e16d77f4d91af0dfc', 'message': 'Allow keystone url to be accessed via tenant_name\n\n- We allow URL access via AUTH_tenantName but still store internally as\n  UUID.\n- This should not conflict with domain since tenantId should be\n  differents even tho tenantName should be the same.\n- Implements blueprint keystoneauth-tenant-name-url.\n\nChange-Id: I8b86407808beea00625416333cb440fbfe91e035\n'}]",3,35628,a9256e0b26e9217bd557f76e16d77f4d91af0dfc,14,9,2,866,,,0,"Allow keystone url to be accessed via tenant_name

- We allow URL access via AUTH_tenantName but still store internally as
  UUID.
- This should not conflict with domain since tenantId should be
  differents even tho tenantName should be the same.
- Implements blueprint keystoneauth-tenant-name-url.

Change-Id: I8b86407808beea00625416333cb440fbfe91e035
",git fetch https://review.opendev.org/openstack/swift refs/changes/28/35628/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/test_keystoneauth.py', 'swift/common/middleware/keystoneauth.py']",2,400cbd8e312f2335ab68b0b8e5064f626da5877d,bp/keystoneauth-tenant-name-url," # allow access via tenant_name base_account = account.replace(self.reseller_prefix, '') (tenant_id, tenant_name) = env_identity['tenant'] if base_account == tenant_name: # rewrite account to AUTH_tenantId account = ""%s%s"" % (self.reseller_prefix, env_identity['tenant'][0]) other = '' if part[2] is not None: other = ""/"" + '/'.join(part[2:]) # rewrite the PATH_INFO to AUTH_tenantId req.environ['PATH_INFO'] = ""/%s%s%s"" % (self.reseller_prefix, env_identity['tenant'][0], other) ",,23,0
openstack%2Fgrenade~master~Iace5728bb348d04fd7258035f60273cad67d0ebc,openstack/grenade,master,Iace5728bb348d04fd7258035f60273cad67d0ebc,Jenkins of grenade failure due to neutron rename,ABANDONED,2013-07-09 08:01:58.000000000,2013-07-17 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 2976}]","[{'number': 1, 'created': '2013-07-09 08:01:58.000000000', 'files': ['upgrade-nova', 'upgrade-tempest', 'functions'], 'web_link': 'https://opendev.org/openstack/grenade/commit/dae705763a80bc98c2d45cfb948368f6dd72029f', 'message': 'Jenkins of grenade failure due to neutron rename\n\nFixes bug #1199250\n\nChange-Id: Iace5728bb348d04fd7258035f60273cad67d0ebc\n'}]",0,36186,dae705763a80bc98c2d45cfb948368f6dd72029f,4,2,1,2711,,,0,"Jenkins of grenade failure due to neutron rename

Fixes bug #1199250

Change-Id: Iace5728bb348d04fd7258035f60273cad67d0ebc
",git fetch https://review.opendev.org/openstack/grenade refs/changes/86/36186/1 && git format-patch -1 --stdout FETCH_HEAD,"['upgrade-nova', 'upgrade-tempest', 'functions']",3,dae705763a80bc98c2d45cfb948368f6dd72029f,bug/1199250," if [[ ! $file_to_parse =~ neutron ]]; then file_to_parse=""${file_to_parse} neutron""# **neutron** returns true if any service enabled start with **q-** [[ ${service} == ""neutron"" && ${ENABLED_SERVICES} =~ ""q-"" ]] && return 0# for nova, glance, and neutron built into is_service_enabled().# for nova, glance, and neutron built into is_service_enabled(). if is_service_enabled neutron; then _ping_check_neutron ""$1"" $2 $3 $4 if is_service_enabled neutron; then _ssh_check_neutron ""$1"" $2 $3 $4 $5"," if [[ ! $file_to_parse =~ quantum ]]; then file_to_parse=""${file_to_parse} quantum""# **quantum** returns true if any service enabled start with **q-** [[ ${service} == ""quantum"" && ${ENABLED_SERVICES} =~ ""q-"" ]] && return 0# for nova, glance, and quantum built into is_service_enabled().# for nova, glance, and quantum built into is_service_enabled(). if is_service_enabled quantum; then _ping_check_quantum ""$1"" $2 $3 $4 if is_service_enabled quantum; then _ssh_check_quantum ""$1"" $2 $3 $4 $5",14,14
openstack%2Fcinder~master~I1e4d13804537ee57427c64be02cda113214d41f3,openstack/cinder,master,I1e4d13804537ee57427c64be02cda113214d41f3,Implementation of Volume Anti Affinity Filter.,ABANDONED,2013-06-28 11:05:18.000000000,2013-07-17 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 1531}, {'_account_id': 2166}, {'_account_id': 6938}]","[{'number': 1, 'created': '2013-06-28 11:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ae7695e84e470dd6e512456a21ba3547a02f6f30', 'message': ""Implementation of Volume Anti Affinity Filter.\n\nThis filter allows one to place a volume on a different host\nto which specified volumes don't belong.\n\nBlueprint cinder-volume-antiaffinity-filter\n\nChange-Id: I1e4d13804537ee57427c64be02cda113214d41f3\n""}, {'number': 2, 'created': '2013-07-04 14:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ea90de42135ba771f4c2a810ef84383f9c7774e2', 'message': ""Implementation of Volume Anti Affinity Filter.\n\nThis filter allows one to place a volume on a different host\nto which specified volumes don't belong.\n\nBlueprint cinder-volume-antiaffinity-filter\n\nChange-Id: I1e4d13804537ee57427c64be02cda113214d41f3\n""}, {'number': 3, 'created': '2013-07-08 10:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dcc4b3588a6d13525c6753accfa2d22bad943217', 'message': ""Implementation of Volume Anti Affinity Filter.\n\nThis filter allows one to place a volume on a different host\nto which specified volumes don't belong.\n\nBlueprint cinder-volume-antiaffinity-filter\n\nChange-Id: I1e4d13804537ee57427c64be02cda113214d41f3\n""}, {'number': 4, 'created': '2013-07-08 11:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7ba682592f074ce452124dc46f38d6a476d4b3a9', 'message': ""Implementation of Volume Anti Affinity Filter.\n\nThis filter allows one to place a volume on a different host\nto which specified volumes don't belong.\n\nBlueprint cinder-volume-antiaffinity-filter\n\nChange-Id: I1e4d13804537ee57427c64be02cda113214d41f3\n""}, {'number': 5, 'created': '2013-07-09 12:27:01.000000000', 'files': ['cinder/tests/scheduler/test_host_filters.py', 'setup.cfg', 'cinder/scheduler/filters/antiaffinity_filter.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9934f066ce602f58e23e3ecaafdbd837597b0606', 'message': ""Implementation of Volume Anti Affinity Filter.\n\nThis filter allows one to place a volume on a different host\nto which specified volumes don't belong.\n\nBlueprint cinder-volume-antiaffinity-filter\n\nChange-Id: I1e4d13804537ee57427c64be02cda113214d41f3\n""}]",0,34867,9934f066ce602f58e23e3ecaafdbd837597b0606,22,5,5,6938,,,0,"Implementation of Volume Anti Affinity Filter.

This filter allows one to place a volume on a different host
to which specified volumes don't belong.

Blueprint cinder-volume-antiaffinity-filter

Change-Id: I1e4d13804537ee57427c64be02cda113214d41f3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/67/34867/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/scheduler/filters/antiaffinity_filter.py'],1,ae7695e84e470dd6e512456a21ba3547a02f6f30,bp/cinder-volume-antiaffinity-filter,"# Copyright (c) 2013 OpenStack, LLC. # # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Volume Anti Affinity Filter For Cinder-Scheduler. This filter selects only those hosts to which specified volumes don't belong. Hosts containing specified volumes get rejected. """""" from cinder.db import api as db_api from cinder import exception from cinder.openstack.common import log as logging from cinder.openstack.common.scheduler import filters LOG = logging.getLogger(__name__) class VolumeAntiAffinityFilter(filters.BaseHostFilter): """"""Filters hosts that don't contain specified volumes."""""" hint_name = 'not_with_volume_id' def host_passes(self, host_state, filter_properties): """"""Processes not_with_volume_id hint if given."""""" context = filter_properties['context'] scheduler_hints = filter_properties.get('scheduler_hints', {}) volume_ids = scheduler_hints.get(self.hint_name, []) # This will be triggered by empty list thus covering both no hint and # empty hint cases. if not volume_ids: LOG.debug('no %s hint provided, filter passes', self.hint_name) return True if not isinstance(volume_ids, list): volume_ids = [volume_ids] host = host_state.host # This one must be refactored to reduce db_api load for volume_id in volume_ids: try: vol = db_api.volume_get(context, volume_id) except exception.VolumeNotFound: LOG.warning('volume with provided id (""%s"") was not found', volume_id) else: vol_host = getattr(vol, 'host', None) if vol_host == host: return False return True ",,62,0
openstack%2Fnova~master~If0644e947329439aa4700498e703d9f96855277d,openstack/nova,master,If0644e947329439aa4700498e703d9f96855277d,Nova does not work due to neutron rename,ABANDONED,2013-07-08 11:39:18.000000000,2013-07-17 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-07-08 11:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32e81334a4158944f832c060348f3efd9ffe4c0c', 'message': 'Nova does not work due to neutron rename\n\nDue to the new quantum/neutronclient package rename\nthe current nova code does not work correctly.\n\nFixes the bug, 1198040\n\nChange-Id: If0644e947329439aa4700498e703d9f96855277d\n'}, {'number': 2, 'created': '2013-07-08 11:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47c230ce1f10606c4a67c08d22c7e5d5a258cb40', 'message': 'Nova does not work due to neutron rename\n\nDue to the new quantum/neutronclient package rename\nthe current nova code does not work correctly.\n\nFixes the bug: 1198040\n\nChange-Id: If0644e947329439aa4700498e703d9f96855277d\n'}, {'number': 3, 'created': '2013-07-09 05:18:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5715b0ea36ac00dc866351be77807221b0d31a4b', 'message': 'Nova does not work due to neutron rename\n\nDue to the new quantum/neutronclient package rename\nthe current nova code does not work correctly.\n\nFixes the bug: 1198040\n\nChange-Id: If0644e947329439aa4700498e703d9f96855277d\n'}, {'number': 4, 'created': '2013-07-09 07:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3b40532ade6b93483c20f965a4f680d441ba72a', 'message': 'Nova does not work due to neutron rename\n\nDue to the new quantum/neutronclient package rename\nthe current nova code does not work correctly.\n\nFixes the bug: 1198040\n\nChange-Id: If0644e947329439aa4700498e703d9f96855277d\n'}, {'number': 5, 'created': '2013-07-09 07:52:37.000000000', 'files': ['nova/tests/network/security_group/test_quantum_driver.py', 'requirements.txt', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/network/quantumv2/__init__.py', 'nova/network/security_group/quantum_driver.py', 'nova/network/quantumv2/api.py', 'nova/tests/network/test_quantumv2.py', 'nova/api/openstack/compute/servers.py', 'nova/tests/api/openstack/compute/contrib/test_quantum_security_groups.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/42522f05ed2ae15c437821ef1e482916bf4c5f26', 'message': 'Nova does not work due to neutron rename\n\nDue to the new quantum/neutronclient package rename\nthe current nova code does not work correctly.\n\nFixes the bug: 1198040\n\nChange-Id: If0644e947329439aa4700498e703d9f96855277d\n'}]",4,36061,42522f05ed2ae15c437821ef1e482916bf4c5f26,16,7,5,2711,,,0,"Nova does not work due to neutron rename

Due to the new quantum/neutronclient package rename
the current nova code does not work correctly.

Fixes the bug: 1198040

Change-Id: If0644e947329439aa4700498e703d9f96855277d
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/36061/5 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,32e81334a4158944f832c060348f3efd9ffe4c0c,bug/1198040,"python-neutronclient>=2.2.0,<3.0.0","python-quantumclient>=2.2.0,<3.0.0",1,1
openstack%2Fceilometer~master~Icea91bb05b494f7977ae6447ec8de1f96b1b2897,openstack/ceilometer,master,Icea91bb05b494f7977ae6447ec8de1f96b1b2897,Unpin keystoneclient (bug 1194921),ABANDONED,2013-07-05 17:14:57.000000000,2013-07-17 06:03:04.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-05 17:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/92e214cc039322d195e1b6e8f0673abd38371406', 'message': 'Unpin keystoneclient (bug 1194921)\n\nChange-Id: Icea91bb05b494f7977ae6447ec8de1f96b1b2897\n'}, {'number': 2, 'created': '2013-07-05 17:14:57.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b7031ade9bf8fca6f38be7558fc913986386f679', 'message': 'Unpin keystoneclient (bug 1194921)\n\nChange-Id: Icea91bb05b494f7977ae6447ec8de1f96b1b2897\n'}]",0,35842,b7031ade9bf8fca6f38be7558fc913986386f679,5,1,2,4,,,0,"Unpin keystoneclient (bug 1194921)

Change-Id: Icea91bb05b494f7977ae6447ec8de1f96b1b2897
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/42/35842/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,92e214cc039322d195e1b6e8f0673abd38371406,bug/1194921,python-keystoneclient>=0.2,"python-keystoneclient>=0.2,<0.3",1,1
openstack%2Fpython-keystoneclient~master~I777c6ab7e7dc3577ac83f165c5a0dd62641f09fd,openstack/python-keystoneclient,master,I777c6ab7e7dc3577ac83f165c5a0dd62641f09fd,Provided tenant-id support for keystone user-create.,ABANDONED,2013-05-27 18:31:24.000000000,2013-07-17 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 866}, {'_account_id': 2218}, {'_account_id': 6167}, {'_account_id': 7668}, {'_account_id': 7669}]","[{'number': 1, 'created': '2013-05-27 18:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/3b93604416bb627e4ee0636aa5058637a90cb3ad', 'message': ""Provided tenant-id support for keystone user-create.\n\nCurrently when a user is created through CLI using\nkeystone user-create, the user's tenant cannot be\nupdated through CLI. Provided tenant-id support for\nkeystone user-create cli command. Now using CLI\noption we can updateupdate tenant for a user.\n\nFixes: bug #1177224\nChange-Id: I777c6ab7e7dc3577ac83f165c5a0dd62641f09fd\n""}, {'number': 2, 'created': '2013-05-28 18:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/4cf67d50a239aca1d7e77f11f577ef6e7a1db885', 'message': ""Provided tenant-id support for keystone user-create.\n\nCurrently when a user is created through CLI using\nkeystone user-create, the user's tenant cannot be\nupdated through CLI. Provided tenant-id support for\nkeystone user-create cli command. Now using CLI\noption we can update tenant for a user.\nAlso corrected indentation to resolve jenkins issue.\n\nFixes: bug #1177224\nChange-Id: I777c6ab7e7dc3577ac83f165c5a0dd62641f09fd\n""}, {'number': 3, 'created': '2013-06-10 05:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ea58cfb27232492a29d5bbda46b8074aef66b879', 'message': ""Provided tenant-id support for keystone user-create.\n\nCurrently when a user is created through CLI using\nkeystone user-create, the user's tenant cannot be\nupdated through CLI. Provided tenant-id support for\nkeystone user-create cli command. Now using CLI\noption we can update tenant for a user.\nFixed code review comments.\n\nFixes: bug #1177224\nChange-Id: I777c6ab7e7dc3577ac83f165c5a0dd62641f09fd\n""}, {'number': 4, 'created': '2013-06-26 03:03:21.000000000', 'files': ['keystoneclient/v2_0/users.py', 'keystoneclient/v2_0/shell.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/aa5a55244e89caf9777feb238ea099cacf879041', 'message': ""Provided tenant-id support for keystone user-create.\n\nCurrently when a user is created through CLI using\nkeystone user-create, the user's tenant cannot be\nupdated through CLI. Provided tenant-id support for\nkeystone user-create cli command. Now using CLI\noption we can update tenant for a user.\nFixed code review comments and modify help text.\n\nFixes: bug #1177224\nChange-Id: I777c6ab7e7dc3577ac83f165c5a0dd62641f09fd\n""}]",9,30639,aa5a55244e89caf9777feb238ea099cacf879041,31,7,4,7669,,,0,"Provided tenant-id support for keystone user-create.

Currently when a user is created through CLI using
keystone user-create, the user's tenant cannot be
updated through CLI. Provided tenant-id support for
keystone user-create cli command. Now using CLI
option we can update tenant for a user.
Fixed code review comments and modify help text.

Fixes: bug #1177224
Change-Id: I777c6ab7e7dc3577ac83f165c5a0dd62641f09fd
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/39/30639/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/v2_0/users.py', 'keystoneclient/v2_0/shell.py']",2,3b93604416bb627e4ee0636aa5058637a90cb3ad,bug/1177224,"@utils.arg('--tenant-id', metavar='<tenant-id>', help='Desired tenant id') """"""Update user's name, tenant-id, email, and enabled status"""""" if args.tenant_id: kwargs['tenant_id'] = args.tenant_id"," """"""Update user's name, email, and enabled status""""""",6,2
openstack%2Fkeystone~master~I68c82b64eecd5f10ff1516a249ca6d171c49e697,openstack/keystone,master,I68c82b64eecd5f10ff1516a249ca6d171c49e697,Unpin python-keystoneclient dep,ABANDONED,2013-07-09 22:35:56.000000000,2013-07-17 06:03:03.000000000,,"[{'_account_id': 3}, {'_account_id': 6}, {'_account_id': 2166}, {'_account_id': 2472}, {'_account_id': 5707}, {'_account_id': 5971}]","[{'number': 1, 'created': '2013-07-09 22:35:56.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/632bf0848b5da1d20e747a35baf2ececab336a03', 'message': 'Unpin python-keystoneclient dep\n\nChange-Id: I68c82b64eecd5f10ff1516a249ca6d171c49e697\n'}]",0,36355,632bf0848b5da1d20e747a35baf2ececab336a03,8,6,1,4,,,0,"Unpin python-keystoneclient dep

Change-Id: I68c82b64eecd5f10ff1516a249ca6d171c49e697
",git fetch https://review.opendev.org/openstack/keystone refs/changes/55/36355/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,632bf0848b5da1d20e747a35baf2ececab336a03,(detached,python-keystoneclient>=0.2.1,"python-keystoneclient>=0.2.1,<0.3",1,1
openstack%2Fcinder~master~I3f1aa527f49175d9fac6fbe7309383709c30c237,openstack/cinder,master,I3f1aa527f49175d9fac6fbe7309383709c30c237,Add tests for cinder/api/urlmap.py,MERGED,2013-07-08 10:08:20.000000000,2013-07-17 06:00:38.000000000,2013-07-17 06:00:38.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1531}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 7331}, {'_account_id': 7369}]","[{'number': 1, 'created': '2013-07-08 10:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6cddd6248a805018839c6fbe3f3f84c4de022485', 'message': 'Add tests for cinder/api/urlmap.py\n\nAdd tests for unquoting and parsing functions in\nTestParseFunction class\nAdd tests for Accept class methods:\n - TestAccept class - test cases for processing content types\n - TestUrlMapFactory - test cases for urlmap factory\nAdd tests for URLMap class methods except __call__ method in TestURLMap\n\nChange-Id: I3f1aa527f49175d9fac6fbe7309383709c30c237\n'}, {'number': 2, 'created': '2013-07-11 07:30:24.000000000', 'files': ['cinder/tests/test_api_urlmap.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/627812890a3e7c5f8789a7deaa14d5daefde166a', 'message': 'Add tests for cinder/api/urlmap.py\n\nAdd tests for unquoting and parsing functions in\nTestParseFunction class\nAdd tests for Accept class methods:\n - TestAccept class - test cases for processing content types\n - TestUrlMapFactory - test cases for urlmap factory\nAdd tests for URLMap class methods except __call__ method in TestURLMap\n\nChange-Id: I3f1aa527f49175d9fac6fbe7309383709c30c237\n'}]",2,36038,627812890a3e7c5f8789a7deaa14d5daefde166a,15,10,2,7331,,,0,"Add tests for cinder/api/urlmap.py

Add tests for unquoting and parsing functions in
TestParseFunction class
Add tests for Accept class methods:
 - TestAccept class - test cases for processing content types
 - TestUrlMapFactory - test cases for urlmap factory
Add tests for URLMap class methods except __call__ method in TestURLMap

Change-Id: I3f1aa527f49175d9fac6fbe7309383709c30c237
",git fetch https://review.opendev.org/openstack/cinder refs/changes/38/36038/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_api_urlmap.py'],1,6cddd6248a805018839c6fbe3f3f84c4de022485,urlmap,"# Copyright 2011 OpenStack LLC. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Tests for cinder.api.urlmap.py """""" from cinder.api import urlmap from cinder import test class TestParseFunctions(test.TestCase): def test_unquote_header_value_without_quotes(self): arg = 'TestString' result = urlmap.unquote_header_value(arg) self.assertEqual(result, arg) def test_unquote_header_value_with_quotes(self): result = urlmap.unquote_header_value('""TestString""') self.assertEqual(result, 'TestString') def test_parse_list_header(self): arg = 'token, ""quoted value""' result = urlmap.parse_list_header(arg) self.assertEqual(result, ['token', 'quoted value']) def test_parse_options_header(self): result = urlmap.parse_options_header('Content-Type: text/html;' ' mimetype=text/html') self.assertEqual(result, ('Content-Type:', {'mimetype': 'text/html'})) def test_parse_options_header_without_value(self): result = urlmap.parse_options_header(None) self.assertEqual(result, ('', {})) class TestAccept(test.TestCase): def test_best_match_ValueError(self): arg = 'text/html; q=some_invalud_value' accept = urlmap.Accept(arg) self.assertEqual(accept.best_match(['text/html']), (None, {})) def test_best_match(self): arg = '*/*; q=0.7, application/json; q=0.7, text/html; q=-0.8' accept = urlmap.Accept(arg) self.assertEqual(accept.best_match(['application/json', 'application/xml', 'text/html']), ('application/json', {'q': '0.7'})) def test_match_mask_one_asterisk(self): arg = 'text/*; q=0.7' accept = urlmap.Accept(arg) self.assertEqual(accept.best_match(['text/html']), ('text/html', {'q': '0.7'})) def test_match_mask_two_asterisk(self): arg = '*/*; q=0.7' accept = urlmap.Accept(arg) self.assertEqual(accept.best_match(['text/html']), ('text/html', {'q': '0.7'})) def test_match_mask_no_asterisk(self): arg = 'application/json; q=0.7' accept = urlmap.Accept(arg) self.assertEqual(accept.best_match(['text/html']), (None, {})) def test_content_type_params(self): arg = ""application/xml; q=0.1, application/json; q=0.2,"" \ "" text/html; q=0.3"" accept = urlmap.Accept(arg) self.assertEqual(accept.content_type_params('application/json'), {'q': '0.2'}) def test_content_type_params_wrong_content_type(self): arg = 'application/xml; q=0.1, text/html; q=0.1' accept = urlmap.Accept(arg) self.assertEqual(accept.content_type_params('application/json'), {}) class TestUrlMapFactory(test.TestCase): def setUp(self): super(TestUrlMapFactory, self).setUp() self.global_conf = {'not_found_app': 'app_global', 'domain hoobar.com port 10 /': 'some_app_global'} self.loader = self.mox.CreateMockAnything() def test_not_found_app_in_local_conf(self): local_conf = {'not_found_app': 'app_local', 'domain foobar.com port 20 /': 'some_app_local'} self.loader.get_app('app_local', global_conf=self.global_conf).\ AndReturn('app_local_loader') self.loader.get_app('some_app_local', global_conf=self.global_conf).\ AndReturn('some_app_loader') self.mox.ReplayAll() expected_urlmap = urlmap.URLMap(not_found_app='app_local_loader') expected_urlmap['http://foobar.com:20'] = 'some_app_loader' self.assertEqual(urlmap.urlmap_factory(self.loader, self.global_conf, **local_conf), expected_urlmap) def test_not_found_app_not_in_local_conf(self): local_conf = {'domain foobar.com port 20 /': 'some_app_local'} self.loader.get_app('app_global', global_conf=self.global_conf).\ AndReturn('app_global_loader') self.loader.get_app('some_app_local', global_conf=self.global_conf).\ AndReturn('some_app_returned_by_loader') self.mox.ReplayAll() expected_urlmap = urlmap.URLMap(not_found_app='app_global_loader') expected_urlmap['http://foobar.com:20'] = 'some_app_returned'\ '_by_loader' self.assertEqual(urlmap.urlmap_factory(self.loader, self.global_conf, **local_conf), expected_urlmap) def test_not_found_app_is_none(self): local_conf = {'not_found_app': None, 'domain foobar.com port 20 /': 'some_app_local'} self.loader.get_app('some_app_local', global_conf=self.global_conf).\ AndReturn('some_app_returned_by_loader') self.mox.ReplayAll() expected_urlmap = urlmap.URLMap(not_found_app=None) expected_urlmap['http://foobar.com:20'] = 'some_app_returned'\ '_by_loader' self.assertEqual(urlmap.urlmap_factory(self.loader, self.global_conf, **local_conf), expected_urlmap) class TestURLMap(test.TestCase): def setUp(self): super(TestURLMap, self).setUp() self.urlmap = urlmap.URLMap() self.input_environ = {'HTTP_ACCEPT': ""application/json;"" ""version=9.0"", 'REQUEST_METHOD': ""GET"", 'CONTENT_TYPE': 'application/xml', 'SCRIPT_NAME': '/scriptname', 'PATH_INFO': ""/resource.xml""} self.environ = {'HTTP_ACCEPT': ""application/json;"" ""version=9.0"", 'REQUEST_METHOD': ""GET"", 'CONTENT_TYPE': 'application/xml', 'SCRIPT_NAME': '/scriptname/app_url', 'PATH_INFO': ""/resource.xml""} def test_match_with_applications(self): self.urlmap[('http://10.20.30.40:50', '/path/somepath')] = 'app' self.assertEqual(self.urlmap._match('20.30.40.50', '20', 'path/somepath'), (None, None)) def test_match_without_applications(self): self.assertEqual(self.urlmap._match('host', 20, 'app_url/somepath'), (None, None)) def test_match_path_info_equals_app_url(self): self.urlmap[('http://20.30.40.50:60', '/app_url/somepath')] = 'app' self.assertEqual(self.urlmap._match('http://20.30.40.50', '60', '/app_url/somepath'), ('app', '/app_url/somepath')) def test_match_path_info_equals_app_url(self): self.urlmap[('http://20.30.40.50:60', '/path')] = 'app1' self.urlmap[('http://20.30.40.50:60', '/path/somepath')] = 'app2' self.urlmap[('http://20.30.40.50:60', '/path/somepath/elsepath')] = \ 'app3' self.assertEqual(self.urlmap._match('http://20.30.40.50', '60', '/path/somepath/elsepath'), ('app3', '/path/somepath/elsepath')) def test_set_script_name(self): app = self.mox.CreateMockAnything() start_response = self.mox.CreateMockAnything() app.__call__(self.environ, start_response).AndReturn('value') self.mox.ReplayAll() wrap = self.urlmap._set_script_name(app, '/app_url') self.assertEqual(wrap(self.input_environ, start_response), 'value') def test_munge_path(self): app = self.mox.CreateMockAnything() start_response = self.mox.CreateMockAnything() app.__call__(self.environ, start_response).AndReturn('value') self.mox.ReplayAll() wrap = self.urlmap._munge_path(app, '/app_url/resource.xml', '/app_url') self.assertEqual(wrap(self.input_environ, start_response), 'value') def test_content_type_strategy_without_version(self): self.assertEqual(self.urlmap._content_type_strategy('host', 20, self.environ), None) def test_content_type_strategy_with_version(self): environ = {'HTTP_ACCEPT': ""application/vnd.openstack.melange+xml;"" ""version=9.0"", 'REQUEST_METHOD': ""GET"", 'PATH_INFO': ""/resource.xml"", 'CONTENT_TYPE': 'application/xml; version=2.0'} self.urlmap[('http://10.20.30.40:50', '/v2.0')] = 'app' self.mox.StubOutWithMock(self.urlmap, '_set_script_name') self.urlmap._set_script_name('app', '/v2.0').AndReturn('value') self.mox.ReplayAll() self.assertEqual(self.urlmap._content_type_strategy( 'http://10.20.30.40', '50', environ), 'value') def test_path_strategy_wrong_path_info(self): self.assertEqual(self.urlmap._path_strategy('http://10.20.30.40', '50', '/resource'), (None, None, None)) def test_path_strategy_mime_type_only(self): self.assertEqual(self.urlmap._path_strategy('http://10.20.30.40', '50', '/resource.xml'), ('application/xml', None, None)) def test_path_strategy(self): self.urlmap[('http://10.20.30.40:50', '/path/elsepath/')] = 'app' self.mox.StubOutWithMock(self.urlmap, '_munge_path') self.urlmap._munge_path('app', '/path/elsepath/resource.xml', '/path/elsepath').AndReturn('value') self.mox.ReplayAll() self.assertEqual(self.urlmap._path_strategy( 'http://10.20.30.40', '50', '/path/elsepath/resource.xml'), ('application/xml', 'value', '/path/elsepath')) def test_path_strategy_wrong_mime_type(self): self.urlmap[('http://10.20.30.40:50', '/path/elsepath/')] = 'app' self.mox.StubOutWithMock(self.urlmap, '_munge_path') self.urlmap._munge_path('app', '/path/elsepath/resource.abc', '/path/elsepath').AndReturn('value') self.mox.ReplayAll() self.assertEqual(self.urlmap._path_strategy( 'http://10.20.30.40', '50', '/path/elsepath/resource.abc'), (None, 'value', '/path/elsepath')) def test_accept_strategy_version_not_in_params(self): environ = {'HTTP_ACCEPT': ""application/xml; q=0.1, application/json; "" ""q=0.2"", 'REQUEST_METHOD': ""GET"", 'PATH_INFO': ""/resource.xml"", 'CONTENT_TYPE': 'application/xml; version=2.0'} self.assertEqual(self.urlmap._accept_strategy( 'http://10.20.30.40', '50', environ, ['application/xml']), ('application/xml', None)) def test_accept_strategy_version(self): environ = {'HTTP_ACCEPT': ""application/xml; q=0.1; version=1.0,"" ""application/json; q=0.2; version=2.0"", 'REQUEST_METHOD': ""GET"", 'PATH_INFO': ""/resource.xml"", 'CONTENT_TYPE': 'application/xml; version=2.0'} self.urlmap[('http://10.20.30.40:50', '/v1.0')] = 'app' self.mox.StubOutWithMock(self.urlmap, '_set_script_name') self.urlmap._set_script_name('app', '/v1.0').AndReturn('value') self.mox.ReplayAll() self.assertEqual(self.urlmap._accept_strategy( 'http://10.20.30.40', '50', environ, ['application/xml']), ('application/xml', 'value')) ",,261,0
openstack%2Fheat~master~I4c85ebf496b19999e47cf3838e6ca160aa194f20,openstack/heat,master,I4c85ebf496b19999e47cf3838e6ca160aa194f20,Check missing parameters during stack create,MERGED,2013-07-16 16:28:50.000000000,2013-07-17 06:00:30.000000000,2013-07-17 06:00:30.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 7256}]","[{'number': 1, 'created': '2013-07-16 16:28:50.000000000', 'files': ['heat/api/aws/exception.py', 'heat/tests/test_parameters.py', 'heat/tests/test_parser.py', 'heat/tests/test_autoscaling.py', 'heat/tests/test_clouddatabase.py', 'heat/engine/parameters.py', 'heat/tests/test_api_openstack_v1.py', 'heat/tests/test_api_cfn_v1.py', 'heat/api/openstack/v1/util.py', 'heat/engine/service.py', 'heat/engine/resources/loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/89a648d7ad9d10634c93e3f1ff8a9a8c72dba572', 'message': 'Check missing parameters during stack create\n\nAdd missing parameters checking logic to Parameter validation. It\nhas to be optional, since template validation makes use of the same\nParameter validation code.\n\nFixes bug #1198670\n\nChange-Id: I4c85ebf496b19999e47cf3838e6ca160aa194f20\n'}]",0,37283,89a648d7ad9d10634c93e3f1ff8a9a8c72dba572,8,5,1,7135,,,0,"Check missing parameters during stack create

Add missing parameters checking logic to Parameter validation. It
has to be optional, since template validation makes use of the same
Parameter validation code.

Fixes bug #1198670

Change-Id: I4c85ebf496b19999e47cf3838e6ca160aa194f20
",git fetch https://review.opendev.org/openstack/heat refs/changes/83/37283/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/api/aws/exception.py', 'heat/tests/test_parameters.py', 'heat/tests/test_autoscaling.py', 'heat/tests/test_clouddatabase.py', 'heat/tests/test_parser.py', 'heat/engine/parameters.py', 'heat/tests/test_api_cfn_v1.py', 'heat/tests/test_api_openstack_v1.py', 'heat/api/openstack/v1/util.py', 'heat/engine/resources/loadbalancer.py', 'heat/engine/service.py']",11,89a648d7ad9d10634c93e3f1ff8a9a8c72dba572,bug/1198670," tmpl_params = parser.Parameters(None, tmpl, validate_value=False)"," tmpl_params = parser.Parameters(None, tmpl)",108,55
openstack%2Fcinder~master~I2b41d025f8cffa6c0b3f0153a5194d5e7b1a05df,openstack/cinder,master,I2b41d025f8cffa6c0b3f0153a5194d5e7b1a05df,Fix error when QuotaUsage.updated_at is NULL,MERGED,2013-07-16 13:49:35.000000000,2013-07-17 06:00:28.000000000,2013-07-17 06:00:27.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 7593}]","[{'number': 1, 'created': '2013-07-16 13:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9ebefd040981263bc7e40b7a5b6bafc01e1c9647', 'message': 'Fix error when QuotaUsage.updated_at is NULL\n\nWhen QuotaUsage.updated_at is None, it will raise non-expected exception.\nJust verify it.\n\nFix bug 1197259\n\nChange-Id: I2b41d025f8cffa6c0b3f0153a5194d5e7b1a05df\n'}, {'number': 2, 'created': '2013-07-17 02:35:13.000000000', 'files': ['cinder/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9f75e546aaf2b791868a3eac424462f78dca707f', 'message': 'Fix error when QuotaUsage.updated_at is NULL\n\nWhen QuotaUsage.updated_at is None, it will raise non-expected exception.\nJust verify it.\n\nFix bug 1197259\n\nChange-Id: I2b41d025f8cffa6c0b3f0153a5194d5e7b1a05df\n'}]",1,37250,9f75e546aaf2b791868a3eac424462f78dca707f,11,6,2,7593,,,0,"Fix error when QuotaUsage.updated_at is NULL

When QuotaUsage.updated_at is None, it will raise non-expected exception.
Just verify it.

Fix bug 1197259

Change-Id: I2b41d025f8cffa6c0b3f0153a5194d5e7b1a05df
",git fetch https://review.opendev.org/openstack/cinder refs/changes/50/37250/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/db/sqlalchemy/api.py'],1,9ebefd040981263bc7e40b7a5b6bafc01e1c9647,bug/1197259, elif usages[resource].updated_at is not None: if max_age and (usages[resource].updated_at - timeutils.utcnow()).seconds >= max_age: refresh = True, elif max_age and (usages[resource].updated_at - timeutils.utcnow()).seconds >= max_age: refresh = True,4,3
openstack%2Fneutron~master~I22e8d11b9676cbcfe9e72449031bb63071be8314,openstack/neutron,master,I22e8d11b9676cbcfe9e72449031bb63071be8314,Fix argument name mismatch in L3-RPC sync_routers,MERGED,2013-07-16 08:17:30.000000000,2013-07-17 05:50:03.000000000,2013-07-17 05:50:02.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 2583}, {'_account_id': 2592}, {'_account_id': 5948}]","[{'number': 1, 'created': '2013-07-16 08:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6514339c0049485aecd9f995cd1d1ac83373cbde', 'message': 'Fix argument name mismatch in L3-RPC sync_routers\n\nIn sync_routers L3-RPC method l3-agent sends router_ids but the\nserver side expected router_id. This commit fixes the server side\nto accept router_ids.\nThis change allows l3-agent to sync only the specified routers\ninstead of all routers.\n\nFixes bug #1201553\n\nAs a result of the above change, auto_schedule_routers() and\nlist_active_sync_routers_on_active_l3_agent() in L3 scheduler\nneeds to handle a list of router IDs. This commit changes L3 scheduler\nto accept a list of router IDs in the above two methods.\n\nAlso fixes the argument order of fullsync and router_ids in get_routers\nin L3PluginApi. L3-agent main code expects router_ids as the second arg.\n\nChange-Id: I22e8d11b9676cbcfe9e72449031bb63071be8314\n'}, {'number': 2, 'created': '2013-07-16 09:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd76111771913b8c40a2dec4fe342859a2fe3355', 'message': 'Fix argument name mismatch in L3-RPC sync_routers\n\nIn sync_routers L3-RPC method l3-agent sends router_ids but the\nserver side expected router_id. This commit fixes the server side\nto accept router_ids, and drops ""fullsync"" arg from the agent side\n(fullsync is not used anywhere and it does not affect RPC signature).\nThis change allows l3-agent to sync only the specified routers\ninstead of all routers.\n\nFixes bug #1201553\n\nAs a result of the above change, auto_schedule_routers() and\nlist_active_sync_routers_on_active_l3_agent() in L3 scheduler\nneeds to handle a list of router IDs. This commit changes L3 scheduler\nto accept a list of router IDs in the above two methods.\n\nAlso fixes the argument order of fullsync and router_ids in get_routers\nin L3PluginApi. L3-agent main code expects router_ids as the second arg.\n\nChange-Id: I22e8d11b9676cbcfe9e72449031bb63071be8314\n'}, {'number': 3, 'created': '2013-07-16 11:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0b657789b7481df2af2453966ddda518ea3dca10', 'message': 'Fix argument name mismatch in L3-RPC sync_routers\n\nIn sync_routers L3-RPC method l3-agent sends router_ids but the\nserver side expected router_id. This commit fixes the server side\nto accept router_ids, and drops ""fullsync"" arg from the agent side\n(fullsync is not used anywhere and it does not affect RPC signature).\nThis change allows l3-agent to sync only the specified routers\ninstead of all routers.\n\nFixes bug #1201553\n\nAs a result of the above change, auto_schedule_routers() and\nlist_active_sync_routers_on_active_l3_agent() in L3 scheduler\nneeds to handle a list of router IDs. This commit changes L3 scheduler\nto accept a list of router IDs in the above two methods.\n\nAlso fixes the argument order of fullsync and router_ids in get_routers\nin L3PluginApi. L3-agent main code expects router_ids as the second arg.\n\nChange-Id: I22e8d11b9676cbcfe9e72449031bb63071be8314\n'}, {'number': 4, 'created': '2013-07-17 03:22:38.000000000', 'files': ['neutron/db/l3_rpc_base.py', 'neutron/agent/l3_agent.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/db/agentschedulers_db.py', 'neutron/scheduler/l3_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/de1967452e935e8d78255c448715a588d19ae838', 'message': 'Fix argument name mismatch in L3-RPC sync_routers\n\nIn sync_routers L3-RPC method l3-agent sends router_ids but the\nserver side expected router_id. This commit fixes the server side\nto accept router_ids, and drops ""fullsync"" arg from the agent side\n(fullsync is not used anywhere and it does not affect RPC signature).\nThis change allows l3-agent to sync only the specified routers\ninstead of all routers.\n\nFixes bug #1201553\n\nAs a result of the above change, auto_schedule_routers() and\nlist_active_sync_routers_on_active_l3_agent() in L3 scheduler\nneeds to handle a list of router IDs. This commit changes L3 scheduler\nto accept a list of router IDs in the above two methods.\n\nAlso fixes the argument order of fullsync and router_ids in get_routers\nin L3PluginApi. L3-agent main code expects router_ids as the second arg.\n\nChange-Id: I22e8d11b9676cbcfe9e72449031bb63071be8314\n'}]",6,37193,de1967452e935e8d78255c448715a588d19ae838,26,6,4,841,,,0,"Fix argument name mismatch in L3-RPC sync_routers

In sync_routers L3-RPC method l3-agent sends router_ids but the
server side expected router_id. This commit fixes the server side
to accept router_ids, and drops ""fullsync"" arg from the agent side
(fullsync is not used anywhere and it does not affect RPC signature).
This change allows l3-agent to sync only the specified routers
instead of all routers.

Fixes bug #1201553

As a result of the above change, auto_schedule_routers() and
list_active_sync_routers_on_active_l3_agent() in L3 scheduler
needs to handle a list of router IDs. This commit changes L3 scheduler
to accept a list of router IDs in the above two methods.

Also fixes the argument order of fullsync and router_ids in get_routers
in L3PluginApi. L3-agent main code expects router_ids as the second arg.

Change-Id: I22e8d11b9676cbcfe9e72449031bb63071be8314
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/37193/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_rpc_base.py', 'neutron/agent/l3_agent.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/db/agentschedulers_db.py', 'neutron/scheduler/l3_agent_scheduler.py']",5,6514339c0049485aecd9f995cd1d1ac83373cbde,bug/1201553," def auto_schedule_routers(self, plugin, context, host, router_ids): If router_ids is given, each router in router_ids is scheduled if it is not scheduled yet. Otherwise all unscheduled routers are scheduled. # check if each of the specified routers is hosted if router_ids: unschd_router_ids = [] for router_id in router_ids: l3_agents = plugin.get_l3_agents_hosting_routers( context, [router_id], admin_state_up=True) if l3_agents: LOG.debug(_('Router %(router_id)s has already been' ' hosted by L3 agent %(agent_id)s'), {'router_id': router_id, 'agent_id': l3_agents[0]['id']}) else: unschd_router_ids.append(router_id) if not unschd_router_ids: # all (specified) routers are already scheduled unschd_router_ids = [router_id_[0] for router_id_ in context.session.query( l3_db.Router.id).filter(stmt).all()] if not unschd_router_ids: LOG.debug(_('No non-hosted routers')) return False routers = plugin.get_routers(context, filters={'id': unschd_router_ids}) router_ids = list(set(unschd_router_ids) - set(to_removed_ids))"," def auto_schedule_routers(self, plugin, context, host, router_id): If router_id is given, only this router is scheduled if it is not hosted yet. # check if the specified router is hosted if router_id: l3_agents = plugin.get_l3_agents_hosting_routers( context, [router_id], admin_state_up=True) if l3_agents: LOG.debug(_('Router %(router_id)s has already been hosted' ' by L3 agent %(agent_id)s'), {'router_id': router_id, 'agent_id': l3_agents[0]['id']}) # get the router ids if router_id: router_ids = [(router_id,)] router_ids = context.session.query( l3_db.Router.id).filter(stmt).all() if not router_ids: LOG.debug(_('No non-hosted routers')) return False router_ids = [router_id_[0] for router_id_ in router_ids] routers = plugin.get_routers(context, filters={'id': router_ids}) router_ids = list(set(router_ids) - set(to_removed_ids))",121,38
openstack%2Fcinder~master~Ibc36453caa174432b69597b1b2a0b314a7730357,openstack/cinder,master,Ibc36453caa174432b69597b1b2a0b314a7730357,Add te field user_id into the volume detailed information.,MERGED,2013-07-16 03:49:10.000000000,2013-07-17 05:49:55.000000000,2013-07-17 05:49:54.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2166}, {'_account_id': 2243}]","[{'number': 1, 'created': '2013-07-16 03:49:10.000000000', 'files': ['cinder/api/v2/views/volumes.py', 'cinder/tests/api/v2/test_volumes.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c562ac705229710068c7f57fb87d2ab0f4fe54a0', 'message': 'Add te field user_id into the volume detailed information.\n\nFixed Bug 1200555.\n\nChange-Id: Ibc36453caa174432b69597b1b2a0b314a7730357\n'}]",0,37167,c562ac705229710068c7f57fb87d2ab0f4fe54a0,7,4,1,2861,,,0,"Add te field user_id into the volume detailed information.

Fixed Bug 1200555.

Change-Id: Ibc36453caa174432b69597b1b2a0b314a7730357
",git fetch https://review.opendev.org/openstack/cinder refs/changes/67/37167/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/v2/views/volumes.py', 'cinder/tests/api/v2/test_volumes.py']",2,c562ac705229710068c7f57fb87d2ab0f4fe54a0,bug/1200555," 'user_id': 'fakeuser', 'user_id': 'fakeuser', 'user_id': 'fakeuser', 'user_id': 'fakeuser', 'user_id': 'fakeuser',",,7,1
openstack%2Fpython-cinderclient~master~I4a53fd545ed3b446441302d00a429168a996a34a,openstack/python-cinderclient,master,I4a53fd545ed3b446441302d00a429168a996a34a,Add os-services extension support,MERGED,2013-06-27 05:31:50.000000000,2013-07-17 05:02:07.000000000,2013-07-17 05:02:07.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2468}, {'_account_id': 2759}, {'_account_id': 7156}, {'_account_id': 7494}]","[{'number': 1, 'created': '2013-06-27 05:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/730b90558e2c2c7cbca66bf6e59114ee1bb89cb5', 'message': 'Add os-services extension support\n\nImplement client bindings for Cinder os-services API extension, so\nclient would be able to list services, enable or disable particular\nservices.\n\nUsage:\ncinder service-list [--host <hostname>] [--binary <binary>]\ncinder service-enable <hostname> <binary>\ncinder service-disable <hostname> <binary>\n\nThis change is depended on following change at Cinder side\nI7f3fa889294ca6caebdf46b8689345bcac1cdf54\n\nImplements blueprint os-services-extension\n\nChange-Id: I4a53fd545ed3b446441302d00a429168a996a34a\n'}, {'number': 2, 'created': '2013-06-27 06:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/dbdc9f96ece557d9d307f276160bf3b83d217b07', 'message': 'Add os-services extension support\n\nImplement client bindings for Cinder os-services API extension, so\nclient would be able to list services, enable or disable particular\nservices.\n\nUsage:\ncinder service-list [--host <hostname>] [--binary <binary>]\ncinder service-enable <hostname> <binary>\ncinder service-disable <hostname> <binary>\n\nThis change is depended on following change at Cinder side\nI7f3fa889294ca6caebdf46b8689345bcac1cdf54\n\nImplements blueprint os-services-extension\n\nChange-Id: I4a53fd545ed3b446441302d00a429168a996a34a\n'}, {'number': 3, 'created': '2013-06-27 06:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/fdcf326c0f1c2c269eb061059d3bb69d36de1f1d', 'message': 'Add os-services extension support\n\nImplement client bindings for Cinder os-services API extension, so\nclient would be able to list services, enable or disable particular\nservices.\n\nUsage:\ncinder service-list [--host <hostname>] [--binary <binary>]\ncinder service-enable <hostname> <binary>\ncinder service-disable <hostname> <binary>\n\nThis change is depended on following change at Cinder side\nI7f3fa889294ca6caebdf46b8689345bcac1cdf54\n\nImplements blueprint os-services-extension\n\nChange-Id: I4a53fd545ed3b446441302d00a429168a996a34a\n'}, {'number': 4, 'created': '2013-06-30 09:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/ac3baafd49cb128065d23127389b55be8430a348', 'message': 'Add os-services extension support\n\nImplement client bindings for Cinder os-services API extension, so\nclient would be able to list services, enable or disable particular\nservices.\n\nUsage:\ncinder service-list [--host <hostname>] [--binary <binary>]\ncinder service-enable <hostname> <binary>\ncinder service-disable <hostname> <binary>\n\nThis change is depended on following change at Cinder side\nI7f3fa889294ca6caebdf46b8689345bcac1cdf54\n\nImplements blueprint os-services-extension\n\nChange-Id: I4a53fd545ed3b446441302d00a429168a996a34a\n'}, {'number': 5, 'created': '2013-07-14 15:18:47.000000000', 'files': ['cinderclient/tests/v2/test_services.py', 'cinderclient/v2/services.py', 'cinderclient/tests/v1/test_services.py', 'cinderclient/tests/v2/fakes.py', 'cinderclient/v1/client.py', 'cinderclient/v1/shell.py', 'cinderclient/tests/v1/fakes.py', 'cinderclient/v2/client.py', 'cinderclient/v1/services.py', 'cinderclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/627b616227badd893ff2d8d7addf162d605b2299', 'message': 'Add os-services extension support\n\nImplement client bindings for Cinder os-services API extension, so\nclient would be able to list services, enable or disable particular\nservices.\n\nUsage:\ncinder service-list [--host <hostname>] [--binary <binary>]\ncinder service-enable <hostname> <binary>\ncinder service-disable <hostname> <binary>\n\nThis change is depended on following change at Cinder side\nI7f3fa889294ca6caebdf46b8689345bcac1cdf54\n\nImplements blueprint os-services-extension\n\nChange-Id: I4a53fd545ed3b446441302d00a429168a996a34a\n'}]",8,34674,627b616227badd893ff2d8d7addf162d605b2299,26,6,5,2468,,,0,"Add os-services extension support

Implement client bindings for Cinder os-services API extension, so
client would be able to list services, enable or disable particular
services.

Usage:
cinder service-list [--host <hostname>] [--binary <binary>]
cinder service-enable <hostname> <binary>
cinder service-disable <hostname> <binary>

This change is depended on following change at Cinder side
I7f3fa889294ca6caebdf46b8689345bcac1cdf54

Implements blueprint os-services-extension

Change-Id: I4a53fd545ed3b446441302d00a429168a996a34a
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/74/34674/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/tests/v2/fakes.py', 'cinderclient/v1/client.py', 'cinderclient/v1/shell.py', 'cinderclient/tests/v1/fakes.py', 'cinderclient/v2/client.py', 'cinderclient/v2/shell.py']",6,730b90558e2c2c7cbca66bf6e59114ee1bb89cb5,bp/os-services-extension," @utils.arg('--host', metavar='<hostname>', default=None, help='Name of host.') @utils.arg('--binary', metavar='<binary>', default=None, help='Service binary.') @utils.service_type('volume') def do_service_list(cs, args): """"""List all the services. Filter by host & service name."""""" result = cs.services.list(host=args.host, binary=args.binary) columns = [""Binary"", ""Host"", ""Zone"", ""Status"", ""State"", ""Updated_at""] utils.print_list(result, columns) @utils.arg('host', metavar='<hostname>', help='Name of host.') @utils.arg('binary', metavar='<binary>', help='Service binary.') @utils.service_type('volume') def do_service_enable(cs, args): """"""Enable the service"""""" cs.services.enable(args.host, args.binary) @utils.arg('host', metavar='<hostname>', help='Name of host.') @utils.arg('binary', metavar='<binary>', help='Service binary.') @utils.service_type('volume') def do_service_disable(cs, args): """"""Disable the service"""""" cs.services.disable(args.host, args.binary)",,146,0
openstack%2Fkeystone~master~I9fb2c4f5c32ed8c2ce8ba4038caaae39590f8c1a,openstack/keystone,master,I9fb2c4f5c32ed8c2ce8ba4038caaae39590f8c1a,Fix XML rendering with empty auth payload.,MERGED,2013-07-17 02:52:08.000000000,2013-07-17 05:01:59.000000000,2013-07-17 05:01:59.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-17 02:52:08.000000000', 'files': ['keystone/auth/controllers.py', 'keystone/token/controllers.py', 'keystone/common/serializer.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/71edac1585fd3cf6333e8f642339ce63784d4f53', 'message': ""Fix XML rendering with empty auth payload.\n\nJust add some sensible defaults to places where XML parses for example\nan empty dictionary as an empty string. Also 'access' shouldn't be\nconsidered a plural.\n\nChange-Id: I9fb2c4f5c32ed8c2ce8ba4038caaae39590f8c1a\n""}]",0,37377,71edac1585fd3cf6333e8f642339ce63784d4f53,7,4,1,7191,,,0,"Fix XML rendering with empty auth payload.

Just add some sensible defaults to places where XML parses for example
an empty dictionary as an empty string. Also 'access' shouldn't be
considered a plural.

Change-Id: I9fb2c4f5c32ed8c2ce8ba4038caaae39590f8c1a
",git fetch https://review.opendev.org/openstack/keystone refs/changes/77/37377/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/auth/controllers.py', 'keystone/token/controllers.py', 'keystone/common/serializer.py']",3,71edac1585fd3cf6333e8f642339ce63784d4f53,bp/authentication-tied-to-token, if (decoded_tag[-1] == 's' and len(values) == 0 and decoded_tag != 'access'):, if decoded_tag[-1] == 's' and len(values) == 0:,8,2
openstack%2Fkeystone~master~I9dda6dbe073f03806bdf539db6faa01644109f1c,openstack/keystone,master,I9dda6dbe073f03806bdf539db6faa01644109f1c,Pluggable Remote User,MERGED,2013-07-12 14:25:08.000000000,2013-07-17 05:01:51.000000000,2013-07-17 05:01:50.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 6460}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-07-12 14:25:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/baa9d050492b8642a244cbce37a7339128249ae5', 'message': 'Pluggable Remote User\n\nSelect the code to handle REMOTE_USER based on a config file option\n\nblueprint pluggable-remote-user\n\nChange-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c\n'}, {'number': 2, 'created': '2013-07-15 17:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d19f36b9923cbd649bf10861d2c11941e7daed5a', 'message': 'Pluggable Remote User\n\nSelect the code to handle REMOTE_USER based on a config file option\n\nFixes the REMOTE_USER logic to get the domain name from\nREALM, which is the least surprise option.\n\nDisregards the auth_data passed in, as we should be using REMOTE_USER\nto get the user name.\n\nblueprint pluggable-remote-user\n\nChange-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c\n'}, {'number': 4, 'created': '2013-07-15 19:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9d481acbc07d0cda2c2ebfe5f37650b559555f21', 'message': 'Pluggable Remote User\n\nSelect the code to handle REMOTE_USER based on a config file option\n\nFixes the REMOTE_USER logic to get the domain name from\nREALM, which is the least surprise option.\n\nDisregards the auth_data passed in, as we should be using REMOTE_USER\nto get the user name.\n\nblueprint pluggable-remote-user\n\nChange-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c\n'}, {'number': 3, 'created': '2013-07-15 19:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fc16a553f62d1de54062180f101e8778760ada5d', 'message': 'Pluggable Remote User\n\nSelect the code to handle REMOTE_USER based on a config file option\n\nFixes the REMOTE_USER logic to get the domain name from\nREALM, which is the least surprise option.\n\nDisregards the auth_data passed in, as we should be using REMOTE_USER\nto get the user name.\n\nblueprint pluggable-remote-user\n\nChange-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c\n'}, {'number': 5, 'created': '2013-07-16 01:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/15f4b70de37327064c3a8bf08a0e05787f997829', 'message': 'Pluggable Remote User\n\nSelect the code to handle REMOTE_USER based on a config file option\n\nFixes the REMOTE_USER logic to get the domain name from\nREALM, which is the least surprise option.\n\nDisregards the auth_data passed in, as we should be using REMOTE_USER\nto get the user name.\n\nExternal Plugin is inow executed in conjunction with the auth methods,\nas opposed to in place of them.\n\nblueprint pluggable-remote-user\n\nChange-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c\n'}, {'number': 6, 'created': '2013-07-16 16:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8894cf0c9b1003dbd1679d3c89dd8b64b243ded8', 'message': 'Pluggable Remote User\n\nSelect the code to handle REMOTE_USER based on a config file option\n\nFixes the REMOTE_USER logic to get the domain name from\nREALM, which is the least surprise option.\n\nDisregards the auth_data passed in, as we should be using REMOTE_USER\nto get the user name.\n\nExternal Plugin is inow executed in conjunction with the auth methods,\nas opposed to in place of them.\n\nblueprint pluggable-remote-user\n\nChange-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c\n'}, {'number': 7, 'created': '2013-07-16 20:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/580abdcbd7e09c231bb5698db9088ce7563bcc73', 'message': 'Pluggable Remote User\n\nSelect the code to handle REMOTE_USER based on a config file option\n\nFixes the REMOTE_USER logic to get the domain name from\nREALM, which is the least surprise option.\n\nDisregards the auth_data passed in, as we should be using REMOTE_USER\nto get the user name.\n\nExternal Plugin is inow executed in conjunction with the auth methods,\nas opposed to in place of them.\n\nblueprint pluggable-remote-user\n\nChange-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c\n'}, {'number': 8, 'created': '2013-07-16 21:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7ad2aab3b21174be4cf349f8cde1f7930a961986', 'message': 'Pluggable Remote User\n\nSelect the code to handle REMOTE_USER based on a config file option\n\nFixes the REMOTE_USER logic to get the domain name from\nREALM, which is the least surprise option.\n\nDisregards the auth_data passed in, as we should be using REMOTE_USER\nto get the user name.\n\nExternal Plugin is now executed in conjunction with the auth methods,\nas opposed to in place of them.\n\nDocImpact\n\nblueprint pluggable-remote-user\n\nChange-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c\n'}, {'number': 9, 'created': '2013-07-16 23:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/426b612b56ca5f9fc1d6af922b918641a2d533c7', 'message': 'Pluggable Remote User\n\nSelect the code to handle REMOTE_USER based on a config file option\n\nFixes the REMOTE_USER logic to get the domain name from\nREALM, which is the least surprise option.\n\nDisregards the auth_data passed in, as we should be using REMOTE_USER\nto get the user name.\n\nExternal Plugin is now executed in conjunction with the auth methods,\nas opposed to in place of them.\n\nDocImpact\n\nblueprint pluggable-remote-user\n\nChange-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c\n'}, {'number': 10, 'created': '2013-07-17 02:52:10.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/auth/controllers.py', 'keystone/common/config.py', 'tests/test_auth_plugin.conf', 'keystone/auth/plugins/external.py', 'doc/source/configuration.rst', 'tests/auth_plugin_external_domain.conf', 'tests/test_v3_auth.py', 'tests/auth_plugin_external_disabled.conf'], 'web_link': 'https://opendev.org/openstack/keystone/commit/88c319e6bce98082f9a90b8b27726793d5366326', 'message': 'Pluggable Remote User\n\nSelect the code to handle REMOTE_USER based on a config file option\n\nFixes the REMOTE_USER logic to get the domain name from\nREALM, which is the least surprise option.\n\nDisregards the auth_data passed in, as we should be using REMOTE_USER\nto get the user name.\n\nExternal Plugin is now executed in conjunction with the auth methods,\nas opposed to in place of them.\n\nDocImpact\n\nblueprint pluggable-remote-user\n\nChange-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c\n'}]",54,36839,88c319e6bce98082f9a90b8b27726793d5366326,60,9,10,2218,,,0,"Pluggable Remote User

Select the code to handle REMOTE_USER based on a config file option

Fixes the REMOTE_USER logic to get the domain name from
REALM, which is the least surprise option.

Disregards the auth_data passed in, as we should be using REMOTE_USER
to get the user name.

External Plugin is now executed in conjunction with the auth methods,
as opposed to in place of them.

DocImpact

blueprint pluggable-remote-user

Change-Id: I9dda6dbe073f03806bdf539db6faa01644109f1c
",git fetch https://review.opendev.org/openstack/keystone refs/changes/39/36839/9 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/auth/controllers.py', 'keystone/common/config.py', 'keystone/auth/plugins/external.py']",3,baa9d050492b8642a244cbce37a7339128249ae5,bp/authentication-tied-to-token,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2013 OpenStack LLC # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Keystone External Authentication Plugin"""""" from keystone import exception class External(object): def authenticate(self, context, auth_info, auth_context): username = context['REMOTE_USER'] # FIXME(gyee): REMOTE_USER is not good enough since we are # requiring domain_id to do user lookup now. Try to get # the user_id from auth_info for now, assuming external auth # has check to make sure user is the same as the one specify # in ""identity"". if 'password' in auth_info.get_method_names(): user_info = auth_info.get_method_data('password') user_ref = auth_info.lookup_user(user_info['user']) auth_context['user_id'] = user_ref['id'] else: msg = _('Unable to lookup user %s') % (username) raise exception.Unauthorized(msg) ",,44,20
openstack%2Fheat~master~I6c4692df71dc7188c0a9caf0ca6c26b67b4e168f,openstack/heat,master,I6c4692df71dc7188c0a9caf0ca6c26b67b4e168f,Fix resource-data delete bug.,MERGED,2013-07-16 21:33:34.000000000,2013-07-17 03:52:40.000000000,2013-07-17 03:52:40.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6488}, {'_account_id': 7256}]","[{'number': 1, 'created': '2013-07-16 21:33:34.000000000', 'files': ['heat/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/319d3e158f0d92c0f3d1e20095db8db6f056365c', 'message': 'Fix resource-data delete bug.\n\nBug 1201974.\n\nChange-Id: I6c4692df71dc7188c0a9caf0ca6c26b67b4e168f\n'}]",1,37334,319d3e158f0d92c0f3d1e20095db8db6f056365c,9,4,1,7253,,,0,"Fix resource-data delete bug.

Bug 1201974.

Change-Id: I6c4692df71dc7188c0a9caf0ca6c26b67b4e168f
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/37334/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/db/sqlalchemy/models.py'],1,319d3e158f0d92c0f3d1e20095db8db6f056365c,bug/1201974," data = relationship(ResourceData, cascade=""all,delete"", backref=backref('resource', lazy='joined'))"," data = relationship(ResourceData, backref=backref('resources', lazy='joined'))",3,2
openstack%2Fglance~master~I4cdeccdb518972c0280e59c984ed6b001dafe243,openstack/glance,master,I4cdeccdb518972c0280e59c984ed6b001dafe243,Adding Cinder backend storage driver to Glance,MERGED,2013-06-13 10:33:04.000000000,2013-07-17 03:52:32.000000000,2013-07-17 03:52:32.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1207}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 5313}, {'_account_id': 6159}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 6737}]","[{'number': 1, 'created': '2013-06-13 10:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ca74719d04673f0af9aa409ba8e09d9df8b60c3a', 'message': ""Adding Cinder backend storage driver to Glance\n\nThis change allows Glance drive Cinder as a block storage backend to\nstore image data.\nBefore this we already use swift as an object storage backend to save\nimage.\n\nCurrently the patch is a partial implementation, after Cinder 'brick'\nlibrary or 'host-volume-attaching' enhancement ready, the store will\nsupport ADD/GET/DELETE interface finally.\n\nblueprint: glance-cinder-driver\n\nChange-Id: I4cdeccdb518972c0280e59c984ed6b001dafe243\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>""}, {'number': 2, 'created': '2013-06-14 08:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2849d018544740bb2dbec24657dd82295dececaf', 'message': ""Adding Cinder backend storage driver to Glance\n\nThis change allows Glance drive Cinder as a block storage backend to\nstore image data.\nBefore this we already use swift as an object storage backend to save\nimage.\n\nCurrently the patch is a partial implementation, after Cinder 'brick'\nlibrary or 'host-volume-attaching' enhancement ready, the store will\nsupport ADD/GET/DELETE interface finally.\n\nblueprint: glance-cinder-driver\n\nChange-Id: I4cdeccdb518972c0280e59c984ed6b001dafe243\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 3, 'created': '2013-06-29 05:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ec68ce9881f67b1a5034989ae20884d7e6639fdc', 'message': ""Adding Cinder backend storage driver to Glance\n\nThis change allows Glance drive Cinder as a block storage backend to\nstore image data.\nBefore this we already use swift as an object storage backend to save\nimage.\n\nCurrently the patch is a partial implementation, after Cinder expose\n'brick' library, 'host-volume-attaching' and 'multiple-attaching'\nenhancement ready, the store will support ADD/GET/DELETE interface\nfinally.\n\nblueprint: glance-cinder-driver\n\nChange-Id: I4cdeccdb518972c0280e59c984ed6b001dafe243\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 4, 'created': '2013-07-10 10:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/40677b33c46fb6b328e271d32c1deee9ad1ed8e9', 'message': ""Adding Cinder backend storage driver to Glance\n\nThis change allows Glance drive Cinder as a block storage backend to\nstore image data.\nBefore this we already use swift as an object storage backend to save\nimage.\n\nCurrently the patch is a partial implementation, after Cinder expose\n'brick' library, 'host-volume-attaching' and 'multiple-attaching'\nenhancement ready, the store will support ADD/GET/DELETE interface\nfinally.\n\nblueprint: glance-cinder-driver\n\nChange-Id: I4cdeccdb518972c0280e59c984ed6b001dafe243\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 5, 'created': '2013-07-10 10:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c6ddf72a7c3c488ab5695588065fbc6e91e8ab72', 'message': ""Adding Cinder backend storage driver to Glance\n\nThis change allows Glance drive Cinder as a block storage backend to\nstore image data.\nBefore this we already use swift as an object storage backend to save\nimage.\n\nCurrently the patch is a partial implementation, after Cinder expose\n'brick' library, 'host-volume-attaching' and 'multiple-attaching'\nenhancement ready, the store will support ADD/GET/DELETE interface\nfinally.\n\nblueprint: glance-cinder-driver\n\nChange-Id: I4cdeccdb518972c0280e59c984ed6b001dafe243\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 6, 'created': '2013-07-10 11:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ec0a7738fb087245bcb1a0f7b7a320dbf273f6be', 'message': ""Adding Cinder backend storage driver to Glance\n\nThis change allows Glance drive Cinder as a block storage backend to\nstore image data.\nBefore this we already use swift as an object storage backend to save\nimage.\n\nCurrently the patch is a partial implementation, after Cinder expose\n'brick' library, 'host-volume-attaching' and 'multiple-attaching'\nenhancement ready, the store will support ADD/GET/DELETE interface\nfinally.\n\nblueprint: glance-cinder-driver\n\nChange-Id: I4cdeccdb518972c0280e59c984ed6b001dafe243\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 7, 'created': '2013-07-16 09:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/950ef28f519c904944f2059b94206a16946aef48', 'message': ""Adding Cinder backend storage driver to Glance\n\nThis change allows Glance drive Cinder as a block storage backend to\nstore image data.\nBefore this we already use swift as an object storage backend to save\nimage.\n\nCurrently the patch is a partial implementation, after Cinder expose\n'brick' library, 'host-volume-attaching' and 'multiple-attaching'\nenhancement ready, the store will support ADD/GET/DELETE interface\nfinally.\n\nblueprint: glance-cinder-driver\n\nChange-Id: I4cdeccdb518972c0280e59c984ed6b001dafe243\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 8, 'created': '2013-07-16 11:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/10b1dfdf536c4c5fd2e319208abfab36c091afc0', 'message': ""Adding Cinder backend storage driver to Glance\n\nThis change allows Glance drive Cinder as a block storage backend to\nstore image data.\nBefore this we already use swift as an object storage backend to save\nimage.\n\nCurrently the patch is a partial implementation, after Cinder expose\n'brick' library, 'host-volume-attaching' and 'multiple-attaching'\nenhancement ready, the store will support ADD/GET/DELETE interface\nfinally.\n\nblueprint: glance-cinder-driver\n\nChange-Id: I4cdeccdb518972c0280e59c984ed6b001dafe243\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 9, 'created': '2013-07-16 22:30:40.000000000', 'files': ['glance/store/__init__.py', 'glance/tests/functional/store/test_cinder.py', 'glance/common/exception.py', 'glance/tests/functional/store/__init__.py', 'doc/source/configuring.rst', 'glance/store/location.py', 'glance/store/cinder.py', 'etc/glance-cache.conf', 'glance/tests/unit/test_cinder_store.py', 'glance/tests/unit/test_store_location.py', 'etc/glance-api.conf', 'glance/api/v1/images.py', 'tools/pip-requires'], 'web_link': 'https://opendev.org/openstack/glance/commit/d13493be80be66b7ac98e08534b3c59334b75f41', 'message': ""Adding Cinder backend storage driver to Glance\n\nThis change allows Glance drive Cinder as a block storage backend to\nstore image data.\nBefore this we already use swift as an object storage backend to save\nimage.\n\nCurrently the patch is a partial implementation, after Cinder expose\n'brick' library, 'host-volume-attaching' and 'multiple-attaching'\nenhancement ready, the store will support ADD/GET/DELETE interface\nfinally.\n\nblueprint: glance-cinder-driver\n\nChange-Id: I4cdeccdb518972c0280e59c984ed6b001dafe243\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}]",16,32864,d13493be80be66b7ac98e08534b3c59334b75f41,45,10,9,6549,,,0,"Adding Cinder backend storage driver to Glance

This change allows Glance drive Cinder as a block storage backend to
store image data.
Before this we already use swift as an object storage backend to save
image.

Currently the patch is a partial implementation, after Cinder expose
'brick' library, 'host-volume-attaching' and 'multiple-attaching'
enhancement ready, the store will support ADD/GET/DELETE interface
finally.

blueprint: glance-cinder-driver

Change-Id: I4cdeccdb518972c0280e59c984ed6b001dafe243
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/64/32864/8 && git format-patch -1 --stdout FETCH_HEAD,"['glance/store/__init__.py', 'glance/common/exception.py', 'etc/glance-api.conf', 'doc/source/configuring.rst', 'glance/api/v1/images.py', 'glance/store/location.py', 'tools/pip-requires', 'glance/store/cinder.py', 'etc/glance-cache.conf']",9,ca74719d04673f0af9aa409ba8e09d9df8b60c3a,,"# glance.store.http.Store, # glance.store.rbd.Store, # glance.store.s3.Store, # glance.store.swift.Store, # glance.store.cinder.Store,# ============ Cinder Store Options =========================== # Info to match when looking for cinder in the service catalog # Format is : separated values of the form: # <service_type>:<service_name>:<endpoint_type> (string value) #cinder_catalog_info = volume:cinder:publicURL # Override service catalog lookup with template for cinder endpoint # e.g. http://localhost:8776/v1/%(project_id)s (string value) #cinder_endpoint_template = <None> # Region name of this node (string value) #os_region_name = <None> # Location of ca certicates file to use for cinder client requests # (string value) #cinder_ca_certificates_file = <None> # Number of cinderclient retries on failed http calls (integer value) #cinder_http_retries = 3 # Allow to perform insecure SSL requests to cinder (boolean value) #cinder_api_insecure = False ","# glance.store.http.Store, # glance.store.rbd.Store, # glance.store.s3.Store, # glance.store.swift.Store,",318,8
openstack%2Fcinder~master~Idf3a75f2e799c16b1442a349e0724d3e5af2795a,openstack/cinder,master,Idf3a75f2e799c16b1442a349e0724d3e5af2795a,"Mark methods used in class only with prefix ""_""",MERGED,2013-07-14 23:07:35.000000000,2013-07-17 03:52:30.000000000,2013-07-17 03:52:29.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 6737}, {'_account_id': 6743}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-14 23:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce0179f738701217e2de10ac86b40fde047946f5', 'message': 'Mark methods used in class only with prefix ""_""\n\nIn the swift driver the three methods �prepare_nbackup, backup_chunk\nand finalize_backup are used internally in the class only and are\nnot meant to be used from outside. Thus marked with prefix ""_""\n\nChange-Id: Idf3a75f2e799c16b1442a349e0724d3e5af2795a\n'}, {'number': 2, 'created': '2013-07-16 09:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71450ea6409ddaaf311f2be1f137e3e22927f48a', 'message': 'Mark methods used in class only with prefix ""_""\n\nIn the swift driver the three methods ¿½prepare_nbackup, backup_chunk\nand finalize_backup are used internally in the class only and are\nnot meant to be used from outside. Thus marked with prefix ""_""\n\nChange-Id: Idf3a75f2e799c16b1442a349e0724d3e5af2795a\n'}, {'number': 3, 'created': '2013-07-16 10:57:38.000000000', 'files': ['cinder/backup/drivers/swift.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2fd5e00ce51146f376f4d0aae712c650ebc6f6ed', 'message': 'Mark methods used in class only with prefix ""_""\n\nIn the swift driver the three methods prepare_nbackup, backup_chunk\nand finalize_backup are used internally in the class only and are\nnot meant to be used from outside. Thus marked with prefix ""_""\n\nChange-Id: Idf3a75f2e799c16b1442a349e0724d3e5af2795a\n'}]",1,37001,2fd5e00ce51146f376f4d0aae712c650ebc6f6ed,21,8,3,6743,,,0,"Mark methods used in class only with prefix ""_""

In the swift driver the three methods prepare_nbackup, backup_chunk
and finalize_backup are used internally in the class only and are
not meant to be used from outside. Thus marked with prefix ""_""

Change-Id: Idf3a75f2e799c16b1442a349e0724d3e5af2795a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/01/37001/3 && git format-patch -1 --stdout FETCH_HEAD,['cinder/backup/drivers/swift.py'],1,ce0179f738701217e2de10ac86b40fde047946f5,swift_cleanup," def _prepare_backup(self, backup): def _backup_chunk(self, backup, container, data, data_offset, object_meta): def _finalize_backup(self, backup, container, object_meta): object_meta, container = self._prepare_backup(backup) self._backup_chunk(backup, container, data, data_offset, object_meta) self._finalize_backup(backup, container, object_meta)"," def prepare_backup(self, backup): def backup_chunk(self, backup, container, data, data_offset, object_meta): def finalize_backup(self, backup, container, object_meta): object_meta, container = self.prepare_backup(backup) self.backup_chunk(backup, container, data, data_offset, object_meta) self.finalize_backup(backup, container, object_meta)",7,7
openstack%2Fglance~master~Ifcfc82060116127f5acb5215b140eef31f7882a4,openstack/glance,master,Ifcfc82060116127f5acb5215b140eef31f7882a4,Rename requires files to standard names.,ABANDONED,2013-05-29 09:08:37.000000000,2013-07-17 03:34:02.000000000,,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6593}, {'_account_id': 6610}]","[{'number': 1, 'created': '2013-05-29 09:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/71776285458b36ab1fc1da48b0b4dda1da97f3e7', 'message': 'Rename requires files to standard names.\n\nRename tools/pip-requires to requirements.txt and tools/test-requires\nto test-requirements.txt. These are standard files, and tools in the\ngeneral world are growing intelligence about them.\n\nChange-Id: Ifcfc82060116127f5acb5215b140eef31f7882a4\nFixes: bug #1179008\n'}, {'number': 2, 'created': '2013-05-29 09:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a51d628ea4a91dd00369cf8a3d4a9b5e2813c41d', 'message': 'Rename requires files to standard names.\n\nRename tools/pip-requires to requirements.txt and tools/test-requires\nto test-requirements.txt. These are standard files, and tools in the\ngeneral world are growing intelligence about them.\n\nChange-Id: Ifcfc82060116127f5acb5215b140eef31f7882a4\nFixes: bug #1179008\n'}, {'number': 3, 'created': '2013-05-30 22:13:18.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'glance/openstack/common/setup.py', 'tools/install_venv.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/glance/commit/e1251a55813c5f845c552f76096aeb6a4d2eac3c', 'message': 'Rename requires files to standard names.\n\nRename tools/pip-requires to requirements.txt and tools/test-requires\nto test-requirements.txt. These are standard files, and tools in the\ngeneral world are growing intelligence about them.\n\nChange-Id: Ifcfc82060116127f5acb5215b140eef31f7882a4\nFixes: bug #1179008\n'}]",1,30848,e1251a55813c5f845c552f76096aeb6a4d2eac3c,13,8,3,6610,,,0,"Rename requires files to standard names.

Rename tools/pip-requires to requirements.txt and tools/test-requires
to test-requirements.txt. These are standard files, and tools in the
general world are growing intelligence about them.

Change-Id: Ifcfc82060116127f5acb5215b140eef31f7882a4
Fixes: bug #1179008
",git fetch https://review.opendev.org/openstack/glance refs/changes/48/30848/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'glance/openstack/common/setup.py', 'tools/install_venv.py', 'tox.ini']",5,71776285458b36ab1fc1da48b0b4dda1da97f3e7,bug/1179008,deps = -r{toxinidir}/tools/requirements.txt -r{toxinidir}/tools/test-requirements.txt,deps = -r{toxinidir}/tools/pip-requires -r{toxinidir}/tools/test-requires,6,8
openstack%2Fneutron~master~I7fcc384cc44d5adc752510847d8ba5f46bbb79fb,openstack/neutron,master,I7fcc384cc44d5adc752510847d8ba5f46bbb79fb,Add VXLAN tunneling support for the ML2 plugin,MERGED,2013-07-06 16:06:39.000000000,2013-07-17 03:32:14.000000000,2013-07-17 03:32:13.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1689}, {'_account_id': 2031}, {'_account_id': 2583}, {'_account_id': 2592}, {'_account_id': 2888}, {'_account_id': 4395}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 7170}]","[{'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a4538664e59dbdc8fd7e4e95d0a3ef571246db90', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6cca2cfa812e6a1e745ed88075a6a1832baaf384', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 3, 'created': '2013-07-08 18:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6790d6e4e25beed366fbb8da416edb1c2e3a6837', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 4, 'created': '2013-07-08 20:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f90f514a6be5fd4642720b7f3abb42569823e4b', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 5, 'created': '2013-07-09 02:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a60d6d9ef5d437d2bfc3ba8bed6aa8bded4c06f', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 6, 'created': '2013-07-09 13:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a34c5cc5d7cee08706303ac3a5e410305bee84b8', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 7, 'created': '2013-07-09 13:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/19fc3c8ed9d3597e0aaeaf2aabe4af1092007676', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 8, 'created': '2013-07-09 20:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/997039f9bc76d59bbaf4c9aa25ec8c0fad7018c8', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 9, 'created': '2013-07-10 13:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/808139c7ae7eea2f61e7d851eb60a8c330ecc1fe', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 10, 'created': '2013-07-10 16:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c9423a4a1d048fa3ed6847e2a72091ef1c049d1', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 11, 'created': '2013-07-10 16:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/946748a3935e3871288d6a9b5c9c6f585ea99652', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 12, 'created': '2013-07-10 20:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/235008d3684c4e4d8c03030168c7648437273cbd', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 13, 'created': '2013-07-11 02:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/15283fceb8b724a29d8f137192667ca50453f98d', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 14, 'created': '2013-07-11 12:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dfb87b48a4b275cc95770bcf9b136519016e1567', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 15, 'created': '2013-07-11 20:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/275c08140395713d6b68d61156940cc7e428b982', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 16, 'created': '2013-07-12 13:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b89a302ee083822d7d6c1c1efc2d1e8625991053', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 17, 'created': '2013-07-12 13:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1882828abab7b7c2a68881c45a44885a67b33058', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 18, 'created': '2013-07-12 21:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d8a5e0c0c260c4fba5d4ceb38f1f8e13a5833b34', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 19, 'created': '2013-07-12 23:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e7d37bab908db88a3ce86155b62686c25a1ce25', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 20, 'created': '2013-07-14 04:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b13b5c43191c408df8bd5864f478aec22c31e3a8', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 21, 'created': '2013-07-14 04:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1c6e2429b7d32726988a846516c810138c83ce2c', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 22, 'created': '2013-07-14 13:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b68eff93772424b14d8a84fc5edd8717992b0557', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 23, 'created': '2013-07-14 13:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f057748caa66a27d1df7a0d20f1b0d610418f9f3', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 24, 'created': '2013-07-14 19:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b509caf739135ffdc2e51b1d1a9e6cff3def15ca', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 25, 'created': '2013-07-15 02:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/19b001a1524488500c24102e854375910f4d2a90', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 26, 'created': '2013-07-15 04:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ed38bf8f114f410d9c813167e328a582b8f99c59', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 27, 'created': '2013-07-16 13:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea8d411fc00a1035ef112ba8a3c5eab435c8a93a', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}, {'number': 28, 'created': '2013-07-16 20:27:52.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/477a4488d3f4_ml2_vxlan_type_driver.py', 'etc/neutron/plugins/ml2/ml2_conf.ini', 'neutron/plugins/ml2/config.py', 'neutron/tests/unit/ml2/test_type_vxlan.py', 'neutron/plugins/ml2/drivers/type_tunnel.py', 'neutron/plugins/ml2/drivers/type_vxlan.py', 'setup.cfg', 'neutron/plugins/ml2/drivers/type_gre.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/81e87775c8ab56c4b4c7b5048041caef7670bc9d', 'message': 'Add VXLAN tunneling support for the ML2 plugin\n\nAdd an ML2 Type Driver for VXLAN networks to allow the creation\nof VXLAN networks with the OVS agent.\n\nChange-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb\nImplements: blueprint ml2-vxlan\n'}]",98,35384,81e87775c8ab56c4b4c7b5048041caef7670bc9d,116,11,28,105,,,0,"Add VXLAN tunneling support for the ML2 plugin

Add an ML2 Type Driver for VXLAN networks to allow the creation
of VXLAN networks with the OVS agent.

Change-Id: I7fcc384cc44d5adc752510847d8ba5f46bbb79fb
Implements: blueprint ml2-vxlan
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/35384/6 && git format-patch -1 --stdout FETCH_HEAD,"['etc/quantum/plugins/ml2/ml2_conf.ini', 'quantum/plugins/ml2/drivers/type_vxlan.py', 'quantum/tests/unit/ml2/test_type_vxlan.py', 'quantum/plugins/ml2/config.py', 'quantum/plugins/ml2/drivers/type_tunnel.py']",5,a4538664e59dbdc8fd7e4e95d0a3ef571246db90,bp/ml2-vxlan,TYPE_VXLAN = 'vxlan' tunnel_type = kwargs.get('tunnel_type'), # TODO(matrohon) tunnel_type should be a list of every tunnel_type that # the agent supports. Should be implemented in bp/ml2-vxlan # tunnel_type = kwargs.get('tunnel_type') tunnel_type = TYPE_GRE,451,8
openstack%2Fcinder~master~I21f979bf2c0ca6910a6437cb6277193f71fed664,openstack/cinder,master,I21f979bf2c0ca6910a6437cb6277193f71fed664,Fixes ceph-backup failure if original volume deleted,MERGED,2013-07-11 19:32:12.000000000,2013-07-17 03:32:11.000000000,2013-07-17 03:32:10.000000000,"[{'_account_id': 3}, {'_account_id': 1107}, {'_account_id': 2166}, {'_account_id': 5997}, {'_account_id': 6737}, {'_account_id': 6743}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-07-11 19:32:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ed71af26373f595dba46287c108532f284172b83', 'message': 'Fixes ceph-backup failure if original volume deleted\n\nFixes: bug #1199661\n\nChange-Id: I21f979bf2c0ca6910a6437cb6277193f71fed664\n'}, {'number': 2, 'created': '2013-07-12 08:56:19.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/backup/drivers/ceph.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f6a8b28dbbb86f97458b80cb5f583725fec4b62f', 'message': 'Fixes ceph-backup failure if original volume deleted\n\nFixes: bug #1199661\n\nChange-Id: I21f979bf2c0ca6910a6437cb6277193f71fed664\n'}]",2,36719,f6a8b28dbbb86f97458b80cb5f583725fec4b62f,14,7,2,6737,,,0,"Fixes ceph-backup failure if original volume deleted

Fixes: bug #1199661

Change-Id: I21f979bf2c0ca6910a6437cb6277193f71fed664
",git fetch https://review.opendev.org/openstack/cinder refs/changes/19/36719/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/backup/drivers/ceph.py']",2,ed71af26373f595dba46287c108532f284172b83,bug/1199661," def _get_backup_base_name(self, volume_id, backup_id): """""" Return name of base image used for backup. """""" # Ensure no unicode return str(""volume-%s.backup.%s"" % (volume_id, backup_id)) backup_name = self._get_backup_base_name(volume['id'], backup_id) backup_name = self._get_backup_base_name(backup['volume_id'], backup['id']) backup_name = self._get_backup_base_name(backup['volume_id'], backup_id)"," def _get_backup_rbd_name(self, vol_name, backup_id): """"""Make sure we use a consistent format for backup names"""""" # ensure no unicode return str(""%s.backup.%s"" % (vol_name, backup_id)) backup_name = self._get_backup_rbd_name(volume['name'], backup_id) volume_id = backup['volume_id'] backup_name = self._get_backup_rbd_name(volume['name'], backup['id']) volume_id = backup['volume_id'] volume = self.db.volume_get(self.context, volume_id) backup_name = self._get_backup_rbd_name(volume['name'], backup_id)",11,11
openstack%2Fcinder~master~I98c399f5d647e14f031018f7fc1cc43bb0d94c84,openstack/cinder,master,I98c399f5d647e14f031018f7fc1cc43bb0d94c84,Increase timeout period for clone volume.,MERGED,2013-07-17 00:29:19.000000000,2013-07-17 03:32:09.000000000,2013-07-17 03:32:09.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5997}]","[{'number': 1, 'created': '2013-07-17 00:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/72733a43f948911d170976e275c638dd4d9cf3fb', 'message': ""Increate timeout period for clone volume.\n\nCurrent timeout value for clone volume in the\nSolidFire driver is 20 seconds, this is fine\nin many cases however there seems to be a\nnumber of customers doing clones of\nvolumes >= 400G.\n\nA populated 400G volume is taking upwards of\n35 seconds to clone in some cases resulting in failure.\n\nThere's no reason not to bump this timeout value up\nsignificantly to a worst case scenario (ie multi-terrabyte volume).\n\nFixes bug: 1202007\n\nChange-Id: I98c399f5d647e14f031018f7fc1cc43bb0d94c84\n""}, {'number': 2, 'created': '2013-07-17 00:30:20.000000000', 'files': ['cinder/volume/drivers/solidfire.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9ce7cdbaeb73031d841cb0943ca1812b149d1c19', 'message': ""Increase timeout period for clone volume.\n\nCurrent timeout value for clone volume in the\nSolidFire driver is 20 seconds, this is fine\nin many cases however there seems to be a\nnumber of customers doing clones of\nvolumes >= 400G.\n\nA populated 400G volume is taking upwards of\n35 seconds to clone in some cases resulting in failure.\n\nThere's no reason not to bump this timeout value up\nsignificantly to a worst case scenario (ie multi-terrabyte volume).\n\nFixes bug: 1202007\n\nChange-Id: I98c399f5d647e14f031018f7fc1cc43bb0d94c84\n""}]",0,37358,9ce7cdbaeb73031d841cb0943ca1812b149d1c19,8,4,2,2243,,,0,"Increase timeout period for clone volume.

Current timeout value for clone volume in the
SolidFire driver is 20 seconds, this is fine
in many cases however there seems to be a
number of customers doing clones of
volumes >= 400G.

A populated 400G volume is taking upwards of
35 seconds to clone in some cases resulting in failure.

There's no reason not to bump this timeout value up
significantly to a worst case scenario (ie multi-terrabyte volume).

Fixes bug: 1202007

Change-Id: I98c399f5d647e14f031018f7fc1cc43bb0d94c84
",git fetch https://review.opendev.org/openstack/cinder refs/changes/58/37358/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/solidfire.py'],1,72733a43f948911d170976e275c638dd4d9cf3fb,bug/1202007, while not found_volume and iteration_count < 600:, while not found_volume and iteration_count < 10:,1,1
openstack%2Fneutron~master~I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66,openstack/neutron,master,I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66,Add gre tunneling support for the ML2 plugin,MERGED,2013-07-06 16:06:39.000000000,2013-07-17 03:32:00.000000000,2013-07-17 03:31:59.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 2888}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7170}]","[{'number': 8, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/77df0413eb693776d06f965c9980f5ba5da6191b', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 9, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4421cc1548337be0b347a8b80ac81138e1a1f2dc', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7896da58bca6e8ef2aad2e83d4669fb6b57cc653', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable teh creation of GRE\ntunnels with the OVS agent\n\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\nImplements: blueprint ml2-gre\n'}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/922efa6381a1f9ed17d9cdeb79bd49cf6e8c35b8', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable teh creation of GRE\ntunnels with the OVS agent\n\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\nImplements: blueprint ml2-gre\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c52658d44fa5ca044edea8011887f52e977a7d2c', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable teh creation of GRE\ntunnels with the OVS agent\n\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\nImplements: blueprint ml2-gre\n'}, {'number': 6, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/db1997cb46a989d52b53e46265e1fd3ac8a70c73', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 7, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/28611b66e5c42d7daed3b157c1b1fbade167da57', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9715f6f98269828f954fb38c07eafbe4af84ead6', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable teh creation of GRE\ntunnels with the OVS agent\n\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\nImplements: blueprint ml2-gre\n'}, {'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/277b8d9590fadc3843b8476b5479f6745e65a81e', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable teh creation of GRE\ntunnels with the OVS agent\n\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\nImplements: blueprint ml2-gre\n'}, {'number': 10, 'created': '2013-07-08 18:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c7a73aa4a708a680d01409b861e189f9da792c69', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 11, 'created': '2013-07-09 07:58:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d85ba88240e36bf2b012604a38d0752fa45bec9b', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 12, 'created': '2013-07-10 15:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1c6c94d1f0928db21df025ad00926b4ecc307fa', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 13, 'created': '2013-07-11 07:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/52b2af64f6be6be608bab8711b0751e3a19050b8', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 14, 'created': '2013-07-11 12:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44888f33f3ab260fdceb86a6fca26ff6dd08e67f', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 15, 'created': '2013-07-11 20:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58a6391f924677719bdf935b5c496923ab5b834a', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 16, 'created': '2013-07-12 21:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3cc46e21d45d0cd9734c9fa4f01ea72ef9254822', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 17, 'created': '2013-07-12 23:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f6869df6e8eb6626ce6dc62a6f3261c9d9ba256d', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 18, 'created': '2013-07-14 04:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3657b9a3e46457cd708e56a9fb96ddfefb432f87', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 19, 'created': '2013-07-14 13:18:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f51adac5483bdc1277a97addcf4027e1de265a8', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 20, 'created': '2013-07-14 13:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b1de6fa72a0bcf62dc15e7e9409c0243a799c2c', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 21, 'created': '2013-07-14 19:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d2b009229becd8fa0066c7cef47032dbae261c35', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 22, 'created': '2013-07-15 02:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1db47ae545d38f86e396cff366eed33c5ac23cd0', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 23, 'created': '2013-07-15 04:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a692a9581139c5a4d8e0ae31617a445ba3fb97f2', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 24, 'created': '2013-07-16 11:26:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b4c4eaeb2403f2e5009218ee3e5263ddc6f2e75', 'message': 'commit 609a96ff2fdb911245ec72acac56ec452f4fe59b\nAuthor: mathieu-rohon <mathieu.rohon@gmail.com>\nDate:   Tue Jul 16 10:56:12 2013 +0200\n\n    Add gre tunneling support for the ML2 plugin\n\n    This patch add the type_driver GRE to enable the creation of GRE\n    tunnels with the OVS agent.\n    No Endpoints ID are managed. Only Endpoint IP are stored in DB,\n    and this IP is proposed as an endpoint ID for the OVS agent.\n    It also fixes the bug 1201471.\n\n    Implements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 25, 'created': '2013-07-16 11:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9610de8ca5d03f872c7a3384d3cddd31a736ac1c', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\nIt also fixes the bug 1201471.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 26, 'created': '2013-07-16 12:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/33f22debb9a563a064a5179f2a6397a6a43ebcc0', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\nIt also fixes the bug 1201471.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 27, 'created': '2013-07-16 12:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c67ca07725178e0527bfe0428f0f9a3489dd72e', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\nIt also fixes the bug 1201471.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 28, 'created': '2013-07-16 13:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ff7e7dce8120506918aaead7507253784baaa7d', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\nIt also fixes the bug 1201471.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}, {'number': 29, 'created': '2013-07-16 14:00:22.000000000', 'files': ['neutron/plugins/ml2/rpc.py', 'etc/neutron/plugins/ml2/ml2_conf.ini', 'neutron/plugins/ml2/config.py', 'neutron/tests/unit/ml2/test_rpcapi.py', 'neutron/plugins/ml2/drivers/type_tunnel.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/rpc.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/ml2/test_type_gre.py', 'neutron/tests/unit/openvswitch/test_ovs_rpcapi.py', 'neutron/db/migration/alembic_migrations/versions/20ae61555e95_ml2_gre_type_driver.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'setup.cfg', 'neutron/plugins/ml2/drivers/type_gre.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6bdfccaf1b011a9354ef82a73500e6ce0967b2ed', 'message': 'Add gre tunneling support for the ML2 plugin\n\nThis patch add the type_driver GRE to enable the creation of GRE\ntunnels with the OVS agent.\nNo Endpoints ID are managed. Only Endpoint IP are stored in DB,\nand this IP is proposed as an endpoint ID for the OVS agent.\nIt also fixes the bug 1201471.\n\nImplements: blueprint ml2-gre\nChange-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66\n'}]",104,33297,6bdfccaf1b011a9354ef82a73500e6ce0967b2ed,119,11,29,2888,,,0,"Add gre tunneling support for the ML2 plugin

This patch add the type_driver GRE to enable the creation of GRE
tunnels with the OVS agent.
No Endpoints ID are managed. Only Endpoint IP are stored in DB,
and this IP is proposed as an endpoint ID for the OVS agent.
It also fixes the bug 1201471.

Implements: blueprint ml2-gre
Change-Id: I1a33a4bd3ebc4c97eecf17a59ce16b8c2066ec66
",git fetch https://review.opendev.org/openstack/neutron refs/changes/97/33297/26 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/plugins/ml2/drivers/type_gre.py', 'quantum/plugins/ml2/db.py', 'quantum/plugins/ml2/plugin.py', 'quantum/tests/unit/ml2/test_rpcapi.py', 'etc/quantum/plugins/ml2/ml2_conf.ini', 'quantum/plugins/openvswitch/agent/ovs_quantum_agent.py', 'quantum/plugins/ml2/config.py', 'quantum/plugins/ml2/rpc.py', 'quantum/tests/unit/ml2/test_type_gre.py', 'setup.cfg', 'quantum/plugins/ml2/drivers/type_tunnel.py']",11,77df0413eb693776d06f965c9980f5ba5da6191b,bug/1201471,"# Copyright (c) 2013 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from abc import ABCMeta, abstractmethod from quantum.common import exceptions as exc from quantum.common import topics from quantum.openstack.common import log LOG = log.getLogger(__name__) TUNNEL = 'tunnel' TYPE_GRE = 'gre' class TunnelTypeDriver(object): """"""Define stable abstract interface for ML2 type drivers. tunnel type networks rely on tunnel endpoints. This class defines abstract methods to manage these endpoints. """""" __metaclass__ = ABCMeta @abstractmethod def add_endpoint(self, ip): """"""Register the endpoint in the type_driver database. param ip: the ip of the endpoint """""" pass @abstractmethod def get_endpoints(self): """"""Get every endpoint managed by the type_driver :returns a list of dict [{id:endpoint_id, ip_address:endpoint_ip},..] """""" pass class TunnelRpcCallbackMixin(object): def __init__(self, notifier, type_manager): self.notifier = notifier self.type_manager = type_manager def tunnel_sync(self, rpc_context, **kwargs): """"""Update new tunnel. Updates the database with the tunnel IP. All listening agents will also be notified about the new tunnel IP. """""" tunnel_ip = kwargs.get('tunnel_ip') # TODO(matrohon) tunnel_type should be a list of every tunnel_type that # the agent supports. Should be implemented in bp/ml2-vxlan # tunnel_type = kwargs.get('tunnel_type') tunnel_type = TYPE_GRE driver = self.type_manager.drivers.get(tunnel_type) if driver: tunnel = driver.obj.add_endpoint(tunnel_ip) tunnels = driver.obj.get_endpoints() entry = dict() entry['tunnels'] = tunnels # Notify all other listening agents self.notifier.tunnel_update(rpc_context, tunnel.ip_address) # Return the list of tunnels IP's to the agent return entry else: msg = _(""network_type value '%s' not supported"") % tunnel_type raise exc.InvalidInput(error_message=msg) class TunnelAgentRpcApiMixin(object): def _get_tunnel_update_topic(self): return topics.get_topic_name(self.topic, TUNNEL, topics.UPDATE) def tunnel_update(self, context, tunnel_ip): self.fanout_cast(context, self.make_msg('tunnel_update', tunnel_ip=tunnel_ip), topic=self._get_tunnel_update_topic()) ",,511,31
openstack%2Fkeystone~master~I35b57ce0df668f12462e96b3467cef0239594e97,openstack/keystone,master,I35b57ce0df668f12462e96b3467cef0239594e97,Implement role assignment inheritance (OS-INHERIT extension),MERGED,2013-07-07 08:30:13.000000000,2013-07-17 03:31:51.000000000,2013-07-17 03:31:50.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-07-07 08:30:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7389f14c758e8a841051a1a5c1c2a22804b9e62a', 'message': ""Implement role assignments inheritance (OS-INHERIT extension)\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, where each\ndict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nEach of the grant api calls is extended to take the\ninherited_to_projects flag, althoulh only valid for domain grants.\nThe response to the list_role_assignments call is also modified to\ntake account of inherited role assignments.\n\nThe extension can be enabled/disabled via a config setting.\n\nWork still to do:\n\n- Modify the 'get_roles_for_user_and_project()' call to interpret\n  inherited roles and exapnd the role list accordingly\n- extend the list_role_assignment response\n- Make the extension discoverable via url\n- Add all the testing for inherited roles\n\nImplements bp/inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 2, 'created': '2013-07-07 08:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/715dc2f9807dade1cf7c521d33f2d74c288fe776', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nEach of the grant api calls is extended to take the\ninherited_to_projects flag, althoulh only valid on domain grants.\nThe response to the list_role_assignments call is also modified to\ntake account of inherited role assignments.\n\nThe extension can be enabled/disabled via a config setting.\n\nWIP - work still to do:\n\n- Modify the 'get_roles_for_user_and_project()' call to interpret\n  inherited roles and exapnd the role list accordingly\n- Extend the list_role_assignment response\n- Make the extension discoverable via url\n- Add all the testing for inherited roles\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 3, 'created': '2013-07-12 14:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/82b21902be1db1281b795a81f9652cf3d385a061', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nThe extension can be enabled/disabled via a config setting.\n\nWIP - Essentailly complet, with the following work still to do:\n\n- Make the extension discoverable via url\n- Make the extnesion disabled by default\n- Fix an issue with sql migration where sqlalchemy appears to\n  try and re-load a lond-deleted table (marked with FIXME)\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nroles assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 4, 'created': '2013-07-12 14:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d3e0a7d01d09a8f162c6472b5e7cee27b8e91169', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nThe extension can be enabled/disabled via a config setting.\n\nWIP - Essentially complete, with the following work still to do:\n\n- Make the extension discoverable via url\n- Make the extnesion disabled by default\n- Fix an issue with sql migration where sqlalchemy appears to\n  try and re-load a lond-deleted table (marked with FIXME)\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nroles assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 5, 'created': '2013-07-12 16:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2e7cba245ba8903cdb4a5c9478d0b6158d131015', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nThe extension can be enabled/disabled via a config setting.\n\nWIP - Essentially complete, with the following work still to do:\n\n- Make the extension discoverable via url\n- Make the extnesion disabled by default\n- Fix an issue with sql migration where sqlalchemy appears to\n  try and re-load a lond-deleted table (marked with FIXME)\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nroles assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 6, 'created': '2013-07-12 23:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5bf59d41eeeba1e65e6bda0cc06a20f0f74a5f51', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n- SQL migration for sqlite is not supported, since sqlite migrations\n  were broken back at 015 and it is not considered worthwile\n  maintaining this.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nroles assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 7, 'created': '2013-07-13 15:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/21ec871355503b50e3f43976b3e9b0511127a1d1', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n- SQL migration for sqlite is not supported, since sqlite migrations\n  were broken back at 015 and it is not considered worthwile\n  maintaining this.  test_sql_upgrade.py has been tested with MySQL\n  to confirm correct functionality.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nroles assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 8, 'created': '2013-07-13 15:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cf913e2fed39c6e999fcc50c4a16f6ae52d42ecf', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n- SQL migration for sqlite is not supported, since sqlite migrations\n  were broken back at 015 and it is not considered worthwile\n  maintaining this.  test_sql_upgrade.py has been tested with MySQL\n  to confirm correct functionality.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 9, 'created': '2013-07-13 22:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3a467771d96739b383083b23536b2e770140f4b9', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n- SQL migration for sqlite is not supported, since sqlite migrations\n  were broken back at 015 and it is not considered worthwile\n  maintaining this.  test_sql_upgrade.py has been tested with MySQL\n  to confirm correct functionality.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 10, 'created': '2013-07-14 20:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bfedc9b858afed0ccfe5bdb718d26a4ea3893a30', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n- SQL migration for sqlite is not supported, since sqlite migrations\n  were broken back at 015 and it is not considered worthwile\n  maintaining this.  test_sql_upgrade.py has been tested with MySQL\n  and Postgresql to confirm correct functionality.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 11, 'created': '2013-07-15 16:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d7fd4bac25786674a98fc5034487c0b80590bc98', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n- SQL migration for sqlite is not supported, since sqlite migrations\n  were broken back at 015 and it is not considered worthwile\n  maintaining this.  test_sql_upgrade.py has been tested with MySQL\n  and Postgresql to confirm correct functionality.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 12, 'created': '2013-07-15 16:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4c4da1f0d497af60b98762febc0d5325b05b1969', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n- SQL migration for sqlite is not supported, since sqlite migrations\n  were broken back at 015 and it is not considered worthwile\n  maintaining this.  test_sql_upgrade.py has been tested with MySQL\n  and Postgresql to confirm correct functionality.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 13, 'created': '2013-07-15 17:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4e19586108e5a29a2dc59676d5e4013edb000efd', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n- SQL migration for sqlite is not supported, since sqlite migrations\n  were broken back at 015 and it is not considered worthwile\n  maintaining this.  test_sql_upgrade.py has been tested with MySQL\n  and Postgresql to confirm correct functionality.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 14, 'created': '2013-07-16 13:27:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/26953cbcd3a77d2ec359617199dbc4b7a259180c', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n- SQL migration for sqlite is not supported, since sqlite migrations\n  were broken back at 015 and it is not considered worthwile\n  maintaining this.  test_sql_upgrade.py has been tested with MySQL\n  and Postgresql to confirm correct functionality.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 15, 'created': '2013-07-16 16:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1bc9d6643cd79fd788f4fd850dd9cc21db40e982', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n- SQL migration for sqlite is not supported, since sqlite migrations\n  were broken back at 015 and it is not considered worthwile\n  maintaining this.  test_sql_upgrade.py has been tested with MySQL\n  and Postgresql to confirm correct functionality.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 16, 'created': '2013-07-16 18:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/72c5cae3f08bc581a4b31e85b79737ec2e1f4291', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 17, 'created': '2013-07-16 18:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f6d127e60e1d213aa91565255fd6f0530f9e7efe', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 18, 'created': '2013-07-16 21:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/38018a7a8f5c02d63e8cd4182239d82caf89122b', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nDocImpact\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 19, 'created': '2013-07-16 21:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c7e9c3ec7c91dabe5aaad5b9be9983d9a08478cc', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nDocImpact\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}, {'number': 20, 'created': '2013-07-16 23:37:44.000000000', 'files': ['tests/test_backend_ldap.py', 'keystone/common/config.py', 'keystone/common/sql/migrate_repo/versions/029_update_assignment_metadata.py', 'doc/source/configuration.rst', 'keystone/assignment/backends/sql.py', 'keystone/identity/controllers.py', 'keystone/common/sql/migrate_repo/versions/028_fixup_group_metadata.py', 'tests/test_sql_upgrade.py', 'tests/test_v3_identity.py', 'keystone/identity/routers.py', 'keystone/assignment/backends/kvs.py', 'etc/keystone.conf.sample', 'keystone/identity/core.py', 'tests/test_v3.py', 'keystone/assignment/core.py', 'tests/test_backend.py', 'tests/test_backend_sql.py', 'keystone/assignment/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7f4891ddc3da7457df09c0cc8bbfe8a888063feb', 'message': ""Implement role assignment inheritance (OS-INHERIT extension)\n\nThis extension allows for project roles to be optionally\ninherited from the owning domain.  The v3 grant APIs are extended\nto take an inherited_to_projects flag.  The GET role_assignments\nAPI will also include these roles in its response, either showing them\nas inherited roles assigned to the domain or, if the 'effective'\nquery parameter is set, will interpret the inheritance and reflect\nthose role assignments on the projects.\n\nThe inherited_to_projects flag is encoded in the role list in\nthe metadata of the relevant entries in the grant tables. The\n'roles' key in the metadata is now a list of dicts, as opposed\nto a simple list, where each dict is either\n\n{'id': role_id} for a regular role, or\n{'id': role_id, 'inherited_to': 'projects'} for an inherited role\n\nRemember that a previous patch had rationalized the way metadata is\nhandled so that its structure is entirely hidden within the driver\nlayer.\n\nThe extension can be enabled/disabled via a config setting.\n\nLimitations:\n\n- The extension is not yet discoverable via url, this will be added\n  as a separate patch when the v3/extensions work is complete.\n\nA separate issue has been discovered with the fact that the v2\ncalls of 'get_projects_for_user()' and 'list_user_projects()'\nshould be rationalized and also honor both group (and inherited)\nrole assignments.  This is being raised as a separate bug.\n\nDocImpact\n\nImplements bp inherited-domain-roles\n\nChange-Id: I35b57ce0df668f12462e96b3467cef0239594e97\n""}]",68,35986,7f4891ddc3da7457df09c0cc8bbfe8a888063feb,83,9,20,5707,,,0,"Implement role assignment inheritance (OS-INHERIT extension)

This extension allows for project roles to be optionally
inherited from the owning domain.  The v3 grant APIs are extended
to take an inherited_to_projects flag.  The GET role_assignments
API will also include these roles in its response, either showing them
as inherited roles assigned to the domain or, if the 'effective'
query parameter is set, will interpret the inheritance and reflect
those role assignments on the projects.

The inherited_to_projects flag is encoded in the role list in
the metadata of the relevant entries in the grant tables. The
'roles' key in the metadata is now a list of dicts, as opposed
to a simple list, where each dict is either

{'id': role_id} for a regular role, or
{'id': role_id, 'inherited_to': 'projects'} for an inherited role

Remember that a previous patch had rationalized the way metadata is
handled so that its structure is entirely hidden within the driver
layer.

The extension can be enabled/disabled via a config setting.

Limitations:

- The extension is not yet discoverable via url, this will be added
  as a separate patch when the v3/extensions work is complete.

A separate issue has been discovered with the fact that the v2
calls of 'get_projects_for_user()' and 'list_user_projects()'
should be rationalized and also honor both group (and inherited)
role assignments.  This is being raised as a separate bug.

DocImpact

Implements bp inherited-domain-roles

Change-Id: I35b57ce0df668f12462e96b3467cef0239594e97
",git fetch https://review.opendev.org/openstack/keystone refs/changes/86/35986/6 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/identity/core.py', 'keystone/common/config.py', 'keystone/identity/backends/kvs.py', 'keystone/identity/backends/sql.py', 'keystone/identity/controllers.py', 'tests/test_backend.py', 'tests/test_v3_identity.py', 'keystone/identity/routers.py', 'keystone/identity/backends/ldap.py']",10,7389f14c758e8a841051a1a5c1c2a22804b9e62a,bp/inherited-domain-roles," return {'roles': [self._role_to_dict(r, False) for r in metadata_ref]}", return {'roles': metadata_ref},226,55
openstack%2Fnova~master~Idd485b591730c6ac025ee57a1242afdd02191b2f,openstack/nova,master,Idd485b591730c6ac025ee57a1242afdd02191b2f,API for shelving,MERGED,2013-06-21 19:09:14.000000000,2013-07-17 03:31:31.000000000,2013-07-17 03:31:29.000000000,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 191}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4328}, {'_account_id': 4393}, {'_account_id': 4715}, {'_account_id': 5441}, {'_account_id': 6488}, {'_account_id': 7629}]","[{'number': 1, 'created': '2013-06-21 19:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f485b91faf996d180c8c3fe416637df05e597cb0', 'message': ""API for shelving\n\nAdds new 'shelve' and 'unshelve' actions to the API.\n\nThe basic idea is that an instance can be put into a shelved state which\nsnapshots it, unless volume backed, and powers it down.  A periodic task\non the compute nodes will clean up the instance after a configurable\nperiod of time(default: 3 days).  This should allow for fast startup\ntimes when an instance is shelved for a night or over a weekend, and\nfree up resources when left longer.\n\nbp shelve-instance\n\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 2, 'created': '2013-06-28 19:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aeca42604c1bfb764084fabac0e1684716f3a7b4', 'message': ""API for shelving\n\nAdds new 'shelve' and 'unshelve' actions to the API.  Exposes the\nfunctionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 3, 'created': '2013-07-02 21:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc17cab3c8751231cc4a616de1acdca963e06ef9', 'message': ""WIP API for shelving\n\nAdds new 'shelve' and 'unshelve' actions to the API.  Exposes the\nfunctionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 4, 'created': '2013-07-03 15:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c3e2157c01f4f86b677945eec2c97eb6727fe0e', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 5, 'created': '2013-07-12 20:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19471f624a7a4407d940f48c99bfc60ac3051564', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 6, 'created': '2013-07-15 19:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c16add5b37ffc90825c3795457dd6c8ead2e17f3', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 7, 'created': '2013-07-15 20:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09efed2dc19e6a4f4784b125a3f92eb41df57778', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 8, 'created': '2013-07-15 20:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/21dd52529b98a3ff395977e36077d399ff3e84b4', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 9, 'created': '2013-07-15 22:14:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aea240782124c753ce338dedd074480ca3eb16da', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 10, 'created': '2013-07-16 01:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38f5331e4d47487901883e08f0240be1a324c303', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 11, 'created': '2013-07-16 11:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c50359c03f08d542569983292032689787068ae', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 12, 'created': '2013-07-16 16:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a07d6b99c15affda7e9a66a98048e9c0eaccdbda', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 13, 'created': '2013-07-16 17:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73635331b0684a5d4ce7eabf27c4488bee9c260e', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 14, 'created': '2013-07-16 17:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0993830e6b7cdca885f936890827deef20e2db8b', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload', and 'unshelve' actions to the API.\nExposes the functionality already provided in the compute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 15, 'created': '2013-07-16 19:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/375fe8012a301a99db2d425100046398f35ea1db', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload'/'shelve_offload'(V3), and 'unshelve'\nactions to the API.  Exposes the functionality already provided in the\ncompute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 16, 'created': '2013-07-16 20:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f96c3316e0afd8a676a9b1f9611ebb31469a75d', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload'/'shelve_offload'(V3), and 'unshelve'\nactions to the API.  Exposes the functionality already provided in the\ncompute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}, {'number': 17, 'created': '2013-07-17 00:18:10.000000000', 'files': ['doc/api_samples/all_extensions/extensions-get-resp.json', 'doc/api_samples/os-shelve/server-post-req.xml', 'nova/tests/integrated/api_samples/os-shelve/server-post-req.xml.tpl', 'nova/tests/integrated/api_samples/os-shelve/os-shelve.json.tpl', 'nova/tests/integrated/api_samples/os-shelve/server-post-resp.xml.tpl', 'etc/nova/policy.json', 'nova/api/openstack/compute/plugins/v3/shelve.py', 'nova/tests/api/openstack/compute/contrib/test_shelve.py', 'doc/api_samples/os-shelve/os-shelve.json', 'nova/api/openstack/common.py', 'doc/api_samples/os-shelve/server-post-resp.xml', 'nova/api/openstack/compute/contrib/shelve.py', 'nova/tests/integrated/api_samples/os-shelve/os-shelve.xml.tpl', 'doc/api_samples/os-shelve/server-post-resp.json', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.xml.tpl', 'nova/tests/integrated/api_samples/os-shelve/server-post-req.json.tpl', 'doc/api_samples/all_extensions/extensions-get-resp.xml', 'doc/api_samples/os-shelve/os-shelve.xml', 'nova/tests/fake_policy.py', 'nova/tests/integrated/api_samples/os-shelve/server-post-resp.json.tpl', 'doc/api_samples/os-shelve/server-post-req.json', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.json.tpl', 'nova/tests/integrated/test_api_samples.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e53fb7dcddfa2ec4cfd8d1ef984577a06344e07a', 'message': ""API for shelving\n\nAdds new 'shelve', 'shelveOffload'/'shelve_offload'(V3), and 'unshelve'\nactions to the API.  Exposes the functionality already provided in the\ncompute api.\n\nPart of bp shelve-instance\n\nCo-author: Dan Smith <danms@us.ibm.com> (Instance objects)\nChange-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f\n""}]",11,34033,e53fb7dcddfa2ec4cfd8d1ef984577a06344e07a,73,14,17,5441,,,0,"API for shelving

Adds new 'shelve', 'shelveOffload'/'shelve_offload'(V3), and 'unshelve'
actions to the API.  Exposes the functionality already provided in the
compute api.

Part of bp shelve-instance

Co-author: Dan Smith <danms@us.ibm.com> (Instance objects)
Change-Id: Idd485b591730c6ac025ee57a1242afdd02191b2f
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/34033/16 && git format-patch -1 --stdout FETCH_HEAD,"['doc/api_samples/all_extensions/extensions-get-resp.json', 'doc/api_samples/os-shelve/server-post-req.xml', 'nova/tests/integrated/api_samples/os-shelve/server-post-req.xml.tpl', 'nova/tests/integrated/api_samples/os-shelve/os-shelve.json.tpl', 'nova/tests/integrated/api_samples/os-shelve/server-post-resp.xml.tpl', 'etc/nova/policy.json', 'doc/api_samples/os-shelve/os-shelve.json', 'doc/api_samples/os-shelve/server-post-resp.xml', 'nova/api/openstack/compute/contrib/shelve.py', 'nova/tests/integrated/api_samples/os-shelve/os-shelve.xml.tpl', 'doc/api_samples/os-shelve/server-post-resp.json', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.xml.tpl', 'nova/tests/integrated/api_samples/os-shelve/server-post-req.json.tpl', 'doc/api_samples/all_extensions/extensions-get-resp.xml', 'doc/api_samples/os-shelve/os-shelve.xml', 'nova/tests/fake_policy.py', 'nova/tests/integrated/api_samples/os-shelve/server-post-resp.json.tpl', 'doc/api_samples/os-shelve/server-post-req.json', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.json.tpl', 'nova/tests/integrated/test_api_samples.py']",20,f485b91faf996d180c8c3fe416637df05e597cb0,bp/shelve-instance,"class ShelveJsonTest(ServersSampleBase): extension_name = ""nova.api.openstack.compute.contrib.shelve.Shelve"" def _test_server_action(self, uuid, action): response = self._do_post('servers/%s/action' % uuid, 'os-shelve', {'action': action}) self.assertEqual(response.status, 202) self.assertEqual(response.read(), """") def test_shelve(self): uuid = self._post_server() self._test_server_action(uuid, 'shelve') def test_unshelve(self): uuid = self._post_server() self._test_server_action(uuid, 'shelve') self._test_server_action(uuid, 'unshelve') class ShelveXmlTest(ShelveJsonTest): ctype = 'xml' ",,257,0
openstack%2Fnova~master~I4938b4f937df7039d77c3b760f7d81b7e7908570,openstack/nova,master,I4938b4f937df7039d77c3b760f7d81b7e7908570,Do not merge: time trial of setting a default value for a col,ABANDONED,2013-07-17 02:20:54.000000000,2013-07-17 03:22:05.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2271}]","[{'number': 1, 'created': '2013-07-17 02:20:54.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/201_add_instance_cleaned.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0f1815bba995f84a4498ad66647d6ac54520b39c', 'message': 'Do not merge: time trial of setting a default value for a col\n\nJust seeing if not setting a default value for a new column is\nfaster or not.\n\nChange-Id: I4938b4f937df7039d77c3b760f7d81b7e7908570\n'}]",0,37376,0f1815bba995f84a4498ad66647d6ac54520b39c,4,3,1,2271,,,0,"Do not merge: time trial of setting a default value for a col

Just seeing if not setting a default value for a new column is
faster or not.

Change-Id: I4938b4f937df7039d77c3b760f7d81b7e7908570
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/37376/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/migrate_repo/versions/201_add_instance_cleaned.py'],1,0f1815bba995f84a4498ad66647d6ac54520b39c,master,"# Copyright 2013 Rackspace Australia # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from sqlalchemy import Column, Index, Integer, MetaData, Table def upgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine instances = Table('instances', meta, autoload=True) shadow_instances = Table('shadow_instances', meta, autoload=True) cleaned_column = Column('cleaned', Integer, default=0) instances.create_column(cleaned_column) shadow_instances.create_column(cleaned_column.copy()) cleaned_index = Index('instances_cleaned_idx', instances.c.cleaned) cleaned_index.create(migrate_engine) def downgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine instances = Table('instances', meta, autoload=True) instances.columns.cleaned.drop() shadow_instances = Table('shadow_instances', meta, autoload=True) shadow_instances.columns.cleaned.drop() ",,41,0
openstack%2Fnova~master~Ie1dffa90b1e339b81883dc14037f7817f1cec15d,openstack/nova,master,Ie1dffa90b1e339b81883dc14037f7817f1cec15d,Fix aggregate update.,MERGED,2013-07-12 13:25:45.000000000,2013-07-17 02:30:03.000000000,2013-07-17 02:29:59.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-07-12 13:25:45.000000000', 'files': ['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d9f88f7b9e2d82ddec32d1b25ffb9e8e46c9232e', 'message': ""Fix aggregate update.\n\nBug description: when update 'availability_zone'\nvalue existing aggregate metadata cleared.\n\nMethod aggregate_update() in sqlalchemy api updated.\n\nFix bug 1200369.\n\nChange-Id: Ie1dffa90b1e339b81883dc14037f7817f1cec15d\n""}]",1,36828,d9f88f7b9e2d82ddec32d1b25ffb9e8e46c9232e,8,5,1,7711,,,0,"Fix aggregate update.

Bug description: when update 'availability_zone'
value existing aggregate metadata cleared.

Method aggregate_update() in sqlalchemy api updated.

Fix bug 1200369.

Change-Id: Ie1dffa90b1e339b81883dc14037f7817f1cec15d
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/36828/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,d9f88f7b9e2d82ddec32d1b25ffb9e8e46c9232e,bug/1200369, set_delete = True set_delete = False set_delete=set_delete), set_delete=True),13,1
openstack%2Fnova~master~Ib58c2934626c28349dd49bafd1b3e781fcbe9cb9,openstack/nova,master,Ib58c2934626c28349dd49bafd1b3e781fcbe9cb9,Fix debug message for GroupAntiAffinityFilter,MERGED,2013-07-05 11:35:33.000000000,2013-07-17 02:29:33.000000000,2013-07-17 02:29:29.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 6873}]","[{'number': 1, 'created': '2013-07-05 11:35:33.000000000', 'files': ['nova/scheduler/filters/affinity_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5b5e1989c1898360fbf3b7182b1ba81998acf401', 'message': 'Fix debug message for GroupAntiAffinityFilter\n\nFix bug 1198109\n\nThe log message in not accurate for GroupAntiAffinityFilter, it\nshould be fixed as ""Group anti affinity""\n\nChange-Id: Ib58c2934626c28349dd49bafd1b3e781fcbe9cb9\n'}]",0,35787,5b5e1989c1898360fbf3b7182b1ba81998acf401,9,6,1,7494,,,0,"Fix debug message for GroupAntiAffinityFilter

Fix bug 1198109

The log message in not accurate for GroupAntiAffinityFilter, it
should be fixed as ""Group anti affinity""

Change-Id: Ib58c2934626c28349dd49bafd1b3e781fcbe9cb9
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/35787/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/filters/affinity_filter.py'],1,5b5e1989c1898360fbf3b7182b1ba81998acf401,bug/1198109," LOG.debug(_(""Group anti affinity: check if %(host)s not "" ""in %(configured)s""), {'host': host_state.host, 'configured': group_hosts})"," LOG.debug(_(""Group affinity: %(host)s in %(configured)s""), {'host': host_state.host, 'configured': group_hosts})",3,3
openstack%2Fnova~master~I781754ae0cb9b2a9f7e7e973f4531f2a99a98d86,openstack/nova,master,I781754ae0cb9b2a9f7e7e973f4531f2a99a98d86,Don't ignore 'capabilities' flavor extra_spec,MERGED,2013-07-08 12:56:37.000000000,2013-07-17 02:29:03.000000000,2013-07-17 02:28:59.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1994}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-07-08 12:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b07810f1f1ef43cf855ae708b792d782aedfe68', 'message': ""Don't ignore 'capabilities' flavor extra_spec\n\nThe ComputeCapabilitiesFilter would improperly ignore an extra spec of\n'capabilities' since it matched the scope name.  When it's not scoped,\nit should be treated as an unscopd extra_spec.\n\nFix bug 1198941.\n\nChange-Id: I781754ae0cb9b2a9f7e7e973f4531f2a99a98d86\n""}, {'number': 2, 'created': '2013-07-16 16:11:18.000000000', 'files': ['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/compute_capabilities_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e0024580d2360d84486a7387df82c2f6a4d3de37', 'message': ""Don't ignore 'capabilities' flavor extra_spec\n\nThe ComputeCapabilitiesFilter would improperly ignore an extra spec of\n'capabilities' since it matched the scope name.  When it's not scoped,\nit should be treated as an unscoped extra_spec.\n\nFix bug 1198941.\n\nChange-Id: I781754ae0cb9b2a9f7e7e973f4531f2a99a98d86\n""}]",6,36074,e0024580d2360d84486a7387df82c2f6a4d3de37,17,6,2,1561,,,0,"Don't ignore 'capabilities' flavor extra_spec

The ComputeCapabilitiesFilter would improperly ignore an extra spec of
'capabilities' since it matched the scope name.  When it's not scoped,
it should be treated as an unscoped extra_spec.

Fix bug 1198941.

Change-Id: I781754ae0cb9b2a9f7e7e973f4531f2a99a98d86
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/36074/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/compute_capabilities_filter.py']",2,9b07810f1f1ef43cf855ae708b792d782aedfe68,bug/1198941," if len(scope) > 1: if scope[0] != ""capabilities"": continue elif scope[0] == ""capabilities"": del scope[0]"," if len(scope) > 1 and scope[0] != ""capabilities"": continue elif scope[0] == ""capabilities"": del scope[0]",12,4
openstack%2Fneutron~master~I531ebe0053b1b9e21d6f0685776acebe3173b170,openstack/neutron,master,I531ebe0053b1b9e21d6f0685776acebe3173b170,Nicira NVP plugin support for l3_ext_gw_mode extension,MERGED,2013-07-06 16:06:39.000000000,2013-07-17 01:50:56.000000000,2013-07-17 01:50:55.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 4395}]","[{'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd8c52eaec5ada7ac47dc11a0af073450edef36d', 'message': ""Nicira NVP plugin support for l3_ext_gw_mode extension\n\nBug 1121129\n\nThis patch adds support the 'configurable external gateway' extension\nin the NVP plugin.\n\nChange-Id: I531ebe0053b1b9e21d6f0685776acebe3173b170\n""}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/738518422f3252c14c179661df4d7fc422523d6f', 'message': ""Nicira NVP plugin support for l3_ext_gw_mode extension\n\nBug 1121129\n\nThis patch adds support the 'configurable external gateway' extension\nin the NVP plugin.\n\nChange-Id: I531ebe0053b1b9e21d6f0685776acebe3173b170\n""}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58da0be3d9db92acbabba2ab211f2f4de8035769', 'message': ""Nicira NVP plugin support for l3_ext_gw_mode extension\n\nBug 1121129\n\nThis patch adds support the 'configurable external gateway' extension\nin the NVP plugin.\n\nChange-Id: I531ebe0053b1b9e21d6f0685776acebe3173b170\n""}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b6f424297d4f8c18a001b2434fb055ac4bfb3e8', 'message': ""Nicira NVP plugin support for l3_ext_gw_mode extension\n\nBug 1121129\n\nThis patch adds support the 'configurable external gateway' extension\nin the NVP plugin.\n\nChange-Id: I531ebe0053b1b9e21d6f0685776acebe3173b170\n""}, {'number': 5, 'created': '2013-07-15 20:41:50.000000000', 'files': ['neutron/db/l3_gwmode_db.py', 'neutron/plugins/nicira/NeutronPlugin.py', 'neutron/tests/unit/nicira/test_nicira_plugin.py', 'neutron/db/migration/alembic_migrations/versions/128e042a2b68_ext_gw_mode.py', 'neutron/tests/unit/test_extension_ext_gw_mode.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/60a392f0aa0d5a8c865e81f65566549b7a753c24', 'message': ""Nicira NVP plugin support for l3_ext_gw_mode extension\n\nBug 1121129\n\nThis patch adds support the 'configurable external gateway' extension\nin the NVP plugin.\n\nChange-Id: I531ebe0053b1b9e21d6f0685776acebe3173b170\n""}]",2,26077,60a392f0aa0d5a8c865e81f65566549b7a753c24,45,7,5,261,,,0,"Nicira NVP plugin support for l3_ext_gw_mode extension

Bug 1121129

This patch adds support the 'configurable external gateway' extension
in the NVP plugin.

Change-Id: I531ebe0053b1b9e21d6f0685776acebe3173b170
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/26077/5 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/tests/unit/test_extension_ext_gw_mode.py', 'quantum/db/l3_gwmode_db.py', 'quantum/tests/unit/nicira/test_nicira_plugin.py', 'quantum/db/migration/alembic_migrations/versions/128e042a2b68_ext_gw_mode.py', 'quantum/plugins/nicira/QuantumPlugin.py']",5,bd8c52eaec5ada7ac47dc11a0af073450edef36d,bug/1121129,"from quantum.db import l3_gwmode_db l3_gwmode_db.L3_NAT_db_mixin, supported_extension_aliases = [""ext-gw-mode"", ""mac-learning"", def _update_router_gw_info(self, context, router_id, info): # NOTE(salvatore-orlando): We need to worry about rollback of NVP # configuration in case of failures in the process # Ref. LP bug 1102301 router = self._get_router(context, router_id) # Check whether SNAT rule update should be triggered # NVP also supports multiple external networks so there is also # the possibility that NAT rules should be replaced current_ext_net_id = router.gw_port_id and router.gw_port.network_id new_ext_net_id = info and info.get('network_id') # SNAT should be enabled unless info['enable_snat'] is # explicitly set to false enable_snat = new_ext_net_id and info.get('enable_snat', True) # Remove if ext net removed, changed, or if snat disabled remove_snat_rules = (current_ext_net_id and new_ext_net_id != current_ext_net_id or router.enable_snat and not enable_snat) # Add rules if snat is enabled, and if either the external network # changed or snat was previously disabled # NOTE: enable_snat == True implies new_ext_net_id != None add_snat_rules = (enable_snat and (new_ext_net_id != current_ext_net_id or not router.enable_snat)) router = super(NvpPluginV2, self)._update_router_gw_info( context, router_id, info, router=router) # Add/Remove SNAT rules as needed # Create an elevated context for dealing with metadata access # cidrs which are created within admin context ctx_elevated = context.elevated() if remove_snat_rules or add_snat_rules: cidrs = self._find_router_subnets_cidrs(ctx_elevated, router_id) if remove_snat_rules: # Be safe and concede NAT rules might not exist. # Therefore use min_num_expected=0 for cidr in cidrs: nvplib.delete_nat_rules_by_match( self.cluster, router_id, ""SourceNatRule"", max_num_expected=1, min_num_expected=0, source_ip_addresses=cidr) if add_snat_rules: ip_addresses = self._build_ip_address_list( ctx_elevated, router.gw_port['fixed_ips']) # Set the SNAT rule for each subnet (only first IP) for cidr in cidrs: cidr_prefix = int(cidr.split('/')[1]) nvplib.create_lrouter_snat_rule( self.cluster, router_id, ip_addresses[0].split('/')[0], ip_addresses[0].split('/')[0], order=NVP_EXTGW_NAT_RULES_ORDER - cidr_prefix, match_criteria={'source_ip_addresses': cidr}) if gw_port and router.enable_snat: # using floating is the floating ip itself."," l3_db.L3_NAT_db_mixin, supported_extension_aliases = [""mac-learning"", # Set the SNAT rule for each subnet (only first IP) for cidr in self._find_router_subnets_cidrs(context, router_id): cidr_prefix = int(cidr.split('/')[1]) nvplib.create_lrouter_snat_rule( self.cluster, router_id, ip_addresses[0].split('/')[0], ip_addresses[0].split('/')[0], order=NVP_EXTGW_NAT_RULES_ORDER - cidr_prefix, match_criteria={'source_ip_addresses': cidr}) # Delete the SNAT rule for each subnet, keep in mind # that the rule might have already been removed from NVP for cidr in self._find_router_subnets_cidrs(context, router_id): nvplib.delete_nat_rules_by_match( self.cluster, router_id, ""SourceNatRule"", max_num_expected=1, min_num_expected=0, source_ip_addresses=cidr) if gw_port: # using floating is the floating ip itself.",73,23
openstack%2Fopenstack-manuals~master~I6a486981bfa7d3ac888fa4af5c2d49f386dc3de0,openstack/openstack-manuals,master,I6a486981bfa7d3ac888fa4af5c2d49f386dc3de0,bug 1197117 modified package name for cpu-checker,MERGED,2013-07-16 07:50:09.000000000,2013-07-17 01:44:01.000000000,2013-07-17 01:44:01.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-16 07:50:09.000000000', 'files': ['doc/src/docbkx/common/kvm.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/85cb1e1d8949b2a2d30c76b6ef6a0a84a8bbdb7c', 'message': 'bug 1197117 modified package name for cpu-checker\n\nChange-Id: I6a486981bfa7d3ac888fa4af5c2d49f386dc3de0\n'}]",0,37190,85cb1e1d8949b2a2d30c76b6ef6a0a84a8bbdb7c,6,3,1,7166,,,0,"bug 1197117 modified package name for cpu-checker

Change-Id: I6a486981bfa7d3ac888fa4af5c2d49f386dc3de0
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/90/37190/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/common/kvm.xml'],1,85cb1e1d8949b2a2d30c76b6ef6a0a84a8bbdb7c,bug/1197117, <prompt>#</prompt> <userinput>apt-get install cpu-checker</userinput>, <prompt>#</prompt> <userinput>apt-get install cpu</userinput>,1,1
openstack%2Fkeystone~master~I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5,openstack/keystone,master,I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5,assignment backend,MERGED,2013-06-20 02:12:43.000000000,2013-07-17 01:40:37.000000000,2013-07-09 18:52:30.000000000,"[{'_account_id': 3}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6456}, {'_account_id': 6460}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-06-20 02:12:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bf386f50fbaa32339d28ecce8af2093e3a38f7cc', 'message': 'assignment backend\n\nmoved assignment delegation functions to id driver\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 2, 'created': '2013-06-20 03:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ae1453d9af9e96d7664c9f4d329ad4810a6d421e', 'message': 'assignment backend\n\nmoved assignment delegation functions to id driver\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 4, 'created': '2013-06-25 03:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4e01769020f47f4f5062e42409472df307fd3adf', 'message': 'assignment backend\n\nmoved assignment delegation functions to Identity Manager\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 3, 'created': '2013-06-25 03:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9a7dab8225c2fcc18549c33983cc94f435d70b5d', 'message': 'assignment backend\n\nmoved assignment delegation functions to Identity Manager\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 5, 'created': '2013-06-26 15:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3d51644dd5c667f98f57cbd6087379736d69743d', 'message': 'assignment backend\n\nmoved assignment delegation functions to Identity Manager\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 6, 'created': '2013-06-28 17:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/914e169f1a72b05538dbee3b55580da83ee36d49', 'message': 'assignment backend\n\nSplits the assignments functions off of the identity api\nand manager, and moved them into their own backend.\n\nTo prevent breaking existing code, this adds assignment delegation\nfunctions to Identity Manager.\n\nThere is a circular dependency between ID and assignments.\n\nThis code is mostly pure refactoring, with no changes to the\nunit tests.  Existing behavior is maintained.\n\nIn the future, we will add unit tests for mixing an LDAP\nidentity provider with a SQL assignment backend.\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 7, 'created': '2013-06-28 17:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/10e95b23046befa5c62631f6e7679bd83ab831b0', 'message': 'assignment backend\n\nSplits the assignments functions off of the identity api\nand manager, and moved them into their own backend.\n\nTo prevent breaking existing code, this adds assignment delegation\nfunctions to Identity Manager.\n\nThere is a circular dependency between ID and assignments.\n\nThis code is mostly pure refactoring, with no changes to the\nunit tests.  Existing behavior is maintained.\n\nIn the future, we will add unit tests for mixing an LDAP\nidentity provider with a SQL assignment backend.\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 8, 'created': '2013-06-28 18:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a2f6d9c367a4dcd2533373f8b8dc8865a36bc401', 'message': 'assignment backend\n\nSplits the assignments functions off of the identity api\nand manager, and moved them into their own backend.\n\nTo prevent breaking existing code, this adds assignment delegation\nfunctions to Identity Manager.\n\nThere is a circular dependency between ID and assignments.\n\nThis code is mostly pure refactoring, with no changes to the\nunit tests.  Existing behavior is maintained.\n\nIn the future, we will add unit tests for mixing an LDAP\nidentity provider with a SQL assignment backend.\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 10, 'created': '2013-06-28 20:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3a19f450afe8875175da58df073a3409c9f9bb65', 'message': 'assignment backend\n\nSplits the assignments functions off of the identity api\nand manager, and moved them into their own backend.\n\nTo prevent breaking existing code, this adds assignment delegation\nfunctions to Identity Manager.\n\nThere is a circular dependency between ID and assignments.\n\nThis code is mostly pure refactoring, with no changes to the\nunit tests.  Existing behavior is maintained.\n\nIn the future, we will add unit tests for mixing an LDAP\nidentity provider with a SQL assignment backend.\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 9, 'created': '2013-06-28 20:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3f76b4c0dde237d4eb78ef4ea6a105dbda1b662f', 'message': 'assignment backend\n\nSplits the assignments functions off of the identity api\nand manager, and moved them into their own backend.\n\nTo prevent breaking existing code, this adds assignment delegation\nfunctions to Identity Manager.\n\nThere is a circular dependency between ID and assignments.\n\nThis code is mostly pure refactoring, with no changes to the\nunit tests.  Existing behavior is maintained.\n\nIn the future, we will add unit tests for mixing an LDAP\nidentity provider with a SQL assignment backend.\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 11, 'created': '2013-07-08 19:44:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4650c827feb484cc28f31046bbac781d93fcf5c9', 'message': 'assignment backend\n\nSplits the assignments functions off of the identity api\nand manager, and moved them into their own backend.\n\nTo prevent breaking existing code, this adds assignment delegation\nfunctions to Identity Manager.\n\nThere is a circular dependency between ID and assignments.\n\nThis code is mostly pure refactoring, with no changes to the\nunit tests.  Existing behavior is maintained.\n\nIn the future, we will add unit tests for mixing an LDAP\nidentity provider with a SQL assignment backend.\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 12, 'created': '2013-07-08 20:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/504dbc21490a4c7c9291e782c340b915764626ee', 'message': 'assignment backend\n\nSplits the assignments functions off of the identity api\nand manager, and moved them into their own backend.\n\nTo prevent breaking existing code, this adds assignment delegation\nfunctions to Identity Manager.\n\nThere is a circular dependency between ID and assignments.\n\nThis code is mostly pure refactoring, with no changes to the\nunit tests.  Existing behavior is maintained.\n\nIn the future, we will add unit tests for mixing an LDAP\nidentity provider with a SQL assignment backend.\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}, {'number': 13, 'created': '2013-07-09 15:57:47.000000000', 'files': ['keystone/test.py', 'keystone/common/sql/legacy.py', 'keystone/common/config.py', 'keystone/assignment/backends/sql.py', 'keystone/common/sql/nova.py', 'keystone/assignment/backends/__init__.py', 'keystone/assignment/backends/kvs.py', 'keystone/identity/backends/ldap.py', 'keystone/token/controllers.py', 'keystone/identity/core.py', 'keystone/identity/backends/kvs.py', 'keystone/identity/backends/sql.py', 'keystone/assignment/__init__.py', 'keystone/common/controller.py', 'keystone/assignment/core.py', 'keystone/common/kvs.py', 'keystone/assignment/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/fafdf072f5a34ee12ffe9d7651551c83459759bb', 'message': 'assignment backend\n\nSplits the assignments functions off of the identity api\nand manager, and moved them into their own backend.\n\nTo prevent breaking existing code, this adds assignment delegation\nfunctions to Identity Manager.\n\nThere is a circular dependency between ID and assignments.\n\nThis code is mostly pure refactoring, with no changes to the\nunit tests.  Existing behavior is maintained.\n\nIn the future, we will add unit tests for mixing an LDAP\nidentity provider with a SQL assignment backend.\n\nblueprint split-identity\n\nChange-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5\n'}]",39,33745,fafdf072f5a34ee12ffe9d7651551c83459759bb,79,11,13,2218,,,0,"assignment backend

Splits the assignments functions off of the identity api
and manager, and moved them into their own backend.

To prevent breaking existing code, this adds assignment delegation
functions to Identity Manager.

There is a circular dependency between ID and assignments.

This code is mostly pure refactoring, with no changes to the
unit tests.  Existing behavior is maintained.

In the future, we will add unit tests for mixing an LDAP
identity provider with a SQL assignment backend.

blueprint split-identity

Change-Id: I6c180aa1ae626ace5b91e0bf1931bdaf2aa031d5
",git fetch https://review.opendev.org/openstack/keystone refs/changes/45/33745/12 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/assignment/backends/sql.py', 'keystone/identity/backends/ldap/core.py', 'tests/test_drivers.py', 'keystone/assignment/backends/__init__.py', 'keystone/assignment/backends/kvs.py', 'keystone/identity/core.py', 'keystone/identity/backends/kvs.py', 'keystone/identity/backends/sql.py', 'keystone/assignment/__init__.py', 'keystone/assignment/core.py', 'keystone/common/kvs.py', 'keystone/assignment/backends/ldap.py']",12,bf386f50fbaa32339d28ecce8af2093e3a38f7cc,bp/split-identity,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2012-2013 OpenStack LLC # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from __future__ import absolute_import import uuid import ldap as ldap from keystone import assignment from keystone import clean from keystone.common import ldap as common_ldap from keystone.common import logging from keystone.common import models from keystone import config from keystone import exception from keystone import identity CONF = config.CONF LOG = logging.getLogger(__name__) DEFAULT_DOMAIN = { 'id': CONF.identity.default_domain_id, 'name': 'Default', 'enabled': True } class Assignment(assignment.Driver): def __init__(self, identity): super(Assignment, self).__init__() self.identity = identity self.LDAP_URL = CONF.ldap.url self.LDAP_USER = CONF.ldap.user self.LDAP_PASSWORD = CONF.ldap.password self.suffix = CONF.ldap.suffix #These are the only deep dependency from assignment back #to identity. The assumption is that if you are using #LDAP for assignments, you are using it for Id as well. self.user = identity.user self.group = identity.group self.project = ProjectApi(CONF) self.role = RoleApi(CONF) def authorize_for_project(self, user_ref, tenant_id=None): user_id = user_ref['id'] tenant_ref = None metadata_ref = {} if tenant_id is not None: if tenant_id not in self.get_projects_for_user(user_id): raise AssertionError('Invalid tenant') try: tenant_ref = self.get_project(tenant_id) # TODO(termie): this should probably be made into a # get roles call metadata_ref = self.get_metadata(user_id, tenant_id) except exception.ProjectNotFound: tenant_ref = None metadata_ref = {} except exception.MetadataNotFound: metadata_ref = {} user_ref = self._set_default_domain(identity.filter_user(user_ref)) return (user_ref, tenant_ref, metadata_ref) def get_project(self, tenant_id): return self._set_default_domain(self.project.get(tenant_id)) def list_projects(self): return self._set_default_domain(self.project.get_all()) def get_project_by_name(self, tenant_name, domain_id): self._validate_domain_id(domain_id) return self._set_default_domain(self.project.get_by_name(tenant_name)) def _validate_domain(self, ref): """"""Validate that either the default domain or nothing is specified. Also removes the domain from the ref so that LDAP doesn't have to persist the attribute. """""" ref = ref.copy() domain_id = ref.pop('domain_id', CONF.identity.default_domain_id) self._validate_domain_id(domain_id) return ref def _validate_domain_id(self, domain_id): """"""Validate that the domain ID specified belongs to the default domain. """""" if domain_id != CONF.identity.default_domain_id: raise exception.DomainNotFound(domain_id=domain_id) def _set_default_domain(self, ref): """"""Overrides any domain reference with the default domain."""""" if isinstance(ref, dict): ref = ref.copy() ref['domain_id'] = CONF.identity.default_domain_id return ref elif isinstance(ref, list): return [self._set_default_domain(x) for x in ref] else: raise ValueError(_('Expected dict or list: %s') % type(ref)) def create_project(self, tenant_id, tenant): tenant = self._validate_domain(tenant) tenant['name'] = clean.project_name(tenant['name']) data = tenant.copy() if 'id' not in data or data['id'] is None: data['id'] = str(uuid.uuid4().hex) if 'description' in data and data['description'] in ['', None]: data.pop('description') return self._set_default_domain(self.project.create(data)) def update_project(self, tenant_id, tenant): tenant = self._validate_domain(tenant) if 'name' in tenant: tenant['name'] = clean.project_name(tenant['name']) return self._set_default_domain(self.project.update(tenant_id, tenant)) def get_metadata(self, user_id=None, tenant_id=None, domain_id=None, group_id=None): if domain_id is not None: raise NotImplemented('Domain metadata not supported by LDAP.') if (not self.get_project(tenant_id) or not self.identity.get_user(user_id)): return {} metadata_ref = self.get_roles_for_user_and_project(user_id, tenant_id) if not metadata_ref: return {} return {'roles': metadata_ref} def get_role(self, role_id): return self.role.get(role_id) def list_roles(self): return self.role.get_all() def get_projects_for_user(self, user_id): self.identity.get_user(user_id) user_dn = self.user._id_to_dn(user_id) associations = (self.role.list_project_roles_for_user (user_dn, self.project.tree_dn)) return [p['id'] for p in self.project.get_user_projects(user_dn, associations)] def get_project_users(self, tenant_id): self.get_project(tenant_id) tenant_dn = self.project._id_to_dn(tenant_id) rolegrants = self.role.get_role_assignments(tenant_dn) users = [self.user.get_filtered(self.user._dn_to_id(user_id)) for user_id in self.project.get_user_dns(tenant_id, rolegrants)] return self._set_default_domain(users) def get_roles_for_user_and_project(self, user_id, tenant_id): self.identity.get_user(user_id) self.get_project(tenant_id) user_dn = self.user._id_to_dn(user_id) return [self.role._dn_to_id(a.role_dn) for a in self.role.get_role_assignments (self.project._id_to_dn(tenant_id)) if a.user_dn == user_dn] def _subrole_id_to_dn(self, role_id, tenant_id): if tenant_id is None: return self.role._id_to_dn(role_id) else: return '%s=%s,%s' % (self.role.id_attr, ldap.dn.escape_dn_chars(role_id), self.project._id_to_dn(tenant_id)) def add_role_to_user_and_project(self, user_id, tenant_id, role_id): self.identity.get_user(user_id) self.get_project(tenant_id) self.get_role(role_id) user_dn = self.user._id_to_dn(user_id) role_dn = self._subrole_id_to_dn(role_id, tenant_id) self.role.add_user(role_id, role_dn, user_dn, user_id, tenant_id) tenant_dn = self.project._id_to_dn(tenant_id) return UserRoleAssociation( role_dn=role_dn, user_dn=user_dn, tenant_dn=tenant_dn) def create_metadata(self, user_id, tenant_id, metadata): return {} def create_role(self, role_id, role): try: self.get_role(role_id) except exception.NotFound: pass else: msg = 'Duplicate ID, %s.' % role_id raise exception.Conflict(type='role', details=msg) try: self.role.get_by_name(role['name']) except exception.NotFound: pass else: msg = 'Duplicate name, %s.' % role['name'] raise exception.Conflict(type='role', details=msg) return self.role.create(role) def delete_role(self, role_id): return self.role.delete(role_id, self.project.tree_dn) def delete_project(self, tenant_id): if self.project.subtree_delete_enabled: self.project.deleteTree(id) else: tenant_dn = self.project._id_to_dn(tenant_id) self.role.roles_delete_subtree_by_project(tenant_dn) self.project.delete(tenant_id) def remove_role_from_user_and_project(self, user_id, tenant_id, role_id): role_dn = self._subrole_id_to_dn(role_id, tenant_id) return self.role.delete_user(role_dn, self.user._id_to_dn(user_id), self.project._id_to_dn(tenant_id), user_id, role_id) def update_role(self, role_id, role): self.get_role(role_id) self.role.update(role_id, role) def create_domain(self, domain_id, domain): if domain_id == CONF.identity.default_domain_id: msg = 'Duplicate ID, %s.' % domain_id raise exception.Conflict(type='domain', details=msg) raise exception.Forbidden('Domains are read-only against LDAP') def get_domain(self, domain_id): self._validate_domain_id(domain_id) return DEFAULT_DOMAIN def update_domain(self, domain_id, domain): self._validate_domain_id(domain_id) raise exception.Forbidden('Domains are read-only against LDAP') def delete_domain(self, domain_id): self._validate_domain_id(domain_id) raise exception.Forbidden('Domains are read-only against LDAP') def list_domains(self): return [DEFAULT_DOMAIN] #Bulk actions on User From identity def delete_user(self, user_id): user_dn = self.user._id_to_dn(user_id) for ref in self.role.list_global_roles_for_user(user_dn): self.role.delete_user(ref.role_dn, ref.user_dn, ref.project_dn, user_id, self.role._dn_to_id(ref.role_dn)) for ref in self.role.list_project_roles_for_user(user_dn, self.project.tree_dn): self.role.delete_user(ref.role_dn, ref.user_dn, ref.project_dn, user_id, self.role._dn_to_id(ref.role_dn)) user = self.user.get(user_id) if hasattr(user, 'tenant_id'): self.project.remove_user(user.tenant_id, self.user._id_to_dn(user_id)) #LDAP assignments only supports LDAP identity. Assignments under identity #are already deleted def delete_group(self, group_id): if not self.identity.group.subtree_delete_enabled: # TODO(spzala): this is only placeholder for group and domain # role support which will be added under bug 1101287 conn = self.group.get_connection() query = '(objectClass=%s)' % self.group.object_class dn = None dn = self.group._id_to_dn(id) if dn: try: roles = conn.search_s(dn, ldap.SCOPE_ONELEVEL, query, ['%s' % '1.1']) for role_dn, _ in roles: conn.delete_s(role_dn) except ldap.NO_SUCH_OBJECT: pass # TODO(termie): turn this into a data object and move logic to driver class ProjectApi(common_ldap.EnabledEmuMixIn, common_ldap.BaseLdap): DEFAULT_OU = 'ou=Groups' DEFAULT_STRUCTURAL_CLASSES = [] DEFAULT_OBJECTCLASS = 'groupOfNames' DEFAULT_ID_ATTR = 'cn' DEFAULT_MEMBER_ATTRIBUTE = 'member' DEFAULT_ATTRIBUTE_IGNORE = [] NotFound = exception.ProjectNotFound notfound_arg = 'project_id' # NOTE(yorik-sar): while options_name = tenant options_name = 'tenant' attribute_mapping = {'name': 'ou', 'description': 'description', 'tenantId': 'cn', 'enabled': 'enabled', 'domain_id': 'domain_id'} model = models.Project def __init__(self, conf): super(ProjectApi, self).__init__(conf) self.attribute_mapping['name'] = conf.ldap.tenant_name_attribute self.attribute_mapping['description'] = conf.ldap.tenant_desc_attribute self.attribute_mapping['enabled'] = conf.ldap.tenant_enabled_attribute self.attribute_mapping['domain_id'] = ( conf.ldap.tenant_domain_id_attribute) self.member_attribute = (getattr(conf.ldap, 'tenant_member_attribute') or self.DEFAULT_MEMBER_ATTRIBUTE) self.attribute_ignore = (getattr(conf.ldap, 'tenant_attribute_ignore') or self.DEFAULT_ATTRIBUTE_IGNORE) def create(self, values): self.affirm_unique(values) data = values.copy() if data.get('id') is None: data['id'] = uuid.uuid4().hex return super(ProjectApi, self).create(data) def get_user_projects(self, user_dn, associations): """"""Returns list of tenants a user has access to """""" project_ids = set() for assoc in associations: project_ids.add(self._dn_to_id(assoc.project_dn)) projects = [] for project_id in project_ids: #slower to get them one at a time, but a huge list could blow out #the connection. This is the safer way projects.append(self.get(project_id)) return projects def add_user(self, tenant_id, user_dn): conn = self.get_connection() try: conn.modify_s( self._id_to_dn(tenant_id), [(ldap.MOD_ADD, self.member_attribute, user_dn)]) except ldap.TYPE_OR_VALUE_EXISTS: # As adding a user to a tenant is done implicitly in several # places, and is not part of the exposed API, it's easier for us to # just ignore this instead of raising exception.Conflict. pass def remove_user(self, tenant_id, user_dn, user_id): conn = self.get_connection() try: conn.modify_s(self._id_to_dn(tenant_id), [(ldap.MOD_DELETE, self.member_attribute, user_dn)]) except ldap.NO_SUCH_ATTRIBUTE: raise exception.NotFound(user_id) def get_user_dns(self, tenant_id, rolegrants, role_dn=None): tenant = self._ldap_get(tenant_id) res = set() if not role_dn: # Get users who have default tenant mapping for user_dn in tenant[1].get(self.member_attribute, []): if self.use_dumb_member and user_dn == self.dumb_member: continue res.add(user_dn) # Get users who are explicitly mapped via a tenant for rolegrant in rolegrants: if role_dn is None or rolegrant.role_dn == role_dn: res.add(rolegrant.user_dn) return list(res) def update(self, id, values): old_obj = self.get(id) if old_obj['name'] != values['name']: msg = 'Changing Name not supported by LDAP' raise exception.NotImplemented(message=msg) return super(ProjectApi, self).update(id, values, old_obj) class UserRoleAssociation(object): """"""Role Grant model."""""" def __init__(self, user_dn=None, role_dn=None, tenant_dn=None, *args, **kw): self.user_dn = user_dn self.role_dn = role_dn self.project_dn = tenant_dn class GroupRoleAssociation(object): """"""Role Grant model."""""" def __init__(self, group_dn=None, role_dn=None, tenant_dn=None, *args, **kw): self.group_dn = group_dn self.role_dn = role_dn self.project_dn = tenant_dn # TODO(termie): turn this into a data object and move logic to driver class RoleApi(common_ldap.BaseLdap): DEFAULT_OU = 'ou=Roles' DEFAULT_STRUCTURAL_CLASSES = [] DEFAULT_OBJECTCLASS = 'organizationalRole' DEFAULT_MEMBER_ATTRIBUTE = 'roleOccupant' DEFAULT_ATTRIBUTE_IGNORE = [] NotFound = exception.RoleNotFound options_name = 'role' attribute_mapping = {'name': 'ou', #'serviceId': 'service_id', } model = models.Role def __init__(self, conf): super(RoleApi, self).__init__(conf) self.attribute_mapping['name'] = conf.ldap.role_name_attribute self.member_attribute = (getattr(conf.ldap, 'role_member_attribute') or self.DEFAULT_MEMBER_ATTRIBUTE) self.attribute_ignore = (getattr(conf.ldap, 'role_attribute_ignore') or self.DEFAULT_ATTRIBUTE_IGNORE) def get(self, id, filter=None): model = super(RoleApi, self).get(id, filter) return model def create(self, values): return super(RoleApi, self).create(values) def add_user(self, role_id, role_dn, user_dn, user_id, tenant_id=None): conn = self.get_connection() try: conn.modify_s(role_dn, [(ldap.MOD_ADD, self.member_attribute, user_dn)]) except ldap.TYPE_OR_VALUE_EXISTS: msg = ('User %s already has role %s in tenant %s' % (user_id, role_id, tenant_id)) raise exception.Conflict(type='role grant', details=msg) except ldap.NO_SUCH_OBJECT: if tenant_id is None or self.get(role_id) is None: raise Exception(_(""Role %s not found"") % (role_id,)) attrs = [('objectClass', [self.object_class]), (self.member_attribute, [user_dn])] if self.use_dumb_member: attrs[1][1].append(self.dumb_member) try: conn.add_s(role_dn, attrs) except Exception as inst: raise inst def delete_user(self, role_dn, user_dn, tenant_dn, user_id, role_id): conn = self.get_connection() try: conn.modify_s(role_dn, [(ldap.MOD_DELETE, self.member_attribute, user_dn)]) except ldap.NO_SUCH_OBJECT: if tenant_dn is None: raise exception.RoleNotFound(role_id=role_id) attrs = [('objectClass', [self.object_class]), (self.member_attribute, [user_dn])] if self.use_dumb_member: attrs[1][1].append(self.dumb_member) try: conn.add_s(role_dn, attrs) except Exception as inst: raise inst except ldap.NO_SUCH_ATTRIBUTE: raise exception.UserNotFound(user_id=user_id) def get_role_assignments(self, tenant_dn): conn = self.get_connection() query = '(objectClass=%s)' % self.object_class try: roles = conn.search_s(tenant_dn, ldap.SCOPE_ONELEVEL, query) except ldap.NO_SUCH_OBJECT: return [] res = [] for role_dn, attrs in roles: try: user_dns = attrs[self.member_attribute] except KeyError: continue for user_dn in user_dns: if self.use_dumb_member and user_dn == self.dumb_member: continue res.append(UserRoleAssociation( user_dn=user_dn, role_dn=role_dn, tenant_dn=tenant_dn)) return res def list_global_roles_for_user(self, user_dn): roles = self.get_all('(%s=%s)' % (self.member_attribute, user_dn)) return [UserRoleAssociation( role_dn=role.dn, user_dn=user_dn) for role in roles] def list_project_roles_for_user(self, user_dn, project_subtree): conn = self.get_connection() query = '(&(objectClass=%s)(%s=%s))' % (self.object_class, self.member_attribute, user_dn) try: roles = conn.search_s(project_subtree, ldap.SCOPE_SUBTREE, query) except ldap.NO_SUCH_OBJECT: return [] res = [] for role_dn, _ in roles: #ldap.dn.dn2str returns an array, where the first #element is the first segment. #For a role assignment, this contains the role ID, #The remainder is the DN of the tenant. tenant = ldap.dn.str2dn(role_dn) tenant.pop(0) tenant_dn = ldap.dn.dn2str(tenant) res.append(UserRoleAssociation( user_dn=user_dn, role_dn=role_dn, tenant_dn=tenant_dn)) return res def roles_delete_subtree_by_project(self, tenant_dn): conn = self.get_connection() query = '(objectClass=%s)' % self.object_class try: roles = conn.search_s(tenant_dn, ldap.SCOPE_ONELEVEL, query) for role_dn, _ in roles: try: conn.delete_s(role_dn) except Exception as inst: raise inst except ldap.NO_SUCH_OBJECT: pass def update(self, role_id, role): if role['id'] != role_id: raise exception.ValidationError('Cannot change role ID') try: old_name = self.get_by_name(role['name']) raise exception.Conflict('Cannot duplicate name %s' % old_name) except exception.NotFound: pass return super(RoleApi, self).update(role_id, role) def delete(self, id, tenant_dn): conn = self.get_connection() query = '(&(objectClass=%s)(%s=%s))' % (self.object_class, self.id_attr, id) try: for role_dn, _ in conn.search_s(tenant_dn, ldap.SCOPE_SUBTREE, query): conn.delete_s(role_dn) except ldap.NO_SUCH_OBJECT: pass super(RoleApi, self).delete(id) ",,2253,1558
openstack%2Fnova~master~I18ac285d5b3c8200d7706c7d577809b15d6ab9e8,openstack/nova,master,I18ac285d5b3c8200d7706c7d577809b15d6ab9e8,Validate volume_size in block_device_mapping,MERGED,2013-06-27 15:25:22.000000000,2013-07-17 01:27:49.000000000,2013-07-17 01:27:46.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 5511}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-06-27 15:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d69fee32b27a1ec1d9c66de11897b422d55ac1f', 'message': 'Validate volume_size in block_device_mapping\n\nThe passed volume_size was not validated, causing\ninteresting backtraces elsewhere. Reject invalid\nvalues upfront.\n\nCreate a common _validate_int_value() function for\nvalidating that a parameter is an integer in a given\nrange. Use it also for min_count/max_count to share code.\n\nChange-Id: I18ac285d5b3c8200d7706c7d577809b15d6ab9e8\n'}, {'number': 2, 'created': '2013-07-09 22:03:55.000000000', 'files': ['nova/tests/api/openstack/compute/test_servers.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3ff667620c2d735536b26c024691dfb9193975a2', 'message': 'Validate volume_size in block_device_mapping\n\nReject invalid values for volume_size upfront.\nFor compatibility with old python-novaclient, an\nempty volume_size is ignored.\n\nCreate a common _validate_int_value() function for\nvalidating that a parameter is an integer in a given\nrange. Use it also for min_count/max_count to share code.\n\nFixes LP Bug#1199539\n\nChange-Id: I18ac285d5b3c8200d7706c7d577809b15d6ab9e8\n'}]",0,34749,3ff667620c2d735536b26c024691dfb9193975a2,16,6,2,6593,,,0,"Validate volume_size in block_device_mapping

Reject invalid values for volume_size upfront.
For compatibility with old python-novaclient, an
empty volume_size is ignored.

Create a common _validate_int_value() function for
validating that a parameter is an integer in a given
range. Use it also for min_count/max_count to share code.

Fixes LP Bug#1199539

Change-Id: I18ac285d5b3c8200d7706c7d577809b15d6ab9e8
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/34749/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/test_servers.py', 'nova/api/openstack/compute/servers.py']",2,8d69fee32b27a1ec1d9c66de11897b422d55ac1f,bug/1199539," def _validate_int_value(self, str_value, str_name, min_value=None, max_value=None): try: value = int(str(str_value)) except ValueError: msg = _('%(value_name)s must be an integer') raise exc.HTTPBadRequest(explanation=msg % ( {'value_name': str_name})) if min_value is not None: if value < min_value: msg = _('%(value_name)s must be >= %(min_value)d') raise exc.HTTPBadRequest(explanation=msg % ( {'value_name': str_name, 'min_value': min_value})) if max_value is not None: if value > max_value: msg = _('%{value_name}s must be <= %(max_value)d') raise exc.HTTPBadRequest(explanation=msg % ( {'value_name': str_name, 'max_value': max_value})) return value def _validate_block_device(self, bd): self._check_string_length(bd['device_name'], 'Device name', max_length=255) if ' ' in bd['device_name']: if 'volume_size' in bd: self._validate_int_value(bd['volume_size'], 'volume_size', min_value=0) self._validate_block_device(bdm) min_count = self._validate_int_value(min_count, ""min_count"", min_value=1) max_count = self._validate_int_value(max_count, ""max_count"", min_value=1)"," def _validate_device_name(self, value): self._check_string_length(value, 'Device name', max_length=255) if ' ' in value: self._validate_device_name(bdm[""device_name""]) try: min_count = int(str(min_count)) except ValueError: msg = _('min_count must be an integer value') raise exc.HTTPBadRequest(explanation=msg) if min_count < 1: msg = _('min_count must be > 0') raise exc.HTTPBadRequest(explanation=msg) try: max_count = int(str(max_count)) except ValueError: msg = _('max_count must be an integer value') raise exc.HTTPBadRequest(explanation=msg) if max_count < 1: msg = _('max_count must be > 0') raise exc.HTTPBadRequest(explanation=msg)",53,21
openstack%2Fnova~master~I5e7c3069913eea11633f35273183c3c3b46f4969,openstack/nova,master,I5e7c3069913eea11633f35273183c3c3b46f4969,Fix duplicate fping_path config option,MERGED,2013-07-09 08:17:31.000000000,2013-07-17 01:27:26.000000000,2013-07-17 01:27:24.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1669}, {'_account_id': 1849}, {'_account_id': 6864}]","[{'number': 1, 'created': '2013-07-09 08:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/17b7244035813256d201af778daf81e4a9bf3956', 'message': 'Fix duplicate fping_path config option\n\nThis is causing an error in the config file tool generator. Just use\nthe config option in the original copy of this code.\n\nChange-Id: I5e7c3069913eea11633f35273183c3c3b46f4969\n'}, {'number': 2, 'created': '2013-07-10 14:05:13.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/fping.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3f648678bcad2305c5c68c0cd98bfb86da92ffaf', 'message': 'Fix duplicate fping_path config option\n\nThis is causing an error in the config file tool generator. Just use\nthe config option in the original copy of this code.\n\nChange-Id: I5e7c3069913eea11633f35273183c3c3b46f4969\n'}]",1,36190,3f648678bcad2305c5c68c0cd98bfb86da92ffaf,19,6,2,1247,,,0,"Fix duplicate fping_path config option

This is causing an error in the config file tool generator. Just use
the config option in the original copy of this code.

Change-Id: I5e7c3069913eea11633f35273183c3c3b46f4969
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/36190/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/plugins/v3/fping.py'],1,17b7244035813256d201af778daf81e4a9bf3956,jd/check-config-uptodate,"CONF.import_opt('fping_path', 'nova.api.openstack.compute.contrib.fping')"," 'compute', 'fping:all_tenants') fping_opts = [ cfg.StrOpt(""fping_path"", default=""/usr/sbin/fping"", help=""Full path to fping.""), ]CONF.register_opts(fping_opts)",1,7
openstack%2Fswift~master~I11d405e629063177ef21543b75e9076da1a03b61,openstack/swift,master,I11d405e629063177ef21543b75e9076da1a03b61,Refactor auditors to rely on expected gen names,MERGED,2013-06-27 22:13:20.000000000,2013-07-17 01:27:20.000000000,2013-07-17 01:27:20.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 4108}, {'_account_id': 6198}, {'_account_id': 7652}]","[{'number': 1, 'created': '2013-06-27 22:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f1de3d2eba3b5860537fe4e3d25b14050a028fd6', 'message': 'Refactor auditors to rely on expected gen names\n\nRefactor the various auditors to rely on the audit_location_generator\nyielding tuples containing paths with the expected suffix.\n\nWe also fix the exception handling for container_sync to not expect a\nbroker object (since the act of creating a broker object can raise an\nexception).\n\nFor the object auditor we removed an unneeded check for disk_file\nsince get_data_file_size() will raise DiskFileNotExist under the same\ncondition (raises code coverage slightly).\n\nChange-Id: I11d405e629063177ef21543b75e9076da1a03b61\n'}, {'number': 2, 'created': '2013-07-01 12:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cef41c6e089b1cc88dfcea8309260e0f6f31e3e1', 'message': 'Refactor auditors to rely on expected gen names\n\nRefactor the various auditors to rely on the audit_location_generator\nyielding tuples containing paths with the expected suffix.\n\nWe also fix the exception handling for container_sync to not expect a\nbroker object (since the act of creating a broker object can raise an\nexception).\n\nFor the object auditor we removed an unneeded check for disk_file\nsince get_data_file_size() will raise DiskFileNotExist under the same\ncondition (raises code coverage slightly).\n\nChange-Id: I11d405e629063177ef21543b75e9076da1a03b61\n'}, {'number': 3, 'created': '2013-07-02 20:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/69783aa66511b579dd50f9e120cf72710df38b7a', 'message': 'Refactor auditors to rely on expected gen names\n\nRefactor the various auditors to rely on the audit_location_generator\nyielding tuples containing paths with the expected suffix.\n\nWe also fix the exception handling for container_sync to not expect a\nbroker object (since the act of creating a broker object can raise an\nexception).\n\nFor the object auditor we removed an unneeded check for disk_file\nsince get_data_file_size() will raise DiskFileNotExist under the same\ncondition (raises code coverage slightly).\n\nChange-Id: I11d405e629063177ef21543b75e9076da1a03b61\n'}, {'number': 4, 'created': '2013-07-03 15:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c915f23093352eb519e8db408a94af96b67bd38d', 'message': 'Refactor auditors to rely on expected gen names\n\nRefactor the various auditors to rely on the audit_location_generator\nyielding tuples containing paths with the expected suffix.\n\nWe also fix the exception handling for container_sync to not expect a\nbroker object (since the act of creating a broker object can raise an\nexception).\n\nFor the object auditor we removed an unneeded check for disk_file\nsince get_data_file_size() will raise DiskFileNotExist under the same\ncondition (raises code coverage slightly).\n\nChange-Id: I11d405e629063177ef21543b75e9076da1a03b61\n'}, {'number': 5, 'created': '2013-07-03 19:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f8f5d352622afb3672833fbc47d054f767ebb06a', 'message': 'Refactor auditors to rely on expected gen names\n\nRefactor the various auditors to rely on the audit_location_generator\nyielding tuples containing paths with the expected suffix.\n\nWe also fix the exception handling for container_sync to not expect a\nbroker object (since the act of creating a broker object can raise an\nexception).\n\nFor the object auditor we removed an unneeded check for disk_file\nsince get_data_file_size() will raise DiskFileNotExist under the same\ncondition (raises code coverage slightly).\n\nChange-Id: I11d405e629063177ef21543b75e9076da1a03b61\n'}, {'number': 6, 'created': '2013-07-05 21:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/34c938088c24a81ec02f7069627f3a5e3c66e7da', 'message': 'Refactor auditors to rely on expected gen names\n\nRefactor the various auditors to rely on the audit_location_generator\nyielding tuples containing paths with the expected suffix.\n\nWe also fix the exception handling for container_sync to not expect a\nbroker object (since the act of creating a broker object can raise an\nexception).\n\nFor the object auditor we removed an unneeded check for disk_file\nsince get_data_file_size() will raise DiskFileNotExist under the same\ncondition (raises code coverage slightly).\n\nChange-Id: I11d405e629063177ef21543b75e9076da1a03b61\n'}, {'number': 7, 'created': '2013-07-16 01:20:41.000000000', 'files': ['test/unit/obj/test_auditor.py', 'swift/container/auditor.py', 'swift/account/auditor.py', 'swift/container/sync.py', 'swift/common/utils.py', 'swift/obj/auditor.py', 'test/unit/container/test_sync.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/9480ff8a28e6a5e0a6b79dc2456381bbb76e9c98', 'message': 'Refactor auditors to rely on expected gen names\n\nRefactor the various auditors to rely on the audit_location_generator\nyielding tuples containing paths with the expected suffix.\n\nWe also fix the exception handling for container_sync to not expect a\nbroker object (since the act of creating a broker object can raise an\nexception).\n\nFor the object auditor we removed an unneeded check for disk_file\nsince get_data_file_size() will raise DiskFileNotExist under the same\ncondition (raises code coverage slightly).\n\nChange-Id: I11d405e629063177ef21543b75e9076da1a03b61\n'}]",4,34810,9480ff8a28e6a5e0a6b79dc2456381bbb76e9c98,33,8,7,6198,,,0,"Refactor auditors to rely on expected gen names

Refactor the various auditors to rely on the audit_location_generator
yielding tuples containing paths with the expected suffix.

We also fix the exception handling for container_sync to not expect a
broker object (since the act of creating a broker object can raise an
exception).

For the object auditor we removed an unneeded check for disk_file
since get_data_file_size() will raise DiskFileNotExist under the same
condition (raises code coverage slightly).

Change-Id: I11d405e629063177ef21543b75e9076da1a03b61
",git fetch https://review.opendev.org/openstack/swift refs/changes/10/34810/6 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_auditor.py', 'swift/container/auditor.py', 'swift/account/auditor.py', 'swift/common/utils.py', 'swift/container/sync.py', 'swift/obj/auditor.py', 'test/unit/container/test_sync.py']",7,f1de3d2eba3b5860537fe4e3d25b14050a028fd6,mkstemp," # Makes .container_sync() short-circuit yield 0, 'device', 'partition' return # Makes .container_sync() short-circuit yield 0, 'device', 'partition' return"," # Makes .container_sync() short-circuit because 'path' doesn't end # with .db return [('path', 'device', 'partition')] # Makes .container_sync() short-circuit because 'path' doesn't end # with .db return [('path', 'device', 'partition')] ",29,35
openstack%2Fnova~master~I709292a7725f0a21f04f1c3c79f2fafc4437e402,openstack/nova,master,I709292a7725f0a21f04f1c3c79f2fafc4437e402,Reassign MAC address for vm  when resize_revert,MERGED,2013-07-01 07:41:54.000000000,2013-07-17 01:27:02.000000000,2013-07-17 01:26:59.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 6873}, {'_account_id': 6981}, {'_account_id': 7282}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-07-01 07:41:54.000000000', 'files': ['nova/virt/powervm/driver.py', 'nova/tests/virt/powervm/test_powervm.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/742eb2ee44e54d675f0147b09c875c63618706f6', 'message': ""Reassign MAC address for vm  when resize_revert\n\nIn the case of a resize or migrate on the same host, we need to assign\na temp mac address to the source LPAR so we don't have a conflict when\nanother LPAR is booted with the same mac address as the original LPAR.\nWe need reassign the original mac address, replacing the temp mac on\nthe old instance during revert resize. The new instance has been\ndestroyed before this method, so remove the precondition to make sure\noriginal mac address be set.\n\nFixes bug #1196404\n\nChange-Id: I709292a7725f0a21f04f1c3c79f2fafc4437e402\n""}]",1,35096,742eb2ee44e54d675f0147b09c875c63618706f6,10,9,1,6722,,,0,"Reassign MAC address for vm  when resize_revert

In the case of a resize or migrate on the same host, we need to assign
a temp mac address to the source LPAR so we don't have a conflict when
another LPAR is booted with the same mac address as the original LPAR.
We need reassign the original mac address, replacing the temp mac on
the old instance during revert resize. The new instance has been
destroyed before this method, so remove the precondition to make sure
original mac address be set.

Fixes bug #1196404

Change-Id: I709292a7725f0a21f04f1c3c79f2fafc4437e402
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/35096/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/powervm/test_powervm.py', 'nova/virt/powervm/driver.py']",2,742eb2ee44e54d675f0147b09c875c63618706f6,bug/1196404," # NOTE(guochbo) We can't judge if a resize_revert on the same host # due to the instance on destination host has been destoryed. # Original mac address is always kept in network_info, we can # reassign the original mac address here without negative effects # even the old instance kept the original mac address if self.instance_exists(new_name): self._powervm._operator.set_lpar_mac_base_value(new_name,"," if (self._powervm.instance_exists(new_name) and self._powervm.instance_exists(instance['name'])): self._powervm._operator.set_lpar_mac_base_value(instance['name'], if self.instance_exists(new_name):",9,6
openstack%2Fcinder~master~I4155583bb7911587c5c7e1c4c0a8d522dcf032c1,openstack/cinder,master,I4155583bb7911587c5c7e1c4c0a8d522dcf032c1,Add Fibre Channel image tranfer support.,ABANDONED,2013-07-10 23:09:31.000000000,2013-07-17 01:10:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6549}]","[{'number': 2, 'created': '2013-07-10 23:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/72c881432d457115df2fcca6af112eb9d80c3bb2', 'message': 'Add Fibre Channel image tranfer support.\n\nThis patch adds support to the base Fiber\nChannel driver to do copy volume to image\nand copy image to volume.\n\nblueprint cinder-refactor-attach\n\nChange-Id: I4155583bb7911587c5c7e1c4c0a8d522dcf032c1\n'}, {'number': 1, 'created': '2013-07-10 23:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f54c88a973e3336283d9789e565fb1d45e078c12', 'message': 'Add Fibre Channel image tranfer support.\n\nThis patch adds support to the base Fiber\nChannel driver to do copy volume to image\nand copy image to volume.\n\nblueprint cinder-refactor-attach\n\nChange-Id: I4155583bb7911587c5c7e1c4c0a8d522dcf032c1\n'}, {'number': 5, 'created': '2013-07-15 22:41:37.000000000', 'files': ['cinder/volume/driver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9a459975f0cbd7f9a4f97c3c1cfba4c4832b25bc', 'message': 'Add Fibre Channel image tranfer support.\n\nThis patch adds support to the base Fiber\nChannel driver to do copy volume to image\nand copy image to volume.\n\nblueprint cinder-refactor-attach\n\nChange-Id: I4155583bb7911587c5c7e1c4c0a8d522dcf032c1\n'}, {'number': 4, 'created': '2013-07-15 22:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/55e24b3821017d71b1b60e4e48e89702af4a25c0', 'message': 'Add Fibre Channel image tranfer support.\n\nThis patch adds support to the base Fiber\nChannel driver to do copy volume to image\nand copy image to volume.\n\nblueprint cinder-refactor-attach\n\nChange-Id: I4155583bb7911587c5c7e1c4c0a8d522dcf032c1\n'}, {'number': 3, 'created': '2013-07-15 22:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/62a3b01c9cdd8a33081bfae818f95616f9024c64', 'message': 'Add Fibre Channel image tranfer support.\n\nThis patch adds support to the base Fiber\nChannel driver to do copy volume to image\nand copy image to volume.\n\nblueprint cinder-refactor-attach\n\nChange-Id: I4155583bb7911587c5c7e1c4c0a8d522dcf032c1\n'}]",2,36578,9a459975f0cbd7f9a4f97c3c1cfba4c4832b25bc,18,5,5,5997,,,0,"Add Fibre Channel image tranfer support.

This patch adds support to the base Fiber
Channel driver to do copy volume to image
and copy image to volume.

blueprint cinder-refactor-attach

Change-Id: I4155583bb7911587c5c7e1c4c0a8d522dcf032c1
",git fetch https://review.opendev.org/openstack/cinder refs/changes/78/36578/5 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/driver.py'],1,72c881432d457115df2fcca6af112eb9d80c3bb2,fc-volume-image-xfer," """"""Fetch the image from image_service and write it to the volume."""""" LOG.debug(_('copy_image_to_volume %s.') % volume['name']) multipath_flag = self.configuration.use_multipath_for_image_xfer fc_connector = initiator.FibreChannelConnector( use_multipath=multipath_flag) connector = {'wwpns': fc_connector._linuxfc.get_fc_wwpns(), 'host': socket.gethostname()} conf, volume_path = self._attach_volume(context, volume, connector, fc_connector) try: image_utils.fetch_to_raw(context, image_service, image_id, volume_path) finally: self._detach_volume(conf, fc_connector) self.terminate_connection(volume, connector) """"""Copy the volume to the specified image."""""" LOG.debug(_('copy_volume_to_image %s.') % volume['name']) multipath_flag = self.configuration.use_multipath_for_image_xfer fc_connector = initiator.FibreChannelConnector( use_multipath=multipath_flag) connector = {'wwpns': fc_connector._linuxfc.get_fc_wwpns(), 'host': socket.gethostname()} conf, volume_path = self._attach_volume(context, volume, connector, fc_connector) try: image_utils.upload_volume(context, image_service, image_meta, volume_path) finally: self._detach_volume(conf, fc_connector) self.terminate_connection(volume, connector) def _attach_volume(self, context, volume, connector, fc_connector): """"""Attach the volume."""""" fc_properties = None host_device = None init_conn = self.initialize_connection(volume, connector) fc_properties = init_conn['data'] # Use Brick's code to do attach/detach conf = fc_connector.connect_volume(fc_properties) host_device = conf['path'] if not self._check_valid_device(host_device): raise exception.DeviceUnavailable(path=host_device, reason=(_(""Unable to access "" ""the backend storage "" ""via the path "" ""%(path)s."") % {'path': host_device})) LOG.debug(""Volume attached %s"" % host_device) return conf, host_device def _detach_volume(self, conf, fc_connector): LOG.debug(""Detach Fibre Channel volume %(path)s:%(devices)s"" % {""path"": conf[""path""], ""devices"": conf[""devices""]}) # Use Brick's code to do attach/detach conf = fc_connector.disconnect_volume(conf) def _check_valid_device(self, path): fc_devs = self._get_fc_devices() LOG.warn(""Look for %(path)s in list %(list)s"" % {""path"": path, ""list"": fc_devs}) cmd = ('dd', 'if=%(path)s' % {""path"": path}, 'of=/dev/null', 'count=1') out, info = None, None try: out, info = self._execute(*cmd, run_as_root=True) except exception.ProcessExecutionError as e: LOG.error(_(""Failed to access the device on the path "" ""%(path)s: %(error)s %(info)s."") % {""path"": path, ""error"": e.stderr, ""info"": info}) return False # If the info is none, the path does not exist. if info is None: return False return True def _get_fc_devices(self): try: devices = list(os.walk('/dev/disk/by-path'))[0][-1] except IndexError: return [] return [entry for entry in devices if ""-fc-"" in entry]", raise NotImplementedError() raise NotImplementedError(),94,2
openstack%2Fopenstack-manuals~master~I2b47b70ef3b388e6563a5c9a218e2a208beac7c8,openstack/openstack-manuals,master,I2b47b70ef3b388e6563a5c9a218e2a208beac7c8,Bug # 1200372 - Added hp3par_iscsi_ips to HP 3PAR configuration.,ABANDONED,2013-07-16 18:38:59.000000000,2013-07-17 00:51:52.000000000,,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 6772}, {'_account_id': 7389}]","[{'number': 1, 'created': '2013-07-16 18:38:59.000000000', 'files': ['doc/src/docbkx/openstack-block-storage-admin/drivers/hp-3par-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/594abd009f817cddf38559d5cbe8445c25636d20', 'message': 'Bug # 1200372 - Added hp3par_iscsi_ips to HP 3PAR configuration.\n\nAdded hp3par_iscsi_ips, replacing the generic (but singular)\niscsi_ip_address configuration key. Added paragraph explaining how iSCSI\naddress selection now works.\n\nChange-Id: I2b47b70ef3b388e6563a5c9a218e2a208beac7c8\nFixes: bug 1200372\n'}]",0,37304,594abd009f817cddf38559d5cbe8445c25636d20,5,4,1,6772,,,0,"Bug # 1200372 - Added hp3par_iscsi_ips to HP 3PAR configuration.

Added hp3par_iscsi_ips, replacing the generic (but singular)
iscsi_ip_address configuration key. Added paragraph explaining how iSCSI
address selection now works.

Change-Id: I2b47b70ef3b388e6563a5c9a218e2a208beac7c8
Fixes: bug 1200372
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/04/37304/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-block-storage-admin/drivers/hp-3par-driver.xml'],1,594abd009f817cddf38559d5cbe8445c25636d20,," <para> When the driver is configured to use iSCSI and a volume is attached to a host for the first time the driver will iterate through all iSCSI addresses listed in the <literal>hp3par_iscsi_ips</literal> configuration key. The volume will be attached to the iSCSI address that has the least existing volumes attached. Volumes subsequently attached to the same host will use the established target address. </para># 3PAR WS API Server URL, in the format https://&lt;3par ip&gt;:8080/api/v1# iSCSI (uncomment the next line to enable the iSCSI driver)# List of target iSCSI addresses to use (list value) &lt;IP&gt;:&lt;PORT&gt;,... hp3par_iscsi_ips= <emphasis role=""bold"">## OPTIONAL SETTINGS</emphasis>","# 3PAR WS API Server URL# iSCSI (uncomment the next line to enable the iSCSI driver and the iscsi_ip_address)# The port that the iSCSI daemon is listening on #iscsi_ip_address=""10.10.220.253"" <emphasis role=""bold"">## OPTIONAL SETTING</emphasis>",14,5
openstack%2Fnova~master~I8955cb358ca07c7f4bcd6e3e60066501ec0f6cb2,openstack/nova,master,I8955cb358ca07c7f4bcd6e3e60066501ec0f6cb2,Removes duplicate registration of fping_path option,ABANDONED,2013-07-17 00:46:33.000000000,2013-07-17 00:49:42.000000000,,[],"[{'number': 1, 'created': '2013-07-17 00:46:33.000000000', 'files': ['nova/api/openstack/compute/contrib/fping.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8f8722448e87adefca1b0d0c8720f5ef979ff874', 'message': 'Removes duplicate registration of fping_path option\n\nDuplicate registration of the same option can cause an error.\nSince fping has moved to nova API v3, import the option from fping extention.\n\nChange-Id: I8955cb358ca07c7f4bcd6e3e60066501ec0f6cb2\n'}]",0,37365,8f8722448e87adefca1b0d0c8720f5ef979ff874,1,0,1,1994,,,0,"Removes duplicate registration of fping_path option

Duplicate registration of the same option can cause an error.
Since fping has moved to nova API v3, import the option from fping extention.

Change-Id: I8955cb358ca07c7f4bcd6e3e60066501ec0f6cb2
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/37365/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/contrib/fping.py'],1,8f8722448e87adefca1b0d0c8720f5ef979ff874,fping,"CONF.import_opt('fping_path', 'nova.api.openstack.compute.plugins.v3.fping')","fping_opts = [ cfg.StrOpt(""fping_path"", default=""/usr/sbin/fping"", help=""Full path to fping.""), ]CONF.register_opts(fping_opts)",1,6
openstack%2Fbarbican~master~Ia44ed880d4aba43d85c38d7fa7314cc9b01e3815,openstack/barbican,master,Ia44ed880d4aba43d85c38d7fa7314cc9b01e3815,Package dependencies in RPMs using fpm.,MERGED,2013-07-17 00:31:12.000000000,2013-07-17 00:41:13.000000000,2013-07-17 00:41:13.000000000,"[{'_account_id': 3}, {'_account_id': 7789}, {'_account_id': 7973}]","[{'number': 1, 'created': '2013-07-17 00:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/d9cae9a5694b5646983f3cb667d65a9b054f9b36', 'message': 'Package dependencies in RPMs using fpm.\n\nChange-Id: Ia44ed880d4aba43d85c38d7fa7314cc9b01e3815\n'}, {'number': 2, 'created': '2013-07-17 00:33:44.000000000', 'files': ['rpmbuild/package_dependencies.sh'], 'web_link': 'https://opendev.org/openstack/barbican/commit/11c1e2c9ebeafe05d5565c232d8e5d98c3348b09', 'message': 'Package dependencies in RPMs using fpm.\n\nChange-Id: Ia44ed880d4aba43d85c38d7fa7314cc9b01e3815\n'}]",0,37361,11c1e2c9ebeafe05d5565c232d8e5d98c3348b09,7,3,2,7973,,,0,"Package dependencies in RPMs using fpm.

Change-Id: Ia44ed880d4aba43d85c38d7fa7314cc9b01e3815
",git fetch https://review.opendev.org/openstack/barbican refs/changes/61/37361/2 && git format-patch -1 --stdout FETCH_HEAD,['rpmbuild/package_dependencies.sh'],1,d9cae9a5694b5646983f3cb667d65a9b054f9b36,rpm-package-deps,"#!/bin/bash # --------------------- # Barbican Dependencies # --------------------- pushd $PWD/rpmbuild fpm -s python -t rpm falcon fpm -s python -t rpm uWSGI fpm -s python -t rpm pysqlite fpm -s python -t rpm eventlet fpm -s python -t rpm oslo.config fpm -s python -t rpm iso8601 fpm -s python -t rpm kombu fpm -s python -t rpm webob # --> # python-webob.noarch 0.9.6.1-3.el6 exists, but is incompatible # fpm -s python -t rpm PasteDeploy # --> python-paste-deploy 1.3.3-2.1.el6 fpm -s python -t rpm Celery fpm -s python -t rpm python-keystoneclient fpm -s python -t rpm stevedore # fpm -s python -t rpm pycrypto # --> python-crypto 2.0.1-22.el6 fpm -s python -t rpm python-dateutil # --> python-dateutil 1.4.1-6.el6 exists, but is incompatible fpm -s python -t rpm jsonschema fpm -s python -t rpm SQLAlchemy # --> python-sqlalchemy 0.5.5-3.el6_2 exists, but is incompatible fpm -s python -t rpm alembic # fpm -s python -t rpm psycopg2 # --> python-psycopg2 2.0.14-2.el6 # --------------------- # Indirect dependencies # --------------------- # python-alembic fpm -s python -t rpm mako # --> mako needs markupsafe # python-markupsafe 0.9.2-4.el6 # fpm -s python -t rpm markupsafe fpm -s python -t rpm argparse # python-celery fpm -s python -t rpm billiard # python-eventlet fpm -s python -t rpm greenlet # python-falcon fpm -s python -t rpm six fpm -s python -t rpm ordereddict # python-keystoneclient # fpm -s python -t rpm six # fpm -s python -t rpm argparse fpm -s python -t rpm d2to1 fpm -s python -t rpm pbr # --> pbr needs setuptools-git fpm -s python -t rpm setuptools-git fpm -s python -t rpm prettytable fpm -s python -t rpm requests fpm -s python -t rpm simplejson # python-kombu fpm -s python -t rpm anyjson fpm -s python -t rpm -v 1.0.12 amqp # --> latest amqp is incompatible fpm -s python -t rpm importlib # fpm -s python -t rpm ordereddict # oslo.config # fpm -s python -t rpm argparse # python-stevedore # fpm -s python -t rpm argparse # ------------------------------- # Upload to yum-repo.cloudkeep.io # ------------------------------- scp *.rpm rpmbuild@yum-repo.cloudkeep.io:/var/www/html/centos/6/barbican/x86_64/ ssh rpmbuild@yum-repo.cloudkeep.io 'createrepo /var/www/html/centos/6/barbican/x86_64/' popd",,85,0
openstack-attic%2Fidentity-api~master~I8950540c14d61eecdac4014899a5a69bdcdcc319,openstack-attic/identity-api,master,I8950540c14d61eecdac4014899a5a69bdcdcc319,Add optional token bind information to identity-api.,MERGED,2013-07-09 04:23:07.000000000,2013-07-17 00:26:12.000000000,2013-07-17 00:26:12.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 994}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-07-09 04:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/7cfdd6f2e3f61ac17f69febff728e196d37d0003', 'message': 'Add optional token bind information to identity-api.\n\nBind information is a dictionary keyed by the mechanism identifier with\na value containing data that is specific to that mechanism.\n\nRequired for bp authentication-tied-to-token\n\nChange-Id: I8950540c14d61eecdac4014899a5a69bdcdcc319\n'}, {'number': 2, 'created': '2013-07-10 00:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/1119b47580e6c29251715166a961428e16988da1', 'message': 'Add optional token bind information to identity-api.\n\nBind information is a dictionary keyed by the mechanism identifier with\na value containing data that is specific to that mechanism.\n\nRequired for bp authentication-tied-to-token\n\nChange-Id: I8950540c14d61eecdac4014899a5a69bdcdcc319\n'}, {'number': 3, 'created': '2013-07-10 01:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/daaed24c7557a1ff7c922935110f30371800812b', 'message': 'Add optional token bind information to identity-api.\n\nBind information is a dictionary keyed by the mechanism identifier with\na value containing data that is specific to that mechanism.\n\nRequired for bp authentication-tied-to-token\n\nChange-Id: I8950540c14d61eecdac4014899a5a69bdcdcc319\n'}, {'number': 4, 'created': '2013-07-10 02:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/484358ca0f0b21fd74862ee912e98b97edc0aaac', 'message': 'Add optional token bind information to identity-api.\n\nBind information is a dictionary keyed by the mechanism identifier with\na value containing data that is specific to that mechanism.\n\nRequired for bp authentication-tied-to-token\n\nChange-Id: I8950540c14d61eecdac4014899a5a69bdcdcc319\n'}, {'number': 5, 'created': '2013-07-15 00:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/c37c739e039e3c406b11120632bb883e04604be0', 'message': 'Add optional token bind information to identity-api.\n\nBind information is a dictionary keyed by the mechanism identifier with\na value containing data that is specific to that mechanism.\n\nRequired for bp authentication-tied-to-token\n\nChange-Id: I8950540c14d61eecdac4014899a5a69bdcdcc319\n'}, {'number': 6, 'created': '2013-07-16 04:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/569d1139fb1c222f70697e89a6b11dfe27cd15f5', 'message': 'Add optional token bind information to identity-api.\n\nBind information is a dictionary keyed by the mechanism identifier with\na value containing data that is specific to that mechanism.\n\nRequired for bp authentication-tied-to-token\n\nChange-Id: I8950540c14d61eecdac4014899a5a69bdcdcc319\n'}, {'number': 7, 'created': '2013-07-17 00:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/64b8ee9539f7f6ac56f1be84fb32559c832817ee', 'message': 'Add optional token bind information to identity-api.\n\nBind information is a dictionary keyed by the mechanism identifier with\na value containing data that is specific to that mechanism.\n\nRequired for bp authentication-tied-to-token\n\nChange-Id: I8950540c14d61eecdac4014899a5a69bdcdcc319\n'}, {'number': 8, 'created': '2013-07-17 00:09:33.000000000', 'files': ['openstack-identity-api/v3/src/markdown/identity-api-v3.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/8652675faaf06c921257ff857769863de2fee9fa', 'message': 'Add optional token bind information to identity-api.\n\nBind information is a dictionary keyed by the mechanism identifier with\na value containing data that is specific to that mechanism.\n\nRequired for bp authentication-tied-to-token\n\nChange-Id: I8950540c14d61eecdac4014899a5a69bdcdcc319\n'}]",22,36166,8652675faaf06c921257ff857769863de2fee9fa,44,10,8,7191,,,0,"Add optional token bind information to identity-api.

Bind information is a dictionary keyed by the mechanism identifier with
a value containing data that is specific to that mechanism.

Required for bp authentication-tied-to-token

Change-Id: I8950540c14d61eecdac4014899a5a69bdcdcc319
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/66/36166/8 && git format-patch -1 --stdout FETCH_HEAD,['openstack-identity-api/v3/src/markdown/identity-api-v3.md'],1,7cfdd6f2e3f61ac17f69febff728e196d37d0003,bp/authentication-tied-to-token,"- Added optional bind information to token structure.- `bind` (object) Specifies one or more authorization mechanisms that must be used in conjunction with the current token. For example a token may only be usable over a kerberos authenticated connection or with a specific client certificate. Includes a mechanism identifier with protocol specific data. ""bind"": { ""kerberos"": { ""principal"": ""USER@REALM"" } },",,15,0
openstack%2Fpython-heatclient~master~Iaeb926b929d4f8210ebbfa310134b1fb50dce276,openstack/python-heatclient,master,Iaeb926b929d4f8210ebbfa310134b1fb50dce276,Cleanup in preperation for release.,MERGED,2013-07-16 22:45:56.000000000,2013-07-17 00:21:48.000000000,2013-07-16 23:42:39.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-07-16 22:45:56.000000000', 'files': ['setup.cfg', 'MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/3f1b15cdce172e3d66720b4503eaae0d11a563f6', 'message': 'Cleanup in preperation for release.\n\nChange-Id: Iaeb926b929d4f8210ebbfa310134b1fb50dce276\n'}]",0,37347,3f1b15cdce172e3d66720b4503eaae0d11a563f6,7,3,1,4571,,,0,"Cleanup in preperation for release.

Change-Id: Iaeb926b929d4f8210ebbfa310134b1fb50dce276
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/47/37347/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'MANIFEST.in']",2,3f1b15cdce172e3d66720b4503eaae0d11a563f6,,,recursive-include tests *exclude .gitignore exclude .gitreview,0,7
openstack%2Fpuppet-nova~master~Iaeebb97c3437e5d610c606925a219e1c9949ae87,openstack/puppet-nova,master,Iaeebb97c3437e5d610c606925a219e1c9949ae87,Add Support for Rabbit Mirrored (HA) Queues,ABANDONED,2013-07-11 18:40:52.000000000,2013-07-17 00:17:33.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 3217}, {'_account_id': 6836}, {'_account_id': 6838}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-07-11 18:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f427f12c8d0b48858558ef36101b68c0450e43a3', 'message': 'Add Support for Rabbit Mirrored (HA) Queues\n\nPreviously, the nova::rabbitmq class could take advantage of\nclustering, but mirrored (HA) queues would not behave properly\ndue to the version of RabbitMQ server installed.\n\nRabbit mirrored queues had several bugs that were fixed in 2.8.7:\n  https://www.rabbitmq.com/release-notes/README-2.8.7.txt\n\nThis change will allow rabbit mirrored queues to behave properly\nby installing the correct rabbitmq-server version.\n\nDefaults to false to disable the use of rabbitmq-server version 2.8.7\nand preservce backwards compatibility.\n\nChange-Id: Iaeebb97c3437e5d610c606925a219e1c9949ae87\n'}, {'number': 2, 'created': '2013-07-15 21:11:05.000000000', 'files': ['spec/classes/nova_rabbitmq_spec.rb', 'manifests/rabbitmq.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/e52dd9eb0b17ea6b3d0e22a3c2d1c7c30cab9f65', 'message': 'Add Support for Rabbit Mirrored (HA) Queues\n\nPreviously, the nova::rabbitmq class could take advantage of\nclustering, but mirrored (HA) queues would not behave properly\ndue to the version of RabbitMQ server installed.\n\nRabbit mirrored queues had several bugs that were fixed in 2.8.7:\n  https://www.rabbitmq.com/release-notes/README-2.8.7.txt\n\nThis change will allow rabbit mirrored queues to behave properly\nby installing the correct rabbitmq-server version.\n\nDefaults to false to disable the use of rabbitmq-server version 2.8.7\nand preservce backwards compatibility.\n\nChange-Id: Iaeebb97c3437e5d610c606925a219e1c9949ae87\n'}]",5,36714,e52dd9eb0b17ea6b3d0e22a3c2d1c7c30cab9f65,14,7,2,6836,,,0,"Add Support for Rabbit Mirrored (HA) Queues

Previously, the nova::rabbitmq class could take advantage of
clustering, but mirrored (HA) queues would not behave properly
due to the version of RabbitMQ server installed.

Rabbit mirrored queues had several bugs that were fixed in 2.8.7:
  https://www.rabbitmq.com/release-notes/README-2.8.7.txt

This change will allow rabbit mirrored queues to behave properly
by installing the correct rabbitmq-server version.

Defaults to false to disable the use of rabbitmq-server version 2.8.7
and preservce backwards compatibility.

Change-Id: Iaeebb97c3437e5d610c606925a219e1c9949ae87
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/14/36714/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/nova_rabbitmq_spec.rb', 'manifests/rabbitmq.pp']",2,f427f12c8d0b48858558ef36101b68c0450e43a3,rabbit_ha_queues,"# [config_mirrored_queues] Whether to configure RabbitMQ mirrored queues within a Rabbit Cluster # Optional. Defaults to false. # $userid = 'guest', $password = 'guest', $port = '5672', $virtual_host = '/', $cluster_disk_nodes = false, $config_mirrored_queues = false, $enabled = true if $config_mirrored_queues { $config_mirrored_queues_real = true } else { $config_mirrored_queues_real = false } config_mirrored_queues => $config_mirrored_queues_real,"," $userid ='guest', $password ='guest', $port ='5672', $virtual_host ='/', $cluster_disk_nodes = false, $enabled = true",44,7
openstack%2Fceilometer~master~I22e1dadbe9a90e03e8ccfbcc6e0e8dc3f17c5a3e,openstack/ceilometer,master,I22e1dadbe9a90e03e8ccfbcc6e0e8dc3f17c5a3e,Fix the argument of UnknownArgument exception,MERGED,2013-07-16 15:19:17.000000000,2013-07-17 00:17:12.000000000,2013-07-17 00:17:12.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-07-16 15:19:17.000000000', 'files': ['ceilometer/api/controllers/v2.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/384617f6ca98723cd9c1ad66d74c4cb827fdf42c', 'message': 'Fix the argument of UnknownArgument exception\n\nThis change sets the real UnknownArgument instead of the last\nvalid one in the exception raised by the API.\n\nFixes bug #1201839\n\nChange-Id: I22e1dadbe9a90e03e8ccfbcc6e0e8dc3f17c5a3e\n'}]",0,37270,384617f6ca98723cd9c1ad66d74c4cb827fdf42c,7,4,1,2813,,,0,"Fix the argument of UnknownArgument exception

This change sets the real UnknownArgument instead of the last
valid one in the exception raised by the API.

Fixes bug #1201839

Change-Id: I22e1dadbe9a90e03e8ccfbcc6e0e8dc3f17c5a3e
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/70/37270/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/api/controllers/v2.py'],1,384617f6ca98723cd9c1ad66d74c4cb827fdf42c,bug/1201839," raise wsme.exc.UnknownArgument(k, ""unrecognized query field"")"," raise wsme.exc.UnknownArgument(i.field, ""unrecognized query field"")",1,2
openstack%2Fceilometer~master~I364208c87e450e7cb0443774e80916845dbfb32a,openstack/ceilometer,master,I364208c87e450e7cb0443774e80916845dbfb32a,doc: add a bunch of functional examples for the API,MERGED,2013-07-04 13:24:09.000000000,2013-07-17 00:17:04.000000000,2013-07-17 00:17:04.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 4715}, {'_account_id': 7993}]","[{'number': 1, 'created': '2013-07-04 13:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/40856135d07ee9083d5d5fb788bb38f4c358fa0c', 'message': 'doc: add a bunch of functional examples for the API\n\nChange-Id: I364208c87e450e7cb0443774e80916845dbfb32a\n'}, {'number': 2, 'created': '2013-07-05 09:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/44af4b16a6f447daaae6791762418c3ef40328ce', 'message': 'doc: add a bunch of functional examples for the API\n\nChange-Id: I364208c87e450e7cb0443774e80916845dbfb32a\n'}, {'number': 3, 'created': '2013-07-05 15:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/98658007c0b6a2880a2d4f9d2e6ea61d9afe6684', 'message': 'doc: add a bunch of functional examples for the API\n\nChange-Id: I364208c87e450e7cb0443774e80916845dbfb32a\n'}, {'number': 4, 'created': '2013-07-16 08:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4cb8f1671fb18ad2e65193532750e1e268748a73', 'message': 'doc: add a bunch of functional examples for the API\n\nChange-Id: I364208c87e450e7cb0443774e80916845dbfb32a\n'}, {'number': 5, 'created': '2013-07-16 16:29:34.000000000', 'files': ['ceilometer/api/controllers/v2.py', 'doc/source/webapi/v2.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2d25f8867adfc1994dec4f245bd56420882be2c8', 'message': 'doc: add a bunch of functional examples for the API\n\nChange-Id: I364208c87e450e7cb0443774e80916845dbfb32a\n'}]",51,35650,2d25f8867adfc1994dec4f245bd56420882be2c8,21,6,5,1669,,,0,"doc: add a bunch of functional examples for the API

Change-Id: I364208c87e450e7cb0443774e80916845dbfb32a
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/50/35650/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/webapi/v2.rst'],1,40856135d07ee9083d5d5fb788bb38f4c358fa0c,jd/doc-more-examples," Functional examples +++++++++++++++++++ The above examples are meant to help you understand how to query the Ceilometer API to build custom metrics report. The query parameters should be encoded using one of the above method, e.g. into the URL parameters or into JSON encoded data passed to the GET request. Get the meters about instances running for June 2013:: GET /v2/meters/instance q: [{""field"": ""timestamp"", ""op"": ""ge"", ""value"": ""2013-06-01T00:00:00""}, {""field"": ""timestamp"", ""op"": ""lt"", ""value"": ""2013-07-01T00:00:00""}] Get the meters about instances running for June 2013 for a particular project:: GET /v2/meters/instance q: [{""field"": ""timestamp"", ""op"": ""ge"", ""value"": ""2013-06-01T00:00:00""}, {""field"": ""timestamp"", ""op"": ""lt"", ""value"": ""2013-07-01T00:00:00""}, {""field"": ""project_id"", ""op"": ""eq"", ""value"": ""8d6057bc-5b90-4296-afe0-84acaa2ef909""}] Get the meters about instances running for June 2013 for a particular project:: GET /v2/meters/instance q: [{""field"": ""timestamp"", ""op"": ""ge"", ""value"": ""2013-06-01T00:00:00""}, {""field"": ""timestamp"", ""op"": ""lt"", ""value"": ""2013-07-01T00:00:00""}, {""field"": ""project_id"", ""op"": ""eq"", ""value"": ""8d6057bc-5b90-4296-afe0-84acaa2ef909""}] If you want to retrieve all the instances that have been run during this month, you should ask the resource endpoint for the list:: GET /v2/resources q: [{""field"": ""timestamp"", ""op"": ""ge"", ""value"": ""2013-06-01T00:00:00""}, {""field"": ""timestamp"", ""op"": ""lt"", ""value"": ""2013-07-01T00:00:00""}, {""field"": ""project_id"", ""op"": ""eq"", ""value"": ""8d6057bc-5b90-4296-afe0-84acaa2ef909""}] Then look for resources that have a *instance* meter linked to them. That will indicate resources that has been measured has being instance. You can them request their samples to have more detailled information, like their state or their flavor:: GET /v2/meter/instance q: [{""field"": ""timestamp"", ""op"": ""ge"", ""value"": ""2013-06-01T00:00:00""}, {""field"": ""timestamp"", ""op"": ""lt"", ""value"": ""2013-07-01T00:00:00""}, {""field"": ""resource_id"", ""op"": ""eq"", ""value"": ""64da755c-9120-4236-bee1-54acafe24980""}, {""field"": ""project_id"", ""op"": ""eq"", ""value"": ""8d6057bc-5b90-4296-afe0-84acaa2ef909""}] This will return a list of samples that has been recorded on this particular resource. You can inspect them to retrieve information, such as the instance state (check the *metadata.vm_state* field) or the instance flavor (check the *metadata.flavor* field).",,85,0
openstack%2Fceilometer~master~I23070f153ce03a8d6d8c9f17f05e2d5dae38647e,openstack/ceilometer,master,I23070f153ce03a8d6d8c9f17f05e2d5dae38647e,Add index for db.meter by descending timestamp,MERGED,2013-07-09 02:44:42.000000000,2013-07-17 00:16:57.000000000,2013-07-17 00:16:56.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4715}, {'_account_id': 7399}]","[{'number': 1, 'created': '2013-07-09 02:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0be678a507f1317cce149720627acdf4dbf6e9df', 'message': 'Add index for db.meter by descending timestamp\n\nFixes bug #1193906\n\nHacked tests/storage/base.py to make database 15000 times larger -- at this size\nthe MongoDB sort() operation fails without an index\n\nAdded an index for db.meter to sort by descending time stamp for class\nConnection in ceilometer/storage/impl_mongodb.py\n\nChange-Id: I23070f153ce03a8d6d8c9f17f05e2d5dae38647e\n'}, {'number': 2, 'created': '2013-07-09 04:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/aed725b6d7e27fe1f1bad666f82149305a31af38', 'message': 'Add index for db.meter by descending timestamp\n\nFixes bug #1193906\n\nHacked tests/storage/base.py to make database 15000 times larger -- at this size\nthe MongoDB sort() operation fails without an index\n\nAdded an index for db.meter to sort by descending time stamp for class\nConnection in ceilometer/storage/impl_mongodb.py\n\nChange-Id: I23070f153ce03a8d6d8c9f17f05e2d5dae38647e\n'}, {'number': 3, 'created': '2013-07-16 18:06:04.000000000', 'files': ['ceilometer/storage/impl_mongodb.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e984f28b00e3a073c176f6435507f5bce1c82d30', 'message': 'Add index for db.meter by descending timestamp\n\nFixes bug #1193906\n\nAdded an index for db.meter to sort by descending time stamp for class\nConnection in ceilometer/storage/impl_mongodb.py\n\nensure_index() is used rather than create_index() to be more efficient.\n\nThis index is needed because get_samples() in\nceilometer/storage/impl_mongodb.py sorts by descending timestamp.  Without an\nindex, MongoDB will fail to sort if the database is too large.\n\nChange-Id: I23070f153ce03a8d6d8c9f17f05e2d5dae38647e\n'}]",0,36159,e984f28b00e3a073c176f6435507f5bce1c82d30,15,4,3,7399,,,0,"Add index for db.meter by descending timestamp

Fixes bug #1193906

Added an index for db.meter to sort by descending time stamp for class
Connection in ceilometer/storage/impl_mongodb.py

ensure_index() is used rather than create_index() to be more efficient.

This index is needed because get_samples() in
ceilometer/storage/impl_mongodb.py sorts by descending timestamp.  Without an
index, MongoDB will fail to sort if the database is too large.

Change-Id: I23070f153ce03a8d6d8c9f17f05e2d5dae38647e
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/59/36159/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/storage/base.py', 'ceilometer/storage/impl_mongodb.py']",2,0be678a507f1317cce149720627acdf4dbf6e9df,bug/1193906," self.db.meter.create_index([('timestamp', pymongo.DESCENDING)], name='timestamp_idx') ",,3,1
openstack%2Ftempest~master~I7188929485e29a761327ab24e2bb1213fbd052a9,openstack/tempest,master,I7188929485e29a761327ab24e2bb1213fbd052a9,Add an option to run_stress.py to run tests serially.,MERGED,2013-07-16 14:59:36.000000000,2013-07-17 00:16:01.000000000,2013-07-17 00:16:01.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1795}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-07-16 14:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/efad74efc3867bc83d257e6f81fdd4ee8ab956a8', 'message': 'Add an option to run_stress.py to run tests serially.\n\nThis commit adds a new option to run_stress.py to run the stress\ntests serially. If more there is more than one JSON test in the\nfile passed into run_stress.py it would by default run the tests\nin parallel. However, there was no way to specify running the tests\nserially. This commit fixes this by adding a -s/--serial option\nwhich will run each test to completion before launching the next\none.\n\nChange-Id: I7188929485e29a761327ab24e2bb1213fbd052a9\n'}, {'number': 2, 'created': '2013-07-16 15:31:09.000000000', 'files': ['tempest/stress/run_stress.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8e663fc62076f86fa7425faac53c43f7a28250ec', 'message': 'Add an option to run_stress.py to run tests serially.\n\nThis commit adds a new option to run_stress.py to run the stress\ntests serially. If more there is more than one JSON test in the\nfile passed into run_stress.py it would by default run the tests\nin parallel. However, there was no way to specify running the tests\nserially. This commit fixes this by adding a -s/--serial option\nwhich will run each test to completion before launching the next\none.\n\nPart of: blueprint stress-tests\n\nChange-Id: I7188929485e29a761327ab24e2bb1213fbd052a9\n'}]",2,37263,8e663fc62076f86fa7425faac53c43f7a28250ec,12,6,2,5196,,,0,"Add an option to run_stress.py to run tests serially.

This commit adds a new option to run_stress.py to run the stress
tests serially. If more there is more than one JSON test in the
file passed into run_stress.py it would by default run the tests
in parallel. However, there was no way to specify running the tests
serially. This commit fixes this by adding a -s/--serial option
which will run each test to completion before launching the next
one.

Part of: blueprint stress-tests

Change-Id: I7188929485e29a761327ab24e2bb1213fbd052a9
",git fetch https://review.opendev.org/openstack/tempest refs/changes/63/37263/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/stress/run_stress.py'],1,efad74efc3867bc83d257e6f81fdd4ee8ab956a8,fix-stress-tox," if ns.serial: for test in tests: driver.stress_openstack([test], ns.duration) else: driver.stress_openstack(tests, ns.duration) help=""Duration of test in secs."") parser.add_argument('-s', '--serial', action='store_true', help=""Trigger running tests serially."")"," driver.stress_openstack(tests, ns.duration) help=""Duration of test."")",8,2
openstack%2Ftempest~master~I5eb0652799601631e34cc2bbef836624d71bb3e7,openstack/tempest,master,I5eb0652799601631e34cc2bbef836624d71bb3e7,Fix tox job for stress tests.,MERGED,2013-07-16 14:59:36.000000000,2013-07-17 00:14:06.000000000,2013-07-17 00:14:05.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1795}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-07-16 14:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8ebc3891436f7207e7c8d03994b7fc9d0efa4d1b', 'message': 'Fix tox job for stress tests.\n\nThis commit fixes the behavior of the tox stress job. To do this a\nnew json tests file was added for the tox job. This json file will\ncontain a list of all the actions that will get run as part of the\ntox job. (and by extension the periodic jenkins stress test job) The\ntox job is then updated to run each of the tests listed in the json\nfile for an hour each.\n\nChange-Id: I5eb0652799601631e34cc2bbef836624d71bb3e7\n'}, {'number': 2, 'created': '2013-07-16 15:31:08.000000000', 'files': ['tempest/stress/etc/stress-tox-job.json', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7bd1cf26c951c5fded4bea8a2018269630e8f498', 'message': 'Fix tox job for stress tests.\n\nThis commit fixes the behavior of the tox stress job. To do this a\nnew json tests file was added for the tox job. This json file will\ncontain a list of all the actions that will get run as part of the\ntox job. (and by extension the periodic jenkins stress test job) The\ntox job is then updated to run each of the tests listed in the json\nfile for an hour each.\n\nPart of: blueprint stress-tests\n\nChange-Id: I5eb0652799601631e34cc2bbef836624d71bb3e7\n'}]",3,37262,7bd1cf26c951c5fded4bea8a2018269630e8f498,15,6,2,5196,,,0,"Fix tox job for stress tests.

This commit fixes the behavior of the tox stress job. To do this a
new json tests file was added for the tox job. This json file will
contain a list of all the actions that will get run as part of the
tox job. (and by extension the periodic jenkins stress test job) The
tox job is then updated to run each of the tests listed in the json
file for an hour each.

Part of: blueprint stress-tests

Change-Id: I5eb0652799601631e34cc2bbef836624d71bb3e7
",git fetch https://review.opendev.org/openstack/tempest refs/changes/62/37262/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/stress/etc/stress-tox-job.json', 'tox.ini']",2,8ebc3891436f7207e7c8d03994b7fc9d0efa4d1b,fix-stress-tox, python -m tempest/stress/run_stress tempest/stress/etc/stress-tox-job.json -d 3600, python -m tempest/stress/run_stress tempest/stress/etc/sample-test.json -d 60 python -m tempest/stress/run_stress tempest/stress/etc/volume-create-delete-test.json -d 60 ,14,3
openstack%2Ftempest~master~I39b8a1d38f70ddda4867126b58bb7053b45654d6,openstack/tempest,master,I39b8a1d38f70ddda4867126b58bb7053b45654d6,Rework stress to be more UnitTest like,MERGED,2013-07-12 00:24:40.000000000,2013-07-17 00:13:59.000000000,2013-07-17 00:13:58.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}, {'_account_id': 5997}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-07-12 00:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/779047acb2afb3f36f4147e5f108f8e62c3d4ec8', 'message': ""Rework stress to be more UnitTest like\n\nThis patch reworks the stress test framework and\nthe scripts to be a bit more flexible and to be\nlike how unit tests are written.  Instead of\nwriting a module that contains functions, we now\nwrite an object that can implement a setUp and tearDown\nmethod.  By default the object's 'run' method will be\ncalled by the driver.\n\nThe setUp method will be called prior to calling run\nand tearDown will be called after run is stopped.\n\nDocImpact\n\nChange-Id: I39b8a1d38f70ddda4867126b58bb7053b45654d6\n""}, {'number': 2, 'created': '2013-07-12 21:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dba759660fbe3a23d5aa87a48a9c8aaf53a1cfa2', 'message': ""Rework stress to be more UnitTest like\n\nThis patch reworks the stress test framework and\nthe scripts to be a bit more flexible and to be\nlike how unit tests are written.  Instead of\nwriting a module that contains functions, we now\nwrite an object that can implement a setUp and tearDown\nmethod.  By default the object's 'run' method will be\ncalled by the driver.\n\nThe setUp method will be called prior to calling run\nand tearDown will be called after run is stopped.\n\nDocImpact\n\nImplements:  blueprint stress-tests\n\nChange-Id: I39b8a1d38f70ddda4867126b58bb7053b45654d6\n""}, {'number': 3, 'created': '2013-07-12 22:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a2e0c686f78828193f0ec5989a627add2020b618', 'message': ""Rework stress to be more UnitTest like\n\nThis patch reworks the stress test framework and\nthe scripts to be a bit more flexible and to be\nlike how unit tests are written.  Instead of\nwriting a module that contains functions, we now\nwrite an object that can implement a setUp and tearDown\nmethod.  By default the object's 'run' method will be\ncalled by the driver.\n\nThe setUp method will be called prior to calling run\nand tearDown will be called after run is stopped.\n\nDocImpact\n\nImplements:  blueprint stress-tests\n\nChange-Id: I39b8a1d38f70ddda4867126b58bb7053b45654d6\n""}, {'number': 4, 'created': '2013-07-13 00:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/95789a918ffd4cbb11740f9286a23f34577aae2a', 'message': ""Rework stress to be more UnitTest like\n\nThis patch reworks the stress test framework and\nthe scripts to be a bit more flexible and to be\nlike how unit tests are written.  Instead of\nwriting a module that contains functions, we now\nwrite an object that can implement a setUp and tearDown\nmethod.  By default the object's 'run' method will be\ncalled by the driver.\n\nThe setUp method will be called prior to calling run\nand tearDown will be called after run is stopped.\n\nAlso added debug logging to the cleanup mechanism.\nAlso added removing snapshots prior to removing\nvolumes during cleanup\n\nDocImpact\n\nImplements:  blueprint stress-tests\n\nChange-Id: I39b8a1d38f70ddda4867126b58bb7053b45654d6\n""}, {'number': 5, 'created': '2013-07-15 16:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8223963aa3827ab7590a6b8161b880a952e4b539', 'message': ""Rework stress to be more UnitTest like\n\nThis patch reworks the stress test framework and\nthe scripts to be a bit more flexible and to be\nlike how unit tests are written.  Instead of\nwriting a module that contains functions, we now\nwrite an object that can implement a setUp and tearDown\nmethod.  By default the object's 'run' method will be\ncalled by the driver.\n\nThe setUp method will be called prior to calling run\nand tearDown will be called after run is stopped.\n\nAlso added debug logging to the cleanup mechanism.\nAlso added removing snapshots prior to removing\nvolumes during cleanup\n\nDocImpact\n\nImplements:  blueprint stress-tests\n\nChange-Id: I39b8a1d38f70ddda4867126b58bb7053b45654d6\n""}, {'number': 6, 'created': '2013-07-15 20:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c0ff60104763fb4419bfc97c78db4e10df6ff189', 'message': ""Rework stress to be more UnitTest like\n\nThis patch reworks the stress test framework and\nthe scripts to be a bit more flexible and to be\nlike how unit tests are written.  Instead of\nwriting a module that contains functions, we now\nwrite an object that can implement a setUp and tearDown\nmethod.  By default the object's 'run' method will be\ncalled by the driver.\n\nThe setUp method will be called prior to calling run\nand tearDown will be called after run is stopped.\n\nAlso added debug logging to the cleanup mechanism.\nAlso added removing snapshots prior to removing\nvolumes during cleanup\n\nDocImpact\n\nImplements:  blueprint stress-tests\n\nChange-Id: I39b8a1d38f70ddda4867126b58bb7053b45654d6\n""}, {'number': 7, 'created': '2013-07-16 08:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/094254754882e2439f79aac2a0b65c542afff3cb', 'message': ""Rework stress to be more UnitTest like\n\nThis patch reworks the stress test framework and\nthe scripts to be a bit more flexible and to be\nlike how unit tests are written.  Instead of\nwriting a module that contains functions, we now\nwrite an object that can implement a setUp and tearDown\nmethod.  By default the object's 'run' method will be\ncalled by the driver.\n\nThe setUp method will be called prior to calling run\nand tearDown will be called after run is stopped.\n\nAlso added debug logging to the cleanup mechanism.\nAlso added removing snapshots prior to removing\nvolumes during cleanup\n\nDocImpact\n\nImplements:  blueprint stress-tests\n\nChange-Id: I39b8a1d38f70ddda4867126b58bb7053b45654d6\n""}, {'number': 8, 'created': '2013-07-16 18:17:14.000000000', 'files': ['tempest/stress/etc/volume-create-delete-test.json', 'tempest/stress/tools/cleanup.py', 'tempest/stress/etc/sample-test.json', 'tempest/stress/actions/volume_create_delete.py', 'tempest/stress/driver.py', 'tempest/stress/actions/create_destroy_server.py', 'tempest/stress/cleanup.py', 'tempest/stress/stressaction.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b725e62d7d6d0413878ebc804c8a6eec8786794c', 'message': ""Rework stress to be more UnitTest like\n\nThis patch reworks the stress test framework and\nthe scripts to be a bit more flexible and to be\nlike how unit tests are written.  Instead of\nwriting a module that contains functions, we now\nwrite an object that can implement a setUp and tearDown\nmethod.  By default the object's 'run' method will be\ncalled by the driver.\n\nThe setUp method will be called prior to calling run\nand tearDown will be called after run is stopped.\n\nAlso added debug logging to the cleanup mechanism.\nAlso added removing snapshots prior to removing\nvolumes during cleanup\n\nDocImpact\n\nImplements:  blueprint stress-tests\n\nChange-Id: I39b8a1d38f70ddda4867126b58bb7053b45654d6\n""}]",21,36752,b725e62d7d6d0413878ebc804c8a6eec8786794c,32,5,8,5997,,,0,"Rework stress to be more UnitTest like

This patch reworks the stress test framework and
the scripts to be a bit more flexible and to be
like how unit tests are written.  Instead of
writing a module that contains functions, we now
write an object that can implement a setUp and tearDown
method.  By default the object's 'run' method will be
called by the driver.

The setUp method will be called prior to calling run
and tearDown will be called after run is stopped.

Also added debug logging to the cleanup mechanism.
Also added removing snapshots prior to removing
volumes during cleanup

DocImpact

Implements:  blueprint stress-tests

Change-Id: I39b8a1d38f70ddda4867126b58bb7053b45654d6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/36752/8 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/stress/etc/volume-create-delete-test.json', 'tempest/stress/etc/sample-test.json', 'tempest/stress/testObject.py', 'tempest/stress/actions/volume_create_delete.py', 'tempest/stress/driver.py', 'tempest/stress/actions/create_destroy_server.py']",6,779047acb2afb3f36f4147e5f108f8e62c3d4ec8,bp/stress-tests,"import tempest.stress.testObject as testObject class CreateDestroyServerTest(testObject.testObject): def __init__(self, manager, logger, *args, **kwargs): super(CreateDestroyServerTest, self).__init__( manager, logger, *args, **kwargs) def run(self, **kwargs): image = self.manager.config.compute.image_ref flavor = self.manager.config.compute.flavor_ref while True: name = rand_name(""instance"") self.logger.info(""creating %s"" % name) resp, server = self.manager.servers_client.create_server( name, image, flavor) server_id = server['id'] assert(resp.status == 202) self.manager.servers_client.wait_for_server_status(server_id, 'ACTIVE') self.logger.info(""created %s"" % server_id) self.logger.info(""deleting %s"" % name) resp, _ = self.manager.servers_client.delete_server(server_id) assert(resp.status == 204) self.manager.servers_client.wait_for_server_termination(server_id) self.logger.info(""deleted %s"" % server_id)"," def create_destroy(manager, logger): image = manager.config.compute.image_ref flavor = manager.config.compute.flavor_ref while True: name = rand_name(""instance"") logger.info(""creating %s"" % name) resp, server = manager.servers_client.create_server( name, image, flavor) server_id = server['id'] assert(resp.status == 202) manager.servers_client.wait_for_server_status(server_id, 'ACTIVE') logger.info(""created %s"" % server_id) logger.info(""deleting %s"" % name) resp, _ = manager.servers_client.delete_server(server_id) assert(resp.status == 204) manager.servers_client.wait_for_server_termination(server_id) logger.info(""deleted %s"" % server_id)",105,42
openstack%2Fcinder~master~Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3,openstack/cinder,master,Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3,Adds multiple iSCSI port support to 3PAR,MERGED,2013-07-10 19:41:30.000000000,2013-07-17 00:13:55.000000000,2013-07-17 00:13:55.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 7389}]","[{'number': 1, 'created': '2013-07-10 19:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/20c57c31f0ba73c3a0564e59ae7ff27f282691d5', 'message': 'Adds multiple iSCSI port support\n\nAdded support to the 3PAR iSCSI OpenStack driver to provide the\nability to select the best fit target iSCSI port from a list of\ncandidate ports. The first time a volume is attached to a host,\nall iSCSI ports configured for driver selection, are examined for\nbest fit. The port with the least active volumes attached will\nthen be selected as the path to the 3PAR array. Any subsequent\nvolume attach, to the same host, will use the established target\nport.\n\nFixes but #1197036\n\nChange-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3\n'}, {'number': 2, 'created': '2013-07-10 22:31:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3917ded942ac9b70687a5d0b233becfde248d775', 'message': 'Adds multiple iSCSI port support\n\nAdded support to the 3PAR iSCSI OpenStack driver to provide the\nability to select the best fit target iSCSI port from a list of\ncandidate ports. The first time a volume is attached to a host,\nall iSCSI ports configured for driver selection, are examined for\nbest fit. The port with the least active volumes attached will\nthen be selected as the path to the 3PAR array. Any subsequent\nvolume attach, to the same host, will use the established target\nport.\n\nFixes bug #1197036\n\nChange-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3\n'}, {'number': 3, 'created': '2013-07-10 22:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c31678562c5ec8d5056000428ed64bf04f7f4e0', 'message': 'Adds multiple iSCSI port support\n\nAdded support to the 3PAR iSCSI OpenStack driver to provide the\nability to select the best fit target iSCSI port from a list of\ncandidate ports. The first time a volume is attached to a host,\nall iSCSI ports configured for driver selection, are examined for\nbest fit. The port with the least active volumes attached will\nthen be selected as the path to the 3PAR array. Any subsequent\nvolume attach, to the same host, will use the established target\nport.\n\nFixes bug #1197036\n\nChange-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3\n'}, {'number': 4, 'created': '2013-07-11 20:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7e98b595361ae8769f0cd5bde4e28fc7fcb2e408', 'message': 'Adds multiple iSCSI port support\n\nAdded support to the 3PAR iSCSI OpenStack driver to provide the\nability to select the best fit target iSCSI port from a list of\ncandidate ports. The first time a volume is attached to a host,\nall iSCSI ports configured for driver selection, are examined for\nbest fit. The port with the least active volumes attached will\nthen be selected as the path to the 3PAR array. Any subsequent\nvolume attach, to the same host, will use the established target\nport.\n\nDocImpact\n\nFixes bug #1197036\n\nChange-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3\n'}, {'number': 5, 'created': '2013-07-13 00:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f15d109e1d4702a28026c359544abfe09cc5f29e', 'message': 'Adds multiple iSCSI port support\n\nAdded support to the 3PAR iSCSI OpenStack driver to provide the\nability to select the best fit target iSCSI port from a list of\ncandidate ports. The first time a volume is attached to a host,\nall iSCSI ports configured for driver selection, are examined for\nbest fit. The port with the least active volumes attached will\nthen be selected as the path to the 3PAR array. Any subsequent\nvolume attach, to the same host, will use the established target\nport.\n\nDocImpact\n\nFixes bug #1197036\n\nChange-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3\n'}, {'number': 6, 'created': '2013-07-15 17:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e4cb7a7b87891adc7d9e128bd02bde02ef4b4717', 'message': 'Adds multiple iSCSI port support\n\nAdded support to the 3PAR iSCSI OpenStack driver to provide the\nability to select the best fit target iSCSI port from a list of\ncandidate ports. The first time a volume is attached to a host,\nall iSCSI ports configured for driver selection, are examined for\nbest fit. The port with the least active volumes attached will\nthen be selected as the path to the 3PAR array. Any subsequent\nvolume attach, to the same host, will use the established target\nport.\n\nDocImpact\n\nFixes bug #1197036\n\nChange-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3\n'}, {'number': 7, 'created': '2013-07-15 18:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b087c867ce01fd71160186f6ce55d5b73e813f77', 'message': 'Adds multiple iSCSI port support\n\nAdded support to the 3PAR iSCSI OpenStack driver to provide the\nability to select the best fit target iSCSI port from a list of\ncandidate ports. The first time a volume is attached to a host,\nall iSCSI ports configured for driver selection, are examined for\nbest fit. The port with the least active volumes attached will\nthen be selected as the path to the 3PAR array. Any subsequent\nvolume attach, to the same host, will use the established target\nport.\n\nDocImpact\n\nFixes bug #1197036\n\nChange-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3\n'}, {'number': 8, 'created': '2013-07-15 23:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/20bef009df23c8e5df33ffebd3475be69eee6a6c', 'message': 'Adds multiple iSCSI port support\n\nAdded support to the 3PAR iSCSI OpenStack driver to provide the\nability to select the best fit target iSCSI port from a list of\ncandidate ports. The first time a volume is attached to a host,\nall iSCSI ports configured for driver selection, are examined for\nbest fit. The port with the least active volumes attached will\nthen be selected as the path to the 3PAR array. Any subsequent\nvolume attach, to the same host, will use the established target\nport.\n\nDocImpact\n\nFixes bug #1197036\n\nChange-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3\n'}, {'number': 9, 'created': '2013-07-15 23:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/edc7657a7fe7411588b3ea0ffdcd53ce73b1ee6a', 'message': 'Adds multiple iSCSI port support\n\nAdded support to the 3PAR iSCSI OpenStack driver to provide the\nability to select the best fit target iSCSI port from a list of\ncandidate ports. The first time a volume is attached to a host,\nall iSCSI ports configured for driver selection, are examined for\nbest fit. The port with the least active volumes attached will\nthen be selected as the path to the 3PAR array. Any subsequent\nvolume attach, to the same host, will use the established target\nport.\n\nDocImpact\n\nFixes bug #1197036\n\nChange-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3\n'}, {'number': 10, 'created': '2013-07-16 15:49:48.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d9e2c642e229f6a7e9448e81b64a94493a89c280', 'message': 'Adds multiple iSCSI port support to 3PAR\n\nAdded support to the 3PAR iSCSI OpenStack driver to provide the\nability to select the best fit target iSCSI port from a list of\ncandidate ports. The first time a volume is attached to a host,\nall iSCSI ports configured for driver selection, are examined for\nbest fit. The port with the least active volumes attached will\nthen be selected as the path to the 3PAR array. Any subsequent\nvolume attach, to the same host, will use the established target\nport.\n\nDocImpact\n\nFixes bug #1197036\n\nChange-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3\n'}]",29,36535,d9e2c642e229f6a7e9448e81b64a94493a89c280,48,8,10,7389,,,0,"Adds multiple iSCSI port support to 3PAR

Added support to the 3PAR iSCSI OpenStack driver to provide the
ability to select the best fit target iSCSI port from a list of
candidate ports. The first time a volume is attached to a host,
all iSCSI ports configured for driver selection, are examined for
best fit. The port with the least active volumes attached will
then be selected as the path to the 3PAR array. Any subsequent
volume attach, to the same host, will use the established target
port.

DocImpact

Fixes bug #1197036

Change-Id: Icf8c28ea3f201e5e21c9a6ed00a2fbdda445c8b3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/35/36535/8 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py']",4,20c57c31f0ba73c3a0564e59ae7ff27f282691d5,bug/1197036," help=""Enable HTTP debugging to 3PAR""), cfg.ListOpt('hp3par_iscsi_ips', default=[], help=""List of iSCSI addresses to use."")"," help=""Enable HTTP debugging to 3PAR"")",365,97
openstack%2Fnova~master~Ibe6ebf266a2f4694fb218266ba644be825889907,openstack/nova,master,Ibe6ebf266a2f4694fb218266ba644be825889907,Move a migration test to MigrationTestCase.,MERGED,2013-07-16 15:28:27.000000000,2013-07-17 00:12:53.000000000,2013-07-17 00:12:51.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 4393}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-07-16 15:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58bc4962220dcb36c3f225c7253038b7c15ec6d9', 'message': 'Move test_migration_get_unconfirmed_by_dest_compute to MigrationTestCase.\n\nThere is test_migration_get_unconfirmed_by_dest_compute\ntest in old mixed DbApiTestCase. This patch moves this test\nto its native test case MigrationTestCase.\n\nDbApiTestCase renamed as DecoratorTestCase because no\ndb api methods tests remained in this test case.\n\nblueprint db-api-tests\n\nChange-Id: Ibe6ebf266a2f4694fb218266ba644be825889907\n'}, {'number': 2, 'created': '2013-07-16 21:29:55.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2bd8d5a86d16ec539ad6be02c6faf75ce1224bab', 'message': 'Move a migration test to MigrationTestCase.\n\nThere is test_migration_get_unconfirmed_by_dest_compute\ntest in old mixed DbApiTestCase. This patch moves this test\nto its native test case MigrationTestCase.\n\nDbApiTestCase renamed as DecoratorTestCase because no\ndb api methods tests remained in this test case.\n\nblueprint db-api-tests\n\nChange-Id: Ibe6ebf266a2f4694fb218266ba644be825889907\n'}]",0,37273,2bd8d5a86d16ec539ad6be02c6faf75ce1224bab,9,4,2,7711,,,0,"Move a migration test to MigrationTestCase.

There is test_migration_get_unconfirmed_by_dest_compute
test in old mixed DbApiTestCase. This patch moves this test
to its native test case MigrationTestCase.

DbApiTestCase renamed as DecoratorTestCase because no
db api methods tests remained in this test case.

blueprint db-api-tests

Change-Id: Ibe6ebf266a2f4694fb218266ba644be825889907
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/37273/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,58bc4962220dcb36c3f225c7253038b7c15ec6d9,bp/db-api-tests,"class DecoratorTestCase(test.TestCase): def test_migration_get_unconfirmed_by_dest_compute(self): # Ensure no migrations are returned. results = db.migration_get_unconfirmed_by_dest_compute(self.ctxt, 10, 'fake_host') self.assertEqual(0, len(results)) # Ensure no migrations are returned. results = db.migration_get_unconfirmed_by_dest_compute(self.ctxt, 10, 'fake_host2') self.assertEqual(0, len(results)) updated_at = datetime.datetime(2000, 1, 1, 12, 0, 0) values = {""status"": ""finished"", ""updated_at"": updated_at, ""dest_compute"": ""fake_host2""} migration = db.migration_create(self.ctxt, values) # Ensure different host is not returned results = db.migration_get_unconfirmed_by_dest_compute(self.ctxt, 10, 'fake_host') self.assertEqual(0, len(results)) # Ensure one migration older than 10 seconds is returned. results = db.migration_get_unconfirmed_by_dest_compute(self.ctxt, 10, 'fake_host2') self.assertEqual(1, len(results)) db.migration_update(self.ctxt, migration['id'], {""status"": ""CONFIRMED""}) # Ensure the new migration is not returned. updated_at = timeutils.utcnow() values = {""status"": ""finished"", ""updated_at"": updated_at, ""dest_compute"": ""fake_host2""} migration = db.migration_create(self.ctxt, values) results = db.migration_get_unconfirmed_by_dest_compute(self.ctxt, 10, ""fake_host2"") self.assertEqual(0, len(results)) db.migration_update(self.ctxt, migration['id'], {""status"": ""CONFIRMED""}) ","class DbApiTestCase(DbTestCase): def test_migration_get_unconfirmed_by_dest_compute(self): ctxt = context.get_admin_context() # Ensure no migrations are returned. results = db.migration_get_unconfirmed_by_dest_compute(ctxt, 10, 'fake_host') self.assertEqual(0, len(results)) # Ensure no migrations are returned. results = db.migration_get_unconfirmed_by_dest_compute(ctxt, 10, 'fake_host2') self.assertEqual(0, len(results)) updated_at = datetime.datetime(2000, 1, 1, 12, 0, 0) values = {""status"": ""finished"", ""updated_at"": updated_at, ""dest_compute"": ""fake_host2""} migration = db.migration_create(ctxt, values) # Ensure different host is not returned results = db.migration_get_unconfirmed_by_dest_compute(ctxt, 10, 'fake_host') self.assertEqual(0, len(results)) # Ensure one migration older than 10 seconds is returned. results = db.migration_get_unconfirmed_by_dest_compute(ctxt, 10, 'fake_host2') self.assertEqual(1, len(results)) db.migration_update(ctxt, migration['id'], {""status"": ""CONFIRMED""}) # Ensure the new migration is not returned. updated_at = timeutils.utcnow() values = {""status"": ""finished"", ""updated_at"": updated_at, ""dest_compute"": ""fake_host2""} migration = db.migration_create(ctxt, values) results = db.migration_get_unconfirmed_by_dest_compute(ctxt, 10, ""fake_host2"") self.assertEqual(0, len(results)) db.migration_update(ctxt, migration['id'], {""status"": ""CONFIRMED""}) ",40,41
openstack%2Fnova~master~I771ccec9f41480c8aa90e18b60cc8d75137027d3,openstack/nova,master,I771ccec9f41480c8aa90e18b60cc8d75137027d3,Move test_stringified_ips to InstanceTestCase.,MERGED,2013-07-16 14:32:43.000000000,2013-07-17 00:11:47.000000000,2013-07-17 00:11:44.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-07-16 14:32:43.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b9443fafd33b21897f505d186fa37b3b54efe280', 'message': 'Move test_stringified_ips to InstanceTestCase.\n\nThere is test_stringified_ips for instance_*\nmethods in old mixed DbApiTestCase.\nThis patch moves this test to InstanceTestCase.\n\nblueprint db-api-tests\n\nChange-Id: I771ccec9f41480c8aa90e18b60cc8d75137027d3\n'}]",0,37257,b9443fafd33b21897f505d186fa37b3b54efe280,8,5,1,7711,,,0,"Move test_stringified_ips to InstanceTestCase.

There is test_stringified_ips for instance_*
methods in old mixed DbApiTestCase.
This patch moves this test to InstanceTestCase.

blueprint db-api-tests

Change-Id: I771ccec9f41480c8aa90e18b60cc8d75137027d3
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/37257/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,b9443fafd33b21897f505d186fa37b3b54efe280,bp/db-api-tests," def test_instance_stringified_ips(self): instance = self.create_instance_with_args() instance = db.instance_update( self.ctxt, instance['uuid'], {'access_ip_v4': netaddr.IPAddress('1.2.3.4'), 'access_ip_v6': netaddr.IPAddress('::1')}) self.assertTrue(isinstance(instance['access_ip_v4'], basestring)) self.assertTrue(isinstance(instance['access_ip_v6'], basestring)) instance = db.instance_get_by_uuid(self.ctxt, instance['uuid']) self.assertTrue(isinstance(instance['access_ip_v4'], basestring)) self.assertTrue(isinstance(instance['access_ip_v6'], basestring)) "," def test_stringified_ips(self): instance = self.create_instance_with_args() instance = db.instance_update( self.context, instance['uuid'], {'access_ip_v4': netaddr.IPAddress('1.2.3.4'), 'access_ip_v6': netaddr.IPAddress('::1')}) self.assertTrue(isinstance(instance['access_ip_v4'], basestring)) self.assertTrue(isinstance(instance['access_ip_v6'], basestring)) instance = db.instance_get_by_uuid(self.context, instance['uuid']) self.assertTrue(isinstance(instance['access_ip_v4'], basestring)) self.assertTrue(isinstance(instance['access_ip_v6'], basestring)) ",12,12
openstack%2Fnova~master~Iba59764e692cd1d3bc80521ba5a4412f2bebb168,openstack/nova,master,Iba59764e692cd1d3bc80521ba5a4412f2bebb168,Add a new GroupAffinityFilter,MERGED,2013-07-05 11:42:12.000000000,2013-07-17 00:11:25.000000000,2013-07-17 00:11:22.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2468}, {'_account_id': 2889}, {'_account_id': 5441}, {'_account_id': 7494}]","[{'number': 1, 'created': '2013-07-05 11:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39269151f0e9bc0c7ab003993815a09078f75041', 'message': 'Add a new GroupAffinityFilter\n\nAdd a new filter to schedule the instance on to host from a set\nof group hosts\n\nblueprint group-affinity-filter\n\nChange-Id: Iba59764e692cd1d3bc80521ba5a4412f2bebb168\n'}, {'number': 2, 'created': '2013-07-06 23:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5fbb272ed9844f2879eeb1c705867e0d816cf8d9', 'message': 'Add a new GroupAffinityFilter\n\nAdd a new filter to schedule the instance on to host from a set\nof group hosts\n\nImplements part of blueprint instance-group-api-extension\n\nChange-Id: Iba59764e692cd1d3bc80521ba5a4412f2bebb168\n'}, {'number': 3, 'created': '2013-07-06 23:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/332e9ec26b49bf054ce0151602512e7e8b2c3215', 'message': 'Add a new GroupAffinityFilter\n\nAdd a new filter to schedule the instance on to host from a set\nof group hosts\n\nImplements blueprint group-affinity-filter\n\nChange-Id: Iba59764e692cd1d3bc80521ba5a4412f2bebb168\n'}, {'number': 4, 'created': '2013-07-07 04:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09c96dad75c33550cc0711f6c0037895e72195a1', 'message': 'Add a new GroupAffinityFilter\n\nAdd a new filter to schedule the instance on to host from a set\nof group hosts\n\nImplements blueprint group-affinity-filter\n\nChange-Id: Iba59764e692cd1d3bc80521ba5a4412f2bebb168\n'}, {'number': 5, 'created': '2013-07-16 16:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5be063b12c20eae69cadc7320efcc865fda18e52', 'message': 'Add a new GroupAffinityFilter\n\n1) Add a new filter to schedule the instance on to host from a set\n   of group hosts\n2) Update filter_scheduler.rst to add the new GroupAffinityFilter\n   filter description\n\nImplements blueprint group-affinity-filter\n\nChange-Id: Iba59764e692cd1d3bc80521ba5a4412f2bebb168\n'}, {'number': 6, 'created': '2013-07-16 21:31:52.000000000', 'files': ['nova/tests/scheduler/test_host_filters.py', 'doc/source/devref/filter_scheduler.rst', 'nova/scheduler/filters/affinity_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/58e6bee5299f07b34833b35ac3976d4be600a515', 'message': 'Add a new GroupAffinityFilter\n\n1) Add a new filter to schedule the instance on to host from a set\n   of group hosts\n2) Update filter_scheduler.rst to add the new GroupAffinityFilter\n   filter description\n\nImplements blueprint group-affinity-filter\n\nDocImpact\n\nChange-Id: Iba59764e692cd1d3bc80521ba5a4412f2bebb168\n'}]",7,35788,58e6bee5299f07b34833b35ac3976d4be600a515,43,8,6,7494,,,0,"Add a new GroupAffinityFilter

1) Add a new filter to schedule the instance on to host from a set
   of group hosts
2) Update filter_scheduler.rst to add the new GroupAffinityFilter
   filter description

Implements blueprint group-affinity-filter

DocImpact

Change-Id: Iba59764e692cd1d3bc80521ba5a4412f2bebb168
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/35788/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_host_filters.py', 'doc/source/devref/filter_scheduler.rst', 'nova/scheduler/filters/affinity_filter.py']",3,39269151f0e9bc0c7ab003993815a09078f75041,bp/group-affinity-filter," class GroupAffinityFilter(AffinityFilter): """"""Schedule the instance on to host from a set of group hosts. """""" def host_passes(self, host_state, filter_properties): group_hosts = filter_properties.get('group_hosts') or [] LOG.debug(_(""Group affinity: check if %(host)s in "" ""%(configured)s""), {'host': host_state.host, 'configured': group_hosts}) if group_hosts: return host_state.host in group_hosts # No groups configured return True",,35,0
openstack%2Frequirements~master~Ia113d8e5b774bec649b20ac1279715cbdae5ea9a,openstack/requirements,master,Ia113d8e5b774bec649b20ac1279715cbdae5ea9a,"Revert ""Add support for Keystone V3 Auth in Horizon.""",ABANDONED,2013-07-16 23:59:01.000000000,2013-07-17 00:05:10.000000000,,[],"[{'number': 1, 'created': '2013-07-16 23:59:01.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a113d8e5b774bec649b20ac1279715cbdae5ea9a', 'message': 'Revert ""Add support for Keystone V3 Auth in Horizon.""\n\nWe need to get the patches landed into client libs first.\n\nThis reverts commit d5e21fb99e4a8526dc1d30db382f6e2469e78963'}]",0,37356,a113d8e5b774bec649b20ac1279715cbdae5ea9a,1,0,1,2,,,0,"Revert ""Add support for Keystone V3 Auth in Horizon.""

We need to get the patches landed into client libs first.

This reverts commit d5e21fb99e4a8526dc1d30db382f6e2469e78963",git fetch https://review.opendev.org/openstack/requirements refs/changes/56/37356/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a113d8e5b774bec649b20ac1279715cbdae5ea9a,,"django_openstack_auth>=1.0.11,!=1.1.0python-keystoneclient>=0.2.1",django_openstack_auth>=1.1.0python-keystoneclient>=0.3.0,2,2
openstack%2Fnova~master~I2d14cd36873c736411f6cc587aa52dbdb1296445,openstack/nova,master,I2d14cd36873c736411f6cc587aa52dbdb1296445,Move *_ec2_* tests in test_db_api to own test case.,MERGED,2013-07-16 13:37:58.000000000,2013-07-17 00:05:05.000000000,2013-07-17 00:05:03.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-07-16 13:37:58.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/333512ef22db0372f2311cf175eb33f97e908d8a', 'message': 'Move *_ec2_* tests in test_db_api to own test case.\n\nThere is *_ec2_* tests in old mixed DbApiTestCase.\nThis patch moves them to its own test case Ec2TestCase.\n\nAlso missing tests added to new test case.\n\nblueprint db-api-tests\n\nChange-Id: I2d14cd36873c736411f6cc587aa52dbdb1296445\n'}]",0,37248,333512ef22db0372f2311cf175eb33f97e908d8a,8,5,1,7711,,,0,"Move *_ec2_* tests in test_db_api to own test case.

There is *_ec2_* tests in old mixed DbApiTestCase.
This patch moves them to its own test case Ec2TestCase.

Also missing tests added to new test case.

blueprint db-api-tests

Change-Id: I2d14cd36873c736411f6cc587aa52dbdb1296445
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/37248/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,333512ef22db0372f2311cf175eb33f97e908d8a,bp/db-api-tests,"class Ec2TestCase(test.TestCase): def setUp(self): super(Ec2TestCase, self).setUp() self.ctxt = context.RequestContext('fake_user', 'fake_project') def test_ec2_ids_not_found_are_printable(self): def check_exc_format(method, value): try: method(self.ctxt, value) except exception.NotFound as exc: self.assertTrue(unicode(value) in unicode(exc)) check_exc_format(db.get_ec2_volume_id_by_uuid, 'fake') check_exc_format(db.get_volume_uuid_by_ec2_id, 123456) check_exc_format(db.get_ec2_snapshot_id_by_uuid, 'fake') check_exc_format(db.get_snapshot_uuid_by_ec2_id, 123456) check_exc_format(db.get_ec2_instance_id_by_uuid, 'fake') check_exc_format(db.get_instance_uuid_by_ec2_id, 123456) def test_ec2_volume_create(self): vol = db.ec2_volume_create(self.ctxt, 'fake-uuid') self.assertIsNotNone(vol['id']) self.assertEqual(vol['uuid'], 'fake-uuid') def test_get_ec2_volume_id_by_uuid(self): vol = db.ec2_volume_create(self.ctxt, 'fake-uuid') vol_id = db.get_ec2_volume_id_by_uuid(self.ctxt, 'fake-uuid') self.assertEqual(vol['id'], vol_id) def test_get_volume_uuid_by_ec2_id(self): vol = db.ec2_volume_create(self.ctxt, 'fake-uuid') vol_uuid = db.get_volume_uuid_by_ec2_id(self.ctxt, vol['id']) self.assertEqual(vol_uuid, 'fake-uuid') def test_get_ec2_volume_id_by_uuid_not_found(self): self.assertRaises(exception.VolumeNotFound, db.get_ec2_volume_id_by_uuid, self.ctxt, 'uuid-not-present') def test_get_volume_uuid_by_ec2_id_not_found(self): self.assertRaises(exception.VolumeNotFound, db.get_volume_uuid_by_ec2_id, self.ctxt, 100500) def test_ec2_snapshot_create(self): snap = db.ec2_snapshot_create(self.ctxt, 'fake-uuid') self.assertIsNotNone(snap['id']) self.assertEqual(snap['uuid'], 'fake-uuid') def test_get_ec2_snapshot_id_by_uuid(self): snap = db.ec2_snapshot_create(self.ctxt, 'fake-uuid') snap_id = db.get_ec2_snapshot_id_by_uuid(self.ctxt, 'fake-uuid') self.assertEqual(snap['id'], snap_id) def test_get_snapshot_uuid_by_ec2_id(self): snap = db.ec2_snapshot_create(self.ctxt, 'fake-uuid') snap_uuid = db.get_snapshot_uuid_by_ec2_id(self.ctxt, snap['id']) self.assertEqual(snap_uuid, 'fake-uuid') def test_get_ec2_snapshot_id_by_uuid_not_found(self): self.assertRaises(exception.SnapshotNotFound, db.get_ec2_snapshot_id_by_uuid, self.ctxt, 'uuid-not-present') def test_get_snapshot_uuid_by_ec2_id_not_found(self): self.assertRaises(exception.SnapshotNotFound, db.get_snapshot_uuid_by_ec2_id, self.ctxt, 100500) def test_ec2_instance_create(self): inst = db.ec2_instance_create(self.ctxt, 'fake-uuid') self.assertIsNotNone(inst['id']) self.assertEqual(inst['uuid'], 'fake-uuid') def test_get_ec2_instance_id_by_uuid(self): inst = db.ec2_instance_create(self.ctxt, 'fake-uuid') inst_id = db.get_ec2_instance_id_by_uuid(self.ctxt, 'fake-uuid') self.assertEqual(inst['id'], inst_id) def test_get_instance_uuid_by_ec2_id(self): inst = db.ec2_instance_create(self.ctxt, 'fake-uuid') inst_uuid = db.get_instance_uuid_by_ec2_id(self.ctxt, inst['id']) self.assertEqual(inst_uuid, 'fake-uuid') def test_get_ec2_instance_id_by_uuid_not_found(self): self.assertRaises(exception.InstanceNotFound, db.get_ec2_instance_id_by_uuid, self.ctxt, 'uuid-not-present') def test_get_instance_uuid_by_ec2_id_not_found(self): self.assertRaises(exception.InstanceNotFound, db.get_instance_uuid_by_ec2_id, self.ctxt, 100500) "," def test_ec2_ids_not_found_are_printable(self): def check_exc_format(method, value): try: method(self.context, value) except exception.NotFound as exc: self.assertTrue(unicode(value) in unicode(exc)) check_exc_format(db.get_ec2_volume_id_by_uuid, 'fake') check_exc_format(db.get_volume_uuid_by_ec2_id, 123456) check_exc_format(db.get_ec2_snapshot_id_by_uuid, 'fake') check_exc_format(db.get_snapshot_uuid_by_ec2_id, 123456) check_exc_format(db.get_ec2_instance_id_by_uuid, 'fake') check_exc_format(db.get_instance_uuid_by_ec2_id, 123456) def test_get_vol_mapping_non_admin(self): ref = db.ec2_volume_create(self.context, 'fake-uuid') ec2_id = db.get_ec2_volume_id_by_uuid(self.context, 'fake-uuid') self.assertEqual(ref['id'], ec2_id) def test_get_snap_mapping_non_admin(self): ref = db.ec2_snapshot_create(self.context, 'fake-uuid') ec2_id = db.get_ec2_snapshot_id_by_uuid(self.context, 'fake-uuid') self.assertEqual(ref['id'], ec2_id) ",96,24
openstack%2Fnova~master~Icf64651dbea4d97480a218140abc6e72166713d3,openstack/nova,master,Icf64651dbea4d97480a218140abc6e72166713d3,Move test_security_group_update to SecurityGroupTestCase.,MERGED,2013-07-16 11:37:24.000000000,2013-07-17 00:03:09.000000000,2013-07-17 00:03:07.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 6172}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-07-16 11:37:24.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/75983939a09c6b769d242356ab7e3e6211270080', 'message': 'Move test_security_group_update to SecurityGroupTestCase.\n\nThere is security group update test in old mixed\nDbApiTestCase. This patch moves this test to its\nown test case SecurityGroupTestCase.\n\nblueprint db-api-tests\n\nChange-Id: Icf64651dbea4d97480a218140abc6e72166713d3\n'}]",3,37227,75983939a09c6b769d242356ab7e3e6211270080,10,6,1,7711,,,0,"Move test_security_group_update to SecurityGroupTestCase.

There is security group update test in old mixed
DbApiTestCase. This patch moves this test to its
own test case SecurityGroupTestCase.

blueprint db-api-tests

Change-Id: Icf64651dbea4d97480a218140abc6e72166713d3
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/37227/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,75983939a09c6b769d242356ab7e3e6211270080,bp/db-api-tests," def test_security_group_update(self): security_group = self._create_security_group({}) new_values = { 'name': 'sec_group1', 'description': 'sec_group_descr1', 'user_id': 'fake_user1', 'project_id': 'fake_proj1', } updated_group = db.security_group_update(self.ctxt, security_group['id'], new_values) for key, value in new_values.iteritems(): self.assertEqual(updated_group[key], value) "," def test_security_group_update(self): ctxt = context.get_admin_context() values = {'security_group': {'tenant_id': '123', 'name': 'test', 'description': 'test-description'}} sg = db.security_group_create(ctxt, values) values['security_group']['name'] = 'test_name' values['security_group']['description'] = 'test_desc' sg = db.security_group_update(ctxt, sg['id'], values) self.assertNotEqual(None, sg) self.assertEqual(sg['security_group']['name'], 'test_name') self.assertEqual(sg['security_group']['description'], 'test_desc') ",14,13
openstack%2Fnova~master~Ie79d31694d9c72d9d6f43772aeadff200987646c,openstack/nova,master,Ie79d31694d9c72d9d6f43772aeadff200987646c,Move bw_usage_* tests in test_db_api to own test case.,MERGED,2013-07-16 10:07:17.000000000,2013-07-17 00:02:48.000000000,2013-07-17 00:02:45.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-07-16 10:07:17.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5131ccb57a6c8f06a455e281a7066d28caec6aad', 'message': 'Move bw_usage_* tests in test_db_api to own test case.\n\nThere is bw_usage_* tests in old mixed DbApiTestCase.\nThis patch moves them to its own test case BwUsageTestCase.\n\nMissing test_bw_usage_get added.\n\nblueprint db-api-tests\n\nChange-Id: Ie79d31694d9c72d9d6f43772aeadff200987646c\n'}]",0,37206,5131ccb57a6c8f06a455e281a7066d28caec6aad,8,5,1,7711,,,0,"Move bw_usage_* tests in test_db_api to own test case.

There is bw_usage_* tests in old mixed DbApiTestCase.
This patch moves them to its own test case BwUsageTestCase.

Missing test_bw_usage_get added.

blueprint db-api-tests

Change-Id: Ie79d31694d9c72d9d6f43772aeadff200987646c
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/37206/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,5131ccb57a6c8f06a455e281a7066d28caec6aad,bp/db-api-tests,"class BwUsageTestCase(test.TestCase, ModelsObjectComparatorMixin): _ignored_keys = ['id', 'deleted', 'deleted_at', 'created_at', 'updated_at'] def setUp(self): super(BwUsageTestCase, self).setUp() self.ctxt = context.get_admin_context() self.useFixture(test.TimeOverride()) def test_bw_usage_get_by_uuids(self): now = timeutils.utcnow() start_period = now - datetime.timedelta(seconds=10) uuid3_refreshed = now - datetime.timedelta(seconds=5) expected_bw_usages = [{'uuid': 'fake_uuid1', 'mac': 'fake_mac1', 'start_period': start_period, 'bw_in': 100, 'bw_out': 200, 'last_ctr_in': 12345, 'last_ctr_out': 67890, 'last_refreshed': now}, {'uuid': 'fake_uuid2', 'mac': 'fake_mac2', 'start_period': start_period, 'bw_in': 200, 'bw_out': 300, 'last_ctr_in': 22345, 'last_ctr_out': 77890, 'last_refreshed': now}, {'uuid': 'fake_uuid3', 'mac': 'fake_mac3', 'start_period': start_period, 'bw_in': 400, 'bw_out': 500, 'last_ctr_in': 32345, 'last_ctr_out': 87890, 'last_refreshed': uuid3_refreshed}] bw_usages = db.bw_usage_get_by_uuids(self.ctxt, ['fake_uuid1', 'fake_uuid2'], start_period) # No matches self.assertEqual(len(bw_usages), 0) # Add 3 entries db.bw_usage_update(self.ctxt, 'fake_uuid1', 'fake_mac1', start_period, 100, 200, 12345, 67890) db.bw_usage_update(self.ctxt, 'fake_uuid2', 'fake_mac2', start_period, 100, 200, 42, 42) # Test explicit refreshed time db.bw_usage_update(self.ctxt, 'fake_uuid3', 'fake_mac3', start_period, 400, 500, 32345, 87890, last_refreshed=uuid3_refreshed) # Update 2nd entry db.bw_usage_update(self.ctxt, 'fake_uuid2', 'fake_mac2', start_period, 200, 300, 22345, 77890) bw_usages = db.bw_usage_get_by_uuids(self.ctxt, ['fake_uuid1', 'fake_uuid2', 'fake_uuid3'], start_period) self.assertEqual(len(bw_usages), 3) for i, expected in enumerate(expected_bw_usages): self._assertEqualObjects(bw_usages[i], expected, ignored_keys=self._ignored_keys) def test_bw_usage_get(self): now = timeutils.utcnow() start_period = now - datetime.timedelta(seconds=10) expected_bw_usage = {'uuid': 'fake_uuid1', 'mac': 'fake_mac1', 'start_period': start_period, 'bw_in': 100, 'bw_out': 200, 'last_ctr_in': 12345, 'last_ctr_out': 67890, 'last_refreshed': now} bw_usage = db.bw_usage_get(self.ctxt, 'fake_uuid1', start_period, 'fake_mac1') self.assertIsNone(bw_usage) db.bw_usage_update(self.ctxt, 'fake_uuid1', 'fake_mac1', start_period, 100, 200, 12345, 67890) bw_usage = db.bw_usage_get(self.ctxt, 'fake_uuid1', start_period, 'fake_mac1') self._assertEqualObjects(bw_usage, expected_bw_usage, ignored_keys=self._ignored_keys) "," def test_bw_usage_calls(self): ctxt = context.get_admin_context() now = timeutils.utcnow() timeutils.set_time_override(now) start_period = now - datetime.timedelta(seconds=10) uuid3_refreshed = now - datetime.timedelta(seconds=5) expected_bw_usages = [{'uuid': 'fake_uuid1', 'mac': 'fake_mac1', 'start_period': start_period, 'bw_in': 100, 'bw_out': 200, 'last_ctr_in': 12345, 'last_ctr_out': 67890, 'last_refreshed': now}, {'uuid': 'fake_uuid2', 'mac': 'fake_mac2', 'start_period': start_period, 'bw_in': 200, 'bw_out': 300, 'last_ctr_in': 22345, 'last_ctr_out': 77890, 'last_refreshed': now}, {'uuid': 'fake_uuid3', 'mac': 'fake_mac3', 'start_period': start_period, 'bw_in': 400, 'bw_out': 500, 'last_ctr_in': 32345, 'last_ctr_out': 87890, 'last_refreshed': uuid3_refreshed}] def _compare(bw_usage, expected): for key, value in expected.items(): self.assertEqual(bw_usage[key], value) bw_usages = db.bw_usage_get_by_uuids(ctxt, ['fake_uuid1', 'fake_uuid2'], start_period) # No matches self.assertEqual(len(bw_usages), 0) # Add 3 entries db.bw_usage_update(ctxt, 'fake_uuid1', 'fake_mac1', start_period, 100, 200, 12345, 67890) db.bw_usage_update(ctxt, 'fake_uuid2', 'fake_mac2', start_period, 100, 200, 42, 42) # Test explicit refreshed time db.bw_usage_update(ctxt, 'fake_uuid3', 'fake_mac3', start_period, 400, 500, 32345, 87890, last_refreshed=uuid3_refreshed) # Update 2nd entry db.bw_usage_update(ctxt, 'fake_uuid2', 'fake_mac2', start_period, 200, 300, 22345, 77890) bw_usages = db.bw_usage_get_by_uuids(ctxt, ['fake_uuid1', 'fake_uuid2', 'fake_uuid3'], start_period) self.assertEqual(len(bw_usages), 3) _compare(bw_usages[0], expected_bw_usages[0]) _compare(bw_usages[1], expected_bw_usages[1]) _compare(bw_usages[2], expected_bw_usages[2]) timeutils.clear_time_override() ",95,66
openstack%2Frequirements~master~I6df0624cbcc6b08030d48d905603463a8eaafdc7,openstack/requirements,master,I6df0624cbcc6b08030d48d905603463a8eaafdc7,Add support for Keystone V3 Auth in Horizon.,MERGED,2013-07-09 21:23:15.000000000,2013-07-16 23:59:01.000000000,2013-07-16 21:28:06.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4}, {'_account_id': 24}, {'_account_id': 1816}, {'_account_id': 1941}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-07-09 21:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/b9d63ad3c1fa483cab968b2c77584e9e5e743d26', 'message': 'Add support for Keystone V3 Auth in Horizon.\n\nSet the minimum version required to run Horizon with\nKeystone V3 Auth.\n\nChange-Id: I6df0624cbcc6b08030d48d905603463a8eaafdc7\nImplements: blueprint login-domain-support\n'}, {'number': 2, 'created': '2013-07-10 21:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/733b7be5a5f1819b36a2a21e5fe12e810b1c644a', 'message': 'Add support for Keystone V3 Auth in Horizon.\n\nSet the minimum version required to run Horizon with\nKeystone V3 Auth.\n\nChange-Id: I6df0624cbcc6b08030d48d905603463a8eaafdc7\nImplements: blueprint login-domain-support\n'}, {'number': 3, 'created': '2013-07-16 21:08:39.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d5e21fb99e4a8526dc1d30db382f6e2469e78963', 'message': 'Add support for Keystone V3 Auth in Horizon.\n\nSet the minimum version required to run Horizon with\nKeystone V3 Auth.\n\nChange-Id: I6df0624cbcc6b08030d48d905603463a8eaafdc7\nImplements: blueprint login-domain-support\n'}]",0,36343,d5e21fb99e4a8526dc1d30db382f6e2469e78963,17,7,3,1941,,,0,"Add support for Keystone V3 Auth in Horizon.

Set the minimum version required to run Horizon with
Keystone V3 Auth.

Change-Id: I6df0624cbcc6b08030d48d905603463a8eaafdc7
Implements: blueprint login-domain-support
",git fetch https://review.opendev.org/openstack/requirements refs/changes/43/36343/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b9d63ad3c1fa483cab968b2c77584e9e5e743d26,bp/login-domain-support,"django_openstack_auth>=1.1.0python-keystoneclient>=0.3.0,<0.4","django_openstack_auth>=1.0.11python-keystoneclient>=0.2.1,<0.4",2,2
openstack%2Ftripleo-image-elements~master~I7808055ff978ace362c56a37cd09e85b29ad013c,openstack/tripleo-image-elements,master,I7808055ff978ace362c56a37cd09e85b29ad013c,Configure polkit to allow nova to use libvirt,MERGED,2013-07-16 23:51:02.000000000,2013-07-16 23:51:02.000000000,2013-07-16 23:51:02.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-16 23:51:02.000000000', 'files': ['elements/nova-kvm/install.d/80-nova-kvm'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/78dcaeb82a281e5e3bd9e14f8281c86592da692f', 'message': 'Configure polkit to allow nova to use libvirt\n\nChange-Id: I7808055ff978ace362c56a37cd09e85b29ad013c\n'}]",0,37352,78dcaeb82a281e5e3bd9e14f8281c86592da692f,5,2,1,1926,,,0,"Configure polkit to allow nova to use libvirt

Change-Id: I7808055ff978ace362c56a37cd09e85b29ad013c
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/52/37352/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/nova-kvm/install.d/80-nova-kvm'],1,78dcaeb82a281e5e3bd9e14f8281c86592da692f,fedora-polkit," # On Fedora configure polkit to allow nova to use libvirt if [ -e /etc/polkit-1/rules.d ] ; then cat - <<-EOF > /etc/polkit-1/rules.d/50-nova.rules // openstack-nova libvirt management permissions polkit.addRule(function(action, subject) { if (action.id == ""org.libvirt.unix.manage"" && subject.user == ""nova"") { return polkit.Result.YES; } }); EOF fi",,13,0
openstack%2Ftripleo-image-elements~master~If2af136caaa28a6553f3f0579c91aa53a6dfb74e,openstack/tripleo-image-elements,master,If2af136caaa28a6553f3f0579c91aa53a6dfb74e,Fedora firewall changes,MERGED,2013-07-16 23:49:59.000000000,2013-07-16 23:49:59.000000000,2013-07-16 23:49:59.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-16 23:49:59.000000000', 'files': ['elements/boot-stack/first-boot.d/97-fedora-iptables'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f3e30589d16e087452e2a4b0f22e4f5426260618', 'message': ""Fedora firewall changes\n\nAllow access to\n - Metadata API (8775)\n - Neutron API  (9696)\n - AMQP         (5672)\n\nDeny access to dhcp, specific MAC's are granted access by\nelements/nova-baremetal/bin/filter-bootps\n\nChange-Id: If2af136caaa28a6553f3f0579c91aa53a6dfb74e\n""}]",2,37351,f3e30589d16e087452e2a4b0f22e4f5426260618,6,2,1,1926,,,0,"Fedora firewall changes

Allow access to
 - Metadata API (8775)
 - Neutron API  (9696)
 - AMQP         (5672)

Deny access to dhcp, specific MAC's are granted access by
elements/nova-baremetal/bin/filter-bootps

Change-Id: If2af136caaa28a6553f3f0579c91aa53a6dfb74e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/51/37351/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/boot-stack/first-boot.d/97-fedora-iptables'],1,f3e30589d16e087452e2a4b0f22e4f5426260618,fedora-iptables, iptables -I INPUT -p tcp --dport 8775 -j ACCEPT iptables -I INPUT -p tcp --dport 9696 -j ACCEPT # AMQP iptables -I INPUT -p tcp --dport 5672 -j ACCEPT, iptables -I INPUT -m udp -p udp --dport 67 -j ACCEPT,5,1
openstack%2Fzaqar~master~I347e764ed0e965f17aa49f3e80f2f100ba8ba495,openstack/zaqar,master,I347e764ed0e965f17aa49f3e80f2f100ba8ba495,feat(storage): do not restrict the container type,MERGED,2013-07-16 16:20:58.000000000,2013-07-16 23:40:12.000000000,2013-07-16 23:40:12.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 6944}]","[{'number': 1, 'created': '2013-07-16 16:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/33cb50fa4787d42ede28765d72e4a69f126244d9', 'message': 'feat(storage): do not restrict the container type\n\nChange-Id: I347e764ed0e965f17aa49f3e80f2f100ba8ba495\n'}, {'number': 2, 'created': '2013-07-16 18:22:31.000000000', 'files': ['marconi/storage/sqlite/messages.py', 'marconi/storage/base.py', 'marconi/storage/mongodb/messages.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/adf9a2e7142ac20e6e4f188748945d2275d87722', 'message': 'feat(storage): do not restrict the container type\n\nIn Python, container is a concept, not a specific type.  The original\nimplementation limit the container to list, while this change allow you\nto use other containers, like tuple, to supply as a sequence of the\nmessage IDs.\n\nChange-Id: I347e764ed0e965f17aa49f3e80f2f100ba8ba495\n'}]",3,37281,adf9a2e7142ac20e6e4f188748945d2275d87722,12,5,2,6943,,,0,"feat(storage): do not restrict the container type

In Python, container is a concept, not a specific type.  The original
implementation limit the container to list, while this change allow you
to use other containers, like tuple, to supply as a sequence of the
message IDs.

Change-Id: I347e764ed0e965f17aa49f3e80f2f100ba8ba495
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/81/37281/2 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/storage/sqlite/messages.py', 'marconi/storage/base.py', 'marconi/storage/mongodb/messages.py']",3,33cb50fa4787d42ede28765d72e4a69f126244d9,bulk-message-deletion,"import six if isinstance(message_ids, six.string_types):"," if not isinstance(message_ids, list):",7,4
openstack%2Fzaqar~master~Icac834b4b621dac92afdc5f8e6c8fe609f5f300e,openstack/zaqar,master,Icac834b4b621dac92afdc5f8e6c8fe609f5f300e,Cleanup PATCH Claim Tests,MERGED,2013-07-15 15:41:54.000000000,2013-07-16 23:38:54.000000000,2013-07-16 23:38:53.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 7044}]","[{'number': 1, 'created': '2013-07-15 15:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e1af3267a6961e88ebd442ae1d7e7528cfefbb55', 'message': 'Cleanup PATCH Claim Tests\n\nThis makes the PATCH claim tests more explicit.\n\nBUG: 1200664\nChange-Id: Icac834b4b621dac92afdc5f8e6c8fe609f5f300e\n'}, {'number': 2, 'created': '2013-07-15 23:08:46.000000000', 'files': ['marconi/tests/system/claim/claimfnlib.py', 'marconi/tests/system/claim/test_claims.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/18bed416348ecfecfdf3cbde40e9142f9f25e72f', 'message': 'Cleanup PATCH Claim Tests\n\nThis makes the PATCH claim tests more explicit.\n\nTests: bug#1200664\nChange-Id: Icac834b4b621dac92afdc5f8e6c8fe609f5f300e\n'}]",2,37075,18bed416348ecfecfdf3cbde40e9142f9f25e72f,9,5,2,6971,,,0,"Cleanup PATCH Claim Tests

This makes the PATCH claim tests more explicit.

Tests: bug#1200664
Change-Id: Icac834b4b621dac92afdc5f8e6c8fe609f5f300e
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/75/37075/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/tests/system/claim/claimfnlib.py', 'marconi/tests/system/claim/test_claims.py']",2,e1af3267a6961e88ebd442ae1d7e7528cfefbb55,bug/1200664," doc = '{""ttl"": 300, ""grace"": 400}' #Patch Claim claim_location = result.headers['Location'] url = self.cfg.base_server + claim_location doc_updated = '{""ttl"": 300}' result = http.patch(url, self.header, doc_updated) self.assertEqual(result.status_code, 204) #Verify that the Patch operation extended the TTL test_result_flag = claimfnlib.verify_patch_claim(url, self.header, 300) doc = '{""ttl"": 300}' #Get Claim & Message Locations. claim_location = result.headers['Location'] url = self.cfg.base_server + message_location #Delete Expired Claim. url = self.cfg.base_server + claim_location result = http.delete(url, self.header) self.assertEqual(result.status_code, 204) "," doc = '{""ttl"": 300, ""grace"": 100}' #Update Claim & Verify the patch test_result_flag = claimfnlib.patch_claim( result.headers, result.text) doc = '{""ttl"": 300, ""grace"": 100}' #Create url, using message location from claim response. url = self.cfg.base_server + message_location",21,36
openstack%2Fglance~master~I845646fde22e18be27929b5ec70ef8041b6fa733,openstack/glance,master,I845646fde22e18be27929b5ec70ef8041b6fa733,Add/remove/replace locations from an image,MERGED,2013-07-01 13:37:16.000000000,2013-07-16 23:24:06.000000000,2013-07-14 01:17:59.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6159}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-01 13:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/371c265fe74603a6580a3e9d2291ce5d07421615', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2013-07-02 05:11:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/49f48e7d3bcd30996bd5d24c9daf682a5acfc134', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 3, 'created': '2013-07-02 10:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/69711a9c53ecd85893e65e582d67f08baf494fc7', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 4, 'created': '2013-07-03 08:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0f1656da340f3a0d9a2331953b84bbfb05313d6f', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 5, 'created': '2013-07-05 04:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5385a1e93067c5c0f5cb188aae71644d391b5992', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 6, 'created': '2013-07-08 08:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9de6a53b418e13165bb22c762bd101ea5774290b', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 7, 'created': '2013-07-08 08:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e461316074415b84e9af7f23011ae2d16a790a15', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 8, 'created': '2013-07-09 03:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7a679e0abaf084fea64d0b10b31b635bf9656a22', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 9, 'created': '2013-07-09 08:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/14624e8042494f00073d14155596d200f6f3847e', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 10, 'created': '2013-07-09 13:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/178f6a5ad8871cc66ed1372e4bd4e1183e0faf64', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 11, 'created': '2013-07-10 19:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d80c6c565180c058f91293796b119689f10d0dac', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 12, 'created': '2013-07-11 07:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0bb3943b7dd960b04411eedd6001a3edfa5cfa80', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 13, 'created': '2013-07-12 05:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d4ae54c4d1c5881913e78f4b207bc2ea800ffe2e', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"", ""value"": ""scheme3://path3""}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"", ""value"": ""scheme4://path4""}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": [""scheme5://path5"",\n""scheme6://path6""]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 14, 'created': '2013-07-13 08:52:45.000000000', 'files': ['glance/store/__init__.py', 'glance/api/v2/images.py', 'glance/tests/unit/utils.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/tests/unit/test_store_image.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/1e40cf967f671392d79f5368ad277a6a373d7040', 'message': 'Add/remove/replace locations from an image\n\nThis patch modifies the PATCH /v2/images/{id} API call. Clients can add,\nremove and replace locations from the set of multiple locations\nassociated with a given image ID in the following way:\n\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/-"",\n  ""value"": {""url"": ""scheme3://path3"", ""metadata"": {}}}]\nPATCH /images/1234\n[{""op"": ""add"", ""path"": ""/locations/1"",\n  ""value"": {""url"": ""scheme4://path4"", ""metadata"": {}}}]\nPATCH /images/1234\n[{""op"": ""remove"", ""path"": ""/locations/2""}]\nPATCH /images/1234\n[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]\nPATCH /images/5678\n[{""op"": ""replace"", ""path"": ""/locations"",\n  ""value"": [{""url"": ""scheme5://path5"", ""metadata"": {}},\n            {""url"": ""scheme6://path6"", ""metadata"": {}}]}]\n\nGlance will check location correctness when client adding, and will\nremove the image content from the store when client remove a location.\n\nImplement bp: multiple-image-locations\ndocimpact\n\nChange-Id: I845646fde22e18be27929b5ec70ef8041b6fa733\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}]",47,35134,1e40cf967f671392d79f5368ad277a6a373d7040,85,8,14,6549,,,0,"Add/remove/replace locations from an image

This patch modifies the PATCH /v2/images/{id} API call. Clients can add,
remove and replace locations from the set of multiple locations
associated with a given image ID in the following way:

PATCH /images/1234
[{""op"": ""add"", ""path"": ""/locations/-"",
  ""value"": {""url"": ""scheme3://path3"", ""metadata"": {}}}]
PATCH /images/1234
[{""op"": ""add"", ""path"": ""/locations/1"",
  ""value"": {""url"": ""scheme4://path4"", ""metadata"": {}}}]
PATCH /images/1234
[{""op"": ""remove"", ""path"": ""/locations/2""}]
PATCH /images/1234
[{""op"": ""replace"", ""path"": ""/locations"", ""value"": []}]
PATCH /images/5678
[{""op"": ""replace"", ""path"": ""/locations"",
  ""value"": [{""url"": ""scheme5://path5"", ""metadata"": {}},
            {""url"": ""scheme6://path6"", ""metadata"": {}}]}]

Glance will check location correctness when client adding, and will
remove the image content from the store when client remove a location.

Implement bp: multiple-image-locations
docimpact

Change-Id: I845646fde22e18be27929b5ec70ef8041b6fa733
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/34/35134/13 && git format-patch -1 --stdout FETCH_HEAD,"['glance/store/__init__.py', 'glance/api/policy.py', 'glance/api/v2/images.py', 'glance/tests/functional/v2/test_schemas.py', 'glance/tests/unit/v2/test_schemas_resource.py', 'glance/tests/unit/v2/test_images_resource.py']",6,371c265fe74603a6580a3e9d2291ce5d07421615,," changes = [{'op': 'replace', 'path': ['name'], 'value': 'fedora'}] {'op': 'replace', 'path': ['tags'], 'value': ['king', 'kong']}, {'op': 'replace', 'path': ['foo'], 'value': 'baz'}, {'op': 'add', 'path': ['murphy'], 'value': 'brown'}, changes = [{'op': 'add', 'path': ['name'], 'value': 'fedora'}] changes = [{'op': 'remove', 'path': ['name']}] {'op': 'remove', 'path': ['snitch']}, {'op': 'replace', 'path': ['min_ram'], 'value': 128}, {'op': 'replace', 'path': ['foo'], 'value': 'baz'}, {'op': 'remove', 'path': ['snitch']}, {'op': 'add', 'path': ['kb'], 'value': 'dvorak'}, {'op': 'add', 'path': ['foo'], 'value': 'baz'}, {'op': 'remove', 'path': ['foo']}, {'op': 'replace', 'path': ['tags'], 'value': ['ping', 'ping']}, changes = [{'op': 'replace', 'path': ['name'], 'value': 'image-2'}] changes = [{'op': 'replace', 'path': ['visibility'], 'value': 'public'}] changes = [{'op': 'replace', 'path': ['visibility'], 'value': 'private'}] {'op': 'replace', 'path': ['name'], 'value': 'fedora'}, {'op': 'replace', 'path': ['tags'], 'value': ['king', 'kong']}, {'op': 'replace', 'path': ['foo'], 'value': 'bar'}, {'op': 'add', 'path': ['bebim'], 'value': 'bap'}, {'op': 'remove', 'path': ['sparks']}, {'op': 'replace', 'path': ['name'], 'value': 'fedora'}, {'op': 'replace', 'path': ['tags'], 'value': ['king', 'kong']}, {'op': 'replace', 'path': ['foo'], 'value': 'bar'}, {'op': 'add', 'path': ['bebim'], 'value': 'bap'}, {'op': 'remove', 'path': ['sparks']}, {'op': 'replace', 'path': ['id'], 'value': UUID1}, {'op': 'replace', 'path': ['name'], 'value': 'fedora'}, {'op': 'replace', 'path': ['visibility'], 'value': 'public'}, {'op': 'replace', 'path': ['tags'], 'value': ['king', 'kong']}, {'op': 'replace', 'path': ['protected'], 'value': True}, {'op': 'replace', 'path': ['container_format'], 'value': 'bare'}, {'op': 'replace', 'path': ['disk_format'], 'value': 'raw'}, {'op': 'replace', 'path': ['min_ram'], 'value': 128}, {'op': 'replace', 'path': ['min_disk'], 'value': 10}, '///twoslash', '/tw/ /oslash', body = [{'op': 'replace', 'path': '[%s]' % key, 'value': 'dummy'}] '/keywith~1slash': [u'keywith/slash'], '/keywith~0tilde': [u'keywith~tilde'], '/tricky~01': [u'tricky~1'], {'op': 'add', 'path': ['pants'], 'value': 'off'}, change = {'op': 'add', 'path': ['foo'], 'value': 'bar'}"," changes = [{'op': 'replace', 'path': 'name', 'value': 'fedora'}] {'op': 'replace', 'path': 'tags', 'value': ['king', 'kong']}, {'op': 'replace', 'path': 'foo', 'value': 'baz'}, {'op': 'add', 'path': 'murphy', 'value': 'brown'}, changes = [{'op': 'add', 'path': 'name', 'value': 'fedora'}] changes = [{'op': 'remove', 'path': 'name'}] {'op': 'remove', 'path': 'snitch'}, {'op': 'replace', 'path': 'min_ram', 'value': 128}, {'op': 'replace', 'path': 'foo', 'value': 'baz'}, {'op': 'remove', 'path': 'snitch'}, {'op': 'add', 'path': 'kb', 'value': 'dvorak'}, {'op': 'add', 'path': 'foo', 'value': 'baz'}, {'op': 'remove', 'path': 'foo'}, {'op': 'replace', 'path': 'tags', 'value': ['ping', 'ping']}, changes = [{'op': 'replace', 'path': 'name', 'value': 'image-2'}] changes = [{'op': 'replace', 'path': 'visibility', 'value': 'public'}] changes = [{'op': 'replace', 'path': 'visibility', 'value': 'private'}] {'op': 'replace', 'path': 'name', 'value': 'fedora'}, {'op': 'replace', 'path': 'tags', 'value': ['king', 'kong']}, {'op': 'replace', 'path': 'foo', 'value': 'bar'}, {'op': 'add', 'path': 'bebim', 'value': 'bap'}, {'op': 'remove', 'path': 'sparks'}, {'op': 'replace', 'path': 'name', 'value': 'fedora'}, {'op': 'replace', 'path': 'tags', 'value': ['king', 'kong']}, {'op': 'replace', 'path': 'foo', 'value': 'bar'}, {'op': 'add', 'path': 'bebim', 'value': 'bap'}, {'op': 'remove', 'path': 'sparks'}, {'op': 'replace', 'path': 'id', 'value': UUID1}, {'op': 'replace', 'path': 'name', 'value': 'fedora'}, {'op': 'replace', 'path': 'visibility', 'value': 'public'}, {'op': 'replace', 'path': 'tags', 'value': ['king', 'kong']}, {'op': 'replace', 'path': 'protected', 'value': True}, {'op': 'replace', 'path': 'container_format', 'value': 'bare'}, {'op': 'replace', 'path': 'disk_format', 'value': 'raw'}, {'op': 'replace', 'path': 'min_ram', 'value': 128}, {'op': 'replace', 'path': 'min_disk', 'value': 10}, 'locations': ['/a/b/c/d'], '//twoslash', body = [{'op': 'replace', 'path': '%s' % key, 'value': 'dummy'}] '/keywith~1slash': 'keywith/slash', '/keywith~0tilde': 'keywith~tilde', '/tricky~01': 'tricky~1', {'op': 'add', 'path': 'pants', 'value': 'off'}, change = {'op': 'add', 'path': 'foo', 'value': 'bar'}",243,103
openstack%2Fpython-heatclient~master~Ie8d72c222a992ee0048897d040e8bc88fcf51760,openstack/python-heatclient,master,Ie8d72c222a992ee0048897d040e8bc88fcf51760,Display yaml format for stack deployed via hot template,MERGED,2013-07-16 05:56:14.000000000,2013-07-16 23:14:03.000000000,2013-07-16 23:14:03.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-07-16 05:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/d3a6cafbcb5c769c3dcaf67e2a7f816202f60bb4', 'message': 'Show yaml template for hot template deployed stack\n\nDetermine hot template and display yaml format for it, display json\nformat for others.\n\nChange-Id: Ie8d72c222a992ee0048897d040e8bc88fcf51760\nFixes: bug #1201482\n'}, {'number': 2, 'created': '2013-07-16 06:02:33.000000000', 'files': ['heatclient/tests/test_shell.py', 'heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/e14758686f71932c5fe5c884bdf7344a1f339d0a', 'message': 'Display yaml format for stack deployed via hot template\n\nDetermine hot template and display yaml format for it, display json\nformat for others.\n\nChange-Id: Ie8d72c222a992ee0048897d040e8bc88fcf51760\nFixes: bug #1201482\n'}]",0,37175,e14758686f71932c5fe5c884bdf7344a1f339d0a,11,5,2,7761,,,0,"Display yaml format for stack deployed via hot template

Determine hot template and display yaml format for it, display json
format for others.

Change-Id: Ie8d72c222a992ee0048897d040e8bc88fcf51760
Fixes: bug #1201482
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/75/37175/2 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/test_shell.py', 'heatclient/v1/shell.py']",2,d3a6cafbcb5c769c3dcaf67e2a7f816202f60bb4,bug/1201482," if 'heat_template_version' in template: print yaml.safe_dump(template, indent=2) else: print json.dumps(template, indent=2)"," print json.dumps(template, indent=2)",57,1
openstack%2Ftripleo-image-elements~master~I2a62f48b307f09aa23603d97066e6a1c9c76135f,openstack/tripleo-image-elements,master,I2a62f48b307f09aa23603d97066e6a1c9c76135f,Fix nova-bm-dnsmasq.service,MERGED,2013-07-16 23:13:29.000000000,2013-07-16 23:13:29.000000000,2013-07-16 23:13:29.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-16 23:13:29.000000000', 'files': ['elements/nova-baremetal/install.d/81-nova-bm-services'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ac2f4167fa7ae763a48a47c1c2c54b9b55c12bcc', 'message': 'Fix nova-bm-dnsmasq.service\n\n[/usr/lib/systemd/system/nova-bm-dnsmasq.service:9] Unknown lvalue\n\'-ExecStartPre\' in section \'Service\'\n\nAdding a - to ExecStartPre causes systemd to ignore\nthe exit code but the ""-"" was in the wrong place.\n\nChange-Id: I2a62f48b307f09aa23603d97066e6a1c9c76135f\n'}]",0,37343,ac2f4167fa7ae763a48a47c1c2c54b9b55c12bcc,5,2,1,1926,,,0,"Fix nova-bm-dnsmasq.service

[/usr/lib/systemd/system/nova-bm-dnsmasq.service:9] Unknown lvalue
'-ExecStartPre' in section 'Service'

Adding a - to ExecStartPre causes systemd to ignore
the exit code but the ""-"" was in the wrong place.

Change-Id: I2a62f48b307f09aa23603d97066e6a1c9c76135f
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/43/37343/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/nova-baremetal/install.d/81-nova-bm-services'],1,ac2f4167fa7ae763a48a47c1c2c54b9b55c12bcc,move-minus,ExecStartPre=-/bin/killall -9 dnsmasq,-ExecStartPre=/bin/killall -9 dnsmasq,1,1
openstack%2Fdiskimage-builder~master~I52723d4d14c21b1787b4c7e0dd21a09cdbdae0d1,openstack/diskimage-builder,master,I52723d4d14c21b1787b4c7e0dd21a09cdbdae0d1,Fedora 19 GRUB,MERGED,2013-07-16 23:13:28.000000000,2013-07-16 23:13:28.000000000,2013-07-16 23:13:28.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-07-16 23:13:28.000000000', 'files': ['elements/base/finalise.d/52-force-text-mode-console'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/64d7b8d4cb3d3fafac27acbcefca5189fe9ef012', 'message': ""Fedora 19 GRUB\n\nIn the 52-force-text-mode-console hook, gracefully exit when the\n/boot/grub2 directory does not exist on the Fedora 19 cloud image\nfilesystem. By default the Fedora 19 cloud image is using extlinux to boot\nthe image instead of GRUB. The decision was taken because GRUB is quite\nbig (would pull in ~30MB of dependencies) and there's very little benefit\nin using it because cloud images don't need to cover all the corner cases.\n\nChange-Id: I52723d4d14c21b1787b4c7e0dd21a09cdbdae0d1\n""}]",0,37291,64d7b8d4cb3d3fafac27acbcefca5189fe9ef012,5,2,1,6773,,,0,"Fedora 19 GRUB

In the 52-force-text-mode-console hook, gracefully exit when the
/boot/grub2 directory does not exist on the Fedora 19 cloud image
filesystem. By default the Fedora 19 cloud image is using extlinux to boot
the image instead of GRUB. The decision was taken because GRUB is quite
big (would pull in ~30MB of dependencies) and there's very little benefit
in using it because cloud images don't need to cover all the corner cases.

Change-Id: I52723d4d14c21b1787b4c7e0dd21a09cdbdae0d1
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/91/37291/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/base/finalise.d/52-force-text-mode-console'],1,64d7b8d4cb3d3fafac27acbcefca5189fe9ef012,f19-grub, # By default the F19 cloud image is using extlinux to boot the image [[ ! -d /boot/grub2 ]] && exit 0 ,,3,0
openstack%2Fneutron~master~I70aaf6e02fee461fa97dc254db906d9efa173669,openstack/neutron,master,I70aaf6e02fee461fa97dc254db906d9efa173669,Limit min<=max port check to TCP/UDP in secgroup rule,MERGED,2013-07-06 16:06:39.000000000,2013-07-16 22:58:32.000000000,2013-07-16 22:58:31.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2592}]","[{'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dbca6d639ca42a27cc956f5bc1b3e32dc51b2ee0', 'message': 'Limit min<=max port check to TCP/UDP in secgroup rule\n\nicmp_type and icmp_code are mapped to port_min_range and port_max_range\nrespectively. For ICMP there is no constraint between type and code.\nThus port range min<=max check should be enforced only for TCP and UDP.\n\nAlso makes sure that ICMP type/code are 0 to 255 (both inclusive).\nPreviously a value with 0 to 65535 were accepted for ICMP type/code.\n\nFixes bug 1197760\nFixes bug 1197769\n\nChange-Id: I70aaf6e02fee461fa97dc254db906d9efa173669\n'}, {'number': 2, 'created': '2013-07-08 13:42:35.000000000', 'files': ['neutron/tests/unit/test_extension_security_group.py', 'neutron/db/securitygroups_db.py', 'neutron/common/constants.py', 'neutron/extensions/securitygroup.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/24e6ef332d11de4dc0d08ecf824ad216b2b6500c', 'message': 'Limit min<=max port check to TCP/UDP in secgroup rule\n\nicmp_type and icmp_code are mapped to port_min_range and port_max_range\nrespectively. For ICMP there is no constraint between type and code.\nThus port range min<=max check should be enforced only for TCP and UDP.\n\nAlso makes sure that ICMP type/code are 0 to 255 (both inclusive).\nPreviously a value with 0 to 65535 were accepted for ICMP type/code.\n\nFixes bug 1197760\nFixes bug 1197769\n\nChange-Id: I70aaf6e02fee461fa97dc254db906d9efa173669\n'}]",0,35736,24e6ef332d11de4dc0d08ecf824ad216b2b6500c,10,4,2,841,,,0,"Limit min<=max port check to TCP/UDP in secgroup rule

icmp_type and icmp_code are mapped to port_min_range and port_max_range
respectively. For ICMP there is no constraint between type and code.
Thus port range min<=max check should be enforced only for TCP and UDP.

Also makes sure that ICMP type/code are 0 to 255 (both inclusive).
Previously a value with 0 to 65535 were accepted for ICMP type/code.

Fixes bug 1197760
Fixes bug 1197769

Change-Id: I70aaf6e02fee461fa97dc254db906d9efa173669
",git fetch https://review.opendev.org/openstack/neutron refs/changes/36/35736/1 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/extensions/securitygroup.py', 'quantum/tests/unit/test_extension_security_group.py', 'quantum/common/constants.py', 'quantum/db/securitygroups_db.py']",4,dbca6d639ca42a27cc956f5bc1b3e32dc51b2ee0,bug/1197760,"from quantum.common import constantsIP_PROTOCOL_MAP = {'tcp': constants.TCP_PROTOCOL, 'udp': constants.UDP_PROTOCOL, 'icmp': constants.ICMP_PROTOCOL} def _get_ip_proto_number(self, protocol): if protocol is None: return return IP_PROTOCOL_MAP.get(protocol, protocol) def _validate_port_range(self, rule): """"""Check that port_range is valid."""""" if (rule['port_range_min'] is None and rule['port_range_max'] is None): return if not rule['protocol']: raise ext_sg.SecurityGroupProtocolRequiredWithPorts() ip_proto = self._get_ip_proto_number(rule['protocol']) if ip_proto in [constants.TCP_PROTOCOL, constants.UDP_PROTOCOL]: if (rule['port_range_min'] is not None and rule['port_range_min'] <= rule['port_range_max']): pass else: raise ext_sg.SecurityGroupInvalidPortRange() elif ip_proto == constants.ICMP_PROTOCOL: for attr, field in [('port_range_min', 'type'), ('port_range_max', 'code')]: if rule[attr] > 255: raise ext_sg.SecurityGroupInvalidIcmpValue( field=field, attr=attr, value=rule[attr]) self._validate_port_range(rule)", # Check that port_range's are valid if (rule['port_range_min'] is None and rule['port_range_max'] is None): pass elif (rule['port_range_min'] is not None and rule['port_range_min'] <= rule['port_range_max']): if not rule['protocol']: raise ext_sg.SecurityGroupProtocolRequiredWithPorts() else: raise ext_sg.SecurityGroupInvalidPortRange(),152,16
openstack%2Fpbr~master~Icfe1ed7dd256568f33487d03ba9c9be9a454c84a,openstack/pbr,master,Icfe1ed7dd256568f33487d03ba9c9be9a454c84a,Add Python 3.3 checking,MERGED,2013-07-15 17:40:22.000000000,2013-07-16 22:58:29.000000000,2013-07-16 22:58:29.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-15 17:40:22.000000000', 'files': ['test-requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/pbr/commit/5f94c7ee4a2d12609391cf1635b6d1dd016ff954', 'message': 'Add Python 3.3 checking\n\nThis adds support for a working py33 tox target.\n\nChange-Id: Icfe1ed7dd256568f33487d03ba9c9be9a454c84a\n'}]",0,37103,5f94c7ee4a2d12609391cf1635b6d1dd016ff954,7,4,1,1669,,,0,"Add Python 3.3 checking

This adds support for a working py33 tox target.

Change-Id: Icfe1ed7dd256568f33487d03ba9c9be9a454c84a
",git fetch https://review.opendev.org/openstack/pbr refs/changes/03/37103/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements-py3.txt', 'tox.ini']",2,5f94c7ee4a2d12609391cf1635b6d1dd016ff954,jd/python3,[testenv:py33] deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements-py3.txt ,,14,0
openstack%2Fnova~master~If2ea83cd317aa8897b7b6bd6b43a2067e1074e33,openstack/nova,master,If2ea83cd317aa8897b7b6bd6b43a2067e1074e33,Fix power_state lookup in confirm_resize,MERGED,2013-07-03 21:39:37.000000000,2013-07-16 22:02:10.000000000,2013-07-16 22:02:08.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 6873}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-07-03 21:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf982a67eb21fb6714a26bec31043a1bba3b82f4', 'message': ""Fix power_state lookup in confirm_resize\n\nPreviously the compute manager's confirm_resize method was trying to get\nthe current power_state of the resized/migrated instance from the\nhypervisor layer to account for a case where the user migrated from a\nstopped instance and then powered it on via the hypervisor (below\nopenstack) to test it before confirming the migration.  This doesn't\nwork in the migrate case but the confirm_resize request is serviced on\nthe source compute node, and the instance no longer lives there so\n_get_power_state results in an InstanceNotFound.  The vm_state would\nthen be set to ACTIVE even though the instance's power_state is still\nSHUTDOWN.\n\nThis patch fixes this problem by just getting the instance power_state\nfrom the database since the scenario of powering on the migrated\ninstance outside of openstack is not supported.\n\nFixes bug 1197514\n\nChange-Id: If2ea83cd317aa8897b7b6bd6b43a2067e1074e33\n""}, {'number': 2, 'created': '2013-07-03 21:41:01.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fbe792902476fe7f508204c810050157dcc99c0d', 'message': ""Fix power_state lookup in confirm_resize\n\nPreviously the compute manager's confirm_resize method was trying to get\nthe current power_state of the resized/migrated instance from the\nhypervisor layer to account for a case where the user migrated from a\nstopped instance and then powered it on via the hypervisor (below\nopenstack) to test it before confirming the migration.  This doesn't\nwork in the migrate case because the confirm_resize request is serviced\non the source compute node, and the instance no longer lives there so\n_get_power_state results in an InstanceNotFound.  The vm_state would\nthen be set to ACTIVE even though the instance's power_state is still\nSHUTDOWN.\n\nThis patch fixes this problem by just getting the instance power_state\nfrom the database since the scenario of powering on the migrated\ninstance outside of openstack is not supported.\n\nFixes bug 1197514\n\nChange-Id: If2ea83cd317aa8897b7b6bd6b43a2067e1074e33\n""}]",0,35554,fbe792902476fe7f508204c810050157dcc99c0d,12,6,2,6873,,,0,"Fix power_state lookup in confirm_resize

Previously the compute manager's confirm_resize method was trying to get
the current power_state of the resized/migrated instance from the
hypervisor layer to account for a case where the user migrated from a
stopped instance and then powered it on via the hypervisor (below
openstack) to test it before confirming the migration.  This doesn't
work in the migrate case because the confirm_resize request is serviced
on the source compute node, and the instance no longer lives there so
_get_power_state results in an InstanceNotFound.  The vm_state would
then be set to ACTIVE even though the instance's power_state is still
SHUTDOWN.

This patch fixes this problem by just getting the instance power_state
from the database since the scenario of powering on the migrated
instance outside of openstack is not supported.

Fixes bug 1197514

Change-Id: If2ea83cd317aa8897b7b6bd6b43a2067e1074e33
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/35554/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,cf982a67eb21fb6714a26bec31043a1bba3b82f4,bug/1197514," p_state = None p_state = power_state.RUNNING p_state = power_state.SHUTDOWN params = {'vm_state': old_vm_state, 'power_state': p_state} {'vm_state': old_vm_state, 'power_state': p_state}) self.assertEqual(p_state, instance['power_state'])"," params = {'vm_state': old_vm_state} {'vm_state': old_vm_state}) def fake_get_power_state(context, instance): if power_on: return power_state.RUNNING else: return power_state.SHUTDOWN self.stubs.Set(self.compute, '_get_power_state', fake_get_power_state) ",8,11
openstack%2Fhorizon~master~I47254cf9a790727102f7993d0fd107da514983df,openstack/horizon,master,I47254cf9a790727102f7993d0fd107da514983df,Enable H304 check,MERGED,2013-07-04 15:01:36.000000000,2013-07-16 22:00:42.000000000,2013-07-16 22:00:41.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1816}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 4375}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 5733}, {'_account_id': 6914}]","[{'number': 1, 'created': '2013-07-04 15:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ec594ed2bc97fd2e45e3f176469ca6c0a5d19919', 'message': 'Enable H304 check\n\nThis patch replaces relative imports with full paths and\nmakes H304 test enabled.\n\nFixes bug 1188535\n\nChange-Id: I47254cf9a790727102f7993d0fd107da514983df\n'}, {'number': 2, 'created': '2013-07-16 14:52:10.000000000', 'files': ['openstack_dashboard/dashboards/admin/groups/tables.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/views.py', 'openstack_dashboard/dashboards/admin/networks/subnets/views.py', 'openstack_dashboard/dashboards/admin/overview/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/views.py', 'openstack_dashboard/dashboards/admin/images/views.py', 'openstack_dashboard/dashboards/admin/instances/urls.py', 'openstack_dashboard/dashboards/project/stacks/urls.py', 'openstack_dashboard/dashboards/admin/hypervisors/urls.py', 'openstack_dashboard/dashboards/admin/flavors/urls.py', 'openstack_dashboard/dashboards/project/loadbalancers/tabs.py', 'openstack_dashboard/dashboards/admin/flavors/views.py', 'openstack_dashboard/dashboards/project/network_topology/urls.py', 'openstack_dashboard/dashboards/admin/domains/workflows.py', 'openstack_dashboard/dashboards/project/access_and_security/views.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/snapshots/views.py', 'openstack_dashboard/dashboards/admin/images/tests.py', 'openstack_dashboard/dashboards/project/volumes/views.py', 'openstack_dashboard/dashboards/admin/groups/tests.py', 'openstack_dashboard/dashboards/admin/roles/urls.py', 'openstack_dashboard/dashboards/project/loadbalancers/tests.py', 'openstack_dashboard/dashboards/project/volumes/urls.py', 'openstack_dashboard/dashboards/admin/info/urls.py', 'openstack_dashboard/dashboards/admin/networks/views.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/tests.py', 'openstack_dashboard/test/test_data/keystone_data.py', 'openstack_dashboard/test/test_data/exceptions.py', 'openstack_dashboard/dashboards/project/volumes/forms.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/volume_snapshots/tables.py', 'openstack_dashboard/dashboards/project/networks/tests.py', 'openstack_dashboard/dashboards/project/stacks/views.py', 'openstack_dashboard/dashboards/admin/info/tabs.py', 'openstack_dashboard/dashboards/project/networks/subnets/views.py', 'openstack_dashboard/dashboards/admin/roles/views.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/snapshots/urls.py', 'openstack_dashboard/dashboards/settings/user/urls.py', 'openstack_dashboard/dashboards/project/routers/ports/urls.py', 'openstack_dashboard/dashboards/admin/routers/urls.py', 'openstack_dashboard/dashboards/admin/volumes/urls.py', 'openstack_dashboard/dashboards/admin/routers/ports/urls.py', 'openstack_dashboard/dashboards/settings/user/views.py', 'openstack_dashboard/dashboards/admin/volumes/views.py', 'openstack_dashboard/dashboards/project/networks/ports/views.py', 'openstack_dashboard/dashboards/project/access_and_security/keypairs/views.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/tests.py', 'openstack_dashboard/dashboards/admin/groups/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/urls.py', 'openstack_dashboard/test/test_data/nova_data.py', 'openstack_dashboard/dashboards/project/access_and_security/urls.py', 'openstack_dashboard/dashboards/admin/domains/tables.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/routers/views.py', 'openstack_dashboard/dashboards/admin/projects/tests.py', 'openstack_dashboard/dashboards/project/networks/urls.py', 'openstack_dashboard/dashboards/admin/projects/tables.py', 'openstack_dashboard/dashboards/project/routers/ports/views.py', 'openstack_dashboard/dashboards/admin/domains/urls.py', 'openstack_dashboard/dashboards/admin/projects/views.py', 'horizon/browsers/__init__.py', 'openstack_dashboard/dashboards/admin/domains/tests.py', 'openstack_dashboard/dashboards/project/networks/ports/urls.py', 'openstack_dashboard/dashboards/project/stacks/tabs.py', 'openstack_dashboard/dashboards/admin/domains/views.py', 'openstack_dashboard/dashboards/admin/routers/ports/views.py', 'openstack_dashboard/dashboards/project/access_and_security/tabs.py', 'openstack_dashboard/dashboards/project/networks/views.py', 'openstack_dashboard/dashboards/settings/password/urls.py', 'openstack_dashboard/test/test_data/neutron_data.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/floating_ips/views.py', 'openstack_dashboard/dashboards/admin/users/urls.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/urls.py', 'openstack_dashboard/dashboards/admin/flavors/extras/views.py', 'openstack_dashboard/dashboards/admin/networks/ports/views.py', 'tox.ini', 'openstack_dashboard/dashboards/admin/routers/views.py', 'openstack_dashboard/dashboards/project/overview/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/keypairs/urls.py', 'openstack_dashboard/dashboards/admin/networks/urls.py', 'openstack_dashboard/test/test_data/heat_data.py', 'openstack_dashboard/dashboards/admin/projects/urls.py', 'openstack_dashboard/test/test_data/swift_data.py', 'openstack_dashboard/dashboards/project/access_and_security/floating_ips/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/api_access/urls.py', 'openstack_dashboard/dashboards/admin/flavors/extras/urls.py', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'openstack_dashboard/test/test_data/cinder_data.py', 'openstack_dashboard/dashboards/project/stacks/tests.py', 'openstack_dashboard/test/test_data/glance_data.py', 'openstack_dashboard/dashboards/admin/users/views.py', 'openstack_dashboard/dashboards/admin/groups/views.py', 'openstack_dashboard/dashboards/project/networks/subnets/urls.py', 'openstack_dashboard/dashboards/admin/info/views.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/views.py', 'openstack_dashboard/dashboards/admin/images/urls.py', 'openstack_dashboard/dashboards/project/routers/urls.py', 'openstack_dashboard/dashboards/settings/password/views.py', 'openstack_dashboard/test/test_data/utils.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3087c3486bda8b9deb87d3c7ec6ca1ef9812fe22', 'message': 'Enable H304 check\n\nThis patch replaces relative imports with full paths and\nmakes H304 test enabled.\n\nFixes bug 1188535\n\nChange-Id: I47254cf9a790727102f7993d0fd107da514983df\n'}]",2,35664,3087c3486bda8b9deb87d3c7ec6ca1ef9812fe22,28,10,2,6914,,,0,"Enable H304 check

This patch replaces relative imports with full paths and
makes H304 test enabled.

Fixes bug 1188535

Change-Id: I47254cf9a790727102f7993d0fd107da514983df
",git fetch https://review.opendev.org/openstack/horizon refs/changes/64/35664/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/groups/tables.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/views.py', 'openstack_dashboard/dashboards/admin/networks/subnets/views.py', 'openstack_dashboard/dashboards/admin/overview/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/views.py', 'openstack_dashboard/dashboards/admin/images/views.py', 'openstack_dashboard/dashboards/admin/instances/urls.py', 'openstack_dashboard/dashboards/admin/flavors/urls.py', 'openstack_dashboard/dashboards/project/loadbalancers/tabs.py', 'openstack_dashboard/dashboards/admin/flavors/views.py', 'openstack_dashboard/dashboards/project/network_topology/urls.py', 'openstack_dashboard/dashboards/admin/domains/workflows.py', 'openstack_dashboard/dashboards/project/access_and_security/floating_ips/tables.py', 'openstack_dashboard/dashboards/project/access_and_security/views.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/snapshots/views.py', 'openstack_dashboard/dashboards/admin/images/tests.py', 'openstack_dashboard/dashboards/project/volumes/views.py', 'openstack_dashboard/dashboards/admin/groups/tests.py', 'openstack_dashboard/dashboards/admin/roles/urls.py', 'openstack_dashboard/dashboards/project/loadbalancers/tests.py', 'openstack_dashboard/dashboards/project/volumes/urls.py', 'openstack_dashboard/dashboards/admin/info/urls.py', 'openstack_dashboard/test/test_data/quantum_data.py', 'openstack_dashboard/dashboards/admin/networks/views.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/tests.py', 'openstack_dashboard/test/test_data/keystone_data.py', 'openstack_dashboard/test/test_data/exceptions.py', 'openstack_dashboard/dashboards/project/volumes/forms.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/volume_snapshots/tables.py', 'openstack_dashboard/dashboards/project/networks/tests.py', 'openstack_dashboard/dashboards/admin/info/tabs.py', 'openstack_dashboard/dashboards/project/networks/subnets/views.py', 'openstack_dashboard/dashboards/admin/roles/views.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/snapshots/urls.py', 'openstack_dashboard/dashboards/settings/user/urls.py', 'openstack_dashboard/dashboards/project/routers/ports/urls.py', 'openstack_dashboard/dashboards/admin/routers/urls.py', 'openstack_dashboard/dashboards/admin/volumes/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/floating_ips/tests.py', 'openstack_dashboard/dashboards/admin/routers/ports/urls.py', 'openstack_dashboard/dashboards/settings/user/views.py', 'openstack_dashboard/dashboards/admin/volumes/views.py', 'openstack_dashboard/dashboards/project/networks/ports/views.py', 'openstack_dashboard/dashboards/project/access_and_security/keypairs/views.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/tests.py', 'openstack_dashboard/dashboards/admin/groups/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/urls.py', 'openstack_dashboard/test/test_data/nova_data.py', 'openstack_dashboard/dashboards/project/access_and_security/urls.py', 'openstack_dashboard/dashboards/admin/domains/tables.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/routers/views.py', 'openstack_dashboard/dashboards/admin/projects/tests.py', 'openstack_dashboard/dashboards/project/networks/urls.py', 'openstack_dashboard/dashboards/admin/projects/tables.py', 'openstack_dashboard/dashboards/project/routers/ports/views.py', 'openstack_dashboard/dashboards/admin/domains/urls.py', 'openstack_dashboard/dashboards/admin/projects/views.py', 'horizon/browsers/__init__.py', 'openstack_dashboard/dashboards/admin/domains/tests.py', 'openstack_dashboard/dashboards/project/networks/ports/urls.py', 'openstack_dashboard/dashboards/admin/domains/views.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/tables.py', 'openstack_dashboard/dashboards/admin/routers/ports/views.py', 'openstack_dashboard/dashboards/project/access_and_security/tabs.py', 'openstack_dashboard/dashboards/project/networks/views.py', 'openstack_dashboard/dashboards/settings/password/urls.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/floating_ips/views.py', 'openstack_dashboard/dashboards/admin/users/urls.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/urls.py', 'openstack_dashboard/dashboards/admin/flavors/extras/views.py', 'openstack_dashboard/dashboards/admin/networks/ports/views.py', 'tox.ini', 'openstack_dashboard/dashboards/admin/routers/views.py', 'openstack_dashboard/dashboards/project/overview/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/keypairs/urls.py', 'openstack_dashboard/dashboards/admin/networks/urls.py', 'openstack_dashboard/test/test_data/heat_data.py', 'openstack_dashboard/dashboards/admin/projects/urls.py', 'openstack_dashboard/test/test_data/swift_data.py', 'openstack_dashboard/dashboards/project/access_and_security/floating_ips/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/floating_ips/workflows.py', 'openstack_dashboard/dashboards/project/access_and_security/api_access/urls.py', 'openstack_dashboard/dashboards/admin/flavors/extras/urls.py', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'openstack_dashboard/test/test_data/cinder_data.py', 'openstack_dashboard/test/test_data/glance_data.py', 'openstack_dashboard/dashboards/admin/users/views.py', 'openstack_dashboard/dashboards/admin/groups/views.py', 'openstack_dashboard/dashboards/project/networks/subnets/urls.py', 'openstack_dashboard/dashboards/admin/info/views.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/views.py', 'openstack_dashboard/dashboards/admin/images/urls.py', 'openstack_dashboard/dashboards/project/routers/urls.py', 'openstack_dashboard/dashboards/settings/password/views.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/forms.py', 'openstack_dashboard/test/test_data/utils.py']",98,ec594ed2bc97fd2e45e3f176469ca6c0a5d19919,bug/1188535, from openstack_dashboard.test.test_data import cinder_data from openstack_dashboard.test.test_data import exceptions from openstack_dashboard.test.test_data import glance_data from openstack_dashboard.test.test_data import heat_data from openstack_dashboard.test.test_data import keystone_data from openstack_dashboard.test.test_data import nova_data from openstack_dashboard.test.test_data import quantum_data from openstack_dashboard.test.test_data import swift_data, from . import cinder_data from . import exceptions from . import glance_data from . import heat_data from . import keystone_data from . import nova_data from . import quantum_data from . import swift_data,439,275
openstack%2Fopenstack-manuals~master~I12fedcf8e899bca4e160bdc8e7385804dce79d8b,openstack/openstack-manuals,master,I12fedcf8e899bca4e160bdc8e7385804dce79d8b,Makes pom.xml file for Security Guide on par with Ops Guide.,MERGED,2013-07-16 21:19:16.000000000,2013-07-16 21:21:24.000000000,2013-07-16 21:21:23.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-16 21:19:16.000000000', 'files': ['doc/src/docbkx/openstack-security/pom.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c34fc2f1dbac2d665bedfafb69b2e497ae832eef', 'message': 'Makes pom.xml file for Security Guide on par with Ops Guide.\n\nMeans chapter numbering changes from previous.\n\nChange-Id: I12fedcf8e899bca4e160bdc8e7385804dce79d8b\n'}]",1,37332,c34fc2f1dbac2d665bedfafb69b2e497ae832eef,6,3,1,964,,,0,"Makes pom.xml file for Security Guide on par with Ops Guide.

Means chapter numbering changes from previous.

Change-Id: I12fedcf8e899bca4e160bdc8e7385804dce79d8b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/32/37332/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-security/pom.xml'],1,c34fc2f1dbac2d665bedfafb69b2e497ae832eef,pom-file-parity," <enableGoogleAnalytics>1</enableGoogleAnalytics> <googleAnalyticsId>UA-17511903-1</googleAnalyticsId> <chapterAutolabel>1</chapterAutolabel> <appendixAutolabel>1</appendixAutolabel> <sectionAutolabel>0</sectionAutolabel> <tocSectionDepth>1</tocSectionDepth> <formalProcedures>0</formalProcedures> <generateToc> appendix toc,title article/appendix nop article toc,title book toc,title,figure,table,equation chapter toc part toc,title acknowledgements toc,title preface toc qandadiv toc qandaset toc reference toc,title section toc set toc,title </generateToc>",,22,0
openstack%2Fopenstack-manuals~master~Ief819e1d3366ee1e1cd42f6bd8b61eaf7c20401d,openstack/openstack-manuals,master,Ief819e1d3366ee1e1cd42f6bd8b61eaf7c20401d,Bug # 1200232 - force_dhcp_release now defaults to True.,MERGED,2013-07-16 16:57:32.000000000,2013-07-16 21:20:17.000000000,2013-07-16 21:20:16.000000000,"[{'_account_id': 3}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-16 16:57:32.000000000', 'files': ['doc/src/docbkx/openstack-compute-admin/computenetworking.xml', 'doc/src/docbkx/common/tables/nova-network.xml', 'doc/src/docbkx/openstack-install/compute-config-guest-network.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2010081abc520ae17e1ee4976659b8e9b0a1384b', 'message': ""Bug # 1200232 - force_dhcp_release now defaults to True.\n\nHistorically it was was False because it requires the dnsmasq binary\n'dhcp_release' which was not present in all distributions. Most\ncontent and sample files already recommended setting the value to\nTrue, I have updated the few instances I found where it seemed\napplicable to highlight that True is now the default. I did leave one\nmention where it is recommended to set False for RHEL 6.2 because this\nis still the case.\n\nThere is probably a wider discussion needed there about whether\nat this point we should recommend >= RHEL 6.3 or even 6.4 for\nGrizzly/Havana as it significantly improves the availability of\npackages for a number of issues like this).\n\nChange-Id: Ief819e1d3366ee1e1cd42f6bd8b61eaf7c20401d\nFixes: bug 1200232\n""}]",0,37288,2010081abc520ae17e1ee4976659b8e9b0a1384b,5,2,1,6772,,,0,"Bug # 1200232 - force_dhcp_release now defaults to True.

Historically it was was False because it requires the dnsmasq binary
'dhcp_release' which was not present in all distributions. Most
content and sample files already recommended setting the value to
True, I have updated the few instances I found where it seemed
applicable to highlight that True is now the default. I did leave one
mention where it is recommended to set False for RHEL 6.2 because this
is still the case.

There is probably a wider discussion needed there about whether
at this point we should recommend >= RHEL 6.3 or even 6.4 for
Grizzly/Havana as it significantly improves the availability of
packages for a number of issues like this).

Change-Id: Ief819e1d3366ee1e1cd42f6bd8b61eaf7c20401d
Fixes: bug 1200232
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/88/37288/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-compute-admin/computenetworking.xml', 'doc/src/docbkx/common/tables/nova-network.xml', 'doc/src/docbkx/openstack-install/compute-config-guest-network.xml']",3,2010081abc520ae17e1ee4976659b8e9b0a1384b,," <para>If you are using a distribution based on RHEL 6.2 or earlier, use the <command>openstack-config</command> utility to turn off forced DHCP releases:</para> <para>If you are using a distribution based on RHEL 6.3 or later, install the dnsmasq utilities (<package>dnsmasq-utils</package>) package, which provides support for forced DHCP releases:</para>"," <para>If RHEL 6.2 based, use the openstack-config package to turn off force DHCP releases.</para> <para>If RHEL 6.3 based, install dnsmasq utilities.</para>",10,26
openstack%2Fcinder~master~Idd687514be9d622df84aad54b1b33ddc6615851b,openstack/cinder,master,Idd687514be9d622df84aad54b1b33ddc6615851b,Be sure to check deleted types on quota update.,MERGED,2013-07-12 23:46:03.000000000,2013-07-16 21:15:44.000000000,2013-07-16 21:15:44.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1773}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4159}, {'_account_id': 4355}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-07-12 23:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/72d5768b3e0f53073086b13838306e88e77fd808', 'message': ""Be sure to check deleted types on quota update.\n\nIf a volume-type is deleted, and later a volume\nthat's assigned that type is deleted the quota\nupdate will fail and result in a trace for\nVolumeTypeNotFound exception.\n\nThe volume is succesfully deleted, however the\nquota information for the volume-type let alone\nthe other quota items for the volume are not\nupdated.\n\nFixes bug: 1200709\n\nChange-Id: Idd687514be9d622df84aad54b1b33ddc6615851b\n""}, {'number': 2, 'created': '2013-07-12 23:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/02faf0050fc1e6c1983a7c846e4e37c68a3d9421', 'message': ""Be sure to check deleted types on quota update.\n\nIf a volume-type is deleted, and later a volume\nthat's assigned that type is deleted the quota\nupdate will fail and result in a trace for\nVolumeTypeNotFound exception.\n\nThe volume is succesfully deleted, however the\nquota information for the volume-type let alone\nthe other quota items for the volume are not\nupdated.\n\nFixes bug: 1200709\n\nChange-Id: Idd687514be9d622df84aad54b1b33ddc6615851b\n""}, {'number': 3, 'created': '2013-07-13 00:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0df4ed5709fba648f48ee01480321e66dfd69f3e', 'message': ""Be sure to check deleted types on quota update.\n\nIf a volume-type is deleted, and later a volume\nthat's assigned that type is deleted the quota\nupdate will fail and result in a trace for\nVolumeTypeNotFound exception.\n\nThe volume is succesfully deleted, however the\nquota information for the volume-type let alone\nthe other quota items for the volume are not\nupdated.\n\nFixes bug: 1200709\n\nChange-Id: Idd687514be9d622df84aad54b1b33ddc6615851b\n""}, {'number': 4, 'created': '2013-07-15 18:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4ee8e0f41dfdf9626a69b1d9252ccc692f654b5e', 'message': ""Be sure to check deleted types on quota update.\n\nIf a volume-type is deleted, and later a volume\nthat's assigned that type is deleted the quota\nupdate will fail and result in a trace for\nVolumeTypeNotFound exception.\n\nThe volume is succesfully deleted, however the\nquota information for the volume-type let alone\nthe other quota items for the volume are not\nupdated.\n\nFixes bug: 1200709\n\nChange-Id: Idd687514be9d622df84aad54b1b33ddc6615851b\n""}, {'number': 5, 'created': '2013-07-16 18:45:19.000000000', 'files': ['cinder/db/api.py', 'cinder/db/sqlalchemy/api.py', 'cinder/quota.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/18308807de7e7090854d6fde9ae06c7ffbf9b7ac', 'message': ""Be sure to check deleted types on quota update.\n\nIf a volume-type is deleted, and later a volume\nthat's assigned that type is deleted the quota\nupdate will fail and result in a trace for\nVolumeTypeNotFound exception.\n\nThe volume is succesfully deleted, however the\nquota information for the volume-type let alone\nthe other quota items for the volume are not\nupdated.\n\nFixes bug: 1200709\n\nChange-Id: Idd687514be9d622df84aad54b1b33ddc6615851b\n""}]",5,36922,18308807de7e7090854d6fde9ae06c7ffbf9b7ac,27,9,5,2243,,,0,"Be sure to check deleted types on quota update.

If a volume-type is deleted, and later a volume
that's assigned that type is deleted the quota
update will fail and result in a trace for
VolumeTypeNotFound exception.

The volume is succesfully deleted, however the
quota information for the volume-type let alone
the other quota items for the volume are not
updated.

Fixes bug: 1200709

Change-Id: Idd687514be9d622df84aad54b1b33ddc6615851b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/22/36922/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/quota.py'],1,72d5768b3e0f53073086b13838306e88e77fd808,bug/1200709," try: volume_type = db.volume_type_get(context, volume_type_id) except exception.VolumeTypeNotFound: volume_type = None volume_types = db.volume_type_get_all(context, True) for v_type in volume_types.values(): if v_type['id'] == volume_type_id: volume_type = v_type volume_types = db.volume_type_get_all(context.get_admin_context(), True)"," volume_type = db.volume_type_get(context, volume_type_id) volume_types = db.volume_type_get_all(context.get_admin_context())",10,2
openstack%2Fopenstack-manuals~master~Ia7662220e375054471da3912393ae3d77f94547e,openstack/openstack-manuals,master,Ia7662220e375054471da3912393ae3d77f94547e,Removes pagebreak processing instructions that broke the Security Guide build.,MERGED,2013-07-16 21:06:14.000000000,2013-07-16 21:11:13.000000000,2013-07-16 21:11:12.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-07-16 21:06:14.000000000', 'files': ['doc/src/docbkx/openstack-security/ch002_why-and-how-we-wrote-this-book.xml', 'doc/src/docbkx/openstack-security/ch020_ssl-everywhere.xml', 'doc/src/docbkx/openstack-security/ch012_configuration-management.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bef33a6a74f8094f1f58606c394e4890a948a550', 'message': 'Removes pagebreak processing instructions that broke the Security Guide build.\n\nChange-Id: Ia7662220e375054471da3912393ae3d77f94547e\n'}]",0,37325,bef33a6a74f8094f1f58606c394e4890a948a550,5,2,1,964,,,0,"Removes pagebreak processing instructions that broke the Security Guide build.

Change-Id: Ia7662220e375054471da3912393ae3d77f94547e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/25/37325/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-security/ch002_why-and-how-we-wrote-this-book.xml', 'doc/src/docbkx/openstack-security/ch020_ssl-everywhere.xml', 'doc/src/docbkx/openstack-security/ch012_configuration-management.xml']",3,bef33a6a74f8094f1f58606c394e4890a948a550,troubleshoot-sec-guide,, <?hard-pagebreak?>,0,3
openstack%2Ftrove~master~I34268f768a5cdb8085607269e2c2cb95974a539d,openstack/trove,master,I34268f768a5cdb8085607269e2c2cb95974a539d,Change the swift file deletion to use the manifest.,MERGED,2013-07-01 17:43:47.000000000,2013-07-16 21:10:06.000000000,2013-07-16 21:10:06.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 971}, {'_account_id': 1375}, {'_account_id': 5293}, {'_account_id': 6268}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-07-01 17:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c3e4f2b72359964552742c4bd461e0a56ef8c257', 'message': 'Change the swift file deletion to use the manifest.\n\n* Adding a _parse_manifest helper to parse the x-object-manifest header\n* Delete file using the prefix in the manifest.\n* Fix error handling in the delete_backup method.\n\nFixes Bug: #1194653\n\nChange-Id: I34268f768a5cdb8085607269e2c2cb95974a539d\n'}, {'number': 2, 'created': '2013-07-01 19:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/392463ad4312882708a01271de72206b87add194', 'message': 'Change the swift file deletion to use the manifest.\n\n* Adding a _parse_manifest helper to parse the x-object-manifest header\n* Delete file using the prefix in the manifest.\n* Fix error handling in the delete_backup method.\n\nFixes Bug: #1194653\n\nChange-Id: I34268f768a5cdb8085607269e2c2cb95974a539d\n'}, {'number': 3, 'created': '2013-07-16 19:19:04.000000000', 'files': ['trove/backup/models.py', 'trove/guestagent/strategies/storage/swift.py', 'trove/taskmanager/models.py', 'trove/tests/unittests/taskmanager/test_models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/1815d5d56635d98dc95b302b5bf869543d05b8cb', 'message': 'Change the swift file deletion to use the manifest.\n\n* Adding a _parse_manifest helper to parse the x-object-manifest header\n* Delete file using the prefix in the manifest.\n* Fix error handling in the delete_backup method.\n\nFixes Bug: #1194653\n\nChange-Id: I34268f768a5cdb8085607269e2c2cb95974a539d\n'}]",4,35166,1815d5d56635d98dc95b302b5bf869543d05b8cb,27,7,3,6268,,,0,"Change the swift file deletion to use the manifest.

* Adding a _parse_manifest helper to parse the x-object-manifest header
* Delete file using the prefix in the manifest.
* Fix error handling in the delete_backup method.

Fixes Bug: #1194653

Change-Id: I34268f768a5cdb8085607269e2c2cb95974a539d
",git fetch https://review.opendev.org/openstack/trove refs/changes/66/35166/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/guestagent/strategies/storage/swift.py', 'trove/taskmanager/models.py', 'trove/tests/unittests/taskmanager/test_models.py']",3,c3e4f2b72359964552742c4bd461e0a56ef8c257,swift,"from trove.common.exception import TroveError when(self.swift_client).head_object(any(), any()).thenReturn({}) self.assertRaises( TroveError, taskmanager_models.BackupTasks.delete_backup, 'dummy context', self.backup.id) self.assertRaises( TroveError, taskmanager_models.BackupTasks.delete_backup, 'dummy context', self.backup.id) def test_parse_manifest(self): manifest = 'container/prefix' cont, prefix = taskmanager_models.BackupTasks._parse_manifest(manifest) self.assertEqual(cont, 'container') self.assertEqual(prefix, 'prefix') def test_parse_manifest_bad(self): manifest = 'bad_prefix' cont, prefix = taskmanager_models.BackupTasks._parse_manifest(manifest) self.assertEqual(cont, None) self.assertEqual(prefix, None) def test_parse_manifest_long(self): manifest = 'container/long/path/to/prefix' cont, prefix = taskmanager_models.BackupTasks._parse_manifest(manifest) self.assertEqual(cont, 'container') self.assertEqual(prefix, 'long/path/to/prefix') def test_parse_manifest_short(self): manifest = 'container/' cont, prefix = taskmanager_models.BackupTasks._parse_manifest(manifest) self.assertEqual(cont, 'container') self.assertEqual(prefix, '')"," when(self.swift_client).head_object(any(), any()).thenReturn(None) taskmanager_models.BackupTasks.delete_backup('dummy context', self.backup.id) self.assertEqual(backup_models.BackupState.FAILED, self.backup.state, ""backup should be in FAILED status"") def test_delete_backup_fail_delete_container(self): when(self.swift_client).delete_container( any()).thenRaise(ClientException(""foo"")) when(self.swift_client).head_container(any()).thenReturn(None) taskmanager_models.BackupTasks.delete_backup('dummy context', self.backup.id) verify(backup_models.Backup, never).delete(self.backup.id) self.assertEqual(backup_models.BackupState.FAILED, self.backup.state, ""backup should be in FAILED status"") when(self.swift_client).delete_container( any()).thenRaise(ClientException(""foo"")) when(self.swift_client).head_container(any()).thenReturn(None) taskmanager_models.BackupTasks.delete_backup('dummy context', self.backup.id) self.assertEqual(backup_models.BackupState.FAILED, self.backup.state, ""backup should be in FAILED status"")",77,52
openstack%2Fneutron~master~I4fb77ed07b85b2f01ebb48b57adb10dfbadb3167,openstack/neutron,master,I4fb77ed07b85b2f01ebb48b57adb10dfbadb3167,Imported Translations from Transifex,MERGED,2013-07-16 19:58:50.000000000,2013-07-16 21:06:41.000000000,2013-07-16 21:06:40.000000000,"[{'_account_id': 3}, {'_account_id': 2031}]","[{'number': 1, 'created': '2013-07-16 19:58:50.000000000', 'files': ['neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/70c2fcf1a0e6406c92f6916073810fdfe7e83afc', 'message': 'Imported Translations from Transifex\n\nChange-Id: I4fb77ed07b85b2f01ebb48b57adb10dfbadb3167\n'}]",0,37316,70c2fcf1a0e6406c92f6916073810fdfe7e83afc,6,2,1,3,,,0,"Imported Translations from Transifex

Change-Id: I4fb77ed07b85b2f01ebb48b57adb10dfbadb3167
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/37316/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po']",20,70c2fcf1a0e6406c92f6916073810fdfe7e83afc,transifex/translations,"""POT-Creation-Date: 2013-07-16 19:58+0000\n""#: neutron/policy.py:137 #, python-format msgid ""Unable to find data type descriptor for attribute %s"" msgstr """" #: neutron/policy.py:142 #, python-format msgid """" ""Attribute type descriptor is not a dict. Unable to generate any sub-attr "" ""policy rule for %s."" msgstr """" #: neutron/policy.py:216#: neutron/policy.py:242#: neutron/policy.py:246#: neutron/policy.py:255#: neutron/policy.py:277#: neutron/policy.py:309#: neutron/service.py:38#: neutron/service.py:41#: neutron/service.py:98#: neutron/service.py:102#: neutron/service.py:111#: neutron/service.py:117#: neutron/service.py:218#: neutron/service.py:228#: neutron/agent/dhcp_agent.py:63 neutron/agent/l3_agent.py:172#: neutron/agent/dhcp_agent.py:528 neutron/agent/l3_agent.py:160#: neutron/agent/dhcp_agent.py:542 neutron/agent/l3_agent.py:203#: neutron/agent/dhcp_agent.py:848 neutron/agent/l3_agent.py:806#: neutron/agent/dhcp_agent.py:854 neutron/agent/l3_agent.py:811#: neutron/agent/dhcp_agent.py:862 neutron/agent/l3_agent.py:816#: neutron/agent/l3_agent.py:157 neutron/debug/debug_agent.py:48#: neutron/agent/l3_agent.py:164#: neutron/agent/l3_agent.py:168#: neutron/agent/l3_agent.py:174#: neutron/agent/l3_agent.py:179#: neutron/agent/l3_agent.py:181#: neutron/agent/l3_agent.py:184#: neutron/agent/l3_agent.py:196#: neutron/agent/l3_agent.py:238#: neutron/agent/l3_agent.py:267#: neutron/agent/l3_agent.py:335#: neutron/agent/l3_agent.py:337 neutron/db/l3_db.py:924#: neutron/agent/l3_agent.py:471#: neutron/agent/l3_agent.py:608msgid ""Got router deleted notification for %s""#: neutron/agent/l3_agent.py:613 #, python-format msgid ""Got routers updated notification :%s""#: neutron/agent/l3_agent.py:621 #, python-format msgid ""Got router removed from agent :%r"" msgstr """" #: neutron/agent/l3_agent.py:625 #, python-format msgid ""Got router added to agent :%r"" msgstr """" #: neutron/agent/l3_agent.py:632#: neutron/agent/l3_agent.py:688 neutron/agent/l3_agent.py:717#: neutron/agent/l3_agent.py:713 #, python-format msgid ""Processing :%r"" msgstr """" #: neutron/agent/l3_agent.py:721#: neutron/agent/l3_agent.py:741#: neutron/agent/l3_agent.py:749#: neutron/common/config.py:49 neutron/plugins/metaplugin/common/config.py:47#: neutron/agent/linux/iptables_manager.py:148#: neutron/agent/linux/iptables_manager.py:190#: neutron/agent/linux/iptables_manager.py:216#: neutron/agent/linux/iptables_manager.py:366#: neutron/agent/linux/iptables_manager.py:376 #, python-format msgid ""Unable to find table %s"" msgstr """" #: neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py:85#: neutron/common/config.py:39#: neutron/common/config.py:41#: neutron/common/config.py:43#: neutron/common/config.py:45#: neutron/common/config.py:47#: neutron/common/config.py:51#: neutron/common/config.py:53#: neutron/common/config.py:55#: neutron/common/config.py:57#: neutron/common/config.py:59#: neutron/common/config.py:61#: neutron/common/config.py:63#: neutron/common/config.py:65#: neutron/common/config.py:69#: neutron/common/config.py:71#: neutron/common/config.py:73#: neutron/common/config.py:76#: neutron/common/config.py:78#: neutron/common/config.py:81#: neutron/common/config.py:83#: neutron/common/config.py:85#: neutron/common/config.py:114#: neutron/common/config.py:125#: neutron/common/config.py:138#: neutron/common/config.py:143#: neutron/db/agentschedulers_db.py:399#: neutron/db/l3_db.py:205#: neutron/db/l3_db.py:225 neutron/db/l3_db.py:632#: neutron/db/l3_db.py:311#: neutron/db/l3_db.py:325#: neutron/db/l3_db.py:334 neutron/db/l3_db.py:410#: neutron/db/l3_db.py:341#: neutron/db/l3_db.py:351#: neutron/db/l3_db.py:366#: neutron/db/l3_db.py:492#: neutron/db/l3_db.py:531#: neutron/db/l3_db.py:535#: neutron/db/l3_db.py:547#: neutron/db/l3_db.py:554#: neutron/db/l3_db.py:558#: neutron/db/l3_db.py:600 neutron/plugins/nicira/NeutronPlugin.py:1821#: neutron/db/l3_db.py:756#: neutron/db/l3_db.py:774#: neutron/db/l3_db.py:930#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:96#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:114 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:134 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:149#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:328#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:475#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:122#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:374#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:378#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:384 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:403#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:387#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:407#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:413#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:419#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:425#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:431#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:326#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:141#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:280#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:296#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:337#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:341#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:394#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:397#: neutron/scheduler/l3_agent_scheduler.py:133#: neutron/scheduler/l3_agent_scheduler.py:138#: neutron/scheduler/l3_agent_scheduler.py:147#~ msgid ""Failed dealing with router '%s' deletion RPC message""#~ msgid ""Failed dealing with routers update RPC message""","""POT-Creation-Date: 2013-07-15 19:54+0000\n""#: neutron/policy.py:181#: neutron/policy.py:207#: neutron/policy.py:211#: neutron/policy.py:220#: neutron/policy.py:242#: neutron/policy.py:274#: neutron/service.py:37#: neutron/service.py:40#: neutron/service.py:96#: neutron/service.py:100#: neutron/service.py:109#: neutron/service.py:115#: neutron/service.py:216#: neutron/service.py:226#: neutron/agent/dhcp_agent.py:63 neutron/agent/l3_agent.py:161#: neutron/agent/dhcp_agent.py:528 neutron/agent/l3_agent.py:149#: neutron/agent/dhcp_agent.py:542 neutron/agent/l3_agent.py:192#: neutron/agent/dhcp_agent.py:848 neutron/agent/l3_agent.py:764#: neutron/agent/dhcp_agent.py:854 neutron/agent/l3_agent.py:769#: neutron/agent/dhcp_agent.py:862 neutron/agent/l3_agent.py:774#: neutron/agent/l3_agent.py:146 neutron/debug/debug_agent.py:48#: neutron/agent/l3_agent.py:153#: neutron/agent/l3_agent.py:157#: neutron/agent/l3_agent.py:163#: neutron/agent/l3_agent.py:168#: neutron/agent/l3_agent.py:170#: neutron/agent/l3_agent.py:173#: neutron/agent/l3_agent.py:185#: neutron/agent/l3_agent.py:221#: neutron/agent/l3_agent.py:250#: neutron/agent/l3_agent.py:318#: neutron/agent/l3_agent.py:320 neutron/db/l3_db.py:932#: neutron/agent/l3_agent.py:452#: neutron/agent/l3_agent.py:594msgid ""Failed dealing with router '%s' deletion RPC message""#: neutron/agent/l3_agent.py:607 msgid ""Failed dealing with routers update RPC message""#: neutron/agent/l3_agent.py:620#: neutron/agent/l3_agent.py:675#: neutron/agent/l3_agent.py:679#: neutron/agent/l3_agent.py:699#: neutron/agent/l3_agent.py:707#: neutron/common/config.py:50 neutron/plugins/metaplugin/common/config.py:47#: neutron/agent/linux/iptables_manager.py:139#: neutron/agent/linux/iptables_manager.py:165#: neutron/agent/linux/iptables_manager.py:189#: neutron/agent/linux/iptables_manager.py:339#: neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py:84#: neutron/common/config.py:40#: neutron/common/config.py:42#: neutron/common/config.py:44#: neutron/common/config.py:46#: neutron/common/config.py:48#: neutron/common/config.py:52#: neutron/common/config.py:54#: neutron/common/config.py:56#: neutron/common/config.py:58#: neutron/common/config.py:60#: neutron/common/config.py:62#: neutron/common/config.py:64#: neutron/common/config.py:66#: neutron/common/config.py:70#: neutron/common/config.py:72#: neutron/common/config.py:74#: neutron/common/config.py:77#: neutron/common/config.py:79#: neutron/common/config.py:82#: neutron/common/config.py:84#: neutron/common/config.py:86#: neutron/common/config.py:117#: neutron/common/config.py:128#: neutron/common/config.py:141#: neutron/common/config.py:146#: neutron/db/agentschedulers_db.py:400#: neutron/db/l3_db.py:206#: neutron/db/l3_db.py:226 neutron/db/l3_db.py:639#: neutron/db/l3_db.py:312#: neutron/db/l3_db.py:326#: neutron/db/l3_db.py:335 neutron/db/l3_db.py:412#: neutron/db/l3_db.py:340#: neutron/db/l3_db.py:350#: neutron/db/l3_db.py:365#: neutron/db/l3_db.py:499#: neutron/db/l3_db.py:538#: neutron/db/l3_db.py:542#: neutron/db/l3_db.py:554#: neutron/db/l3_db.py:561#: neutron/db/l3_db.py:565#: neutron/db/l3_db.py:607 neutron/plugins/nicira/NeutronPlugin.py:1821#: neutron/db/l3_db.py:764#: neutron/db/l3_db.py:782#: neutron/db/l3_db.py:938#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:95#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:113 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:133 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:148#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:326#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:473#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:121#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:372#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:376#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:382 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:401#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:385#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:405#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:411#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:417#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:423#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:429#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:324#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:140#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:279#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:294#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:335#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:339#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:392#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:395#: neutron/scheduler/l3_agent_scheduler.py:132#: neutron/scheduler/l3_agent_scheduler.py:137#: neutron/scheduler/l3_agent_scheduler.py:146#~ msgid ""[%(rid)d] Request '%(method) %(url)s' received: %(status)s""#~ msgid ""Network type for agent tunnel networks (gre or vxlan)""",3127,2467
openstack%2Fnova~master~I49ee53709270aa25de76d58666c250537f6a0314,openstack/nova,master,I49ee53709270aa25de76d58666c250537f6a0314,Periodic task for offloading shelved instances,MERGED,2013-07-02 18:50:56.000000000,2013-07-16 21:06:22.000000000,2013-07-16 21:06:19.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-02 18:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0935a8c15669bed6cc553d7f209f77e4732a016f', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 2, 'created': '2013-07-02 20:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/379a117b9e796c00bf70086c123b60ddf8b6c46e', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 3, 'created': '2013-07-03 13:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee4ae69b75048a0537665379e12ebe1ab0c468f6', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 4, 'created': '2013-07-03 15:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1eae447d987bdffeaa038fe712f14beaadf9b110', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 5, 'created': '2013-07-03 16:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a86e8641c68507b3f21fd9b0babb390c228d869', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 6, 'created': '2013-07-12 18:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2ac01cff535e486cae707892d49fcfbe5529d459', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nSetting a >0 shelved_offload_time means that hypervisor resources will\nstill be in used until the periodic task offloads them.  So capacity is\nnot reduced, but unshelving times may be decreased.\n\nOffloading immediately means that capacity becomes available quickly,\nbut may increase unshelving times if the instance is not volume backed\nand its snapshot takes a long time to transfer.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 7, 'created': '2013-07-12 19:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7bf7ca4df533cd5e540a5840030c9d41e61c955d', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nSetting a >0 shelved_offload_time means that hypervisor resources will\nstill be in used until the periodic task offloads them.  So capacity is\nnot reduced, but unshelving times may be decreased.\n\nOffloading immediately means that capacity becomes available quickly,\nbut may increase unshelving times if the instance is not volume backed\nand its snapshot takes a long time to transfer.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 8, 'created': '2013-07-15 20:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e18ad343fbb2b463e4b317c41a9bddd17bede0bd', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nSetting a >0 shelved_offload_time means that hypervisor resources will\nstill be in used until the periodic task offloads them.  So capacity is\nnot reduced, but unshelving times may be decreased.\n\nOffloading immediately means that capacity becomes available quickly,\nbut may increase unshelving times if the instance is not volume backed\nand its snapshot takes a long time to transfer.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 9, 'created': '2013-07-15 22:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/133b3cdd12944a611ffa6d896c7c91688318b1ed', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nSetting a >0 shelved_offload_time means that hypervisor resources will\nstill be in used until the periodic task offloads them.  So capacity is\nnot reduced, but unshelving times may be decreased.\n\nOffloading immediately means that capacity becomes available quickly,\nbut may increase unshelving times if the instance is not volume backed\nand its snapshot takes a long time to transfer.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 10, 'created': '2013-07-16 01:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1ed5d367158cba70e5c686372808c183ae4093c', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nSetting a >0 shelved_offload_time means that hypervisor resources will\nstill be in used until the periodic task offloads them.  So capacity is\nnot reduced, but unshelving times may be decreased.\n\nOffloading immediately means that capacity becomes available quickly,\nbut may increase unshelving times if the instance is not volume backed\nand its snapshot takes a long time to transfer.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 11, 'created': '2013-07-16 11:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc37d534a2419375e8079c8b39b06dbb264fe20f', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nSetting a >0 shelved_offload_time means that hypervisor resources will\nstill be in used until the periodic task offloads them.  So capacity is\nnot reduced, but unshelving times may be decreased.\n\nOffloading immediately means that capacity becomes available quickly,\nbut may increase unshelving times if the instance is not volume backed\nand its snapshot takes a long time to transfer.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 12, 'created': '2013-07-16 12:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84c0bda14fcd5e8b9e5eb7e1c07eb0b31c278e86', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nSetting a >0 shelved_offload_time means that hypervisor resources will\nstill be in used until the periodic task offloads them.  So capacity is\nnot reduced, but unshelving times may be decreased.\n\nOffloading immediately means that capacity becomes available quickly,\nbut may increase unshelving times if the instance is not volume backed\nand its snapshot takes a long time to transfer.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 13, 'created': '2013-07-16 13:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db50f002bfea8e9a5b4eb964925e6f6544606611', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nSetting a >0 shelved_offload_time means that hypervisor resources will\nstill be in used until the periodic task offloads them.  So capacity is\nnot reduced, but unshelving times may be decreased.\n\nOffloading immediately means that capacity becomes available quickly,\nbut may increase unshelving times if the instance is not volume backed\nand its snapshot takes a long time to transfer.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 14, 'created': '2013-07-16 16:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ac9403258befed8965199d0ab61dafcdccdf134', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nSetting a >0 shelved_offload_time means that hypervisor resources will\nstill be in used until the periodic task offloads them.  So capacity is\nnot reduced, but unshelving times may be decreased.\n\nOffloading immediately means that capacity becomes available quickly,\nbut may increase unshelving times if the instance is not volume backed\nand its snapshot takes a long time to transfer.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}, {'number': 15, 'created': '2013-07-16 17:59:03.000000000', 'files': ['nova/tests/compute/test_shelve.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ebebeb88083d8fa01f1318e36f48c53acdb78f37', 'message': 'Periodic task for offloading shelved instances\n\nAdds a periodic task which removes a shelved instance from a hypervisor\nif it has been shelved > CONF.shelved_offload_time seconds.\n\nCONF.shelved_offload_time can also be set to -1 to mean never offload,\nand 0 to mean offload immediately when shelved.\n\nSetting a >0 shelved_offload_time means that hypervisor resources will\nstill be in used until the periodic task offloads them.  So capacity is\nnot reduced, but unshelving times may be decreased.\n\nOffloading immediately means that capacity becomes available quickly,\nbut may increase unshelving times if the instance is not volume backed\nand its snapshot takes a long time to transfer.\n\nDocImpact\nPart of bp shelve-instance\n\nChange-Id: I49ee53709270aa25de76d58666c250537f6a0314\n'}]",8,35361,ebebeb88083d8fa01f1318e36f48c53acdb78f37,53,8,15,5441,,,0,"Periodic task for offloading shelved instances

Adds a periodic task which removes a shelved instance from a hypervisor
if it has been shelved > CONF.shelved_offload_time seconds.

CONF.shelved_offload_time can also be set to -1 to mean never offload,
and 0 to mean offload immediately when shelved.

Setting a >0 shelved_offload_time means that hypervisor resources will
still be in used until the periodic task offloads them.  So capacity is
not reduced, but unshelving times may be decreased.

Offloading immediately means that capacity becomes available quickly,
but may increase unshelving times if the instance is not volume backed
and its snapshot takes a long time to transfer.

DocImpact
Part of bp shelve-instance

Change-Id: I49ee53709270aa25de76d58666c250537f6a0314
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/35361/12 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_shelve.py']",2,0935a8c15669bed6cc553d7f209f77e4732a016f,bp/shelve-instance,"from oslo.config import cfgCONF = cfg.CONF def test_shelved_poll_none_exist(self): instance = jsonutils.to_primitive(self._create_fake_instance()) self.compute.run_instance(self.context, instance=instance) self.mox.StubOutWithMock(self.compute.driver, 'destroy') self.mox.StubOutWithMock(timeutils, 'is_older_than') self.mox.ReplayAll() self.compute._poll_shelved_instances(self.context) def test_shelved_poll_not_timedout(self): instance = jsonutils.to_primitive(self._create_fake_instance()) self.compute.run_instance(self.context, instance=instance) sys_meta = utils.metadata_to_dict(instance['system_metadata']) shelved_time = timeutils.utcnow() timeutils.set_time_override(shelved_time) timeutils.advance_time_seconds(CONF.shelved_offload_time - 1) sys_meta['shelved_at'] = timeutils.strtime(at=shelved_time) db.instance_update_and_get_original(self.context, instance['uuid'], {'vm_state': vm_states.SHELVED, 'system_metadata': sys_meta}) self.mox.StubOutWithMock(self.compute.driver, 'destroy') self.mox.ReplayAll() self.compute._poll_shelved_instances(self.context) def test_shelved_poll_timedout(self): active_instance = jsonutils.to_primitive(self._create_fake_instance()) self.compute.run_instance(self.context, instance=active_instance) instance = jsonutils.to_primitive(self._create_fake_instance()) self.compute.run_instance(self.context, instance=instance) sys_meta = utils.metadata_to_dict(instance['system_metadata']) shelved_time = timeutils.utcnow() timeutils.set_time_override(shelved_time) timeutils.advance_time_seconds(CONF.shelved_offload_time + 1) sys_meta['shelved_at'] = timeutils.strtime(at=shelved_time) (old, instance) = db.instance_update_and_get_original(self.context, instance['uuid'], {'vm_state': vm_states.SHELVED, 'system_metadata': sys_meta}) def fake_destroy(inst, nw_info, bdm): # NOTE(alaski) There are too many differences between an instance # as returned by instance_update_and_get_original and # instance_get_all_by_filters so just compare the uuid. self.assertEqual(instance['uuid'], inst['uuid']) self.stubs.Set(self.compute.driver, 'destroy', fake_destroy) self.compute._poll_shelved_instances(self.context) ",,87,1
openstack%2Fnova~master~Id41b3b86a7af476622c70415080f4982c267a646,openstack/nova,master,Id41b3b86a7af476622c70415080f4982c267a646,Use db.flavor_ instead of db.instance_type_,MERGED,2013-07-09 15:15:43.000000000,2013-07-16 21:06:00.000000000,2013-07-16 21:05:57.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-07-09 15:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b93fd13e2d6ca7816aebc86bf8d3ac21ba8760b7', 'message': 'Use db.flavor_ instead of db.instance_type_\n\nWe are removing instance_type as a synonym for a flavor. This fixes that\nfor the db.ap.\n\nPartially implements bp flavor-instance-type-dedup\n\nChange-Id: Id41b3b86a7af476622c70415080f4982c267a646\n'}, {'number': 2, 'created': '2013-07-09 16:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/233d34dccdf08d4b541aa5a8a1f982daff6625ae', 'message': 'Use db.flavor_ instead of db.instance_type_\n\nWe are removing instance_type as a synonym for a flavor. This fixes that\nfor the db.ap.\n\nPartially implements bp flavor-instance-type-dedup\n\nChange-Id: Id41b3b86a7af476622c70415080f4982c267a646\n'}, {'number': 3, 'created': '2013-07-16 19:43:15.000000000', 'files': ['nova/tests/test_nova_manage.py', 'nova/tests/db/fakes.py', 'nova/tests/virt/vmwareapi/db_fakes.py', 'nova/scheduler/utils.py', 'nova/tests/api/openstack/compute/contrib/test_flavors_extra_specs.py', 'nova/tests/api/openstack/compute/test_flavors.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/compute/flavors.py', 'nova/tests/conductor/test_conductor.py', 'nova/tests/compute/test_compute.py', 'nova/cells/state.py', 'nova/tests/virt/libvirt/test_libvirt_blockinfo.py', 'nova/tests/test_instance_types_extra_specs.py', 'nova/tests/utils.py', 'nova/tests/test_flavors.py', 'nova/tests/db/test_db_api.py', 'nova/tests/virt/powervm/test_powervm.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/api/openstack/compute/contrib/flavorextraspecs.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors.py', 'nova/cmd/manage.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/tests/virt/hyperv/db_fakes.py', 'nova/tests/virt/libvirt/test_libvirt.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/tests/cells/test_cells_state_manager.py', 'nova/conductor/manager.py', 'nova/tests/cells/test_cells_scheduler.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/952a26a851ed11d157dba926349472cdac00155b', 'message': 'Use db.flavor_ instead of db.instance_type_\n\nWe are removing instance_type as a synonym for a flavor. This fixes that\nfor the db.ap.\n\nPartially implements bp flavor-instance-type-dedup\n\nChange-Id: Id41b3b86a7af476622c70415080f4982c267a646\n'}]",0,36235,952a26a851ed11d157dba926349472cdac00155b,16,5,3,1849,,,0,"Use db.flavor_ instead of db.instance_type_

We are removing instance_type as a synonym for a flavor. This fixes that
for the db.ap.

Partially implements bp flavor-instance-type-dedup

Change-Id: Id41b3b86a7af476622c70415080f4982c267a646
",git fetch https://review.opendev.org/openstack/nova refs/changes/35/36235/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_nova_manage.py', 'nova/tests/db/fakes.py', 'nova/tests/virt/vmwareapi/db_fakes.py', 'nova/scheduler/utils.py', 'nova/tests/api/openstack/compute/contrib/test_flavors_extra_specs.py', 'nova/tests/api/openstack/compute/test_flavors.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/compute/flavors.py', 'nova/tests/conductor/test_conductor.py', 'nova/tests/compute/test_compute.py', 'nova/cells/state.py', 'nova/tests/virt/libvirt/test_libvirt_blockinfo.py', 'nova/tests/test_instance_types_extra_specs.py', 'nova/tests/utils.py', 'nova/tests/test_flavors.py', 'nova/tests/db/test_db_api.py', 'nova/tests/virt/powervm/test_powervm.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/api/openstack/compute/contrib/flavorextraspecs.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors.py', 'nova/cmd/manage.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/tests/virt/hyperv/db_fakes.py', 'nova/tests/virt/libvirt/test_libvirt.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/tests/cells/test_cells_state_manager.py', 'nova/conductor/manager.py', 'nova/tests/cells/test_cells_scheduler.py']",28,b93fd13e2d6ca7816aebc86bf8d3ac21ba8760b7,bp/flavor-instance-type-dedup," inst_type = db.flavor_get(self.ctxt, 1)"," inst_type = db.instance_type_get(self.ctxt, 1)",163,163
openstack%2Fpython-novaclient~master~I7d238bbe43e1760e31f1a9ba783c668246f20844,openstack/python-novaclient,master,I7d238bbe43e1760e31f1a9ba783c668246f20844,Add AgregatesManager.get(),MERGED,2013-07-11 19:32:52.000000000,2013-07-16 21:05:34.000000000,2013-07-16 21:05:33.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}]","[{'number': 1, 'created': '2013-07-11 19:32:52.000000000', 'files': ['novaclient/v1_1/aggregates.py', 'novaclient/tests/v1_1/test_shell.py', 'novaclient/v1_1/shell.py', 'novaclient/tests/v1_1/test_aggregates.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/c360c3e8dad8bdf9f86b8f8596a956e518d0f526', 'message': 'Add AgregatesManager.get()\n\nutils.find_resource() uses manager.get() as part of converting Resource\nnames to IDs.  AggregatesManager had get_details() instead of get().\n\nAdd AggregatesManager.get(), leaving .get_details() in place for backward\nAPI compatibility.\n\nBug: 1200341\n\nChange-Id: I7d238bbe43e1760e31f1a9ba783c668246f20844\n'}]",1,36720,c360c3e8dad8bdf9f86b8f8596a956e518d0f526,6,3,1,970,,,0,"Add AgregatesManager.get()

utils.find_resource() uses manager.get() as part of converting Resource
names to IDs.  AggregatesManager had get_details() instead of get().

Add AggregatesManager.get(), leaving .get_details() in place for backward
API compatibility.

Bug: 1200341

Change-Id: I7d238bbe43e1760e31f1a9ba783c668246f20844
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/20/36720/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/v1_1/aggregates.py', 'novaclient/tests/v1_1/test_shell.py', 'novaclient/v1_1/shell.py', 'novaclient/tests/v1_1/test_aggregates.py']",4,c360c3e8dad8bdf9f86b8f8596a956e518d0f526,bug/1200341," def test_get(self): aggregate = cs.aggregates.get(""1"") cs.assert_called('GET', '/os-aggregates/1') self.assertTrue(isinstance(aggregate, aggregates.Aggregate)) aggregate2 = cs.aggregates.get(aggregate) cs.assert_called('GET', '/os-aggregates/1') self.assertTrue(isinstance(aggregate2, aggregates.Aggregate)) aggregate = cs.aggregates.get(""1"") aggregate = cs.aggregates.get(""1"") aggregate = cs.aggregates.get(""1"") aggregate = cs.aggregates.get(""1"") aggregate = cs.aggregates.get(""1"")"," aggregate = cs.aggregates.get_details(""1"") aggregate = cs.aggregates.get_details(""1"") aggregate = cs.aggregates.get_details(""1"") aggregate = cs.aggregates.get_details(""1"") aggregate = cs.aggregates.get_details(""1"")",34,13
openstack%2Fpython-novaclient~master~Iaabc27c42d74b7441c17e63db15724f64114620b,openstack/python-novaclient,master,Iaabc27c42d74b7441c17e63db15724f64114620b,Clean up and make HACKING.rst point to openstack-dev/hacking,MERGED,2013-07-08 17:31:10.000000000,2013-07-16 21:05:32.000000000,2013-07-16 21:05:32.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 5441}, {'_account_id': 7915}]","[{'number': 1, 'created': '2013-07-08 17:31:10.000000000', 'files': ['HACKING', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/1b3cd6ff9e9c77dbb267d293877c0c55c3a0382e', 'message': 'Clean up and make HACKING.rst point to openstack-dev/hacking\n\nInstead of having a full local copy of HACKING Reference the OpenStack\nhacking guide (openstack-dev/hacking) and remove duplicate sections.\n\nChange-Id: Iaabc27c42d74b7441c17e63db15724f64114620b\n'}]",0,36110,1b3cd6ff9e9c77dbb267d293877c0c55c3a0382e,7,4,1,1849,,,0,"Clean up and make HACKING.rst point to openstack-dev/hacking

Instead of having a full local copy of HACKING Reference the OpenStack
hacking guide (openstack-dev/hacking) and remove duplicate sections.

Change-Id: Iaabc27c42d74b7441c17e63db15724f64114620b
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/10/36110/1 && git format-patch -1 --stdout FETCH_HEAD,"['HACKING', 'HACKING.rst']",2,1b3cd6ff9e9c77dbb267d293877c0c55c3a0382e,hacking,"Nova Client Style Commandments ============================== - Step 1: Read the OpenStack Style Commandments https://github.com/openstack-dev/hacking/blob/master/HACKING.rst - Step 2: Read on Nova Client Specific Commandments --------------------------------- None so far Text encoding ------------- - All text within python code should be of type 'unicode'. WRONG: >>> s = 'foo' >>> s 'foo' >>> type(s) <type 'str'> RIGHT: >>> u = u'foo' >>> u u'foo' >>> type(u) <type 'unicode'> - Transitions between internal unicode and external strings should always be immediately and explicitly encoded or decoded. - All external text that is not explicitly encoded (database storage, commandline arguments, etc.) should be presumed to be encoded as utf-8. WRONG: mystring = infile.readline() myreturnstring = do_some_magic_with(mystring) outfile.write(myreturnstring) RIGHT: mystring = infile.readline() mytext = s.decode('utf-8') returntext = do_some_magic_with(mytext) returnstring = returntext.encode('utf-8') outfile.write(returnstring) Running Tests ------------- The testing system is based on a combination of tox and testr. If you just want to run the whole suite, run `tox` and all will be fine. However, if you'd like to dig in a bit more, you might want to learn some things about testr itself. A basic walkthrough for OpenStack can be found at http://wiki.openstack.org/testr ",,59,123
openstack%2Fpython-novaclient~master~I1472e1b648dae8f3b281a113adb60421a00e5a48,openstack/python-novaclient,master,I1472e1b648dae8f3b281a113adb60421a00e5a48,Remove uncessary code related to nova start/stop,MERGED,2013-07-09 06:33:41.000000000,2013-07-16 21:05:30.000000000,2013-07-16 21:05:30.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1607}, {'_account_id': 1849}, {'_account_id': 6743}, {'_account_id': 7148}, {'_account_id': 7915}]","[{'number': 1, 'created': '2013-07-09 06:33:41.000000000', 'files': ['novaclient/tests/v1_1/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/b5c91018e0067a29453c6aa3963e8ce6ecf89b2f', 'message': ""Remove uncessary code related to nova start/stop\n\n'nova start' and 'nova stop' actually send request with 'os-start'\nand 'os-stop', instead of 'start' and 'stop'.\n\nChange-Id: I1472e1b648dae8f3b281a113adb60421a00e5a48\n""}]",0,36181,b5c91018e0067a29453c6aa3963e8ce6ecf89b2f,9,7,1,7915,,,0,"Remove uncessary code related to nova start/stop

'nova start' and 'nova stop' actually send request with 'os-start'
and 'os-stop', instead of 'start' and 'stop'.

Change-Id: I1472e1b648dae8f3b281a113adb60421a00e5a48
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/81/36181/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/tests/v1_1/fakes.py'],1,b5c91018e0067a29453c6aa3963e8ce6ecf89b2f,remove-uncessary-code,, elif action == 'start': assert body[action] is None elif action == 'stop': assert body[action] is None,0,4
openstack%2Fpuppet-swift~master~I4f6075fb189474ee071fa9b80944a5fe5c062193,openstack/puppet-swift,master,I4f6075fb189474ee071fa9b80944a5fe5c062193,Fix Puppet 3.2.x deprecation warnings,MERGED,2013-07-12 22:38:36.000000000,2013-07-16 21:03:14.000000000,2013-07-16 21:03:14.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 6758}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-07-12 22:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/2df7cf6f6991d5c2be077453c03c84e8a0145620', 'message': 'Fix Puppet 3.2.x deprecation warnings\n\nChange-Id: I4f6075fb189474ee071fa9b80944a5fe5c062193\n'}, {'number': 2, 'created': '2013-07-12 22:40:10.000000000', 'files': ['templates/proxy/swauth.conf.erb', 'templates/swift_keystone_test.erb', 'templates/recon.conf.erb', 'templates/proxy/cache.conf.erb', 'templates/container-server.conf.erb', 'templates/account-server.conf.erb', 'templates/proxy/keystone.conf.erb', 'templates/object-server.conf.erb', 'templates/swift.conf.erb', 'templates/dispersion.conf.erb', 'templates/proxy/authtoken.conf.erb', 'templates/proxy-server.conf.erb', 'templates/proxy/ratelimit.conf.erb', 'templates/proxy/s3token.conf.erb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/75e29ee2bee6ba98dd910a4160f95930325810f8', 'message': 'Fix Puppet 3.2.x deprecation warnings\n\nChange-Id: I4f6075fb189474ee071fa9b80944a5fe5c062193\n'}]",0,36915,75e29ee2bee6ba98dd910a4160f95930325810f8,7,4,2,6758,,,0,"Fix Puppet 3.2.x deprecation warnings

Change-Id: I4f6075fb189474ee071fa9b80944a5fe5c062193
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/15/36915/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/proxy/swauth.conf.erb', 'templates/swift_keystone_test.erb', 'templates/recon.conf.erb', 'templates/proxy/cache.conf.erb', 'templates/container-server.conf.erb', 'templates/account-server.conf.erb', 'templates/proxy/keystone.conf.erb', 'templates/object-server.conf.erb', 'templates/swift.conf.erb', 'templates/dispersion.conf.erb', 'templates/proxy/authtoken.conf.erb', 'templates/proxy-server.conf.erb', 'templates/proxy/ratelimit.conf.erb', 'templates/proxy/s3token.conf.erb']",14,2df7cf6f6991d5c2be077453c03c84e8a0145620,fix_dep_warnings,auth_port = <%= @auth_port %> auth_protocol = <%= @auth_protocol %> auth_host = <%= @auth_host %>,auth_port = <%= auth_port %> auth_protocol = <%= auth_protocol %> auth_host = <%= auth_host %>,78,78
openstack%2Frequirements~master~I9df382055de8f1bf0e3f9eadc8065938daae5d0a,openstack/requirements,master,I9df382055de8f1bf0e3f9eadc8065938daae5d0a,Add Mako template engine for Neutron VPNaaS,ABANDONED,2013-07-16 06:18:15.000000000,2013-07-16 20:47:28.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-16 06:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/3bb402712440b2855889e8d988ebf5a99ca565ce', 'message': 'Add Script.mako template engine for Neutron VPNaaS\n\nScript.mako is used for generating config files.\n\nChange-Id: I9df382055de8f1bf0e3f9eadc8065938daae5d0a\n'}, {'number': 2, 'created': '2013-07-16 13:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/abfc8368ded8ffc0ce238a06e03b31cadeb99bcc', 'message': 'Add Script.mako template engine for Neutron VPNaaS\n\nScript.mako is used for generating config files.\n\nChange-Id: I9df382055de8f1bf0e3f9eadc8065938daae5d0a\n'}, {'number': 3, 'created': '2013-07-16 13:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/e32440cccffa396096067c5db96f3f64ca0fb47e', 'message': 'Add mako template engine for Neutron VPNaaS\n\nMako is used for generating config files.\n\nChange-Id: I9df382055de8f1bf0e3f9eadc8065938daae5d0a\n'}, {'number': 4, 'created': '2013-07-16 13:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4cc076e2701e010fb536c46197c10c1004577cc3', 'message': 'Add Mako template engine for Neutron VPNaaS\n\nMako is used for generating config files.\n\nChange-Id: I9df382055de8f1bf0e3f9eadc8065938daae5d0a\n'}, {'number': 5, 'created': '2013-07-16 14:03:23.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/26a96cec89bdaa89bc3800677c5926499abb54b7', 'message': 'Add Mako template engine for Neutron VPNaaS\n\nMako is used for generating config files.\n\nChange-Id: I9df382055de8f1bf0e3f9eadc8065938daae5d0a\n'}]",7,37177,26a96cec89bdaa89bc3800677c5926499abb54b7,17,4,5,2031,,,0,"Add Mako template engine for Neutron VPNaaS

Mako is used for generating config files.

Change-Id: I9df382055de8f1bf0e3f9eadc8065938daae5d0a
",git fetch https://review.opendev.org/openstack/requirements refs/changes/77/37177/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3bb402712440b2855889e8d988ebf5a99ca565ce,master,mako,xattr>=0.4,1,1
openstack%2Fpuppet-glance~master~I0908cde951994db6aba74d2ce3415126c429a76e,openstack/puppet-glance,master,I0908cde951994db6aba74d2ce3415126c429a76e,Add support for rbd in glance,MERGED,2013-06-27 07:56:54.000000000,2013-07-16 20:43:21.000000000,2013-07-16 20:43:21.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 3217}, {'_account_id': 6838}, {'_account_id': 7156}, {'_account_id': 7196}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-06-27 07:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/f1121532a1e65113301cf1e5149ecf25d1c94307', 'message': 'Add support for rbd in glance\n\nAdd support for Ceph/rbd in glance.\nUnit test added to spec.\n\nChange-Id: I0908cde951994db6aba74d2ce3415126c429a76e\n'}, {'number': 2, 'created': '2013-06-28 13:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/2121d50e1607b993750e2850da8b7d3884e3b18d', 'message': 'Add support for rbd in glance\n\nAdd support for Ceph/rbd in glance.\nUnit test added to spec.\n\nChange-Id: I0908cde951994db6aba74d2ce3415126c429a76e\n'}, {'number': 3, 'created': '2013-07-01 07:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/dfc470bbb7de9e22ae6efe5b788ed91ec6f1480a', 'message': 'Add support for rbd in glance\n\nAdd support for Ceph/rbd in glance.\nUnit test added to spec.\n\nAdd package dependency accordingly to a patch from\nMichael Jeanson <mjeanson@gmail.com>.\n\nChange-Id: I0908cde951994db6aba74d2ce3415126c429a76e\n'}, {'number': 4, 'created': '2013-07-05 06:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/27b8e18e437a73b050de344f2a70614dbcd97ff0', 'message': 'Add support for rbd in glance\n\nAdd support for Ceph/rbd in glance.\nUnit test added to spec.\n\nAdd package dependency ""python-ceph"" accordingly to a patch from\nMichael Jeanson <mjeanson@gmail.com>.\n\nChange-Id: I0908cde951994db6aba74d2ce3415126c429a76e\n'}, {'number': 5, 'created': '2013-07-08 13:01:42.000000000', 'files': ['spec/classes/glance_backend_rbd_spec.rb', 'manifests/backend/rbd.pp', 'manifests/params.pp', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/bf195330726434c18456e9d6e975d54afac0eb6a', 'message': 'Add support for rbd in glance\n\nAdd support for Ceph/rbd in glance.\nUnit test added to spec.\n\nAdd package dependency ""python-ceph"" accordingly to a patch from\nMichael Jeanson <mjeanson@gmail.com>.\n\nChange-Id: I0908cde951994db6aba74d2ce3415126c429a76e\n'}]",14,34691,bf195330726434c18456e9d6e975d54afac0eb6a,29,9,5,7872,,,0,"Add support for rbd in glance

Add support for Ceph/rbd in glance.
Unit test added to spec.

Add package dependency ""python-ceph"" accordingly to a patch from
Michael Jeanson <mjeanson@gmail.com>.

Change-Id: I0908cde951994db6aba74d2ce3415126c429a76e
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/91/34691/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/glance_backend_rbd_spec.rb', 'manifests/backend/rbd.pp']",2,f1121532a1e65113301cf1e5149ecf25d1c94307,add_rbd_support,"# # configures the storage backend for glance # as a rbd instance # class glance::backend::rbd( $rbd_store_user, $rbd_store_pool = 'images', ) { glance_api_config { 'DEFAULT/default_store': value => 'rbd'; 'DEFAULT/rbd_store_user': value => $rbd_store_user; 'DEFAULT/rbd_store_pool': value => $rbd_store_pool; } } ",,37,0
openstack%2Fsahara~master~Ia6432fff45728f8ba6c865917e7d9cd0739f4715,openstack/sahara,master,Ia6432fff45728f8ba6c865917e7d9cd0739f4715,Validation exceptions handling improved.,MERGED,2013-07-16 13:08:54.000000000,2013-07-16 20:36:30.000000000,2013-07-16 20:36:30.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-16 13:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e3d1c56f828d0fdfd3ee6ef671aa340d7ae01927', 'message': 'Validation exceptions handling improved.\n\nImplements bluepring expose-cluster-errors-details\n\nChange-Id: Ia6432fff45728f8ba6c865917e7d9cd0739f4715\n'}, {'number': 2, 'created': '2013-07-16 16:04:23.000000000', 'files': ['savanna/utils/api.py', 'savanna/plugins/vanilla/exceptions.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/0c213a01e819d59634b9ccccd269a1b1ee93773d', 'message': 'Validation exceptions handling improved.\n\nImplements bluepring expose-cluster-errors-details\n\nChange-Id: Ia6432fff45728f8ba6c865917e7d9cd0739f4715\n'}]",0,37242,0c213a01e819d59634b9ccccd269a1b1ee93773d,11,4,2,7132,,,0,"Validation exceptions handling improved.

Implements bluepring expose-cluster-errors-details

Change-Id: Ia6432fff45728f8ba6c865917e7d9cd0739f4715
",git fetch https://review.opendev.org/openstack/sahara refs/changes/42/37242/2 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/utils/api.py', 'savanna/plugins/vanilla/exceptions.py']",2,e3d1c56f828d0fdfd3ee6ef671aa340d7ae01927,,"class NotSingleNameNodeException(e.SavannaException): def __init__(self, nn_count): message = ""Hadoop cluster should contain only 1 NameNode "" \ ""instance. Actual NN count is %s"" % nn_count code = ""NOT_SINGLE_NAME_NODE"" super(NotSingleNameNodeException, self).__init__(message, code) message = ""Hadoop cluster should contain 0 or 1 JobTracker ""\ ""instances. Actual JT count is %s"" % jt_count code = ""NOT_SINGLE_JOB_TRACKER"" super(NotSingleJobTrackerException, self).__init__(message, code) message = ""TaskTrackers cannot be configures without JobTracker"" code = ""TASK_TRACKERS_WITHOUT_JOB_TRACKER"" super(TaskTrackersWithoutJobTracker, self).__init__(message, code) message = ""Cluster does not contain node groups: %s"" % names code = ""NODE_GROUP_DOES_NOT_EXIST"" super(NodeGroupsDoNotExist, self).__init__(message, code) message = ""Chosen node group %s cannot be scaled : "" \ ""%s"" % (ng_name, reason) code = ""NODE_GROUP_CANNOT_BE_SCALED"" super(NodeGroupCannotBeScaled, self).__init__(message, code)","class NotSingleNameNodeException(Exception): def __init__(self, nn_count): self.message = ""Hadoop cluster should contain only 1 NameNode "" \ ""instance. Actual NN count is %s"" % nn_count self.code = ""NOT_SINGLE_NAME_NODE"" self.message = ""Hadoop cluster should contain 0 or 1 JobTracker "" \ ""instances. Actual JT count is %s"" % jt_count self.code = ""NOT_SINGLE_JOB_TRACKER"" self.message = ""TaskTrackers cannot be configures without JobTracker"" self.code = ""TASK_TRACKERS_WITHOUT_JOB_TRACKER"" self.message = ""Cluster does not contain node groups: "" +\ names self.code = ""NODE_GROUP_DOES_NOT_EXIST"" self.message = ""Chosen node group %s cannot be "" \ ""scaled : %s"" % (ng_name, reason) self.code = ""NODE_GROUP_CANNOT_BE_SCALED""",27,15
openstack%2Fnova~master~I7b498aaca88693f662e712797a7f9931052ad72e,openstack/nova,master,I7b498aaca88693f662e712797a7f9931052ad72e,Deleting not existing floating ip raises 500,ABANDONED,2013-07-16 01:42:21.000000000,2013-07-16 20:23:23.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 4395}, {'_account_id': 5511}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-16 01:42:21.000000000', 'files': ['nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6da1b853719caef710c4a6442344dce25ab0ccb7', 'message': 'Deleting not existing floating ip raises 500\n\nThe floatingip api layer code does not catch Neutron exceptions so\nwe need to raise the correct nova floating ip exception so a 404\nis raised instead of a 500.\n\nFixes bug 1200175\n\nChange-Id: I7b498aaca88693f662e712797a7f9931052ad72e\n'}]",3,37154,6da1b853719caef710c4a6442344dce25ab0ccb7,7,6,1,4395,,,0,"Deleting not existing floating ip raises 500

The floatingip api layer code does not catch Neutron exceptions so
we need to raise the correct nova floating ip exception so a 404
is raised instead of a 500.

Fixes bug 1200175

Change-Id: I7b498aaca88693f662e712797a7f9931052ad72e
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/37154/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/neutronv2/api.py'],1,6da1b853719caef710c4a6442344dce25ab0ccb7,bug/1200175, try: fip = client.show_floatingip(id)['floatingip'] except neutronv2.exceptions.NeutronClientException as e: if e.status_code == 404: raise exception.FloatingIpNotFound() , fip = client.show_floatingip(id)['floatingip'],6,1
openstack%2Foslo-incubator~master~I6689c7a01bba7a146ac402a1fe72768a29c72161,openstack/oslo-incubator,master,I6689c7a01bba7a146ac402a1fe72768a29c72161,Move `test_migrations` from Nova.,MERGED,2013-06-05 09:32:24.000000000,2013-07-16 20:18:07.000000000,2013-07-16 20:18:07.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 5638}, {'_account_id': 6172}, {'_account_id': 6849}, {'_account_id': 7369}, {'_account_id': 7491}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-06-05 09:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/6632e07d355700e6e747dbbc139d73bc5e59f0bf', 'message': 'Move `test_migrations` from Nova.\n\nAdded class WalkVersionsMixin with common methods for migration tests\n(`_migrate_up()`, `_migrate_down()` and `_walk_versions()`).\nTests added.\n\nblueprint test-migrations\n\nChange-Id: I6689c7a01bba7a146ac402a1fe72768a29c72161\n'}, {'number': 2, 'created': '2013-06-05 09:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/90edd6848c8b9e17e7d065709b3a15dc0ce8c6a2', 'message': 'Move `test_migrations` from Nova.\n\nAdded class WalkVersionsMixin with common methods for migration tests\n(`_migrate_up()`, `_migrate_down()` and `_walk_versions()`).\nTests added.\n\nblueprint test-migrations\n\nChange-Id: I6689c7a01bba7a146ac402a1fe72768a29c72161\n'}, {'number': 3, 'created': '2013-06-05 09:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3296e4adc6a8257ee2f2bf1d708032a933ef1c53', 'message': 'Move `test_migrations` from Nova.\n\nAdded class WalkVersionsMixin with common methods for migration tests\n(`_migrate_up()`, `_migrate_down()` and `_walk_versions()`).\nTests added.\n\nblueprint test-migrations\n\nChange-Id: I6689c7a01bba7a146ac402a1fe72768a29c72161\n'}, {'number': 4, 'created': '2013-06-05 09:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/34ba7ae76ce65a09b2adc5ae4def7db9726a8470', 'message': 'Move `test_migrations` from Nova.\n\nAdded class WalkVersionsMixin with common methods for migration tests\n(`_migrate_up()`, `_migrate_down()` and `_walk_versions()`).\nTests added.\n\nblueprint test-migrations\n\nChange-Id: I6689c7a01bba7a146ac402a1fe72768a29c72161\n'}, {'number': 5, 'created': '2013-07-12 09:17:45.000000000', 'files': ['tests/unit/db/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b2c1eb32fe9bd9f679fe0dfa0302d04a43036226', 'message': 'Move `test_migrations` from Nova.\n\nAdded class WalkVersionsMixin with common methods for migration tests\n(`_migrate_up()`, `_migrate_down()` and `_walk_versions()`).\nTests added.\n\nblueprint test-migrations\n\nChange-Id: I6689c7a01bba7a146ac402a1fe72768a29c72161\n'}]",0,31761,b2c1eb32fe9bd9f679fe0dfa0302d04a43036226,41,9,5,7491,,,0,"Move `test_migrations` from Nova.

Added class WalkVersionsMixin with common methods for migration tests
(`_migrate_up()`, `_migrate_down()` and `_walk_versions()`).
Tests added.

blueprint test-migrations

Change-Id: I6689c7a01bba7a146ac402a1fe72768a29c72161
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/61/31761/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/db/sqlalchemy/test_migrations.py'],1,6632e07d355700e6e747dbbc139d73bc5e59f0bf,bp/test-migrations,"import mock class WalkVersionsMixin(object): def _walk_versions(self, engine=None, snake_walk=False, downgrade=True): # Determine latest version script from the repo, then # upgrade from 1 through to the latest, with no data # in the databases. This just checks that the schema itself # upgrades successfully. # Place the database under version control self.migration_api.version_control(engine, self.REPOSITORY, self.INIT_VERSION) self.assertEqual(self.INIT_VERSION, self.migration_api.db_version(engine, self.REPOSITORY)) LOG.debug('latest version is %s' % self.REPOSITORY.latest) versions = range(self.INIT_VERSION + 1, self.REPOSITORY.latest + 1) for version in versions: # upgrade -> downgrade -> upgrade self._migrate_up(engine, version, with_data=True) if snake_walk: downgraded = self._migrate_down( engine, version - 1, with_data=True) if downgraded: self._migrate_up(engine, version) if downgrade: # Now walk it back down to 0 from the latest, testing # the downgrade paths. for version in reversed(versions): # downgrade -> upgrade -> downgrade downgraded = self._migrate_down(engine, version - 1) if snake_walk and downgraded: self._migrate_up(engine, version) self._migrate_down(engine, version - 1) def _migrate_down(self, engine, version, with_data=False): try: self.migration_api.downgrade(engine, self.REPOSITORY, version) except NotImplementedError: # NOTE(sirp): some migrations, namely release-level # migrations, don't support a downgrade. return False self.assertEqual( version, self.migration_api.db_version(engine, self.REPOSITORY)) # NOTE(sirp): `version` is what we're downgrading to (i.e. the 'target' # version). So if we have any downgrade checks, they need to be run for # the previous (higher numbered) migration. if with_data: post_downgrade = getattr( self, ""_post_downgrade_%03d"" % (version + 1), None) if post_downgrade: post_downgrade(engine) return True def _migrate_up(self, engine, version, with_data=False): """"""migrate up to a new version of the db. We allow for data insertion and post checks at every migration version with special _pre_upgrade_### and _check_### functions in the main test. """""" # NOTE(sdague): try block is here because it's impossible to debug # where a failed data migration happens otherwise try: if with_data: data = None pre_upgrade = getattr( self, ""_pre_upgrade_%03d"" % version, None) if pre_upgrade: data = pre_upgrade(engine) self.migration_api.upgrade(engine, self.REPOSITORY, version) self.assertEqual(version, self.migration_api.db_version(engine, self.REPOSITORY)) if with_data: check = getattr(self, ""_check_%03d"" % version, None) if check: check(engine, data) except Exception: LOG.error(""Failed to migrate to version %s on engine %s"" % (version, engine)) raise class TestWalkVersions(test_utils.BaseTestCase, WalkVersionsMixin): def setUp(self): super(TestWalkVersions, self).setUp() self.migration_api = mock.MagicMock() self.engine = mock.MagicMock() self.REPOSITORY = mock.MagicMock() self.INIT_VERSION = 4 def test_migrate_up(self): self.migration_api.db_version.return_value = 141 self._migrate_up(self.engine, 141) self.migration_api.upgrade.assert_called_with( self.engine, self.REPOSITORY, 141) self.migration_api.db_version.assert_called_with( self.engine, self.REPOSITORY) def test_migrate_up_with_data(self): test_value = {""a"": 1, ""b"": 2} self.migration_api.db_version.return_value = 141 self._pre_upgrade_141 = mock.MagicMock() self._pre_upgrade_141.return_value = test_value self._check_141 = mock.MagicMock() self._migrate_up(self.engine, 141, True) self._pre_upgrade_141.assert_called_with(self.engine) self._check_141.assert_called_with(self.engine, test_value) def test_migrate_down(self): self.migration_api.db_version.return_value = 42 self.assertTrue(self._migrate_down(self.engine, 42)) self.migration_api.db_version.assert_called_with( self.engine, self.REPOSITORY) def test_migrate_down_not_implemented(self): self.migration_api.downgrade.side_effect = NotImplementedError self.assertFalse(self._migrate_down(self.engine, 42)) def test_migrate_down_with_data(self): self._post_downgrade_043 = mock.MagicMock() self.migration_api.db_version.return_value = 42 self._migrate_down(self.engine, 42, True) self._post_downgrade_043.assert_called_with(self.engine) @mock.patch.object(WalkVersionsMixin, '_migrate_up') @mock.patch.object(WalkVersionsMixin, '_migrate_down') def test_walk_versions_all_default(self, _migrate_up, _migrate_down): self.REPOSITORY.latest = 20 self.migration_api.db_version.return_value = self.INIT_VERSION self._walk_versions() self.migration_api.version_control.assert_called_with( None, self.REPOSITORY, self.INIT_VERSION) self.migration_api.db_version.assert_called_with( None, self.REPOSITORY) versions = range(self.INIT_VERSION + 1, self.REPOSITORY.latest + 1) upgraded = [mock.call(None, v, with_data=True) for v in versions] self.assertEquals(self._migrate_up.call_args_list, upgraded) downgraded = [mock.call(None, v - 1) for v in reversed(versions)] self.assertEquals(self._migrate_down.call_args_list, downgraded) @mock.patch.object(WalkVersionsMixin, '_migrate_up') @mock.patch.object(WalkVersionsMixin, '_migrate_down') def test_walk_versions_all_true(self, _migrate_up, _migrate_down): self.REPOSITORY.latest = 20 self.migration_api.db_version.return_value = self.INIT_VERSION self._walk_versions(self.engine, snake_walk=True, downgrade=True) versions = range(self.INIT_VERSION + 1, self.REPOSITORY.latest + 1) upgraded = [] for v in versions: upgraded.append(mock.call(self.engine, v, with_data=True)) upgraded.append(mock.call(self.engine, v)) upgraded.extend( [mock.call(self.engine, v) for v in reversed(versions)] ) self.assertEquals(upgraded, self._migrate_up.call_args_list) downgraded_1 = [ mock.call(self.engine, v - 1, with_data=True) for v in versions ] downgraded_2 = [] for v in reversed(versions): downgraded_2.append(mock.call(self.engine, v - 1)) downgraded_2.append(mock.call(self.engine, v - 1)) downgraded = downgraded_1 + downgraded_2 self.assertEquals(self._migrate_down.call_args_list, downgraded) @mock.patch.object(WalkVersionsMixin, '_migrate_up') @mock.patch.object(WalkVersionsMixin, '_migrate_down') def test_walk_versions_true_false(self, _migrate_up, _migrate_down): self.REPOSITORY.latest = 20 self.migration_api.db_version.return_value = self.INIT_VERSION self._walk_versions(self.engine, snake_walk=True, downgrade=False) versions = range(self.INIT_VERSION + 1, self.REPOSITORY.latest + 1) upgraded = [] for v in versions: upgraded.append(mock.call(self.engine, v, with_data=True)) upgraded.append(mock.call(self.engine, v)) self.assertEquals(upgraded, self._migrate_up.call_args_list) downgraded = [ mock.call(self.engine, v - 1, with_data=True) for v in versions ] self.assertEquals(self._migrate_down.call_args_list, downgraded) @mock.patch.object(WalkVersionsMixin, '_migrate_up') @mock.patch.object(WalkVersionsMixin, '_migrate_down') def test_walk_versions_all_false(self, _migrate_up, _migrate_down): self.REPOSITORY.latest = 20 self.migration_api.db_version.return_value = self.INIT_VERSION self._walk_versions(self.engine, snake_walk=False, downgrade=False) versions = range(self.INIT_VERSION + 1, self.REPOSITORY.latest + 1) upgraded = [ mock.call(self.engine, v, with_data=True) for v in versions ] self.assertEquals(upgraded, self._migrate_up.call_args_list)",,225,0
openstack%2Fpython-novaclient~master~I56f62f036e0c85e79197f4c7dfd25abf7eb4110a,openstack/python-novaclient,master,I56f62f036e0c85e79197f4c7dfd25abf7eb4110a,Adds zsh completion,MERGED,2013-06-29 01:38:12.000000000,2013-07-16 20:05:49.000000000,2013-07-16 20:05:49.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1561}, {'_account_id': 5441}, {'_account_id': 5638}]","[{'number': 1, 'created': '2013-06-29 01:38:12.000000000', 'files': ['tools/nova.zsh_completion'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/2770e059e9b5a3b36298b701e12827aea183acfd', 'message': 'Adds zsh completion\n\nUse nova bash-completion to add native zsh completion using built in\nparameter expansion.  Nothing spectacular or new, this is mostly so that\nzsh users do not need to autoload bashcompinit just to use nova.\n\nChange-Id: I56f62f036e0c85e79197f4c7dfd25abf7eb4110a\nImplements: zsh completion\n'}]",0,34972,2770e059e9b5a3b36298b701e12827aea183acfd,8,5,1,8016,,,0,"Adds zsh completion

Use nova bash-completion to add native zsh completion using built in
parameter expansion.  Nothing spectacular or new, this is mostly so that
zsh users do not need to autoload bashcompinit just to use nova.

Change-Id: I56f62f036e0c85e79197f4c7dfd25abf7eb4110a
Implements: zsh completion
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/72/34972/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/nova.zsh_completion'],1,2770e059e9b5a3b36298b701e12827aea183acfd,zsh-completion,"#compdef nova local -a nbc _nova_opts _nova_flags _nova_opts_exp cur prev nbc=(${(ps: :)$(_call_program options ""$service bash-completion"" 2>/dev/null)}) _nova_opts=(${nbc:#-*}) _nova_flags=(${(M)nbc:#-*}) _nova_opt_exp=${${nbc:#-*}// /|} cur=$words[CURRENT] prev=$words[(( CURRENT - 1 ))] _checkcomp(){ for word in $words[@]; do if [[ -n ${_nova_opts[(r)$word]} ]]; then return 0 fi done return 1 } echo $_nova_opts[@] |grep --color nova if [[ ""$prev"" != ""help"" ]] && _checkcomp; then COMPLETION_CACHE=(~/.novaclient/*/*-cache) cflags=($_nova_flags[@] ${(ps: :)$(cat $COMPLETION_CACHE 2>/dev/null)}) compadd ""$@"" -d $cflags[@] else compadd ""$@"" -d $_nova_opts[@] fi ",,29,0
openstack%2Fpython-openstackclient~master~Ifa6718331d3da91f0e9515a809484808bd6317f9,openstack/python-openstackclient,master,Ifa6718331d3da91f0e9515a809484808bd6317f9,Update openstack-common.conf format,MERGED,2013-07-16 12:20:27.000000000,2013-07-16 20:05:10.000000000,2013-07-16 20:05:10.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-16 12:20:27.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f768ea2b228257030de4696bfefe61d9fc917723', 'message': 'Update openstack-common.conf format\n\nChange-Id: Ifa6718331d3da91f0e9515a809484808bd6317f9\n'}]",0,37236,f768ea2b228257030de4696bfefe61d9fc917723,6,3,1,1267,,,0,"Update openstack-common.conf format

Change-Id: Ifa6718331d3da91f0e9515a809484808bd6317f9
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/36/37236/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,f768ea2b228257030de4696bfefe61d9fc917723,,module=cfg module=iniparser module=install_venv_common module=openstackkeyring,"modules=cfg,iniparser,install_venv_common,openstackkeyring",4,1
openstack%2Fdevstack~master~I3aa991c1c4691df3e3f4798505668da3ab908998,openstack/devstack,master,I3aa991c1c4691df3e3f4798505668da3ab908998,Do not install mysql if mariadb is installed on openSUSE,MERGED,2013-04-11 06:42:35.000000000,2013-07-16 20:01:32.000000000,2013-07-16 20:01:32.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2340}, {'_account_id': 2750}, {'_account_id': 4460}]","[{'number': 1, 'created': '2013-04-11 06:42:35.000000000', 'files': ['lib/databases/mysql'], 'web_link': 'https://opendev.org/openstack/devstack/commit/623a0a58f6db70dd563c951bd601c18e6a1eb524', 'message': 'Do not install mysql if mariadb is installed on openSUSE\n\nmariadb and mysql are conflicting on a package level, but are compatible\nfor our needs. So if mariadb is already installed, do not try to install\nmysql.\n\nChange-Id: I3aa991c1c4691df3e3f4798505668da3ab908998\n'}]",0,26720,623a0a58f6db70dd563c951bd601c18e6a1eb524,21,5,1,4460,,,0,"Do not install mysql if mariadb is installed on openSUSE

mariadb and mysql are conflicting on a package level, but are compatible
for our needs. So if mariadb is already installed, do not try to install
mysql.

Change-Id: I3aa991c1c4691df3e3f4798505668da3ab908998
",git fetch https://review.opendev.org/openstack/devstack refs/changes/20/26720/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/databases/mysql'],1,623a0a58f6db70dd563c951bd601c18e6a1eb524,opensuse-mariadb-compat, if ! is_package_installed mariadb; then install_package mysql-community-server fi, install_package mysql-community-server,3,1
openstack%2Fopenstack-manuals~master~I829d32396e638d07e47e2210ea3affd0a79e1a02,openstack/openstack-manuals,master,I829d32396e638d07e47e2210ea3affd0a79e1a02,"Security Guide final spellcheck, duplicate word elimination, page break check.",MERGED,2013-07-16 19:49:15.000000000,2013-07-16 19:55:00.000000000,2013-07-16 19:54:59.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-07-16 19:49:15.000000000', 'files': ['doc/src/docbkx/openstack-security/ch052_devices.xml', 'doc/src/docbkx/openstack-security/ch008_system-roles-types.xml', 'doc/src/docbkx/openstack-security/ch063_compliance-activities.xml', 'doc/src/docbkx/openstack-security/ch002_why-and-how-we-wrote-this-book.xml', 'doc/src/docbkx/openstack-security/ch006_introduction-to-case-studies.xml', 'doc/src/docbkx/openstack-security/ch046_data-residency.xml', 'doc/src/docbkx/openstack-security/ch066_case-studies-compliance.xml', 'doc/src/docbkx/openstack-security/ch020_ssl-everywhere.xml', 'doc/src/docbkx/openstack-security/ch049_case-studies-tenant-data.xml', 'doc/src/docbkx/openstack-security/ch012_configuration-management.xml', 'doc/src/docbkx/openstack-security/ch014_best-practices-for-operator-mode-access.xml', 'doc/src/docbkx/openstack-security/ch047_data-encryption.xml', 'doc/src/docbkx/openstack-security/ch033_securing-neutron-services.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/233d33e21d85eb5b4dd8c5719ac6f165197775e5', 'message': 'Security Guide final spellcheck, duplicate word elimination, page break check.\n\nChange-Id: I829d32396e638d07e47e2210ea3affd0a79e1a02\n'}]",0,37313,233d33e21d85eb5b4dd8c5719ac6f165197775e5,5,2,1,964,,,0,"Security Guide final spellcheck, duplicate word elimination, page break check.

Change-Id: I829d32396e638d07e47e2210ea3affd0a79e1a02
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/13/37313/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-security/ch052_devices.xml', 'doc/src/docbkx/openstack-security/ch008_system-roles-types.xml', 'doc/src/docbkx/openstack-security/ch063_compliance-activities.xml', 'doc/src/docbkx/openstack-security/ch002_why-and-how-we-wrote-this-book.xml', 'doc/src/docbkx/openstack-security/ch006_introduction-to-case-studies.xml', 'doc/src/docbkx/openstack-security/ch046_data-residency.xml', 'doc/src/docbkx/openstack-security/ch066_case-studies-compliance.xml', 'doc/src/docbkx/openstack-security/ch020_ssl-everywhere.xml', 'doc/src/docbkx/openstack-security/ch049_case-studies-tenant-data.xml', 'doc/src/docbkx/openstack-security/ch012_configuration-management.xml', 'doc/src/docbkx/openstack-security/ch014_best-practices-for-operator-mode-access.xml', 'doc/src/docbkx/openstack-security/ch047_data-encryption.xml', 'doc/src/docbkx/openstack-security/ch033_securing-neutron-services.xml']",13,233d33e21d85eb5b4dd8c5719ac6f165197775e5,sec-guide-final-pdf-cleanup," <para> SDN Services Node: Management, Guest and possibly Public depending upon product used.</para>"," <para> SDN Services Node: Management, Guest and and possibly Public depending upon product used.</para>",113,17
openstack%2Fcinder~master~I0396f1252c8faafff3e8b4f9a4aeffb930350a8d,openstack/cinder,master,I0396f1252c8faafff3e8b4f9a4aeffb930350a8d,CoraidDriver: Allow volumes in error state to be deleted,MERGED,2013-07-12 13:48:41.000000000,2013-07-16 19:54:26.000000000,2013-07-16 19:54:25.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 6798}]","[{'number': 1, 'created': '2013-07-12 13:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4751cb5df592c3f854a54846b51a6f9dfa63efbc', 'message': ""CoraidDriver: Allow volumes in error state to be deleted\n\nThis fix will allow the delete call to be successfull if volume\ndoesn't exists on the SAN.\n\nFixes bug 1195788\n\nChange-Id: I0396f1252c8faafff3e8b4f9a4aeffb930350a8d\n""}, {'number': 2, 'created': '2013-07-16 17:41:25.000000000', 'files': ['cinder/volume/drivers/coraid.py', 'cinder/tests/test_coraid.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8a042e0732fbac24e412306d337c0742b681cfc2', 'message': ""CoraidDriver: Allow volumes in error state to be deleted\n\nThis fix will allow the delete call to be successfull if volume\ndoesn't exists on the SAN.\n\nFixes bug 1195788\n\nChange-Id: I0396f1252c8faafff3e8b4f9a4aeffb930350a8d\n""}]",2,36834,8a042e0732fbac24e412306d337c0742b681cfc2,11,5,2,6798,,,0,"CoraidDriver: Allow volumes in error state to be deleted

This fix will allow the delete call to be successfull if volume
doesn't exists on the SAN.

Fixes bug 1195788

Change-Id: I0396f1252c8faafff3e8b4f9a4aeffb930350a8d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/34/36834/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/coraid.py', 'cinder/tests/test_coraid.py']",2,4751cb5df592c3f854a54846b51a6f9dfa63efbc,bug/1195788," def test_delete_lun_ok(self): """"""Test Delete Volume classic case."""""" lambda *_: self.mox.CreateMockAnything()) result = self.drv.delete_lun(fake_volume_name) self.assertTrue(result) def test_delete_lun_in_error(self): """"""Test Delete Volume in Error State."""""" setattr(self.rest_mock, 'delete_lun', lambda *_: self.mox.CreateMockAnything()) self.stubs.Set(CoraidRESTClient, '_get_volume_info', lambda *_: Exception) self.stubs.Set(CoraidRESTClient, '_check_esm_alive', lambda *_: True) self.rest_mock.delete_lun(fake_volume_name) result = self.drv.delete_lun(fake_volume_name) self.assertTrue(result) def test_delete_lun_esm_unavailable(self): """"""Test Delete Volume with ESM Unavailable."""""" setattr(self.rest_mock, 'delete_lun', lambda *_: self.mox.CreateMockAnything()) self.stubs.Set(CoraidRESTClient, '_get_volume_info', lambda *_: Exception) self.stubs.Set(CoraidRESTClient, '_check_esm_alive', lambda *_: False) self.rest_mock.delete_lun(fake_volume_name) result = self.drv.delete_lun(fake_volume_name) self.assertRaises(Exception, result)", def test_delete_lun(self): lambda *_: True) self.drv.delete_lun(fake_volume_name),54,11
openstack%2Fcinder~master~Id7361e9571742bea210f13ced722829f489e7cb0,openstack/cinder,master,Id7361e9571742bea210f13ced722829f489e7cb0,Implement extend volume functionality in Sheepdog,MERGED,2013-07-16 09:07:31.000000000,2013-07-16 19:54:18.000000000,2013-07-16 19:54:17.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 6043}, {'_account_id': 6737}, {'_account_id': 7593}]","[{'number': 1, 'created': '2013-07-16 09:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/242a5d00d3a2fec5c374d5aa7792eece7282a269', 'message': 'Implement extend volume functionality in Sheepdog\n\nThis implements the extend volume functionality for Sheepdog driver.\n\nChange-Id: Id7361e9571742bea210f13ced722829f489e7cb0\nImplements: blueprint extend-sheepdog-volume\n'}, {'number': 2, 'created': '2013-07-16 10:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c9b408f32e3c39936e4d0c3e81acb0f5e53284e5', 'message': 'Implement extend volume functionality in Sheepdog\n\nThis implements the extend volume functionality for Sheepdog driver.\n\nChange-Id: Id7361e9571742bea210f13ced722829f489e7cb0\nImplements: blueprint extend-sheepdog-volume\n'}, {'number': 3, 'created': '2013-07-16 10:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9367edd1bd8cba2c88261f910607360ebf2aca6c', 'message': 'Implement extend volume functionality in Sheepdog\n\nThis implements the extend volume functionality for Sheepdog driver.\n\nChange-Id: Id7361e9571742bea210f13ced722829f489e7cb0\nImplements: blueprint extend-sheepdog-volume\n'}, {'number': 4, 'created': '2013-07-16 12:43:44.000000000', 'files': ['cinder/tests/test_sheepdog.py', 'cinder/volume/drivers/sheepdog.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0de59a856e554e0c8e784ed83b86534176b7716b', 'message': 'Implement extend volume functionality in Sheepdog\n\nThis implements the extend volume functionality for Sheepdog driver.\n\nChange-Id: Id7361e9571742bea210f13ced722829f489e7cb0\nImplements: blueprint extend-sheepdog-volume\n'}]",4,37198,0de59a856e554e0c8e784ed83b86534176b7716b,17,6,4,7593,,,0,"Implement extend volume functionality in Sheepdog

This implements the extend volume functionality for Sheepdog driver.

Change-Id: Id7361e9571742bea210f13ced722829f489e7cb0
Implements: blueprint extend-sheepdog-volume
",git fetch https://review.opendev.org/openstack/cinder refs/changes/98/37198/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_sheepdog.py', 'cinder/volume/drivers/sheepdog.py']",2,242a5d00d3a2fec5c374d5aa7792eece7282a269,bp/extend-sheepdog-volume,"from cinder import units def _resize(self, volume, **kwargs): size = kwargs.get('size', None) if not size: size = int(volume['size']) * (1024 ** 3) def extend_volume(self, volume, new_size): """"""Extend an Existing Volume."""""" old_size = volume['size'] try: size = int(new_size) * units.GiB self._resize(volume, size=size) except Exception: msg = _('Failed to Extend Volume ' '%(volname)s') % {'volname': volume['name']} LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug(_(""Extend volume from %(old_size) to %(new_size)""), {'old_size': old_size, 'new_size': new_size})"," def _resize(self, volume): size = int(volume['size']) * (1024 ** 3)",39,2
openstack%2Fcookbook-openstack-compute~master~I8c24d7cde1b4a6c4860909e25cf20ad499ac85ce,openstack/cookbook-openstack-compute,master,I8c24d7cde1b4a6c4860909e25cf20ad499ac85ce,SUSE doesn't have a separate nfs-utils-lib package,MERGED,2013-07-16 15:07:19.000000000,2013-07-16 19:46:00.000000000,2013-07-16 19:46:00.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 216}, {'_account_id': 7220}]","[{'number': 1, 'created': '2013-07-16 15:07:19.000000000', 'files': ['spec/compute-opensuse_spec.rb', 'attributes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/51f34a9cef1c3d15a0023c7a82b05fd357be09a0', 'message': ""SUSE doesn't have a separate nfs-utils-lib package\n\nbut nfs-utils provides the functionality of nfs-utils-lib\n\nChange-Id: I8c24d7cde1b4a6c4860909e25cf20ad499ac85ce\n""}]",0,37269,51f34a9cef1c3d15a0023c7a82b05fd357be09a0,7,4,1,2340,,,0,"SUSE doesn't have a separate nfs-utils-lib package

but nfs-utils provides the functionality of nfs-utils-lib

Change-Id: I8c24d7cde1b4a6c4860909e25cf20ad499ac85ce
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/69/37269/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/compute-opensuse_spec.rb', 'attributes/default.rb']",2,51f34a9cef1c3d15a0023c7a82b05fd357be09a0,nfs-utils," default[""openstack""][""compute""][""platform""][""nfs_packages""] = [""nfs-utils""]",,17,0
openstack%2Fnova~master~I204f14246938981633989654bd3446ca3230c222,openstack/nova,master,I204f14246938981633989654bd3446ca3230c222,xenapi: Stub out _add_torrent_url for Vhd tests,MERGED,2013-07-09 20:52:47.000000000,2013-07-16 19:44:50.000000000,2013-07-16 19:44:47.000000000,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 2166}, {'_account_id': 2835}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-09 20:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d67ac3333c16692556fe333acdac0cc2b7132101', 'message': 'xenapi: Stub out _add_torrent_url for Vhd tests\n\nThis will make the FetchVhdImageTestCasetest case play nicer when\na BitTorrent url plugin is installed and the tests are running with\nno virtual environment.\n\nChange-Id: I204f14246938981633989654bd3446ca3230c222\n'}, {'number': 2, 'created': '2013-07-09 23:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24edd767655e75b282cb687abdfa56f67ade82e4', 'message': 'xenapi: Stub out _add_torrent_url for Vhd tests\n\nThis will make the FetchVhdImageTestCasetest case play nicer when\na BitTorrent url plugin is installed and the tests are running with\nno virtual environment.\n\nChange-Id: I204f14246938981633989654bd3446ca3230c222\n'}, {'number': 3, 'created': '2013-07-09 23:29:09.000000000', 'files': ['nova/tests/virt/xenapi/test_vm_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1e4e176d135c56918365714c1b9f4979a5b77afc', 'message': 'xenapi: Stub out _add_torrent_url for Vhd tests\n\nThis will make the FetchVhdImageTestCasetest case play nicer when\na BitTorrent url plugin is installed and the tests are running with\nno virtual environment.\n\nChange-Id: I204f14246938981633989654bd3446ca3230c222\n'}]",0,36340,1e4e176d135c56918365714c1b9f4979a5b77afc,17,7,3,2835,,,0,"xenapi: Stub out _add_torrent_url for Vhd tests

This will make the FetchVhdImageTestCasetest case play nicer when
a BitTorrent url plugin is installed and the tests are running with
no virtual environment.

Change-Id: I204f14246938981633989654bd3446ca3230c222
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/36340/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/xenapi/test_vm_utils.py'],1,d67ac3333c16692556fe333acdac0cc2b7132101,bt_stuff3," self.mox.StubOutWithMock(vm_utils, '_add_torrent_url') if uses_bittorrent: vm_utils._add_torrent_url(self.instance, self.image_id, self.params).AndReturn(True)"," if uses_bittorrent: self.params['torrent_url'] = ""%s.torrent"" % self.image_id",4,2
openstack%2Fnova~master~Ib1d1b8b93f769b8dd8223dbbb3c42288254d8825,openstack/nova,master,Ib1d1b8b93f769b8dd8223dbbb3c42288254d8825,Code dedup in class TestServerActionRequestXMLDeserializer,MERGED,2013-07-04 09:53:03.000000000,2013-07-16 19:44:27.000000000,2013-07-16 19:44:25.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 6509}, {'_account_id': 6722}, {'_account_id': 6938}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7727}]","[{'number': 1, 'created': '2013-07-04 09:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d314745d901870553927e955352e77650a37e78d', 'message': 'Refactor class TestServerActionRequestXMLDeserializer\n\nRemoved code duplucation\n\nbp nova-tests-code-duplication\n\nChange-Id: Ib1d1b8b93f769b8dd8223dbbb3c42288254d8825\n'}, {'number': 2, 'created': '2013-07-05 05:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5978665143724d62928192032d387067353dc77e', 'message': 'Refactor class TestServerActionRequestXMLDeserializer\n\nRemoved code duplucation\n\nbp nova-tests-code-duplication\n\nChange-Id: Ib1d1b8b93f769b8dd8223dbbb3c42288254d8825\n'}, {'number': 3, 'created': '2013-07-05 06:04:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/75cb84064e9c767738e1a97064976ef32afc4c6c', 'message': 'Refactor class TestServerActionRequestXMLDeserializer\n\nRemoved code duplucation\n\nbp nova-tests-code-duplication\n\nChange-Id: Ib1d1b8b93f769b8dd8223dbbb3c42288254d8825\n'}, {'number': 4, 'created': '2013-07-05 07:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c6e81bf139382181eb0f125e934193ce20c92ea', 'message': 'Refactor class TestServerActionRequestXMLDeserializer\n\nRemoved code duplication\n\nbp nova-tests-code-duplication\n\nChange-Id: Ib1d1b8b93f769b8dd8223dbbb3c42288254d8825\n'}, {'number': 5, 'created': '2013-07-05 08:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78d424325af4620ac8537868be47521a4461f166', 'message': 'Refactor class TestServerActionRequestXMLDeserializer\n\nRemoved code duplication\n\nbp nova-tests-code-duplication\n\nChange-Id: Ib1d1b8b93f769b8dd8223dbbb3c42288254d8825\n'}, {'number': 6, 'created': '2013-07-16 14:50:05.000000000', 'files': ['nova/tests/api/openstack/compute/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9cb9c8a9b3186bbfcc016c731a6783bab94157f2', 'message': 'Code dedup in class TestServerActionRequestXMLDeserializer\n\nMoved duplicated requests and expected replies to functions\n-_generate_request()\n-_generate_expected()\n\nbp nova-tests-code-duplication\n\nChange-Id: Ib1d1b8b93f769b8dd8223dbbb3c42288254d8825\n'}]",4,35623,9cb9c8a9b3186bbfcc016c731a6783bab94157f2,33,11,6,7293,,,0,"Code dedup in class TestServerActionRequestXMLDeserializer

Moved duplicated requests and expected replies to functions
-_generate_request()
-_generate_expected()

bp nova-tests-code-duplication

Change-Id: Ib1d1b8b93f769b8dd8223dbbb3c42288254d8825
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/35623/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/test_servers.py'],1,d314745d901870553927e955352e77650a37e78d,bp/nova-tests-code-duplication," def _generate_request(self, action, str1, str2): return """""" <%(action)s xmlns=""http://docs.openstack.org/compute/api/v1.1"" %(disk_config)s=""MANUAL"" %(ref)s=""1""/>"""""" % \ {'action': action, 'disk_config': str1, 'ref': str2} def _generate_expected(self, action, ref): return { ""%s"" % action: { ""%s"" % ref: ""1"", }, } def test_rebuild_request(self): serial_request = self._generate_request(""rebuild"", ""OS-DCF:diskConfig"", ""imageRef"") request = self.deserializer.deserialize(serial_request) expected = self._generate_expected(""rebuild"", ""imageRef"") serial_request = self._generate_request(""rebuild"", ""auto_disk_config"", ""imageRef"") expected = self._generate_expected(""rebuild"", ""imageRef"") serial_request = self._generate_request(""resize"", ""OS-DCF:diskConfig"", ""flavorRef"") expected = self._generate_expected(""resize"", ""flavorRef"") serial_request = self._generate_request(""resize"", ""auto_disk_config"", ""flavorRef"") expected = self._generate_expected(""resize"", ""flavorRef"")"," def test_rebuild_request(self): serial_request = """""" <rebuild xmlns=""http://docs.openstack.org/compute/api/v1.1"" OS-DCF:diskConfig=""MANUAL"" imageRef=""1""/>"""""" request = self.deserializer.deserialize(serial_request) expected = { ""rebuild"": { ""imageRef"": ""1"", }, } serial_request = """""" <rebuild xmlns=""http://docs.openstack.org/compute/api/v1.1"" xmlns:OS-DCF=""http://docs.openstack.org/compute/ext/disk_config/api/v1.1"" auto_disk_config=""MANUAL"" imageRef=""1""/>"""""" expected = { ""rebuild"": { ""imageRef"": ""1"", ""OS-DCF:diskConfig"": ""MANUAL"", }, } serial_request = """""" <resize xmlns=""http://docs.openstack.org/compute/api/v1.1"" xmlns:OS-DCF=""http://docs.openstack.org/compute/ext/disk_config/api/v1.1"" OS-DCF:diskConfig=""MANUAL"" flavorRef=""1""/>"""""" expected = { ""resize"": { ""flavorRef"": ""1"", ""OS-DCF:diskConfig"": ""MANUAL"", }, } serial_request = """""" <resize xmlns=""http://docs.openstack.org/compute/api/v1.1"" xmlns:OS-DCF=""http://docs.openstack.org/compute/ext/disk_config/api/v1.1"" auto_disk_config=""MANUAL"" flavorRef=""1""/>"""""" expected = { ""resize"": { ""flavorRef"": ""1"", ""OS-DCF:diskConfig"": ""MANUAL"", }, }",27,41
openstack%2Fnova~master~Iade232267c58ae2cf3966829e660d3298070a3bf,openstack/nova,master,Iade232267c58ae2cf3966829e660d3298070a3bf,Avoid deleting user-provided Neutron ports if VM spawn fails,MERGED,2013-07-09 22:19:26.000000000,2013-07-16 19:39:54.000000000,2013-07-16 19:39:51.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-07-09 22:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eda76608de162ef694ab858702dff83bdd307a86', 'message': 'Avoid deleting user-provided Neutron ports if VM spawn fails\n\nIf the VM boot fails, resources like Neutron ports are destroyed.\nThis is particularly bad if the failure is transient and a\nrescheduling attempt is made. In this case the port no longer exist\nand the failure becomes self-inflicted. To avoid this, during the\ndeletion of VM resources, we look at the requested_networks passed\nby the user: if they contain port ids, we skip the destruction.\n\nAn optional parameter is added to RPC method deallocate_for_instance.\nRPC Network API is bumped to 1.10 to reflect this change, but the\nchange is backward compatible.\n\nFixes bug #1195490\n\nChange-Id: Iade232267c58ae2cf3966829e660d3298070a3bf\n'}, {'number': 2, 'created': '2013-07-09 22:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22affd863ec86cbbca3681507c1705203cd682a0', 'message': 'Avoid deleting user-provided Neutron ports if VM spawn fails\n\nIf the VM boot fails, resources like Neutron ports are destroyed.\nThis is particularly bad if the failure is transient and a\nrescheduling attempt is made. In this case the port no longer exist\nand the failure becomes self-inflicted. To avoid this, during the\ndeletion of VM resources, we look at the requested_networks passed\nby the user: if they contain port ids, we skip the destruction.\n\nAn optional parameter is added to RPC method deallocate_for_instance.\nRPC Network API is bumped to 1.10 to reflect this change, but the\nchange is backward compatible.\n\nFixes bug #1195490\n\nChange-Id: Iade232267c58ae2cf3966829e660d3298070a3bf\n'}, {'number': 3, 'created': '2013-07-15 23:32:55.000000000', 'files': ['nova/network/neutronv2/api.py', 'nova/network/rpcapi.py', 'nova/network/api.py', 'nova/network/manager.py', 'nova/tests/network/test_rpcapi.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a141206e9dfd31955b9b31d9e5a7f73bbd8510ca', 'message': 'Avoid deleting user-provided Neutron ports if VM spawn fails\n\nIf the VM boot fails, resources like Neutron ports are destroyed.\nThis is particularly bad if the failure is transient and a\nrescheduling attempt is made. In this case the port no longer exist\nand the failure becomes self-inflicted. To avoid this, during the\ndeletion of VM resources, we look at the requested_networks passed\nby the user: if they contain port ids, we skip the destruction.\n\nAn optional parameter is added to RPC method deallocate_for_instance.\nRPC Network API is bumped to 1.10 to reflect this change, but the\nchange is backward compatible.\n\nFixes bug #1195490\n\nChange-Id: Iade232267c58ae2cf3966829e660d3298070a3bf\n'}]",11,36354,a141206e9dfd31955b9b31d9e5a7f73bbd8510ca,18,6,3,748,,,0,"Avoid deleting user-provided Neutron ports if VM spawn fails

If the VM boot fails, resources like Neutron ports are destroyed.
This is particularly bad if the failure is transient and a
rescheduling attempt is made. In this case the port no longer exist
and the failure becomes self-inflicted. To avoid this, during the
deletion of VM resources, we look at the requested_networks passed
by the user: if they contain port ids, we skip the destruction.

An optional parameter is added to RPC method deallocate_for_instance.
RPC Network API is bumped to 1.10 to reflect this change, but the
change is backward compatible.

Fixes bug #1195490

Change-Id: Iade232267c58ae2cf3966829e660d3298070a3bf
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/36354/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/rpcapi.py', 'nova/network/api.py', 'nova/network/manager.py', 'nova/tests/network/test_rpcapi.py', 'nova/compute/manager.py', 'nova/network/quantumv2/api.py', 'nova/tests/compute/test_compute.py']",7,eda76608de162ef694ab858702dff83bdd307a86,bug/1195490," self.compute._deallocate_network(mox.IgnoreArg(), mox.IgnoreArg(), mox.IgnoreArg()) mox.IgnoreArg(), mox.IgnoreArg(), mox.IgnoreArg(), mox.IgnoreArg(),"," self.compute._deallocate_network(mox.IgnoreArg(), mox.IgnoreArg())",61,17
openstack%2Fnova~master~I304f31edec20b1293cf6c8de931415590fde6752,openstack/nova,master,I304f31edec20b1293cf6c8de931415590fde6752,Avoid shadowing Exception 'message' attribute,MERGED,2013-07-01 11:13:27.000000000,2013-07-16 19:39:32.000000000,2013-07-16 19:39:29.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 360}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1247}, {'_account_id': 2166}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-07-01 11:13:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fddf5450833a7f87a04d7fe84560211e8ea92ee', 'message': ""Avoid shadowing Exception 'message' attribute\n\nThe Exception class has a 'message' attribute:\n\n  >>> Exception('foo').message\n  'foo'\n\nhowever, we follow a pattern that results in the attribute being\nshadowed by a class attribute:\n\n  >>> class MyException(Exception):\n  ...     message = 'Foo %s'\n  ...     def __init__(self, bar):\n  ...         message = self.message % bar\n  ...         super(MyException, self).__init__(message)\n  ...\n  >>> MyException('bar').message\n  'Foo %s'\n\nwhereas, we obviously want behaviour like this:\n\n  >>> class MyException(Exception):\n  ...     msg_fmt = 'Foo %s'\n  ...     def __init__(self, bar):\n  ...         message = self.msg_fmt % bar\n  ...         super(MyException, self).__init__(message)\n  ...\n  >>> MyException('bar').message\n  'Foo bar'\n\nAvoid this shadowing by using 'msg_fmt' as the name of the class\nattribute. Add a test which fails without this fix.\n\nChange-Id: I304f31edec20b1293cf6c8de931415590fde6752\n""}, {'number': 2, 'created': '2013-07-04 06:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa1cedf381d993c1d507e64eff33bc201c0181a5', 'message': ""Avoid shadowing Exception 'message' attribute\n\nThe Exception class has a 'message' attribute:\n\n  >>> Exception('foo').message\n  'foo'\n\nThis attribute is deprecated since Python 2.6 and removed in Python 3:\n\n  http://www.python.org/dev/peps/pep-0352/#retracted-ideas\n\nTo help porting to Python 3, we should avoid using the .message\nattribute at all. However, confusingly, we follow a pattern that results\nin the attribute being shadowed by a class attribute:\n\n  >>> class MyException(Exception):\n  ...     message = 'Foo %s'\n  ...     def __init__(self, bar):\n  ...         message = self.message % bar\n  ...         super(MyException, self).__init__(message)\n  ...\n  >>> MyException('bar').message\n  'Foo %s'\n  >>> str(MyException('bar'))\n  'Foo bar'\n\nwhereas, we obviously want behaviour like this:\n\n  >>> class MyException(Exception):\n  ...     msg_fmt = 'Foo %s'\n  ...     def __init__(self, bar):\n  ...         message = self.msg_fmt % bar\n  ...         super(MyException, self).__init__(message)\n  ...\n  >>> MyException('bar').message\n  'Foo bar'\n  >>> str(MyException('bar'))\n  'Foo bar'\n\nAvoid this shadowing by using 'msg_fmt' as the name of the class\nattribute so it's more obvious where we're actually using the deprecated\n.message attribute.\n\nAlso add a test which fails without this fix.\n\nChange-Id: I304f31edec20b1293cf6c8de931415590fde6752\n""}, {'number': 3, 'created': '2013-07-04 06:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d66271dc84d8e6f0bdc5c1d3a24df3d6b3d77f39', 'message': ""Avoid shadowing Exception 'message' attribute\n\nThe Exception class has a 'message' attribute:\n\n  >>> Exception('foo').message\n  'foo'\n\nThis attribute is deprecated since Python 2.6 and removed in Python 3:\n\n  http://www.python.org/dev/peps/pep-0352/#retracted-ideas\n\nTo help porting to Python 3, we should avoid using the .message\nattribute at all. However, confusingly, we follow a pattern that results\nin the attribute being shadowed by a class attribute:\n\n  >>> class MyException(Exception):\n  ...     message = 'Foo %s'\n  ...     def __init__(self, bar):\n  ...         message = self.message % bar\n  ...         super(MyException, self).__init__(message)\n  ...\n  >>> MyException('bar').message\n  'Foo %s'\n  >>> str(MyException('bar'))\n  'Foo bar'\n\nwhereas, we obviously want behaviour like this:\n\n  >>> class MyException(Exception):\n  ...     msg_fmt = 'Foo %s'\n  ...     def __init__(self, bar):\n  ...         message = self.msg_fmt % bar\n  ...         super(MyException, self).__init__(message)\n  ...\n  >>> MyException('bar').message\n  'Foo bar'\n  >>> str(MyException('bar'))\n  'Foo bar'\n\nAvoid this shadowing by using 'msg_fmt' as the name of the class\nattribute so it's more obvious where we're actually using the deprecated\n.message attribute.\n\nAlso add a test which fails without this fix.\n\nChange-Id: I304f31edec20b1293cf6c8de931415590fde6752\n""}, {'number': 4, 'created': '2013-07-16 15:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eac11e0287165bdaceff1b439d0807879116ba51', 'message': ""Avoid shadowing Exception 'message' attribute\n\nThe Exception class has a 'message' attribute:\n\n  >>> Exception('foo').message\n  'foo'\n\nThis attribute is deprecated since Python 2.6 and removed in Python 3:\n\n  http://www.python.org/dev/peps/pep-0352/#retracted-ideas\n\nTo help porting to Python 3, we should avoid using the .message\nattribute at all. However, confusingly, we follow a pattern that results\nin the attribute being shadowed by a class attribute:\n\n  >>> class MyException(Exception):\n  ...     message = 'Foo %s'\n  ...     def __init__(self, bar):\n  ...         message = self.message % bar\n  ...         super(MyException, self).__init__(message)\n  ...\n  >>> MyException('bar').message\n  'Foo %s'\n  >>> str(MyException('bar'))\n  'Foo bar'\n\nwhereas, we obviously want behaviour like this:\n\n  >>> class MyException(Exception):\n  ...     msg_fmt = 'Foo %s'\n  ...     def __init__(self, bar):\n  ...         message = self.msg_fmt % bar\n  ...         super(MyException, self).__init__(message)\n  ...\n  >>> MyException('bar').message\n  'Foo bar'\n  >>> str(MyException('bar'))\n  'Foo bar'\n\nAvoid this shadowing by using 'msg_fmt' as the name of the class\nattribute so it's more obvious where we're actually using the deprecated\n.message attribute.\n\nAlso add a test which fails without this fix.\n\nChange-Id: I304f31edec20b1293cf6c8de931415590fde6752\n""}, {'number': 5, 'created': '2013-07-16 15:53:05.000000000', 'files': ['nova/virt/powervm/exception.py', 'nova/api/openstack/wsgi.py', 'nova/api/ec2/__init__.py', 'nova/exception.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py', 'nova/tests/test_exception.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/70569ae344bceb3794713abc5cb2c82e9671c37d', 'message': ""Avoid shadowing Exception 'message' attribute\n\nThe Exception class has a 'message' attribute:\n\n  >>> Exception('foo').message\n  'foo'\n\nThis attribute is deprecated since Python 2.6 and removed in Python 3:\n\n  http://www.python.org/dev/peps/pep-0352/#retracted-ideas\n\nTo help porting to Python 3, we should avoid using the .message\nattribute at all. However, confusingly, we follow a pattern that results\nin the attribute being shadowed by a class attribute:\n\n  >>> class MyException(Exception):\n  ...     message = 'Foo %s'\n  ...     def __init__(self, bar):\n  ...         message = self.message % bar\n  ...         super(MyException, self).__init__(message)\n  ...\n  >>> MyException('bar').message\n  'Foo %s'\n  >>> str(MyException('bar'))\n  'Foo bar'\n\nwhereas, we obviously want behaviour like this:\n\n  >>> class MyException(Exception):\n  ...     msg_fmt = 'Foo %s'\n  ...     def __init__(self, bar):\n  ...         message = self.msg_fmt % bar\n  ...         super(MyException, self).__init__(message)\n  ...\n  >>> MyException('bar').message\n  'Foo bar'\n  >>> str(MyException('bar'))\n  'Foo bar'\n\nAvoid this shadowing by using 'msg_fmt' as the name of the class\nattribute so it's more obvious where we're actually using the deprecated\n.message attribute.\n\nAlso add a test which fails without this fix.\n\nChange-Id: I304f31edec20b1293cf6c8de931415590fde6752\n""}]",4,35117,70569ae344bceb3794713abc5cb2c82e9671c37d,23,8,5,1247,,,0,"Avoid shadowing Exception 'message' attribute

The Exception class has a 'message' attribute:

  >>> Exception('foo').message
  'foo'

This attribute is deprecated since Python 2.6 and removed in Python 3:

  http://www.python.org/dev/peps/pep-0352/#retracted-ideas

To help porting to Python 3, we should avoid using the .message
attribute at all. However, confusingly, we follow a pattern that results
in the attribute being shadowed by a class attribute:

  >>> class MyException(Exception):
  ...     message = 'Foo %s'
  ...     def __init__(self, bar):
  ...         message = self.message % bar
  ...         super(MyException, self).__init__(message)
  ...
  >>> MyException('bar').message
  'Foo %s'
  >>> str(MyException('bar'))
  'Foo bar'

whereas, we obviously want behaviour like this:

  >>> class MyException(Exception):
  ...     msg_fmt = 'Foo %s'
  ...     def __init__(self, bar):
  ...         message = self.msg_fmt % bar
  ...         super(MyException, self).__init__(message)
  ...
  >>> MyException('bar').message
  'Foo bar'
  >>> str(MyException('bar'))
  'Foo bar'

Avoid this shadowing by using 'msg_fmt' as the name of the class
attribute so it's more obvious where we're actually using the deprecated
.message attribute.

Also add a test which fails without this fix.

Change-Id: I304f31edec20b1293cf6c8de931415590fde6752
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/35117/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/virt/powervm/exception.py', 'nova/api/ec2/__init__.py', 'nova/exception.py', 'nova/tests/compute/test_compute.py', 'nova/tests/test_exception.py']",6,8fddf5450833a7f87a04d7fe84560211e8ea92ee,," msg_fmt = ""default message"" msg_fmt = ""default message: %(code)s"" self.assertEquals(exc.message, 'default message: 500') msg_fmt = ""default message: %(mispelled_code)s"" self.assertEquals(exc.message, 'default message: blah') msg_fmt = ""some message"" msg_fmt = ""some message"" msg_fmt = ""some message %(somearg)s"""," message = ""default message"" message = ""default message: %(code)s"" message = ""default message: %(mispelled_code)s"" message = ""some message"" message = ""some message"" message = ""some message %(somearg)s""",288,288
openstack%2Ftempest~master~If1fbccd83407644b255a42f79134555b0f8eea50,openstack/tempest,master,If1fbccd83407644b255a42f79134555b0f8eea50,Extend the HACKING.rst with basic naming guidelines,ABANDONED,2013-07-12 09:47:33.000000000,2013-07-16 19:37:02.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5803}, {'_account_id': 6796}]","[{'number': 1, 'created': '2013-07-12 09:47:33.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2b67099c29159d71fec191849bc81db80e516497', 'message': 'Extend the HACKING.rst with basic naming guidelines\n\nExtend the HACKING.rst with module and class naming guidelines,\naccording to the pep8.\n\nChange-Id: If1fbccd83407644b255a42f79134555b0f8eea50\n'}]",0,36802,2b67099c29159d71fec191849bc81db80e516497,5,4,1,5803,,,0,"Extend the HACKING.rst with basic naming guidelines

Extend the HACKING.rst with module and class naming guidelines,
according to the pep8.

Change-Id: If1fbccd83407644b255a42f79134555b0f8eea50
",git fetch https://review.opendev.org/openstack/tempest refs/changes/02/36802/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,2b67099c29159d71fec191849bc81db80e516497,naming,Module and Class naming ----------------------- Try to follow the `PEP8 <http://www.python.org/dev/peps/pep-0008/#naming-conventions>`_ recommendations. Class names should use the CapWords convention. Package and module names are all-lowercase names. Underscores can be used in the module name if it improves the readability. ,,12,0
openstack%2Fnova~master~I9d573085964d2f62736413ca49391b19f058edb7,openstack/nova,master,I9d573085964d2f62736413ca49391b19f058edb7,Code dedup in class ImagesControllerTest,MERGED,2013-07-03 09:25:07.000000000,2013-07-16 19:36:39.000000000,2013-07-16 19:36:36.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 6509}, {'_account_id': 6938}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7727}]","[{'number': 1, 'created': '2013-07-03 09:25:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35f790ba409b301087fca96e67f6f6c6593a1242', 'message': 'Refactor class ImagesControllerTest\n\nRemoved code duplucation\n\nbp nova-tests-code-duplication\n\nChange-Id: I9d573085964d2f62736413ca49391b19f058edb7\n'}, {'number': 2, 'created': '2013-07-05 07:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9feca845c595386c05a4926cd88705912ee14a07', 'message': 'Refactor class ImagesControllerTest\n\nRemoved code duplication\n\nbp nova-tests-code-duplication\n\nChange-Id: I9d573085964d2f62736413ca49391b19f058edb7\n'}, {'number': 3, 'created': '2013-07-05 08:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f0527f2106a77ee17ec2c7d9cea46d063446e213', 'message': 'Refactor class ImagesControllerTest\n\nRemoved code duplication\n\nbp nova-tests-code-duplication\n\nChange-Id: I9d573085964d2f62736413ca49391b19f058edb7\n'}, {'number': 4, 'created': '2013-07-08 06:48:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb4a340011a435073b06e60e2a8b6d713e554e9e', 'message': 'Refactor class ImagesControllerTest\n\nRemoved code duplication\n\nbp nova-tests-code-duplication\n\nChange-Id: I9d573085964d2f62736413ca49391b19f058edb7\n'}, {'number': 5, 'created': '2013-07-16 14:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac135527243788241fe37aa4c4e1e70cbe83b140', 'message': 'Code dedup in class ImagesControllerTest\n\nMoved most commonly used values and dictionaries to setUp()\n\nbp nova-tests-code-duplication\n\nChange-Id: I9d573085964d2f62736413ca49391b19f058edb7\n'}, {'number': 6, 'created': '2013-07-16 17:34:15.000000000', 'files': ['nova/tests/api/openstack/compute/test_images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5c8e7b8d83d85185f165388ac29d0ecdd2641d8c', 'message': 'Code dedup in class ImagesControllerTest\n\nMoved most commonly used values and dictionaries to setUp()\n\nbp nova-tests-code-duplication\n\nChange-Id: I9d573085964d2f62736413ca49391b19f058edb7\n'}]",4,35469,5c8e7b8d83d85185f165388ac29d0ecdd2641d8c,39,10,6,7293,,,0,"Code dedup in class ImagesControllerTest

Moved most commonly used values and dictionaries to setUp()

bp nova-tests-code-duplication

Change-Id: I9d573085964d2f62736413ca49391b19f058edb7
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/35469/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/test_images.py'],1,35f790ba409b301087fca96e67f6f6c6593a1242,bp/nova-tests-code-duplication,"import copy self.uuid = 'fa95aaf5-ab3b-4cd8-88c0-2be7dd051aaf' self.url = '/v2/fake/images/detail?server=' + self.uuid self.server_uuid = ""aa640691-d1a7-4a67-9d3c-d35ee6b3cc74"" self.server_href = ""http://localhost/v2/fake/servers/"" + \ self.server_uuid self.server_bookmark = ""http://localhost/fake/servers/"" + \ self.server_uuid self.alternate = ""%s/fake/images/%s"" self.fake_req = fakes.HTTPRequest.blank('/v2/fake/images/123') self.actual_image = self.controller.show(self.fake_req, '124') self.expected_image_123 = { ""image"": {'id': '123', 'name': 'public image', 'metadata': {'key1': 'value1'}, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'ACTIVE', 'minDisk': 10, 'progress': 100, 'minRam': 128, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/123"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/123"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": self.alternate % (glance.generate_glance_url(), 123), }], self.expected_image_124 = { ""image"": {'id': '124', 'name': 'queued snapshot', 'metadata': { u'instance_uuid': self.server_uuid, u'user_id': u'fake', }, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'SAVING', 'progress': 25, 'minDisk': 0, 'minRam': 0, 'server': { 'id': self.server_uuid, ""links"": [{ ""rel"": ""self"", ""href"": self.server_href, }, { ""rel"": ""bookmark"", ""href"": self.server_bookmark, }], }, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/124"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/124"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": self.alternate % (glance.generate_glance_url(), 124), }], }, } self.image_service = self.mox.CreateMockAnything() def test_get_image(self): self.assertThat(self.actual_image, matchers.DictMatches(self.expected_image_124)) expected_image = copy.deepcopy(self.expected_image_124) expected_image[""image""][""links""][0][""href""] = ""https://zoo.com:42"" \ ""/v2/fake/images/124"" expected_image[""image""][""links""][1][""href""] = ""https://zoo.com:42"" \ ""/fake/images/124"" expected_image[""image""][""links""][2][""href""] = ""http://circus.com:34"" \ ""/fake/images/124"" expected_image[""image""][""server""][""links""][0][""href""] =\ ""https://zoo.com:42/v2/fake/servers/"" + self.server_uuid expected_image[""image""][""server""][""links""][1][""href""] =\ ""https://zoo.com:42/fake/servers/"" + self.server_uuid image_125 = copy.deepcopy(self.expected_image_124[""image""]) image_125['id'] = '125' image_125['name'] = 'saving snapshot' image_125['progress'] = 50 image_125[""links""][0][""href""] = ""http://localhost/v2/fake/images/125"" image_125[""links""][1][""href""] = ""http://localhost/fake/images/125"" image_125[""links""][2][""href""] = ""%s/fake/images/125"" %\ glance.generate_glance_url() image_126 = copy.deepcopy(self.expected_image_124[""image""]) image_126['id'] = '126' image_126['name'] = 'active snapshot' image_126['status'] = 'ACTIVE' image_126['progress'] = 100 image_126[""links""][0][""href""] = ""http://localhost/v2/fake/images/126"" image_126[""links""][1][""href""] = ""http://localhost/fake/images/126"" image_126[""links""][2][""href""] = ""%s/fake/images/126"" %\ glance.generate_glance_url() image_127 = copy.deepcopy(self.expected_image_124[""image""]) image_127['id'] = '127' image_127['name'] = 'killed snapshot' image_127['status'] = 'ERROR' image_127['progress'] = 0 image_127[""links""][0][""href""] = ""http://localhost/v2/fake/images/127"" image_127[""links""][1][""href""] = ""http://localhost/fake/images/127"" image_127[""links""][2][""href""] = ""%s/fake/images/127"" %\ glance.generate_glance_url() image_128 = copy.deepcopy(self.expected_image_124[""image""]) image_128['id'] = '128' image_128['name'] = 'deleted snapshot' image_128['status'] = 'DELETED' image_128['progress'] = 0 image_128[""links""][0][""href""] = ""http://localhost/v2/fake/images/128"" image_128[""links""][1][""href""] = ""http://localhost/fake/images/128"" image_128[""links""][2][""href""] = ""%s/fake/images/128"" %\ glance.generate_glance_url() image_129 = copy.deepcopy(self.expected_image_124[""image""]) image_129['id'] = '129' image_129['name'] = 'pending_delete snapshot' image_129['status'] = 'DELETED' image_129['progress'] = 0 image_129[""links""][0][""href""] = ""http://localhost/v2/fake/images/129"" image_129[""links""][1][""href""] = ""http://localhost/fake/images/129"" image_129[""links""][2][""href""] = ""%s/fake/images/129"" %\ glance.generate_glance_url() image_130 = copy.deepcopy(self.expected_image_123[""image""]) image_130['id'] = '130' image_130['name'] = None image_130['metadata'] = {} image_130['minDisk'] = 0 image_130['minRam'] = 0 image_130[""links""][0][""href""] = ""http://localhost/v2/fake/images/130"" image_130[""links""][1][""href""] = ""http://localhost/fake/images/130"" image_130[""links""][2][""href""] = ""%s/fake/images/130"" %\ glance.generate_glance_url() expected = [self.expected_image_123[""image""], self.expected_image_124[""image""], image_125, image_126, image_127, image_128, image_129, image_130] expected = [self.expected_image_123[""image""], self.expected_image_124[""image""]] self.image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=self.image_service) self.image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=self.image_service) self.image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=self.image_service) ref = 'http://localhost:8774/servers/' + self.uuid filters = {'property-instance_uuid': self.uuid} request = fakes.HTTPRequest.blank(self.url) self.image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=self.image_service) filters = {'property-instance_uuid': self.uuid} request = fakes.HTTPRequest.blank(self.url) self.image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=self.image_service) self.image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=self.image_service) self.image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=self.image_service) self.image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=self.image_service) self.image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=self.image_service) '/v2/fake/images/%s' % deleted_image_id) request, '%s' % deleted_image_id)"," def test_get_image(self): fake_req = fakes.HTTPRequest.blank('/v2/fake/images/123') actual_image = self.controller.show(fake_req, '124') href = ""http://localhost/v2/fake/images/124"" bookmark = ""http://localhost/fake/images/124"" alternate = ""%s/fake/images/124"" % glance.generate_glance_url() server_uuid = ""aa640691-d1a7-4a67-9d3c-d35ee6b3cc74"" server_href = ""http://localhost/v2/fake/servers/"" + server_uuid server_bookmark = ""http://localhost/fake/servers/"" + server_uuid expected_image = { ""image"": { ""id"": ""124"", ""name"": ""queued snapshot"", ""updated"": NOW_API_FORMAT, ""created"": NOW_API_FORMAT, ""status"": ""SAVING"", ""progress"": 25, ""minDisk"": 0, ""minRam"": 0, 'server': { 'id': server_uuid, ""links"": [{ ""rel"": ""self"", ""href"": server_href, }, { ""rel"": ""bookmark"", ""href"": server_bookmark, }], }, ""metadata"": { ""instance_uuid"": server_uuid, ""user_id"": ""fake"", }, ""links"": [{ ""rel"": ""self"", ""href"": href, }, { ""rel"": ""bookmark"", ""href"": bookmark, }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": alternate }], self.assertThat(actual_image, matchers.DictMatches(expected_image)) href = ""https://zoo.com:42/v2/fake/images/124"" bookmark = ""https://zoo.com:42/fake/images/124"" alternate = ""http://circus.com:34/fake/images/124"" server_uuid = ""aa640691-d1a7-4a67-9d3c-d35ee6b3cc74"" server_href = ""https://zoo.com:42/v2/fake/servers/"" + server_uuid server_bookmark = ""https://zoo.com:42/fake/servers/"" + server_uuid expected_image = { ""image"": { ""id"": ""124"", ""name"": ""queued snapshot"", ""updated"": NOW_API_FORMAT, ""created"": NOW_API_FORMAT, ""status"": ""SAVING"", ""progress"": 25, ""minDisk"": 0, ""minRam"": 0, 'server': { 'id': server_uuid, ""links"": [{ ""rel"": ""self"", ""href"": server_href, }, { ""rel"": ""bookmark"", ""href"": server_bookmark, }], }, ""metadata"": { ""instance_uuid"": server_uuid, ""user_id"": ""fake"", }, ""links"": [{ ""rel"": ""self"", ""href"": href, }, { ""rel"": ""bookmark"", ""href"": bookmark, }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": alternate }], }, } server_uuid = ""aa640691-d1a7-4a67-9d3c-d35ee6b3cc74"" server_href = ""http://localhost/v2/fake/servers/"" + server_uuid server_bookmark = ""http://localhost/fake/servers/"" + server_uuid alternate = ""%s/fake/images/%s"" expected = [{ 'id': '123', 'name': 'public image', 'metadata': {'key1': 'value1'}, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'ACTIVE', 'progress': 100, 'minDisk': 10, 'minRam': 128, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/123"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/123"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": alternate % (glance.generate_glance_url(), 123), }], }, { 'id': '124', 'name': 'queued snapshot', 'metadata': { u'instance_uuid': server_uuid, u'user_id': u'fake', }, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'SAVING', 'progress': 25, 'minDisk': 0, 'minRam': 0, 'server': { 'id': server_uuid, ""links"": [{ ""rel"": ""self"", ""href"": server_href, }, { ""rel"": ""bookmark"", ""href"": server_bookmark, }], }, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/124"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/124"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": alternate % (glance.generate_glance_url(), 124), }], }, { 'id': '125', 'name': 'saving snapshot', 'metadata': { u'instance_uuid': server_uuid, u'user_id': u'fake', }, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'SAVING', 'progress': 50, 'minDisk': 0, 'minRam': 0, 'server': { 'id': server_uuid, ""links"": [{ ""rel"": ""self"", ""href"": server_href, }, { ""rel"": ""bookmark"", ""href"": server_bookmark, }], }, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/125"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/125"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": ""%s/fake/images/125"" % glance.generate_glance_url() }], }, { 'id': '126', 'name': 'active snapshot', 'metadata': { u'instance_uuid': server_uuid, u'user_id': u'fake', }, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'ACTIVE', 'progress': 100, 'minDisk': 0, 'minRam': 0, 'server': { 'id': server_uuid, ""links"": [{ ""rel"": ""self"", ""href"": server_href, }, { ""rel"": ""bookmark"", ""href"": server_bookmark, }], }, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/126"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/126"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": ""%s/fake/images/126"" % glance.generate_glance_url() }], }, { 'id': '127', 'name': 'killed snapshot', 'metadata': { u'instance_uuid': server_uuid, u'user_id': u'fake', }, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'ERROR', 'progress': 0, 'minDisk': 0, 'minRam': 0, 'server': { 'id': server_uuid, ""links"": [{ ""rel"": ""self"", ""href"": server_href, }, { ""rel"": ""bookmark"", ""href"": server_bookmark, }], }, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/127"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/127"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": ""%s/fake/images/127"" % glance.generate_glance_url() }], }, { 'id': '128', 'name': 'deleted snapshot', 'metadata': { u'instance_uuid': server_uuid, u'user_id': u'fake', }, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'DELETED', 'progress': 0, 'minDisk': 0, 'minRam': 0, 'server': { 'id': server_uuid, ""links"": [{ ""rel"": ""self"", ""href"": server_href, }, { ""rel"": ""bookmark"", ""href"": server_bookmark, }], }, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/128"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/128"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": ""%s/fake/images/128"" % glance.generate_glance_url() }], }, { 'id': '129', 'name': 'pending_delete snapshot', 'metadata': { u'instance_uuid': server_uuid, u'user_id': u'fake', }, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'DELETED', 'progress': 0, 'minDisk': 0, 'minRam': 0, 'server': { 'id': server_uuid, ""links"": [{ ""rel"": ""self"", ""href"": server_href, }, { ""rel"": ""bookmark"", ""href"": server_bookmark, }], }, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/129"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/129"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": ""%s/fake/images/129"" % glance.generate_glance_url() }], }, { 'id': '130', 'name': None, 'metadata': {}, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'ACTIVE', 'progress': 100, 'minDisk': 0, 'minRam': 0, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/130"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/130"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": ""%s/fake/images/130"" % glance.generate_glance_url() }], }, ] server_uuid = ""aa640691-d1a7-4a67-9d3c-d35ee6b3cc74"" server_href = ""http://localhost/v2/fake/servers/"" + server_uuid server_bookmark = ""http://localhost/fake/servers/"" + server_uuid alternate = ""%s/fake/images/%s"" expected = [{ 'id': '123', 'name': 'public image', 'metadata': {'key1': 'value1'}, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'ACTIVE', 'minDisk': 10, 'progress': 100, 'minRam': 128, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/123"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/123"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": alternate % (glance.generate_glance_url(), 123), }], }, { 'id': '124', 'name': 'queued snapshot', 'metadata': { u'instance_uuid': server_uuid, u'user_id': u'fake', }, 'updated': NOW_API_FORMAT, 'created': NOW_API_FORMAT, 'status': 'SAVING', 'minDisk': 0, 'progress': 25, 'minRam': 0, 'server': { 'id': server_uuid, ""links"": [{ ""rel"": ""self"", ""href"": server_href, }, { ""rel"": ""bookmark"", ""href"": server_bookmark, }], }, ""links"": [{ ""rel"": ""self"", ""href"": ""http://localhost/v2/fake/images/124"", }, { ""rel"": ""bookmark"", ""href"": ""http://localhost/fake/images/124"", }, { ""rel"": ""alternate"", ""type"": ""application/vnd.openstack.image"", ""href"": alternate % (glance.generate_glance_url(), 124), }], }] image_service = self.mox.CreateMockAnything() image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=image_service) image_service = self.mox.CreateMockAnything() image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=image_service) image_service = self.mox.CreateMockAnything() image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=image_service) image_service = self.mox.CreateMockAnything() uuid = 'fa95aaf5-ab3b-4cd8-88c0-2be7dd051aaf' ref = 'http://localhost:8774/servers/' + uuid url = '/v2/fake/images/detail?server=' + ref filters = {'property-instance_uuid': uuid} request = fakes.HTTPRequest.blank(url) image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=image_service) image_service = self.mox.CreateMockAnything() uuid = 'fa95aaf5-ab3b-4cd8-88c0-2be7dd051aaf' url = '/v2/fake/images/detail?server=' + uuid filters = {'property-instance_uuid': uuid} request = fakes.HTTPRequest.blank(url) image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=image_service) image_service = self.mox.CreateMockAnything() image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=image_service) image_service = self.mox.CreateMockAnything() image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=image_service) image_service = self.mox.CreateMockAnything() image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=image_service) image_service = self.mox.CreateMockAnything() image_service.detail(context, filters=filters).AndReturn([]) controller = images.Controller(image_service=image_service) '/v2/fake/images/%s' % deleted_image_id) request, '%s' % deleted_image_id)",190,484
openstack%2Fnova~master~I6e0c6eaa38863495bcabf2e6ce082589becdfe82,openstack/nova,master,I6e0c6eaa38863495bcabf2e6ce082589becdfe82,Add API-v3 merged core API into core API list,MERGED,2013-07-10 12:39:55.000000000,2013-07-16 19:36:18.000000000,2013-07-16 19:36:15.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5174}, {'_account_id': 5441}]","[{'number': 1, 'created': '2013-07-10 12:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07b19b2be5af3dd06ad5974ce46d6fa260290c40', 'message': 'Add API-v3 merged core API into core API list\n\nThe follow core API consoles, ips, flavors and extensions were merged but never\nadd added to Core API list.\nRelated to bp nova-v3-api\n\nChange-Id: I6e0c6eaa38863495bcabf2e6ce082589becdfe82\n'}, {'number': 2, 'created': '2013-07-10 14:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1674fd444efe83fbe9c6bccd8ebeb092800de100', 'message': 'Add API-v3 merged core API into core API list\n\nThe follow core API consoles, ips, flavors and extensions were merged but never\nadd added to Core API list.\nRelated to bp nova-v3-api\n\nChange-Id: I6e0c6eaa38863495bcabf2e6ce082589becdfe82\n'}, {'number': 3, 'created': '2013-07-10 17:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff0aec53061335db6662aeb9731dba1960f8ff24', 'message': 'Add API-v3 merged core API into core API list\n\nThe follow core API consoles, ips, flavors and extensions were merged but never\nadd added to Core API list.\nRelated to bp nova-v3-api\n\nChange-Id: I6e0c6eaa38863495bcabf2e6ce082589becdfe82\n'}, {'number': 4, 'created': '2013-07-12 14:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb926fae5cf7a8651c90546f47aaac0bbb3281e9', 'message': 'Add API-v3 merged core API into core API list\n\nThe follow core API consoles, ips, flavors and extensions were merged but never\nadd added to Core API list.\nRelated to bp nova-v3-api\n\nChange-Id: I6e0c6eaa38863495bcabf2e6ce082589becdfe82\n'}, {'number': 5, 'created': '2013-07-16 16:22:00.000000000', 'files': ['nova/api/openstack/__init__.py', 'nova/tests/api/openstack/compute/test_v3_extensions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/459fdad45c30965c5da098e072fe7525b17ece63', 'message': ""Add API-v3 merged core API into core API list\n\nThis completes core API list, so if one of those could not be loaded\nan exception will be raised.\n\nThe changes on the tests were necessary to avoid whitelist or blacklist all the\ncore API or get an exception cause one of them wasn't loadi\nAlso to fix a bug in the tests that override the black or white lists options\nand it wasn't in list format causing, for instance, that ips API match with\nos-fixed-ips.\n\nRelated to bp nova-v3-api\n\nChange-Id: I6e0c6eaa38863495bcabf2e6ce082589becdfe82\n""}]",3,36453,459fdad45c30965c5da098e072fe7525b17ece63,21,7,5,5174,,,0,"Add API-v3 merged core API into core API list

This completes core API list, so if one of those could not be loaded
an exception will be raised.

The changes on the tests were necessary to avoid whitelist or blacklist all the
core API or get an exception cause one of them wasn't loadi
Also to fix a bug in the tests that override the black or white lists options
and it wasn't in list format causing, for instance, that ips API match with
os-fixed-ips.

Related to bp nova-v3-api

Change-Id: I6e0c6eaa38863495bcabf2e6ce082589becdfe82
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/36453/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/__init__.py'],1,07b19b2be5af3dd06ad5974ce46d6fa260290c40,bp/nova-v3-api,"API_V3_CORE_EXTENSIONS = set(['consoles', 'extensions', 'flavors', 'ips', 'servers'])",API_V3_CORE_EXTENSIONS = set(['servers']),2,1
openstack%2Fswift~master~I1041b31413cd0c39000317cc57a8c27816e1dfe8,openstack/swift,master,I1041b31413cd0c39000317cc57a8c27816e1dfe8,Move replication allow method to decorators,MERGED,2013-05-23 16:26:25.000000000,2013-07-16 19:27:59.000000000,2013-07-16 19:27:59.000000000,"[{'_account_id': 3}, {'_account_id': 860}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 1531}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 6529}, {'_account_id': 6577}]","[{'number': 1, 'created': '2013-05-23 16:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/853cabdae58f40a739e41b78b39c73117410e891', 'message': 'Move replication allow method to public decorators\n\nMove logic of allowed methods for replication and object servers to\nexisted logic of allowing methods by decorators.\n* Remove allow methods\n* Add option into public decorator, which shows if this method for\n  replication server or for object one.\n* Fix test\n\nChange-Id: I1041b31413cd0c39000317cc57a8c27816e1dfe8\n'}, {'number': 2, 'created': '2013-05-24 15:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/32f439a579ce309c02c1a1c41e33af5e12de1c23', 'message': 'Move replication allow method to public decorators\n\nMove logic of allowed methods for replication and object servers to\nexisted logic of allowing methods by decorators.\n* Remove allow methods\n* Add option into public decorator, which shows if this method for\n  replication server or for object one.\n* Fix test\n\nChange-Id: I1041b31413cd0c39000317cc57a8c27816e1dfe8\n'}, {'number': 3, 'created': '2013-05-27 12:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3c711a334fd2bc906dd325d8f28835b1aed98eed', 'message': 'Move replication allow method to public decorators\n\nMove logic of allowed methods for replication and object servers to\nexisted logic of allowing methods by decorators.\n* Remove allow methods\n* Add option into public decorator, which shows if this method for\n  replication server or for object one.\n* Fix test\n\nChange-Id: I1041b31413cd0c39000317cc57a8c27816e1dfe8\n'}, {'number': 4, 'created': '2013-05-27 14:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3a3fabbd85b47a14579f103abdeab71566cf113d', 'message': 'Move replication allow method to decorators\n\nRemove logic of allowed methods list from object, container and account\nservers. Instead of it add replicator decorator to utils and use new\ndecorator for REPLICATE methods in object/account/container servers.\nThis decorator mark method as special for using only by replication\nserver.\n\nIf option replication_server not used then this mechanism did not\nworking. And if such option is set (not None) then this server is either\nreplication (option value is True) and should use ONLY special methods.\nOr it is object/account/container (option value is False) and should NOT\nuse special methods.\n\nChange-Id: I1041b31413cd0c39000317cc57a8c27816e1dfe8\n'}, {'number': 5, 'created': '2013-05-28 08:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/11e70f2e14191d7acc2a49b6397f51f17b9e4120', 'message': 'Move replication allow method to decorators\n\nRemove logic of allowed methods list from object, container and account\nservers. Instead of it add replicator decorator to utils and use new\ndecorator for REPLICATE methods in object/account/container servers.\nThis decorator mark method as special for using only by replication\nserver.\n\nIf option replication_server not used then this mechanism did not\nworking. And if such option is set (not None) then this server is either\nreplication (option value is True) and should use ONLY special methods.\nOr it is object/account/container (option value is False) and should NOT\nuse special methods.\n\nChange-Id: I1041b31413cd0c39000317cc57a8c27816e1dfe8\n'}, {'number': 6, 'created': '2013-06-28 10:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d9b675029c827e08b270370081d8016cfe9631c3', 'message': 'Move replication allow method to decorators\n\nRemove logic of allowed methods list from object, container and account\nservers. Instead of it add replicator decorator to utils and use new\ndecorator for REPLICATE methods in object/account/container servers.\nThis decorator mark method as special for using only by replication\nserver.\n\nIf option replication_server not used then this mechanism did not\nworking. And if such option is set (not None) then this server is either\nreplication (option value is True) and should use ONLY special methods.\nOr it is object/account/container (option value is False) and should NOT\nuse special methods.\n\nChange-Id: I1041b31413cd0c39000317cc57a8c27816e1dfe8\n'}, {'number': 7, 'created': '2013-06-28 13:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c4d6634277b970b8a66e2d6fed872c2b0ba4e9d6', 'message': 'Move replication allow method to decorators\n\nRemove logic of allowed methods list from object, container and account\nservers. Instead of it add replicator decorator to utils and use new\ndecorator for REPLICATE methods in object/account/container servers.\nThis decorator mark method as special for using only by replication\nserver.\n\nIf option replication_server not used then this mechanism did not\nworking. And if such option is set (not None) then this server is either\nreplication (option value is True) and should use ONLY special methods.\nOr it is object/account/container (option value is False) and should NOT\nuse special methods.\n\nChange-Id: I1041b31413cd0c39000317cc57a8c27816e1dfe8\n'}, {'number': 8, 'created': '2013-07-02 10:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2a489baa24611ebc5948bd57a541f0ba37ff79e6', 'message': 'Move replication allow method to decorators\n\nRemove logic of allowed methods list from object, container and account\nservers. Instead of it add replicator decorator to utils and use new\ndecorator for REPLICATE methods in object/account/container servers.\nThis decorator mark method as special for using only by replication\nserver.\n\nIf option replication_server not used then this mechanism did not\nworking. And if such option is set (not None) then this server is either\nreplication (option value is True) and should use ONLY special methods.\nOr it is object/account/container (option value is False) and should NOT\nuse special methods.\n\nChange-Id: I1041b31413cd0c39000317cc57a8c27816e1dfe8\n'}, {'number': 9, 'created': '2013-07-12 07:46:37.000000000', 'files': ['swift/obj/server.py', 'test/unit/account/test_server.py', 'swift/container/server.py', 'swift/common/utils.py', 'test/unit/obj/test_server.py', 'swift/account/server.py', 'test/unit/container/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/bc08215f839a0845a29e016b74677d56b4808883', 'message': 'Move replication allow method to decorators\n\nRemove logic of allowed methods list from object, container and account\nservers. Instead of it add replicator decorator to utils and use new\ndecorator for REPLICATE methods in object/account/container servers.\nThis decorator mark method as special for usfor use only by the\nreplication.\n\nIf the option replication_server is not used, then this mechanism is not\nenabled. If the replicaton_server option is set (not None) then the\nrespective server is a replicator (option value is True) and should use\nONLY the methods marked for replication server using the decorator, or\nit is a normal server type and should NOT use methods marked for the\nreplication server.\n\nChange-Id: I1041b31413cd0c39000317cc57a8c27816e1dfe8\n'}]",35,30292,bc08215f839a0845a29e016b74677d56b4808883,54,10,9,6529,,,0,"Move replication allow method to decorators

Remove logic of allowed methods list from object, container and account
servers. Instead of it add replicator decorator to utils and use new
decorator for REPLICATE methods in object/account/container servers.
This decorator mark method as special for usfor use only by the
replication.

If the option replication_server is not used, then this mechanism is not
enabled. If the replicaton_server option is set (not None) then the
respective server is a replicator (option value is True) and should use
ONLY the methods marked for replication server using the decorator, or
it is a normal server type and should NOT use methods marked for the
replication server.

Change-Id: I1041b31413cd0c39000317cc57a8c27816e1dfe8
",git fetch https://review.opendev.org/openstack/swift refs/changes/92/30292/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/server.py', 'swift/obj/server.py', 'test/unit/account/test_server.py', 'swift/common/utils.py', 'test/unit/obj/test_server.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'swift/proxy/controllers/account.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/controllers/container.py', 'swift/proxy/controllers/base.py']",11,853cabdae58f40a739e41b78b39c73117410e891,Change_public_decorators-2, @public() @public() @public(), @public @public @public,118,148
openstack%2Foslo-incubator~master~I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c,openstack/oslo-incubator,master,I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c,Add config for amqp durable/auto_delete queues,MERGED,2013-05-17 23:09:17.000000000,2013-07-16 19:04:05.000000000,2013-07-16 19:04:05.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2967}, {'_account_id': 4912}, {'_account_id': 5652}, {'_account_id': 6857}, {'_account_id': 6928}, {'_account_id': 7494}]","[{'number': 1, 'created': '2013-05-17 23:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/dbf8dc9574e7004f2fcca06825ff7a004439c5f1', 'message': 'Add a config option to make qpid queues durable\n\nThis patch makes a new config option in nova.conf (qpid_durable_queues) that\nenables durable queues in qpid.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 2, 'created': '2013-05-17 23:20:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/577837774403ed6e2a36dc19ce4d373a436b1c77', 'message': 'Add a config option to make qpid queues durable\n\nThis patch makes a new config option in nova.conf (qpid_durable_queues) that\nenables durable queues in qpid.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 3, 'created': '2013-05-18 00:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a0b3a3cf103501a8ee208a1deb8b08eb35276cf9', 'message': 'Add config for qpid durable/auto_delete queues\n\nThis patch makes two new config options in nova.conf (qpid_durable_queues and\nqpid_auto_delete) that enable durable and auto delete queues in qpid.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 4, 'created': '2013-05-18 01:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/39e99294dac0b3c03b3037c8d0311b88f821a7e4', 'message': 'Add config for qpid durable/auto_delete queues\n\nThis patch makes two new config options in nova.conf (qpid_durable_queues and\nqpid_auto_delete) that enable durable and auto delete queues in qpid.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 5, 'created': '2013-05-18 01:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/df76ae60419778ed5e85762272c9f161ded433e8', 'message': 'Add config for qpid durable/auto_delete queues\n\nThis patch makes two new config options in nova.conf (qpid_durable_queues and\nqpid_auto_delete) that enable durable and auto delete queues in qpid.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 6, 'created': '2013-05-20 17:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d46a66b4d3403c3d99319a3c42f149bfacd67749', 'message': 'Add config for qpid durable/auto_delete queues\n\nThis patch makes two new config options in nova.conf (qpid_durable_queues and\nqpid_auto_delete) that enable durable and auto delete queues in qpid.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 7, 'created': '2013-05-29 21:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/cb9897f41eb2a6086d0edae729e7b61d228efe10', 'message': 'Add config for qpid durable/auto_delete queues\n\nThis patch makes two new config options in nova.conf (qpid_durable_queues and\nqpid_auto_delete) that enable durable and auto delete queues in qpid.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 8, 'created': '2013-05-30 20:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/968686e6a3580f6f2cc7cc207f2ab0f998cefa6e', 'message': 'Add config for qpid durable/auto_delete queues\n\nThis patch makes two new config options in nova.conf (qpid_durable_queues and\nqpid_auto_delete) that enable durable and auto delete queues in qpid.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 9, 'created': '2013-05-30 20:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3cbc1f07239ef306b17b3a11abcb973022996a68', 'message': 'Add config for qpid durable/auto_delete queues\n\nThis patch makes two new config options (amqp_durable_queues and\namqp_auto_delete) that enable durable and auto delete queues in amqp.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 10, 'created': '2013-05-30 20:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/58ea2e58f94dbf97321cd16a7f46d08b58f598f3', 'message': 'Add config for amqp durable/auto_delete queues\n\nThis patch makes two new config options (amqp_durable_queues and\namqp_auto_delete) that enable durable and auto delete queues in amqp.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 11, 'created': '2013-05-31 16:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2577dcea75cb85d75dea86a146e2ff854061c195', 'message': 'Add config for amqp durable/auto_delete queues\n\nThis patch makes two new config options (amqp_durable_queues and\namqp_auto_delete) that enable durable and auto delete queues in amqp.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 12, 'created': '2013-06-03 15:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/caecae45a31417fb16db6f275d1fdb1abad2aad1', 'message': 'Add config for amqp durable/auto_delete queues\n\nThis patch makes two new config options (amqp_durable_queues and\namqp_auto_delete) that enable durable and auto delete queues in amqp.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 13, 'created': '2013-06-03 22:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d1c8c9199436b7065f64ae943e9697597bd8951b', 'message': 'Add config for amqp durable/auto_delete queues\n\nThis patch makes two new config options (amqp_durable_queues and\namqp_auto_delete) that enable durable and auto delete queues in amqp.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 14, 'created': '2013-07-12 22:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/fcf82812ea3d5aa4f6ff554af1cfd8456534b7bb', 'message': 'Add config for amqp durable/auto_delete queues\n\nThis patch makes two new config options (amqp_durable_queues and\namqp_auto_delete) that enable durable and auto delete queues in amqp.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 15, 'created': '2013-07-15 15:22:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9c6ead3370d331dadff9c83937a61ed66bef1646', 'message': 'Add config for amqp durable/auto_delete queues\n\nThis patch makes two new config options (amqp_durable_queues and\namqp_auto_delete) that enable durable and auto delete queues in amqp.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}, {'number': 16, 'created': '2013-07-16 15:53:10.000000000', 'files': ['openstack/common/rpc/impl_kombu.py', 'openstack/common/rpc/impl_qpid.py', 'openstack/common/rpc/amqp.py', 'tests/unit/rpc/test_qpid.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/5ff534d15a136decd6d076fc1f2cd066806843c9', 'message': 'Add config for amqp durable/auto_delete queues\n\nThis patch makes two new config options (amqp_durable_queues and\namqp_auto_delete) that enable durable and auto delete queues in amqp.\n\nFixes: bug #1033915\nDocImpact\nChange-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c\n'}]",16,29617,5ff534d15a136decd6d076fc1f2cd066806843c9,73,11,16,6857,,,0,"Add config for amqp durable/auto_delete queues

This patch makes two new config options (amqp_durable_queues and
amqp_auto_delete) that enable durable and auto delete queues in amqp.

Fixes: bug #1033915
DocImpact
Change-Id: I56e5c92f1ed8ac2d429a306f3f38a963f0138c6c
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/17/29617/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/rpc/impl_qpid.py'],1,dbf8dc9574e7004f2fcca06825ff7a004439c5f1,bug/1033915," cfg.BoolOpt('qpid_durable_queues', default=False, help='use durable queues in Qpid'), # Default options options = { 'durable': conf.qpid_durable_queues, } { ""exclusive"": True, ""durable"": options['durable'], }) # Default options options = { 'durable': conf.qpid_durable_queues, } {}, name or topic, { ""durable"": options['durable'], }) Qpid options may be passed as keyword args to override defaults options = { 'durable': conf.qpid_durable_queues, } ""%s/%s"" % (exchange_name, topic), { ""durable"": options['durable'], })"," {""exclusive"": True}) {}, name or topic, {}) ""%s/%s"" % (exchange_name, topic))",28,3
openstack%2Fneutron~master~I086353c93fae0f6ec74d16a485c215c1b3815ee6,openstack/neutron,master,I086353c93fae0f6ec74d16a485c215c1b3815ee6,Enable logging before using it,MERGED,2013-07-12 09:19:44.000000000,2013-07-16 19:03:52.000000000,2013-07-16 19:03:51.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-12 09:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8966897c9330299e17c69a98bc442779961c7d40', 'message': 'Eable logging before using it\n\nBug #1200530\n\nChange-Id: I086353c93fae0f6ec74d16a485c215c1b3815ee6\n'}, {'number': 2, 'created': '2013-07-12 09:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c518f72edb221fc8ed04c87805b8d717c982dcf4', 'message': 'Eable logging before using it\n\nBug #1200530\n\nChange-Id: I086353c93fae0f6ec74d16a485c215c1b3815ee6\n'}, {'number': 3, 'created': '2013-07-13 01:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/23271a6c75c9c1ba0f7c42cf7e95bbad28c9bb40', 'message': 'Eable logging before using it\n\nBug #1200530\n\nChange-Id: I086353c93fae0f6ec74d16a485c215c1b3815ee6\n'}, {'number': 4, 'created': '2013-07-13 07:36:55.000000000', 'files': ['neutron/services/loadbalancer/drivers/haproxy/agent.py', 'neutron/db/migration/cli.py', 'neutron/common/config.py', 'neutron/service.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/47381ff70a9be29a1a3d853c4ff84f51a8c8618b', 'message': 'Enable logging before using it\n\nBug #1200530\n\nChange-Id: I086353c93fae0f6ec74d16a485c215c1b3815ee6\n'}]",3,36796,47381ff70a9be29a1a3d853c4ff84f51a8c8618b,17,7,4,2874,,,0,"Enable logging before using it

Bug #1200530

Change-Id: I086353c93fae0f6ec74d16a485c215c1b3815ee6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/36796/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/loadbalancer/drivers/haproxy/agent.py', 'neutron/db/migration/cli.py', 'neutron/common/config.py', 'neutron/service.py']",4,8966897c9330299e17c69a98bc442779961c7d40,bug/1200530,from neutron.common import legacy legacy.modernize_quantum_config(cfg.CONF),,8,5
openstack%2Fopenstack-manuals~master~Ied74adef5d3a32d6515e5de46710e8fc0e9f38a4,openstack/openstack-manuals,master,Ied74adef5d3a32d6515e5de46710e8fc0e9f38a4,Fix bug 1197651 account-reaper warns if not making progress,MERGED,2013-07-11 21:28:30.000000000,2013-07-16 19:02:09.000000000,2013-07-16 19:02:09.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 8047}]","[{'number': 1, 'created': '2013-07-11 21:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/790be6012c9dad033cf6c847c14b8167885569f2', 'message': 'Fix bug 1197651 account-reaper warns if not making progress\n\nIntroduce reap_warn after config variable to determine message timing\n\nChange-Id: Ied74adef5d3a32d6515e5de46710e8fc0e9f38a4\n'}, {'number': 2, 'created': '2013-07-16 14:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ef42e43c0da79174199e28549bdb98b7a7945fee', 'message': 'Fix bug 1197651 account-reaper warns if not making progress\n\nIntroduce reap_warn after config variable to determine message timing\npatchset 2: diane fleming - editorial changes and spellcheck of file\n\nChange-Id: Ied74adef5d3a32d6515e5de46710e8fc0e9f38a4\n'}, {'number': 3, 'created': '2013-07-16 18:52:50.000000000', 'files': ['doc/src/docbkx/openstack-object-storage-admin/objectstorageadmin.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b132332c97b835f9625f25c43df943745dadf717', 'message': 'Fix bug 1197651 account-reaper warns if not making progress\n\nIntroduce reap_warn after config variable to determine message timing\npatchset 2: diane fleming - editorial changes and spellcheck of file\n\nChange-Id: Ied74adef5d3a32d6515e5de46710e8fc0e9f38a4\n'}]",1,36737,b132332c97b835f9625f25c43df943745dadf717,14,4,3,8047,,,0,"Fix bug 1197651 account-reaper warns if not making progress

Introduce reap_warn after config variable to determine message timing
patchset 2: diane fleming - editorial changes and spellcheck of file

Change-Id: Ied74adef5d3a32d6515e5de46710e8fc0e9f38a4
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/37/36737/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-object-storage-admin/objectstorageadmin.xml'],1,790be6012c9dad033cf6c847c14b8167885569f2,bug/1197651," <para>If the account reaper has not managed to clean out an account after a long period, it prints a message to the log (you can search your system looking for such messages). Introduce reap_warn_after config variable to determine when to emit the message (defaults to 30 days).</para>",,4,0
openstack%2Fbarbican~master~Id3c4fe7590fa8c8dff827fa783880acb4beeba70,openstack/barbican,master,Id3c4fe7590fa8c8dff827fa783880acb4beeba70,Automate rpm build.,MERGED,2013-07-16 18:21:37.000000000,2013-07-16 18:56:11.000000000,2013-07-16 18:56:10.000000000,"[{'_account_id': 3}, {'_account_id': 7789}, {'_account_id': 7973}]","[{'number': 1, 'created': '2013-07-16 18:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c1ed796d55363d66eeb90698a686e94a1f338367', 'message': 'Automate rpm build.\n\nChange-Id: Id3c4fe7590fa8c8dff827fa783880acb4beeba70\n'}, {'number': 2, 'created': '2013-07-16 18:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f4c32f1630080465d7115dd3e48e2a494d97ca03', 'message': 'Automate rpm build.\n\nChange-Id: Id3c4fe7590fa8c8dff827fa783880acb4beeba70\n'}, {'number': 3, 'created': '2013-07-16 18:45:36.000000000', 'files': ['rpmbuild/build_rpm.sh', 'rpmbuild/upload_rpm.sh', 'rpmbuild/SPECS/barbican.spec'], 'web_link': 'https://opendev.org/openstack/barbican/commit/af9f827437dca835dee79c4e0213559344177cb5', 'message': 'Automate rpm build.\n\nChange-Id: Id3c4fe7590fa8c8dff827fa783880acb4beeba70\n'}]",1,37300,af9f827437dca835dee79c4e0213559344177cb5,12,3,3,7973,,,0,"Automate rpm build.

Change-Id: Id3c4fe7590fa8c8dff827fa783880acb4beeba70
",git fetch https://review.opendev.org/openstack/barbican refs/changes/00/37300/2 && git format-patch -1 --stdout FETCH_HEAD,"['rpmbuild/build_rpm.sh', 'rpmbuild/upload_rpm.sh', 'rpmbuild/SPECS/barbican.spec']",3,c1ed796d55363d66eeb90698a686e94a1f338367,rpm-build-automation,%define version 0.1.BUILD_VERSION,%define version 0.1.20130713041652,21,1
openstack%2Fnova~master~Ie32fb43a63ce66c040b5571b13287937bd2df532,openstack/nova,master,Ie32fb43a63ce66c040b5571b13287937bd2df532,Fix malformed format string.,MERGED,2013-07-16 13:15:43.000000000,2013-07-16 18:40:57.000000000,2013-07-16 18:40:52.000000000,"[{'_account_id': 3}, {'_account_id': 1812}, {'_account_id': 2166}, {'_account_id': 2583}, {'_account_id': 4393}, {'_account_id': 5803}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-07-16 13:15:43.000000000', 'files': ['nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/24e737eb759a18c8c5cac2bce00ba8f8f7dddb46', 'message': 'Fix malformed format string.\n\nAlso change dict() to {} which is meant to be more efficient:\n\nhttp://doughellmann.com/2012/11/the-performance-impact-of-using-dict-instead-of-in-cpython-2-7-2.html\n\nThis is required for blueprint ec2-error-codes.\n\nChange-Id: Ie32fb43a63ce66c040b5571b13287937bd2df532\n'}]",0,37243,24e737eb759a18c8c5cac2bce00ba8f8f7dddb46,10,7,1,6717,,,0,"Fix malformed format string.

Also change dict() to {} which is meant to be more efficient:

http://doughellmann.com/2012/11/the-performance-impact-of-using-dict-instead-of-in-cpython-2-7-2.html

This is required for blueprint ec2-error-codes.

Change-Id: Ie32fb43a63ce66c040b5571b13287937bd2df532
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/37243/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,24e737eb759a18c8c5cac2bce00ba8f8f7dddb46,bp/ec2-error-codes," ""invalid. Content limited to '%(allowed)s'."") % {'value': value, 'allowed': allowed, 'property': property.capitalize()})"," ""invalid. Content limited to '%(allowed)'."") % dict(value=value, allowed=allowed, property=property.capitalize()))",3,3
openstack%2Fswift~master~Idd6e8882e062ba2e13489f14189223ab4158677c,openstack/swift,master,Idd6e8882e062ba2e13489f14189223ab4158677c,Fix unit tests to properly marked deleted files,MERGED,2013-07-01 21:46:03.000000000,2013-07-16 18:40:43.000000000,2013-07-16 18:40:43.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7223}]","[{'number': 1, 'created': '2013-07-01 21:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b97225f24bcc3aaf03e6367db76a720d156a8d91', 'message': 'Fix unit tests to properly marked deleted files\n\nThe unit tests were playing fast and loose with the tombstone marker,\nwhere the test framework was setting up a DiskFile object which had\nits data written to the .ts file, not the .data file. This behavior\ndid not reflect how the interfaces to DiskFile were supposed to\nwork.\n\nChange-Id: Idd6e8882e062ba2e13489f14189223ab4158677c\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-07-01 21:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c54ad35911d7504ddff7e636f44f597fbac971ca', 'message': 'Fix unit tests to properly marked deleted files\n\nThe unit tests were playing fast and loose with the tombstone marker,\nwhere the test framework was setting up a DiskFile object which had\nits data written to the .ts file, not the .data file. This behavior\ndid not reflect how the interfaces to DiskFile were supposed to\nwork.\n\nChange-Id: Idd6e8882e062ba2e13489f14189223ab4158677c\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 3, 'created': '2013-07-01 21:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f195250b8377c14c5395448520b2f5b03c7ae1fc', 'message': 'Fix unit tests to properly marked deleted files\n\nThe unit tests were playing fast and loose with the tombstone marker,\nwhere the test framework was setting up a DiskFile object which had\nits data written to the .ts file, not the .data file. This behavior\ndid not reflect how the interfaces to DiskFile were supposed to\nwork.\n\nChange-Id: Idd6e8882e062ba2e13489f14189223ab4158677c\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 4, 'created': '2013-07-01 21:54:07.000000000', 'files': ['test/unit/obj/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/bc99f58c765b2a710ddb73994f1825206ca5fc66', 'message': 'Fix unit tests to properly marked deleted files\n\nThe unit tests were playing fast and loose with the tombstone marker,\nwhere the test framework was setting up a DiskFile object which had\nits data written to the .ts file, not the .data file. This behavior\ndid not reflect how the interfaces to DiskFile were supposed to\nwork.\n\nChange-Id: Idd6e8882e062ba2e13489f14189223ab4158677c\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",0,35204,bc99f58c765b2a710ddb73994f1825206ca5fc66,20,7,4,6198,,,0,"Fix unit tests to properly marked deleted files

The unit tests were playing fast and loose with the tombstone marker,
where the test framework was setting up a DiskFile object which had
its data written to the .ts file, not the .data file. This behavior
did not reflect how the interfaces to DiskFile were supposed to
work.

Change-Id: Idd6e8882e062ba2e13489f14189223ab4158677c
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/04/35204/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/obj/test_server.py'],1,b97225f24bcc3aaf03e6367db76a720d156a8d91,obj-test-cleanup," fsize=1024, csize=8, mark_deleted=False, ts=None, writer.put(metadata) if mark_deleted: df = object_server.DiskFile(self.testdir, 'sda1', '0', 'a', 'c', obj_name, FakeLogger()) metadata = { 'X-Timestamp': timestamp, 'deleted': True } df.put_metadata(metadata, tombstone=True) df = self._get_disk_file(invalid_type='Content-Length') mark_deleted=True) mark_deleted=True) df = self._get_disk_file(invalid_type='Content-Length')"," fsize=1024, csize=8, extension='.data', ts=None, writer.put(metadata, extension=extension) df = self._get_disk_file(invalid_type='Content-Length', extension='.data') extension='.ts') extension='.ts') df = self._get_disk_file(invalid_type='Content-Length', extension='.data')",15,8
openstack%2Fneutron~master~I1ee5cc38d555bd5c26edf00a456ec71919604d79,openstack/neutron,master,I1ee5cc38d555bd5c26edf00a456ec71919604d79,xenapi - rename quantum to neutron,MERGED,2013-07-08 10:16:20.000000000,2013-07-16 18:40:35.000000000,2013-07-16 18:40:35.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 360}, {'_account_id': 782}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5044}]","[{'number': 1, 'created': '2013-07-08 10:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/075831b14e97d1744a9bca3f1e44cec351fe1af2', 'message': 'xenapi - rename quantum to neutron\n\nSome changes were missing from the previous rename patch, so it broke\nXenServer support. This patch contains the missing adjustments.\n\nrelated to blueprint remove-use-of-quantum\n\nChange-Id: I1ee5cc38d555bd5c26edf00a456ec71919604d79\n'}, {'number': 2, 'created': '2013-07-08 10:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8cd2a05453fa5bfb7bd326edfb8c293d98ecee9e', 'message': 'xenapi - rename quantum to neutron\n\nSome changes were missing from the previous rename patch, so it broke\nXenServer support. This patch contains the missing adjustments.\n\nrelated to blueprint remove-use-of-quantum\n\nChange-Id: I1ee5cc38d555bd5c26edf00a456ec71919604d79\n'}, {'number': 3, 'created': '2013-07-16 09:35:10.000000000', 'files': ['bin/quantum-rootwrap-xen-dom0', 'setup.cfg', 'bin/neutron-rootwrap-xen-dom0'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff48cc7d030b5f8ca33a7bd3af38eb8be6d39995', 'message': 'xenapi - rename quantum to neutron\n\nSome changes were missing from the previous rename patch, so it broke\nXenServer support. This patch contains the missing adjustments.\n\nrelated to blueprint remove-use-of-quantum\n\nChange-Id: I1ee5cc38d555bd5c26edf00a456ec71919604d79\n'}]",0,36039,ff48cc7d030b5f8ca33a7bd3af38eb8be6d39995,21,8,3,5044,,,0,"xenapi - rename quantum to neutron

Some changes were missing from the previous rename patch, so it broke
XenServer support. This patch contains the missing adjustments.

related to blueprint remove-use-of-quantum

Change-Id: I1ee5cc38d555bd5c26edf00a456ec71919604d79
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/36039/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/quantum-rootwrap-xen-dom0', 'setup.cfg', 'bin/neutron-rootwrap-xen-dom0']",3,075831b14e97d1744a9bca3f1e44cec351fe1af2,bp/remove-use-of-quantum,"#!/usr/bin/env python # Copyright (c) 2012 Openstack, LLC. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Quantum root wrapper for dom0. Executes networking commands in dom0. The XenAPI plugin is responsible determining whether a command is safe to execute. """""" import ConfigParser import json import os import sys import traceback import XenAPI RC_UNAUTHORIZED = 99 RC_NOCOMMAND = 98 RC_BADCONFIG = 97 RC_XENAPI_ERROR = 96 def parse_args(): # Split arguments, require at least a command exec_name = sys.argv.pop(0) # argv[0] required; path to conf file if len(sys.argv) < 2: print ""%s: No command specified"" % exec_name sys.exit(RC_NOCOMMAND) config_file = sys.argv.pop(0) user_args = sys.argv[:] return exec_name, config_file, user_args def _xenapi_section_name(config): sections = [sect for sect in config.sections() if sect.lower() == ""xenapi""] if len(sections) == 1: return sections[0] print ""Multiple [xenapi] sections or no [xenapi] section found!"" sys.exit(RC_BADCONFIG) def load_configuration(exec_name, config_file): config = ConfigParser.RawConfigParser() config.read(config_file) try: exec_dirs = config.get(""DEFAULT"", ""exec_dirs"").split("","") filters_path = config.get(""DEFAULT"", ""filters_path"").split("","") section = _xenapi_section_name(config) url = config.get(section, ""xenapi_connection_url"") username = config.get(section, ""xenapi_connection_username"") password = config.get(section, ""xenapi_connection_password"") except ConfigParser.Error: print ""%s: Incorrect configuration file: %s"" % (exec_name, config_file) sys.exit(RC_BADCONFIG) if not url or not password: msg = (""%s: Must specify xenapi_connection_url, "" ""xenapi_connection_username (optionally), and "" ""xenapi_connection_password in %s"") % (exec_name, config_file) print msg sys.exit(RC_BADCONFIG) return dict( filters_path=filters_path, url=url, username=username, password=password, exec_dirs=exec_dirs, ) def filter_command(exec_name, filters_path, user_args, exec_dirs): # Add ../ to sys.path to allow running from branch possible_topdir = os.path.normpath(os.path.join(os.path.abspath(exec_name), os.pardir, os.pardir)) if os.path.exists(os.path.join(possible_topdir, ""neutron"", ""__init__.py"")): sys.path.insert(0, possible_topdir) from neutron.rootwrap import wrapper # Execute command if it matches any of the loaded filters filters = wrapper.load_filters(filters_path) filter_match = wrapper.match_filter( filters, user_args, exec_dirs=exec_dirs) if not filter_match: print ""Unauthorized command: %s"" % ' '.join(user_args) sys.exit(RC_UNAUTHORIZED) def run_command(url, username, password, user_args): try: session = XenAPI.Session(url) session.login_with_password(username, password) host = session.xenapi.session.get_this_host(session.handle) result = session.xenapi.host.call_plugin( host, 'netwrap', 'run_command', {'cmd': json.dumps(user_args)}) return json.loads(result) except Exception as e: traceback.print_exc() sys.exit(RC_XENAPI_ERROR) def main(): exec_name, config_file, user_args = parse_args() config = load_configuration(exec_name, config_file) filter_command(exec_name, config['filters_path'], user_args, config['exec_dirs']) return run_command(config['url'], config['username'], config['password'], user_args) if __name__ == '__main__': print main() ",,135,2
openstack%2Fkeystone~master~Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687,openstack/keystone,master,Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687,Implements Pluggable V2 Token Provider,MERGED,2013-06-25 15:23:04.000000000,2013-07-16 18:40:26.000000000,2013-07-16 18:40:25.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 6460}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-06-25 15:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/db40cb3b84f7689fbe6c44fb644571a84d134b42', 'message': ""Pluggable Token Provider (Part 2)\n\nThis patch implemented V2 token provider, which is the second part of\nblueprint pluggable-token-format.\n\nAbstract token provider backend to make token provider pluggable. It enables\ndeployers to customize token management to add their own capabilities.\nToken provider is responsible for issuing, checking, validating, and\nrevoking tokens. Note the distinction between token 'driver' and 'provider'.\nToken 'driver' simply provides token CRUD. It does not issue or interpret\ntokens.\n\nToken provider is specified by the 'provider' property in the '[token]'\nsection of the Keystone configuration file.\n\nNote: This is one of the redos of https://review.openstack.org/#/c/29021\nas it was too big and we need to submit the review in smaller chunks.\n\nChange-Id: Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687\n""}, {'number': 2, 'created': '2013-06-25 15:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bb4750ae4c6266142607375c0e36fccd4a78e8ea', 'message': ""Pluggable Token Provider (Part 2)\n\nThis patch implemented V2 token provider, which is the second part of\nblueprint pluggable-token-format.\n\nAbstract token provider backend to make token provider pluggable. It enables\ndeployers to customize token management to add their own capabilities.\nToken provider is responsible for issuing, checking, validating, and\nrevoking tokens. Note the distinction between token 'driver' and 'provider'.\nToken 'driver' simply provides token CRUD. It does not issue or interpret\ntokens.\n\nToken provider is specified by the 'provider' property in the '[token]'\nsection of the Keystone configuration file.\n\nNote: This is one of the redos of https://review.openstack.org/#/c/29021\nas it was too big and we need to submit the review in smaller chunks.\n\nChange-Id: Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687\n""}, {'number': 3, 'created': '2013-06-28 06:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4e1e1ea6255d6a7ae95d1bb5c3a56fd3959d4793', 'message': ""Pluggable V2 Token Provider\n\nThis patch implemented V2 token provider.\n\nAbstract token provider backend to make token provider pluggable. It enables\ndeployers to customize token management to add their own capabilities.\nToken provider is responsible for issuing, checking, validating, and\nrevoking tokens. Note the distinction between token 'driver' and 'provider'.\nToken 'driver' simply provides token CRUD. It does not issue or interpret\ntokens.\n\nToken provider is specified by the 'provider' property in the '[token]'\nsection of the Keystone configuration file.\n\nChange-Id: Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687\n""}, {'number': 4, 'created': '2013-07-01 20:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3d9669685d6e2b638931c3f517614ce6697da585', 'message': ""Implements Pluggable V2 Token Provider\n\nThis patch implemented V2 token provider.\n\nAbstract token provider backend to make token provider pluggable. It enables\ndeployers to customize token management to add their own capabilities.\nToken provider is responsible for issuing, checking, validating, and\nrevoking tokens. Note the distinction between token 'driver' and 'provider'.\nToken 'driver' simply provides token CRUD. It does not issue or interpret\ntokens.\n\nToken provider is specified by the 'provider' property in the '[token]'\nsection of the Keystone configuration file.\n\nChange-Id: Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687\n""}, {'number': 5, 'created': '2013-07-02 17:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a06bf2a381d6a03f54abbcc42bb6b1cf998f1f0e', 'message': ""Implements Pluggable V2 Token Provider\n\nThis patch implemented V2 token provider.\n\nAbstract token provider backend to make token provider pluggable. It enables\ndeployers to customize token management to add their own capabilities.\nToken provider is responsible for issuing, checking, validating, and\nrevoking tokens. Note the distinction between token 'driver' and 'provider'.\nToken 'driver' simply provides token CRUD. It does not issue or interpret\ntokens.\n\nToken provider is specified by the 'provider' property in the '[token]'\nsection of the Keystone configuration file.\n\nChange-Id: Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687\n""}, {'number': 6, 'created': '2013-07-08 17:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cc45acb6b4d3e93b3e32cf23470ecd1b086ced93', 'message': ""Implements Pluggable V2 Token Provider\n\nThis patch implemented V2 token provider.\n\nAbstract token provider backend to make token provider pluggable. It enables\ndeployers to customize token management to add their own capabilities.\nToken provider is responsible for issuing, checking, validating, and\nrevoking tokens. Note the distinction between token 'driver' and 'provider'.\nToken 'driver' simply provides token CRUD. It does not issue or interpret\ntokens.\n\nToken provider is specified by the 'provider' property in the '[token]'\nsection of the Keystone configuration file.\n\nChange-Id: Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687\n""}, {'number': 7, 'created': '2013-07-10 23:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0aa79c80c427a26ccb474062d2dcb9c0baf810f1', 'message': ""Implements Pluggable V2 Token Provider\n\nThis patch implemented V2 token provider.\n\nAbstract token provider backend to make token provider pluggable. It enables\ndeployers to customize token management to add their own capabilities.\nToken provider is responsible for issuing, checking, validating, and\nrevoking tokens. Note the distinction between token 'driver' and 'provider'.\nToken 'driver' simply provides token CRUD. It does not issue or interpret\ntokens.\n\nToken provider is specified by the 'provider' property in the '[token]'\nsection of the Keystone configuration file.\n\nChange-Id: Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687\n""}, {'number': 8, 'created': '2013-07-15 17:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6283e55454b10f671323f4370aeef901046be016', 'message': ""Implements Pluggable V2 Token Provider\n\nThis patch implemented V2 token provider.\n\nAbstract token provider backend to make token provider pluggable. It enables\ndeployers to customize token management to add their own capabilities.\nToken provider is responsible for issuing, checking, validating, and\nrevoking tokens. Note the distinction between token 'driver' and 'provider'.\nToken 'driver' simply provides token CRUD. It does not issue or interpret\ntokens.\n\nToken provider is specified by the 'provider' property in the '[token]'\nsection of the Keystone configuration file.\n\nChange-Id: Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687\n""}, {'number': 9, 'created': '2013-07-15 19:53:37.000000000', 'files': ['keystone/token/provider.py', 'keystone/token/controllers.py', 'keystone/token/providers/uuid.py', 'keystone/common/controller.py', 'keystone/contrib/ec2/core.py', 'tests/test_keystoneclient.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ee27d6eef62d201c99694d0f788ea2a96c6669a4', 'message': ""Implements Pluggable V2 Token Provider\n\nThis patch implemented V2 token provider.\n\nAbstract token provider backend to make token provider pluggable. It enables\ndeployers to customize token management to add their own capabilities.\nToken provider is responsible for issuing, checking, validating, and\nrevoking tokens. Note the distinction between token 'driver' and 'provider'.\nToken 'driver' simply provides token CRUD. It does not issue or interpret\ntokens.\n\nToken provider is specified by the 'provider' property in the '[token]'\nsection of the Keystone configuration file.\n\nChange-Id: Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687\n""}]",37,34421,ee27d6eef62d201c99694d0f788ea2a96c6669a4,44,9,9,1916,,,0,"Implements Pluggable V2 Token Provider

This patch implemented V2 token provider.

Abstract token provider backend to make token provider pluggable. It enables
deployers to customize token management to add their own capabilities.
Token provider is responsible for issuing, checking, validating, and
revoking tokens. Note the distinction between token 'driver' and 'provider'.
Token 'driver' simply provides token CRUD. It does not issue or interpret
tokens.

Token provider is specified by the 'provider' property in the '[token]'
section of the Keystone configuration file.

Change-Id: Ic418ec433bd9e3f2f70fa31c90e570e32c1ca687
",git fetch https://review.opendev.org/openstack/keystone refs/changes/21/34421/7 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/controllers.py', 'keystone/token/provider.py', 'keystone/token/providers/keystone_provider.py', 'keystone/common/controller.py', 'keystone/contrib/ec2/core.py', 'tests/test_keystoneclient.py']",6,db40cb3b84f7689fbe6c44fb644571a84d134b42,v2_v3," def test_ec2_auth(self): client = self.get_client() cred = client.ec2.create(user_id=self.user_foo['id'], tenant_id=self.tenant_bar['id']) from keystoneclient.contrib.ec2 import utils as ec2_utils signer = ec2_utils.Ec2Signer(cred.secret) credentials = {'params': {'SignatureVersion': '2'}, 'access': cred.access, 'verb': 'GET', 'host': 'localhost', 'path': '/thisisgoingtowork'} signature = signer.generate(credentials) credentials['signature'] = signature url = '%s/ec2tokens' % (client.auth_url) (resp, token) = client.request(url=url, method='POST', body={'credentials': credentials}) # make sure we have a v2 token self.assertEqual(resp.status_code, 200) self.assertIn('access', token) ",,295,218
openstack%2Fheat~master~I59d065747db12d2de786881c566cbbfc84cb9c67,openstack/heat,master,I59d065747db12d2de786881c566cbbfc84cb9c67,bug 1201823,ABANDONED,2013-07-16 15:57:19.000000000,2013-07-16 18:36:24.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-16 15:57:19.000000000', 'files': ['doc/source/howto_guides/index.rst', 'doc/source/howto_guides/using_the_metadata_server.rst', 'doc/source/index.rst', 'doc/source/troubleshooting/index.rst', 'doc/source/architecture.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/0794796663058b1e045443655f6fd7fe8899125e', 'message': 'bug 1201823\n\ncreate new layout to match the docs that keystone maintains, porting more docs soon from https://wiki.openstack.org/wiki/Heat\n\nChange-Id: I59d065747db12d2de786881c566cbbfc84cb9c67\n'}]",0,37278,0794796663058b1e045443655f6fd7fe8899125e,2,1,1,7090,,,0,"bug 1201823

create new layout to match the docs that keystone maintains, porting more docs soon from https://wiki.openstack.org/wiki/Heat

Change-Id: I59d065747db12d2de786881c566cbbfc84cb9c67
",git fetch https://review.opendev.org/openstack/heat refs/changes/78/37278/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/howto_guides/index.rst', 'doc/source/howto_guides/using_the_metadata_server.rst', 'doc/source/index.rst', 'doc/source/troubleshooting/index.rst', 'doc/source/architecture.rst']",5,0794796663058b1e045443655f6fd7fe8899125e,bug/1201823,".. Copyright 2011-2012 OpenStack, LLC All Rights Reserved. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Heat Architecture ===================== Heat is a service to orchestrate multiple composite cloud applications using the .. _AWS CloudFormation: http://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/Welcome.html?r=7078 template format, through both an OpenStack-native ReST API and a CloudFormation-compatible Query API. ------------ Detailed Description ------------ What is the purpose of the project and vision for it? * Heat provides an AWS CloudFormation implementation for OpenStack that orchestrates an AWS CloudFormation template describing a cloud application by executing appropriate OpenStack API calls to generate running cloud applications. Describe the relevance of the project to other OpenStack projects and the OpenStack mission to provide a ubiquitous cloud computing platform: *The software integrates other core components of OpenStack into a one-file template system. The templates allow creation of most OpenStack resource types (such as instances, floating ips, volumes, security groups, users, etc), as well as some more advanced functionality such as instance high availability, instance autoscaling, and nested stacks. By providing very tight integration with other OpenStack core projects, all OpenStack core projects could receive a larger user base. *Currently no other CloudFormation implementation exists for OpenStack. The developers believe cloud developers have a strong desire to move workloads from AWS to OpenStack deployments. Given the missing gap of a well-implemented and integrated CloudFormation API in OpenStack, we provide a high quality implementation of this gap improving the ubiquity of OpenStack. ------------ Heat Services ------------ The developers are focused on creating an OpenStack style project using OpenStack design tenets, implemented in Python. We have started with full integration with Keystone. We have a number of components. As the developers have only started development in March 2012, the architecture is evolving rapidly. heat -------- The heat tool is a CLI which communicates with the heat-api to execute AWS CloudFormation APIs. End developers could also use the heat REST API directly. heat-api ----- The heat-api component provides an OpenStack-native REST API that processes API requests by sending them to the heat-engine over RPC. heat-api-cfn ------- The heat-api-cfn component provides an AWS Query API that is compatible with AWS CloudFormation and processes API requests by sending them to the heat-engine over RPC. heat-engine ------ The heat engine's main responsibility is to orchestrate the launching of templates and provide events back to the API consumer. The templates integrate well with .. _Puppet: https://s3.amazonaws.com/cloudformation-examples/IntegratingAWSCloudFormationWithPuppet.pdf and .. _Chef: http://www.full360.com/2011/02/27/integrating-aws-cloudformation-and-chef.html",,191,11
openstack%2Fheat~master~Ied58cad79290cef63a71aea8ca30e682cc0b6ff2,openstack/heat,master,Ied58cad79290cef63a71aea8ca30e682cc0b6ff2,bug 1201823 ported more guides from wiki.openstack.org,ABANDONED,2013-07-16 18:19:51.000000000,2013-07-16 18:21:07.000000000,,[],"[{'number': 1, 'created': '2013-07-16 18:19:51.000000000', 'files': ['doc/source/howto_guides/using_floating_ips.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/d85fbdea447c24f6e9b07466185185a9204dac5e', 'message': 'bug 1201823\nported more guides from wiki.openstack.org\n\nChange-Id: Ied58cad79290cef63a71aea8ca30e682cc0b6ff2\n'}]",0,37299,d85fbdea447c24f6e9b07466185185a9204dac5e,1,0,1,7090,,,0,"bug 1201823
ported more guides from wiki.openstack.org

Change-Id: Ied58cad79290cef63a71aea8ca30e682cc0b6ff2
",git fetch https://review.opendev.org/openstack/heat refs/changes/99/37299/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/howto_guides/using_floating_ips.rst'],1,d85fbdea447c24f6e9b07466185185a9204dac5e,bug/1201823,".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Overview -------- Amazon Elastic IPs (resources `AWS::EC2::EIP` and `AWS::EC2::EIPAssociation`) under Heat use OpenStack's Floating IPs. Initially, there aren't any IP addresses available so using a template that depends on Elastic IPs will fail. This guide shows how to set them up. Security Group Policy -------- Allow ICMP, SSH and HTTP connections on the instances: Add the following to the template: [[[SecurityGroup]]](.. _ https://github.com/openstack/heat/commit/0ee8db445941f24e07a3a93b91adc87c192b1c1f#diff-2) Configuring OpenStack for floating IPs -------- OpenStack expects a default interface of eth0. If running Fedora or another operating system that renames the physical interface, it is necessary to reconfigure OpenStack.: sudo openstack-config --set /etc/nova/nova.conf DEFAULT public_interface em1 or wlan0 sudo systemctl restart openstack-nova-network.service Allocate Address Space -------- Pick a pool of addresses you want to allocate to OpenStack. The following allocates the `10.1.0.125/28` subnet:: sudo nova-manage floating create 10.1.0.125/28 --interface=<public_interface> sudo nova-manage floating list This tool will print out something similar to the following:: None 10.34.30.113 None nova eth0 None 10.34.30.114 None nova eth0 None 10.34.30.115 None nova eth0 None 10.34.30.116 None nova eth0 None 10.34.30.117 None nova eth0 None 10.34.30.118 None nova eth0 None 10.34.30.119 None nova eth0 None 10.34.30.120 None nova eth0 None 10.34.30.121 None nova eth0 None 10.34.30.122 None nova eth0 None 10.34.30.123 None nova eth0 None 10.34.30.124 None nova eth0 None 10.34.30.125 None nova eth0 None 10.34.30.126 None nova eth0 Deallocate the floating IPs -------- : sudo nova-manage floating delete 10.1.0.125/28 Troubleshooting floating IPs in a NAT environment -------- In a typical laptop, wireless runs on wlan0. Typically the wireless router takes care of NAT from external addresses and assigns the host an address of 192.168.1.x. Unfortunately openstack floating IPs are designed to run on routed networks, not NAT networks. In a real deployment, ingress traffic would look like this: ROUTED NETWORK -> HOST -> FLOAT NAT -> VM In a laptop, ingress traffic looks like this: NAT -> HOST -> FLOAT NAT -> VM Since the Wireless NAT can't NAT IPs it hasn't assigned, the Linux kernel must do NAT translation for the HOST's wlan0. Unfortunately this is not possible because the floating IP has to be NAT translated first. From iptables man page: This target is only valid in the nat table, in the POSTROUTING chain. It specifies that the source address of the packet should be modified (and all future packets in this connection will also be mangled, and rules **should cease being examined**. Because the rules are not examined further, it is not possible to have back-to-back NATs. To work around this problem on Laptops, the following rule should do the trick:: iptables -t nat -I POSTROUTING 1 -s 10.0.0.0/8 -j MASQUERADE -o wlan0 If your nova-manage network is created on 10.0.0.0 and your floating is on 10.1.0.0, this rule will force masquerading over wlan0 for the 10.x.x.x network. Note if your internal network is already on 10.0.0.0, you will want to use a different network that isn't already being used in your routing tables (such as 11.x.x.x). A **BIG** thank you to Fabio Di Nitto for helping sort out this issue. ",,103,0
openstack%2Fneutron~master~I7f46a395597b71bb1c5110aa4e792a04a5010d4c,openstack/neutron,master,I7f46a395597b71bb1c5110aa4e792a04a5010d4c,Enable policy control over external_gateway_info sub-attributes,MERGED,2013-07-06 16:06:39.000000000,2013-07-16 18:12:13.000000000,2013-07-16 18:12:12.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 1038}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 6072}]","[{'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9e427aa562151447f559ee66fd71dabb13c397ba', 'message': 'Enable policy control over external_gateway_info sub-attributes\n\nPart 2 of blueprint l3-ext-gw-modes\n\nThis patch extends the logic for building policy rule matches in order to\ninclude sub-attributes as well. This logic will be leveraged by the\next-gw-mode api extension.\n\nChange-Id: I7f46a395597b71bb1c5110aa4e792a04a5010d4c\n'}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a0b7db594fce796f836db7690299b1f919976612', 'message': 'Enable policy control over external_gateway_info sub-attributes\n\nPart 2 of blueprint l3-ext-gw-modes\n\nThis patch extends the logic for building policy rule matches in order to\ninclude sub-attributes as well. This logic will be leveraged by the\next-gw-mode api extension.\n\nChange-Id: I7f46a395597b71bb1c5110aa4e792a04a5010d4c\n'}, {'number': 6, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8039da719349d4b175b5d60e6f659277b8f8c57d', 'message': 'Enable policy control over external_gateway_info sub-attributes\n\nPart 2 of blueprint l3-ext-gw-modes\n\nThis patch extends the logic for building policy rule matches in order to\ninclude sub-attributes as well. This logic will be leveraged by the\next-gw-mode api extension.\n\nChange-Id: I7f46a395597b71bb1c5110aa4e792a04a5010d4c\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66718f45b7a30f33748e38e397af4a3f24c14709', 'message': 'Enable policy control over external_gateway_info sub-attributes\n\nPart 2 of blueprint ext-gw-modes\n\nThis patch extends the logic for building policy rule matches in order to\ninclude sub-attributes as well. This logic will be leveraged by the\nl3-ext-gw-mode api extension.\n\nChange-Id: I7f46a395597b71bb1c5110aa4e792a04a5010d4c\n'}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/de56f0830d81818abb6e8b78392f13c5917a0166', 'message': 'Enable policy control over external_gateway_info sub-attributes\n\nPart 2 of blueprint ext-gw-modes\n\nThis patch extends the logic for building policy rule matches in order to\ninclude sub-attributes as well. This logic will be leveraged by the\nl3-ext-gw-mode api extension.\n\nChange-Id: I7f46a395597b71bb1c5110aa4e792a04a5010d4c\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1e3634d9ae95e461f2b7b59a4879f9638e8b875', 'message': 'Enable policy control over external_gateway_info sub-attributes\n\nPart 2 of blueprint ext-gw-modes\n\nThis patch extends the logic for building policy rule matches in order to\ninclude sub-attributes as well. This logic will be leveraged by the\nl3-ext-gw-mode api extension.\n\nChange-Id: I7f46a395597b71bb1c5110aa4e792a04a5010d4c\n'}, {'number': 7, 'created': '2013-07-16 01:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ed0d2c1d4311d555cdba6f2dc09bd547a50b1f2d', 'message': 'Enable policy control over external_gateway_info sub-attributes\n\nPart 2 of blueprint l3-ext-gw-modes\n\nThis patch extends the logic for building policy rule matches in order to\ninclude sub-attributes as well. This logic will be leveraged by the\next-gw-mode api extension.\n\nChange-Id: I7f46a395597b71bb1c5110aa4e792a04a5010d4c\n'}, {'number': 8, 'created': '2013-07-16 15:51:24.000000000', 'files': ['neutron/tests/unit/test_policy.py', 'neutron/policy.py', 'etc/policy.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ce9bc96aba0fe7649465ca8cf9d517db366b4b4', 'message': 'Enable policy control over external_gateway_info sub-attributes\n\nPart 2 of blueprint l3-ext-gw-modes\n\nThis patch extends the logic for building policy rule matches in order to\ninclude sub-attributes as well. This logic will be leveraged by the\next-gw-mode api extension.\n\nChange-Id: I7f46a395597b71bb1c5110aa4e792a04a5010d4c\n'}]",11,29014,7ce9bc96aba0fe7649465ca8cf9d517db366b4b4,39,8,8,261,,,0,"Enable policy control over external_gateway_info sub-attributes

Part 2 of blueprint l3-ext-gw-modes

This patch extends the logic for building policy rule matches in order to
include sub-attributes as well. This logic will be leveraged by the
ext-gw-mode api extension.

Change-Id: I7f46a395597b71bb1c5110aa4e792a04a5010d4c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/14/29014/8 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/tests/unit/test_policy.py', 'quantum/policy.py', 'etc/policy.json']",3,9e427aa562151447f559ee66fd71dabb13c397ba,bp/l3-ext-gw-modes," ""create_router:external_gateway_info:enable_snat"": ""rule_admin_only"", ""update_router:external_gateway_info:enable_snat"": ""rule_admin_only"", ",,84,2
openstack%2Fnova~master~Id7deb28803b0c93c5077306be9afa5ddf1e76a32,openstack/nova,master,Id7deb28803b0c93c5077306be9afa5ddf1e76a32,Fix EC2 DescribeTags filter,MERGED,2013-07-03 14:50:09.000000000,2013-07-16 17:50:52.000000000,2013-07-16 17:50:50.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2140}, {'_account_id': 2166}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-07-03 14:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce131b2aafff439f8101e7cf7e2aa1e3dd9c1070', 'message': 'Fix EC2 DescribeTags filter\n\nUse resource-id/resource-type rather than resource_id/resource_type\nas the filter key_name for describe_tags.\n\nFix bug 1197294\n\nChange-Id: Id7deb28803b0c93c5077306be9afa5ddf1e76a32\n'}, {'number': 2, 'created': '2013-07-16 12:59:30.000000000', 'files': ['nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/de5dff5fb592fa634c07dc44ec54263030d3f85f', 'message': 'Fix EC2 DescribeTags filter\n\nSupport resource-id and resource-type as the filter key_name for\ndescribe_tags.\n\nFix bug 1197294\n\nChange-Id: Id7deb28803b0c93c5077306be9afa5ddf1e76a32\n'}]",2,35498,de5dff5fb592fa634c07dc44ec54263030d3f85f,12,5,2,2140,,,0,"Fix EC2 DescribeTags filter

Support resource-id and resource-type as the filter key_name for
describe_tags.

Fix bug 1197294

Change-Id: Id7deb28803b0c93c5077306be9afa5ddf1e76a32
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/35498/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py']",2,ce131b2aafff439f8101e7cf7e2aa1e3dd9c1070,bug/1197294, if key_name == 'resource-id': elif key_name == 'resource-type':, if key_name == 'resource_id': elif key_name == 'resource_type':,5,5
openstack-attic%2Fidentity-api~master~I61b236ace7796185e913f7b624aca1c25f5d3655,openstack-attic/identity-api,master,I61b236ace7796185e913f7b624aca1c25f5d3655,Updated google analytics number,MERGED,2013-07-16 14:59:44.000000000,2013-07-16 17:24:04.000000000,2013-07-16 17:24:04.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-07-16 14:59:44.000000000', 'files': ['openstack-identity-api/v2.0/pom.xml'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/647e409e4018587ace0699cce27a1b8fc4bdacc6', 'message': 'Updated google analytics number\n\nbug: #1196922\n\nChange-Id: I61b236ace7796185e913f7b624aca1c25f5d3655\nauthor: diane fleming\n'}]",0,37264,647e409e4018587ace0699cce27a1b8fc4bdacc6,5,2,1,2448,,,0,"Updated google analytics number

bug: #1196922

Change-Id: I61b236ace7796185e913f7b624aca1c25f5d3655
author: diane fleming
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/64/37264/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-identity-api/v2.0/pom.xml'],1,647e409e4018587ace0699cce27a1b8fc4bdacc6,1196922, <googleAnalyticsId>UA-17511903-1</googleAnalyticsId>, <googleAnalyticsId>UA-17511903-6</googleAnalyticsId>,1,1
openstack%2Fpbr~feature%2Fmerged2to1~Ife0414af468e7fcd4fc419eafc3e19e29efcfc7b,openstack/pbr,feature/merged2to1,Ife0414af468e7fcd4fc419eafc3e19e29efcfc7b,Add support for globbing in data files,ABANDONED,2013-07-07 17:19:43.000000000,2013-07-16 16:54:22.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4571}, {'_account_id': 5263}]","[{'number': 1, 'created': '2013-07-07 17:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/bf5afde0fc285fef4051a0af52703a91d2429795', 'message': 'Add support for globbing in data files.\n\nSimilar to the work in the packages argument, allow the specification\nof a directory to recursively include as part of the install.\n\nChange-Id: Ife0414af468e7fcd4fc419eafc3e19e29efcfc7b\n'}, {'number': 2, 'created': '2013-07-12 00:00:57.000000000', 'files': ['pbr/hooks/files.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/316ad67cefb918930d31dfd1cbf90e94519978db', 'message': 'Add support for globbing in data files\n\nSimilar to the work in the packages argument, allow the specification\nof a directory to recursively include as part of the install.\n\nChange-Id: Ife0414af468e7fcd4fc419eafc3e19e29efcfc7b\n'}]",2,36003,316ad67cefb918930d31dfd1cbf90e94519978db,7,5,2,2,,,0,"Add support for globbing in data files

Similar to the work in the packages argument, allow the specification
of a directory to recursively include as part of the install.

Change-Id: Ife0414af468e7fcd4fc419eafc3e19e29efcfc7b
",git fetch https://review.opendev.org/openstack/pbr refs/changes/03/36003/2 && git format-patch -1 --stdout FETCH_HEAD,['pbr/hooks/files.py'],1,bf5afde0fc285fef4051a0af52703a91d2429795,file-globbing,"class PathContainer(object): def __init__(self, source_prefix, target_prefix, paths): self.source_prefix = source_prefix self.target_prefix = target_prefix.strip() if not self.target_prefix.endswith(os.path.sep): self.target_prefix += '/' self.paths = paths def accumulate_paths(arg, dirname, fnames): non_dir_fnames = [f for f in fnames if not os.path.isdir( os.path.join(dirname, f))] if non_dir_fnames: arg.paths.append( ""%s ="" % dirname.replace(arg.source_prefix, arg.target_prefix)) arg.paths.extend(["" %s"" % os.path.join(dirname, f) for f in non_dir_fnames]) def expand_globs(self): finished = [] for line in self.data_files.split(""\n""): if line.rstrip().endswith('*') and '=' in line: (target, source_glob) = line.split('=') paths = PathContainer( source_glob.strip()[:-1], target, finished) os.path.walk(paths.source_prefix, accumulate_paths, paths) else: finished.append(line) self.data_files = ""\n"".join(finished) self.expand_globs() ",,35,0
openstack%2Fnova~master~I21170252400ffc73f386dbd19aaa9f7a7613bd56,openstack/nova,master,I21170252400ffc73f386dbd19aaa9f7a7613bd56,xenapi: Add disk config value to xenstore.,MERGED,2013-06-27 13:34:27.000000000,2013-07-16 16:53:28.000000000,2013-07-16 16:53:26.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2166}, {'_account_id': 5441}, {'_account_id': 7094}]","[{'number': 1, 'created': '2013-06-27 13:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4bf9a132638b149b913f3bbe10011d732eff2edc', 'message': 'Add disk config value to xenstore.\n\nTo be able to access the value of disk_config from inside the VM,\nadded the value to xenstore.\n\nImplements blueprint add-disk-config-to-xenstore\nChange-Id: I21170252400ffc73f386dbd19aaa9f7a7613bd56\n'}, {'number': 2, 'created': '2013-06-28 09:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5861647acf13cd4017c7d6628acbd3f9932d02a8', 'message': 'Add disk config value to xenstore.\n\nTo be able to access the value of disk_config from inside the VM,\nadded the value to xenstore.\n\nImplements blueprint add-disk-config-to-xenstore\nChange-Id: I21170252400ffc73f386dbd19aaa9f7a7613bd56\n'}, {'number': 3, 'created': '2013-07-01 10:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc99d1be8b25bfac897a2c97e16097f32dd69fc6', 'message': 'Add disk config value to xenstore.\n\nTo be able to access the value of disk_config from inside the VM,\nadded the value to xenstore.\n\nImplements blueprint add-disk-config-to-xenstore\nChange-Id: I21170252400ffc73f386dbd19aaa9f7a7613bd56\n'}, {'number': 4, 'created': '2013-07-08 05:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2de55a3fc69a417965bb3f41be994d20a0375acd', 'message': 'xenapi: Add disk config value to xenstore.\n\nTo be able to access the value of disk_config from inside the VM,\nadded the value to xenstore.\n\nImplements blueprint add-disk-config-to-xenstore\nChange-Id: I21170252400ffc73f386dbd19aaa9f7a7613bd56\n'}, {'number': 5, 'created': '2013-07-10 13:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac84461566d9ef946516795c50099065ad5fae27', 'message': 'xenapi: Add disk config value to xenstore.\n\nTo be able to access the value of disk_config from inside the VM,\nadded the value to xenstore.\n\nImplements blueprint add-disk-config-to-xenstore\nChange-Id: I21170252400ffc73f386dbd19aaa9f7a7613bd56\n'}, {'number': 6, 'created': '2013-07-12 05:19:00.000000000', 'files': ['nova/tests/virt/xenapi/test_xenapi.py', 'nova/virt/xenapi/vmops.py', 'nova/tests/virt/xenapi/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f37a93dd7ebd4f1cc349e9f74d76a46448d2442c', 'message': 'xenapi: Add disk config value to xenstore.\n\nTo be able to access the value of disk_config from inside the VM,\nadded the value to xenstore.\n\nImplements blueprint add-disk-config-to-xenstore\nChange-Id: I21170252400ffc73f386dbd19aaa9f7a7613bd56\n'}]",17,34735,f37a93dd7ebd4f1cc349e9f74d76a46448d2442c,28,5,6,7094,,,0,"xenapi: Add disk config value to xenstore.

To be able to access the value of disk_config from inside the VM,
added the value to xenstore.

Implements blueprint add-disk-config-to-xenstore
Change-Id: I21170252400ffc73f386dbd19aaa9f7a7613bd56
",git fetch https://review.opendev.org/openstack/nova refs/changes/35/34735/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/xenapi/test_xenapi.py', 'nova/virt/xenapi/vmops.py']",2,4bf9a132638b149b913f3bbe10011d732eff2edc,bp/add-disk-config-to-xenstore," def inject_auto_disk_config_step(undo_mgr, vm_ref): self.inject_auto_disk_config(instance, vm_ref) @step inject_auto_disk_config_step(undo_mgr, vm_ref) def inject_auto_disk_config(self, instance, vm_ref): if instance['auto_disk_config']: self._add_to_param_xenstore(vm_ref, 'vm-data/auto-disk-config', instance['auto_disk_config']) ",,31,0
openstack%2Fnova~master~Ib2eb91f6f18af6d39f9381daeff7ba9a24b4785a,openstack/nova,master,Ib2eb91f6f18af6d39f9381daeff7ba9a24b4785a,xenapi:populating hypervisor version in host state,MERGED,2013-07-15 05:41:54.000000000,2013-07-16 16:51:26.000000000,2013-07-16 16:51:24.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 5441}, {'_account_id': 7094}]","[{'number': 1, 'created': '2013-07-15 05:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a218be9e608375ead6121092f1a680313f279d6', 'message': 'xenapi:populating hypervisor version in host state\n\nThis will be used in the scheduler to compare it to the image\nproperties.\nPulled out conversion of version string into integer to utils.\nPartially implements blueprint xen-support-for-hypervisor-versions\n\nChange-Id: Ib2eb91f6f18af6d39f9381daeff7ba9a24b4785a\n'}, {'number': 2, 'created': '2013-07-15 05:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1183c63a775514b37c13296311642dc221cecc7', 'message': 'xenapi:populating hypervisor version in host state\n\nThis will be used in the scheduler to compare it to the image\nproperties.\nPulled out conversion of version string into integer to utils.\nPartially implements blueprint xen-support-for-hypervisor-versions\n\nChange-Id: Ib2eb91f6f18af6d39f9381daeff7ba9a24b4785a\n'}, {'number': 3, 'created': '2013-07-15 06:52:43.000000000', 'files': ['nova/tests/virt/xenapi/test_driver.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b5b4a1c02e5097f215ea08a809616d551e0c23c2', 'message': 'xenapi:populating hypervisor version in host state\n\nThis will be used in the scheduler to compare it to the image\nproperties.\nPulled out conversion of version string into integer to utils.\nPartially implements blueprint xen-support-for-hypervisor-versions\n\nChange-Id: Ib2eb91f6f18af6d39f9381daeff7ba9a24b4785a\n'}]",1,37016,b5b4a1c02e5097f215ea08a809616d551e0c23c2,12,6,3,7094,,,0,"xenapi:populating hypervisor version in host state

This will be used in the scheduler to compare it to the image
properties.
Pulled out conversion of version string into integer to utils.
Partially implements blueprint xen-support-for-hypervisor-versions

Change-Id: Ib2eb91f6f18af6d39f9381daeff7ba9a24b4785a
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/37016/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/xenapi/test_driver.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/utils.py']",4,8a218be9e608375ead6121092f1a680313f279d6,bp/xen-support-for-hypervisor-versions, def convert_to_int(version): return version[0] * 1000000 + version[1] * 1000 + version[2],,63,6
openstack%2Fopenstack-manuals~master~Ia3b3d7c17053aa975b9081acbe0f3908c80e484b,openstack/openstack-manuals,master,Ia3b3d7c17053aa975b9081acbe0f3908c80e484b,Renames the openstack-security-guide folder to shorter name,MERGED,2013-07-16 16:13:04.000000000,2013-07-16 16:46:43.000000000,2013-07-16 16:46:43.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-07-16 16:13:04.000000000', 'files': ['doc/src/docbkx/openstack-security/ch002_why-and-how-we-wrote-this-book.xml', 'doc/src/docbkx/openstack-security/ch032_networking-best-practices.xml', 'doc/src/docbkx/openstack-security/static/Red_Hat_RGB_300px_2.png', 'doc/src/docbkx/openstack-security/static/conductor.jpg', 'doc/src/docbkx/openstack-security/ch062_audit-guidance.xml', 'doc/src/docbkx/openstack-security/static/CommonCriteria.png', 'doc/src/docbkx/openstack-security/static/group.png', 'doc/src/docbkx/openstack-security/ch042_database-overview.xml', 'doc/src/docbkx/openstack-security/static/HP RGB_WEB_1.png', 'doc/src/docbkx/openstack-security/bk_openstack-sec-guide.xml', 'doc/src/docbkx/openstack-security/static/Quantum_Components_Communication.JPG', 'doc/src/docbkx/openstack-security/static/networking-architecture-diagram-2.png', 'doc/src/docbkx/openstack-security/static/node-provisioning-pxe.png', 'doc/src/docbkx/openstack-security/static/filteringWorkflow1.png', 'doc/src/docbkx/openstack-security/static/novaconductor.png', 'doc/src/docbkx/openstack-security/static/bridging_security_domains.png', 'doc/src/docbkx/openstack-security/ch039_case-studies-messaging.xml', 'doc/src/docbkx/openstack-security/static/APL Logo.jpg', 'doc/src/docbkx/openstack-security/static/marketecture-diagram.png', 'doc/src/docbkx/openstack-security/static/Quantum-PhysNet-Diagram.png', 'doc/src/docbkx/openstack-security/static/Rackspace_Cloud_Company_Logo_clr_1.png', 'doc/src/docbkx/openstack-security/ch017_threat-models-confidence-and-confidentiality.xml', 'doc/src/docbkx/openstack-security/ch021_paste-and-middleware.xml', 'doc/src/docbkx/openstack-security/ch059_case-studies-monitoring-logging.xml', 'doc/src/docbkx/openstack-security/static/high-capability.svg', 'doc/src/docbkx/openstack-security/static/bridging_domains_clouduser.svg', 'doc/src/docbkx/openstack-security/ch027_storage.xml', 'doc/src/docbkx/openstack-security/ch033_securing-neutron-services.xml', 'doc/src/docbkx/openstack-security/ch051_vss-intro.xml', 'doc/src/docbkx/openstack-security/static/network-diagram.png', 'doc/src/docbkx/openstack-security/ch008_system-roles-types.xml', 'doc/src/docbkx/openstack-security/ch063_compliance-activities.xml', 'doc/src/docbkx/openstack-security/static/HP RGB_WEB.png', 'doc/src/docbkx/openstack-security/static/cs.png', 'doc/src/docbkx/openstack-security/ch041_database-backend-considerations.xml', 'doc/src/docbkx/openstack-security/static/intel-blue-logo.jpg', 'doc/src/docbkx/openstack-security/static/secure-boot-arch.png', 'doc/src/docbkx/openstack-security/ch013_node-bootstrapping.xml', 'doc/src/docbkx/openstack-security/ch038_transport-security.xml', 'doc/src/docbkx/openstack-security/static/Red_Hat_RGB_300px.png', 'doc/src/docbkx/openstack-security/static/floss_badge_transp.gif', 'doc/src/docbkx/openstack-security/static/CP_Logotype_small.png', 'doc/src/docbkx/openstack-security/static/bridging_security_domains_1.png', 'doc/src/docbkx/openstack-security/ch055_security-services-for-instances.xml', 'doc/src/docbkx/openstack-security/static/threat_actors.svg', 'doc/src/docbkx/openstack-security/static/Nicira-byVMware_logo_V_CL_CMYK.png', 'doc/src/docbkx/openstack-security/static/Quantum_Components_Communication_1.JPG', 'doc/src/docbkx/openstack-security/static/reference.png', 'doc/src/docbkx/openstack-security/static/services-protocols-ports.png', 'doc/src/docbkx/openstack-security/ch026_compute.xml', 'doc/src/docbkx/openstack-security/static/SecurityDomains.jpg', 'doc/src/docbkx/openstack-security/static/hp_cloud_services_blue_logo.png', 'doc/src/docbkx/openstack-security/static/svirt_on_disk.png', 'doc/src/docbkx/openstack-security/static/databaseusernamessl.png', 'doc/src/docbkx/openstack-security/ch015_case-studies-management.xml', 'doc/src/docbkx/openstack-security/ch001_acknowledgements.xml', 'doc/src/docbkx/openstack-security/ch018_case-studies-pkissl.xml', 'doc/src/docbkx/openstack-security/static/networking-architecture-diagram.png', 'doc/src/docbkx/openstack-security/ch064_certifications-compliance-statements.xml', 'doc/src/docbkx/openstack-security/ch030_state-of-networking.xml', 'doc/src/docbkx/openstack-security/pom.xml', 'doc/src/docbkx/openstack-security/ch066_case-studies-compliance.xml', 'doc/src/docbkx/openstack-security/static/dbred.jpg', 'doc/src/docbkx/openstack-security/ch012_configuration-management.xml', 'doc/src/docbkx/openstack-security/ch022_case-studies-api-endpoints.xml', 'doc/src/docbkx/openstack-security/static/sVirt Diagram 1.png', 'doc/src/docbkx/openstack-security/static/Networking_Use_Case1-Rough.png', 'doc/src/docbkx/openstack-security/ch061_compliance-overview.xml', 'doc/src/docbkx/openstack-security/static/SprintWall.jpg', 'doc/src/docbkx/openstack-security/static/ThreatActors.jpg', 'doc/src/docbkx/openstack-security/static/untrusted_trusted.png', 'doc/src/docbkx/openstack-security/static/APL%20center%20blue.png', 'doc/src/docbkx/openstack-security/static/Nicira-byVMware_300.png', 'doc/src/docbkx/openstack-security/static/book-sprint-all-logos.png', 'doc/src/docbkx/openstack-security/static/bridging_domains_clouduser.png', 'doc/src/docbkx/openstack-security/static/node-provisioning-pxe.graffle', 'doc/src/docbkx/openstack-security/static/databaseusername.svg', 'doc/src/docbkx/openstack-security/static/threat_actors.png', 'doc/src/docbkx/openstack-security/static/1aa-network-domains-diagram.png', 'doc/src/docbkx/openstack-security/static/Openstack_Networking_Service_Communication_Channels.JPG', 'doc/src/docbkx/openstack-security/static/bridging_security_domains_1.svg', 'doc/src/docbkx/openstack-security/static/DomainBridging2.jpg', 'doc/src/docbkx/openstack-security/static/insecure-boot-arch.png', 'doc/src/docbkx/openstack-security/ch009_case-studies.xml', 'doc/src/docbkx/openstack-security/ch014_best-practices-for-operator-mode-access.xml', 'doc/src/docbkx/openstack-security/static/Red_Hat_CMYK.svg', 'doc/src/docbkx/openstack-security/static/databaseusernamessl.svg', 'doc/src/docbkx/openstack-security/static/Screen Shot 2013-06-28 at 10.23.28.png', 'doc/src/docbkx/openstack-security/static/Rackspace_Cloud_Company_Logo_clr.png', 'doc/src/docbkx/openstack-security/static/download.png', 'doc/src/docbkx/openstack-security/static/download_1.png', 'doc/src/docbkx/openstack-security/static/logical-quantum-flow.png', 'doc/src/docbkx/openstack-security/ch046_data-residency.xml', 'doc/src/docbkx/openstack-security/ch044_case-studies-database.xml', 'doc/src/docbkx/openstack-security/ch011_management-introduction.xml', 'doc/src/docbkx/openstack-security/static/dbblack.jpg', 'doc/src/docbkx/openstack-security/ch037_risks.xml', 'doc/src/docbkx/openstack-security/static/Nicira-byVMware_72.png', 'doc/src/docbkx/openstack-security/ch034_tenant-secure-networking-best-practices.xml', 'doc/src/docbkx/openstack-security/static/nebula-black_1.png', 'doc/src/docbkx/openstack-security/static/networking-interactions.svg', 'doc/src/docbkx/openstack-security/static/untrusted_trusted.svg', 'doc/src/docbkx/openstack-security/static/sdn-connections.svg', 'doc/src/docbkx/openstack-security/ch065_privacy.xml', 'doc/src/docbkx/openstack-security/static/Nicira-byVMware_72_1.png', 'doc/src/docbkx/openstack-security/ch005_security-domains.xml', 'doc/src/docbkx/openstack-security/ch006_introduction-to-case-studies.xml', 'doc/src/docbkx/openstack-security/static/nebula-black.png', 'doc/src/docbkx/openstack-security/static/nsa-logo.png', 'doc/src/docbkx/openstack-security/ch035_case-studies-networking.xml', 'doc/src/docbkx/openstack-security/ch020_ssl-everywhere.xml', 'doc/src/docbkx/openstack-security/ch049_case-studies-tenant-data.xml', 'doc/src/docbkx/openstack-security/static/Networking_Use_Case2-Rough.png', 'doc/src/docbkx/openstack-security/ch028_case-studies-identity-management.xml', 'doc/src/docbkx/openstack-security/ch024_authentication.xml', 'doc/src/docbkx/openstack-security/ch053_case-studies-instance-isolation.xml', 'doc/src/docbkx/openstack-security/static/fm.png', 'doc/src/docbkx/openstack-security/static/secure-boot-arch.graffle', 'doc/src/docbkx/openstack-security/static/conductor3.jpg', 'doc/src/docbkx/openstack-security/static/1aa-logical-quantum-flow.png', 'doc/src/docbkx/openstack-security/static/bridging_security_domains.svg', 'doc/src/docbkx/openstack-security/static/novaconductor.svg', 'doc/src/docbkx/openstack-security/ch043_database-transport-security.xml', 'doc/src/docbkx/openstack-security/ch052_devices.xml', 'doc/src/docbkx/openstack-security/ch048_key-management.xml', 'doc/src/docbkx/openstack-security/static/Bridging Security Domains.jpg', 'doc/src/docbkx/openstack-security/ch031_neutron-architecture.xml', 'doc/src/docbkx/openstack-security/ch058_forensicsincident-response.xml', 'doc/src/docbkx/openstack-security/static/high-capability.png', 'doc/src/docbkx/openstack-security/ch004_book-introduction.xml', 'doc/src/docbkx/openstack-security/static/AttackTypes.jpg', 'doc/src/docbkx/openstack-security/static/sdn-connections.png', 'doc/src/docbkx/openstack-security/static/Red_Hat_RGB_300px_1.png', 'doc/src/docbkx/openstack-security/static/networking-interactions.png', 'doc/src/docbkx/openstack-security/static/svirt_vm_running.png', 'doc/src/docbkx/openstack-security/ch047_data-encryption.xml', 'doc/src/docbkx/openstack-security/static/BridgingSecurityDomains2.png', 'doc/src/docbkx/openstack-security/ch056_case-studies-instance-management.xml', 'doc/src/docbkx/openstack-security/ch025_web-dashboard.xml', 'doc/src/docbkx/openstack-security/static/databaseusername.png', 'doc/src/docbkx/openstack-security/static/cs_1.png'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b21a1b62014abb7dddef4d52e685073db86ccc00', 'message': 'Renames the openstack-security-guide folder to shorter name\n\nShould match the openstack-infra/config file now to fix the build.\n\nfix bug 1201625\n\nChange-Id: Ia3b3d7c17053aa975b9081acbe0f3908c80e484b\n'}]",0,37279,b21a1b62014abb7dddef4d52e685073db86ccc00,5,2,1,964,,,0,"Renames the openstack-security-guide folder to shorter name

Should match the openstack-infra/config file now to fix the build.

fix bug 1201625

Change-Id: Ia3b3d7c17053aa975b9081acbe0f3908c80e484b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/37279/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-security/ch002_why-and-how-we-wrote-this-book.xml', 'doc/src/docbkx/openstack-security/ch032_networking-best-practices.xml', 'doc/src/docbkx/openstack-security/static/Red_Hat_RGB_300px_2.png', 'doc/src/docbkx/openstack-security/static/conductor.jpg', 'doc/src/docbkx/openstack-security/ch062_audit-guidance.xml', 'doc/src/docbkx/openstack-security/static/CommonCriteria.png', 'doc/src/docbkx/openstack-security/static/group.png', 'doc/src/docbkx/openstack-security/ch042_database-overview.xml', 'doc/src/docbkx/openstack-security/static/HP RGB_WEB_1.png', 'doc/src/docbkx/openstack-security/bk_openstack-sec-guide.xml', 'doc/src/docbkx/openstack-security/static/Quantum_Components_Communication.JPG', 'doc/src/docbkx/openstack-security/static/networking-architecture-diagram-2.png', 'doc/src/docbkx/openstack-security/static/node-provisioning-pxe.png', 'doc/src/docbkx/openstack-security/static/filteringWorkflow1.png', 'doc/src/docbkx/openstack-security/static/novaconductor.png', 'doc/src/docbkx/openstack-security/static/bridging_security_domains.png', 'doc/src/docbkx/openstack-security/ch039_case-studies-messaging.xml', 'doc/src/docbkx/openstack-security/static/APL Logo.jpg', 'doc/src/docbkx/openstack-security/static/marketecture-diagram.png', 'doc/src/docbkx/openstack-security/static/Quantum-PhysNet-Diagram.png', 'doc/src/docbkx/openstack-security/static/Rackspace_Cloud_Company_Logo_clr_1.png', 'doc/src/docbkx/openstack-security/ch017_threat-models-confidence-and-confidentiality.xml', 'doc/src/docbkx/openstack-security/ch021_paste-and-middleware.xml', 'doc/src/docbkx/openstack-security/ch059_case-studies-monitoring-logging.xml', 'doc/src/docbkx/openstack-security/static/high-capability.svg', 'doc/src/docbkx/openstack-security/static/bridging_domains_clouduser.svg', 'doc/src/docbkx/openstack-security/ch027_storage.xml', 'doc/src/docbkx/openstack-security/ch033_securing-neutron-services.xml', 'doc/src/docbkx/openstack-security/ch051_vss-intro.xml', 'doc/src/docbkx/openstack-security/static/network-diagram.png', 'doc/src/docbkx/openstack-security/ch008_system-roles-types.xml', 'doc/src/docbkx/openstack-security/ch063_compliance-activities.xml', 'doc/src/docbkx/openstack-security/static/HP RGB_WEB.png', 'doc/src/docbkx/openstack-security/static/cs.png', 'doc/src/docbkx/openstack-security/ch041_database-backend-considerations.xml', 'doc/src/docbkx/openstack-security/static/intel-blue-logo.jpg', 'doc/src/docbkx/openstack-security/static/secure-boot-arch.png', 'doc/src/docbkx/openstack-security/ch013_node-bootstrapping.xml', 'doc/src/docbkx/openstack-security/ch038_transport-security.xml', 'doc/src/docbkx/openstack-security/static/Red_Hat_RGB_300px.png', 'doc/src/docbkx/openstack-security/static/floss_badge_transp.gif', 'doc/src/docbkx/openstack-security/static/CP_Logotype_small.png', 'doc/src/docbkx/openstack-security/static/bridging_security_domains_1.png', 'doc/src/docbkx/openstack-security/ch055_security-services-for-instances.xml', 'doc/src/docbkx/openstack-security/static/threat_actors.svg', 'doc/src/docbkx/openstack-security/static/Nicira-byVMware_logo_V_CL_CMYK.png', 'doc/src/docbkx/openstack-security/static/Quantum_Components_Communication_1.JPG', 'doc/src/docbkx/openstack-security/static/reference.png', 'doc/src/docbkx/openstack-security/static/services-protocols-ports.png', 'doc/src/docbkx/openstack-security/ch026_compute.xml', 'doc/src/docbkx/openstack-security/static/SecurityDomains.jpg', 'doc/src/docbkx/openstack-security/static/hp_cloud_services_blue_logo.png', 'doc/src/docbkx/openstack-security/static/svirt_on_disk.png', 'doc/src/docbkx/openstack-security/static/databaseusernamessl.png', 'doc/src/docbkx/openstack-security/ch015_case-studies-management.xml', 'doc/src/docbkx/openstack-security/ch001_acknowledgements.xml', 'doc/src/docbkx/openstack-security/ch018_case-studies-pkissl.xml', 'doc/src/docbkx/openstack-security/static/networking-architecture-diagram.png', 'doc/src/docbkx/openstack-security/ch064_certifications-compliance-statements.xml', 'doc/src/docbkx/openstack-security/ch030_state-of-networking.xml', 'doc/src/docbkx/openstack-security/pom.xml', 'doc/src/docbkx/openstack-security/ch066_case-studies-compliance.xml', 'doc/src/docbkx/openstack-security/static/dbred.jpg', 'doc/src/docbkx/openstack-security/ch012_configuration-management.xml', 'doc/src/docbkx/openstack-security/ch022_case-studies-api-endpoints.xml', 'doc/src/docbkx/openstack-security/static/sVirt Diagram 1.png', 'doc/src/docbkx/openstack-security/static/Networking_Use_Case1-Rough.png', 'doc/src/docbkx/openstack-security/ch061_compliance-overview.xml', 'doc/src/docbkx/openstack-security/static/SprintWall.jpg', 'doc/src/docbkx/openstack-security/static/ThreatActors.jpg', 'doc/src/docbkx/openstack-security/static/untrusted_trusted.png', 'doc/src/docbkx/openstack-security/static/APL%20center%20blue.png', 'doc/src/docbkx/openstack-security/static/Nicira-byVMware_300.png', 'doc/src/docbkx/openstack-security/static/book-sprint-all-logos.png', 'doc/src/docbkx/openstack-security/static/bridging_domains_clouduser.png', 'doc/src/docbkx/openstack-security/static/node-provisioning-pxe.graffle', 'doc/src/docbkx/openstack-security/static/databaseusername.svg', 'doc/src/docbkx/openstack-security/static/threat_actors.png', 'doc/src/docbkx/openstack-security/static/1aa-network-domains-diagram.png', 'doc/src/docbkx/openstack-security/static/Openstack_Networking_Service_Communication_Channels.JPG', 'doc/src/docbkx/openstack-security/static/bridging_security_domains_1.svg', 'doc/src/docbkx/openstack-security/static/DomainBridging2.jpg', 'doc/src/docbkx/openstack-security/static/insecure-boot-arch.png', 'doc/src/docbkx/openstack-security/ch009_case-studies.xml', 'doc/src/docbkx/openstack-security/ch014_best-practices-for-operator-mode-access.xml', 'doc/src/docbkx/openstack-security/static/Red_Hat_CMYK.svg', 'doc/src/docbkx/openstack-security/static/databaseusernamessl.svg', 'doc/src/docbkx/openstack-security/static/Screen Shot 2013-06-28 at 10.23.28.png', 'doc/src/docbkx/openstack-security/static/Rackspace_Cloud_Company_Logo_clr.png', 'doc/src/docbkx/openstack-security/static/download.png', 'doc/src/docbkx/openstack-security/static/download_1.png', 'doc/src/docbkx/openstack-security/static/logical-quantum-flow.png', 'doc/src/docbkx/openstack-security/ch046_data-residency.xml', 'doc/src/docbkx/openstack-security/ch044_case-studies-database.xml', 'doc/src/docbkx/openstack-security/ch011_management-introduction.xml', 'doc/src/docbkx/openstack-security/static/dbblack.jpg', 'doc/src/docbkx/openstack-security/ch037_risks.xml', 'doc/src/docbkx/openstack-security/static/Nicira-byVMware_72.png', 'doc/src/docbkx/openstack-security/ch034_tenant-secure-networking-best-practices.xml', 'doc/src/docbkx/openstack-security/static/nebula-black_1.png', 'doc/src/docbkx/openstack-security/static/networking-interactions.svg', 'doc/src/docbkx/openstack-security/static/untrusted_trusted.svg', 'doc/src/docbkx/openstack-security/static/sdn-connections.svg', 'doc/src/docbkx/openstack-security/ch065_privacy.xml', 'doc/src/docbkx/openstack-security/static/Nicira-byVMware_72_1.png', 'doc/src/docbkx/openstack-security/ch005_security-domains.xml', 'doc/src/docbkx/openstack-security/ch006_introduction-to-case-studies.xml', 'doc/src/docbkx/openstack-security/static/nebula-black.png', 'doc/src/docbkx/openstack-security/static/nsa-logo.png', 'doc/src/docbkx/openstack-security/ch035_case-studies-networking.xml', 'doc/src/docbkx/openstack-security/ch020_ssl-everywhere.xml', 'doc/src/docbkx/openstack-security/ch049_case-studies-tenant-data.xml', 'doc/src/docbkx/openstack-security/static/Networking_Use_Case2-Rough.png', 'doc/src/docbkx/openstack-security/ch028_case-studies-identity-management.xml', 'doc/src/docbkx/openstack-security/ch024_authentication.xml', 'doc/src/docbkx/openstack-security/ch053_case-studies-instance-isolation.xml', 'doc/src/docbkx/openstack-security/static/fm.png', 'doc/src/docbkx/openstack-security/static/secure-boot-arch.graffle', 'doc/src/docbkx/openstack-security/static/conductor3.jpg', 'doc/src/docbkx/openstack-security/static/1aa-logical-quantum-flow.png', 'doc/src/docbkx/openstack-security/static/bridging_security_domains.svg', 'doc/src/docbkx/openstack-security/static/novaconductor.svg', 'doc/src/docbkx/openstack-security/ch043_database-transport-security.xml', 'doc/src/docbkx/openstack-security/ch052_devices.xml', 'doc/src/docbkx/openstack-security/ch048_key-management.xml', 'doc/src/docbkx/openstack-security/static/Bridging Security Domains.jpg', 'doc/src/docbkx/openstack-security/ch031_neutron-architecture.xml', 'doc/src/docbkx/openstack-security/ch058_forensicsincident-response.xml', 'doc/src/docbkx/openstack-security/static/high-capability.png', 'doc/src/docbkx/openstack-security/ch004_book-introduction.xml', 'doc/src/docbkx/openstack-security/static/AttackTypes.jpg', 'doc/src/docbkx/openstack-security/static/sdn-connections.png', 'doc/src/docbkx/openstack-security/static/Red_Hat_RGB_300px_1.png', 'doc/src/docbkx/openstack-security/static/networking-interactions.png', 'doc/src/docbkx/openstack-security/static/svirt_vm_running.png', 'doc/src/docbkx/openstack-security/ch047_data-encryption.xml', 'doc/src/docbkx/openstack-security/static/BridgingSecurityDomains2.png', 'doc/src/docbkx/openstack-security/ch056_case-studies-instance-management.xml', 'doc/src/docbkx/openstack-security/ch025_web-dashboard.xml', 'doc/src/docbkx/openstack-security/static/databaseusername.png', 'doc/src/docbkx/openstack-security/static/cs_1.png']",141,b21a1b62014abb7dddef4d52e685073db86ccc00,bug/1201625,,,0,0
openstack%2Fglance~master~Ib438989f2dd00952a1a1647c101269055088ddaa,openstack/glance,master,Ib438989f2dd00952a1a1647c101269055088ddaa,removed unused variable 'registry_port',MERGED,2013-07-15 20:45:12.000000000,2013-07-16 16:46:27.000000000,2013-07-16 16:46:27.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 2166}, {'_account_id': 2537}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-07-15 20:45:12.000000000', 'files': ['glance/tests/functional/test_cache_middleware.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/629632032948faf63cbb67b2cbe19e4e72aa4b9b', 'message': ""removed unused variable 'registry_port'\n\nThe unused variable 'registry_port' has been removed from function\n'test_cache_manage_delete_cached_images'\n\nFixes bug 1201585\n\nChange-Id: Ib438989f2dd00952a1a1647c101269055088ddaa\n""}]",0,37127,629632032948faf63cbb67b2cbe19e4e72aa4b9b,8,5,1,8158,,,0,"removed unused variable 'registry_port'

The unused variable 'registry_port' has been removed from function
'test_cache_manage_delete_cached_images'

Fixes bug 1201585

Change-Id: Ib438989f2dd00952a1a1647c101269055088ddaa
",git fetch https://review.opendev.org/openstack/glance refs/changes/27/37127/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/functional/test_cache_middleware.py'],1,629632032948faf63cbb67b2cbe19e4e72aa4b9b,bug/1201585,, registry_port = self.registry_port,0,1
openstack%2Fneutron~master~I0978d1c38ac5c38c4548e5b1877857bb5cac3b81,openstack/neutron,master,I0978d1c38ac5c38c4548e5b1877857bb5cac3b81,Improve l3-agent performance and prevent races in it.,MERGED,2013-07-12 19:52:37.000000000,2013-07-16 16:46:18.000000000,2013-07-16 16:46:17.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 308}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2750}, {'_account_id': 2874}, {'_account_id': 4395}]","[{'number': 1, 'created': '2013-07-12 19:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/63910bed1eca7b76ace128175e9d9a600adf191b', 'message': ""Fix race confition in l3-agent and improve performance\n\nWhen I boot 10 vm, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere is some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\ncall by order which has been called. This will lose\nsome configrations\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC stucks.\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configrations.\n\n- Each router run is executed in batch way.\n\nIn this patch, I took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nI expect this patch fixes bug 1194026.\nfixes 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 2, 'created': '2013-07-12 19:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2acf25dfc4e67ea7be62664c6030e66fdae316a5', 'message': ""Fix race confition in l3-agent and improve performance\n\nWhen I boot 10 vm, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere is some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\ncall by order which has been called. This will lose\nsome configrations\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC stucks.\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configrations.\n\n- Each router run is executed in batch way.\n\nIn this patch, I took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nI expect this patch fixes bug 1194026.\nfixes 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 3, 'created': '2013-07-12 22:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f7b6414897a9f3beda6c49dd3a07b3c2c8b75135', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026.\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 4, 'created': '2013-07-12 22:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5847b660ff613665373840fcb8a0906fc28aa70a', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 5, 'created': '2013-07-12 22:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/debe848db8b1c93f970c3f54ed868ad214f1b7e3', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 6, 'created': '2013-07-13 00:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ec27018131553d8bec4c7a12f809769317e88c8', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 7, 'created': '2013-07-13 01:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/071edbc1848590cae1c7734be549f0ab3b80f72a', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 8, 'created': '2013-07-13 05:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7265410fa6a59c1126a87aa8a76bd3cdbdb5cd18', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 9, 'created': '2013-07-13 06:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/28fa41fedb0358d4ebaa918a0c0373844f0de8fd', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 10, 'created': '2013-07-13 06:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/81ce6216161b071075ff4a2b4a79aaacc7d9a8e6', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 11, 'created': '2013-07-13 06:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c7d664e5fc6c7e0ec1eecd9d71930ef2dab2d31', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 12, 'created': '2013-07-13 07:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c11b4e92adc8df2d87c76e8bb8bf31aa582af96f', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 13, 'created': '2013-07-13 20:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a721d3434c83a9f67636ac76a9deeaabda4b56f', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 14, 'created': '2013-07-15 17:19:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/110e9dcbc0568234100cf136c68ec752761f9411', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- Iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\n- Remove sync data from server side notification.\nThis changes needs a fix for transaction.\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 15, 'created': '2013-07-15 18:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8519246fd93de5eff155e17d296b3dda2260c021', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- Iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\n- Remove sync data from server side notification.\nThis changes needs a fix for transaction.\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 16, 'created': '2013-07-15 19:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b7753f778d5a9def7ff39302ee329268cde8c488', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- Iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\n- Remove sync data from server side notification.\nThis changes needs a fix for transaction.\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 17, 'created': '2013-07-15 21:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99228521848ecff20de70ae395b8eb7d69e9d1ce', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- Iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\n- Remove sync data from server side notification.\nThis changes needs a fix for transaction.\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 18, 'created': '2013-07-15 22:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dea0c237bc7b71e4f3eaaa3ed00173ac3d216082', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- Iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\n- Remove sync data from server side notification.\nThis changes needs a fix for transaction.\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 19, 'created': '2013-07-15 23:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/657c77b0481f2efa9737664d83a58fa164c75d6b', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- Iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\n- Remove sync data from server side notification.\nThis changes needs a fix for transaction.\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 20, 'created': '2013-07-16 00:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/95314df6cd8f913462dd61abf4cffadbc801ef47', 'message': ""Fix race condition in l3-agent and improve performance\n\nWhen we boot 10 vms, and assign 10 floatings ips,\nonly about half of it will be configured in 60 sec.\nThere are some timing issue and perfomances issues.\n\n- Current l3-agent will not execute rpc\nRe-ordering of rpc message execution will lose\nsome configuration.\n\n- Iptables apply is a heavy operation.\nBut it is used in several places.\n\n- Sometimes RPC will temporarily block for unexpectedly long periods\nso let's say we got 10 floating ip update rpc request\nfor a server during processsing routers.\nIn this case, it is enough to process the last call.\nHowever current implementation will process all requests.\nThis will delayed 10th floating ip configurations.\n\n- Each router run is executed in batch way.\n\nIn this patch, we took very simple and safe strategy.\n\n- Any update rpc call will simply set fullsync=true\n- rpcloop will check the fullsync for each sec, then\nexecute fullsync\n- use iptables_manager.defer_apply_on\n- spawn for each router operation\n\n- Remove sync data from server side notification.\nThis changes needs a fix for transaction.\n\nThis patch makes the 10 floating ips test works.\n\nThis patch will increases requests for servers,\nhowever this could be future work.\n\nFixes bug 1194026\nFixes bug 1200749\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n""}, {'number': 21, 'created': '2013-07-16 00:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b86e67d098ce03fdf90ba17875378f90ce2b82a1', 'message': 'Improve l3-agent performance and prevent races in it.\n\nFixes bug 1194026\nFixes bug 1200749\n\nIntroduce a looping call for performing synchronization with\nneutron server.\nThe sync will be performed only if router changes are notified\nvia rpc. Only affected routers will be synchronized.\n\nChanges will be implemented by the l3 agent spawning a\ndistinct greenthread for each router - iptables will\nbe executed only once using iptables_manager.defer_apply_on.\n\nThis patch will prevent the occurence of the following issues:\n- Out-of-order rpc message processing\n- Long processing time for router changes due to serial execution\n- Occasional and expected RPC blocks for long periods\n- Unnecessary processing of multiple requests\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n'}, {'number': 22, 'created': '2013-07-16 01:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b43e9df93dec273fb53b96f724873ec9578be7e1', 'message': 'Improve l3-agent performance and prevent races in it.\n\nFixes bug 1194026\nFixes bug 1200749\n\nIntroduce a looping call for performing synchronization with\nneutron server.\nThe sync will be performed only if router changes are notified\nvia rpc. Only affected routers will be synchronized.\n\nChanges will be implemented by the l3 agent spawning a\ndistinct greenthread for each router - iptables will\nbe executed only once using iptables_manager.defer_apply_on.\n\nThis patch will prevent the occurence of the following issues:\n- Out-of-order rpc message processing\n- Long processing time for router changes due to serial execution\n- Occasional and expected RPC blocks for long periods\n- Unnecessary processing of multiple requests\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n'}, {'number': 23, 'created': '2013-07-16 13:20:25.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/db/agentschedulers_db.py', 'neutron/db/l3_db.py', 'neutron/scheduler/l3_agent_scheduler.py', 'neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/57e1fa32648a28ae83e3c3033258fe08de2e5fca', 'message': 'Improve l3-agent performance and prevent races in it.\n\nFixes bug 1194026\nFixes bug 1200749\n\nIntroduce a looping call for performing synchronization with\nneutron server.\nThe sync will be performed only if router changes are notified\nvia rpc. Only affected routers will be synchronized.\n\nChanges will be implemented by the l3 agent spawning a\ndistinct greenthread for each router - iptables will\nbe executed only once using iptables_manager.defer_apply_on.\n\nThis patch will prevent the occurence of the following issues:\n- Out-of-order rpc message processing\n- Long processing time for router changes due to serial execution\n- Occasional and expected RPC blocks for long periods\n- Unnecessary processing of multiple requests\n\nChange-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81\n'}]",88,36890,57e1fa32648a28ae83e3c3033258fe08de2e5fca,116,12,23,2031,,,0,"Improve l3-agent performance and prevent races in it.

Fixes bug 1194026
Fixes bug 1200749

Introduce a looping call for performing synchronization with
neutron server.
The sync will be performed only if router changes are notified
via rpc. Only affected routers will be synchronized.

Changes will be implemented by the l3 agent spawning a
distinct greenthread for each router - iptables will
be executed only once using iptables_manager.defer_apply_on.

This patch will prevent the occurence of the following issues:
- Out-of-order rpc message processing
- Long processing time for router changes due to serial execution
- Occasional and expected RPC blocks for long periods
- Unnecessary processing of multiple requests

Change-Id: I0978d1c38ac5c38c4548e5b1877857bb5cac3b81
",git fetch https://review.opendev.org/openstack/neutron refs/changes/90/36890/20 && git format-patch -1 --stdout FETCH_HEAD,"['etc/l3_agent.ini', 'neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py']",3,63910bed1eca7b76ace128175e9d9a600adf191b,bug/1194026, # verify that will set fullsync self.assertTrue(agent.fullsync)," # verify that remove is called self.assertEqual(self.mock_ip.get_devices.call_count, 1) self.device_exists.assert_has_calls( [mock.call(self.conf.external_network_bridge)])",47,43
openstack%2Fglance~master~I31543afed31512f8f5f613640012bc7c1d7ea993,openstack/glance,master,I31543afed31512f8f5f613640012bc7c1d7ea993,index checksum image property,MERGED,2013-07-02 13:08:37.000000000,2013-07-16 16:46:14.000000000,2013-07-16 16:46:13.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 2537}, {'_account_id': 4463}, {'_account_id': 6493}, {'_account_id': 7491}, {'_account_id': 7701}, {'_account_id': 7780}]","[{'number': 1, 'created': '2013-07-02 13:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e02cdfa398c64f48c3e577d874c0c9b465fc260d', 'message': 'index checksum image property\n\nchecksum image property will be indexed so that users can search for an\nimage by specifying the checksum\n\nChange-Id: I31543afed31512f8f5f613640012bc7c1d7ea993\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 2, 'created': '2013-07-03 07:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/986bbf11de871315f12b49991338642e336e7c1f', 'message': 'index checksum image property\n\nchecksum image property will be indexed so that users can search for an\nimage by specifying the checksum\n\nChange-Id: I31543afed31512f8f5f613640012bc7c1d7ea993\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 3, 'created': '2013-07-10 05:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0cd0d8b9b8eb3e332605acc8b9cb533a653122a7', 'message': 'index checksum image property\n\nchecksum image property will be indexed so that users can search for an\nimage by specifying the checksum\n\nChange-Id: I31543afed31512f8f5f613640012bc7c1d7ea993\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 4, 'created': '2013-07-10 06:49:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/38fa4559f2b2248f48d680850d0a1f82f0420c0e', 'message': 'index checksum image property\n\nchecksum image property will be indexed so that users can search for an\nimage by specifying the checksum\n\nChange-Id: I31543afed31512f8f5f613640012bc7c1d7ea993\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 5, 'created': '2013-07-10 09:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/264de36417f41c997986ce1296ec7158bb10c8e5', 'message': 'index checksum image property\n\nchecksum image property will be indexed so that users can search for an\nimage by specifying the checksum\n\nChange-Id: I31543afed31512f8f5f613640012bc7c1d7ea993\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 6, 'created': '2013-07-11 07:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b84c4b4716dc4d901f6a04cde7411ba49ad46512', 'message': 'index checksum image property\n\nchecksum image property will be indexed so that users can search for an\nimage by specifying the checksum\n\nChange-Id: I31543afed31512f8f5f613640012bc7c1d7ea993\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 7, 'created': '2013-07-12 09:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c59d3129265691518f23893c780e3ee3d33d2785', 'message': 'index checksum image property\n\nchecksum image property will be indexed so that users can search for an\nimage by specifying the checksum\n\nChange-Id: I31543afed31512f8f5f613640012bc7c1d7ea993\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 8, 'created': '2013-07-12 11:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/377d62af14958a71dbae277cc82cf5c6b0badee7', 'message': 'index checksum image property\n\nchecksum image property will be indexed so that users can search for an\nimage by specifying the checksum\n\nChange-Id: I31543afed31512f8f5f613640012bc7c1d7ea993\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 9, 'created': '2013-07-16 09:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e2dfa727495e9024ad5350858f2f838e74d50193', 'message': 'index checksum image property\n\nchecksum image property will be indexed so that users can search for an\nimage by specifying the checksum\n\nChange-Id: I31543afed31512f8f5f613640012bc7c1d7ea993\nImplements: blueprint index-using-checksum-image-property\n'}, {'number': 10, 'created': '2013-07-16 10:51:41.000000000', 'files': ['glance/tests/unit/test_migrations.py', 'glance/tests/unit/test_db.py', 'glance/db/sqlalchemy/api.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/db/sqlalchemy/models.py', 'glance/db/sqlalchemy/migrate_repo/versions/027_checksum_index.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/5670f142d4fc6ac0b09dfd934c4a2da86b2f36fe', 'message': 'index checksum image property\n\nchecksum image property will be indexed so that users can search for an\nimage by specifying the checksum\n\nChange-Id: I31543afed31512f8f5f613640012bc7c1d7ea993\nImplements: blueprint index-using-checksum-image-property\n'}]",29,35289,5670f142d4fc6ac0b09dfd934c4a2da86b2f36fe,50,9,10,7701,,,0,"index checksum image property

checksum image property will be indexed so that users can search for an
image by specifying the checksum

Change-Id: I31543afed31512f8f5f613640012bc7c1d7ea993
Implements: blueprint index-using-checksum-image-property
",git fetch https://review.opendev.org/openstack/glance refs/changes/89/35289/10 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_db.py', 'glance/db/sqlalchemy/api.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/db/sqlalchemy/migrate_repo/versions/026_checksum_index.py', 'glance/db/sqlalchemy/models.py']",5,e02cdfa398c64f48c3e577d874c0c9b465fc260d,bp/index-using-checksum-image-property," checksum = Column(String(32), index=True)", checksum = Column(String(32)),52,5
openstack%2Fnova~master~I9c11ff723d3001499ada54786d09ff397e8fb6e2,openstack/nova,master,I9c11ff723d3001499ada54786d09ff397e8fb6e2,Move dnsdomain_* tests in test_db_api to own test case.,MERGED,2013-07-15 16:25:40.000000000,2013-07-16 16:45:54.000000000,2013-07-16 16:45:52.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2835}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-07-15 16:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e282e5c91defb3c87555d1c3c9d39c1c460f1053', 'message': 'dnsdomain_* tests refactoring in test_db_api\n\ndnsdomain_* tests moved to its own test case.\nMissing test added.\n\nblueprint db-api-tests\n\nChange-Id: I9c11ff723d3001499ada54786d09ff397e8fb6e2\n'}, {'number': 2, 'created': '2013-07-16 07:57:13.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2ca7f2988d0005fa1fc3a158bbf69b12a56d8dce', 'message': 'Move dnsdomain_* tests in test_db_api to own test case.\n\nThere is dnsdomain_* tests in old mixed DbApiTestCase.\nThis patch moves them to its own test case DnsdomainTestCase.\n\nMissing test_dnsdomain_unregister added.\n\nblueprint db-api-tests\n\nChange-Id: I9c11ff723d3001499ada54786d09ff397e8fb6e2\n'}]",3,37085,2ca7f2988d0005fa1fc3a158bbf69b12a56d8dce,14,6,2,7711,,,0,"Move dnsdomain_* tests in test_db_api to own test case.

There is dnsdomain_* tests in old mixed DbApiTestCase.
This patch moves them to its own test case DnsdomainTestCase.

Missing test_dnsdomain_unregister added.

blueprint db-api-tests

Change-Id: I9c11ff723d3001499ada54786d09ff397e8fb6e2
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/37085/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,e282e5c91defb3c87555d1c3c9d39c1c460f1053,bp/db-api-tests,"class DnsdomainTestCase(test.TestCase): def setUp(self): super(DnsdomainTestCase, self).setUp() self.ctxt = context.get_admin_context() self.domain = 'test.domain' self.testzone = 'testzone' self.project = 'fake' def test_dnsdomain_register_for_zone(self): db.dnsdomain_register_for_zone(self.ctxt, self.domain, self.testzone) domain = db.dnsdomain_get(self.ctxt, self.domain) self.assertEqual(domain['domain'], self.domain) self.assertEqual(domain['availability_zone'], self.testzone) self.assertEqual(domain['scope'], 'private') def test_dnsdomain_register_for_project(self): db.dnsdomain_register_for_project(self.ctxt, self.domain, self.project) domain = db.dnsdomain_get(self.ctxt, self.domain) self.assertEqual(domain['domain'], self.domain) self.assertEqual(domain['project_id'], self.project) self.assertEqual(domain['scope'], 'public') def test_dnsdomain_list(self): d_list = ['test.domain.one', 'test.domain.two'] db.dnsdomain_register_for_zone(self.ctxt, d_list[0], self.testzone) db.dnsdomain_register_for_project(self.ctxt, d_list[1], self.project) db_list = db.dnsdomain_list(self.ctxt) self.assertEqual(sorted(d_list), sorted(db_list)) def test_dnsdomain_unregister(self): db.dnsdomain_register_for_zone(self.ctxt, self.domain, self.testzone) db.dnsdomain_unregister(self.ctxt, self.domain) domain = db.dnsdomain_get(self.ctxt, self.domain) self.assertIsNone(domain) "," def test_dns_registration(self): domain1 = 'test.domain.one' domain2 = 'test.domain.two' testzone = 'testzone' ctxt = context.get_admin_context() db.dnsdomain_register_for_zone(ctxt, domain1, testzone) domain_ref = db.dnsdomain_get(ctxt, domain1) zone = domain_ref['availability_zone'] scope = domain_ref['scope'] self.assertEqual(scope, 'private') self.assertEqual(zone, testzone) db.dnsdomain_register_for_project(ctxt, domain2, self.project_id) domain_ref = db.dnsdomain_get(ctxt, domain2) project = domain_ref['project_id'] scope = domain_ref['scope'] self.assertEqual(project, self.project_id) self.assertEqual(scope, 'public') expected = [domain1, domain2] domains = db.dnsdomain_list(ctxt) self.assertEqual(expected, domains) db.dnsdomain_unregister(ctxt, domain1) db.dnsdomain_unregister(ctxt, domain2) ",37,28
openstack%2Fnova~master~Ie25054590286d994bc6748ca85944fa65dcf3d4d,openstack/nova,master,Ie25054590286d994bc6748ca85944fa65dcf3d4d,Remove duplicated key_pair* tests from test_db_api.,MERGED,2013-07-15 14:41:27.000000000,2013-07-16 16:45:32.000000000,2013-07-16 16:45:29.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2835}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-07-15 14:41:27.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3ae9fd6632b0473f32693fbc2d3464a61a7fb6be', 'message': 'Remove duplicated key_pair* tests from test_db_api.\n\nThere is some key_pair* tests in old DbApiTestCase\nwhich are duplicated in new KeyPairTestCase.\nThis patch simply remove them.\n\nblueprint db-api-tests\n\nChange-Id: Ie25054590286d994bc6748ca85944fa65dcf3d4d\n'}]",2,37065,3ae9fd6632b0473f32693fbc2d3464a61a7fb6be,9,6,1,7711,,,0,"Remove duplicated key_pair* tests from test_db_api.

There is some key_pair* tests in old DbApiTestCase
which are duplicated in new KeyPairTestCase.
This patch simply remove them.

blueprint db-api-tests

Change-Id: Ie25054590286d994bc6748ca85944fa65dcf3d4d
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/37065/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,3ae9fd6632b0473f32693fbc2d3464a61a7fb6be,bp/db-api-tests,," def test_add_key_pair(self, name=None): """"""Check if keypair creation work as expected."""""" keypair = { 'user_id': self.user_id, 'name': name or 'test-keypair', 'fingerprint': '15:b0:f8:b3:f9:48:63:71:cf:7b:5b:38:6d:44:2d:4a', 'private_key': 'private_key_value', 'public_key': 'public_key_value' } result_key = db.key_pair_create(context.get_admin_context(), keypair) for label in keypair: self.assertEqual(keypair[label], result_key[label]) def test_key_pair_destroy(self): """"""Check if key pair deletion works as expected."""""" keypair_name = 'test-delete-keypair' self.test_add_key_pair(name=keypair_name) db.key_pair_destroy(context.get_admin_context(), self.user_id, keypair_name) self.assertRaises(exception.KeypairNotFound, db.key_pair_get, context.get_admin_context(), self.user_id, keypair_name) def test_key_pair_get(self): """"""Test if a previously created keypair can be found."""""" keypair_name = 'test-get-keypair' self.test_add_key_pair(name=keypair_name) result = db.key_pair_get(context.get_admin_context(), self.user_id, keypair_name) self.assertEqual(result.name, keypair_name) def test_key_pair_get_all_by_user(self): self.assertTrue(isinstance(db.key_pair_get_all_by_user( context.get_admin_context(), self.user_id), list)) def test_delete_non_existent_key_pair(self): self.assertRaises(exception.KeypairNotFound, db.key_pair_destroy, context.get_admin_context(), self.user_id, 'non-existent-keypair') def test_get_non_existent_key_pair(self): self.assertRaises(exception.KeypairNotFound, db.key_pair_get, context.get_admin_context(), self.user_id, 'invalid-key') ",0,45
openstack%2Fnova~master~Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1,openstack/nova,master,Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1,Add missing tests for db.api.instance_* methods,MERGED,2013-06-21 12:16:45.000000000,2013-07-16 16:45:09.000000000,2013-07-16 16:45:06.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2835}, {'_account_id': 2889}, {'_account_id': 6172}, {'_account_id': 6661}, {'_account_id': 7369}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-06-21 12:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcbaa5c91ba3630355a297ce5099e2956854c4fb', 'message': 'Add missing tests for db.api.instance_* methods\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 2, 'created': '2013-06-21 13:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa9c763ba1a329d4be0a91c2b032f160599c0e72', 'message': 'Add missing tests for db.api.instance_* methods\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 3, 'created': '2013-06-27 07:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5948b1d3bd775ba51768b84308cc57c2540e84c1', 'message': 'Add missing tests for db.api.instance_* methods\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 4, 'created': '2013-06-27 09:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/177a7298c157efb1c78de03421ce4e5ed3351fa7', 'message': 'Add missing tests for db.api.instance_* methods\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 5, 'created': '2013-07-01 09:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a201583a03633746d7093c0ad1c31c591a30a78', 'message': 'Add missing tests for db.api.instance_* methods\n\nAdd missing and fixed existing tests.\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 6, 'created': '2013-07-02 06:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dff1ee7e84fe3f06c2981ac5beada2e62c8369ea', 'message': 'Add missing tests for db.api.instance_* methods\n\nAdd missing and fixed existing tests.\n\nMostly replaced assertEqual(2, len(result)) by _assertEqualListOfInstances\nand some other minor nits.\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 7, 'created': '2013-07-03 11:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47c03256bfe5684869fc2fbc9e3e18bb24b9a5f7', 'message': 'Add missing tests for db.api.instance_* methods\n\nAdd missing and fixed existing tests.\n\nMostly replaced assertEqual(2, len(result)) by _assertEqualListOfInstances\nand some other minor nits.\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 8, 'created': '2013-07-04 15:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a4794a9c2735283aee1c6ce97378249aa1c82bc', 'message': 'Add missing tests for db.api.instance_* methods\n\nAdd missing and fixed existing tests.\n\nMostly replaced assertEqual(2, len(result)) by _assertEqualListOfInstances\nand some other minor nits.\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 9, 'created': '2013-07-04 15:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7557f5894d8bbc6486965315b61647293cb6ce9c', 'message': 'Add missing tests for db.api.instance_* methods\n\nAdd missing and fixed existing tests.\n\nMostly replaced assertEqual(2, len(result)) by _assertEqualListOfInstances\nand some other minor nits.\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 10, 'created': '2013-07-10 13:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5ae74bd9a909826480a491022dc47eabfc578c31', 'message': 'Add missing tests for db.api.instance_* methods\n\nAdd missing and fixed existing tests.\n\nMostly replaced assertEqual(2, len(result)) by _assertEqualListOfInstances\nand some other minor nits.\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 11, 'created': '2013-07-10 15:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5efb970d72ddac7924e10518ea55823a960fdd72', 'message': 'Add missing tests for db.api.instance_* methods\n\nAdd missing and fixed existing tests.\n\nMostly replaced assertEqual(2, len(result)) by _assertEqualListOfInstances\nand some other minor nits.\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}, {'number': 12, 'created': '2013-07-15 14:10:28.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/82977dbc27faaf1524e576811aaa114dd9e215a4', 'message': 'Add missing tests for db.api.instance_* methods\n\nAdd missing and fixed existing tests.\n\nMostly replaced assertEqual(2, len(result)) by _assertEqualListOfInstances\nand some other minor nits.\n\nblueprint db-api-tests\n\nChange-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1\n'}]",9,33962,82977dbc27faaf1524e576811aaa114dd9e215a4,75,10,12,7369,,,0,"Add missing tests for db.api.instance_* methods

Add missing and fixed existing tests.

Mostly replaced assertEqual(2, len(result)) by _assertEqualListOfInstances
and some other minor nits.

blueprint db-api-tests

Change-Id: Ia81dc1d75cbceb3ab882a02a66b3d9ce292816c1
",git fetch https://review.opendev.org/openstack/nova refs/changes/62/33962/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,dcbaa5c91ba3630355a297ce5099e2956854c4fb,bp/db-api-tests,"class InstanceTestCase(test.TestCase, ModelsObjectComparatorMixin): sample_data = { 'project_id': 'project1', 'hostname': 'example.com', 'host': 'h1', 'node': 'n1', 'metadata': {'mkey1': 'mval1', 'mkey2': 'mval2'}, 'system_metadata': {'smkey1': 'smval1', 'smkey2': 'smval2'}, 'info_cache': {'ckey': 'cvalue'}, } self.ctxt = context.get_admin_context() def _assertEqualInstances(self, instance1, instance2): self._assertEqualObjects(instance1, instance2, ignored_keys=['metadata', 'system_metadata', 'info_cache']) def _assertEqualListsOfInstances(self, list1, list2): self._assertEqualListsOfObjects(list1, list2, ignored_keys=['metadata', 'system_metadata', 'info_cache']) def create_instance_with_args(self, **kwargs): if 'context' in kwargs: context = kwargs.pop('context') else: context = self.ctxt args = self.sample_data.copy() args.update(kwargs) return db.instance_create(context, args) def test_instance_create(self): instance = self.create_instance_with_args() self.assertTrue(uuidutils.is_uuid_like(instance['uuid'])) def test_instance_get_all_with_meta(self): inst = self.create_instance_with_args() for inst in db.instance_get_all(self.ctxt): meta = utils.metadata_to_dict(inst['metadata']) self.assertEqual(meta, self.sample_data['metadata']) sys_meta = utils.metadata_to_dict(inst['system_metadata']) self.assertEqual(sys_meta, self.sample_data['system_metadata']) def test_instance_metadata_get_all_query(self): i1 = self.create_instance_with_args(metadata={'k1': 'v1'}) i2 = self.create_instance_with_args(metadata={'k2': 'v2'}) expected1 = {'instance_id': i1['uuid'], 'key': 'k1', 'value': 'v1'} expected2 = {'instance_id': i2['uuid'], 'key': 'k2', 'value': 'v2'} result = db.instance_metadata_get_all(self.ctxt, []) self.assertEqual(sorted(result), sorted([expected1, expected2])) result = db.instance_metadata_get_all(self.ctxt, [{'key': 'k1'}]) self.assertEqual(result, [expected1]) result = db.instance_metadata_get_all(self.ctxt, [{'value': 'v2'}]) self.assertEqual(result, [expected2]) result = db.instance_metadata_get_all(self.ctxt, [{'value': 'v1'}, {'key': 'k2'}]) self.assertEqual(sorted(result), sorted([expected1, expected2])) result = db.instance_metadata_get_all(self.ctxt, [{'value': 'v3'}]) self.assertEqual(result, []) def test_instance_update(self): instance = self.create_instance_with_args() metadata = {'host': 'bar', 'key2': 'wuff'} system_metadata = {'original_image_ref': 'baz'} # Update the metadata db.instance_update(self.ctxt, instance['uuid'], {'metadata': metadata, 'system_metadata': system_metadata}) # Retrieve the user-provided metadata to ensure it was successfully # updated self.assertEqual(metadata, db.instance_metadata_get(self.ctxt, instance['uuid'])) self.assertEqual(system_metadata, db.instance_system_metadata_get(self.ctxt, instance['uuid'])) context1 = context.RequestContext('user1', 'p1') context2 = context.RequestContext('user2', 'p2') self.create_instance_with_args(hostname='h1', project_id='p1') context=context1, hostname='h1', project_id='p3') context=context2, hostname='h1', project_id='p2') context=context1, hostname='h1', project_id='p1') self.create_instance_with_args(context=context2, hostname='h2') for inst in db.instance_get_all(self.ctxt): self.assertEqual(meta, self.sample_data['metadata']) self.assertEqual(sys_meta, self.sample_data['system_metadata']) for inst in db.instance_get_all_by_filters(self.ctxt, {}): self.assertEqual(meta, self.sample_data['metadata']) self.assertEqual(sys_meta, self.sample_data['system_metadata']) result = db.instance_get_all_by_filters(self.ctxt, {}, instances = [self.create_instance_with_args() for i in range(3)] filtered_instances = db.instance_get_all_by_filters(self.ctxt, {}) self._assertEqualListsOfInstances(instances, filtered_instances) i1 = self.create_instance_with_args(display_name='test1') i2 = self.create_instance_with_args(display_name='teeeest2') result = db.instance_get_all_by_filters(self.ctxt, self._assertEqualListsOfInstances(result, [i1, i2]) instance = self.create_instance_with_args(host='host1') result = db.instance_get_all_by_filters(self.ctxt, self._assertEqualListsOfInstances([instance], result) instance = self.create_instance_with_args(metadata={'foo': 'bar'}) result = db.instance_get_all_by_filters(self.ctxt, self._assertEqualListsOfInstances([instance], result) instance = self.create_instance_with_args(display_name=u'test♥') result = db.instance_get_all_by_filters(self.ctxt, self._assertEqualListsOfInstances([instance], result) result = db.instance_get_by_uuid(self.ctxt, inst['uuid']) self._assertEqualInstances(inst, result) result = db.instance_get_by_uuid(self.ctxt, inst['uuid'], result = db.instance_get_by_uuid(self.ctxt, inst['uuid'], columns_to_join=['metadata']) self.assertEqual(meta, self.sample_data['metadata']) result = db.instance_get_by_uuid(self.ctxt, inst['uuid'], self.assertEqual(sys_meta, self.sample_data['system_metadata']) db.instance_destroy(self.ctxt, inst1['uuid']) result = db.instance_get_all_by_filters(self.ctxt, {}) self._assertEqualListsOfObjects([inst1, inst2], result, ignored_keys=['metadata', 'system_metadata', 'deleted', 'deleted_at', 'info_cache']) db.instance_destroy(self.ctxt, inst1['uuid']) result = db.instance_get_all_by_filters(self.ctxt, self._assertEqualListsOfObjects([inst1, inst2], result, ignored_keys=['metadata', 'system_metadata', 'deleted', 'deleted_at', 'info_cache']) db.instance_destroy(self.ctxt, inst1['uuid']) result = db.instance_get_all_by_filters(self.ctxt, self._assertEqualListsOfObjects([inst1], result, ignored_keys=['deleted', 'deleted_at', 'metadata', 'system_metadata', 'info_cache']) db.instance_destroy(self.ctxt, inst1['uuid']) result = db.instance_get_all_by_filters(self.ctxt, self._assertEqualListsOfInstances([inst2, inst3], result) instance = self.create_instance_with_args() result = db.instance_get_all_by_host_and_node(self.ctxt, 'h1', 'n1') self._assertEqualListsOfObjects([instance], result, ignored_keys=['metadata', 'system_metadata', 'info_cache', 'security_groups']) self.assertEqual(result[0]['system_metadata'], []) results = db.instance_get_all_hung_in_rebooting(self.ctxt, 10) self.assertEqual([], results) instance = self.create_instance_with_args(task_state=""rebooting"", updated_at=datetime.datetime(2000, 01, 01, 12, 00, 00)) results = db.instance_get_all_hung_in_rebooting(self.ctxt, 10) self._assertEqualListsOfObjects([instance], results, ignored_keys=['task_state', 'info_cache', 'security_groups', 'metadata', 'system_metadata']) db.instance_update(self.ctxt, instance['uuid'], {""task_state"": None}) instance = self.create_instance_with_args(task_state=""rebooting"", updated_at=timeutils.utcnow()) results = db.instance_get_all_hung_in_rebooting(self.ctxt, 10) self.assertEqual([], results) instance = self.create_instance_with_args(vm_state='foo') db.instance_update(self.ctxt, instance['uuid'], {'host': 'h1', 'expected_vm_state': ('foo', 'bar')}) instance = self.create_instance_with_args(vm_state='foo') db.instance_update, self.ctxt, instance['uuid'], {'host': 'h1', 'expected_vm_state': ('spam', 'bar')}) def test_instance_update_with_and_get_original(self): instance = self.create_instance_with_args(vm_state='building') (old_ref, new_ref) = db.instance_update_and_get_original(self.ctxt, instance['uuid'], {'vm_state': 'needscoffee'}) self.assertEqual('building', old_ref['vm_state']) self.assertEqual('needscoffee', new_ref['vm_state']) def test_instance_update_unique_name(self): context1 = context.RequestContext('user1', 'p1') context2 = context.RequestContext('user2', 'p2') inst1 = self.create_instance_with_args(context=context1, project_id='p1', hostname='fake_name1') inst2 = self.create_instance_with_args(context=context1, project_id='p1', hostname='fake_name2') inst3 = self.create_instance_with_args(context=context2, project_id='p2', # osapi_compute_unique_server_name_scope is unset so this should work: db.instance_update(context1, inst1['uuid'], {'hostname': 'fake_name2'}) db.instance_update(context1, inst1['uuid'], {'hostname': 'fake_name1'}) context1, inst2['uuid'], {'hostname': 'fake_name1'}) context2, inst3['uuid'], {'hostname': 'fake_name1'}) db.instance_update(context1, inst1['uuid'], {'hostname': 'fake_NAME'}) self.assertRaises(exception.InstanceExists, db.instance_update, context1, inst2['uuid'], {'hostname': 'fake_NAME'}) db.instance_update(context2, inst3['uuid'], {'hostname': 'fake_NAME'}) instance = self.create_instance_with_args() inst = db.instance_update(self.ctxt, instance['uuid'],","class InstanceTestCase(DbTestCase): otherprojectcontext = context.RequestContext(self.user_id, ""%s2"" % self.project_id) self.create_instance_with_args(hostname='fake_name') hostname='fake_name') context=otherprojectcontext, hostname='fake_name') hostname='fake_name') self.create_instance_with_args(context=otherprojectcontext, hostname='fake_name') fake_meta, fake_sys = self.create_metadata_for_instance(inst['uuid']) result = db.instance_get_all(self.context) for inst in result: self.assertEqual(meta, fake_meta) self.assertEqual(sys_meta, fake_sys) fake_meta, fake_sys = self.create_metadata_for_instance(inst['uuid']) result = db.instance_get_all_by_filters(self.context, {}) for inst in result: self.assertEqual(meta, fake_meta) self.assertEqual(sys_meta, fake_sys) fake_meta, fake_sys = self.create_metadata_for_instance(inst['uuid']) result = db.instance_get_all_by_filters(self.context, {}, self.create_instance_with_args() self.create_instance_with_args() result = db.instance_get_all_by_filters(self.context, {}) self.assertEqual(2, len(result)) self.create_instance_with_args(display_name='test1') self.create_instance_with_args(display_name='teeeest2') result = db.instance_get_all_by_filters(self.context, self.assertEqual(2, len(result)) self.create_instance_with_args(host='host1') result = db.instance_get_all_by_filters(self.context, self.assertEqual(1, len(result)) self.create_instance_with_args(metadata={'foo': 'bar'}) result = db.instance_get_all_by_filters(self.context, self.assertEqual(1, len(result)) self.create_instance_with_args(display_name=u'test♥') result = db.instance_get_all_by_filters(self.context, self.assertEqual(1, len(result)) fake_meta, fake_sys = self.create_metadata_for_instance(inst['uuid']) result = db.instance_get_by_uuid(self.context, inst['uuid']) meta = utils.metadata_to_dict(result['metadata']) self.assertEqual(meta, fake_meta) sys_meta = utils.metadata_to_dict(result['system_metadata']) self.assertEqual(sys_meta, fake_sys) fake_meta, fake_sys = self.create_metadata_for_instance(inst['uuid']) result = db.instance_get_by_uuid(self.context, inst['uuid'], fake_meta, fake_sys = self.create_metadata_for_instance(inst['uuid']) result = db.instance_get_by_uuid(self.context, inst['uuid'], columns_to_join=['metadata']) self.assertEqual(meta, fake_meta) fake_meta, fake_sys = self.create_metadata_for_instance(inst['uuid']) result = db.instance_get_by_uuid(self.context, inst['uuid'], self.assertEqual(sys_meta, fake_sys) db.instance_destroy(self.context, inst1['uuid']) result = db.instance_get_all_by_filters(self.context, {}) self.assertEqual(2, len(result)) self.assertIn(inst1['id'], [result[0]['id'], result[1]['id']]) self.assertIn(inst2['id'], [result[0]['id'], result[1]['id']]) db.instance_destroy(self.context, inst1['uuid']) result = db.instance_get_all_by_filters(self.context, self.assertEqual(2, len(result)) self.assertIn(inst1['id'], [result[0]['id'], result[1]['id']]) self.assertIn(inst2['id'], [result[0]['id'], result[1]['id']]) db.instance_destroy(self.context, inst1['uuid']) result = db.instance_get_all_by_filters(self.context, self.assertEqual(1, len(result)) self.assertEqual(inst1['id'], result[0]['id']) db.instance_destroy(self.context, inst1['uuid']) result = db.instance_get_all_by_filters(self.context, self.assertEqual(2, len(result)) self.assertIn(inst2['id'], [result[0]['id'], result[1]['id']]) self.assertIn(inst3['id'], [result[0]['id'], result[1]['id']]) # Test that system metadata is not joined. sys_meta = {'foo': 'bar'} expected = self.create_instance_with_args(system_metadata=sys_meta) elevated = self.context.elevated() instances = db.instance_get_all_by_host_and_node(elevated, 'host1', 'node1') self.assertEqual(1, len(instances)) instance = instances[0] self.assertEqual(expected['uuid'], instance['uuid']) sysmeta = dict(instance)['system_metadata'] self.assertEqual(len(sysmeta), 0) ctxt = context.get_admin_context() results = db.instance_get_all_hung_in_rebooting(ctxt, 10) self.assertEqual(0, len(results)) updated_at = datetime.datetime(2000, 1, 1, 12, 0, 0) values = {""task_state"": ""rebooting"", ""updated_at"": updated_at} instance = db.instance_create(ctxt, values) results = db.instance_get_all_hung_in_rebooting(ctxt, 10) self.assertEqual(1, len(results)) db.instance_update(ctxt, instance['uuid'], {""task_state"": None}) updated_at = timeutils.utcnow() values = {""task_state"": ""rebooting"", ""updated_at"": updated_at} instance = db.instance_create(ctxt, values) results = db.instance_get_all_hung_in_rebooting(ctxt, 10) self.assertEqual(0, len(results)) db.instance_update(ctxt, instance['uuid'], {""task_state"": None}) ctxt = context.get_admin_context() uuid = uuidutils.generate_uuid() updates = {'expected_vm_state': 'meow', 'moo': 'cow'} class FakeInstance(dict): def save(self, session=None): pass fake_instance_values = {'vm_state': 'meow', 'hostname': '', 'metadata': None, 'system_metadata': None} fake_instance = FakeInstance(fake_instance_values) self.mox.StubOutWithMock(sqlalchemy_api, '_instance_get_by_uuid') self.mox.StubOutWithMock(fake_instance, 'save') sqlalchemy_api._instance_get_by_uuid(ctxt, uuid, session=mox.IgnoreArg()).AndReturn(fake_instance) fake_instance.save(session=mox.IgnoreArg()) self.mox.ReplayAll() result = db.instance_update(ctxt, uuid, updates) expected_instance = dict(fake_instance_values) expected_instance['moo'] = 'cow' self.assertEqual(expected_instance, result) ctxt = context.get_admin_context() uuid = uuidutils.generate_uuid() updates = {'expected_vm_state': 'meow'} fake_instance = {'vm_state': 'nomatch'} self.mox.StubOutWithMock(sqlalchemy_api, '_instance_get_by_uuid') sqlalchemy_api._instance_get_by_uuid(ctxt, uuid, session=mox.IgnoreArg()).AndReturn(fake_instance) self.mox.ReplayAll() db.instance_update, ctxt, uuid, updates) def test_instance_update_unique_name(self): otherprojectcontext = context.RequestContext(self.user_id, ""%s2"" % self.project_id) inst = self.create_instance_with_args(hostname='fake_name') uuid1p1 = inst['uuid'] inst = self.create_instance_with_args(hostname='fake_name2') uuid2p1 = inst['uuid'] inst = self.create_instance_with_args(context=otherprojectcontext, uuid1p2 = inst['uuid'] # osapi_compute_unique_server_name_scope is unset so this should work: values = {'hostname': 'fake_name2'} db.instance_update(self.context, uuid1p1, values) values = {'hostname': 'fake_name'} db.instance_update(self.context, uuid1p1, values) self.context, uuid2p1, values) otherprojectcontext, uuid1p2, values) case_only_values = {'hostname': 'fake_NAME'} db.instance_update(self.context, uuid1p1, case_only_values) self.assertRaises(exception.InstanceExists, db.instance_update, self.context, uuid2p1, values) db.instance_update(otherprojectcontext, uuid1p2, values) def test_instance_update_with_and_get_original(self): ctxt = context.get_admin_context() # Create an instance with some metadata values = {'vm_state': 'building'} instance = db.instance_create(ctxt, values) (old_ref, new_ref) = db.instance_update_and_get_original(ctxt, instance['uuid'], {'vm_state': 'needscoffee'}) self.assertEquals(""building"", old_ref[""vm_state""]) self.assertEquals(""needscoffee"", new_ref[""vm_state""]) ctxt = context.get_admin_context() instance = db.instance_create(ctxt, {}) inst = db.instance_update(ctxt, instance['uuid'],",189,196
openstack%2Fnova~master~I7046ce55a0a294293c1b1a5fb0f092aeb891ee01,openstack/nova,master,I7046ce55a0a294293c1b1a5fb0f092aeb891ee01,Load cell data from a configuration file,MERGED,2013-06-25 21:02:08.000000000,2013-07-16 16:44:46.000000000,2013-07-16 16:44:44.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2835}]","[{'number': 1, 'created': '2013-06-25 21:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c94c97021ab31fb7b6c28536735e2f7bca1014b', 'message': ""*WIP* Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nTODO:\n\n* Update the cells extension to turn off (return 403?) the create,\n  delete, and update operations\n* Update the cells extension to call to the cells manager for get\n  and list operations, allowing the configuration file to only\n  need to be present on the cell manager node(s)\n* Update the test suite to test the newly-added code and verify\n  behavior when cells_config is provided\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 2, 'created': '2013-06-25 21:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2da82c439eb9c626fcf32539895f6be57a81f74e', 'message': ""*WIP* Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nTODO:\n\n* Update the cells extension to turn off (return 403?) the create,\n  delete, and update operations\n* Update the cells extension to call to the cells manager for get\n  and list operations, allowing the configuration file to only\n  need to be present on the cell manager node(s)\n* Update the test suite to test the newly-added code and verify\n  behavior when cells_config is provided\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 3, 'created': '2013-06-25 22:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcf307a25e61420d5a2cff334278fa3e37b23ef2', 'message': ""*WIP* Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nTODO:\n\n* Update the cells extension to turn off (return 403?) the create,\n  delete, and update operations\n* Update the cells extension to call to the cells manager for get\n  and list operations, allowing the configuration file to only\n  need to be present on the cell manager node(s)\n* Update the test suite to test the newly-added code and verify\n  behavior when cells_config is provided\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 4, 'created': '2013-06-25 22:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ce4394f42950926bcec437832d36d5ab9c4b4af', 'message': ""*WIP* Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nTODO:\n\n* Update the cells extension to turn off (return 403?) the create,\n  delete, and update operations\n* Update the cells extension to call to the cells manager for get\n  and list operations, allowing the configuration file to only\n  need to be present on the cell manager node(s)\n* Update the test suite to test the newly-added code and verify\n  behavior when cells_config is provided\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 5, 'created': '2013-06-26 16:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/daa613104355d20e32ff7d4d2f26e99dd810ab5b', 'message': ""*WIP* Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nTODO:\n\n* Update the cells extension to turn off (return 403?) the create,\n  delete, and update operations\n* Update the cells extension to call to the cells manager for get\n  and list operations, allowing the configuration file to only\n  need to be present on the cell manager node(s)\n* Update the test suite to test the newly-added code and verify\n  behavior when cells_config is provided\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 6, 'created': '2013-06-26 22:48:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5411e46ade7ad3df97a4e14102cb16c172f4563', 'message': ""Load cell data from a configuration file\n\n**WIP**\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nTODO:\n\n* Update the test suite to test the newly-added code and verify\n  behavior when cells_config is provided\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 7, 'created': '2013-06-26 22:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f5ff4668bafb06b3f33dcca3e48d842f7467e42b', 'message': ""Load cell data from a configuration file\n\n**WIP**\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nTODO:\n\n* Update the test suite to test the newly-added code and verify\n  behavior when cells_config is provided\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 8, 'created': '2013-06-27 15:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98c887f08b13e4d6fba39ba5868859b6e6ce779c', 'message': ""Load cell data from a configuration file\n\n**WIP**\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nTODO:\n\n* Update the test suite to test the newly-added code and verify\n  behavior when cells_config is provided\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 9, 'created': '2013-06-27 20:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb360622beed16e6581eb8b6c4a447454272d962', 'message': ""Load cell data from a configuration file\n\n**WIP**\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: Cells may now optionally be configured through a JSON-\nformatted file.  The file will need the columns present in the Cell\nmodel (excluding common database fields and the 'id' column).  The\nqueue connection information must be specified through a\n'transport_url' field, instead of 'username', 'password', etc.  The\ntransport_url has the following form:\n\n    rabbit://<username>:<password>@<hostname>:<port>/<virtual_host>\n\nThe scheme may be either 'rabbit' (shown above) or 'qpid'.\n\nTODO:\n\n* Update the test suite to test the newly-added code and verify\n  behavior when cells_config is provided\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 10, 'created': '2013-06-27 22:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be4b514ac33527ad0da65fe05583095e74d4081b', 'message': ""Load cell data from a configuration file\n\n**WIP**\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: Cells may now optionally be configured through a JSON-\nformatted file.  The file will need the columns present in the Cell\nmodel (excluding common database fields and the 'id' column).  The\nqueue connection information must be specified through a\n'transport_url' field, instead of 'username', 'password', etc.  The\ntransport_url has the following form:\n\n    rabbit://<username>:<password>@<hostname>:<port>/<virtual_host>\n\nThe scheme may be either 'rabbit' (shown above) or 'qpid'.\n\nTODO:\n\n* Update the test suite to test the newly-added code and verify\n  behavior when cells_config is provided\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 11, 'created': '2013-06-28 21:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a630e1304a72922b5f01c2714b56894f01cb207b', 'message': ""Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: Cells may now optionally be configured through a JSON-\nformatted file.  The file will need the columns present in the Cell\nmodel (excluding common database fields and the 'id' column).  The\nqueue connection information must be specified through a\n'transport_url' field, instead of 'username', 'password', etc.  The\ntransport_url has the following form:\n\n    rabbit://<username>:<password>@<hostname>:<port>/<virtual_host>\n\nThe scheme may be either 'rabbit' (shown above) or 'qpid'.\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 12, 'created': '2013-06-28 23:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9227543376dc0b488c475d8c8a15753598145ac5', 'message': ""Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: Cells may now optionally be configured through a JSON-\nformatted file.  The file will need the columns present in the Cell\nmodel (excluding common database fields and the 'id' column).  The\nqueue connection information must be specified through a\n'transport_url' field, instead of 'username', 'password', etc.  The\ntransport_url has the following form:\n\n    rabbit://<username>:<password>@<hostname>:<port>/<virtual_host>\n\nThe scheme may be either 'rabbit' (shown above) or 'qpid'.\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 13, 'created': '2013-07-10 22:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/acadde6b16ecf090b2335b6ae2e24507d48361b2', 'message': ""Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: Cells may now optionally be configured through a JSON-\nformatted file.  The file will need the columns present in the Cell\nmodel (excluding common database fields and the 'id' column).  The\nqueue connection information must be specified through a\n'transport_url' field, instead of 'username', 'password', etc.  The\ntransport_url has the following form:\n\n    rabbit://<username>:<password>@<hostname>:<port>/<virtual_host>\n\nThe scheme may be either 'rabbit' (shown above) or 'qpid'.\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 14, 'created': '2013-07-11 22:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0097bef3c40042c6f06aab4c6e1afd258f6db289', 'message': ""Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: Cells may now optionally be configured through a JSON-\nformatted file.  The file will need the columns present in the Cell\nmodel (excluding common database fields and the 'id' column).  The\nqueue connection information must be specified through a\n'transport_url' field, instead of 'username', 'password', etc.  The\ntransport_url has the following form:\n\n    rabbit://<username>:<password>@<hostname>:<port>/<virtual_host>\n\nThe scheme may be either 'rabbit' (shown above) or 'qpid'.\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 15, 'created': '2013-07-12 16:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c75f2481b98c6815cca0c98dbe16509ebd6d8bbd', 'message': ""Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: Cells may now optionally be configured through a JSON-\nformatted file.  The file will need the columns present in the Cell\nmodel (excluding common database fields and the 'id' column).  The\nqueue connection information must be specified through a\n'transport_url' field, instead of 'username', 'password', etc.  The\ntransport_url has the following form:\n\n    rabbit://<username>:<password>@<hostname>:<port>/<virtual_host>\n\nThe scheme may be either 'rabbit' (shown above) or 'qpid'.\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 16, 'created': '2013-07-12 23:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/315cf6a824e5f3b38725fa5ba35a98152ad8b20e', 'message': ""Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: Cells may now optionally be configured through a JSON-\nformatted file.  The file will need the columns present in the Cell\nmodel (excluding common database fields and the 'id' column).  The\nqueue connection information must be specified through a\n'transport_url' field, instead of 'username', 'password', etc.  The\ntransport_url has the following form:\n\n    rabbit://<username>:<password>@<hostname>:<port>/<virtual_host>\n\nThe scheme may be either 'rabbit' (shown above) or 'qpid'.\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}, {'number': 17, 'created': '2013-07-15 15:32:46.000000000', 'files': ['etc/nova/cells.json', 'nova/tests/cells/fakes.py', 'nova/tests/cells/test_cells_rpcapi.py', 'nova/api/openstack/compute/plugins/v3/cells.py', 'nova/api/openstack/compute/contrib/cells.py', 'nova/tests/cells/test_cells_manager.py', 'nova/exception.py', 'nova/tests/api/openstack/compute/contrib/test_cells.py', 'nova/cells/manager.py', 'nova/cells/state.py', 'nova/tests/api/openstack/compute/plugins/v3/test_cells.py', 'nova/tests/cells/test_cells_state_manager.py', 'nova/tests/integrated/test_api_samples.py', 'nova/cells/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/88ab9369e3ddfd8b8684bf280330ff8d37a74b2b', 'message': ""Load cell data from a configuration file\n\nCells currently keeps all inter-cell communication data, including\nusernames and passwords, in the database.  This is undesirable and\nunnecessary, since cells data isn't updated very frequently.  This\nchange allows cells data to be drawn from a JSON file specified via\na new [cells]cells_config option.  When specified, the database is\nno longer consulted when reloading cells data.\n\nImplements blueprint eliminate-clear-passwords-from-cells-table.\n\nDocImpact: Cells may now optionally be configured through a JSON-\nformatted file.  The file will need the columns present in the Cell\nmodel (excluding common database fields and the 'id' column).  The\nqueue connection information must be specified through a\n'transport_url' field, instead of 'username', 'password', etc.  The\ntransport_url has the following form:\n\n    rabbit://<username>:<password>@<hostname>:<port>/<virtual_host>\n\nThe scheme may be either 'rabbit' (shown above) or 'qpid'.\n\nChange-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01\n""}]",15,34464,88ab9369e3ddfd8b8684bf280330ff8d37a74b2b,63,7,17,679,,,0,"Load cell data from a configuration file

Cells currently keeps all inter-cell communication data, including
usernames and passwords, in the database.  This is undesirable and
unnecessary, since cells data isn't updated very frequently.  This
change allows cells data to be drawn from a JSON file specified via
a new [cells]cells_config option.  When specified, the database is
no longer consulted when reloading cells data.

Implements blueprint eliminate-clear-passwords-from-cells-table.

DocImpact: Cells may now optionally be configured through a JSON-
formatted file.  The file will need the columns present in the Cell
model (excluding common database fields and the 'id' column).  The
queue connection information must be specified through a
'transport_url' field, instead of 'username', 'password', etc.  The
transport_url has the following form:

    rabbit://<username>:<password>@<hostname>:<port>/<virtual_host>

The scheme may be either 'rabbit' (shown above) or 'qpid'.

Change-Id: I7046ce55a0a294293c1b1a5fb0f092aeb891ee01
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/34464/16 && git format-patch -1 --stdout FETCH_HEAD,['nova/cells/state.py'],1,8c94c97021ab31fb7b6c28536735e2f7bca1014b,bp/eliminate-clear-passwords-from-cells-table,"from nova.openstack.common import fileutils from nova.openstack.common import jsonutils cfg.StrOpt('cells_config', default=None, help='Configuration file from which to read cells ' 'configuration. If given, overrides reading cells ' 'from the database.'), if self.cells_config_file: self._file_needs_resync(): if self._time_to_sync(): self.last_cell_db_check = timeutils.utcnow() self._update_our_capacity() else: if self._time_to_sync(): self._cell_db_sync()_unset = object() class CellStateManager(base.Base): def __init__(self, cell_state_cls=None, cells_config=_unset): # NOTE(Vek): We want the constructor argument to override the # configuration setting even if it's None, which is # where the _unset singleton comes in... if cells_config is _unset: self.cells_config_file = CONF.cells_config else: self.cells_config_file = cells_config if self.cells_config_file: # Draw cells data from the config file self.cells_config_path = CONF.find_file(self.cells_config_file) if not self.cells_config_path: raise cfg.ConfigFilesNotFoundError(path=self.cells_config_file) self._file_needs_resync(force=True) else: # Draw cells data from the database self._cell_db_sync() def _refresh_cells_from_dict(self, cells_dict): db_dict = cells_dict.get(cell_name) for cell_name, db_info in cells_dict.items(): def _update_our_capacity(self, ctxt=None): if not ctxt: ctxt = context.get_admin_context() compute_nodes = self.db.compute_node_get_all(ctxt) instance_types = self.db.instance_type_get_all(ctxt) db_cells = self.db.cell_get_all(ctxt) db_cells_dict = dict([(cell['name'], cell) for cell in db_cells]) self._refresh_cells_from_dict(db_cells_dict) def _file_needs_resync(self, force=False): reloaded, data = fileutils.read_cached_file(self.cells_config_path, force_reload=force) if reloaded: LOG.debug(_(""Updating cell cache from config file."")) self.cells_config_data = jsonutils.loads(data) self._refresh_cells_from_dict(self.cells_config_data) "," if self._time_to_sync(): self._cell_db_sync()class CellStateManager(base.Base): def __init__(self, cell_state_cls=None): self._cell_db_sync() def _refresh_cells_from_db(self, ctxt): # Add/update existing cells ... db_cells = self.db.cell_get_all(ctxt) db_cells_dict = dict([(cell['name'], cell) for cell in db_cells]) db_dict = db_cells_dict.get(cell_name) for cell_name, db_info in db_cells_dict.items(): def _update_our_capacity(self, context): compute_nodes = self.db.compute_node_get_all(context) instance_types = self.db.instance_type_get_all(context) self._refresh_cells_from_db(ctxt)",59,14
openstack%2Fpbr~feature%2Fmerged2to1~Ibb80649b45ecab90f982138cb07d2e5a8b7ac6d9,openstack/pbr,feature/merged2to1,Ibb80649b45ecab90f982138cb07d2e5a8b7ac6d9,Add version override support from nova.,ABANDONED,2013-07-15 00:33:56.000000000,2013-07-16 16:41:14.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-07-15 00:33:56.000000000', 'files': ['pbr/tests/test_version.py', 'pbr/version.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/fc1a0ebd9d24f7681372782575f0d0f96b79fa04', 'message': ""Add version override support from nova.\n\nNova has a great feature that allows distro packagers to override\nversion strings by putting config files in known locations. We should\nsupport this in our version processing code, because it's quite handy.\n\nChange-Id: Ibb80649b45ecab90f982138cb07d2e5a8b7ac6d9\n""}]",0,37002,fc1a0ebd9d24f7681372782575f0d0f96b79fa04,2,1,1,2,,,0,"Add version override support from nova.

Nova has a great feature that allows distro packagers to override
version strings by putting config files in known locations. We should
support this in our version processing code, because it's quite handy.

Change-Id: Ibb80649b45ecab90f982138cb07d2e5a8b7ac6d9
",git fetch https://review.opendev.org/openstack/pbr refs/changes/02/37002/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/test_version.py', 'pbr/version.py']",2,fc1a0ebd9d24f7681372782575f0d0f96b79fa04,add-version-override,"import os import sys try: import ConfigParser as configparser except ImportError: import configparserdef _fixpath(p): """"""Apply tilde expansion and absolutization to a path."""""" return os.path.abspath(os.path.expanduser(p)) def _get_config_dirs(project=None): """"""Return a list of directors where config files may be located. :param project: an optional project name If a project is specified, following directories are returned:: ~/.${project}/ ~/ /etc/${project}/ /etc/ Otherwise, these directories:: ~/ /etc/ """""" cfg_dirs = [ _fixpath(os.path.join('~', '.' + project)) if project else None, _fixpath('~'), os.path.join('/etc', project) if project else None, '/etc' ] return list(_filter(bool, cfg_dirs)) def _search_dirs(dirs, basename, extension=""""): """"""Search a list of directories for a given filename. Iterator over the supplied directories, returning the first file found with the supplied name and extension. :param dirs: a list of directories :param basename: the filename, e.g. 'glance-api' :param extension: the file extension, e.g. '.conf' :returns: the path to a matching file, or None """""" for d in dirs: path = os.path.join(d, '%s%s' % (basename, extension)) if os.path.exists(path): return path def _filter(*args): if sys.version_info >= (2, 7): import itertools return itertools.ifilter(*args) else: return filter(*args) def _find_config_files(project=None, prog=None, extension='.conf'): """"""Return a list of default configuration files. :param project: an optional project name :param prog: the program name, defaulting to the basename of sys.argv[0] :param extension: the type of the config file We default to two config files: [${project}.conf, ${prog}.conf] And we look for those config files in the following directories:: ~/.${project}/ ~/ /etc/${project}/ /etc/ We return an absolute path for (at most) one of each the default config files, for the topmost directory it exists in. For example, if project=foo, prog=bar and /etc/foo/foo.conf, /etc/bar.conf and ~/.foo/bar.conf all exist, then we return ['/etc/foo/foo.conf', '~/.foo/bar.conf'] If no project name is supplied, we only look for ${prog.conf}. """""" if prog is None: prog = os.path.basename(sys.argv[0]) cfg_dirs = _get_config_dirs(project) config_files = [] if project: config_files.append(_search_dirs(cfg_dirs, project, extension)) config_files.append(_search_dirs(cfg_dirs, prog, extension)) return list(_filter(bool, config_files)) self.vendor = None self.product = None self.suffix = None self._provider = None self._loaded = False def _load_from_setup_cfg(self): import d2to1.util parsed_cfg = d2to1.util.cfg_to_args() self.vendor = parsed_cfg['author'] self.product = parsed_cfg['description'] def _load_from_pkg_info(self, provider): import email pkg_info = email.message_from_string(provider.get_metadata('PKG-INFO')) self.vendor = pkg_info['Author'] self.product = pkg_info['Summary'] def _load_from_cfg_file(self, cfgfile): try: cfg = configparser.RawConfigParser() cfg.read(cfgfile) except Exception: return project_name = self.package if project_name.startswith('python-'): project_name = project_name[7:] self.vendor = cfg.get(project_name, ""vendor"", self.vendor) self.product = cfg.get(project_name, ""product"", self.product) self.suffix = cfg.get(project_name, ""package"", self.suffix) def _load_vendor_strings(self): """"""Load default and override vendor strings. Load default values from the project configuration. Then try loading override values from release config files. At the end of this, self.vendor, self.product and self.suffix should be directly consumable. """""" if self._loaded: return provider = self._get_provider() if provider: self._load_from_pkg_info(provider) else: self._load_from_setup_cfg() cfgfile = _find_config_files(""release"") if cfgfile: self._load_from_cfg_file(cfgfile) self._loaded = True def _get_provider(self): if self._provider is None: try: requirement = pkg_resources.Requirement.parse(self.package) self._provider = pkg_resources.get_provider(requirement) except pkg_resources.DistributionNotFound: pass return self._provider provider = self._get_provider() if provider: else: def vendor_string(self): self._load_vendor_strings() return self.vendor def product_string(self): self._load_vendor_strings() return self.product def suffix_string(self): self._load_vendor_strings() return self.suffix package_string = suffix_string", try: requirement = pkg_resources.Requirement.parse(self.package) provider = pkg_resources.get_provider(requirement) except pkg_resources.DistributionNotFound:,212,4
openstack%2Fpbr~feature%2Fmerged2to1~I3b6708444ec8b3d37271c0c8df91fee2cd593088,openstack/pbr,feature/merged2to1,I3b6708444ec8b3d37271c0c8df91fee2cd593088,Defer to pip for requirements processing,ABANDONED,2013-07-12 02:59:00.000000000,2013-07-16 16:40:06.000000000,,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2013-07-12 02:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/3b3aff30ab739751a1e8e41843565b994aa2a53e', 'message': ""Defer to pip for requirements processing.\n\npip knows what it's doing, we should stop doing its job for it.\nAdditionally, we should not inject version numbers into the\ninstall_requires itself, as upstream pip tells us this is bad form.\ninstall_requires should list the requirement itself, requirements.txt\nshould indicate the version that should be installed.\n\nChange-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088\n""}, {'number': 2, 'created': '2013-07-15 00:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/c1abd037f913aaadd13a4f0be4da79b0dcfdf1b6', 'message': ""Defer to pip for requirements processing\n\npip knows what it's doing, we should stop doing its job for it.\nAdditionally, we should not inject version numbers into the\ninstall_requires itself, as upstream pip tells us this is bad form.\ninstall_requires should list the requirement itself, requirements.txt\nshould indicate the version that should be installed.\n\nChange-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088\n""}, {'number': 3, 'created': '2013-07-15 00:52:24.000000000', 'files': ['pbr/tests/test_setup.py', 'pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/93ddad9d5b75c64c61b6a53e2ce2b12b32f2b87b', 'message': ""Defer to pip for requirements processing\n\npip knows what it's doing, we should stop doing its job for it.\nAdditionally, we should not inject version numbers into the\ninstall_requires itself, as upstream pip tells us this is bad form.\ninstall_requires should list the requirement itself, requirements.txt\nshould indicate the version that should be installed.\n\nChange-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088\n""}]",0,36767,93ddad9d5b75c64c61b6a53e2ce2b12b32f2b87b,9,2,3,2,,,0,"Defer to pip for requirements processing

pip knows what it's doing, we should stop doing its job for it.
Additionally, we should not inject version numbers into the
install_requires itself, as upstream pip tells us this is bad form.
install_requires should list the requirement itself, requirements.txt
should indicate the version that should be installed.

Change-Id: I3b6708444ec8b3d37271c0c8df91fee2cd593088
",git fetch https://review.opendev.org/openstack/pbr refs/changes/67/36767/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/test_setup.py', 'pbr/packaging.py', 'pbr/hooks/backwards.py']",3,3b3aff30ab739751a1e8e41843565b994aa2a53e,fix-pip-install,," self.config, 'dependency_links', packaging.parse_dependency_links()) packaging.append_text_list(",25,107
openstack%2Fpbr~feature%2Fmerged2to1~I163b1c153d030e79b120600a2890edeb49e1fa90,openstack/pbr,feature/merged2to1,I163b1c153d030e79b120600a2890edeb49e1fa90,Replace setuptools_git with a smarter approach.,ABANDONED,2013-07-12 02:52:41.000000000,2013-07-16 16:38:54.000000000,,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2013-07-12 02:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/60c939fd98f4539863afd3697bfaa5e76101fb51', 'message': 'Replace setuptools_git with a smarter approach.\n\nImplement a local egg_info command that only re-generates the\nSOURCES.txt file when we need to. That is:\n\n - If there is no SOURCES.txt, make one\n - If we have run the sdist command, make one\n\nOtherwise, leave well enough alone.\n\nAlso, skip doing any git processing if SKIP_GIT_FILES is specified.\n\nThis should mean that consumers of our tarballs should not get screwed\nby the need to inject git processing into the sdist.\n\nChange-Id: I163b1c153d030e79b120600a2890edeb49e1fa90\n'}, {'number': 2, 'created': '2013-07-15 00:39:48.000000000', 'files': ['pbr/packaging.py', 'requirements.txt', 'pbr/hooks/commands.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/d7704a20448162ef0cfebbbe0888695eb1e85778', 'message': 'Replace setuptools_git with a smarter approach.\n\nImplement a local egg_info command that only re-generates the\nSOURCES.txt file when we need to. That is:\n\n - If there is no SOURCES.txt, make one\n - If we have run the sdist command, make one\n\nOtherwise, leave well enough alone.\n\nAlso, skip doing any git processing if SKIP_GIT_FILES is specified.\n\nThis should mean that consumers of our tarballs should not get screwed\nby the need to inject git processing into the sdist.\n\nChange-Id: I163b1c153d030e79b120600a2890edeb49e1fa90\n'}]",0,36766,d7704a20448162ef0cfebbbe0888695eb1e85778,4,2,2,2,,,0,"Replace setuptools_git with a smarter approach.

Implement a local egg_info command that only re-generates the
SOURCES.txt file when we need to. That is:

 - If there is no SOURCES.txt, make one
 - If we have run the sdist command, make one

Otherwise, leave well enough alone.

Also, skip doing any git processing if SKIP_GIT_FILES is specified.

This should mean that consumers of our tarballs should not get screwed
by the need to inject git processing into the sdist.

Change-Id: I163b1c153d030e79b120600a2890edeb49e1fa90
",git fetch https://review.opendev.org/openstack/pbr refs/changes/66/36766/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/packaging.py', 'requirements.txt', 'pbr/hooks/commands.py']",3,60c939fd98f4539863afd3697bfaa5e76101fb51,replace-setuptools-git, self.add_command('pbr.packaging.LocalEggInfo'),,74,1
openstack%2Fpbr~feature%2Fmerged2to1~Ifa472f344489295a5b8a1910bff2672087653547,openstack/pbr,feature/merged2to1,Ifa472f344489295a5b8a1910bff2672087653547,"We force installs via pip, we should declare it.",ABANDONED,2013-07-12 02:52:41.000000000,2013-07-16 16:38:44.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2013-07-12 02:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/3d274d09f213b49934fa9d70d146662e88ad7d0a', 'message': 'We force installs via pip, we should declare it.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}, {'number': 2, 'created': '2013-07-15 00:39:48.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/pbr/commit/99c400e6a70429e0f99008a62406c6ad1813e8be', 'message': 'We force installs via pip, we should declare it.\n\nChange-Id: Ifa472f344489295a5b8a1910bff2672087653547\n'}]",0,36765,99c400e6a70429e0f99008a62406c6ad1813e8be,5,3,2,2,,,0,"We force installs via pip, we should declare it.

Change-Id: Ifa472f344489295a5b8a1910bff2672087653547
",git fetch https://review.opendev.org/openstack/pbr refs/changes/65/36765/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3d274d09f213b49934fa9d70d146662e88ad7d0a,replace-setuptools-git,pip>1.0,,1,0
openstack%2Fpbr~master~Ibd16944e76ad8398b57b6ddcbcd150cd462add3e,openstack/pbr,master,Ibd16944e76ad8398b57b6ddcbcd150cd462add3e,Merge feature/merged2to1 into master,MERGED,2013-07-12 07:05:43.000000000,2013-07-16 16:33:16.000000000,2013-07-16 16:33:16.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 6159}]","[{'number': 1, 'created': '2013-07-12 07:05:43.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/5ebf34cc1701dbd9925631e453f39cc8125e600f', 'message': 'Merge feature/merged2to1 into master\n\nUpstream d2to1 has been rather unresponsive, and doing what we need\nin this case is really easier without the extra complexity.\n\nChange-Id: Ibd16944e76ad8398b57b6ddcbcd150cd462add3e\n'}]",0,36787,5ebf34cc1701dbd9925631e453f39cc8125e600f,6,3,1,2,,,0,"Merge feature/merged2to1 into master

Upstream d2to1 has been rather unresponsive, and doing what we need
in this case is really easier without the extra complexity.

Change-Id: Ibd16944e76ad8398b57b6ddcbcd150cd462add3e
",git fetch https://review.opendev.org/openstack/pbr refs/changes/87/36787/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,5ebf34cc1701dbd9925631e453f39cc8125e600f,,,"<<<<<<< HEAD (b24d4c Merge ""Fix some issues in setup.py test."") _run_shell_command( ""%s -m pip.__init__ install %s %s %s"" % ( sys.executable, root_cmd, "" "".join(links), "" "".join(_wrap_in_quotes(requires))), throw_on_error=True, buffer=False) =======>>>>>>> BRANCH (a61eae Fix some issues in setup.py test)",0,10
openstack%2Fpython-muranoclient~master~I09eee7d8595e2afd98751d18d47ed357195073e9,openstack/python-muranoclient,master,I09eee7d8595e2afd98751d18d47ed357195073e9,setup.sh add,MERGED,2013-07-11 11:53:10.000000000,2013-07-16 16:32:55.000000000,2013-07-16 16:32:55.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7613}]","[{'number': 1, 'created': '2013-07-11 11:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/dbf9f5836479eb02d593ef28b85086c4962bf160', 'message': 'setup.sh add\n\nChange-Id: I09eee7d8595e2afd98751d18d47ed357195073e9\n'}, {'number': 2, 'created': '2013-07-16 15:38:21.000000000', 'files': ['setup.sh'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/599f08ff7140782e27e31220df6dd8aa8c49ac2c', 'message': 'setup.sh add\n\nChange-Id: I09eee7d8595e2afd98751d18d47ed357195073e9\n'}]",0,36643,599f08ff7140782e27e31220df6dd8aa8c49ac2c,11,4,2,7613,,,0,"setup.sh add

Change-Id: I09eee7d8595e2afd98751d18d47ed357195073e9
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/43/36643/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.sh'],1,dbf9f5836479eb02d593ef28b85086c4962bf160,scripts,"#!/bin/sh # Copyright (c) 2013 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # Ubuntu script. LOGLVL=1 SERVICE_CONTENT_DIRECTORY=`cd $(dirname ""$0"") && pwd` PREREQ_PKGS=""wget make git python-pip python-dev python-mysqldb libxml2-dev libxslt-dev"" SERVICE_SRV_NAME=""python-muranoclient"" GIT_CLONE_DIR=`echo $SERVICE_CONTENT_DIRECTORY | sed -e ""s/$SERVICE_SRV_NAME//""` # Functions # Loger function log() { MSG=$1 if [ $LOGLVL -gt 0 ]; then echo ""LOG:> $MSG"" fi } # Check or install package in_sys_pkg() { PKG=$1 dpkg -s $PKG > /dev/null 2>&1 if [ $? -eq 0 ]; then log ""Package \""$PKG\"" already installed"" else log ""Installing \""$PKG\""..."" apt-get install $PKG --yes > /dev/null 2>&1 if [ $? -ne 0 ];then log ""installation fails, exiting!!!"" exit fi fi } # git clone gitclone() { FROM=$1 CLONEROOT=$2 log ""Cloning from \""$FROM\"" repo to \""$CLONEROOT\"""" cd $CLONEROOT && git clone $FROM > /dev/null 2>&1 if [ $? -ne 0 ];then log ""cloning from \""$FROM\"" fails, exiting!!!"" exit fi } # install inst() { CLONE_FROM_GIT=$1 # Checking packages for PKG in $PREREQ_PKGS do in_sys_pkg $PKG done # If clone from git set if [ ! -z $CLONE_FROM_GIT ]; then # Preparing clone root directory if [ ! -d $GIT_CLONE_DIR ];then log ""Creting $GIT_CLONE_DIR direcory..."" mkdir -p $GIT_CLONE_DIR if [ $? -ne 0 ];then log ""Can't create $GIT_CLONE_DIR, exiting!!!"" exit fi fi # Cloning from GIT GIT_WEBPATH_PRFX=""https://github.com/stackforge/"" gitclone ""$GIT_WEBPATH_PRFX$SERVICE_SRV_NAME.git"" $GIT_CLONE_DIR # End clone from git section fi # Setupping... log ""Running setup.py"" #MRN_CND_SPY=$GIT_CLONE_DIR/$SERVICE_SRV_NAME/setup.py MRN_CND_SPY=$SERVICE_CONTENT_DIRECTORY/setup.py if [ -e $MRN_CND_SPY ]; then chmod +x $MRN_CND_SPY log ""$MRN_CND_SPY output:_____________________________________________________________"" #cd $GIT_CLONE_DIR/$SERVICE_SRV_NAME && $MRN_CND_SPY install #if [ $? -ne 0 ]; then # log ""\""$MRN_CND_SPY\"" python setup FAILS, exiting!"" # exit 1 #fi ## Setup through pip # Creating tarball #cd $GIT_CLONE_DIR/$SERVICE_SRV_NAME && $MRN_CND_SPY sdist cd $SERVICE_CONTENT_DIRECTORY && python $MRN_CND_SPY egg_info if [ $? -ne 0 ];then log ""\""$MRN_CND_SPY\"" egg info creation FAILS, exiting!!!"" exit 1 fi cd $SERVICE_CONTENT_DIRECTORY && python $MRN_CND_SPY sdist if [ $? -ne 0 ];then log ""\""$MRN_CND_SPY\"" tarball creation FAILS, exiting!!!"" exit 1 fi # Running tarball install #TRBL_FILE=$(basename `ls $GIT_CLONE_DIR/$SERVICE_SRV_NAME/dist/*.tar.gz`) #pip install $GIT_CLONE_DIR/$SERVICE_SRV_NAME/dist/$TRBL_FILE TRBL_FILE=$(basename `ls $SERVICE_CONTENT_DIRECTORY/dist/*.tar.gz`) pip install $SERVICE_CONTENT_DIRECTORY/dist/$TRBL_FILE if [ $? -ne 0 ];then log ""pip install \""$TRBL_FILE\"" FAILS, exiting!!!"" exit 1 fi else log ""$MRN_CND_SPY not found!"" fi } # uninstall uninst() { # Uninstall trough pip # looking up for python package installed #PYPKG=`echo $SERVICE_SRV_NAME | tr -d '-'` PYPKG=$SERVICE_SRV_NAME pip freeze | grep $PYPKG if [ $? -eq 0 ]; then log ""Removing package \""$PYPKG\"" with pip"" pip uninstall $PYPKG --yes else log ""Python package \""$PYPKG\"" not found"" fi } # Command line args' COMMAND=""$1"" case $COMMAND in install ) inst ;; installfromgit ) inst ""yes"" ;; uninstall ) log ""Uninstalling \""$SERVICE_SRV_NAME\"" from system..."" uninst ;; * ) echo ""Usage: $(basename ""$0"") command \nCommands:\n\tinstall - Install $SERVICE_SRV_NAME software\n\tuninstall - Uninstall $SERVICE_SRV_NAME software"" exit 1 ;; esac ",,165,0
openstack%2Fmurano-dashboard~master~Ic2dfc3468328cd0558af9574dabf6dc2afafe764,openstack/murano-dashboard,master,Ic2dfc3468328cd0558af9574dabf6dc2afafe764,Add unautorized exception handling,MERGED,2013-07-16 15:27:55.000000000,2013-07-16 16:32:26.000000000,2013-07-16 16:32:26.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-07-16 15:27:55.000000000', 'files': ['muranodashboard/panel/views.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ffc560112d0e55f8ca92791cc73fd7d8e9bc7454', 'message': 'Add unautorized exception handling\n\nChange-Id: Ic2dfc3468328cd0558af9574dabf6dc2afafe764\n'}]",0,37272,ffc560112d0e55f8ca92791cc73fd7d8e9bc7454,5,2,1,7549,,,0,"Add unautorized exception handling

Change-Id: Ic2dfc3468328cd0558af9574dabf6dc2afafe764
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/72/37272/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/views.py'],1,ffc560112d0e55f8ca92791cc73fd7d8e9bc7454,,"from muranoclient.common.exceptions import HTTPUnauthorized, \ exceptions.handle(self.request, 'Could not connect to Murano API \ Service, check connection details') except HTTPInternalServerError: exceptions.handle(self.request, 'Murano API Service is not responding. \ Try again later') except HTTPUnauthorized: exceptions.handle(self.request) ","from muranoclient.common.exceptions import \ messages.error(self.request, 'Could not connect to Murano API ' 'Service, check connection details.') except HTTPInternalServerError: pass",11,4
openstack%2Fmurano-dashboard~master~Iad48506cbdf6e5bf4b462b1d91af01c53cd1686a,openstack/murano-dashboard,master,Iad48506cbdf6e5bf4b462b1d91af01c53cd1686a,Add * to templates in manifest,MERGED,2013-07-16 14:33:45.000000000,2013-07-16 16:31:47.000000000,2013-07-16 16:31:47.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-07-16 14:33:45.000000000', 'files': ['MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/35237703cf1f969dba9ad8665fe79be85b6c117a', 'message': 'Add * to templates in manifest\n\nChange-Id: Iad48506cbdf6e5bf4b462b1d91af01c53cd1686a\n'}]",0,37258,35237703cf1f969dba9ad8665fe79be85b6c117a,5,2,1,7549,,,0,"Add * to templates in manifest

Change-Id: Iad48506cbdf6e5bf4b462b1d91af01c53cd1686a
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/58/37258/1 && git format-patch -1 --stdout FETCH_HEAD,['MANIFEST.in'],1,35237703cf1f969dba9ad8665fe79be85b6c117a,,include muranodashboard/templates/*,include muranodashboard/templates/,1,1
openstack%2Fpython-zaqarclient~master~I82df865d52f32ce47dde6a09a84d3d917fd77918,openstack/python-zaqarclient,master,I82df865d52f32ce47dde6a09a84d3d917fd77918,Add apiclient library,MERGED,2013-05-15 16:03:04.000000000,2013-07-16 16:17:17.000000000,2013-07-16 16:17:17.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1267}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6482}, {'_account_id': 6944}, {'_account_id': 6971}, {'_account_id': 7044}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-05-15 16:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/f15eae9ad86b74fb4c483828397b5f9db84703a4', 'message': 'Add apiclient, setup, and version from oslo\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 2, 'created': '2013-05-15 19:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/84aa26cb715e05e3b11c5763078b4db342d8118b', 'message': 'Add apiclient, setup, and version from oslo\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 3, 'created': '2013-05-18 10:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/4870f4fdcb36f8f8c25799782f603758d459f495', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* store authentication information in a keyring;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 4, 'created': '2013-05-18 10:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/19d807a84d251451827d1d51f609db29201eccd9', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* store authentication information in a keyring;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 5, 'created': '2013-05-18 16:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/6d40d23070b9ea2ea6de1c7e0e2361e3bf1d5384', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* store authentication information in a keyring;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 6, 'created': '2013-05-20 19:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/9337a83d21131030a368e8fbf6584074fe317b5d', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* store authentication information in a keyring;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 7, 'created': '2013-05-20 19:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/1516d2801015f92955c39109d69731bb54cf55c4', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* store authentication information in a keyring;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 8, 'created': '2013-05-20 19:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/ec5294f48ed40e9786747b3d1aaeacdfce454f72', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* store authentication information in a keyring;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 9, 'created': '2013-06-06 19:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/f90829a0edf1a1b2582ee598de6934fc802e0ca0', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 10, 'created': '2013-06-06 19:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/ada6feb0889286cb501f65c9dd45558270a9ae6e', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 11, 'created': '2013-06-11 17:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/2a91e8e18a4c6ff998cc187eae924aea20cf96c2', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 12, 'created': '2013-06-14 14:39:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/19c1c067ec76e9c145d11591e640d9375adc2ec7', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 13, 'created': '2013-06-14 14:47:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/d4418a5a892d536a5f0f62408ac9da11a6448580', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 14, 'created': '2013-06-20 18:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/dbc531a2c854738ed31c14d5633305b98966bfe8', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 15, 'created': '2013-06-20 19:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/8005db283c287851f0b5bf74ba1ca8c5d308d5a8', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 16, 'created': '2013-06-21 05:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/3a6562129aae7ff3aef934b99a89026e111e70e3', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 17, 'created': '2013-07-03 15:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/f7715fb3a92cb3aae1dc3cf397c70c692cf12f39', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 18, 'created': '2013-07-03 15:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/15c6c0ceba00f42aecefabb12e9074279ef22cd9', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 19, 'created': '2013-07-03 15:19:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/5fcd34fe1bd4d28ee164bf5e602398c85131f01c', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 20, 'created': '2013-07-03 15:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/4354ae0d85c1831f6c6ec76fd36f9b040137b797', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 21, 'created': '2013-07-03 19:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/f8e4880e706e35c1d876861eb2470cd7a7c30a72', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 22, 'created': '2013-07-10 10:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/f3b01fcd526012f304815dd1afe1fbe0f1ea55c0', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 23, 'created': '2013-07-10 10:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/79705d31e1a17517b63ddb3c952a9d69c1b5c145', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 24, 'created': '2013-07-10 11:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/6a88db3b439ddc2c99acbe434d75dfa550699571', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}, {'number': 25, 'created': '2013-07-10 11:32:47.000000000', 'files': ['marconiclient/openstack/common/importutils.py', 'marconiclient/common/apiclient/auth/keystone.py', 'marconiclient/openstack/common/timeutils.py', 'tests/common/apiclient/auth/test_response.py', 'marconiclient/openstack/common/strutils.py', 'marconiclient/openstack/__init__.py', 'tests/common/apiclient/auth/test_base.py', 'marconiclient/common/apiclient/auth/endpoint.py', 'marconiclient/common/apiclient/auth/base.py', 'requirements.txt', 'tests/common/apiclient/test_exceptions.py', 'marconiclient/common/apiclient/base.py', 'marconiclient/common/apiclient/fake_client.py', 'marconiclient/common/apiclient/client.py', 'openstack-common.conf', 'tests/common/apiclient/auth/test_nova.py', 'marconiclient/openstack/common/gettextutils.py', 'marconiclient/common/apiclient/auth/nova.py', 'marconiclient/openstack/common/__init__.py', 'tests/common/apiclient/auth/__init__.py', 'tests/common/apiclient/__init__.py', 'marconiclient/common/apiclient/exceptions.py', 'marconiclient/common/apiclient/auth/__init__.py', 'marconiclient/common/cliutils.py', 'tests/utils.py', 'tests/common/apiclient/test_client.py', 'tests/common/test_cliutils.py', 'marconiclient/common/apiclient/auth/response.py', 'marconiclient/common/__init__.py', 'tests/common/apiclient/auth/test_keystone.py', 'tests/common/apiclient/test_base.py', 'tests/common/__init__.py', 'setup.cfg', 'marconiclient/common/apiclient/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/4b9b0139641f0e85805783d69dfc3650885cd24a', 'message': 'Add apiclient library\n\nThis library can be used in novaclient, keystoneclient,\nglanceclient, and other client projects. The library\ncontains common code and uses python-requests for\nHTTP communication.\n\nFeatures:\n* reissue authentication request for expired tokens;\n* pluggable authentication;\n* rich exceptions hierarchy;\n* utils for building CLI tools.\n\nPartially implements: blueprint common-client-library\n\nChange-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918\n'}]",93,29255,4b9b0139641f0e85805783d69dfc3650885cd24a,94,10,25,1267,,,0,"Add apiclient library

This library can be used in novaclient, keystoneclient,
glanceclient, and other client projects. The library
contains common code and uses python-requests for
HTTP communication.

Features:
* reissue authentication request for expired tokens;
* pluggable authentication;
* rich exceptions hierarchy;
* utils for building CLI tools.

Partially implements: blueprint common-client-library

Change-Id: I82df865d52f32ce47dde6a09a84d3d917fd77918
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/55/29255/8 && git format-patch -1 --stdout FETCH_HEAD,"['marconiclient/openstack/common/importutils.py', 'marconiclient/openstack/common/__init__.py', 'marconiclient/openstack/common/setup.py', 'marconiclient/openstack/common/timeutils.py', 'marconiclient/openstack/common/apiclient/__init__.py', 'marconiclient/openstack/common/apiclient/client.py', 'marconiclient/openstack/common/apiclient/exceptions.py', 'marconiclient/openstack/common/strutils.py', 'marconiclient/openstack/__init__.py', 'marconiclient/openstack/common/apiclient/base.py', 'marconiclient/openstack/common/apiclient/auth_plugin.py', 'marconiclient/openstack/common/apiclient/utils.py', 'openstack-common.conf', 'marconiclient/openstack/common/version.py', 'marconiclient/openstack/common/apiclient/keyring_saver.py', 'marconiclient/openstack/common/gettextutils.py']",16,f15eae9ad86b74fb4c483828397b5f9db84703a4,bp/common-client-library,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2012 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" gettext for openstack-common modules. Usual usage in an openstack.common module: from marconiclient.openstack.common.gettextutils import _ """""" import gettext import os _localedir = os.environ.get('marconiclient'.upper() + '_LOCALEDIR') _t = gettext.translation('marconiclient', localedir=_localedir, fallback=True) def _(msg): return _t.ugettext(msg) def install(domain): """"""Install a _() function using the given translation domain. Given a translation domain, install a _() function using gettext's install() function. The main difference from gettext.install() is that we allow overriding the default localedir (e.g. /usr/share/locale) using a translation-domain-specific environment variable (e.g. NOVA_LOCALEDIR). """""" gettext.install(domain, localedir=os.environ.get(domain.upper() + '_LOCALEDIR'), unicode=True) ",,2974,0
openstack%2Foslo-incubator~master~I51aca3b05866e513cbbb3163df7e5514d99af192,openstack/oslo-incubator,master,I51aca3b05866e513cbbb3163df7e5514d99af192,Fixes path to add on PYTHONPATH in generate_sample.sh,MERGED,2013-07-16 07:55:46.000000000,2013-07-16 16:15:08.000000000,2013-07-16 16:15:08.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-07-16 07:55:46.000000000', 'files': ['tools/config/generate_sample.sh'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3ea1767ac39d3cd57e49f7bb03eb2014e6484e6a', 'message': 'Fixes path to add on PYTHONPATH in generate_sample.sh\n\nFixes bug #1201699\n\nChange-Id: I51aca3b05866e513cbbb3163df7e5514d99af192\n'}]",0,37191,3ea1767ac39d3cd57e49f7bb03eb2014e6484e6a,7,4,1,1994,,,0,"Fixes path to add on PYTHONPATH in generate_sample.sh

Fixes bug #1201699

Change-Id: I51aca3b05866e513cbbb3163df7e5514d99af192
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/91/37191/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/config/generate_sample.sh'],1,3ea1767ac39d3cd57e49f7bb03eb2014e6484e6a,bug/1201699,PYTHONPATH=$BASEDIR/:${PYTHONPATH} python $MODULEPATH $FILES > $OUTPUTFILE,PYTHONPATH=./:${PYTHONPATH} python $MODULEPATH $FILES > $OUTPUTFILE,1,1
openstack%2Fsahara-dashboard~master~I7c3d2bf9d0f941d6cdbe0611c1574e949467a447,openstack/sahara-dashboard,master,I7c3d2bf9d0f941d6cdbe0611c1574e949467a447,Error messages support added.,MERGED,2013-07-15 14:14:47.000000000,2013-07-16 16:09:56.000000000,2013-07-16 16:09:56.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7132}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-15 14:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/7a8973797d218db43885e09dac203ee1a59f7cb7', 'message': 'Error messages support added.\n\nNow response code and response message are displayed.\n\nChange-Id: I7c3d2bf9d0f941d6cdbe0611c1574e949467a447\n'}, {'number': 2, 'created': '2013-07-16 09:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/db94209d49e025db57779d04a1de6311ad25a870', 'message': 'Error messages support added.\n\nNow response message is displayed.\n\nImplements blueprint handle-cluster-errors\n\nChange-Id: I7c3d2bf9d0f941d6cdbe0611c1574e949467a447\n'}, {'number': 3, 'created': '2013-07-16 10:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/1c0234fe61c60fc2b765f66f79fb0e27cc9f1fec', 'message': 'Error messages support added.\n\nNow response message is displayed.\n\nImplements blueprint handle-cluster-errors\n\nChange-Id: I7c3d2bf9d0f941d6cdbe0611c1574e949467a447\n'}, {'number': 4, 'created': '2013-07-16 11:30:02.000000000', 'files': ['savannadashboard/cluster_templates/workflows/copy.py', 'savannadashboard/nodegroup_templates/workflows/copy.py', 'savannadashboard/cluster_templates/forms.py', 'savannadashboard/utils/workflow_helpers.py', 'savannadashboard/api/base.py', 'savannadashboard/clusters/workflows/scale.py', 'savannadashboard/image_registry/forms.py', 'savannadashboard/nodegroup_templates/workflows/create.py', 'savannadashboard/clusters/workflows/create.py', 'savannadashboard/cluster_templates/workflows/create.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/76b3db19f65ff8106ee9d3d1e72c08cf81919788', 'message': 'Error messages support added.\n\nNow response message is displayed.\n\nImplements blueprint handle-cluster-errors\n\nChange-Id: I7c3d2bf9d0f941d6cdbe0611c1574e949467a447\n'}]",10,37059,76b3db19f65ff8106ee9d3d1e72c08cf81919788,23,5,4,7132,,,0,"Error messages support added.

Now response message is displayed.

Implements blueprint handle-cluster-errors

Change-Id: I7c3d2bf9d0f941d6cdbe0611c1574e949467a447
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/59/37059/4 && git format-patch -1 --stdout FETCH_HEAD,"['savannadashboard/cluster_templates/forms.py', 'savannadashboard/api/base.py', 'savannadashboard/clusters/workflows/scale.py', 'savannadashboard/clusters/workflows/create.py', 'savannadashboard/image_registry/forms.py', 'savannadashboard/nodegroup_templates/workflows/create.py', 'savannadashboard/cluster_templates/workflows/create.py']",7,7a8973797d218db43885e09dac203ee1a59f7cb7,bp/handle-cluster-errors," failure_message = ""Could not create Cluster Template %s. %s"" error_description = getattr(self, 'error_description', None) if error_description: return message % (self.context[""general_cluster_template_name""], error_description) else: return message % self.context[""general_cluster_template_name""] except Exception as e: self.error_description = str(e)","from horizon import exceptions failure_message = _(""Could not create Cluster Template %s"") return message % self.context[""general_cluster_template_name""] except Exception: exceptions.handle(request)",46,37
openstack%2Fceilometer~master~I69d0ba99b4f31b293e4d372dd85b663bc60042ff,openstack/ceilometer,master,I69d0ba99b4f31b293e4d372dd85b663bc60042ff,make publisher procedure call configurable,MERGED,2013-07-16 03:46:12.000000000,2013-07-16 15:54:45.000000000,2013-07-16 15:54:45.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-07-16 03:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/02b1d71ec83c62ff7a9276a42e30d955dc9ca3c6', 'message': 'make publisher procedure call configurable\n\nallow configurable publisher to cast to procedure other than\nrecord_metering_data\n\nChange-Id: I69d0ba99b4f31b293e4d372dd85b663bc60042ff\n'}, {'number': 2, 'created': '2013-07-16 13:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4268f0dc8eb3038a36d4eae6dcf627d76db0bf42', 'message': 'make publisher procedure call configurable\n\nallow configurable publisher to cast to procedure other than\nrecord_metering_data\n\nChange-Id: I69d0ba99b4f31b293e4d372dd85b663bc60042ff\n'}, {'number': 3, 'created': '2013-07-16 14:15:41.000000000', 'files': ['tests/publisher/test_rpc_publisher.py', 'ceilometer/publisher/rpc.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e3acc106e9377895fcbe761ccaa1399367ea58ca', 'message': 'make publisher procedure call configurable\n\nallow configurable publisher to cast to procedure other than\nrecord_metering_data\n\nChange-Id: I69d0ba99b4f31b293e4d372dd85b663bc60042ff\n'}]",0,37166,e3acc106e9377895fcbe761ccaa1399367ea58ca,11,4,3,6537,,,0,"make publisher procedure call configurable

allow configurable publisher to cast to procedure other than
record_metering_data

Change-Id: I69d0ba99b4f31b293e4d372dd85b663bc60042ff
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/66/37166/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/publisher/test_rpc_publisher.py', 'ceilometer/publisher/rpc.py']",2,02b1d71ec83c62ff7a9276a42e30d955dc9ca3c6,configurable-publisher-target," import pdb;pdb.set_trace() self.target = options.get('target', ['record_metering_data'])[0] 'method': self.target, 'method': self.target,"," 'method': 'record_metering_data', 'method': 'record_metering_data',",19,2
openstack%2Fironic~master~I6cc851554e2dcc620bfeb45dc63c9d80d09e9586,openstack/ironic,master,I6cc851554e2dcc620bfeb45dc63c9d80d09e9586,update requires to prevent version cap,MERGED,2013-07-11 15:48:25.000000000,2013-07-16 15:47:21.000000000,2013-07-16 15:47:21.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-07-11 15:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/de44097dae0f48fbd70c223f1e25cbd0133dc812', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group mails\n\nfixes bug #1200214\n\nChange-Id: I6cc851554e2dcc620bfeb45dc63c9d80d09e9586\n'}, {'number': 2, 'created': '2013-07-11 17:13:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f8616abcfbc5dcae7e672cfcc7ef9d3b11f9c6bb', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group mails\n(http://lists.openstack.org/pipermail/openstack-dev/2013-July/011660.html)\n\nfixes bug #1200214\n\nChange-Id: I6cc851554e2dcc620bfeb45dc63c9d80d09e9586\n'}, {'number': 3, 'created': '2013-07-13 04:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4a9afdaef1ce13fd91b17c99103330a4981a0d75', 'message': 'update requires to prevent version cap\n\nbased on talks in openstack-dev group mails\n(http://lists.openstack.org/pipermail/openstack-dev/2013-July/011660.html)\n\nfixes bug #1200214\n\nChange-Id: I6cc851554e2dcc620bfeb45dc63c9d80d09e9586\n'}, {'number': 4, 'created': '2013-07-15 16:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/89d5a881d7590fd1c376d1c4986abb9656e40944', 'message': 'update requires to prevent version cap\n\nOpenStack clients. None of these should have an upper bound\nas that has implications for testing in the gate. An exception\nis currently being made for neutron client because of the need\nfor an incompatible change in their next release.\nhttps://github.com/openstack/requirements\n\nfixes bug #1200214\n\nChange-Id: I6cc851554e2dcc620bfeb45dc63c9d80d09e9586\n'}, {'number': 5, 'created': '2013-07-15 16:26:47.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/3a3ce4399a03024517e16fd6c9d61b887b9eba02', 'message': 'update requires to prevent version cap\n\nOpenStack clients. None of these should have an upper bound\nas that has implications for testing in the gate. An exception\nis currently being made for neutron client because of the need\nfor an incompatible change in their next release.\nhttps://github.com/openstack/requirements\n\nfixes bug #1200214\n\nChange-Id: I6cc851554e2dcc620bfeb45dc63c9d80d09e9586\n'}]",0,36683,3a3ce4399a03024517e16fd6c9d61b887b9eba02,18,5,5,6835,,,0,"update requires to prevent version cap

OpenStack clients. None of these should have an upper bound
as that has implications for testing in the gate. An exception
is currently being made for neutron client because of the need
for an incompatible change in their next release.
https://github.com/openstack/requirements

fixes bug #1200214

Change-Id: I6cc851554e2dcc620bfeb45dc63c9d80d09e9586
",git fetch https://review.opendev.org/openstack/ironic refs/changes/83/36683/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,de44097dae0f48fbd70c223f1e25cbd0133dc812,bug/1200214,"python-keystoneclient>=0.2,<0.4oslo.config>=1.1.0,<2.0","python-keystoneclient>=0.2,<0.3oslo.config>=1.1.0",2,2
openstack%2Fnova~master~I6f3eb5fd2c75615d9a1cae172aed859b36b27d4c,openstack/nova,master,I6f3eb5fd2c75615d9a1cae172aed859b36b27d4c,Fix issue with pip installing oslo.config-1.2.0,MERGED,2013-07-02 12:07:19.000000000,2013-07-16 15:44:33.000000000,2013-07-16 15:44:30.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1297}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1669}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 4912}]","[{'number': 1, 'created': '2013-07-02 12:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5cdb7746080cc9137e4c1fff9e83e78e39d90ea', 'message': 'Fix issue with pip installing oslo.config-1.2.0\n\nFixes bug #1194807\n\nFirstly, we update the oslo.config dep to 1.2.0a3 because of the issue\nwith namespace packages (bug #1194742).\n\nBut the main issue here is that when we previously depended on 1.2.0a3\nwe found that if you did:\n\n  $> pip install -r nova/requirements.txt\n\nthen you end up with the oslo.config 1.1.1 code installed. This is\nbecause oslo.config>=1.1.0 gets pulled in as a transitive dep and pip\ngets confused.\n\nSee I977700d73342e81ee962019b76238d2cb2b1fff4\n\nYou can reproduce with e.g.\n\n  $> pip install \\\n       http://.../oslo.config-1.2.0a3.tar.gz#egg=oslo.config-1.2.0a3 \\\n       python-keystoneclient\n  $> pip freeze | grep oslo.config\n  oslo.config-1.2.0a3\n  $> python -c \'from oslo.config.cfg import DeprecatedOpt\'\n  Traceback (most recent call last):\n    File ""<string>"", line 1, in <module>\n  ImportError: cannot import name DeprecatedOpt\n\nThis is because of a bug with pip where it sees oslo.config-1.2.0a3 and\noslo.config as two unrelated things. It should strip the version part of\nthe egg= fragment before using it as a package name, but it doesn\'t.\n\nHowever, we can simply use the -f/--find-links pip option in our\nrequirements.txt to add the tarball URL to the list of URLs considered\nand also add the oslo.config>=1.2.0a3 dependency:\n\n  $> pip install \\\n       -f http://.../oslo.config-1.2.0a3.tar.gz#egg=oslo.config-1.2.0a3 \\\n       \'oslo.config>=1.2.0a3\' \\\n       python-keystoneclient\n  $> pip freeze | grep oslo.config\n  oslo.config-1.2.0a3\n  $> python -c \'from oslo.config.cfg import DeprecatedOpt\'\n\nThis is actually exactly the semantics we want and we go to great\nlengths in pbr to get these semantics while using a single tarball URL.\nThe only downside to this --find-links strategy is that we gain an extra\nline in our requirements.txt ... but it does work around the pip bug.\n\nChange-Id: I6f3eb5fd2c75615d9a1cae172aed859b36b27d4c\n'}, {'number': 2, 'created': '2013-07-10 21:29:26.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/59b799d30e58cc294e843dfc25895574b2ab40a7', 'message': 'Fix issue with pip installing oslo.config-1.2.0\n\nFixes bug #1194807\n\nFirstly, we update the oslo.config dep to 1.2.0a3 because of the issue\nwith namespace packages (bug #1194742).\n\nBut the main issue here is that when we previously depended on 1.2.0a3\nwe found that if you did:\n\n  $> pip install -r nova/requirements.txt\n\nthen you end up with the oslo.config 1.1.1 code installed. This is\nbecause oslo.config>=1.1.0 gets pulled in as a transitive dep and pip\ngets confused.\n\nSee I977700d73342e81ee962019b76238d2cb2b1fff4\n\nYou can reproduce with e.g.\n\n  $> pip install \\\n       http://.../oslo.config-1.2.0a3.tar.gz#egg=oslo.config-1.2.0a3 \\\n       python-keystoneclient\n  $> pip freeze | grep oslo.config\n  oslo.config-1.2.0a3\n  $> python -c \'from oslo.config.cfg import DeprecatedOpt\'\n  Traceback (most recent call last):\n    File ""<string>"", line 1, in <module>\n  ImportError: cannot import name DeprecatedOpt\n\nThis is because of a bug with pip where it sees oslo.config-1.2.0a3 and\noslo.config as two unrelated things. It should strip the version part of\nthe egg= fragment before using it as a package name, but it doesn\'t.\n\nHowever, we can simply use the -f/--find-links pip option in our\nrequirements.txt to add the tarball URL to the list of URLs considered\nand also add the oslo.config>=1.2.0a3 dependency:\n\n  $> pip install \\\n       -f http://.../oslo.config-1.2.0a3.tar.gz#egg=oslo.config-1.2.0a3 \\\n       \'oslo.config>=1.2.0a3\' \\\n       python-keystoneclient\n  $> pip freeze | grep oslo.config\n  oslo.config-1.2.0a3\n  $> python -c \'from oslo.config.cfg import DeprecatedOpt\'\n\nThis is actually exactly the semantics we want and we go to great\nlengths in pbr to get these semantics while using a single tarball URL.\nThe only downside to this --find-links strategy is that we gain an extra\nline in our requirements.txt ... but it does work around the pip bug.\n\nChange-Id: I6f3eb5fd2c75615d9a1cae172aed859b36b27d4c\n'}]",0,35281,59b799d30e58cc294e843dfc25895574b2ab40a7,25,10,2,1247,,,0,"Fix issue with pip installing oslo.config-1.2.0

Fixes bug #1194807

Firstly, we update the oslo.config dep to 1.2.0a3 because of the issue
with namespace packages (bug #1194742).

But the main issue here is that when we previously depended on 1.2.0a3
we found that if you did:

  $> pip install -r nova/requirements.txt

then you end up with the oslo.config 1.1.1 code installed. This is
because oslo.config>=1.1.0 gets pulled in as a transitive dep and pip
gets confused.

See I977700d73342e81ee962019b76238d2cb2b1fff4

You can reproduce with e.g.

  $> pip install \
       http://.../oslo.config-1.2.0a3.tar.gz#egg=oslo.config-1.2.0a3 \
       python-keystoneclient
  $> pip freeze | grep oslo.config
  oslo.config-1.2.0a3
  $> python -c 'from oslo.config.cfg import DeprecatedOpt'
  Traceback (most recent call last):
    File ""<string>"", line 1, in <module>
  ImportError: cannot import name DeprecatedOpt

This is because of a bug with pip where it sees oslo.config-1.2.0a3 and
oslo.config as two unrelated things. It should strip the version part of
the egg= fragment before using it as a package name, but it doesn't.

However, we can simply use the -f/--find-links pip option in our
requirements.txt to add the tarball URL to the list of URLs considered
and also add the oslo.config>=1.2.0a3 dependency:

  $> pip install \
       -f http://.../oslo.config-1.2.0a3.tar.gz#egg=oslo.config-1.2.0a3 \
       'oslo.config>=1.2.0a3' \
       python-keystoneclient
  $> pip freeze | grep oslo.config
  oslo.config-1.2.0a3
  $> python -c 'from oslo.config.cfg import DeprecatedOpt'

This is actually exactly the semantics we want and we go to great
lengths in pbr to get these semantics while using a single tarball URL.
The only downside to this --find-links strategy is that we gain an extra
line in our requirements.txt ... but it does work around the pip bug.

Change-Id: I6f3eb5fd2c75615d9a1cae172aed859b36b27d4c
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/35281/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b5cdb7746080cc9137e4c1fff9e83e78e39d90ea,, -f http://tarballs.openstack.org/oslo.config/oslo.config-1.2.0a3.tar.gz#egg=oslo.config-1.2.0a3 oslo.config>=1.2.0a3,oslo.config>=1.1.0,3,1
openstack%2Fironic~master~I02bee4e10dcee233209e57025c18e5ae5cea86f8,openstack/ironic,master,I02bee4e10dcee233209e57025c18e5ae5cea86f8,Implement chassis api actions,MERGED,2013-07-10 10:43:52.000000000,2013-07-16 15:43:02.000000000,2013-07-16 15:43:02.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6623}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-07-10 10:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/decd4a7d09290f4292f8009209f395e271a3ae62', 'message': 'Implement chassis api\n\nChange-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8\n'}, {'number': 2, 'created': '2013-07-10 14:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/296d71e3a1df5abca292ebc4a04f22daf7ef61fc', 'message': 'Implement chassis api\n\nChange-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8\n'}, {'number': 3, 'created': '2013-07-10 15:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b13434892b2d4cb74ecff98028c0fa2efeca97d0', 'message': 'Implement chassis api actions\n\nPartially implements blueprint chassis-api-actions\n\nChange-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8\n'}, {'number': 4, 'created': '2013-07-10 16:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1306090cf29287290a802ecdd2151755761021ca', 'message': 'Implement chassis api actions\n\nPartially implements blueprint chassis-api-actions\n\nChange-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8\n'}, {'number': 5, 'created': '2013-07-11 10:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1cff073d21922e9d714947ee2e71909c11ad1195', 'message': 'Implement chassis api actions\n\nPartially implements blueprint chassis-api-actions\n\nChange-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8\n'}, {'number': 6, 'created': '2013-07-12 14:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bd3cd1b231c948730a1d7ce555ef033bd30665b2', 'message': 'Implement chassis api actions\n\nPartially implements blueprint chassis-api-actions\n\nChange-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8\n'}, {'number': 7, 'created': '2013-07-16 11:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/175fc4ffcc0c03bfbd312b64707926818bf40920', 'message': ""Implement chassis api actions\n\nPartially implements blueprint chassis-api-actions:\n* adds 'description' field to chassis\n* api to retrieve list of chassis\n* api to retrieve details of a single chassis\n* api to create/update/delete a chassis\n\nChange-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8\n""}, {'number': 8, 'created': '2013-07-16 11:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/420d6522ac24b45a4b862ed05d296aa89113f5d8', 'message': ""Implement chassis api actions\n\nPartially implements blueprint chassis-api-actions:\n* adds 'description' field to chassis\n* api to retrieve list of chassis\n* api to retrieve details of a single chassis\n* api to create/update/delete a chassis\n\nChange-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8\n""}, {'number': 9, 'created': '2013-07-16 13:13:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/dd4222cba3ab3f3e87094a70d38c9cd095362ce4', 'message': ""Implement chassis api actions\n\nPartially implements blueprint chassis-api-actions:\n* adds 'description' field to chassis\n* api to retrieve list of chassis\n* api to retrieve details of a single chassis\n* api to create/update/delete a chassis\n\nChange-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8\n""}, {'number': 10, 'created': '2013-07-16 15:11:06.000000000', 'files': ['ironic/tests/db/utils.py', 'ironic/api/controllers/v1/chassis.py', 'ironic/db/sqlalchemy/api.py', 'ironic/objects/chassis.py', 'ironic/db/sqlalchemy/migrate_repo/versions/008_add_description_to_chassis.py', 'ironic/api/controllers/v1/controller.py', 'ironic/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d497895767b17acbfbc67d8335a653546a7aa4b6', 'message': ""Implement chassis api actions\n\nPartially implements blueprint chassis-api-actions:\n* adds 'description' field to chassis\n* api to retrieve list of chassis\n* api to retrieve details of a single chassis\n* api to create/update/delete a chassis\n\nChange-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8\n""}]",12,36432,d497895767b17acbfbc67d8335a653546a7aa4b6,30,4,10,6773,,,0,"Implement chassis api actions

Partially implements blueprint chassis-api-actions:
* adds 'description' field to chassis
* api to retrieve list of chassis
* api to retrieve details of a single chassis
* api to create/update/delete a chassis

Change-Id: I02bee4e10dcee233209e57025c18e5ae5cea86f8
",git fetch https://review.opendev.org/openstack/ironic refs/changes/32/36432/5 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/chassis.py', 'ironic/db/sqlalchemy/api.py', 'ironic/tests/db/test_chassis.py', 'ironic/api/controllers/v1/controller.py', 'ironic/db/api.py']",5,decd4a7d09290f4292f8009209f395e271a3ae62,bp/chassis-api-actions," def get_chassis_list(self): """"""Return a list of node UUIDs."""""" @abc.abstractmethod",,123,0
openstack%2Foslo-incubator~master~I77ec36e94f589032f6f7ef65cea6420d6f15d804,openstack/oslo-incubator,master,I77ec36e94f589032f6f7ef65cea6420d6f15d804,Document Flavio as a maintainer of the policy code,MERGED,2013-07-16 15:05:21.000000000,2013-07-16 15:35:56.000000000,2013-07-16 15:35:56.000000000,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 2472}, {'_account_id': 6159}]","[{'number': 1, 'created': '2013-07-16 15:05:21.000000000', 'files': ['MAINTAINERS'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/0c5ea042b951802f057ac570fd55ebfc3731f0b5', 'message': 'Document Flavio as a maintainer of the policy code\n\nChange-Id: I77ec36e94f589032f6f7ef65cea6420d6f15d804\n'}]",0,37267,0c5ea042b951802f057ac570fd55ebfc3731f0b5,6,4,1,1247,,,0,"Document Flavio as a maintainer of the policy code

Change-Id: I77ec36e94f589032f6f7ef65cea6420d6f15d804
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/67/37267/1 && git format-patch -1 --stdout FETCH_HEAD,['MAINTAINERS'],1,0c5ea042b951802f057ac570fd55ebfc3731f0b5,,M: Flavio Percoco <flavio@redhat.com> S: Maintained,M: S: Orphan,2,2
openstack%2Foslo-incubator~master~I41338675842be517146062d11012462c5c90d6e5,openstack/oslo-incubator,master,I41338675842be517146062d11012462c5c90d6e5,Fix missing argument bug in oslo common policy,MERGED,2013-06-25 09:02:36.000000000,2013-07-16 15:21:25.000000000,2013-07-16 15:21:25.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6928}, {'_account_id': 7040}]","[{'number': 1, 'created': '2013-06-25 09:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/05a5d2fafd999fe7c42566c60cdd04e6f1fdd43a', 'message': 'Fix missing argument bug in oslo common policy\n\nSome checks in policy module missing a argument, this\npatch fixed it by adding the necessary argument.\n\nFixed bug #1194354\n\nChange-Id: I41338675842be517146062d11012462c5c90d6e5\n'}, {'number': 2, 'created': '2013-06-26 02:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/20b84a3ca51fe0f1c69751bab1b87c0e4f3acc80', 'message': 'Fix missing argument bug in oslo common policy\n\nSome checks in policy module missing a argument, this\npatch fixed it by adding the necessary argument.\n\nFixed bug #1194354\n\nChange-Id: I41338675842be517146062d11012462c5c90d6e5\n'}, {'number': 3, 'created': '2013-06-26 10:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/19cc53d99a0f102c6028508e91b0fce6a93b66ed', 'message': 'Fix missing argument bug in oslo common policy\n\nSome checks in policy module missing a argument, this\npatch fixed it by adding the necessary argument.\n\nFixed bug #1194354\n\nChange-Id: I41338675842be517146062d11012462c5c90d6e5\n'}, {'number': 4, 'created': '2013-06-27 18:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/4297435ec1b6d4c946104d0cb183890456a78986', 'message': 'Fix missing argument bug in oslo common policy\n\nSome checks in policy module missing a argument, this\npatch fixed it by adding the necessary argument.\n\nFixed bug #1194354\n\nChange-Id: I41338675842be517146062d11012462c5c90d6e5\n'}, {'number': 5, 'created': '2013-07-12 07:56:22.000000000', 'files': ['openstack/common/policy.py', 'tests/unit/test_policy.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/e4ac367561b3811a9cd94e51accdf8045b7d6adc', 'message': 'Fix missing argument bug in oslo common policy\n\nSome checks in policy module missing a argument, this\npatch fixed it by adding the necessary argument.\n\nFixed bug #1194354\n\nChange-Id: I41338675842be517146062d11012462c5c90d6e5\n'}]",12,34333,e4ac367561b3811a9cd94e51accdf8045b7d6adc,28,8,5,7040,,,0,"Fix missing argument bug in oslo common policy

Some checks in policy module missing a argument, this
patch fixed it by adding the necessary argument.

Fixed bug #1194354

Change-Id: I41338675842be517146062d11012462c5c90d6e5
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/33/34333/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/policy.py', 'tests/unit/test_policy.py']",2,05a5d2fafd999fe7c42566c60cdd04e6f1fdd43a,bug/1194354," def test_rule_with_check(self): rules_json = """"""{ ""deny_stack_user"": ""not role:stack_user"", ""cloudwatch:PutMetricData"": """" }"""""" rules = policy.Rules.load_json(rules_json) self.enforcer.set_rules(rules) action = ""cloudwatch:PutMetricData"" creds = { 'roles': '', } #self.enforcer.enforce(action, {}, creds) self.assertEqual(self.enforcer.enforce(action, {}, creds), True) self.assertEqual(check('target', 'creds', None), False) self.assertEqual(check('target', 'creds', None), True) self.assertEqual(check('target', 'cred', None), False) rule.assert_called_once_with('target', 'cred', None) self.assertEqual(check('target', 'cred', None), True) rule.assert_called_once_with('target', 'cred', None) self.assertEqual(check('target', 'cred', None), False) self.assertEqual(check('target', 'cred', None), True) self.assertEqual(check('target', 'cred', None), True)"," self.assertEqual(check('target', 'creds'), False) self.assertEqual(check('target', 'creds'), True) self.assertEqual(check('target', 'cred'), False) rule.assert_called_once_with('target', 'cred') self.assertEqual(check('target', 'cred'), True) rule.assert_called_once_with('target', 'cred') self.assertEqual(check('target', 'cred'), False) self.assertEqual(check('target', 'cred'), True) self.assertEqual(check('target', 'cred'), True)",29,15
openstack%2Foslo-incubator~master~I00306821d1437324262ba8a3154b8a837bfb6434,openstack/oslo-incubator,master,I00306821d1437324262ba8a3154b8a837bfb6434,Allow launchers to be stopped multiple times,MERGED,2013-07-09 16:46:35.000000000,2013-07-16 15:17:49.000000000,2013-07-16 15:17:49.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1994}, {'_account_id': 2835}]","[{'number': 1, 'created': '2013-07-09 16:46:35.000000000', 'files': ['tests/unit/test_service.py', 'openstack/common/service.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/dc8aa797c304251a3cb960f5274681a602ea077b', 'message': 'Allow launchers to be stopped multiple times\n\nMakes launchers play nicely with unit test fixtures in nova.\n\nbug 1199315\n\nChange-Id: I00306821d1437324262ba8a3154b8a837bfb6434\n'}]",2,36292,dc8aa797c304251a3cb960f5274681a602ea077b,8,4,1,2835,,,0,"Allow launchers to be stopped multiple times

Makes launchers play nicely with unit test fixtures in nova.

bug 1199315

Change-Id: I00306821d1437324262ba8a3154b8a837bfb6434
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/92/36292/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_service.py', 'openstack/common/service.py']",2,dc8aa797c304251a3cb960f5274681a602ea077b,bug/1199315," # Signal that service cleanup is done: if not self._done.ready(): self._done.send() # Each service has performed cleanup, now signal that the run_service # wrapper threads can now die: if not self.done.ready(): self.done.send()"," self._done.send() # each service has performed cleanup, now signal that the run_service # wrapper threads can now die: self.done.send()",10,3
openstack%2Fceilometer~master~I59cf409106e0ba8bb819f7fc6aeddd0a837fee4c,openstack/ceilometer,master,I59cf409106e0ba8bb819f7fc6aeddd0a837fee4c,Added alembic migrations,MERGED,2013-07-16 11:33:55.000000000,2013-07-16 15:14:44.000000000,2013-07-16 15:14:44.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-07-16 11:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5133c429caa19bf44df86b7331ee9d6b51951be6', 'message': 'Added alembic migrations\n\nAdded alembic dependency to requirements\nCreated alembic config files\n\nTo create alembic migration:\n$ cd ./ceilometer/storage/sqlalchemy/alembic\n$ alembic revision -m ""migration_description""\n\nRelated to blueprint convert-to-alembic\n\nChange-Id: I59cf409106e0ba8bb819f7fc6aeddd0a837fee4c\n'}, {'number': 2, 'created': '2013-07-16 12:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fbe70ec3f44b3c372203db015489bb2684e1cfda', 'message': 'Added alembic migrations\n\nAdded alembic dependency to requirements\nCreated alembic config files\n\nTo create alembic migration:\n$ cd ./ceilometer/storage/sqlalchemy/alembic\n$ alembic revision -m ""migration_description""\n\nRelated to blueprint convert-to-alembic\n\nChange-Id: I59cf409106e0ba8bb819f7fc6aeddd0a837fee4c\n'}, {'number': 3, 'created': '2013-07-16 12:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ac864af9401dfdb338ef9b60ddd242c47844ad1c', 'message': 'Added alembic migrations\n\nAdded alembic dependency to requirements\nCreated alembic config files\n\nTo create alembic migration:\n$ cd ./ceilometer/storage/sqlalchemy/alembic\n$ alembic revision -m ""migration_description""\n\nRelated to blueprint convert-to-alembic\n\nChange-Id: I59cf409106e0ba8bb819f7fc6aeddd0a837fee4c\n'}, {'number': 4, 'created': '2013-07-16 13:07:38.000000000', 'files': ['ceilometer/storage/sqlalchemy/alembic/env.py', 'requirements.txt', 'ceilometer/storage/sqlalchemy/alembic/alembic.ini', 'ceilometer/storage/sqlalchemy/alembic/versions/README', 'ceilometer/storage/sqlalchemy/alembic/README', 'ceilometer/storage/sqlalchemy/alembic/script.py.mako'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/19acddf600030bfe8e86a8db032a1c6ef60e9db7', 'message': 'Added alembic migrations\n\nAdded alembic dependency to requirements\nCreated alembic config files\n\nTo create alembic migration:\n$ cd ./ceilometer/storage/sqlalchemy/alembic\n$ alembic revision -m ""migration_description""\n\nRelated to blueprint convert-to-alembic\n\nChange-Id: I59cf409106e0ba8bb819f7fc6aeddd0a837fee4c\n'}]",1,37223,19acddf600030bfe8e86a8db032a1c6ef60e9db7,12,4,4,7763,,,0,"Added alembic migrations

Added alembic dependency to requirements
Created alembic config files

To create alembic migration:
$ cd ./ceilometer/storage/sqlalchemy/alembic
$ alembic revision -m ""migration_description""

Related to blueprint convert-to-alembic

Change-Id: I59cf409106e0ba8bb819f7fc6aeddd0a837fee4c
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/23/37223/4 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/sqlalchemy/alembic/env.py', 'requirements.txt', 'ceilometer/storage/sqlalchemy/alembic/alembic.ini', 'ceilometer/storage/sqlalchemy/alembic/README', 'ceilometer/storage/sqlalchemy/alembic/script.py.mako']",5,5133c429caa19bf44df86b7331ee9d6b51951be6,bp/convert-to-alembic,"""""""${message} Revision ID: ${up_revision} Revises: ${down_revision} Create Date: ${create_date} """""" # revision identifiers, used by Alembic. revision = ${repr(up_revision)} down_revision = ${repr(down_revision)} from alembic import op import sqlalchemy as sa ${imports if imports else """"} def upgrade(): ${upgrades if upgrades else ""pass""} def downgrade(): ${downgrades if downgrades else ""pass""} ",,142,0
openstack%2Foslo-incubator~master~I8841da1e8d105aac4a86b247228a9c935e00afc5,openstack/oslo-incubator,master,I8841da1e8d105aac4a86b247228a9c935e00afc5,Make lock_file_prefix optional,MERGED,2013-06-10 13:48:24.000000000,2013-07-16 15:11:38.000000000,2013-07-16 15:11:38.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1994}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6849}, {'_account_id': 6928}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-06-10 13:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/449f1d995eb6bd65cbef2c7ae0edcaf9c8d2fd1e', 'message': ""Make lock_file_prefix optional\n\nCurrently, the lock_file_prefix says it should end with an hypen if\nspecified. It seems that it was intended to be optional. Since that\nbehavior makes sense, this patch changes the synchronized's signature\nand makes lock_file_prefix optional.\n\nWith this patch, the prefix will not be required to end with an hypen\nanymore, such sign will be added to the prefix if specified and if not\nalready present.\n\nThis patch doesn't change synchronized's behavior at all, which means it\ndoesn't break backward compatibility.\n\nChange-Id: I8841da1e8d105aac4a86b247228a9c935e00afc5\n""}, {'number': 2, 'created': '2013-06-11 08:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a1f956d952dc4c3885c1132b02d25fec6f7418b3', 'message': ""Make lock_file_prefix optional\n\nCurrently, the lock_file_prefix says it should end with an hypen if\nspecified. It seems that it was intended to be optional. Since that\nbehavior makes sense, this patch changes the synchronized's signature\nand makes lock_file_prefix optional.\n\nWith this patch, the prefix will not be required to end with an hypen\nanymore, such sign will be added to the prefix if specified and if not\nalready present.\n\nThis patch doesn't change synchronized's behavior at all, which means it\ndoesn't break backward compatibility.\n\nChange-Id: I8841da1e8d105aac4a86b247228a9c935e00afc5\n""}, {'number': 3, 'created': '2013-06-11 10:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d3529914fbcd2f9387aac993f161b34da8dfbf88', 'message': ""Make lock_file_prefix optional\n\nCurrently, the lock_file_prefix says it should end with an hypen if\nspecified. It seems that it was intended to be optional. Since that\nbehavior makes sense, this patch changes the synchronized's signature\nand makes lock_file_prefix optional.\n\nWith this patch, the prefix will not be required to end with an hypen\nanymore, such sign will be added to the prefix if specified and if not\nalready present.\n\nThis patch doesn't change synchronized's behavior at all, which means it\ndoesn't break backward compatibility.\n\nChange-Id: I8841da1e8d105aac4a86b247228a9c935e00afc5\n""}, {'number': 4, 'created': '2013-06-11 18:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/54b86062a94776f653b136c94a6d8992fcdc7951', 'message': ""Make lock_file_prefix optional\n\nCurrently, the lock_file_prefix says it should end with an hypen if\nspecified. It seems that it was intended to be optional. Since that\nbehavior makes sense, this patch changes the synchronized's signature\nand makes lock_file_prefix optional.\n\nWith this patch, the prefix will not be required to end with an hypen\nanymore, such sign will be added to the prefix if specified and if not\nalready present.\n\nThis patch doesn't change synchronized's behavior at all, which means it\ndoesn't break backward compatibility.\n\nChange-Id: I8841da1e8d105aac4a86b247228a9c935e00afc5\n""}, {'number': 5, 'created': '2013-07-15 15:33:19.000000000', 'files': ['openstack/common/lockutils.py', 'tests/unit/test_lockutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/15c17fb1d04bf9fa3094e86fd7c38c4c8efad43c', 'message': ""Make lock_file_prefix optional\n\nCurrently, the lock_file_prefix says it should end with an hypen if\nspecified. It seems that it was intended to be optional. Since that\nbehavior makes sense, this patch changes the synchronized's signature\nand makes lock_file_prefix optional.\n\nWith this patch, the prefix will not be required to end with an hypen\nanymore, such sign will be added to the prefix if specified and if not\nalready present.\n\nThis patch doesn't change synchronized's behavior at all, which means it\ndoesn't break backward compatibility.\n\nChange-Id: I8841da1e8d105aac4a86b247228a9c935e00afc5\n""}]",23,32399,15c17fb1d04bf9fa3094e86fd7c38c4c8efad43c,34,8,5,6159,,,0,"Make lock_file_prefix optional

Currently, the lock_file_prefix says it should end with an hypen if
specified. It seems that it was intended to be optional. Since that
behavior makes sense, this patch changes the synchronized's signature
and makes lock_file_prefix optional.

With this patch, the prefix will not be required to end with an hypen
anymore, such sign will be added to the prefix if specified and if not
already present.

This patch doesn't change synchronized's behavior at all, which means it
doesn't break backward compatibility.

Change-Id: I8841da1e8d105aac4a86b247228a9c935e00afc5
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/99/32399/5 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/lockutils.py', 'tests/unit/test_lockutils.py']",2,449f1d995eb6bd65cbef2c7ae0edcaf9c8d2fd1e,bp/cache-backend-abstraction," def test_optional_prefix(self): lock_dir = tempfile.mkdtemp() @lockutils.synchronized('lock', 'test-', True, lock_dir) def test(): path = os.path.join(lock_dir, ""test-lock"") self.assertTrue(os.path.exists(path)) @lockutils.synchronized('lock', external=True, lock_path=lock_dir) def test_without_prefix(): path = os.path.join(lock_dir, ""lock"") self.assertTrue(os.path.exists(path)) @lockutils.synchronized('lock', 'hypen', True, lock_dir) def test_without_hypen(): path = os.path.join(lock_dir, ""hypen-lock"") self.assertTrue(os.path.exists(path)) test() test_without_hypen() test_without_prefix()",,34,4
openstack%2Fsahara-extra~master~I23d873adfc7c16e36cf26af2cd9156c2a8ec90fc,openstack/sahara-extra,master,I23d873adfc7c16e36cf26af2cd9156c2a8ec90fc,Replace elements/hadoop/ with Fedora&Ubuntu supporting elements/hadoop_fedora,MERGED,2013-07-16 12:37:18.000000000,2013-07-16 15:07:42.000000000,2013-07-16 15:07:42.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7555}, {'_account_id': 7732}]","[{'number': 1, 'created': '2013-07-16 12:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/fe64871a97f3b69582ff92595d77a71724ade071', 'message': 'Replace elements/hadoop/ with Fedora&Ubuntu supporting elements/hadoop_fedora\n\nNote: this requires a DIB version that includes change I7a42409a (SHA\n82eacdec) from 11 July 2013\n\nChange-Id: I23d873adfc7c16e36cf26af2cd9156c2a8ec90fc\n'}, {'number': 2, 'created': '2013-07-16 12:38:00.000000000', 'files': ['elements/hadoop/install.d/80-setup-hadoop', 'elements/hadoop/install.d/20-setup-java', 'elements/hadoop/install.d/30-setup-hadoop', 'elements/hadoop/README.md', 'elements/hadoop/install.d/90-setup-ssh', 'elements/hadoop_fedora/root.d/0-check', 'elements/README.rst', 'elements/hadoop_fedora/first-boot.d/99-setup', 'elements/hadoop/first-boot.d/99-setup', 'elements/hadoop/install.d/70-setup-java', 'elements/hadoop_fedora/README.md', 'elements/hadoop/root.d/0-check', 'elements/hadoop/install.d/40-setup-ssh'], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/40931bdb5f262359587f9991f8d0b95253b34b8e', 'message': 'Replace elements/hadoop/ with Fedora&Ubuntu supporting elements/hadoop_fedora\n\nNote: this requires a DIB version that includes change I7a42409a (SHA\n82eacdec) from 11 July 2013\n\nImplements: blueprint merge-dib-hadoop-elements\nChange-Id: I23d873adfc7c16e36cf26af2cd9156c2a8ec90fc\n'}]",2,37237,40931bdb5f262359587f9991f8d0b95253b34b8e,12,4,2,7555,,,0,"Replace elements/hadoop/ with Fedora&Ubuntu supporting elements/hadoop_fedora

Note: this requires a DIB version that includes change I7a42409a (SHA
82eacdec) from 11 July 2013

Implements: blueprint merge-dib-hadoop-elements
Change-Id: I23d873adfc7c16e36cf26af2cd9156c2a8ec90fc
",git fetch https://review.opendev.org/openstack/sahara-extra refs/changes/37/37237/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/hadoop/install.d/80-setup-hadoop', 'elements/hadoop/install.d/20-setup-java', 'elements/hadoop/install.d/30-setup-hadoop', 'elements/hadoop/README.md', 'elements/hadoop/install.d/90-setup-ssh', 'elements/hadoop_fedora/root.d/0-check', 'elements/README.rst', 'elements/hadoop_fedora/first-boot.d/99-setup', 'elements/hadoop/first-boot.d/99-setup', 'elements/hadoop/install.d/70-setup-java', 'elements/hadoop_fedora/README.md', 'elements/hadoop/root.d/0-check', 'elements/hadoop/install.d/40-setup-ssh']",13,fe64871a97f3b69582ff92595d77a71724ade071,bp/merge-dib-hadoop-elements,,,40,157
openstack%2Fsahara~master~I0defc257fd9ff83d678d857131ac7108bd13cf7c,openstack/sahara,master,I0defc257fd9ff83d678d857131ac7108bd13cf7c,REST API returns traceback fix,ABANDONED,2013-07-16 14:28:00.000000000,2013-07-16 15:01:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-07-16 14:28:00.000000000', 'files': ['savanna/middleware/auth_valid.py', 'savanna/openstack/commons.py', 'AUTHORS'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4ba208f212af1e007196b0b3edd4271954e650ea', 'message': 'REST API returns traceback fix\n\nFixes: bug #1200565\n\nChange-Id: I0defc257fd9ff83d678d857131ac7108bd13cf7c\n'}]",0,37255,4ba208f212af1e007196b0b3edd4271954e650ea,3,3,1,7700,,,0,"REST API returns traceback fix

Fixes: bug #1200565

Change-Id: I0defc257fd9ff83d678d857131ac7108bd13cf7c
",git fetch https://review.opendev.org/openstack/sahara refs/changes/55/37255/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/middleware/auth_valid.py', 'savanna/openstack/commons.py', 'AUTHORS']",3,4ba208f212af1e007196b0b3edd4271954e650ea,bug/1200565,Nikolay Mahotkin <nmakhotkin@mirantis.com>,,3,3
openstack%2Fdesignate~master~If217582dc9175d697f74d3591d686ec82df59be3,openstack/designate,master,If217582dc9175d697f74d3591d686ec82df59be3,Update docs links from moniker.rtfd.org to designate.rtfd.org,MERGED,2013-07-16 14:45:48.000000000,2013-07-16 14:59:52.000000000,2013-07-16 14:59:51.000000000,"[{'_account_id': 3}, {'_account_id': 6494}, {'_account_id': 8174}]","[{'number': 1, 'created': '2013-07-16 14:45:48.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/designate/commit/ffa5bd38b4bcee8ecab39dcbf50473c139aa6ece', 'message': 'Update docs links from moniker.rtfd.org to designate.rtfd.org\n\nChange-Id: If217582dc9175d697f74d3591d686ec82df59be3\n'}]",0,37259,ffa5bd38b4bcee8ecab39dcbf50473c139aa6ece,6,3,1,741,,,0,"Update docs links from moniker.rtfd.org to designate.rtfd.org

Change-Id: If217582dc9175d697f74d3591d686ec82df59be3
",git fetch https://review.opendev.org/openstack/designate refs/changes/59/37259/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,ffa5bd38b4bcee8ecab39dcbf50473c139aa6ece,,Docs: http://designate.readthedocs.org and some below for now.Installation: http://designate.readthedocs.org/en/latest/install.html,Docs: http://moniker.rtfd.org and some below for now.Installation: http://moniker.readthedocs.org/en/latest/install.html,2,2
openstack%2Fapi-site~master~I9e99fa333cee4af0d047afb63890dfa5f8539718,openstack/api-site,master,I9e99fa333cee4af0d047afb63890dfa5f8539718,Updates to WADLs and samples for the API Ref page for Identity v2.0,MERGED,2013-07-08 20:51:27.000000000,2013-07-16 14:57:57.000000000,2013-07-16 14:57:57.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 964}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-08 20:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/679ce843806823c638f77eb275993566468de7c1', 'message': 'Updates to WADLs and samples for the API Ref page for Identity v2.0\n\nbug: #1194997\n\nChange-Id: I9e99fa333cee4af0d047afb63890dfa5f8539718\nauthor: diane fleming\n'}, {'number': 2, 'created': '2013-07-09 00:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/eefd068986668c565ca5d1395f5b9e2eb21ad539', 'message': 'Updates to WADLs and samples for the API Ref page for Identity v2.0\n\nbug: #1194997\n\nChange-Id: I9e99fa333cee4af0d047afb63890dfa5f8539718\nauthor: diane fleming\n'}, {'number': 3, 'created': '2013-07-09 19:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/2b464c5a249c3a970cab3ac7ccfc51a8db71fa3b', 'message': 'Updates to WADLs and samples for the API Ref page for Identity v2.0\n\nbug: #1194997\n\nChange-Id: I9e99fa333cee4af0d047afb63890dfa5f8539718\nauthor: diane fleming\n'}, {'number': 4, 'created': '2013-07-11 16:20:34.000000000', 'files': ['api-ref/src/wadls/identity-api/src/common/samples/extensions.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupsListResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentials.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainsListResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/credentialswithapikey.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithoutid.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/credentials.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordDomainRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/credentialswithec2.json', 'api-ref/src/wadls/identity-api/src/common/samples/extensions.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/version.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/users.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-3.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RoleListUsersResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSVALIDATE/samples/validatetoken.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplateWithOnlyId.xml', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_darkblue.css', 'api-ref/src/wadls/identity-api/src/v2.0/js/shjs/sh_javascript.js', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/fault.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/tenant.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/roles.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/auth_credentials-OS-KSEC2.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/extensions.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/credentials.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESToken.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainListGroupRolesResponse.json', 'api-ref/src/wadls/identity-api/src/common/samples/validatetoken.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/EndpointCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/HP-IDM-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithoutid.json', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_acid.css', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenValidateRequest.txt', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESRole.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/users.xml', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/tenant.xsd', 'api-ref/src/wadls/identity-api/src/common/samples/tenants.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/samplerequestheader.txt', 'api-ref/src/wadls/identity-api/src/v2.0/samples/extension.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenantwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/service.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/getuser-1.xml', 'api-ref/src/wadls/identity-api/src/v3/admin/identity-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/choices.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplate.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-for-update.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/extension.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-1.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserListGroupsResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordNameRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/credentialswithapikey.xml', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/api.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplateWithOnlyId.json', 'api-ref/src/wadls/identity-api/src/v2.0/js/trc/schema/controller.js', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/PolicyCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CredentialUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CredentialsListResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/PolicyCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/user.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/role.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSVALIDATE/samples/validatetoken.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthScopeDomainResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/RAX-KSGRP-groups.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplateWithOnlyId.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/role.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RoleGetResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDListFilterRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/js/trc/util.js', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_with_token.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ServicesListResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/extensions.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/common.ent', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_pablo.css', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/tenant.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials-OS-KSEC2.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/endpoints.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/OS-KSCATALOG.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpoints.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/services.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-request-XML.txt', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/identity-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-request.txt', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSS3-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/services.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/updatedtenant.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSEC2-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/api.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSVALIDATE/samples/endpoints.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-1.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSQA/samples/RAX-KSQA-secretQA.json', 'api-ref/src/wadls/identity-api/src/v2.0/js/shjs/sh_java.js', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESUser.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/sampleresponseheader.txt', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/role.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthScopeProjectResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDDeleteRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/version.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDGetNestedResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplates.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-updated.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplates.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSS3/samples/credentialswiths3.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectListUserRolesResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-3.xml', 'api-ref/src/wadls/identity-api/src/service/identity.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/api-common.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RoleUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupListUsersResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenantwithoutid.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RoleCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSS3/samples/s3Credentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-KSGRP-groups.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CredentialCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/norequestbody.txt', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-KSKEY-admin.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthFail401aResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplate.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplates.json', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_print.css', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpoint.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-for-create.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/auth_credentials-RAX-KSKEY.xml', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_whitengrey.css', 'api-ref/src/wadls/identity-api/src/admin/identity-admin.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDGetResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ServiceCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/apiKeyCredentials.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/roles.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/user.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplate.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/RAX-KSGRP-groups.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/version.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectsListResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDListAllRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESCredential.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentialswithec2.json', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-KSQA-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/users.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserListRolesResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/PolicyUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/role.xml', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_night.css', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpoints.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/services.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESProject.json', 'www/index.html', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/tenantwithoutid.json', 'api-ref/src/wadls/identity-api/src/admin/version.json.tpl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDListAllResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/authwithgroups.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenantlock.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/roles.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/roles.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/tenantwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/extensions.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenantlock.xml', 'api-ref/src/docbkx/api-ref.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-KSKEY-credentials.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/common.ent', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpoints.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CredentialCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/groups.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/authwithgroups.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials-RAX-KSKEY.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/identity_fault.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/ext-getuser.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/ext-getuser.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDDeleteResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordIDScopeProjDomainNameRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-2.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/OS-KSADM.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-for-update.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentialswithapikey.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/passwordcredentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/services.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpoint.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplateWithOnlyId.json', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-GRPADM.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/fault.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/ec2Credentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/RAX-KSQA-secretQA.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/ec2Credentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/ec2Credentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/atom/xml.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainListUserRolesResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/passwordcredentials.json', 'api-ref/src/wadls/identity-api/src/common/samples/version.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithenabledonly.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/getuser-1.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSGRP/samples/RAX-KSGRP-group.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/versions.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials-RAX-KSKEY.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthFail401cResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ServiceGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-2.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESEndpoint.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/identity_fault.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/user.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESGroup.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithenabledonly.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectListUsersResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RolesListResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/js/trc/schema/layoutManager.js', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESPolicy.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDGetRequest.json', 'api-ref/src/wadls/identity-api/src/admin/OS-KSCATALOG-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSVALIDATE-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSCATALOG-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpoint.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordIDScopeProjNameRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/credentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/user.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/EndpointUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-updated.xml', 'api-ref/src/wadls/identity-api/src/v2.0/js/trc/schema/sampleManager.js', 'api-ref/src/wadls/identity-api/src/v3/common/samples/PoliciesListResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESDomain.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/service.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/credentialswithec2.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/choices.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/version.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/EndpointCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectListGroupRolesResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpoints.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/credentials.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/RAX-KSQA-secretQA.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/versions-atom.xml', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_emacs.css', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ServiceUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSVALIDATE/samples/endpoints.xml', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/atom/xml.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/token.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_style.css', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/passwordcredentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/service.json', 'api-ref/src/wadls/identity-api/src/service/version.xml.tpl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/apiKeyCredentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/OS-KSS3-credentials.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESService.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/service.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-KSGRP-admin.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/notusedTokenAuthGenericMethodRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-GRPADM.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordIDScopeProjIDRequest.json', 'api-ref/src/wadls/identity-api/src/admin/RAX-KSKEY-admin.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/PolicyGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentialswithapikey.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserListProjectsResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/auth_credentials-RAX-KSKEY.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/users.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RoleCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/token.xsd', 'api-ref/src/wadls/identity-api/src/service/extensions.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/OS-KSEC2-credentials.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/credentials.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/atom/atom.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/js/shjs/sh_main.js', 'api-ref/src/wadls/identity-api/src/v2.0/style/schema.css', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/endpoints.xsd', 'api-ref/src/wadls/identity-api/src/admin/extensions.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/noresponsebody.txt', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenant.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithenabledonly.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/apiKeyCredentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/versions.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSGRP/samples/RAX-KSGRP-group.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithenabledonly.json', 'api-ref/src/wadls/identity-api/src/admin/RAX-KSQA-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/roles.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplates.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/ec2Credentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/auth_credentials-OS-KSEC2.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/atom/atom.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/users.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/services.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/roles.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-KSQA-secretQA.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/version-atom.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthFail401bResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthTokenRequest.json', 'api-ref/src/wadls/identity-api/src/service/extensions.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/groups.json', 'api-ref/src/wadls/identity-api/src/v2.0/js/shjs/sh_xml.js', 'api-ref/src/wadls/identity-api/src/common/xsd/extensions.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthNoScopeResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenant.json', 'api-ref/src/wadls/identity-api/src/v2.0/xslt/schema.xslt', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/tenant.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/user.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials-OS-KSEC2.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-KSADM-users.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/extensions.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/credentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/passwordcredentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/services.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/notusedTokenAuthBasicRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSS3/samples/credentialswiths3.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ServiceCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/validatetoken.json', 'api-ref/src/wadls/identity-api/src/admin/OS-KSEC2-admin.wadl', 'api-ref/src/wadls/identity-api/src/admin/version.xml.tpl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/item_not_found.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/item_not_found.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CredentialGetResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UsersListResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordIDRequest.json', 'api-ref/src/wadls/identity-api/src/common/samples/version.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/validatetoken.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-for-create.json', 'api-ref/src/wadls/identity-api/src/service/version.json.tpl', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/users.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSQA/samples/RAX-KSQA-secretQA.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-request-JSON.txt', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpoint.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSS3/samples/s3Credentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentialswithec2.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDUpdateRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-KSADM-credentials.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSGRP/samples/RAX-KSGRP-groups.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/user.xml', 'api-ref/src/wadls/identity-api/src/admin/extensions.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplate.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/updatedtenant.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSGRP/samples/RAX-KSGRP-groups.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDListFilterResponse.json', 'api-ref/src/wadls/identity-api/src/admin/OS-KSADM-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_with_token.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/identity.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/apiKeyCredentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/api-common.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/EndpointsListResponse.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/4011a802537c5354f3a911e1143d59ca64674992', 'message': 'Updates to WADLs and samples for the API Ref page for Identity v2.0\n\nbug: #1194997\n\nChange-Id: I9e99fa333cee4af0d047afb63890dfa5f8539718\nauthor: diane fleming\n'}]",0,36127,4011a802537c5354f3a911e1143d59ca64674992,15,5,4,2448,,,0,"Updates to WADLs and samples for the API Ref page for Identity v2.0

bug: #1194997

Change-Id: I9e99fa333cee4af0d047afb63890dfa5f8539718
author: diane fleming
",git fetch https://review.opendev.org/openstack/api-site refs/changes/27/36127/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/identity-api/src/common/samples/extensions.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/version.json.tpl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupsListResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentials.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainsListResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/credentialswithapikey.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithoutid.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/credentials.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordDomainRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/credentialswithec2.json', 'api-ref/src/wadls/identity-api/src/common/samples/extensions.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/version.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/users.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-3.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RoleListUsersResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSVALIDATE/samples/validatetoken.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplateWithOnlyId.xml', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_darkblue.css', 'api-ref/src/wadls/identity-api/src/v2.0/js/shjs/sh_javascript.js', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/fault.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/tenant.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/roles.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/auth_credentials-OS-KSEC2.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/extensions.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/credentials.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESToken.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainListGroupRolesResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/EndpointCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/HP-IDM-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithoutid.json', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_acid.css', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenValidateRequest.txt', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESRole.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/users.xml', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/tenant.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/samplerequestheader.txt', 'api-ref/src/wadls/identity-api/src/v2.0/samples/extension.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenantwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/service.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/getuser-1.xml', 'api-ref/src/wadls/identity-api/src/v3/admin/identity-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/choices.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplate.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-for-update.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/extension.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-1.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserListGroupsResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordNameRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/credentialswithapikey.xml', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/api.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplateWithOnlyId.json', 'api-ref/src/wadls/identity-api/src/v2.0/js/trc/schema/controller.js', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/PolicyCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CredentialUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CredentialsListResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/PolicyCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/user.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/role.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSVALIDATE/samples/validatetoken.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthScopeDomainResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/RAX-KSGRP-groups.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplateWithOnlyId.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/role.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RoleGetResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDListFilterRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/js/trc/util.js', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_with_token.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ServicesListResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/extensions.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/common.ent', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_pablo.css', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/tenant.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials-OS-KSEC2.json', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/version.xml.tpl', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/endpoints.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/OS-KSCATALOG.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpoints.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/services.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-request-XML.txt', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/identity-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-request.txt', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSS3-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/services.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/updatedtenant.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSEC2-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/api.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSVALIDATE/samples/endpoints.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-1.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSQA/samples/RAX-KSQA-secretQA.json', 'api-ref/src/wadls/identity-api/src/v2.0/js/shjs/sh_java.js', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESUser.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/sampleresponseheader.txt', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/role.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthScopeProjectResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDDeleteRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/version.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDGetNestedResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplates.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-updated.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplates.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSS3/samples/credentialswiths3.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectListUserRolesResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-3.xml', 'api-ref/src/wadls/identity-api/src/service/identity.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/api-common.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RoleUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupListUsersResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenantwithoutid.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RoleCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSS3/samples/s3Credentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-KSGRP-groups.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CredentialCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/norequestbody.txt', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-KSKEY-admin.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthFail401aResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplate.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplates.json', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_print.css', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpoint.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-for-create.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/auth_credentials-RAX-KSKEY.xml', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_whitengrey.css', 'api-ref/src/wadls/identity-api/src/admin/identity-admin.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDGetResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ServiceCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/apiKeyCredentials.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/roles.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/user.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplate.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/RAX-KSGRP-groups.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/version.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectsListResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDListAllRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESCredential.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentialswithec2.json', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-KSQA-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/users.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserListRolesResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/PolicyUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/role.xml', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_night.css', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpoints.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/services.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESProject.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/tenantwithoutid.json', 'api-ref/src/wadls/identity-api/src/admin/version.json.tpl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDListAllResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/authwithgroups.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenantlock.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/roles.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/roles.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/tenantwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/extensions.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenantlock.xml', 'api-ref/src/docbkx/api-ref.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-KSKEY-credentials.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/common.ent', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpoints.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CredentialCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/groups.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/authwithgroups.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials-RAX-KSKEY.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/identity_fault.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/ext-getuser.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/ext-getuser.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDDeleteResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordIDScopeProjDomainNameRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-2.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/OS-KSADM.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-for-update.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentialswithapikey.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/passwordcredentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/services.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpoint.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpointTemplateWithOnlyId.json', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-GRPADM.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/fault.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/ec2Credentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/RAX-KSQA-secretQA.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/ec2Credentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/ec2Credentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/atom/xml.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainListUserRolesResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/passwordcredentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithenabledonly.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/getuser-1.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSGRP/samples/RAX-KSGRP-group.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/versions.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials-RAX-KSKEY.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthFail401cResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ServiceGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithoutid.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-2.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESEndpoint.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/identity_fault.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/user.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESGroup.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithenabledonly.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectListUsersResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RolesListResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/js/trc/schema/layoutManager.js', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESPolicy.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDGetRequest.json', 'api-ref/src/wadls/identity-api/src/admin/OS-KSCATALOG-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSVALIDATE-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSCATALOG-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/endpoint.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordIDScopeProjNameRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/credentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/user.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/EndpointUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-updated.xml', 'api-ref/src/wadls/identity-api/src/v2.0/js/trc/schema/sampleManager.js', 'api-ref/src/wadls/identity-api/src/v3/common/samples/PoliciesListResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESDomain.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/service.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/credentialswithec2.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/choices.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/version.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/EndpointCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/GroupCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectListGroupRolesResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpoints.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/credentials.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/RAX-KSQA-secretQA.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/versions-atom.xml', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_emacs.css', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ServiceUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSVALIDATE/samples/endpoints.xml', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/atom/xml.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/token.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/style/shjs/sh_style.css', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/passwordcredentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/service.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/apiKeyCredentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/OS-KSS3-credentials.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RESService.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/service.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-KSGRP-admin.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/notusedTokenAuthGenericMethodRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-GRPADM.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordIDScopeProjIDRequest.json', 'api-ref/src/wadls/identity-api/src/admin/RAX-KSKEY-admin.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/PolicyGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentialswithapikey.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserListProjectsResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/auth_credentials-RAX-KSKEY.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/users.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/RoleCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/token.xsd', 'api-ref/src/wadls/identity-api/src/service/extensions.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/OS-KSEC2-credentials.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/credentials.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/atom/atom.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/js/shjs/sh_main.js', 'api-ref/src/wadls/identity-api/src/v2.0/style/schema.css', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/endpoints.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/noresponsebody.txt', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenant.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/userwithenabledonly.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/apiKeyCredentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/versions.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSGRP/samples/RAX-KSGRP-group.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/userwithenabledonly.json', 'api-ref/src/wadls/identity-api/src/admin/RAX-KSQA-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/roles.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplates.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/ec2Credentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSEC2/samples/auth_credentials-OS-KSEC2.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/atom/atom.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/users.json', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/services.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/roles.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-KSQA-secretQA.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/samples/version-atom.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthFail401bResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthTokenRequest.json', 'api-ref/src/wadls/identity-api/src/service/extensions.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/groups.json', 'api-ref/src/wadls/identity-api/src/v2.0/js/shjs/sh_xml.js', 'api-ref/src/wadls/identity-api/src/common/xsd/extensions.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/DomainCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthNoScopeResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenant.json', 'api-ref/src/wadls/identity-api/src/v2.0/xslt/schema.xslt', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/tenant.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/user.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ProjectGetResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials-OS-KSEC2.xml', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-KSADM-users.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/xsd/extensions.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSKEY/samples/credentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/passwordcredentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/services.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-KSGRP.wadl', 'api-ref/src/wadls/identity-api/src/v3/common/samples/notusedTokenAuthBasicRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSS3/samples/credentialswiths3.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/ServiceCreateRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/validatetoken.json', 'api-ref/src/wadls/identity-api/src/admin/OS-KSEC2-admin.wadl', 'api-ref/src/wadls/identity-api/src/admin/version.xml.tpl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/item_not_found.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/item_not_found.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CredentialGetResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UsersListResponse.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/TokenAuthPasswordIDRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/samples/validatetoken.xml', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group-for-create.json', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/users.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_credentials.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDUpdateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSQA/samples/RAX-KSQA-secretQA.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/tenants-request-JSON.txt', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpoint.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSS3/samples/s3Credentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/credentialswithec2.xml', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDUpdateRequest.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/RAX-KSADM-credentials.xsd', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSGRP/samples/RAX-KSGRP-groups.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/user.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSCATALOG/samples/endpointTemplate.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/UserCreateResponse.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-GRPADM/samples/group.xml', 'api-ref/src/wadls/identity-api/src/v2.0/samples/updatedtenant.json', 'api-ref/src/wadls/identity-api/src/v2.0/RAX-KSGRP/samples/RAX-KSGRP-groups.json', 'api-ref/src/wadls/identity-api/src/v3/common/samples/CRUDListFilterResponse.json', 'api-ref/src/wadls/identity-api/src/admin/OS-KSADM-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/auth_with_token.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/identity.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/samples/apiKeyCredentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/xsd/api-common.xsd', 'api-ref/src/wadls/identity-api/src/v3/common/samples/EndpointsListResponse.json']",355,679ce843806823c638f77eb275993566468de7c1,1194997,"[ { ""id"": ""--endpoint-id--"", ""interface"": ""public"", ""links"": { ""self"": ""http://identity:35357/v3/endpoints/--endpoint-id--"" }, ""name"": ""the public volume endpoint"", ""service_id"": ""--service-id--"" }, { ""id"": ""--endpoint-id--"", ""interface"": ""internal"", ""links"": { ""self"": ""http://identity:35357/v3/endpoints/--endpoint-id--"" }, ""name"": ""the internal volume endpoint"", ""service_id"": ""--service-id--"" } ]",,9317,2730
openstack%2Freviewday~master~I4d43017be6a54bc3322d5aa754034a3d973d484d,openstack/reviewday,master,I4d43017be6a54bc3322d5aa754034a3d973d484d,Add a 0-score for unknown score keys,MERGED,2013-07-12 15:22:10.000000000,2013-07-16 14:52:15.000000000,2013-07-16 14:52:15.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 360}, {'_account_id': 5263}, {'_account_id': 6735}]","[{'number': 1, 'created': '2013-07-12 15:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/reviewday/commit/c3ede75a38144a12420f1c9e08f2aa524f48cc2f', 'message': 'Add a 0-score for unknown score keys\n\nWill print a warning message - so cron should email the owner of the job\nwhen an unknown score key is encountered.\n\nThe example is https://blueprints.launchpad.net/glance/+spec/db2-database has ""Not""\nas the priority\n\nChange-Id: I4d43017be6a54bc3322d5aa754034a3d973d484d\n'}, {'number': 2, 'created': '2013-07-12 15:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/reviewday/commit/ed65139a86fca220c554938e49dd8ed518aa39a5', 'message': 'Add a 0-score for unknown score keys\n\nWill print a warning message - so cron should email the owner of the job\nwhen an unknown score key is encountered.\n\nThe example is https://blueprints.launchpad.net/glance/+spec/db2-database has ""Not""\nas the priority\n\nChange-Id: I4d43017be6a54bc3322d5aa754034a3d973d484d\n'}, {'number': 3, 'created': '2013-07-12 16:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/reviewday/commit/ce46d542a36c3670cb8fcdc41932b422cff18b9e', 'message': 'Add a 0-score for unknown score keys\n\nWill print a warning message - so cron should email the owner of the job\nwhen an unknown score key is encountered.\n\nThe example is blueprint db2-database which has ""Not"" as the priority\n\nChange-Id: I4d43017be6a54bc3322d5aa754034a3d973d484d\n'}, {'number': 4, 'created': '2013-07-16 14:52:15.000000000', 'files': ['reviewday/mergeprop.py'], 'web_link': 'https://opendev.org/openstack/reviewday/commit/e95925a075b77d7cb33e477154eab1c8f4e250ee', 'message': 'Add a 0-score for unknown score keys\n\nWill print a warning message - so cron should email the owner of the job\nwhen an unknown score key is encountered.\n\nThe example is blueprint db2-database which has ""Not"" as the priority\n\nChange-Id: I4d43017be6a54bc3322d5aa754034a3d973d484d\nReviewed-on: https://review.openstack.org/36846\nReviewed-by: Jeremy Stanley <fungi@yuggoth.org>\nApproved: Dan Prince <dprince@redhat.com>\nReviewed-by: Dan Prince <dprince@redhat.com>\nTested-by: Jenkins\n'}]",0,36846,e95925a075b77d7cb33e477154eab1c8f4e250ee,13,5,4,6735,,,0,"Add a 0-score for unknown score keys

Will print a warning message - so cron should email the owner of the job
when an unknown score key is encountered.

The example is blueprint db2-database which has ""Not"" as the priority

Change-Id: I4d43017be6a54bc3322d5aa754034a3d973d484d
Reviewed-on: https://review.openstack.org/36846
Reviewed-by: Jeremy Stanley <fungi@yuggoth.org>
Approved: Dan Prince <dprince@redhat.com>
Reviewed-by: Dan Prince <dprince@redhat.com>
Tested-by: Jenkins
",git fetch https://review.opendev.org/openstack/reviewday refs/changes/46/36846/1 && git format-patch -1 --stdout FETCH_HEAD,['reviewday/mergeprop.py'],1,c3ede75a38144a12420f1c9e08f2aa524f48cc2f,bp/db2-database," if cause not in cause_score: print 'WARNING: unable to find score for (%s, %s)' % (topic, cause) return (""Unknown cause: ""+cause, 0)",,3,0
openstack%2Fopenstack-manuals~master~I9912c6e544c49f10f1214eee9c4735d79a2a34f6,openstack/openstack-manuals,master,I9912c6e544c49f10f1214eee9c4735d79a2a34f6,Fix capitalization of VMBuilder and improve wording,MERGED,2013-07-16 11:49:54.000000000,2013-07-16 14:41:40.000000000,2013-07-16 14:41:39.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-07-16 11:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7404f406ac0a87d37f93831c4de8a18cf33674ac', 'message': ""Fix capitalization of VMBuilder\n\nThe proper capitalization is VMBuilder, let's use that.\nReference: https://launchpad.net/vmbuilder\n\nChange-Id: I9912c6e544c49f10f1214eee9c4735d79a2a34f6\n""}, {'number': 2, 'created': '2013-07-16 14:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e4e018d65fd05e9f2c2da773b4c404998459047e', 'message': ""Fix capitalization of VMBuilder and improve wording\n\nThe proper capitalization is VMBuilder, let's use that.\nReference: https://launchpad.net/vmbuilder\n\nI've updated this with suggestions by Diane Fleming (thanks!)\nto improve the overall section.\n\nChange-Id: I9912c6e544c49f10f1214eee9c4735d79a2a34f6\n""}, {'number': 3, 'created': '2013-07-16 14:20:43.000000000', 'files': ['doc/src/docbkx/openstack-image/ch_creating_images_automatically.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ce325243a9329ece6a74bcb1914f2de3f895897e', 'message': ""Fix capitalization of VMBuilder and improve wording\n\nThe proper capitalization is VMBuilder, let's use that.\nReference: https://launchpad.net/vmbuilder\n\nI've updated this with suggestions by Diane Fleming (thanks!)\nto improve the overall section (now really part of this set).\n\nChange-Id: I9912c6e544c49f10f1214eee9c4735d79a2a34f6\n""}]",2,37230,ce325243a9329ece6a74bcb1914f2de3f895897e,11,4,3,6547,,,0,"Fix capitalization of VMBuilder and improve wording

The proper capitalization is VMBuilder, let's use that.
Reference: https://launchpad.net/vmbuilder

I've updated this with suggestions by Diane Fleming (thanks!)
to improve the overall section (now really part of this set).

Change-Id: I9912c6e544c49f10f1214eee9c4735d79a2a34f6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/30/37230/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-image/ch_creating_images_automatically.xml'],1,7404f406ac0a87d37f93831c4de8a18cf33674ac,master," <title>VMBuilder</title> <para><link xlink:href=""https://launchpad.net/vmbuilder"">VMBuilder</link> (Virtual Machine for different hypervisors. The version of VMBuilder that ships with Ubuntu can only create Ubuntu virtual machine guests. The version of VMBuilder that ships with Debian >Ubuntu 12.04 server guide</link> has documentation on how to use VMBuilder to"," <title>vmbuilder</title> <para><link xlink:href=""https://launchpad.net/vmbuilder"">vmbuilder</link> (Virtual Machine for different hypervisors. The version of vmbuilder that ships with Ubuntu can only create Ubuntu virtual machine guests. The version of vmbuilder that ships with Debian >Ubuntu 12.04 server guide</link> has documentation on how to use vmbuilder to",5,5
openstack%2Fceilometer~master~Ia2ff201c0cfa882aa00bb7ce8ce990525f18339e,openstack/ceilometer,master,Ia2ff201c0cfa882aa00bb7ce8ce990525f18339e,"Disable mongod prealloc, wait for it to start",MERGED,2013-07-15 17:54:57.000000000,2013-07-16 14:18:18.000000000,2013-07-16 14:18:18.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 7336}]","[{'number': 1, 'created': '2013-07-15 17:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ba4acb7a72d2b607f3034cc27c8e0796a81beeae', 'message': 'Disable mongod prealloc\n\nThat should make mongod starts faster.\n\nChange-Id: Ia2ff201c0cfa882aa00bb7ce8ce990525f18339e\n'}, {'number': 2, 'created': '2013-07-16 08:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f8ca92ddcaea6876a75976abae32d5135bb89f60', 'message': 'Disable mongod prealloc, wait for it to starts\n\nNo prealloc should make mongod starts faster, and the while loop will\nwait it is listening before running the tests.\n\nChange-Id: Ia2ff201c0cfa882aa00bb7ce8ce990525f18339e\n'}, {'number': 3, 'created': '2013-07-16 13:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/81000ee301d89e8a3f0b9a2ee638cbe1b3723ea2', 'message': 'Disable mongod prealloc, wait for it to starts\n\nNo prealloc should make mongod starts faster, and the while loop will\nwait it is listening before running the tests.\n\nChange-Id: Ia2ff201c0cfa882aa00bb7ce8ce990525f18339e\n'}, {'number': 4, 'created': '2013-07-16 13:15:56.000000000', 'files': ['run-tests.sh'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d2578433b17ffc4fdd82fded0837f59e83f7ae0e', 'message': 'Disable mongod prealloc, wait for it to start\n\nNo prealloc should make mongod starts faster, and the while loop will\nwait it is listening before running the tests.\n\nChange-Id: Ia2ff201c0cfa882aa00bb7ce8ce990525f18339e\n'}]",5,37105,d2578433b17ffc4fdd82fded0837f59e83f7ae0e,17,6,4,1669,,,0,"Disable mongod prealloc, wait for it to start

No prealloc should make mongod starts faster, and the while loop will
wait it is listening before running the tests.

Change-Id: Ia2ff201c0cfa882aa00bb7ce8ce990525f18339e
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/05/37105/1 && git format-patch -1 --stdout FETCH_HEAD,['run-tests.sh'],1,ba4acb7a72d2b607f3034cc27c8e0796a81beeae,jd/run-tests-wait-for-mongo,"mongod --maxConns 32 --smallfiles --noprealloc --quiet --noauth --port 29000 --dbpath ""${MONGO_DATA}"" --bind_ip localhost &","mongod --maxConns 32 --smallfiles --quiet --noauth --port 29000 --dbpath ""${MONGO_DATA}"" --bind_ip localhost &",1,1
openstack%2Fmurano-dashboard~master~I9d2acbbd9456525a42a7c7fb39876eb344b74758,openstack/murano-dashboard,master,I9d2acbbd9456525a42a7c7fb39876eb344b74758,Add fix due to new deployment return value,MERGED,2013-07-16 14:06:02.000000000,2013-07-16 14:15:36.000000000,2013-07-16 14:15:36.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-07-16 14:06:02.000000000', 'files': ['muranodashboard/panel/api.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ed8aaa3c7cdbe43a9d2064f53d5e18660a1fa134', 'message': 'Add fix due to new deployment return value\n\nChange-Id: I9d2acbbd9456525a42a7c7fb39876eb344b74758\n'}]",0,37252,ed8aaa3c7cdbe43a9d2064f53d5e18660a1fa134,5,2,1,7549,,,0,"Add fix due to new deployment return value

Change-Id: I9d2acbbd9456525a42a7c7fb39876eb344b74758
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/52/37252/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/api.py'],1,ed8aaa3c7cdbe43a9d2064f53d5e18660a1fa134,, list(environment_id) return result, list(environment_id).deployments return reports,2,2
openstack%2Fsahara~master~I120c29bc018a229ec89a2b7ddbc553d2848699cb,openstack/sahara,master,I120c29bc018a229ec89a2b7ddbc553d2848699cb,Initial implementation of HDP plugin.,MERGED,2013-06-18 15:08:10.000000000,2013-07-16 14:14:37.000000000,2013-07-16 14:14:36.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7478}, {'_account_id': 7737}]","[{'number': 1, 'created': '2013-06-18 15:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ba900ea064769a847153058059697d6dafba2179', 'message': 'initial upload of hdp plugin source. still working on resolving runtime issues...\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 2, 'created': '2013-06-18 20:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7ef1b6d8ee01da2cb8d5cc7c4376f56898706bf1', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 3, 'created': '2013-06-19 20:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/cfe919dcd6b46875c999397efbe79b3e0e36dbba', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 4, 'created': '2013-06-19 23:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0486e3da9585555e0ff4a12761b97d070e106bfd', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 5, 'created': '2013-06-20 13:40:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2c961d3774911df0a1e9f25fd87ffede468b5084', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 6, 'created': '2013-06-20 19:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/675be30c4eac2b8b6b2002ebc9d6537529e29f4c', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 7, 'created': '2013-06-20 19:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/30e7e7f2158a91ce8e1d7d87b426667957e09b04', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 8, 'created': '2013-06-20 20:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5ed2dbd09599196246acba627ee9ba6348e172c6', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 9, 'created': '2013-06-23 20:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/54aea5eabf262b216611d66669fe4247ce8b5588', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 10, 'created': '2013-06-23 21:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8eb53ba00ea3fe44bd567d4d67c95ee58753faf7', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nCo-Authored-By: John Speidel <jspeidel@hortonworks.com>\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 11, 'created': '2013-06-25 14:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/29d0f0f79e570485abc5721016001466c48f1aa5', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nCo-Authored-By: John Speidel <jspeidel@hortonworks.com>\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 12, 'created': '2013-06-25 15:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c072935c3f018530de475268b6244b9cc899fa54', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nCo-Authored-By: John Speidel <jspeidel@hortonworks.com>\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 13, 'created': '2013-07-12 21:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b4262717d45717cbe89049a03e1163791ad009e2', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nCo-Authored-By: John Speidel <jspeidel@hortonworks.com>\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 14, 'created': '2013-07-12 22:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d8e455a88544b403f56026c1ccbf3c64ec0b6c2e', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nCo-Authored-By: John Speidel <jspeidel@hortonworks.com>\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}, {'number': 15, 'created': '2013-07-13 15:39:17.000000000', 'files': ['savanna/plugins/hdp/resources/ambari-bp-skeleton.json', 'savanna/plugins/hdp/resources/ambari-config-resource.json', 'savanna/plugins/hdp/blueprintprocessor.py', 'savanna/tests/unit/plugins/hdp/clusterspec_test.py', 'savanna/tests/unit/plugins/hdp/ambariplugin_test.py', 'savanna/plugins/hdp/resources/default-cluster.template', 'AUTHORS', 'savanna/tests/unit/plugins/hdp/resources/config-resource.json', 'savanna/plugins/hdp/configprovider.py', 'savanna/plugins/hdp/clustercontext.py', 'savanna/plugins/hdp/baseprocessor.py', 'savanna/plugins/hdp/ambariplugin.py', 'savanna/tests/unit/plugins/hdp/resources/sample-ambari-blueprint.json', 'savanna/plugins/hdp/clusterspec.py', 'savanna/plugins/hdp/hadoopserver.py', 'savanna/plugins/hdp/__init__.py', 'savanna/plugins/hdp/savannautils.py', 'savanna/tests/unit/plugins/hdp/__init__.py', 'savanna/tests/unit/plugins/hdp/blueprintprocessor_test.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4a3cab23b65313499ea2bd07090451b6df6589e6', 'message': 'Initial implementation of HDP plugin.\n\nImplements blueprint apache-ambari-service-provider\n\nCo-Authored-By: John Speidel <jspeidel@hortonworks.com>\n\nChange-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb\n'}]",93,33455,4a3cab23b65313499ea2bd07090451b6df6589e6,68,7,15,7737,,,0,"Initial implementation of HDP plugin.

Implements blueprint apache-ambari-service-provider

Co-Authored-By: John Speidel <jspeidel@hortonworks.com>

Change-Id: I120c29bc018a229ec89a2b7ddbc553d2848699cb
",git fetch https://review.opendev.org/openstack/sahara refs/changes/55/33455/9 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/plugins/hdp/resources/ambari-bp-skeleton.json', 'savanna/plugins/hdp/resources/ambari-config-resource.json', 'savanna/plugins/hdp/blueprintprocessor.py', 'savanna/plugins/hdp/cloudplugin.py', 'savanna/plugins/hdp/resources/default-cluster.template', 'savanna/plugins/hdp/configprovider.py', 'savanna/plugins/hdp/clustercontext.py', 'savanna/plugins/hdp/baseprocessor.py', 'savanna/plugins/hdp/ambariplugin.py', 'savanna/plugins/hdp/clusterspec.py', 'savanna/plugins/hdp/hadoopserver.py', 'savanna/plugins/hdp/__init__.py']",12,ba900ea064769a847153058059697d6dafba2179,bp/apache-ambari-service-provider,,,3789,0
openstack%2Fnova~master~Idc847e1b3c9fb422043d3a919452d842c2c4c30b,openstack/nova,master,Idc847e1b3c9fb422043d3a919452d842c2c4c30b,Port deferredDelete API to v3 Part 2,MERGED,2013-06-26 13:32:17.000000000,2013-07-16 14:13:48.000000000,2013-07-16 14:13:46.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 5586}, {'_account_id': 5754}]","[{'number': 1, 'created': '2013-06-26 13:32:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93a1312b820eaedbd0f882e0be1b7d30325a37d2', 'message': 'Port deferredDelete API to v3 Part 2\n\nPorts the deferredDelete extensions and the corresponding unittests\nto the v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Idc847e1b3c9fb422043d3a919452d842c2c4c30b\n'}, {'number': 2, 'created': '2013-07-07 11:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39c7b4c1b92d027b327c7d6f6a9511397502b134', 'message': 'Port deferredDelete API to v3 Part 2\n\nPorts the deferredDelete extensions and the corresponding unittests\nto the v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Idc847e1b3c9fb422043d3a919452d842c2c4c30b\n'}, {'number': 3, 'created': '2013-07-08 05:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e13c542ff44bab91f7d68e8af294e5f016e0c09b', 'message': 'Port deferredDelete API to v3 Part 2\n\nPorts the deferredDelete extensions and the corresponding unittests\nto the v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Idc847e1b3c9fb422043d3a919452d842c2c4c30b\n'}, {'number': 4, 'created': '2013-07-15 01:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06ed88d488d974fe60c9416a7ce57f947ba38d5e', 'message': 'Port deferredDelete API to v3 Part 2\n\nPorts the deferredDelete extensions and the corresponding unittests\nto the v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Idc847e1b3c9fb422043d3a919452d842c2c4c30b\n'}, {'number': 5, 'created': '2013-07-15 05:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c52c36898a5bf88df9a1fea2c11a5e2360b23c59', 'message': 'Port deferredDelete API to v3 Part 2\n\nPorts the deferredDelete extensions and the corresponding unittests\nto the v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Idc847e1b3c9fb422043d3a919452d842c2c4c30b\n'}, {'number': 6, 'created': '2013-07-15 06:32:18.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_deferred_delete.py', 'etc/nova/policy.json', 'nova/api/openstack/compute/plugins/v3/deferred_delete.py', 'nova/tests/fake_policy.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/nova/commit/90b1bf5bd5c96c36ae19d963c80853cce88ca550', 'message': 'Port deferredDelete API to v3 Part 2\n\nPorts the deferredDelete extensions and the corresponding unittests\nto the v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Idc847e1b3c9fb422043d3a919452d842c2c4c30b\n'}]",11,34548,90b1bf5bd5c96c36ae19d963c80853cce88ca550,34,8,6,5586,,,0,"Port deferredDelete API to v3 Part 2

Ports the deferredDelete extensions and the corresponding unittests
to the v3 framework.

Partially implements blueprint nova-v3-api

Change-Id: Idc847e1b3c9fb422043d3a919452d842c2c4c30b
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/34548/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_deferred_delete.py', 'etc/nova/policy.json', 'nova/api/openstack/compute/plugins/v3/deferred_delete.py', 'nova/tests/fake_policy.py', 'setup.cfg']",5,93a1312b820eaedbd0f882e0be1b7d30325a37d2,bp/nova-v3-api, deferred_delete = nova.api.openstack.compute.plugins.v3.deferred_delete:DeferredDelete,,13,6
openstack%2Fnova~master~I0f3d4da962323a318448634e762f7c31490f9298,openstack/nova,master,I0f3d4da962323a318448634e762f7c31490f9298,Port AttachInterfaces API to v3 Part 2,MERGED,2013-06-21 09:25:47.000000000,2013-07-16 14:13:26.000000000,2013-07-16 14:13:23.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5292}, {'_account_id': 5586}, {'_account_id': 5754}]","[{'number': 1, 'created': '2013-06-21 09:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a87ae677d5408aec848278ca3f999b8e9b2ead50', 'message': 'Port AttachInterfaces API to v3 Part 2\n\nThis patch contains the changes required to adapt the AttachInterfaces\nextension and the corresponding unittest to the v3 framework\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: I0f3d4da962323a318448634e762f7c31490f9298\n'}, {'number': 2, 'created': '2013-06-26 02:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2ee26edc0e8b83054bdaec45b5bba3906bedba5', 'message': 'Port AttachInterfaces API to v3 Part 2\n\nThis patch contains the changes required to adapt the AttachInterfaces\nextension and the corresponding unittest to the v3 framework\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: I0f3d4da962323a318448634e762f7c31490f9298\n'}, {'number': 3, 'created': '2013-06-26 07:17:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a4aadaff1370303c271c7790179a3ffda8f5dc0', 'message': 'Port AttachInterfaces API to v3 Part 2\n\nThis patch contains the changes required to adapt the AttachInterfaces\nextension and the corresponding unittest to the v3 framework\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: I0f3d4da962323a318448634e762f7c31490f9298\n'}, {'number': 4, 'created': '2013-07-07 11:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff40add86b7f48bb2397f177b5c9cd18f149a078', 'message': 'Port AttachInterfaces API to v3 Part 2\n\nThis patch contains the changes required to adapt the AttachInterfaces\nextension and the corresponding unittest to the v3 framework\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: I0f3d4da962323a318448634e762f7c31490f9298\n'}, {'number': 5, 'created': '2013-07-15 08:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/000379361a9e9dc5da6dbcf5fea0dcab3a7247fb', 'message': 'Port AttachInterfaces API to v3 Part 2\n\nThis patch contains the changes required to adapt the AttachInterfaces\nextension and the corresponding unittest to the v3 framework\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: I0f3d4da962323a318448634e762f7c31490f9298\n'}, {'number': 6, 'created': '2013-07-15 08:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6d5a6d6fa265f570b508776af7cbf2f2742ed03', 'message': 'Port AttachInterfaces API to v3 Part 2\n\nThis patch contains the changes required to adapt the AttachInterfaces\nextension and the corresponding unittest to the v3 framework\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: I0f3d4da962323a318448634e762f7c31490f9298\n'}, {'number': 7, 'created': '2013-07-15 13:14:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12f19feee181835b57fe0003e1bad49c9346118e', 'message': 'Port AttachInterfaces API to v3 Part 2\n\nThis patch contains the changes required to adapt the AttachInterfaces\nextension and the corresponding unittest to the v3 framework\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: I0f3d4da962323a318448634e762f7c31490f9298\n'}, {'number': 8, 'created': '2013-07-15 14:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f7f009fa0e4e0f1de465d42adfbcbe7e6535dcf', 'message': 'Port AttachInterfaces API to v3 Part 2\n\nThis patch contains the changes required to adapt the AttachInterfaces\nextension and the corresponding unittest to the v3 framework\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: I0f3d4da962323a318448634e762f7c31490f9298\n'}, {'number': 9, 'created': '2013-07-16 03:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4946b4cf672d0c3687ffdebb25ce5eacf5c27255', 'message': 'Port AttachInterfaces API to v3 Part 2\n\nThis patch contains the changes required to adapt the AttachInterfaces\nextension and the corresponding unittest to the v3 framework\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: I0f3d4da962323a318448634e762f7c31490f9298\n'}, {'number': 10, 'created': '2013-07-16 11:58:30.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_attach_interfaces.py', 'etc/nova/policy.json', 'nova/tests/fake_policy.py', 'setup.cfg', 'nova/api/openstack/compute/plugins/v3/attach_interfaces.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/76f6c8402cd69229f8715289453ec8dab34d3b94', 'message': 'Port AttachInterfaces API to v3 Part 2\n\nThis patch contains the changes required to adapt the AttachInterfaces\nextension and the corresponding unittest to the v3 framework\n\nPartially implements: bp v3-api-extension-versioning\n\nChange-Id: I0f3d4da962323a318448634e762f7c31490f9298\n'}]",20,33938,76f6c8402cd69229f8715289453ec8dab34d3b94,49,8,10,5586,,,0,"Port AttachInterfaces API to v3 Part 2

This patch contains the changes required to adapt the AttachInterfaces
extension and the corresponding unittest to the v3 framework

Partially implements: bp v3-api-extension-versioning

Change-Id: I0f3d4da962323a318448634e762f7c31490f9298
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/33938/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_attach_interfaces.py', 'etc/nova/policy.json', 'nova/tests/fake_policy.py', 'setup.cfg', 'nova/api/openstack/compute/plugins/v3/attach_interfaces.py']",5,a87ae677d5408aec848278ca3f999b8e9b2ead50,bp/v3-api-extension-versioning,"ALIAS = 'os-attach-interfaces' authorize = extensions.extension_authorizer('compute', 'v3:' + 'ALIAS')class Attach_interfaces(extensions.V3APIExtensionBase): alias = ALIAS namespace = ""http://docs.openstack.org/compute/ext/interfaces/api/v3"" version = 1 res = [extensions.ResourceExtension('os-attach-interfaces', InterfaceAttachmentController(), parent=dict( collection_name='servers'))] return res def get_controller_extensions(self): """"""It's an abstract function V3APIExtensionBase and the extension will not be loaded without it."""""" return []","authorize = extensions.extension_authorizer('compute', 'attach_interfaces')class Attach_interfaces(extensions.ExtensionDescriptor): alias = ""os-attach-interfaces"" namespace = ""http://docs.openstack.org/compute/ext/interfaces/api/v1.1"" updated = ""2012-07-22T00:00:00+00:00"" resources = [] res = extensions.ResourceExtension('os-interface', InterfaceAttachmentController(), parent=dict( collection_name='servers')) resources.append(res) return resources",28,25
openstack%2Fopenstack-manuals~master~I198a02347d6171127665d8358fa2d2cbbeb89773,openstack/openstack-manuals,master,I198a02347d6171127665d8358fa2d2cbbeb89773,Add section about SUSE Studio as imaging tool,MERGED,2013-07-16 13:04:00.000000000,2013-07-16 14:06:34.000000000,2013-07-16 14:06:33.000000000,"[{'_account_id': 3}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-07-16 13:04:00.000000000', 'files': ['doc/src/docbkx/openstack-image/ch_creating_images_automatically.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/012d4b9ccaec2108a097512e3edd8f2cd9d6b5ee', 'message': 'Add section about SUSE Studio as imaging tool\n\nChange-Id: I198a02347d6171127665d8358fa2d2cbbeb89773\n'}]",0,37240,012d4b9ccaec2108a097512e3edd8f2cd9d6b5ee,5,2,1,6547,,,0,"Add section about SUSE Studio as imaging tool

Change-Id: I198a02347d6171127665d8358fa2d2cbbeb89773
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/40/37240/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-image/ch_creating_images_automatically.xml'],1,012d4b9ccaec2108a097512e3edd8f2cd9d6b5ee,studio-branch," <section xml:id=""susestudio""> <title>SUSE Studio</title> <para><link xlink:href=""http://susestudio.com"">SUSE Studio</link> is a web application for building and testing software applications in a web browser. It supports the creation of physical, virtual or cloud-based applications and includes support for building images for OpenStack based clouds using SUSE Linux Enterprise and openSUSE as distributions. </para> </section>",,10,0
openstack%2Fceilometer~master~I869ce6f50065d0ae8d7095a260efbfcd33165eef,openstack/ceilometer,master,I869ce6f50065d0ae8d7095a260efbfcd33165eef,Allow to enable time to live on metering sample,MERGED,2013-05-27 16:59:33.000000000,2013-07-16 14:06:31.000000000,2013-07-16 14:06:31.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 4715}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-05-27 16:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5da87609b7364655868f85a491667447e9cb64ad', 'message': 'WIP Initial implementation of db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n'}, {'number': 2, 'created': '2013-05-27 17:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/be4100b99cbe45ab8d5d87d954b4c2fe5a8d9649', 'message': 'WIP Initial implementation of db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n'}, {'number': 3, 'created': '2013-05-28 10:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/465763f49baebfd2ffa37eaab87430c7a04d005c', 'message': 'WIP Initial implementation of db-ttl\n\nWIP, but remarks are welcome\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n'}, {'number': 4, 'created': '2013-05-28 10:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ae239974cf85ba976f0a4f4d109f14a34f7cba1c', 'message': 'WIP Initial implementation of db-ttl\n\nWIP, but remarks are welcome\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n'}, {'number': 5, 'created': '2013-05-29 12:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e94ac6cf29555ac8ed4627534419b5d3571cdec9', 'message': 'WIP Initial implementation of db-ttl\n\nWIP, but remarks are welcome\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n'}, {'number': 6, 'created': '2013-05-30 09:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7487b3f9d2beea04c66659edbe0431ddf574fe79', 'message': ""Allow to enable time to live on metering sample\n\nblueprint db-ttl\n\nAllow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfonction in the backend is just a dump, and the backend handle the ttl itself.\n\nIf the backend doesn't support ttl at all, it raise a\nNotImplementedException catched by collector to fill the log correctly.\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 7, 'created': '2013-05-30 10:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/47baa026b86683a73af407ca403d09ed40a14321', 'message': ""Allow to enable time to live on metering sample\n\nblueprint db-ttl\n\nAllow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfonction in the backend is just a dump, and the backend handle the ttl itself.\n\nIf the backend doesn't support ttl at all, it raise a\nNotImplementedException catched by collector to fill the log correctly.\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 8, 'created': '2013-06-03 13:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/685c622ae4a497710cdf1fa1d0250e72e3991464', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedExcept2ion caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 9, 'created': '2013-06-03 15:03:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2afa4166d148e92c6ca95747f956f0eefe3888af', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedExcept2ion caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 10, 'created': '2013-06-13 11:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/765bdc0c71c0b12e8473b5adae77c3c12764cfe3', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedExcept2ion caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 11, 'created': '2013-06-13 11:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a873e2d2004a6ba07067eadf529c8251914300b2', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedExcept2ion caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 12, 'created': '2013-06-13 11:58:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/28e6ef8ecfb44947a02f629a9aa0500d78513f2c', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedExcept2ion caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 13, 'created': '2013-06-20 14:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f9c39a0b3c4ef524080ca2bd55d123d127d06f61', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedExcept2ion caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 14, 'created': '2013-06-28 16:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/78f0fb648898109c41711557ad61c979533b9595', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedException caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 15, 'created': '2013-07-09 16:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8e813eb4437b77e4f102af9b483364225c7ce9dd', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedException caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 16, 'created': '2013-07-09 16:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/12ce26efa8354dad3daee2233f279072156f22da', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2 or hbase), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedException caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 17, 'created': '2013-07-09 16:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/863cc2d14ee3bcbbeed58e7d746445fd1a1d2dec', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedException caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 18, 'created': '2013-07-12 06:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4e012f2206ee54e1beaa5f395cb2c30dc9827902', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedException caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 19, 'created': '2013-07-15 15:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/88ae1c74dc6c63dff0377f40638d2efe1042f04c', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedException caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 20, 'created': '2013-07-15 22:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8ee203de954b0bc9be8f2c7205d4521ebac8dd85', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedException caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 21, 'created': '2013-07-16 08:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/00aa000e4b8bce6cb402361d320158b30218a7e9', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedException caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}, {'number': 22, 'created': '2013-07-16 12:53:37.000000000', 'files': ['tests/storage/base.py', 'ceilometer/storage/base.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/impl_log.py', 'ceilometer/storage/__init__.py', 'tests/test_bin.py', 'ceilometer/storage/impl_sqlalchemy.py', 'tests/storage/test_impl_mongodb.py', 'setup.cfg', 'etc/ceilometer/ceilometer.conf.sample'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2c2a07a68854346d06cb3d06e3b6215249c14647', 'message': ""Allow to enable time to live on metering sample\n\nThe collector start the metering sample cleanup\nprocess every 'database_clear_expired_data_interval' seconds to\nremove sample according the 'database_time_to_live'\n\nIf the backend support ttl natively (mongodb >= 2.2), the cleanup\nfunction in the backend is just a dump, and the backend handles the TTL\nitself.\n\nIf the backend doesn't support ttl at all, it will raise a\nNotImplementedException caught by collector to fill the log correctly.\n\nBlueprint: db-ttl\n\nChange-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef\n""}]",81,30635,2c2a07a68854346d06cb3d06e3b6215249c14647,86,8,22,2813,,,0,"Allow to enable time to live on metering sample

The collector start the metering sample cleanup
process every 'database_clear_expired_data_interval' seconds to
remove sample according the 'database_time_to_live'

If the backend support ttl natively (mongodb >= 2.2), the cleanup
function in the backend is just a dump, and the backend handles the TTL
itself.

If the backend doesn't support ttl at all, it will raise a
NotImplementedException caught by collector to fill the log correctly.

Blueprint: db-ttl

Change-Id: I869ce6f50065d0ae8d7095a260efbfcd33165eef
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/35/30635/22 && git format-patch -1 --stdout FETCH_HEAD,"['tests/collector/test_manager.py', 'tests/storage/base.py', 'ceilometer/storage/base.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/impl_log.py', 'tests/storage/test_impl_hbase.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/collector/service.py']",9,5da87609b7364655868f85a491667447e9cb64ad,bp/db-ttl," cfg.IntOpt('database_time_to_live', default=0, help='number of seconds that the sample are kept \ in the database (0 means unlimited)'), cfg.IntOpt('database_clear_expired_data_interval', default=1, help='number of ticks of \""periodic_interval\"" to wait before \ clear expired data (0 means never) (if the database backend support ttl \ natively this is not used'), self.clear_expired_data_ticks = 0 if not hasattr(self, 'storage_conn'): #note(sileht): not really sexy but rpc service not yet started return if cfg.CONF.database_time_to_live != 0 and \ cfg.CONF.database_clear_expired_data_interval != 0: if cfg.CONF.database_clear_expired_data_interval == \ self.clear_expired_data_ticks: self.clear_expired_data_ticks = 0 try: self.storage_conn.clear_expired_metering_data() except NotImplementedError: LOG.exception(""database_time_to_live != 0 but database "" + ""backend doesn't support it"") self.clear_expired_data_ticks += 1", pass,150,3
