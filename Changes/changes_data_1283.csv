id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fsahara~master~I72f222d7a072cb1ddc75a9ff78d80a029173a9c0,openstack/sahara,master,I72f222d7a072cb1ddc75a9ff78d80a029173a9c0,Imported Translations from Transifex,MERGED,2014-07-18 06:10:45.000000000,2014-07-18 08:45:42.000000000,2014-07-18 08:45:41.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-07-18 06:10:45.000000000', 'files': ['sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/ja/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/sahara-log-warning.pot', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/sahara-log-error.pot', 'sahara/locale/vi_VN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/ko_KR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/sahara.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-error.po'], 'web_link': 'https://opendev.org/openstack/sahara/commit/bea0fdacfef78e9e372156592a5d141c578d8ad6', 'message': 'Imported Translations from Transifex\n\nChange-Id: I72f222d7a072cb1ddc75a9ff78d80a029173a9c0\n'}]",0,107906,bea0fdacfef78e9e372156592a5d141c578d8ad6,9,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I72f222d7a072cb1ddc75a9ff78d80a029173a9c0
",git fetch https://review.opendev.org/openstack/sahara refs/changes/06/107906/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/ja/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/sahara-log-warning.pot', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/sahara-log-error.pot', 'sahara/locale/vi_VN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/ko_KR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/sahara.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-error.po']",19,bea0fdacfef78e9e372156592a5d141c578d8ad6,transifex/translations,"# Translations template for sahara. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the sahara project. # # Translators: # Carsten Duch <cad@teuto.net>, 2014 msgid """" msgstr """" ""Project-Id-Version: Sahara\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-07-18 06:10+0000\n"" ""PO-Revision-Date: 2014-07-17 07:01+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n"" ""Language-Team: German (http://www.transifex.com/projects/p/sahara/language/"" ""de/)\n"" ""Language: de\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n != 1);\n"" #: sahara/openstack/common/excutils.py:76 #, python-format msgid ""Original exception being dropped: %s"" msgstr ""Ursprüngliche Ausnahme wird gelöscht: %s"" #: sahara/openstack/common/excutils.py:105 #, python-format msgid ""Unexpected exception occurred %d time(s)... retrying."" msgstr ""Unerwartete Ausnahme %d mal(e) aufgetreten... Neuversuch."" #: sahara/openstack/common/lockutils.py:119 #, python-format msgid ""Could not release the acquired lock `%s`"" msgstr ""Angeforderte Sperre `%s` konnte nicht freigegeben werden"" #: sahara/openstack/common/loopingcall.py:95 msgid ""in fixed duration looping call"" msgstr ""in Schleifenaufruf mit festgelegter Dauer"" #: sahara/openstack/common/loopingcall.py:138 msgid ""in dynamic looping call"" msgstr ""in dynamischen Schleifenaufruf"" #: sahara/openstack/common/periodic_task.py:202 #, python-format msgid ""Error during %(full_task_name)s: %(e)s"" msgstr ""Fehler bei %(full_task_name)s: %(e)s"" #: sahara/openstack/common/db/api.py:72 msgid ""DB exceeded retry limit."" msgstr """" #: sahara/openstack/common/db/api.py:76 msgid ""DB connection error."" msgstr """" #: sahara/openstack/common/db/sqlalchemy/session.py:460 msgid ""DB exception wrapped."" msgstr ""Datenbankausnahme eingeschlossen."" #: sahara/openstack/common/db/sqlalchemy/test_migrations.py:267 #, python-format msgid ""Failed to migrate to version %(version)s on engine %(engine)s"" msgstr ""Migration von Version %(version)s auf Engine %(engine)s"" ",,337,107
openstack%2Fpython-troveclient~master~I19bd08f9dd60b415abb19ec56690c1a3e8b78f97,openstack/python-troveclient,master,I19bd08f9dd60b415abb19ec56690c1a3e8b78f97,WIP: replace dict.iteritems() with six.iteritems(dict),ABANDONED,2014-05-26 20:27:04.000000000,2014-07-18 08:42:42.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8871}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-05-26 20:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/eeb4e3ff3d6ffe6a65b5ce08d44a102b181be746', 'message': 'WIP: replace dict.iteritems() with six.iteritems(dict)\n\nAccording to https://wiki.openstack.org/wiki/Python3 dict.iteritems()\nshould be replaced with six.iteritems(dict).\n\nChange-Id: I19bd08f9dd60b415abb19ec56690c1a3e8b78f97\n'}, {'number': 2, 'created': '2014-05-27 10:07:02.000000000', 'files': ['troveclient/compat/base.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/85ab5d229e91f35ec5b1a92365a93c6c01d7004b', 'message': 'WIP: replace dict.iteritems() with six.iteritems(dict)\n\nAccording to https://wiki.openstack.org/wiki/Python3 dict.iteritems()\nshould be replaced with six.iteritems(dict).\n\nChange-Id: I19bd08f9dd60b415abb19ec56690c1a3e8b78f97\n'}]",0,95583,85ab5d229e91f35ec5b1a92365a93c6c01d7004b,21,5,2,167,,,0,"WIP: replace dict.iteritems() with six.iteritems(dict)

According to https://wiki.openstack.org/wiki/Python3 dict.iteritems()
should be replaced with six.iteritems(dict).

Change-Id: I19bd08f9dd60b415abb19ec56690c1a3e8b78f97
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/83/95583/1 && git format-patch -1 --stdout FETCH_HEAD,['troveclient/compat/base.py'],1,eeb4e3ff3d6ffe6a65b5ce08d44a102b181be746,replace_dict_iteritems," import six for (k, v) in iteritems(info):"," for (k, v) in info.iteritems():",4,1
openstack%2Ftrove~master~I28eace295e7aa3c8d3086e1c5bd053fa2dfee315,openstack/trove,master,I28eace295e7aa3c8d3086e1c5bd053fa2dfee315,Updates heat templates to use instance name,ABANDONED,2014-05-29 18:45:12.000000000,2014-07-18 08:41:33.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 7806}, {'_account_id': 8415}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-05-29 18:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/26b11bcd3a2da396ffb33e8cb1af7ef9b0b0991a', 'message': 'Updates heat templates to use instance name\n\nReasons:\n - Nova Instances created using heat work-flow were getting random\n   generated names, which was different from trove generated name.\n - There were a lot of parameters passed to heat template which had\n   nothing to do with orchestration services, like tenant_id.\n\nChanges:\n - Replaced BaseInstance type AWS::EC2::Instance by OS::Nova::Server.\n - OS::Nova::Server has a name property which is set with the trove\n   provided name.\n - Replaced the heat template parameters (TenantId, DatastoreManager,\n   InstanceId) which were not directly associated with orchestration\n   services by the Jinja parameters, as heat.template is first\n   rendered using Jinja.\n\nChange-Id: I28eace295e7aa3c8d3086e1c5bd053fa2dfee315\nCloses-Bug: #1298763\n'}, {'number': 2, 'created': '2014-05-29 18:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/94b8341b60e8fa712c404731a52bcf345573549d', 'message': 'Updates heat templates to use instance name\n\nReasons:\n - Nova Instances created using heat work-flow were getting random\n   generated names, which was different from trove generated name.\n - There were a lot of parameters passed to heat template which had\n   nothing to do with orchestration services, like tenant_id.\n\nChanges:\n - Replaced BaseInstance type AWS::EC2::Instance by OS::Nova::Server.\n - OS::Nova::Server has a name property which is set with the trove\n   provided name.\n - Replaced the heat template parameters (TenantId, DatastoreManager,\n   InstanceId) which were not directly associated with orchestration\n   services by the Jinja parameters, as heat.template is first\n   rendered using Jinja.\n\nChange-Id: I28eace295e7aa3c8d3086e1c5bd053fa2dfee315\nCloses-Bug: #1298763\n'}, {'number': 3, 'created': '2014-05-29 18:55:00.000000000', 'files': ['trove/templates/redis/heat.template', 'trove/templates/cassandra/heat.template', 'trove/templates/mysql/heat.template', 'trove/templates/mongodb/heat.template', 'trove/taskmanager/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/c67a822c02f970233e3800d98e251420b838362f', 'message': 'Updates heat templates to use instance name\n\nReasons:\n - Nova Instances created using heat work-flow were getting random\n   generated names, which was different from trove generated name.\n - There were a lot of parameters passed to heat template which had\n   nothing to do with orchestration services, like tenant_id.\n\nChanges:\n - Replaced BaseInstance type AWS::EC2::Instance by OS::Nova::Server.\n - OS::Nova::Server has a name property which is set with the trove\n   provided name.\n - Replaced the heat template parameters (TenantId, DatastoreManager,\n   InstanceId) which were not directly associated with orchestration\n   services by the Jinja parameters, as heat.template is first\n   rendered using Jinja.\n\nChange-Id: I28eace295e7aa3c8d3086e1c5bd053fa2dfee315\nCloses-Bug: #1298763\n'}]",0,96552,c67a822c02f970233e3800d98e251420b838362f,18,6,3,7806,,,0,"Updates heat templates to use instance name

Reasons:
 - Nova Instances created using heat work-flow were getting random
   generated names, which was different from trove generated name.
 - There were a lot of parameters passed to heat template which had
   nothing to do with orchestration services, like tenant_id.

Changes:
 - Replaced BaseInstance type AWS::EC2::Instance by OS::Nova::Server.
 - OS::Nova::Server has a name property which is set with the trove
   provided name.
 - Replaced the heat template parameters (TenantId, DatastoreManager,
   InstanceId) which were not directly associated with orchestration
   services by the Jinja parameters, as heat.template is first
   rendered using Jinja.

Change-Id: I28eace295e7aa3c8d3086e1c5bd053fa2dfee315
Closes-Bug: #1298763
",git fetch https://review.opendev.org/openstack/trove refs/changes/52/96552/3 && git format-patch -1 --stdout FETCH_HEAD,"['trove/templates/redis/heat.template', 'trove/templates/cassandra/heat.template', 'trove/templates/mysql/heat.template', 'trove/templates/mongodb/heat.template', 'trove/taskmanager/models.py']",5,26b11bcd3a2da396ffb33e8cb1af7ef9b0b0991a,bug/1298763," instance_info = {'instance_id': self.id, 'datastore_manager': datastore_manager, 'tenant_id': self.tenant_id, 'name': self.name} ifaces=ifaces, ports=ports, instance=instance_info) ""AvailabilityZone"": availability_zone}"," ifaces=ifaces, ports=ports) ""InstanceId"": self.id, ""DatastoreManager"": datastore_manager, ""AvailabilityZone"": availability_zone, ""TenantId"": self.tenant_id}",52,68
openstack%2Ftrove~master~I2ca2f6d9ef08970ab1e55140b3a47faf6242f7cd,openstack/trove,master,I2ca2f6d9ef08970ab1e55140b3a47faf6242f7cd,Add logs validation rules for mysql datastore,ABANDONED,2014-06-04 14:58:36.000000000,2014-07-18 08:40:32.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 10215}]","[{'number': 1, 'created': '2014-06-04 14:58:36.000000000', 'files': ['trove/templates/mysql/validation-rules.json', 'trove/templates/percona/validation-rules.json', 'trove/tests/api/configurations.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/48b0d71ca0fcf343e0a9dff518cdced73828d726', 'message': 'Add logs validation rules for mysql datastore\n\nReasons:\n - Users should be able to configure database logging as they want.\n\nChanges:\n - validation rules were added;\n - int-test proposed.\n\nChange-Id: I2ca2f6d9ef08970ab1e55140b3a47faf6242f7cd\nCloses-Bug: #1325997\n'}]",13,97814,48b0d71ca0fcf343e0a9dff518cdced73828d726,20,5,1,8415,,,0,"Add logs validation rules for mysql datastore

Reasons:
 - Users should be able to configure database logging as they want.

Changes:
 - validation rules were added;
 - int-test proposed.

Change-Id: I2ca2f6d9ef08970ab1e55140b3a47faf6242f7cd
Closes-Bug: #1325997
",git fetch https://review.opendev.org/openstack/trove refs/changes/14/97814/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/templates/mysql/validation-rules.json', 'trove/templates/percona/validation-rules.json', 'trove/tests/api/configurations.py']",3,48b0d71ca0fcf343e0a9dff518cdced73828d726,bug/1325997,"from trove.tests.util.server_connection import ServerSSHConnection values = ('{""join_buffer_size"": 1048576, ""connect_timeout"": 60,' '""general_log_file"": ""/var/log/mysql/general.log"",' '""general_log"":1, ""long_query_time"":11, ' '""bin_log"": ""/var/log/mysql/bin.log""}') @test(runs_after=[test_get_configuration_details_from_instance_validation]) def test_datastore_logs_are_present(self): if CONFIG.fake_mode: raise SkipTest(""SSH-base test is not allowed in FAKE MODE"") ssh_cmd = ""ls -la /var/log/mysql/ | grep log"" ssh_server = ServerSSHConnection(configuration_instance.id) result = ssh_server.execute(ssh_cmd) assert_true(result is not None) assert_true(""bin.log"" in result) "," values = '{""join_buffer_size"": 1048576, ""connect_timeout"": 60}'",83,1
openstack%2Ftrove~master~I892283b8f42af04b36dc8220a7bb97d12b8fb3f8,openstack/trove,master,I892283b8f42af04b36dc8220a7bb97d12b8fb3f8,Corrects spelling errors,ABANDONED,2014-01-27 15:19:24.000000000,2014-07-18 08:39:34.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 739}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 7806}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 10215}]","[{'number': 1, 'created': '2014-01-27 15:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/abead11e0a2c82ea131e70883a653ab8f872abe4', 'message': 'Corrects spelling typos\n\nReasons:\n- There are few spelling typos in code-base.\n\nChanges:\n- Corrected spelling-mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 2, 'created': '2014-01-27 15:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a463871af41697a37fdc991e7913cfd9a117dae0', 'message': 'Corrects spelling typos\n\nReasons:\n- There are few spelling typos in code-base.\n\nChanges:\n- Corrected spelling-mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 3, 'created': '2014-02-07 08:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/fc16ca7cdd09980367bd0f7186fa86e0df668e93', 'message': 'Corrects spelling typos\n\nReasons:\n- There are few spelling typos in code-base.\n\nChanges:\n- Corrected spelling-mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 4, 'created': '2014-02-07 08:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b037fab1cab4c5fd6179d9af342fb74733c5806d', 'message': 'Corrects spelling typos\n\nReasons:\n- There are few spelling typos in code-base.\n\nChanges:\n- Corrected spelling-mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 5, 'created': '2014-03-08 16:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/fbf140cb2ca927ff3d0c1fe804cc546adb619485', 'message': 'Corrects spelling typos\n\nReasons:\n- There are few spelling typos in code-base.\n\nChanges:\n- Corrected spelling-mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 6, 'created': '2014-04-21 16:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/65b639f2f0af5f505859ebbc45c2e9afe3d36297', 'message': 'Corrects spelling typos\n\nReasons:\n- There are few spelling typos in code-base.\n\nChanges:\n- Corrected spelling-mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 7, 'created': '2014-04-28 06:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bcb797315dd12d17b54813b80fd5750a1820b380', 'message': 'Corrects spelling typos\n\nReasons:\n- There are few spelling typos in code base.\n\nChanges:\n- Corrected spelling mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 8, 'created': '2014-04-28 10:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0eee1e2c18e4ead51c8d6a3205162a1411c14953', 'message': 'Corrects spelling typos\n\nReasons:\n- There are few spelling typos in code base.\n\nChanges:\n- Corrected spelling mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 9, 'created': '2014-05-09 09:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f5131dd0ea3e31bbfc847f1c1abdf68fb092471c', 'message': 'Corrects spelling errors\n\nReasons:\n- There are spelling typos in code base.\n- Typos also detected using: https://github.com/intgr/topy\n\nChanges:\n- Corrected spelling mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 10, 'created': '2014-05-12 07:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3e2d9cbfa9ff1822304b04e59facfc37476043b6', 'message': 'Corrects spelling errors\n\nReasons:\n- There are spelling typos in code base.\n- Typos also detected using: https://github.com/intgr/topy\n\nChanges:\n- Corrected spelling mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 11, 'created': '2014-05-12 10:38:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3709cc73d7037d7a83e1613b20691924b03d126d', 'message': 'Corrects spelling errors\n\nReasons:\n- There are spelling typos in code base.\n- Typos also detected using: https://github.com/intgr/topy\n\nChanges:\n- Corrected spelling mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 12, 'created': '2014-05-12 10:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/675336b34738b91ef65cad758ed59144a8caa257', 'message': 'Corrects spelling errors\n\nReasons:\n- There are spelling typos in code base.\n- Typos also detected using: https://github.com/intgr/topy\n\nChanges:\n- Corrected spelling mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}, {'number': 13, 'created': '2014-05-23 07:25:07.000000000', 'files': ['trove/common/wsgi.py', 'trove/guestagent/datastore/mysql/service.py', 'trove/tests/fakes/guestagent.py', 'trove/templates/mysql/config.template', 'trove/instance/models.py', 'trove/common/debug_utils.py', 'trove/quota/quota.py', 'trove/tests/api/mgmt/hosts.py', 'etc/trove/trove.conf.test', 'trove/guestagent/strategies/restore/mysql_impl.py', 'trove/dns/designate/driver.py', 'trove/instance/service.py', 'trove/tests/unittests/api/common/test_limits.py', 'apidocs/src/xslts/js/trc/schema/layoutManager.js', 'rsdns/client/records.py', 'trove/tests/unittests/guestagent/test_pkg.py', 'trove/tests/util/__init__.py', 'etc/trove/trove-taskmanager.conf.sample', 'trove/common/configurations.py', 'trove/tests/api/mgmt/accounts.py', 'apidocs/src/xslts/js/trc/schema/sampleManager.js', 'trove/guestagent/datastore/couchbase/manager.py', 'trove/tests/unittests/guestagent/test_mysql_manager.py', 'trove/extensions/routes/security_group.py', 'trove/guestagent/pkg.py', 'trove/tests/unittests/router/test_router.py', 'trove/taskmanager/manager.py', 'doc/source/conf.py', 'etc/trove/trove.conf.sample', 'trove/templates/percona/config.template', 'apidocs/src/xslts/js/trc/util.js', 'trove/extensions/account/service.py', 'trove/guestagent/datastore/redis/manager.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/guestagent/datastore/redis/service.py', 'trove/tests/api/instances_actions.py', 'trove/tests/unittests/guestagent/test_dbaas.py', 'trove/guestagent/strategies/storage/swift.py', 'trove/taskmanager/api.py', 'etc/tests/core.test.conf', 'trove/tests/unittests/mgmt/test_models.py', 'trove/taskmanager/models.py', 'trove/common/template.py', 'trove/guestagent/api.py', 'trove/tests/api/instances.py', 'trove/extensions/mgmt/instances/service.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/c3f136ea76cb4fddb2a3fd70a66e9946af834a53', 'message': 'Corrects spelling errors\n\nReasons:\n- There are spelling typos in code base.\n- Typos also detected using: https://github.com/intgr/topy\n\nChanges:\n- Corrected spelling mistakes.\n\nNo bug raised, since no functionality is touched in the patchset.\n\nChange-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8\n'}]",20,69383,c3f136ea76cb4fddb2a3fd70a66e9946af834a53,120,10,13,7806,,,0,"Corrects spelling errors

Reasons:
- There are spelling typos in code base.
- Typos also detected using: https://github.com/intgr/topy

Changes:
- Corrected spelling mistakes.

No bug raised, since no functionality is touched in the patchset.

Change-Id: I892283b8f42af04b36dc8220a7bb97d12b8fb3f8
",git fetch https://review.opendev.org/openstack/trove refs/changes/83/69383/10 && git format-patch -1 --stdout FETCH_HEAD,"['trove/tests/fakes/guestagent.py', 'trove/templates/mysql/config.template', 'trove/instance/models.py', 'trove/tests/fakes/swift.py', 'trove/common/debug_utils.py', 'trove/quota/quota.py', 'etc/trove/trove.conf.test', 'trove/dns/designate/driver.py', 'trove/tests/unittests/api/common/test_limits.py', 'trove/tests/unittests/guestagent/test_pkg.py', 'trove/tests/util/__init__.py', 'etc/trove/trove-taskmanager.conf.sample', 'trove/tests/api/mgmt/accounts.py', 'trove/guestagent/pkg.py', 'trove/tests/unittests/router/test_router.py', 'trove/taskmanager/manager.py', 'etc/trove/trove.conf.sample', 'trove/templates/percona/config.template', 'bin/trove-taskmanager', 'trove/guestagent/datastore/redis/manager.py', 'trove/tests/unittests/guestagent/test_manager.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/guestagent/datastore/redis/service.py', 'trove/tests/api/instances_actions.py', 'trove/guestagent/strategies/storage/swift.py', 'etc/tests/core.test.conf', 'trove/tests/unittests/mgmt/test_models.py', 'trove/taskmanager/models.py', 'trove/guestagent/api.py', 'trove/tests/api/instances.py']",30,abead11e0a2c82ea131e70883a653ab8f872abe4,spelling-corrections, self.volume_id = None # Id for the attached volume., self.volume_id = None # Id for the attached vo186lume,47,49
openstack%2Fpython-glanceclient~master~I86572b69c4511f933c9676108190271874346302,openstack/python-glanceclient,master,I86572b69c4511f933c9676108190271874346302,Don't stream non-binary requests,MERGED,2014-07-15 15:10:48.000000000,2014-07-18 08:39:08.000000000,2014-07-18 08:39:08.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 6873}, {'_account_id': 7701}, {'_account_id': 8871}, {'_account_id': 11642}]","[{'number': 1, 'created': '2014-07-15 15:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/f8a0efbdf8aad54821b41f4a4499342146c02db2', 'message': ""Don't stream non-binary requests\n\nSetting stream=True with requests can lead to issues\nwith not closing the connection so the urllib3 connection\npool is not freed up, so only set stream=True if making\na request with application/octet-stream content-type.\n\nSee the body-content-workflow and keep-alive sections\nin the requests docs here for more information:\n\nhttp://docs.python-requests.org/en/latest/user/advanced/\n\nChange-Id: I86572b69c4511f933c9676108190271874346302\nCloses-Bug: #1341777\n""}, {'number': 2, 'created': '2014-07-15 17:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/d4b7450119557b27044ef582cf16db76e5107cc5', 'message': ""Don't stream non-binary requests\n\nSetting stream=True with requests can lead to issues\nwith not closing the connection so the urllib3 connection\npool is not freed up, so only set stream=True if making\na request with application/octet-stream content-type.\n\nSee the body-content-workflow and keep-alive sections\nin the requests docs here for more information:\n\nhttp://docs.python-requests.org/en/latest/user/advanced/\n\nNote that commit dbb242b changed the response body_iter\ncode to potentially return a six.StringIO object rather\nthan the old ResponseBodyIterator class and since the\nimages client code is not converting the body_iter into\na dict using json.loads, we have to do that directly\nin the _request method where the body_iter is\nconstructed.\n\nChange-Id: I86572b69c4511f933c9676108190271874346302\nCloses-Bug: #1341777\n""}, {'number': 3, 'created': '2014-07-15 18:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/087f8035a58b02155a55f3a35c8ae8ba7f0e5ee3', 'message': ""Don't stream non-binary requests\n\nSetting stream=True with requests can lead to issues\nwith not closing the connection so the urllib3 connection\npool is not freed up, so only set stream=True if making\na request with application/octet-stream content-type.\n\nSee the body-content-workflow and keep-alive sections\nin the requests docs here for more information:\n\nhttp://docs.python-requests.org/en/latest/user/advanced/\n\nNote that commit dbb242b changed the response body_iter\ncode to potentially return a six.StringIO object rather\nthan the old ResponseBodyIterator class and since the\nimages client code is not converting the body_iter into\na dict using json.loads, we have to do that directly\nin the _request method where the body_iter is\nconstructed.\n\nChange-Id: I86572b69c4511f933c9676108190271874346302\nCloses-Bug: #1341777\n""}, {'number': 4, 'created': '2014-07-16 10:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/c608b606686182f8f8ca6cbd895205dcbe8d4368', 'message': ""Don't stream non-binary requests\n\nSetting stream=True with requests can lead to issues\nwith not closing the connection so the urllib3 connection\npool is not freed up, so only set stream=True if making\na request with application/octet-stream content-type.\n\nSee the body-content-workflow and keep-alive sections\nin the requests docs here for more information:\n\nhttp://docs.python-requests.org/en/latest/user/advanced/\n\nNote that commit dbb242b changed the response body_iter\ncode to potentially return a six.StringIO object rather\nthan the old ResponseBodyIterator class and since the\nimages client code is not converting the body_iter into\na dict using json.loads, we have to do that directly\nin the _request method where the body_iter is\nconstructed.\n\nChange-Id: I86572b69c4511f933c9676108190271874346302\nCloses-Bug: #1341777\n""}, {'number': 5, 'created': '2014-07-16 14:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/6761ccc6797db5e0e286ce0a520e1653a32dbdd6', 'message': ""Don't stream non-binary requests\n\nSetting stream=True with requests can lead to issues\nwith not closing the connection so the urllib3 connection\npool is not freed up, so only set stream=True if making\na request with application/octet-stream content-type.\n\nSee the body-content-workflow and keep-alive sections\nin the requests docs here for more information:\n\nhttp://docs.python-requests.org/en/latest/user/advanced/\n\nNote that commit dbb242b changed the response body_iter\ncode to potentially return a six.StringIO object rather\nthan the old ResponseBodyIterator class and since the\nimages client code is not converting the body_iter into\na dict using json.loads, we have to do that directly\nin the _request method where the body_iter is\nconstructed.\n\nCo-authored-by: Flavio Percoco <fpercoco@redhat.com>\n\nChange-Id: I86572b69c4511f933c9676108190271874346302\nCloses-Bug: #1341777\n""}, {'number': 6, 'created': '2014-07-16 16:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/cdc6c93da6dbda16b332ed74f3203bbe6fea8d4d', 'message': ""Don't stream non-binary requests\n\nSetting stream=True with requests can lead to issues\nwith not closing the connection so the urllib3 connection\npool is not freed up, so only set stream=True if making\na request with application/octet-stream content-type.\n\nSee the body-content-workflow and keep-alive sections\nin the requests docs here for more information:\n\nhttp://docs.python-requests.org/en/latest/user/advanced/\n\nNote that commit dbb242b changed the response body_iter\ncode to potentially return a six.StringIO object rather\nthan the old ResponseBodyIterator class and since the\nimages client code is not converting the body_iter into\na dict using json.loads, we have to do that directly\nin the _request method where the body_iter is\nconstructed.\n\nCo-authored-by: Flavio Percoco <fpercoco@redhat.com>\n\nChange-Id: I86572b69c4511f933c9676108190271874346302\nPartial-Bug: #1341777\n""}, {'number': 7, 'created': '2014-07-16 20:51:19.000000000', 'files': ['glanceclient/common/http.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/68c1d1fbc614d11b95f2fd6da26fd669e40f4186', 'message': ""Don't stream non-binary requests\n\nSetting stream=True with requests can lead to issues\nwith not closing the connection so the urllib3 connection\npool is not freed up, so only set stream=True if making\na request with application/octet-stream content-type.\n\nSee the body-content-workflow and keep-alive sections\nin the requests docs here for more information:\n\nhttp://docs.python-requests.org/en/latest/user/advanced/\n\nNote that commit dbb242b changed the response body_iter\ncode to potentially return a six.StringIO object rather\nthan the old ResponseBodyIterator class and since the\nimages client code is not converting the body_iter into\na dict using json.loads, we have to do that directly\nin the _request method where the body_iter is\nconstructed.\n\nCo-authored-by: Flavio Percoco <fpercoco@redhat.com>\n\nChange-Id: I86572b69c4511f933c9676108190271874346302\nPartial-Bug: #1341777\n""}]",1,107080,68c1d1fbc614d11b95f2fd6da26fd669e40f4186,44,9,7,6873,,,0,"Don't stream non-binary requests

Setting stream=True with requests can lead to issues
with not closing the connection so the urllib3 connection
pool is not freed up, so only set stream=True if making
a request with application/octet-stream content-type.

See the body-content-workflow and keep-alive sections
in the requests docs here for more information:

http://docs.python-requests.org/en/latest/user/advanced/

Note that commit dbb242b changed the response body_iter
code to potentially return a six.StringIO object rather
than the old ResponseBodyIterator class and since the
images client code is not converting the body_iter into
a dict using json.loads, we have to do that directly
in the _request method where the body_iter is
constructed.

Co-authored-by: Flavio Percoco <fpercoco@redhat.com>

Change-Id: I86572b69c4511f933c9676108190271874346302
Partial-Bug: #1341777
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/80/107080/4 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/common/http.py'],1,f8a0efbdf8aad54821b41f4a4499342146c02db2,bug/1341777," stream = True if content_type == 'application/octet-stream' else False stream=stream, if stream:"," stream=True, if content_type == 'application/octet-stream':",3,2
openstack%2Foslo.db~master~I92b1dcd830c4755f429a0f6529911e607c2c7de7,openstack/oslo.db,master,I92b1dcd830c4755f429a0f6529911e607c2c7de7,Opportunistic migration tests,MERGED,2014-05-13 11:46:47.000000000,2014-07-18 08:38:56.000000000,2014-07-18 08:38:56.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5638}, {'_account_id': 6849}, {'_account_id': 6928}, {'_account_id': 7491}, {'_account_id': 7536}, {'_account_id': 8871}, {'_account_id': 11816}]","[{'number': 1, 'created': '2014-05-13 11:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/6a144edd76e4063a90b616ac389328f3a3c0212d', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 2, 'created': '2014-05-13 12:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/bb4c08dd6a15571862b10773b4df80cf934fe549', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 3, 'created': '2014-05-16 14:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/e44590168fc6b0713532fd3cd11bbbb7b113835c', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 4, 'created': '2014-05-23 09:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/61ee78cc2a98dbba6506528f72fec7f4048fba67', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 5, 'created': '2014-05-26 07:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/18bd04731d919aba63413bab750204fd8dab4ed5', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 6, 'created': '2014-05-26 13:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/ebb94105a14fee6d3554a4d608d8eef990e0f9b7', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 7, 'created': '2014-05-27 09:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/efd7fdaf6a8f5ebf05cd1da51c9b310ee40629cc', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 8, 'created': '2014-05-27 14:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/1f6d7f123a054ab475ab510cbc73dcdf042e8715', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 9, 'created': '2014-05-27 17:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/ac0f9aa923518530a93f70fc669c44b8e0bc4fd2', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 10, 'created': '2014-05-28 08:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/5f22488b80e4f8ce1291c9f4cb564b667f2e1e5c', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 11, 'created': '2014-05-29 11:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/46cd3dbda7a01e8b7bba13915eef1ead7fda225a', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 12, 'created': '2014-06-06 07:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/d09e4bdc7d7154753d6fe5b18014fdef59bab378', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 13, 'created': '2014-06-06 07:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/bdc7750e59f64245c0000efdcdf683ea38221e25', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 14, 'created': '2014-06-13 16:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/762cfff9840156f5587c99c60f377c58557de101', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 15, 'created': '2014-06-16 11:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/3a3882a185d75ac853c7e8157c976c11ae9267ed', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 16, 'created': '2014-06-18 15:40:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0feeaf0e4e037c38617ba3cbd03743adf76ec567', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 17, 'created': '2014-06-23 08:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/4a03f462e99f80320255045bccb0e23c96acc0bd', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 18, 'created': '2014-06-23 15:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/d2564e57f644eae413b08e5404be6ce89f2f3eb3', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 19, 'created': '2014-06-25 08:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/a435c606b1d86bb42a64e908719a0894f62c5468', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 20, 'created': '2014-06-26 09:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/747b51e46c7cd008ebab93734978b387d9ac0993', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 21, 'created': '2014-07-01 10:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/52e24c58bd369624a1cfe4e209bc8a55331d65af', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 22, 'created': '2014-07-03 15:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/792f65ecb7812b9a11904074714c4c56c3f3e061', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 23, 'created': '2014-07-04 13:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/1bda1c67ea06a0208eb668deb7d08bd388e3cc31', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 24, 'created': '2014-07-07 14:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/227fc9382d39cd2453b62b03ad20729eb4f7b02a', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 25, 'created': '2014-07-10 16:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/034cfa6791d7f48edf4854d1bf549a91e4eaf683', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 26, 'created': '2014-07-14 09:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/cd095a32db8bc722ef1c38a29521ae8a6f34422f', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 27, 'created': '2014-07-14 14:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/136f1b98e434dd87a57aeaa2ebf713fa4a578561', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 28, 'created': '2014-07-15 08:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/64d53426503a592357c8ca7833ef7a277f2ace0b', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 29, 'created': '2014-07-15 15:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/b1c01f5c61d9d1c5248d40dae96f4c4eff3313c0', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 30, 'created': '2014-07-16 07:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/309d7e182d6bf5e324c0d00e10d98b2c934ab5af', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}, {'number': 31, 'created': '2014-07-16 07:31:36.000000000', 'files': ['tests/sqlalchemy/test_utils.py', 'requirements.txt', 'oslo/db/sqlalchemy/test_migrations.conf', 'tests/sqlalchemy/test_migrations.py', 'oslo/db/sqlalchemy/test_migrations.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/c34c32e09ed1f170dfe62c7daedf0cd60f57a833', 'message': ""Opportunistic migration tests\n\nMigrations should be tested with real database backends. For this goal\nintended number of base test cases which used in current implementation.\nPreviously there were two ways to run migration tests: using\nopportunistic test cases (default way we've been using on CI) and\nby using database connection strings, specified in test_migrations.conf,\nfor every particular database test case. For the sake of simplicity and\nconsistency we are moving to using of opportunistic db test cases here.\n\nWith this change we are free from locking, so we don't need `lockfile`\nanymore.\n\nCloses-Bug: #1327397\nCloses-Bug: #1328997\nChange-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7\n""}]",64,93424,c34c32e09ed1f170dfe62c7daedf0cd60f57a833,156,9,31,7536,,,0,"Opportunistic migration tests

Migrations should be tested with real database backends. For this goal
intended number of base test cases which used in current implementation.
Previously there were two ways to run migration tests: using
opportunistic test cases (default way we've been using on CI) and
by using database connection strings, specified in test_migrations.conf,
for every particular database test case. For the sake of simplicity and
consistency we are moving to using of opportunistic db test cases here.

With this change we are free from locking, so we don't need `lockfile`
anymore.

Closes-Bug: #1327397
Closes-Bug: #1328997
Change-Id: I92b1dcd830c4755f429a0f6529911e607c2c7de7
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/24/93424/21 && git format-patch -1 --stdout FETCH_HEAD,"['tests/sqlalchemy/test_utils.py', 'oslo/db/sqlalchemy/test_migrations.conf', 'tests/sqlalchemy/test_migrations.py', 'oslo/db/sqlalchemy/test_migrations.py']",4,6a144edd76e4063a90b616ac389328f3a3c0212d,alembic_migraton_test," from openstack.common.gettextutils import _LEclass WalkVersionsMixin(object): """"""Test mixin to check upgrade and downgrade ability of migration."""""" def _walk_versions(self, snake_walk=False, downgrade=True): """"""Check is migration upgrading and downgrading successfully Determine latest version script from the repo, then upgrade from 1 through to the latest, with no data in the databases. This just checks that the schema itself upgrades successfully. :snake_walk: Boolean. Force double check if True. :downgrade: Boolean. Check downgrade behavior if True. """""" self.migration_api.version_control(self.engine, self.REPOSITORY, self.migration_api.db_version(self.engine, self._migrate_up(version, with_data=True) if snake_walk: downgraded = self._migrate_down(version - 1, with_data=True) if downgraded: self._migrate_up(version) downgraded = self._migrate_down(version - 1) self._migrate_up(version) self._migrate_down(version - 1) def _migrate_down(self, version, with_data=False): """"""Migrate down to a previous version of the db."""""" try: self.migration_api.downgrade(self.engine, self.REPOSITORY, version) self.assertEqual(version, self.migration_api.db_version( self.engine, self.REPOSITORY)) post_downgrade(self.engine) def _migrate_up(self, version, with_data=False): """"""Migrate up to a new version of the db. data = pre_upgrade(self.engine) self.migration_api.upgrade(self.engine, self.REPOSITORY, version) self.migration_api.db_version(self.engine, check(self.engine, data) (version, self.engine))","import functoolsimport os import subprocess import lockfile from oslotest import base as test_base from six import moves from six.moves.urllib import parse import sqlalchemy import sqlalchemy.exc from oslo.db.openstack.common.gettextutils import _LE from oslo.db.sqlalchemy import utilsdef _have_mysql(user, passwd, database): present = os.environ.get('TEST_MYSQL_PRESENT') if present is None: return utils.is_backend_avail(backend='mysql', user=user, passwd=passwd, database=database) return present.lower() in ('', 'true') def _have_postgresql(user, passwd, database): present = os.environ.get('TEST_POSTGRESQL_PRESENT') if present is None: return utils.is_backend_avail(backend='postgres', user=user, passwd=passwd, database=database) return present.lower() in ('', 'true') def _set_db_lock(lock_path=None, lock_prefix=None): def decorator(f): @functools.wraps(f) def wrapper(*args, **kwargs): try: path = lock_path or os.environ.get(""OSLO_LOCK_PATH"") lock = lockfile.FileLock(os.path.join(path, lock_prefix)) with lock: LOG.debug('Got lock ""%s""' % f.__name__) return f(*args, **kwargs) finally: LOG.debug('Lock released ""%s""' % f.__name__) return wrapper return decorator class BaseMigrationTestCase(test_base.BaseTestCase): """"""Base class fort testing of migration utils."""""" def __init__(self, *args, **kwargs): super(BaseMigrationTestCase, self).__init__(*args, **kwargs) self.DEFAULT_CONFIG_FILE = os.path.join(os.path.dirname(__file__), 'test_migrations.conf') # Test machines can set the TEST_MIGRATIONS_CONF variable # to override the location of the config file for migration testing self.CONFIG_FILE_PATH = os.environ.get('TEST_MIGRATIONS_CONF', self.DEFAULT_CONFIG_FILE) self.test_databases = {} self.migration_api = None def setUp(self): super(BaseMigrationTestCase, self).setUp() # Load test databases from the config file. Only do this # once. No need to re-run this on each test... LOG.debug('config_path is %s' % self.CONFIG_FILE_PATH) if os.path.exists(self.CONFIG_FILE_PATH): cp = moves.configparser.RawConfigParser() try: cp.read(self.CONFIG_FILE_PATH) defaults = cp.defaults() for key, value in defaults.items(): self.test_databases[key] = value except moves.configparser.ParsingError as e: self.fail(""Failed to read test_migrations.conf config "" ""file. Got error: %s"" % e) else: self.fail(""Failed to find test_migrations.conf config "" ""file."") self.engines = {} for key, value in self.test_databases.items(): self.engines[key] = sqlalchemy.create_engine(value) # We start each test case with a completely blank slate. self._reset_databases() def tearDown(self): # We destroy the test data store between each test case, # and recreate it, which ensures that we have no side-effects # from the tests self._reset_databases() super(BaseMigrationTestCase, self).tearDown() def execute_cmd(self, cmd=None): process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT) output = process.communicate()[0] LOG.debug(output) self.assertEqual(0, process.returncode, ""Failed to run: %s\n%s"" % (cmd, output)) def _reset_pg(self, conn_pieces): (user, password, database, host) = utils.get_db_connection_info(conn_pieces) os.environ['PGPASSWORD'] = password os.environ['PGUSER'] = user # note(boris-42): We must create and drop database, we can't # drop database which we have connected to, so for such # operations there is a special database template1. sqlcmd = (""psql -w -U %(user)s -h %(host)s -c"" "" '%(sql)s' -d template1"") sql = (""drop database if exists %s;"") % database droptable = sqlcmd % {'user': user, 'host': host, 'sql': sql} self.execute_cmd(droptable) sql = (""create database %s;"") % database createtable = sqlcmd % {'user': user, 'host': host, 'sql': sql} self.execute_cmd(createtable) os.unsetenv('PGPASSWORD') os.unsetenv('PGUSER') @_set_db_lock(lock_prefix='migration_tests-') def _reset_databases(self): for key, engine in self.engines.items(): conn_string = self.test_databases[key] conn_pieces = parse.urlparse(conn_string) engine.dispose() if conn_string.startswith('sqlite'): # We can just delete the SQLite database, which is # the easiest and cleanest solution db_path = conn_pieces.path.strip('/') if os.path.exists(db_path): os.unlink(db_path) # No need to recreate the SQLite DB. SQLite will # create it for us if it's not there... elif conn_string.startswith('mysql'): # We can execute the MySQL client to destroy and re-create # the MYSQL database, which is easier and less error-prone # than using SQLAlchemy to do this via MetaData...trust me. (user, password, database, host) = \ utils.get_db_connection_info(conn_pieces) sql = (""drop database if exists %(db)s; "" ""create database %(db)s;"") % {'db': database} cmd = (""mysql -u \""%(user)s\"" -p\""%(password)s\"" -h %(host)s "" ""-e \""%(sql)s\"""") % {'user': user, 'password': password, 'host': host, 'sql': sql} self.execute_cmd(cmd) elif conn_string.startswith('postgresql'): self._reset_pg(conn_pieces) class WalkVersionsMixin(object): def _walk_versions(self, engine=None, snake_walk=False, downgrade=True): # Determine latest version script from the repo, then # upgrade from 1 through to the latest, with no data # in the databases. This just checks that the schema itself # upgrades successfully. self.migration_api.version_control(engine, self.REPOSITORY, self.migration_api.db_version(engine, self._migrate_up(engine, version, with_data=True) if snake_walk: downgraded = self._migrate_down( engine, version - 1, with_data=True) if downgraded: self._migrate_up(engine, version) downgraded = self._migrate_down(engine, version - 1) self._migrate_up(engine, version) self._migrate_down(engine, version - 1) def _migrate_down(self, engine, version, with_data=False): try: self.migration_api.downgrade(engine, self.REPOSITORY, version) self.assertEqual( version, self.migration_api.db_version(engine, self.REPOSITORY)) post_downgrade(engine) def _migrate_up(self, engine, version, with_data=False): """"""migrate up to a new version of the db. data = pre_upgrade(engine) self.migration_api.upgrade(engine, self.REPOSITORY, version) self.migration_api.db_version(engine, check(engine, data) (version, engine))",278,452
openstack%2Fpython-troveclient~master~I26c4340a3a3c3e64f688c6e2013f33646a454522,openstack/python-troveclient,master,I26c4340a3a3c3e64f688c6e2013f33646a454522,replace string format arguments with function parameters,ABANDONED,2014-05-19 15:24:14.000000000,2014-07-18 08:36:59.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-05-19 15:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/0c8f20d9c52d40161e28343ffd3eabee544f882f', 'message': 'use logging function parameters instead of string format arguments\n\nChange-Id: I26c4340a3a3c3e64f688c6e2013f33646a454522\n'}, {'number': 2, 'created': '2014-05-19 15:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/011d656519905c613010ed473603d6bab65e9830', 'message': 'replace string format arguments with function parameters\n\nThere are files containing string format arguments inside\nlogging messgaes. Using logging function parameters should\nbe preferred.\n\nChange-Id: I26c4340a3a3c3e64f688c6e2013f33646a454522\nCloses-Bug: #1320926\n'}, {'number': 3, 'created': '2014-05-19 15:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/f79e414657a65446e64e905f46d2fb818bf7a90d', 'message': 'replace string format arguments with function parameters\n\nThere are files containing string format arguments inside\nlogging messages. Using logging function parameters should\nbe preferred.\n\nChange-Id: I26c4340a3a3c3e64f688c6e2013f33646a454522\nCloses-Bug: #1320926\n'}, {'number': 4, 'created': '2014-05-29 21:43:32.000000000', 'files': ['troveclient/client.py', 'troveclient/compat/client.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/916f701bd352a413f3e13e5388182b62a42a2639', 'message': 'replace string format arguments with function parameters\n\nThere are files containing string format arguments inside\nlogging messages. Using logging function parameters should\nbe preferred.\n\nChange-Id: I26c4340a3a3c3e64f688c6e2013f33646a454522\nCloses-Bug: #1320926\n'}]",0,94209,916f701bd352a413f3e13e5388182b62a42a2639,27,5,4,167,,,0,"replace string format arguments with function parameters

There are files containing string format arguments inside
logging messages. Using logging function parameters should
be preferred.

Change-Id: I26c4340a3a3c3e64f688c6e2013f33646a454522
Closes-Bug: #1320926
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/09/94209/4 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/client.py', 'troveclient/compat/client.py']",2,0c8f20d9c52d40161e28343ffd3eabee544f882f,logging_should_be_lazy," _logger.debug(""REQ: %s\n"", """".join(string_parts)) if 'body' in kwargs: _logger.debug(""REQ BODY: %s\n"", kwargs['body']) _logger.debug(""%s -d '%s'"", curl_cmd, kwargs['body']) _logger.debug(""BODY: %s\n"", req_body) _logger.debug(""RESPONSE HEADERS: %s"", resp) _logger.debug(""RESPONSE BODY : %s"", resp_body)"," _logger.debug(""REQ: %s\n"" % """".join(string_parts)) if 'body' in kwargs: _logger.debug(""REQ BODY: %s\n"" % (kwargs['body'])) _logger.debug(""%s -d '%s'"" % (curl_cmd, kwargs['body'])) _logger.debug(""BODY: %s\n"" % (req_body)) _logger.debug(""RESPONSE HEADERS: %s"" % resp) _logger.debug(""RESPONSE BODY : %s"" % resp_body)",11,11
openstack%2Ftripleo-incubator~master~Ic528175649c54395d2d47b0cbbbe11c09b65d91a,openstack/tripleo-incubator,master,Ic528175649c54395d2d47b0cbbbe11c09b65d91a,Improve readability of JQ for novaBM and ironic,MERGED,2014-07-03 14:17:41.000000000,2014-07-18 08:31:51.000000000,2014-07-18 08:31:51.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1726}, {'_account_id': 6348}, {'_account_id': 6449}, {'_account_id': 7579}, {'_account_id': 7585}, {'_account_id': 8688}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-07-03 14:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/8ea3a27d7e4e6f44db0fda13af7ddc927196baf0', 'message': 'Improve readability of JQ for novaBM and ironic\n\nRe-alignment of long expression.\nUnify expressions as much as possible.\nRemove part of the config that are not required.\n\nChange-Id: Ic528175649c54395d2d47b0cbbbe11c09b65d91a\n'}, {'number': 2, 'created': '2014-07-03 14:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/09f05032fc42202db0092e4fe17b4b9344dc2264', 'message': 'Improve readability of JQ for novaBM and ironic\n\nRe-alignment of long expression.\nUnify expressions as much as possible.\nRemove part of the config that are not required.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: Ic528175649c54395d2d47b0cbbbe11c09b65d91a\n'}, {'number': 3, 'created': '2014-07-03 14:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/293e2062954b4c22d796aea3bc5e303371ecad19', 'message': 'Improve readability of JQ for novaBM and ironic\n\nRe-alignment of long expression.\nUnify expressions as much as possible.\nRemove parts of the config that are not required.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: Ic528175649c54395d2d47b0cbbbe11c09b65d91a\n'}, {'number': 4, 'created': '2014-07-03 14:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/909018276fbeee72492b7f56129ed9496e627e14', 'message': 'Improve readability of JQ for novaBM and ironic\n\nRe-alignment of long expression.\nUnify expressions as much as possible.\nRemove parts of the config that are not required.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: Ic528175649c54395d2d47b0cbbbe11c09b65d91a\n'}, {'number': 5, 'created': '2014-07-04 09:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/05811592fa14ce828ed02bedb22463a0fdc21fac', 'message': 'Improve readability of JQ for novaBM and ironic\n\nRe-alignment of long expression.\nUnify expressions as much as possible.\nRemove parts of the config that are not required.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: Ic528175649c54395d2d47b0cbbbe11c09b65d91a\n'}, {'number': 6, 'created': '2014-07-04 09:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/2d01db781e0ee418578ec26a5e422b8661745892', 'message': 'Improve readability of JQ for novaBM and ironic\n\nRe-alignment of long expression.\nUnify expressions as much as possible.\nRemove parts of the config that are not required.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: Ic528175649c54395d2d47b0cbbbe11c09b65d91a\n'}, {'number': 7, 'created': '2014-07-04 14:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/199b246171bd0f37d71c400b7c483334c0a8d14b', 'message': 'Improve readability of JQ for novaBM and ironic\n\nRe-alignment of long expression.\nUnify expressions as much as possible.\nUnsets parts of the config that are not required.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: Ic528175649c54395d2d47b0cbbbe11c09b65d91a\n'}, {'number': 8, 'created': '2014-07-15 17:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/a9a225d33b6c52f1b064717f2b92e69b6ecdcf02', 'message': 'Improve readability of JQ for novaBM and ironic\n\nRe-alignment of long expression.\nUnify expressions as much as possible.\nUnsets parts of the config that are not required.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: Ic528175649c54395d2d47b0cbbbe11c09b65d91a\n'}, {'number': 9, 'created': '2014-07-17 14:37:14.000000000', 'files': ['scripts/devtest_seed.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/8a009d7a79ae6e9f1387a8ed86dbb8807961e333', 'message': 'Improve readability of JQ for novaBM and ironic\n\nRe-alignment of long expression.\nUnify expressions as much as possible.\nUnsets parts of the config that are not required.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: Ic528175649c54395d2d47b0cbbbe11c09b65d91a\n'}]",10,104559,8a009d7a79ae6e9f1387a8ed86dbb8807961e333,50,9,9,10373,,,0,"Improve readability of JQ for novaBM and ironic

Re-alignment of long expression.
Unify expressions as much as possible.
Unsets parts of the config that are not required.

Co-Author: Alexis Lee <alexisl@hp.com>
Change-Id: Ic528175649c54395d2d47b0cbbbe11c09b65d91a
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/59/104559/5 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_seed.sh'],1,8ea3a27d7e4e6f44db0fda13af7ddc927196baf0,jp_seed,"# Deletes the ironic section as it not used in the configuration. jq -s ' .[1] as $config | .[0] | .nova.baremetal as $bm | del(.ironic) + { ""nova"": ( .nova + { ""baremetal"": ($bm + { ""arch"": $config.arch, ""power_manager"": $config.power_manager, ""virtual_power"": ($bm.virtual_power + { ""user"": $config[""ssh-user""], ""ssh_host"": $config[""host-ip""], ""ssh_key"": $config[""ssh-key""] }) }) }) }' config.json $TE_DATAFILE > tmp_local.json# Delete the nova.baremetal section as it not used in the configuration. # Sets: # - ironic.virtual_power_ssh_key. # - nova.compute_driver to ironic.nova.virt.ironic.driver.IronicDriver. # - nova.compute_manager to avoid race conditions on ironic startup. jq -s ' .[1] as $config | .[0] | . + { ""ironic"": (.ironic + { ""virtual_power_ssh_key"": $config[""ssh-key""], }), ""nova"": ((.nova | del(.baremetal)) + { ""compute_driver"": ""ironic.nova.virt.ironic.driver.IronicDriver"", ""compute_manager"": ""ironic.nova.compute.manager.ClusteredComputeManager"", }) }' config.json $TE_DATAFILE > tmp_local.json","# - sets the ironic key to """" to disable configuration looking for Ironic # settings. jq -s '.[1] as $config |(.[0].nova.baremetal |= (.virtual_power.user=$config[""ssh-user""]|.virtual_power.ssh_host=$config[""host-ip""]|.virtual_power.ssh_key=$config[""ssh-key""]|.arch=$config.arch|.power_manager=$config.power_manager))|.[0].ironic=""""| .[0]' config.json $TE_DATAFILE > tmp_local.json# Sets: # - ironic.virtual_power_ssh_key(needed until https://review.openstack.org/#/c/80376 lands). # - nova.compute_driver to ironic.nova.virt.ironic.driver.IronicDriver # - sets the nova.baremetal key to ""{}"" to disable configuration looking for baremetal configuration. # - sets the nova.compute_manager to avoid race conditions on ironic startup. jq -s '.[1] as $config |(.[0].ironic |= (.virtual_power_ssh_key=$config[""ssh-key""]))|.[0].nova.compute_driver=""ironic.nova.virt.ironic.driver.IronicDriver""|.[0].nova.compute_manager=""ironic.nova.compute.manager.ClusteredComputeManager""|.[0].nova.baremetal={}| .[0]' config.json $TE_DATAFILE > tmp_local.json",34,8
openstack%2Foslo.messaging~master~I08dafc4fa150d2213b2bb002da7c9ee0ee517fac,openstack/oslo.messaging,master,I08dafc4fa150d2213b2bb002da7c9ee0ee517fac,Enabled hacking checks H305 and H307,MERGED,2014-07-17 10:41:13.000000000,2014-07-18 08:30:09.000000000,2014-07-18 08:30:09.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 5638}, {'_account_id': 7763}]","[{'number': 1, 'created': '2014-07-17 10:41:13.000000000', 'files': ['tests/test_expected_exceptions.py', 'oslo/messaging/_cmd/zmq_receiver.py', 'tests/notify/test_log_handler.py', 'oslo/messaging/_executors/impl_eventlet.py', 'tests/rpc/test_server.py', 'tests/rpc/test_client.py', 'oslo/messaging/transport.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/_drivers/matchmaker_redis.py', 'tests/executors/test_executor.py', 'oslo/messaging/notify/notifier.py', 'oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/matchmaker_ring.py', 'tests/utils.py', 'oslo/messaging/notify/_impl_routing.py', 'tests/test_transport.py', 'oslo/messaging/_drivers/impl_zmq.py', 'oslo/messaging/rpc/client.py', 'oslo/messaging/_drivers/matchmaker.py', 'oslo/messaging/notify/logger.py', 'oslo/messaging/_drivers/amqp.py', 'tests/notify/test_listener.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5be1b6a6a93e2be1fd6adef109a016f49ed98b0a', 'message': 'Enabled hacking checks H305 and H307\n\n* H305  imports not grouped correctly\n* H307  like imports should be grouped together\n\nChange-Id: I08dafc4fa150d2213b2bb002da7c9ee0ee517fac\n'}]",0,107641,5be1b6a6a93e2be1fd6adef109a016f49ed98b0a,9,4,1,167,,,0,"Enabled hacking checks H305 and H307

* H305  imports not grouped correctly
* H307  like imports should be grouped together

Change-Id: I08dafc4fa150d2213b2bb002da7c9ee0ee517fac
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/41/107641/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_expected_exceptions.py', 'oslo/messaging/_cmd/zmq_receiver.py', 'tests/notify/test_log_handler.py', 'oslo/messaging/_executors/impl_eventlet.py', 'tests/rpc/test_server.py', 'tests/rpc/test_client.py', 'oslo/messaging/transport.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/_drivers/matchmaker_redis.py', 'tests/executors/test_executor.py', 'oslo/messaging/notify/notifier.py', 'oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/matchmaker_ring.py', 'tests/utils.py', 'oslo/messaging/notify/_impl_routing.py', 'tests/test_transport.py', 'oslo/messaging/_drivers/impl_zmq.py', 'oslo/messaging/rpc/client.py', 'oslo/messaging/_drivers/matchmaker.py', 'oslo/messaging/notify/logger.py', 'oslo/messaging/_drivers/amqp.py', 'tests/notify/test_listener.py', 'tox.ini']",24,5be1b6a6a93e2be1fd6adef109a016f49ed98b0a,enable_h305_h307,"ignore = E226,E241,E265,E714,H237,H402,H405,H904","ignore = E226,E241,E265,E714,H237,H305,H307,H402,H405,H904",19,22
openstack%2Fnova~master~I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90,openstack/nova,master,I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90,libvirt: speed up _get_disk_over_committed_size_total method,MERGED,2014-07-07 11:21:43.000000000,2014-07-18 08:29:54.000000000,2014-07-18 08:29:52.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6463}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-07 11:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/863963a1d6356aa742fbbb320c4371e052740750', 'message': 'libvirt: speed up _get_disk_over_committed_size_total method\n\nSwitch the _get_disk_over_committed_size_total method to\nuse the new list_instance_domains method.\n\nBlueprint: libvirt-domain-listing-speedup\nChange-Id: I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90\n'}, {'number': 2, 'created': '2014-07-07 12:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51ff0c85f838ee9f91ac3da1cd0701317adc3ac9', 'message': 'libvirt: speed up _get_disk_over_committed_size_total method\n\nSwitch the _get_disk_over_committed_size_total method to\nuse the new list_instance_domains method.\n\nBlueprint: libvirt-domain-listing-speedup\nChange-Id: I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90\n'}, {'number': 3, 'created': '2014-07-08 11:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5399ce562991f9df0cafc502ea372740ba7df441', 'message': 'libvirt: speed up _get_disk_over_committed_size_total method\n\nSwitch the _get_disk_over_committed_size_total method to\nuse the new list_instance_domains method.\n\nBlueprint: libvirt-domain-listing-speedup\nChange-Id: I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90\n'}, {'number': 4, 'created': '2014-07-11 15:17:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7daec882c6d01d621a885687abf82f24acc61d4e', 'message': 'libvirt: speed up _get_disk_over_committed_size_total method\n\nSwitch the _get_disk_over_committed_size_total method to\nuse the new list_instance_domains method.\n\nBlueprint: libvirt-domain-listing-speedup\nChange-Id: I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90\n'}, {'number': 5, 'created': '2014-07-15 16:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28ddbbab625f79909a2bc0311c275d09f49b2ce3', 'message': 'libvirt: speed up _get_disk_over_committed_size_total method\n\nSwitch the _get_disk_over_committed_size_total method to\nuse the new list_instance_domains method.\n\nBlueprint: libvirt-domain-listing-speedup\nChange-Id: I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90\n'}, {'number': 6, 'created': '2014-07-16 10:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b4534d126d581831c68b101000d8919bc160af1', 'message': 'libvirt: speed up _get_disk_over_committed_size_total method\n\nSwitch the _get_disk_over_committed_size_total method to\nuse the new list_instance_domains method.\n\nBlueprint: libvirt-domain-listing-speedup\nChange-Id: I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90\n'}, {'number': 7, 'created': '2014-07-16 11:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d732ea8a3a80d8d18968529ec9660d50e8fd8ab0', 'message': 'libvirt: speed up _get_disk_over_committed_size_total method\n\nSwitch the _get_disk_over_committed_size_total method to\nuse the new list_instance_domains method.\n\nBlueprint: libvirt-domain-listing-speedup\nChange-Id: I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90\n'}, {'number': 8, 'created': '2014-07-17 16:27:44.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4fc6f87af0399e9f2b8042629eecbd1f804ff7d7', 'message': 'libvirt: speed up _get_disk_over_committed_size_total method\n\nSwitch the _get_disk_over_committed_size_total method to\nuse the new list_instance_domains method.\n\nBlueprint: libvirt-domain-listing-speedup\nChange-Id: I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90\n'}]",2,105127,4fc6f87af0399e9f2b8042629eecbd1f804ff7d7,73,10,8,1779,,,0,"libvirt: speed up _get_disk_over_committed_size_total method

Switch the _get_disk_over_committed_size_total method to
use the new list_instance_domains method.

Blueprint: libvirt-domain-listing-speedup
Change-Id: I4ef00ea5584eda14c4781d3fbf8bb737f3abdc90
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/105127/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py']",2,863963a1d6356aa742fbbb320c4371e052740750,bp/libvirt-domain-listing-speedup," class DiagFakeDomain(object): def __init__(self, name): self._name = name def ID(self): return 1 def name(self): return self._name def UUIDString(self): return ""19479fee-07a5-49bb-9138-d3738280d63c"" def XMLDesc(self, flags): return ""<domain/>"" def fake_list_all(flags): return [DiagFakeDomain(""instance0000001""), DiagFakeDomain(""instance0000002"")] self.mox.StubOutWithMock(libvirt_driver.LibvirtDriver, '_conn') libvirt_driver.LibvirtDriver._conn.listAllDomains = fake_list_all self.mox.ReplayAll() drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) fake_disks = {'instance0000001': [{'type': 'qcow2', 'path': '/somepath/disk1', 'virt_disk_size': '10737418240', 'backing_file': '/somepath/disk1', 'disk_size': '83886080', 'over_committed_disk_size': '10653532160'}], 'instance0000002': [{'type': 'raw', 'path': '/somepath/disk2', 'virt_disk_size': '0', 'backing_file': '/somepath/disk2', 'disk_size': '10737418240', 'over_committed_disk_size': '0'}]} def get_info(instance_name, xml, **kwargs): self.stubs.Set(drvr, '_get_instance_disk_info', get_info) result = drvr._get_disk_over_committed_size_total() # Ensure destroy calls managedSaveRemove for saved instance. class DiagFakeDomain(object): def __init__(self, name): self._name = name def ID(self): return 1 def name(self): return self._name def UUIDString(self): return ""19479fee-07a5-49bb-9138-d3738280d63c"" def XMLDesc(self, flags): return ""<domain/>"" def fake_list_all(flags): return [DiagFakeDomain(""instance0000001""), DiagFakeDomain(""instance0000002"")] self.mox.StubOutWithMock(libvirt_driver.LibvirtDriver, '_conn') libvirt_driver.LibvirtDriver._conn.listAllDomains = fake_list_all self.mox.ReplayAll() drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) fake_disks = {'instance0000001': [{'type': 'qcow2', 'path': '/somepath/disk1', 'virt_disk_size': '10737418240', 'backing_file': '/somepath/disk1', 'disk_size': '83886080', 'over_committed_disk_size': '10653532160'}], 'instance0000002': [{'type': 'raw', 'path': '/somepath/disk2', 'virt_disk_size': '0', 'backing_file': '/somepath/disk2', 'disk_size': '10737418240', 'over_committed_disk_size': '21474836480'}]} def side_effect(name, dom): if name == 'instance0000001': if name == 'instance0000002': return jsonutils.dumps(fake_disks.get(name)) drvr._get_instance_disk_info = get_disk_info result = drvr._get_disk_over_committed_size_total()"," conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) def list_instances(): return ['fake1', 'fake2'] self.stubs.Set(conn, 'list_instances', list_instances) fake_disks = {'fake1': [{'type': 'qcow2', 'path': '/somepath/disk1', 'virt_disk_size': '10737418240', 'backing_file': '/somepath/disk1', 'disk_size': '83886080', 'over_committed_disk_size': '10653532160'}], 'fake2': [{'type': 'raw', 'path': '/somepath/disk2', 'virt_disk_size': '0', 'backing_file': '/somepath/disk2', 'disk_size': '10737418240', 'over_committed_disk_size': '0'}]} def get_info(instance_name, block_device_mapping=None): self.stubs.Set(conn, 'get_instance_disk_info', get_info) result = conn._get_disk_over_committed_size_total() driver = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) driver.list_instances = mock.Mock(return_value=['fake1', 'fake2']) fake_disks = {'fake1': [{'type': 'qcow2', 'path': '/somepath/disk1', 'virt_disk_size': '10737418240', 'backing_file': '/somepath/disk1', 'disk_size': '83886080', 'over_committed_disk_size': '10653532160'}], 'fake2': [{'type': 'raw', 'path': '/somepath/disk2', 'virt_disk_size': '0', 'backing_file': '/somepath/disk2', 'disk_size': '10737418240', 'over_committed_disk_size': '21474836480'}]} def side_effect(arg): if arg == 'fake1': if arg == 'fake2': return jsonutils.dumps(fake_disks.get(arg)) driver.get_instance_disk_info = get_disk_info result = driver._get_disk_over_committed_size_total()",97,43
openstack%2Ftrove~master~I414f05ed698dc7cf12894a10fee1e24f73739306,openstack/trove,master,I414f05ed698dc7cf12894a10fee1e24f73739306,database-delete API is not validating database,ABANDONED,2014-03-18 06:42:15.000000000,2014-07-18 08:29:06.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 7092}, {'_account_id': 8309}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-03-18 06:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3c07c860a8b142108461a504c4e1574bed60daeb', 'message': 'database-delete API is not validating database\n\nReason:\ndatabase-delete API not validating database\nbefore delete operation.\n\nChanges:\nDone validation before delete operation\n\nChange-Id: I414f05ed698dc7cf12894a10fee1e24f73739306\nCloses-Bug: #1293954\n'}, {'number': 2, 'created': '2014-05-06 11:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c8931f9edc1359d755332f2b164044c2e16b7132', 'message': 'database-delete API is not validating database\n\nReason:\ndatabase-delete API not validating database\nbefore delete operation.\n\nChanges:\nDone validation before delete operation\n\nChange-Id: I414f05ed698dc7cf12894a10fee1e24f73739306\nCloses-Bug: #1293954\n'}, {'number': 3, 'created': '2014-06-02 11:03:21.000000000', 'files': ['trove/extensions/mysql/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/5d622eb58cdb462c4e0d927b6f23a4cf92750199', 'message': 'database-delete API is not validating database\n\nReason:\ndatabase-delete API not validating database\nbefore delete operation.\n\nChanges:\nDone validation before delete operation\n\nChange-Id: I414f05ed698dc7cf12894a10fee1e24f73739306\nCloses-Bug: #1293954\n'}]",0,81186,5d622eb58cdb462c4e0d927b6f23a4cf92750199,37,6,3,8309,,,0,"database-delete API is not validating database

Reason:
database-delete API not validating database
before delete operation.

Changes:
Done validation before delete operation

Change-Id: I414f05ed698dc7cf12894a10fee1e24f73739306
Closes-Bug: #1293954
",git fetch https://review.opendev.org/openstack/trove refs/changes/86/81186/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/extensions/mysql/models.py'],1,3c07c860a8b142108461a504c4e1574bed60daeb,," client = create_guest_client(context, instance_id) schema_name = schema['_name'] existing_schema, _nadda = Schemas.load_with_client( client, limit=1, marker=schema_name, include_marker=True) if (len(existing_schema) > 0 and str(existing_schema[0].name) == str(schema_name)): client.delete_database(schema) else: raise exception.DatabaseNotFound(uuid=schema_name)"," create_guest_client(context, instance_id).delete_database(schema)",12,1
openstack%2Ftrove~master~I72733a9733330f7b771d21c0d00fabb38424ad7a,openstack/trove,master,I72733a9733330f7b771d21c0d00fabb38424ad7a,Show stack traces from taskmanager code in fake mode,ABANDONED,2014-05-02 22:40:36.000000000,2014-07-18 08:28:05.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-02 22:40:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f4cfe3839ef70115000a741b0d83b9a9c7c20e35', 'message': 'Show stack traces from taskmanager code in fake mode\n\nOvercomes a shortcoming in Oslo rpc.\n\nChange-Id: I72733a9733330f7b771d21c0d00fabb38424ad7a\nCloses-Bug: #1315561\n'}, {'number': 2, 'created': '2014-05-02 23:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4983c6f7909a75a5116aef3c5611c5cd98942722', 'message': 'Show stack traces from taskmanager code in fake mode\n\nOvercomes a shortcoming in Oslo rpc.\n\nChange-Id: I72733a9733330f7b771d21c0d00fabb38424ad7a\nCloses-Bug: #1315561\n'}, {'number': 3, 'created': '2014-05-02 23:36:20.000000000', 'files': ['run_tests.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/ee8ecb9b0bb5ed8527706f280f73bd6ceee5c405', 'message': 'Show stack traces from taskmanager code in fake mode\n\nOvercomes a shortcoming in Oslo rpc.\n\nChange-Id: I72733a9733330f7b771d21c0d00fabb38424ad7a\nCloses-Bug: #1315561\n'}]",0,91917,ee8ecb9b0bb5ed8527706f280f73bd6ceee5c405,19,4,3,694,,,0,"Show stack traces from taskmanager code in fake mode

Overcomes a shortcoming in Oslo rpc.

Change-Id: I72733a9733330f7b771d21c0d00fabb38424ad7a
Closes-Bug: #1315561
",git fetch https://review.opendev.org/openstack/trove refs/changes/17/91917/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.py'],1,f4cfe3839ef70115000a741b0d83b9a9c7c20e35,bug/1315561,"def fix_fake_cast(): """"""Fixes the RPC fake in Oslo to behave normally."""""" from trove.openstack.common.rpc import impl_fake fake_rpc_log = logging.getLogger(impl_fake.__name__) def cast(conf, context, topic, msg): impl_fake.check_serialize(msg) try: impl_fake.call(conf, context, topic, msg) except Exception: fake_rpc_log.exception(""Error during cast."") pass impl_fake.cast = cast fix_fake_cast()",,17,0
openstack%2Ftrove~master~If6e28dd41693960b678105f2d9d606b274e722aa,openstack/trove,master,If6e28dd41693960b678105f2d9d606b274e722aa,use LOG instead of logger as name for the Logger object,ABANDONED,2014-05-27 08:39:21.000000000,2014-07-18 08:24:44.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-05-27 08:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/dd89d87b86afb8a9fe6edc15a1183c278788d674', 'message': 'use LOG instead of logger as name for the Logger object\n\nChange-Id: If6e28dd41693960b678105f2d9d606b274e722aa\n'}, {'number': 2, 'created': '2014-06-03 06:40:59.000000000', 'files': ['trove/db/sqlalchemy/migrate_repo/versions/020_configurations.py', 'trove/db/sqlalchemy/migration.py', 'trove/db/sqlalchemy/migrate_repo/versions/025_add_service_statuses_indexes.py', 'trove/db/sqlalchemy/migrate_repo/schema.py', 'trove/db/sqlalchemy/migrate_repo/versions/023_add_instance_indexes.py', 'trove/db/sqlalchemy/migrate_repo/versions/026_datastore_versions_unique_fix.py', 'rsdns/client/dns_client.py', 'trove/db/sqlalchemy/migrate_repo/versions/024_add_backup_indexes.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/a456c72878a0ed8a3cc605663547a10c3319a756', 'message': 'use LOG instead of logger as name for the Logger object\n\nAlso used __name__ instead of hardcoded logger names.\n\nChange-Id: If6e28dd41693960b678105f2d9d606b274e722aa\n'}]",1,95686,a456c72878a0ed8a3cc605663547a10c3319a756,17,7,2,167,,,0,"use LOG instead of logger as name for the Logger object

Also used __name__ instead of hardcoded logger names.

Change-Id: If6e28dd41693960b678105f2d9d606b274e722aa
",git fetch https://review.opendev.org/openstack/trove refs/changes/86/95686/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/db/sqlalchemy/migrate_repo/versions/020_configurations.py', 'trove/db/sqlalchemy/migration.py', 'trove/db/sqlalchemy/migrate_repo/versions/025_add_service_statuses_indexes.py', 'trove/db/sqlalchemy/migrate_repo/schema.py', 'trove/db/sqlalchemy/migrate_repo/versions/023_add_instance_indexes.py', 'trove/db/sqlalchemy/migrate_repo/versions/026_datastore_versions_unique_fix.py', 'trove/db/sqlalchemy/migrate_repo/versions/024_add_backup_indexes.py']",7,dd89d87b86afb8a9fe6edc15a1183c278788d674,use_log,LOG = logging.getLogger('trove.db.sqlalchemy.migrate_repo.schema') LOG.info(e) LOG.info(e),logger = logging.getLogger('trove.db.sqlalchemy.migrate_repo.schema') logger.info(e) logger.info(e),20,20
openstack%2Ftripleo-incubator~master~Ia07adc3b85d20c45293fe62d4abca9ec270787ef,openstack/tripleo-incubator,master,Ia07adc3b85d20c45293fe62d4abca9ec270787ef,Fix setup-endpoints handling of public URLs.,MERGED,2014-07-06 23:39:46.000000000,2014-07-18 08:23:40.000000000,2014-07-18 08:23:40.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6796}, {'_account_id': 9369}, {'_account_id': 9453}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-07-06 23:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/8f8cab9297a5dd1a507ccc5af7a5ed73dacfd7ed', 'message': 'Fix setup-endpoints handling of public URLs.\n\nWe were always registering heat, tuskar and ironic with internal URLs,\neven if SSL was requested - this breaks things when the internal URL\nis on an unreachable network for clients.\n\nChange-Id: Ia07adc3b85d20c45293fe62d4abca9ec270787ef\n'}, {'number': 2, 'created': '2014-07-16 05:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ee9d8160fb9a47f9ec5a52c41b35b94737d74278', 'message': 'Fix setup-endpoints handling of public URLs.\n\nWe were always registering heat, tuskar and ironic with internal URLs,\neven if SSL was requested - this breaks things when the internal URL\nis on an unreachable network for clients.\n\nChange-Id: Ia07adc3b85d20c45293fe62d4abca9ec270787ef\n'}, {'number': 3, 'created': '2014-07-17 19:09:43.000000000', 'files': ['scripts/setup-endpoints'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/82f201df41cd6b4c8fd06313fc06f3f94a68729b', 'message': 'Fix setup-endpoints handling of public URLs.\n\nWe were always registering heat, tuskar and ironic with internal URLs,\neven if SSL was requested - this breaks things when the internal URL\nis on an unreachable network for clients.\n\nChange-Id: Ia07adc3b85d20c45293fe62d4abca9ec270787ef\n'}]",1,105044,82f201df41cd6b4c8fd06313fc06f3f94a68729b,21,6,3,4190,,,0,"Fix setup-endpoints handling of public URLs.

We were always registering heat, tuskar and ironic with internal URLs,
even if SSL was requested - this breaks things when the internal URL
is on an unreachable network for clients.

Change-Id: Ia07adc3b85d20c45293fe62d4abca9ec270787ef
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/44/105044/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/setup-endpoints'],1,8f8cab9297a5dd1a507ccc5af7a5ed73dacfd7ed,vlan,"PASSWORD=$HEAT_PASSWORD register-endpoint $DEBUG -r $REGION -d ""Heat Service"" heat orchestration -i ${INTERNAL_HOST}${NORMAL_PORT} ${PUBLIC_HOST}${SSL_PORT} PASSWORD=$IRONIC_PASSWORD register-endpoint $DEBUG -r $REGION -d ""Ironic Service"" ironic baremetal -i ${INTERNAL_HOST}6385 ${PUBLIC_HOST}6385 PASSWORD=$TUSKAR_PASSWORD register-endpoint $DEBUG -r $REGION -d ""Tuskar Service"" tuskar management -i ${INTERNAL_HOST}8585 ${PUBLIC_HOST}8585","PASSWORD=$HEAT_PASSWORD register-endpoint $DEBUG -r $REGION -d ""Heat Service"" heat orchestration -i ${INTERNAL_HOST}${NORMAL_PORT} ${INTERNAL_HOST}${SSL_PORT} PASSWORD=$IRONIC_PASSWORD register-endpoint $DEBUG -r $REGION -d ""Ironic Service"" ironic baremetal http://$HOST:6385 PASSWORD=$TUSKAR_PASSWORD register-endpoint $DEBUG -r $REGION -d ""Tuskar Service"" tuskar management http://$HOST:8585",3,3
openstack%2Ftripleo-incubator~master~I2a1ef0c2933b9beb42382292c40e79eed3a2a288,openstack/tripleo-incubator,master,I2a1ef0c2933b9beb42382292c40e79eed3a2a288,Use mariadb by default on fedora,MERGED,2014-06-26 12:56:48.000000000,2014-07-18 08:21:29.000000000,2014-07-18 08:21:29.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 6969}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 8532}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-06-26 12:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/45e008a262ae1acd8a5436a8bb35cce2f739d0e9', 'message': 'Use mariadb by default on fedora\n\nmariadb-galera-server is now included directly in fedora repositories so\nit makes sense to use galera packages from distribution. Another benefit\nis that mariadb-rpm element will be covered by CI tests.\n\nRelies on: I90e7ca4803516b86179b0f6639e307a60297960b\n\nChange-Id: I2a1ef0c2933b9beb42382292c40e79eed3a2a288\n'}, {'number': 2, 'created': '2014-06-27 05:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/fee60664a830fe7d33eff06708aabb2fac68e4fe', 'message': 'Use mariadb by default on fedora\n\nmariadb-galera-server is now included directly in fedora repositories so\nit makes sense to use galera packages from distribution. Another benefit\nis that mariadb-rpm element will be covered by CI tests.\n\nRelies on: I90e7ca4803516b86179b0f6639e307a60297960b\n\nChange-Id: I2a1ef0c2933b9beb42382292c40e79eed3a2a288\n'}, {'number': 3, 'created': '2014-07-03 12:13:50.000000000', 'files': ['scripts/devtest_undercloud.sh', 'scripts/devtest_variables.sh', 'scripts/devtest_overcloud.sh', 'scripts/boot-seed-vm'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/8226d94cfb3a1e6aaf0d8f235c7756baf53ac7d6', 'message': 'Use mariadb by default on fedora\n\nmariadb-galera-server is now included directly in fedora repositories so\nit makes sense to use galera packages from distribution. Another benefit\nis that mariadb-rpm element will be covered by CI tests.\n\nRelies on: I90e7ca4803516b86179b0f6639e307a60297960b\n\nChange-Id: I2a1ef0c2933b9beb42382292c40e79eed3a2a288\n'}]",3,102818,8226d94cfb3a1e6aaf0d8f235c7756baf53ac7d6,63,9,3,7582,,,0,"Use mariadb by default on fedora

mariadb-galera-server is now included directly in fedora repositories so
it makes sense to use galera packages from distribution. Another benefit
is that mariadb-rpm element will be covered by CI tests.

Relies on: I90e7ca4803516b86179b0f6639e307a60297960b

Change-Id: I2a1ef0c2933b9beb42382292c40e79eed3a2a288
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/18/102818/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/devtest_undercloud.sh', 'scripts/devtest_variables.sh', 'scripts/devtest_overcloud.sh', 'scripts/boot-seed-vm']",4,45e008a262ae1acd8a5436a8bb35cce2f739d0e9,maria,"if [ ""$USE_MARIADB"" -eq 0 ] ; then SEED_DIB_EXTRA_ARGS=""$SEED_DIB_EXTRA_ARGS mariadb-rpm"" fi ",,28,0
openstack%2Ftripleo-incubator~master~I4524cb686f2b1ccbcbdd5018260869abc3117870,openstack/tripleo-incubator,master,I4524cb686f2b1ccbcbdd5018260869abc3117870,Separate Heat BM and VM configs for Nova-BM.,ABANDONED,2014-04-24 09:08:08.000000000,2014-07-18 08:20:39.000000000,,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1528}, {'_account_id': 1706}, {'_account_id': 4190}, {'_account_id': 6348}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 7585}, {'_account_id': 8041}, {'_account_id': 8449}, {'_account_id': 8688}, {'_account_id': 9420}, {'_account_id': 10035}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-04-24 09:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/6fea8e0ee816764d615a492b7e48ee02b311cd30', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 2, 'created': '2014-04-24 09:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/29bc5c0016ad485422f7a5406a25fd2594e735c8', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 3, 'created': '2014-04-24 09:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/dc21fa53d2f60da4d9c9cd95cdba78f7135db017', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 4, 'created': '2014-04-24 09:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/4664593b75a7a4ab1a8041b70340aa5dde66e3e4', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 5, 'created': '2014-04-24 11:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/647e98dc6934ebef5dd0e23c73993edb9d02a8e0', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 6, 'created': '2014-04-24 12:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/87ad856d9d26dd0f5de13a041df5929f8f2ab75e', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 7, 'created': '2014-04-24 12:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/d53bb4a58aae9f9ed9eb295e61ef82673e65fa33', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 8, 'created': '2014-04-29 17:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/7fdfa814c515c02c0e1a8a9ab60bcae22a472704', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 9, 'created': '2014-05-02 13:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/60de17ca9bf97a655a5eae06e310fdaeaf798962', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 10, 'created': '2014-05-02 13:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/3b303830e8aadcfde797dae19a10b6a010b56d66', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 11, 'created': '2014-05-02 13:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/8f72712b5e635a2bb2c2db0c3ade42e39c472ab3', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 12, 'created': '2014-05-02 17:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f18eb1dd0f9b562d9914e59ffdebad9696c5b7a8', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 13, 'created': '2014-05-02 18:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/95626039d3d018c59a99c5c26f98d6eb60482ad0', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 14, 'created': '2014-05-06 07:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/bcc2fce235993d595a3f6ea2e8dcdbaf5b2f93fa', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 15, 'created': '2014-05-06 11:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/b3f00034207d7812b52f63b2dc25ea93db8a9645', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 16, 'created': '2014-05-06 11:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f1ecf9a97c60632b6a81170df9c4fa7b2aff5038', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 17, 'created': '2014-05-06 13:10:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/37725c7db950d024c5004a3913155ab664825562', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 18, 'created': '2014-05-06 14:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/74878ab6afe723704f802ef832526b211f9d4977', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 19, 'created': '2014-05-07 08:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/d0b5276f652b8892af76d8b21e48c24e388cfd53', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 20, 'created': '2014-05-08 19:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/82db7d7958166b13ad09e53d4a0780b86380bc61', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 21, 'created': '2014-05-09 09:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/c554845098b548d33bc99d9536c8ccd97bfec8a8', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 22, 'created': '2014-05-13 14:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/9f46743cfb2b747be73fa34b61a939ca00f294ab', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 23, 'created': '2014-05-14 12:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/0612e40241d1cb94b0678eac3977ff14fb8c7d23', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 24, 'created': '2014-05-16 11:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/213591fb25a480ed29757db069a6a5ecae7bf70d', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 25, 'created': '2014-05-19 13:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/8114778dfab028a11d3beb676340fbaf411ddcad', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 26, 'created': '2014-05-21 09:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/9c910f8b42fd71f913a4c84e5d87de3c4895347a', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 27, 'created': '2014-05-21 14:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/93255fcc54b3de60c8b3648b68959914474b8ff7', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 28, 'created': '2014-05-22 12:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/aacdd7f281d91bfbea08618f35608c1c7f9f4547', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 29, 'created': '2014-05-29 11:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e1372ef89a2a2987164629724a010b4ebbfb0504', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 30, 'created': '2014-06-02 08:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/8e9f04aa8c9b177ef93acf6f35dc74a1048f556b', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 31, 'created': '2014-06-03 17:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ce51c517b74191eee152c2379f193a43f44fa08b', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 32, 'created': '2014-06-04 10:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/3ae662118e4c75880eb590c917ac2cbc2527b5ae', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 33, 'created': '2014-06-06 11:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e2b494d48bbaa458e500f1f705e5e4109afce60f', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 34, 'created': '2014-06-06 11:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/31254be34dbaf42556e03b507c3409c6e340f2c3', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 35, 'created': '2014-06-06 11:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/0e6b473d8eb226184e5cb54e0ffff783523a6438', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 36, 'created': '2014-06-06 11:57:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f2cb56331c2c13ec5419d630166844001c1b4792', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 37, 'created': '2014-06-06 16:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/965ef586d35abb8f06bdfb4bdd3392b1ae8375ed', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 38, 'created': '2014-06-12 15:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/17af6d391ce0ab661b3b1783dd3cdb9f92c703bc', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 39, 'created': '2014-06-16 11:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/1608ddc055a275d75a713beac7867e2a545bc177', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 40, 'created': '2014-06-19 18:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/bec80d8fbff1671569f5f652f0c7b0315fa07f46', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 41, 'created': '2014-06-25 10:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ba130eb2b47c77d086a119a538a78a8efca8f0fb', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 42, 'created': '2014-07-01 10:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/24a4dc660cda8423583d7f326b5ea7f14a182a69', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 43, 'created': '2014-07-15 17:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/23587d119a45d813f9212a31fe44019b97471b4e', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}, {'number': 44, 'created': '2014-07-17 14:36:59.000000000', 'files': ['scripts/devtest_undercloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/c649376740bc55612588c385682c161ed375634c', 'message': 'Separate Heat BM and VM configs for Nova-BM.\n\nAllow BM and VM to have different Heat configuration for the\nundercloud node when using Nova-baremetal\n\nChange-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870\n'}]",5,90033,c649376740bc55612588c385682c161ed375634c,192,15,44,10373,,,0,"Separate Heat BM and VM configs for Nova-BM.

Allow BM and VM to have different Heat configuration for the
undercloud node when using Nova-baremetal

Change-Id: I4524cb686f2b1ccbcbdd5018260869abc3117870
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/33/90033/37 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_undercloud.sh'],1,6fea8e0ee816764d615a492b7e48ee02b311cd30,HEAT_BM_VM,"if [ ""$USE_IRONIC"" -eq 0 && ""$POWER_MANAGER"" = 'nova.virt.baremetal.virtual_power_driver.VirtualPowerManager' ] ; then #nodocs POWER_HOST=$(os-apply-config -m $TE_DATAFILE --key host-ip --type raw) POWER_USER=$(os-apply-config -m $TE_DATAFILE --key ssh-user --type raw) HEAT_UNDERCLOUD_EXTRA_OPTS=""-P \""PowerManager=${POWER_MANAGER}\"" \ -P \""PowerSSHHost=${POWER_HOST}\"" \ -P \""PowerUserName=${POWER_USER}\"""" elif [ ""$USE_IRONIC"" -eq 0 ] ; then #nodocs HEAT_UNDERCLOUD_TEMPLATE=""undercloud-bm.yaml"" HEAT_UNDERCLOUD_EXTRA_OPTS=""-P \""PowerManager=${POWER_MANAGER}\"""" REGISTER_SERVICE_OPTS="""" else #nodocs ## #. If we using 'nova.virt.baremetal.virtual_power_driver.VirtualPowerManager ## as the POWER_MANAGER we need the POWER_KEY for undercloud-vm and ## undercloud-vm-ironic. ## :: if [ ""$POWER_MANAGER"" = 'nova.virt.baremetal.virtual_power_driver.VirtualPowerManager' ] ; then #nodocs POWER_KEY=$(os-apply-config -m $TE_DATAFILE --key ssh-key --type raw) HEAT_UNDERCLOUD_EXTRA_OPTS=""${HEAT_UNDERCLOUD_EXTRA_OPTS} \ -P \""PowerSSHPrivateKey=${POWER_KEY}\"""" fi eval heat stack-create -f $TRIPLEO_ROOT/tripleo-heat-templates/$HEAT_UNDERCLOUD_TEMPLATE \ ""${HEAT_UNDERCLOUD_EXTRA_OPTS}"" \","if [ ""$USE_IRONIC"" -eq 0 ] ; then HEAT_UNDERCLOUD_EXTRA_OPTS=""-P PowerSSHHost=${POWER_HOST} -P PowerManager=${POWER_MANAGER} -P PowerUserName=${POWER_USER}""elseheat stack-create -f $TRIPLEO_ROOT/tripleo-heat-templates/$HEAT_UNDERCLOUD_TEMPLATE \ ${HEAT_UNDERCLOUD_EXTRA_OPTS} \",35,6
openstack%2Ftripleo-heat-templates~master~I44909005d9bc653c3e7c2de1c12fe4ffecf6bede,openstack/tripleo-heat-templates,master,I44909005d9bc653c3e7c2de1c12fe4ffecf6bede,Add corosync and pacemaker properties into overcloud template,MERGED,2014-07-08 08:51:51.000000000,2014-07-18 07:56:40.000000000,2014-07-18 07:56:39.000000000,"[{'_account_id': 3}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-07-08 08:51:51.000000000', 'files': ['overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/423b18def2cbda44686da600fecc13142596e718', 'message': 'Add corosync and pacemaker properties into overcloud template\n\nPacemaker will be used for managing ceilometer central agent,\nwe need basic metadata to setup corosync and pacemaker.\n\nRelated to: Ifa83d62c2132bcdcb40d0b7c80ce3adadc0b5587\n\nChange-Id: I44909005d9bc653c3e7c2de1c12fe4ffecf6bede\n'}]",0,105395,423b18def2cbda44686da600fecc13142596e718,11,3,1,7582,,,0,"Add corosync and pacemaker properties into overcloud template

Pacemaker will be used for managing ceilometer central agent,
we need basic metadata to setup corosync and pacemaker.

Related to: Ifa83d62c2132bcdcb40d0b7c80ce3adadc0b5587

Change-Id: I44909005d9bc653c3e7c2de1c12fe4ffecf6bede
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/95/105395/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-source.yaml'],1,423b18def2cbda44686da600fecc13142596e718,pcmk," corosync: bindnetaddr: {get_input: controller_host} mcastport: 5577 nodes: Merge::Map: controller0: ip: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [controller0, networks]} ]} ] } pacemaker: stonith_enabled : false recheck_interval : 5 quorum_policy : ignore",,11,0
openstack%2Fironic~master~I15edc4fba337efe1c02b5e6774e4a7203bea3b73,openstack/ironic,master,I15edc4fba337efe1c02b5e6774e4a7203bea3b73,Migration to oslo.db,ABANDONED,2014-05-05 15:19:04.000000000,2014-07-18 07:49:35.000000000,,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6623}, {'_account_id': 6773}]","[{'number': 1, 'created': '2014-05-05 15:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9dd6d99a22b32b33a98123b1a69f27fc204c9b05', 'message': 'Migration to oslo.db\n\nReplace oslo-incubator db modules with the\nproject oslo.db\n\nChange-Id: I15edc4fba337efe1c02b5e6774e4a7203bea3b73\n'}, {'number': 2, 'created': '2014-06-16 13:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/aedda94a1653d3bc0d2186290b0bf6b630b87545', 'message': 'Migration to oslo.db\n\nReplace oslo-incubator db modules with the\nproject oslo.db\n\nChange-Id: I15edc4fba337efe1c02b5e6774e4a7203bea3b73\n'}, {'number': 3, 'created': '2014-06-16 17:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b3b6757ca0ddaed1406256dfca2e37f7263de99b', 'message': 'Migration to oslo.db\n\nReplace oslo-incubator db modules with the\nproject oslo.db\n\nChange-Id: I15edc4fba337efe1c02b5e6774e4a7203bea3b73\n'}, {'number': 4, 'created': '2014-06-18 09:41:48.000000000', 'files': ['ironic/openstack/common/db/sqlalchemy/migration_cli/ext_alembic.py', 'ironic/db/migration.py', 'ironic/openstack/common/db/options.py', 'ironic/openstack/common/db/sqlalchemy/migration_cli/manager.py', 'ironic/openstack/common/db/sqlalchemy/utils.py', 'ironic/tests/db/sqlalchemy/test_types.py', 'ironic/tests/api/v1/test_chassis.py', 'tools/config/oslo.config.generator.rc', 'ironic/tests/api/v1/test_nodes.py', 'ironic/openstack/common/db/sqlalchemy/migration_cli/ext_migrate.py', 'ironic/openstack/common/db/sqlalchemy/provision.py', 'requirements.txt', 'etc/ironic/ironic.conf.sample', 'ironic/db/sqlalchemy/api.py', 'ironic/openstack/common/db/sqlalchemy/test_base.py', 'ironic/openstack/common/db/sqlalchemy/test_migrations.py', 'openstack-common.conf', 'ironic/openstack/common/db/sqlalchemy/migration.py', 'ironic/openstack/common/db/sqlalchemy/models.py', 'ironic/openstack/common/db/sqlalchemy/migration_cli/__init__.py', 'ironic/openstack/common/db/sqlalchemy/migration_cli/ext_base.py', 'ironic/openstack/common/db/__init__.py', 'ironic/openstack/common/db/exception.py', 'ironic/openstack/common/db/api.py', 'ironic/tests/db/sqlalchemy/test_migrations.py', 'ironic/tests/api/v1/test_ports.py', 'ironic/tests/base.py', 'ironic/openstack/common/db/sqlalchemy/__init__.py', 'ironic/openstack/common/db/sqlalchemy/session.py', 'ironic/db/sqlalchemy/models.py', 'ironic/db/api.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/aaf0fbaa8603ca2fa0484bb45397b681229d99bc', 'message': 'Migration to oslo.db\n\nReplace oslo-incubator db modules with the\nproject oslo.db\n\nChange-Id: I15edc4fba337efe1c02b5e6774e4a7203bea3b73\n'}]",0,92138,aaf0fbaa8603ca2fa0484bb45397b681229d99bc,22,4,4,1726,,,0,"Migration to oslo.db

Replace oslo-incubator db modules with the
project oslo.db

Change-Id: I15edc4fba337efe1c02b5e6774e4a7203bea3b73
",git fetch https://review.opendev.org/openstack/ironic refs/changes/38/92138/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/openstack/common/db/sqlalchemy/migration_cli/ext_alembic.py', 'ironic/db/migration.py', 'ironic/openstack/common/db/options.py', 'ironic/openstack/common/db/sqlalchemy/migration_cli/manager.py', 'ironic/openstack/common/db/sqlalchemy/utils.py', 'ironic/tests/db/sqlalchemy/test_types.py', 'ironic/tests/api/v1/test_chassis.py', 'tools/config/oslo.config.generator.rc', 'ironic/tests/api/v1/test_nodes.py', 'ironic/openstack/common/db/sqlalchemy/migration_cli/ext_migrate.py', 'ironic/openstack/common/db/sqlalchemy/provision.py', 'requirements.txt', 'etc/ironic/ironic.conf.sample', 'ironic/db/sqlalchemy/api.py', 'ironic/openstack/common/db/sqlalchemy/test_base.py', 'ironic/openstack/common/db/sqlalchemy/test_migrations.py', 'ironic/tests/db/test_nodes.py', 'openstack-common.conf', 'ironic/openstack/common/db/sqlalchemy/migration.py', 'ironic/tests/db/test_conductor.py', 'ironic/openstack/common/db/sqlalchemy/models.py', 'ironic/openstack/common/db/sqlalchemy/migration_cli/__init__.py', 'ironic/openstack/common/db/sqlalchemy/migration_cli/ext_base.py', 'ironic/openstack/common/db/__init__.py', 'ironic/openstack/common/db/exception.py', 'ironic/openstack/common/db/api.py', 'ironic/tests/db/sqlalchemy/test_migrations.py', 'ironic/tests/api/v1/test_ports.py', 'ironic/tests/base.py', 'ironic/openstack/common/db/sqlalchemy/__init__.py', 'ironic/openstack/common/db/sqlalchemy/session.py', 'ironic/db/sqlalchemy/models.py', 'ironic/db/api.py']",33,9dd6d99a22b32b33a98123b1a69f27fc204c9b05,oslo.db,"from oslo.db import api as db_apiCONF.import_opt('backend', 'oslo.db.options',","from ironic.openstack.common.db import api as db_api CONF.import_opt('backend', 'ironic.openstack.common.db.options',",38,3209
openstack%2Fnova~master~Ie651eac86075809bde116c4c1af6f8282cb357b0,openstack/nova,master,Ie651eac86075809bde116c4c1af6f8282cb357b0,Correct the error report when resize-confirm fail,ABANDONED,2014-04-03 03:41:21.000000000,2014-07-18 07:33:24.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8163}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 10614}]","[{'number': 1, 'created': '2014-04-03 03:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e70d69562381b0336a0b1b475151c48c074d14eb', 'message': 'Correct the error report when resize-confirm fail\n\nwhenever confirm resize failed, it will report following reason\n[root@controller ~]# nova resize-confirm test15\nERROR: Instance has not been resized. (HTTP 400)\nif user run confirm_resize 2 times concurrently ,\n2nd run will riase MigrationNotFoundByStatus exception because\nmigration status already updated to confirming,\nwe need to report error info more accurately\n\nChange-Id: Ie651eac86075809bde116c4c1af6f8282cb357b0\nCloses-Bug: #1301689\n'}, {'number': 2, 'created': '2014-04-08 06:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f56ab8e809741b3d71a5b2c2b228e2bbdfe3defd', 'message': 'Correct the error report when resize-confirm fail\n\nwhenever confirm resize failed, it will report following reason\n[root@controller ~]# nova resize-confirm test15\nERROR: Instance has not been resized. (HTTP 400)\nif user run confirm_resize 2 times concurrently ,\n2nd run will raise MigrationNotFoundByStatus exception because\nmigration status already updated to confirming,\nwe need to report error info more accurately\n\nChange-Id: Ie651eac86075809bde116c4c1af6f8282cb357b0\nCloses-Bug: #1301689\n'}, {'number': 3, 'created': '2014-07-03 06:14:38.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/servers.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fea69b68f2421654d45e3509adfbb98342ce7003', 'message': 'Correct the error report when resize-confirm fail\n\nwhenever confirm resize failed, it will report following reason\n[root@controller ~]# nova resize-confirm test15\nERROR: Instance has not been resized. (HTTP 400)\nif user run confirm_resize 2 times concurrently ,\n2nd run will raise MigrationNotFoundByStatus exception because\nmigration status already updated to confirming,\nwe need to report error info more accurately\n\nChange-Id: Ie651eac86075809bde116c4c1af6f8282cb357b0\nCloses-Bug: #1301689\n'}]",2,84931,fea69b68f2421654d45e3509adfbb98342ce7003,42,14,3,6062,,,0,"Correct the error report when resize-confirm fail

whenever confirm resize failed, it will report following reason
[root@controller ~]# nova resize-confirm test15
ERROR: Instance has not been resized. (HTTP 400)
if user run confirm_resize 2 times concurrently ,
2nd run will raise MigrationNotFoundByStatus exception because
migration status already updated to confirming,
we need to report error info more accurately

Change-Id: Ie651eac86075809bde116c4c1af6f8282cb357b0
Closes-Bug: #1301689
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/84931/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/servers.py', 'nova/api/openstack/compute/servers.py']",2,e70d69562381b0336a0b1b475151c48c074d14eb,bug/1301689, except exception.MigrationNotFound as e: raise exc.HTTPBadRequest(explanation=e.format_message())," except exception.MigrationNotFound: msg = _(""Instance has not been resized."") raise exc.HTTPBadRequest(explanation=msg)",4,6
openstack%2Fopenstack-manuals~master~I78c3bf3f42814a60ef977e400ea4b5afacf94358,openstack/openstack-manuals,master,I78c3bf3f42814a60ef977e400ea4b5afacf94358,Added designate to list of developer documentation,MERGED,2014-07-17 13:20:25.000000000,2014-07-18 07:32:08.000000000,2014-07-18 07:32:06.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 741}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-07-17 13:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e788e9b0f59d4a321d1b4098a9af549d03775e3a', 'message': 'Added designate to list of developer documentation\n\nChange-Id: I78c3bf3f42814a60ef977e400ea4b5afacf94358\n'}, {'number': 2, 'created': '2014-07-17 20:41:03.000000000', 'files': ['www/developer/openstack-projects.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9ec197c23d55530412219be6d09ad410a2c224d2', 'message': 'Added designate to list of developer documentation\n\nChange-Id: I78c3bf3f42814a60ef977e400ea4b5afacf94358\n'}]",1,107691,9ec197c23d55530412219be6d09ad410a2c224d2,13,5,2,8099,,,0,"Added designate to list of developer documentation

Change-Id: I78c3bf3f42814a60ef977e400ea4b5afacf94358
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/91/107691/2 && git format-patch -1 --stdout FETCH_HEAD,['www/developer/openstack-projects.html'],1,e788e9b0f59d4a321d1b4098a9af549d03775e3a,," <dd> <a href=""http://docs.openstack.org/developer/designate/""> DNS Services Developer Documentation (designate) </a> </dd>",,5,0
openstack%2Fopenstack-manuals~master~I4ebd43efb8110081118f5713533e9e7fe901d0c0,openstack/openstack-manuals,master,I4ebd43efb8110081118f5713533e9e7fe901d0c0,Edit on common/section_getstart_object-storage,MERGED,2014-07-14 18:20:22.000000000,2014-07-18 07:32:00.000000000,2014-07-18 07:31:59.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-07-14 18:20:22.000000000', 'files': ['doc/common/section_getstart_object-storage.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/af5bb7213e278f64384ba9046c5e88d8af967f1e', 'message': 'Edit on common/section_getstart_object-storage\n\nImprove sentence\n\nChange-Id: I4ebd43efb8110081118f5713533e9e7fe901d0c0\nCloses-Bug: #1341375\n'}]",0,106834,af5bb7213e278f64384ba9046c5e88d8af967f1e,11,4,1,6547,,,0,"Edit on common/section_getstart_object-storage

Improve sentence

Change-Id: I4ebd43efb8110081118f5713533e9e7fe901d0c0
Closes-Bug: #1341375
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/34/106834/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/section_getstart_object-storage.xml'],1,af5bb7213e278f64384ba9046c5e88d8af967f1e,bug/1341375," performance, the proxy server can use an optional cache that is usually deployed with memcache.</para></listitem> <listitem><para>Manages accounts defined with Object"," performance, the proxy server can use an optional cache usually deployed with memcache.</para></listitem> <listitem><para>Manages accounts defined with Object",3,3
openstack%2Fopenstack-manuals~master~Ib33e9fbe146238f80b248649e4637bf0d860b1ff,openstack/openstack-manuals,master,Ib33e9fbe146238f80b248649e4637bf0d860b1ff,Imported Translations from Transifex,MERGED,2014-07-18 06:10:07.000000000,2014-07-18 07:27:37.000000000,2014-07-18 07:27:36.000000000,"[{'_account_id': 3}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-07-18 06:10:07.000000000', 'files': ['doc/image-guide/locale/image-guide.pot', 'doc/common/locale/common.pot', 'doc/glossary/locale/ko_KR.po', 'doc/common/locale/ja.po', 'doc/glossary/locale/ja.po', 'doc/common/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1a8a41e3e892d9e5bb74d599884a6c06c5e7d85e', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib33e9fbe146238f80b248649e4637bf0d860b1ff\n'}]",0,107905,1a8a41e3e892d9e5bb74d599884a6c06c5e7d85e,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Ib33e9fbe146238f80b248649e4637bf0d860b1ff
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/05/107905/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/image-guide/locale/image-guide.pot', 'doc/common/locale/common.pot', 'doc/glossary/locale/ko_KR.po', 'doc/common/locale/ja.po', 'doc/glossary/locale/ja.po', 'doc/common/locale/fr.po']",6,1a8a41e3e892d9e5bb74d599884a6c06c5e7d85e,transifex/translations,"""POT-Creation-Date: 2014-07-17 22:22+0000\n"" ""PO-Revision-Date: 2014-07-18 05:41+0000\n""#: ./doc/common/ch_cli_trove-manage_commands.xml17(para)#: ./doc/common/ch_cli_trove-manage_commands.xml20(replaceable)#: ./doc/common/ch_cli_trove-manage_commands.xml202(para)#: ./doc/common/ch_cli_trove-manage_commands.xml236(title) #: ./doc/common/ch_cli_trove-manage_commands.xml311(title) #: ./doc/common/ch_cli_trove-manage_commands.xml339(title) #: ./doc/common/ch_cli_trove-manage_commands.xml375(title) #: ./doc/common/ch_cli_trove-manage_commands.xml392(title) #: ./doc/common/ch_cli_trove-manage_commands.xml418(title)#: ./doc/common/ch_cli_trove-manage_commands.xml216(title) #: ./doc/common/ch_cli_trove-manage_commands.xml256(title) #: ./doc/common/ch_cli_trove-manage_commands.xml328(title) #: ./doc/common/ch_cli_trove-manage_commands.xml364(title)#: ./doc/common/section_cli_keystone_services.xml102(para)#: ./doc/common/ch_cli_trove-manage_commands.xml41(para) #: ./doc/common/ch_cli_trove-manage_commands.xml240(para) #: ./doc/common/ch_cli_trove-manage_commands.xml315(para) #: ./doc/common/ch_cli_trove-manage_commands.xml343(para) #: ./doc/common/ch_cli_trove-manage_commands.xml379(para) #: ./doc/common/ch_cli_trove-manage_commands.xml396(para) #: ./doc/common/ch_cli_trove-manage_commands.xml422(para)msgstr ""KEYSTONE_DBPASS""#: ./doc/common/section_cli_keystone_services.xml99(para)#: ./doc/common/section_cli_keystone_services.xml101(replaceable)#: ./doc/common/section_cli_keystone_services.xml117(title)#: ./doc/common/section_cli_keystone_services.xml120(para)#: ./doc/common/section_cli_keystone_services.xml125(para)#: ./doc/common/section_cli_keystone_services.xml126(para)#: ./doc/common/section_cli_keystone_services.xml138(para)#: ./doc/common/section_cli_keystone_services.xml142(para)#: ./doc/common/section_cli_keystone_services.xml158(para)#: ./doc/common/section_cli_keystone_services.xml160(replaceable)#: ./doc/common/section_cli_keystone_services.xml160(replaceable)#: ./doc/common/section_cli_keystone_services.xml160(replaceable)#: ./doc/common/section_cli_keystone_services.xml165(title)#: ./doc/common/section_cli_keystone_services.xml166(para)#: ./doc/common/section_cli_keystone_services.xml167(replaceable)#: ./doc/common/ch_cli_trove-manage_commands.xml12(title) msgid ""Database Service Management command-line client"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml13(para) msgid """" ""The <placeholder-1/> client is the command-line interface (CLI) for the "" ""Database Management Utility and its extensions. This chapter documents "" ""<placeholder-2/> version 2014.2."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml20(option) msgid ""--help"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml23(title) msgid ""trove-manage usage"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml36(title) msgid ""trove-manage optional arguments"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml49(para) msgid """" ""Path to a config directory to pull *.conf files from. This file set is "" ""sorted, so as to provide a predictable parse order if individual options are"" "" over-ridden. The set is parsed after the file(s) specified via previous "" ""--config-file, arguments hence over-ridden options in the directory take "" ""precedence."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml62(para) msgid """" ""Path to a config file to use. Multiple config files can be specified, with "" ""values in later files taking precedence. The default files used are: None."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml72(para) msgid """" ""Print debugging output (set logging level to DEBUG instead of default "" ""WARNING level)."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml81(para) msgid """" ""The name of a logging configuration file. This file is appended to any "" ""existing logging configuration files. For details about logging "" ""configuration files, see the Python logging module documentation."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml92(para) msgid ""Format string for %(asctime)s in log records. Default: None ."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml101(para) msgid ""(Optional) The base directory used for relative --log- file paths."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml110(para) msgid """" ""(Optional) Name of log file to output to. If no default is set, logging will"" "" go to stdout."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml119(para) msgid """" ""<emphasis>DEPRECATED</emphasis>. A logging.Formatter log message format "" ""string which may use any of the available logging.LogRecord attributes. This"" "" option is deprecated. Please use logging_context_format_string and "" ""logging_default_format_string instead."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml131(para) msgid ""The inverse of --debug"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml139(para) msgid ""The inverse of --use-syslog"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml147(para) msgid ""The inverse of --use-syslog-rfc-format"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml155(para) msgid ""The inverse of --verbose"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml163(para) msgid ""Syslog facility to receive log lines."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml171(para) msgid """" ""Use syslog for logging. Existing syslog format is "" ""<emphasis>DEPRECATED</emphasis> during I, and will change in J to honor "" ""RFC5424."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml181(para) msgid """" ""(Optional) Enables or disables syslog rfc5424 format for logging. If "" ""enabled, prefixes the MSG part of the syslog message with APP-NAME "" ""(RFC5424). The format without the APP-NAME is deprecated in I, and will be "" ""removed in J."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml193(para) msgid """" ""Print more verbose output (set logging level to INFO instead of default "" ""WARNING level)."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml210(title) msgid ""trove-manage datastore_update command"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml212(para) msgid """" ""Add or update a datastore. If the datastore already exists, the default "" ""version will be updated."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml220(para) #: ./doc/common/ch_cli_trove-manage_commands.xml260(para) msgid ""Name of the datastore."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml228(para) msgid """" ""Name or ID of an existing datastore version to set as the default. When "" ""adding a new datastore, use an empty string."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml248(title) msgid ""trove-manage datastore_version_update command"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml252(para) msgid """" ""Add or update a datastore version. If the datastore version already exists, "" ""all values except the datastore name and version will be updated."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml268(para) msgid ""Name of the datastore version."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml276(para) msgid ""Name of the manager that will administer the datastore version."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml285(para) msgid ""ID of the image used to create an instance of the datastore version."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml294(para) msgid """" ""Packages required by the datastore version that are installed on the guest "" ""image."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml303(para) msgid """" ""Whether the datastore version is active or not. Accepted values are 0 and 1."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml323(title) msgid ""trove-manage db_downgrade command"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml325(para) msgid ""Downgrade the database to the specified version."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml332(para) msgid ""Target version."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml351(para) #: ./doc/common/ch_cli_trove-manage_commands.xml368(para) #: ./doc/common/ch_cli_trove-manage_commands.xml404(para) #: ./doc/common/ch_cli_trove-manage_commands.xml438(para) msgid ""SQLAlchemy Migrate repository path."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml359(title) msgid ""trove-manage db_recreate command"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml361(para) msgid ""Drop the database and recreate it."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml387(title) msgid ""trove-manage db_sync command"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml389(para) msgid ""Populate the database structure"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml412(title) msgid ""trove-manage db_upgrade command"" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml415(para) msgid ""Upgrade the database to the specified version."" msgstr """" #: ./doc/common/ch_cli_trove-manage_commands.xml430(para) msgid ""Target version. Defaults to the latest version."" msgstr """" ","""POT-Creation-Date: 2014-07-16 19:09+0000\n"" ""PO-Revision-Date: 2014-07-17 06:00+0000\n""#: ./doc/common/section_cli_keystone_services.xml101(para)msgstr """"#: ./doc/common/section_cli_keystone_services.xml98(para)#: ./doc/common/section_cli_keystone_services.xml100(replaceable)#: ./doc/common/section_cli_keystone_services.xml115(title)#: ./doc/common/section_cli_keystone_services.xml118(para)#: ./doc/common/section_cli_keystone_services.xml123(para)#: ./doc/common/section_cli_keystone_services.xml124(para)#: ./doc/common/section_cli_keystone_services.xml136(para)#: ./doc/common/section_cli_keystone_services.xml140(para)#: ./doc/common/section_cli_keystone_services.xml156(para)#: ./doc/common/section_cli_keystone_services.xml158(replaceable)#: ./doc/common/section_cli_keystone_services.xml158(replaceable)#: ./doc/common/section_cli_keystone_services.xml158(replaceable)#: ./doc/common/section_cli_keystone_services.xml163(title)#: ./doc/common/section_cli_keystone_services.xml164(para)#: ./doc/common/section_cli_keystone_services.xml165(replaceable)",4999,4357
openstack%2Fmonasca-api~master~Iadba392b01fd0027cfec51aac2490d565032c373,openstack/monasca-api,master,Iadba392b01fd0027cfec51aac2490d565032c373,Updated the documentation,MERGED,2014-07-18 06:31:41.000000000,2014-07-18 06:32:27.000000000,2014-07-18 06:32:27.000000000,"[{'_account_id': 3}, {'_account_id': 2419}]","[{'number': 1, 'created': '2014-07-18 06:31:41.000000000', 'files': ['docs/mon-api-spec.md'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/3e881bebde363c6a27b4966778e0b742caf4d5f6', 'message': 'Updated the documentation\n\nChange-Id: Iadba392b01fd0027cfec51aac2490d565032c373\n'}]",0,107910,3e881bebde363c6a27b4966778e0b742caf4d5f6,7,2,1,2419,,,0,"Updated the documentation

Change-Id: Iadba392b01fd0027cfec51aac2490d565032c373
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/10/107910/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/mon-api-spec.md'],1,3e881bebde363c6a27b4966778e0b742caf4d5f6,documentation,"# Monasca API Date: July 17, 2014 Document Version: v2.0 # Overview This document describes the Monasca API v2.0, which supports Monitoring as a Service (MONaaS). The API consists of five main resources: 1. Versions 2. Metrics 3. Measurements 4. Statistics 5. Notification Methods 6. Alarms # Common Request Headers This section documents the common request headers that are used in requests. ## Common Http Request Headers The standard Http request headers that are used in requests. * Accept - Internet media types that are acceptable in the response. Must be application/json. * Content-Type - The Internet media type of the request body. Used with POST and PUT requests. Must be application/json. * X-Requested-With * Origin ## Non-standard request headers The non-standard request headers that are used in requests. * X-Auth-Token - Keystone auth token. # Common Responses * links # Versions The versions resource supplies operations for accessing information about supported versions of the API. ## List Versions ### GET /v2.0/versions Lists the supported versions. #### Success Response ##### Status code * 200 - OK ##### Response data Returns an array of the supported versions. ``` [ { ""id"":""v2.0"", ""links"":[ { ""rel"":""self"", ""href"":""http://192.168.10.4:8080/v2.0"" } ], ""status"":""CURRENT"", ""updated"":""2014-07-18T03:25:02.423Z"" } ] ``` ## Get Version ### Get /v2.0/versions/{version_id} Gets detail about the specified version. #### Success Response ##### Status code * 200 - OK ##### Response data Returns detail about the specified version. ``` { ""id"":""v2.0"", ""links"":[ { ""rel"":""self"", ""href"":""http://192.168.10.4:8080/v2.0/"" } ], ""status"":""CURRENT"", ""updated"":""2014-07-18T03:25:02.423Z"" } ``` # Metrics The metrics resource allows metrics to be created and queried. ## Create Metric Create metrics. #### Headers * X-Auth-Token (required) * Content-Type (required) #### URL Parameters None #### Body Consists of a single metric or an array of metrics. A metric has the following properties: * name (required) - The name of the metric of type string(64). * dimensions (optional) - A dictionary consisting of (key, value) pairs of type string(255) that are used to uniquely identify a metric. * timestamp (required) - The timestamp in seconds from the Epoch. * value (required) - A float The name and dimensions are used to uniquely identify a metric. #### Request Data ##### Single metric POST a single metric. ``` POST /v2.0/metrics HTTP/1.1 Host: 192.168.10.4:8080 Content-Type: application/json X-Auth-Token: 27feed73a0ce4138934e30d619b415b0 Cache-Control: no-cache { ""name"": ""name1"", ""dimensions"": { ""key1"": ""value1"", ""key2"": ""value2"" }, ""timestamp"": 1405630174, ""value"": 1.0 } ``` ##### Array of metrics POST an array of metrics. ``` POST /v2.0/metrics HTTP/1.1 Host: 192.168.10.4:8080 Content-Type: application/json X-Auth-Token: 27feed73a0ce4138934e30d619b415b0 Cache-Control: no-cache [ { ""name"": ""name1"", ""dimensions"": { ""key1"": ""value1"", ""key2"": ""value2"" }, ""timestamp"": 1405630174, ""value"": 1.0 }, { ""name"": ""name2"", ""dimensions"": { ""key1"": ""value1"", ""key2"": ""value2"" }, ""timestamp"": 1405630174, ""value"": 2.0 } ] ``` #### Success Response ###### Status Code * 204 - No Content ##### Response Data This request does not return a response body. #### Error Response ##### Status Code * 401 - Unauthorized ## List metrics #### Headers * X-Auth-Token (string) #### URL Parameters * name (required) - The name of the metric of type string(64). * dimensions (optional) - A dictionary consisting of (key, value) pairs of type string(255) that are used to uniquely identify a metric. #### Request Data ``` GET /v2.0/metrics?name=metric1&dimensions=key1:value1 HTTP/1.1 Host: 192.168.10.4:8080 Content-Type: application/json X-Auth-Token: 27feed73a0ce4138934e30d619b415b0 Cache-Control: no-cache ``` #### Success Response ##### Status Code * 200 - OK ##### Response Data ```` [ { ""name"":""name1"", ""dimensions"":{ ""key1"":""value1"" } }, { ""name"":""name2"", ""dimensions"":{ ""key1"":""value1"" } } ] ```` #### Error Response ##### Status Code * 401 - Unauthorized # Measurements ## List measurements ### GET /v2.0/metrics/measurements Get measurements for metrics. #### Headers * X-Auth-Token (string) #### URL Parameters * name (required) - A metric name to filter metrics by. * dimensions (optional) - A dictionary to filter metrics by. * start_time (required) - The start time in ISO 8601 combined date and time format in UTC. * end_time (optional) - The end time in ISO 8601 combined date and time format in UTC. * limit (optional) - The number of metrics to return. #### Request Data ``` GET /v2.0/metrics/measurements?name=cpu_user_perc&dimensions=hostname:devstack&start_time=2014-07-18T03:00:00Z HTTP/1.1 Host: 192.168.10.4:8080 Content-Type: application/json X-Auth-Token: 2b8882ba2ec44295bf300aecb2caa4f7 Cache-Control: no-cache ``` #### Success Response * name: A name of a metric. * dimensions: The dimensions of a metric. * columns - An array of column names corresponding to the columns in measurements. * measurements - A two dimensional array of measurements for each timestamp. ##### Status Code * 200 - OK ##### Response Data ``` [ { ""name"":""cpu_user_perc"", ""dimensions"":{ ""hostname"":""devstack"" }, ""columns"":[ ""id"", ""timestamp"", ""value"" ], ""measurements"":[ [ 6254100001, ""2014-07-18T03:24:25Z"", 2.54 ], [ 6248030001, ""2014-07-18T03:23:50Z"", 2.21 ], [ 6246680001, ""2014-07-18T03:23:14Z"", 3.17 ], [ 6242570001, ""2014-07-18T03:22:38Z"", 2.12 ] ] } ] ``` #### Error Response ##### Status Code * 401 - Unauthorized # Statistics ## List statistics ### GET /v2.0/metrics/statistics Get statistics for metrics. #### Headers * X-Auth-Token (string) #### URL Parameters * name (required) - A metric name to filter metrics by. * dimensions (optional) - A dictionary to filter metrics by. * statistics (required) - A comma separate list of statistics to return. Valid statistics are avg, min, max, sum and count. * start_time (required) - The start time in ISO 8601 combined date and time format in UTC. * end_time (optional) - The end time in ISO 8601 combined date and time format in UTC. * period (optional) - The time period to aggregate measurements by. Default is 300 seconds. #### Request Data ``` GET /v2.0/metrics/statistics?name=cpu_user_perc&dimensions=hostname:devstack&start_time=2014-07-18T03:00:00Z&statistics=avg,min,max,sum,count HTTP/1.1 Host: 192.168.10.4:8080 X-Auth-Token: 2b8882ba2ec44295bf300aecb2caa4f7 Content-Type: application/json Cache-Control: no-cache ``` #### Success Response Returns an array of statistics for each unique metric with the following parameters: * name: A name of a metric. * dimensions: The dimensions of a metric. * columns - An array of column names corresponding to the columns in statistics. * statistics - A two dimensional array of statistics for each period. ##### Status Code * 200 - OK ##### Response Data ``` [ { ""name"":""cpu_user_perc"", ""dimensions"":{ ""hostname"":""devstack"" }, ""columns"":[ ""timestamp"", ""avg"", ""min"", ""max"", ""sum"", ""count"" ], ""statistics"":[ [ ""2014-07-18T03:20:00Z"", 2.765, 1.95, 4.93, 22.119999999999997, 8.0 ], [ ""2014-07-18T03:10:00Z"", 2.412941176470588, 1.71, 4.09, 41.019999999999996, 17.0 ], [ ""2014-07-18T03:00:00Z"", 2.1135294117647065, 1.62, 3.85, 35.93000000000001, 17.0 ] ] } ] ``` #### Error Response ##### Status Code * 401 - Unauthorized # Notification Methods ## Create Notification Method Creates a new notification method through which notifications can be sent to when an alarm state transition occurs. Notification methods are associated with alarms when an alarm is created. #### Headers * X-Auth-Token (string) #### URL Parameters None. #### Body * name (required) - A descriptive name of the notifcation method. * type (required) - The type of notification method (EMAIL). * address (required) - The address / number to notify. #### Request Data ``` POST /v2.0/notification-methods HTTP/1.1 Host: 192.168.10.4:8080 Content-Type: application/json X-Auth-Token: 2b8882ba2ec44295bf300aecb2caa4f7 Cache-Control: no-cache { ""name"": ""Name of notification method"", ""type"": ""EMAIL"", ""address"": ""john.doe@hp.com"" } ``` ##### Response Data Returns the notification method that was created consisting of the following parameters: * id - The ID of the notification method that was created. * links - An array of links where a link consists of the following: * rel - Relationship type * href - Hypermedia reference * name * type * address ``` { ""id"":""35cc6f1c-3a29-49fb-a6fc-d9d97d190508"", ""links"":[ { ""rel"":""self"", ""href"":""http://192.168.10.4:8080/v2.0/notification-methods/35cc6f1c-3a29-49fb-a6fc-d9d97d190508"" } ], ""name"":""Name of notification method"", ""type"":""EMAIL"", ""address"":""john.doe@hp.com"" } ``` ## List Notification MethodsList all notification methods. #### Headers * X-Auth-Token (string) #### URL Parameters None #### Body None #### Request Data ``` GET /v2.0/notification-methods HTTP/1.1 Host: 192.168.10.4:8080 Content-Type: application/json X-Auth-Token: 2b8882ba2ec44295bf300aecb2caa4f7 Cache-Control: no-cache ``` #### Success Response ##### Status Code * 200 - OK ##### Response Data Returns an array of notification methods. ``` [ { ""id"":""35cc6f1c-3a29-49fb-a6fc-d9d97d190508"", ""links"":[ { ""rel"":""self"", ""href"":""http://192.168.10.4:8080/v2.0/notification-methods/35cc6f1c-3a29-49fb-a6fc-d9d97d190508"" } ], ""name"":""Name of notification method"", ""type"":""EMAIL"", ""address"":""john.doe@hp.com"" }, { ""id"":""c60ec47e-5038-4bf1-9f95-4046c6e9a759"", ""links"":[ { ""rel"":""self"", ""href"":""http://192.168.10.4:8080/v2.0/notification-methods/c60ec47e-5038-4bf1-9f95-4046c6e9a759"" } ], ""name"":""Name of notification method"", ""type"":""EMAIL"", ""address"":""jane.doe@hp.com"" } ] ``` ## Get Notification MethodGet the details of a specific notification method. #### Headers * X-Auth-Token (string) #### URL Parameters * notification_method_id - ID of the notification method #### Body None ##### Request Data ``` http://192.168.10.4:8080/v2.0/notification-methods/35cc6f1c-3a29-49fb-a6fc-d9d97d190508 ``` #### Success Response ##### Status Code * 200 - OK ##### Response Data Returns the specified notification method ``` { ""id"":""35cc6f1c-3a29-49fb-a6fc-d9d97d190508"", ""links"":[ { ""rel"":""self"", ""href"":""http://192.168.10.4:8080/v2.0/notification-methods/35cc6f1c-3a29-49fb-a6fc-d9d97d190508"" } ], ""name"":""Name of notification method"", ""type"":""EMAIL"", ""address"":""john.doe@hp.com"" } ``` #### Error Response ##### Status Code * 404 - Not Found ## Update Notification MethodUpdate the specified notification method. #### Headers * X-Auth-Token (string) #### URL Parameters * notification_method_id - ID of the notification method to update. #### Body * name (required) - A descriptive name of the notifcation method. * type (required) - The type of notification method (EMAIL). * address (required) - The address / number to notify. #### Request data ```` PUT /v2.0/notification-methods/35cc6f1c-3a29-49fb-a6fc-d9d97d190508 HTTP/1.1 Host: 192.168.10.4:8080 Content-Type: application/json X-Auth-Token: 2b8882ba2ec44295bf300aecb2caa4f7 Cache-Control: no-cache { ""name"": ""New name of notification method"", ""type"": ""EMAIL"", ""address"": ""jane.doe@hp.com"" } ```` #### Success Response ##### Status Code * 200 - OK #### Response data ```` { ""id"":""35cc6f1c-3a29-49fb-a6fc-d9d97d190508"", ""links"":[ { ""rel"":""self"", ""href"":""http://192.168.10.4:8080/v2.0/notification-methods/35cc6f1c-3a29-49fb-a6fc-d9d97d190508"" } ], ""name"":""New name of notification method"", ""type"":""EMAIL"", ""address"":""jane.doe@hp.com"" } ```` ## Delete Notification Method ### DELETE /v2.0/notification-methods/{notification_method_id} Delete the specified notification method. #### Headers * X-Auth-Token (string) #### URL Parameters * notification_method_id - ID of the notification method to delete ##### Request Data ``` DELETE /v2.0/notification-methods/35cc6f1c-3a29-49fb-a6fc-d9d97d190508 HTTP/1.1 Host: 192.168.10.4:8080 Content-Type: application/json X-Auth-Token: 2b8882ba2ec44295bf300aecb2caa4f7 Cache-Control: no-cache ``` #### Success Response ###### Status Code * 204 - No Content ##### Response Data This request does not return a response body. #### Error Response ##### Status Code * 401 - Unauthorized # Alarms",## /v2.0/statistics Operations for accessing statistics ### GET /v2.0/statistics Get statistics #### Parameters * X-Tenant-Id (string) * name (string) * dimensions (string) * start_time (string) * end_time (string) * statistics (string) * period (string) ## /v2.0/metrics Operations for accessing metricsCreate metrics #### Parameters * X-Tenant-Id (string) * X-Roles (string) * tenant_id (string) * body (array)#### Parameters * X-Tenant-Id (string) * name (string) * dimensions (string) ## /v2.0/alarms Operations for working with alarms ### POST /v2.0/alarms Create alarm #### Parameters * X-Tenant-Id (string) * body (CreateAlarmCommand) ### GET /v2.0/alarms List alarms #### Parameters * X-Tenant-Id (string) * dimensions (string) * state (string) ### GET /v2.0/alarms/{alarm_id}/state-history Get alarm state history #### Parameters * X-Tenant-Id (string) * alarm_id (string) ### GET /v2.0/alarms/{alarm_id} Get alarm #### Parameters * X-Tenant-Id (string) * alarm_id (string) #### Responses * 400: Invalid ID supplied * 404: Alarm not found ### DELETE /v2.0/alarms/{alarm_id} Delete alarm #### Parameters * X-Tenant-Id (string) * alarm_id (string) ### PUT /v2.0/alarms/{alarm_id} Update alarm #### Parameters * X-Tenant-Id (string) * alarm_id (string) * body (UpdateAlarmCommand) ## /v2.0/notification-methods Operations for working with notification methodsCreate notification method #### Parameters * X-Tenant-Id (string) * body (CreateNotificationMethodCommand)List notification methods #### Parameters * X-Tenant-Id (string) Get notification method #### Parameters * X-Tenant-Id (string) * notification_method_id (string) ### DELETE /v2.0/notification-methods/{notification_method_id} Delete notification method #### Parameters * X-Tenant-Id (string) * notification_method_id (string)Update notification method #### Parameters * X-Tenant-Id (string) * notification_method_id (string) * body (CreateNotificationMethodCommand) ## /v2.0/measurements Operations for accessing measurements ### GET /v2.0/measurements Get measurements #### Parameters * X-Tenant-Id (string) * name (string) * dimensions (string) * start_time (string) * end_time (string) ## / Operations for accessing versions ## Statistics * columns: array * name: string ## CreateMetricCommand * timestamp: integer * name: string * value: number ## MetricDefinition * name: string ## CreateAlarmCommand * name: string * undeterminedActions: array * alarmActions: array * okActions: array * expression: string * description: string ## Alarm An alarm is a devops's best friend * undeterminedActions: array * links: array * alarmActions: array * description: string * okActions: array * expression: string * id: string * actionsEnabled: boolean * name: string ## AlarmStateHistory * reasonData: string * alarmId: string * reason: string ## Link * href: string * rel: string ## UpdateAlarmCommand * name: string * undeterminedActions: array * alarmActions: array * okActions: array * expression: string * actionsEnabled: boolean * description: string ## NotificationMethod * id: string * name: string * links: array * address: string ## Link * href: string * rel: string ## CreateNotificationMethodCommand * name: string * address: string ## Measurements * columns: array * name: string ,573,167
openstack%2Fmistral~master~I51f074a1ff2b3f3f669865839f658da887d4ce6d,openstack/mistral,master,I51f074a1ff2b3f3f669865839f658da887d4ce6d,Add running mistralclient integrational tests,MERGED,2014-07-11 15:51:03.000000000,2014-07-18 06:14:00.000000000,2014-07-18 06:14:00.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7613}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-07-11 15:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6b64efd723d8186034daeb79f53641f6a9bd931e', 'message': 'Add running mistralclient integrational tests\n\nNow on every commit to the mistral repository mistralclient\nintegrational tests and api integrational tests will run.\nAlso on every commit to the mistralclient repository only\nmistralclient integrational tests will run.\n(after appropriate commit to openstack-infra)\n\nChange-Id: I51f074a1ff2b3f3f669865839f658da887d4ce6d\n'}, {'number': 2, 'created': '2014-07-15 05:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2d51f36813c635a42deedb635ec8da39aa00a2d8', 'message': 'Add running mistralclient integrational tests\n\nNow on every commit to the mistral repository mistralclient\nintegration tests and api integration tests will run.\nAlso on every commit to the mistralclient repository only\nmistralclient integrational tests will run.\n(after appropriate commit to openstack-infra)\n\nChange-Id: I51f074a1ff2b3f3f669865839f658da887d4ce6d\n'}, {'number': 3, 'created': '2014-07-16 06:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d3f1a5977a5eb98c317a0b08019f7e66fb3baeca', 'message': 'Add running mistralclient integrational tests\n\nNow on every commit to the mistral repository mistralclient\nintegration tests and api integration tests will run.\nAlso on every commit to the mistralclient repository only\nmistralclient integrational tests will run.\n(after appropriate commit to openstack-infra)\n\nChange-Id: I51f074a1ff2b3f3f669865839f658da887d4ce6d\n'}, {'number': 4, 'created': '2014-07-16 07:20:55.000000000', 'files': ['functionaltests/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/mistral/commit/2c492fb057377113517c47e0f0d80b357de1fd19', 'message': 'Add running mistralclient integrational tests\n\nNow on every commit to the mistral repository mistralclient\nintegration tests and api integration tests will run.\nAlso on every commit to the mistralclient repository only\nmistralclient integrational tests will run.\n(after appropriate commit to openstack-infra)\n\nChange-Id: I51f074a1ff2b3f3f669865839f658da887d4ce6d\n'}]",1,106413,2c492fb057377113517c47e0f0d80b357de1fd19,26,6,4,8592,,,0,"Add running mistralclient integrational tests

Now on every commit to the mistral repository mistralclient
integration tests and api integration tests will run.
Also on every commit to the mistralclient repository only
mistralclient integrational tests will run.
(after appropriate commit to openstack-infra)

Change-Id: I51f074a1ff2b3f3f669865839f658da887d4ce6d
",git fetch https://review.opendev.org/openstack/mistral refs/changes/13/106413/4 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/post_test_hook.sh'],1,6b64efd723d8186034daeb79f53641f6a9bd931e,(detached," $RETVAL -eq 0 if [[ ! ""$ZUUL_PROJECT"" =~ python-mistralclient ]]; then cd /opt/stack/new/mistral/functionaltests sudo ./run_tests.sh RETVAL=$? # Copy tempest log files to be published among other logs upon job completion sudo cp /opt/stack/new/mistral/functionaltests/tempest.log /opt/stack/logs fi if [[ RETVAL -eq 0 ]]; then cd /opt/stack/new/python-mistralclient/functionaltests sudo ./run_tests.sh RETVAL=$? fisudo cp /opt/stack/new/python-mistralclient/functionaltests/tempest.log /opt/stack/logs/tempest_client.log",cd /opt/stack/new/mistral/functionaltests sudo ./run_tests.sh RETVAL=$?sudo cp /opt/stack/new/mistral/functionaltests/tempest.log /opt/stack/logs,17,4
openstack%2Foslo.messaging~stable%2Ficehouse~Id701d6a80a909d6bd6dabe680c2b8e09dd721ef1,openstack/oslo.messaging,stable/icehouse,Id701d6a80a909d6bd6dabe680c2b8e09dd721ef1,Make the TransportUrl hashable,ABANDONED,2014-06-06 09:40:40.000000000,2014-07-18 06:11:18.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2813}, {'_account_id': 8300}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-06 09:40:40.000000000', 'files': ['oslo/messaging/transport.py', 'tests/test_transport.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/08f664f3b71d8e93d5e28923d74af5c636a2a851', 'message': 'Make the TransportUrl hashable\n\nThe amqp connection pool uses the Transport Url as key\nto track the connection, but currently a different hash can be\nreturned for the same url.\n\nThis change fixes the hash method of the TransportUrl\n\nCloses-bug: #1316891\n(cherry picked from commit 78b498de2339317f9f189f4395878f9abc96e750)\nChange-Id: Id701d6a80a909d6bd6dabe680c2b8e09dd721ef1\n'}]",0,98346,08f664f3b71d8e93d5e28923d74af5c636a2a851,17,5,1,8300,,,0,"Make the TransportUrl hashable

The amqp connection pool uses the Transport Url as key
to track the connection, but currently a different hash can be
returned for the same url.

This change fixes the hash method of the TransportUrl

Closes-bug: #1316891
(cherry picked from commit 78b498de2339317f9f189f4395878f9abc96e750)
Change-Id: Id701d6a80a909d6bd6dabe680c2b8e09dd721ef1
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/46/98346/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/transport.py', 'tests/test_transport.py']",2,08f664f3b71d8e93d5e28923d74af5c636a2a851,," class TestTransportUrlCustomisation(test_utils.BaseTestCase): def setUp(self): super(TestTransportUrlCustomisation, self).setUp() self.url1 = transport.TransportURL.parse(self.conf, ""fake://vhost1"") self.url2 = transport.TransportURL.parse(self.conf, ""fake://vhost2"") self.url3 = transport.TransportURL.parse(self.conf, ""fake://vhost1"") def test_hash(self): urls = {} urls[self.url1] = self.url1 urls[self.url2] = self.url2 urls[self.url3] = self.url3 self.assertEqual(2, len(urls)) def test_eq(self): self.assertEqual(self.url1, self.url3) self.assertNotEqual(self.url1, self.url2) class TestTransportHostCustomisation(test_utils.BaseTestCase): def setUp(self): super(TestTransportHostCustomisation, self).setUp() self.host1 = transport.TransportHost(""host1"", 5662, ""user"", ""pass"") self.host2 = transport.TransportHost(""host1"", 5662, ""user"", ""pass"") self.host3 = transport.TransportHost(""host1"", 5663, ""user"", ""pass"") self.host4 = transport.TransportHost(""host1"", 5662, ""user2"", ""pass"") self.host5 = transport.TransportHost(""host1"", 5662, ""user"", ""pass2"") self.host6 = transport.TransportHost(""host2"", 5662, ""user"", ""pass"") def test_hash(self): hosts = {} hosts[self.host1] = self.host1 hosts[self.host2] = self.host2 hosts[self.host3] = self.host3 hosts[self.host4] = self.host4 hosts[self.host5] = self.host5 hosts[self.host6] = self.host6 self.assertEqual(5, len(hosts)) def test_eq(self): self.assertEqual(self.host1, self.host2) self.assertNotEqual(self.host1, self.host3) self.assertNotEqual(self.host1, self.host4) self.assertNotEqual(self.host1, self.host5) self.assertNotEqual(self.host1, self.host6)",,53,0
openstack%2Ftraining-guides~master~I8ad0860eae53304cf08448aa67f12b6e3ea9caae,openstack/training-guides,master,I8ad0860eae53304cf08448aa67f12b6e3ea9caae,Adds updated install guide content,MERGED,2014-07-17 07:55:17.000000000,2014-07-18 05:09:46.000000000,2014-07-18 05:09:46.000000000,"[{'_account_id': 3}, {'_account_id': 6923}, {'_account_id': 7007}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-07-17 07:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/40b75b7adae2a4d2e7dc613630195a61698f381d', 'message': 'Adds updated install guide content\n\nAdds install guides content to basic-install-guides folder. This content will\nsoon be modified, edited and pushed back to install gudies. It will be linked\nfrom inside install guide and the copy in training guides will be deleted.\n\nThis patch adds these files for easy transition and also to figure out\ndifferent changes to install guides without having to compromise on quality and\nalso to meet Juno2 release date.\n\nChange-Id: I8ad0860eae53304cf08448aa67f12b6e3ea9caae\nImplements: blueprint openstack-training-guides\n'}, {'number': 2, 'created': '2014-07-17 08:32:07.000000000', 'files': ['doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_1_configure-with-dbconfig-yes-no.png', 'doc/training-guides/basic-install-guide/section_keystone-services.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage-troubleshoot.xml', 'doc/training-guides/basic-install-guide/figures/installguide_arch-neutron.png', 'doc/training-guides/basic-install-guide/figures/nova-external-1.svg', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-adding-proxy-server.xml', 'doc/training-guides/basic-install-guide/section_basics-packages.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage-characteristics.xml', 'doc/training-guides/basic-install-guide/ch_swift.xml', 'doc/training-guides/basic-install-guide/section_basics-networking-neutron.xml', 'doc/training-guides/basic-install-guide/ch_keystone.xml', 'doc/training-guides/basic-install-guide/figures/installguide_neutron-initial-networks.png', 'doc/training-guides/basic-install-guide/section_glance-verify.xml', 'doc/training-guides/basic-install-guide/section_neutron-ovs-controller-node.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/api-endpoint_3_keystone_authtoken.png', 'doc/training-guides/basic-install-guide/section_basics-database.xml', 'doc/training-guides/basic-install-guide/section_ceilometer-verify.xml', 'doc/training-guides/basic-install-guide/section_debconf-preseeding.xml', 'doc/training-guides/basic-install-guide/section_debconf-rabbitmq.xml', 'doc/training-guides/basic-install-guide/ch_clients.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/glance-common_pipeline_flavor.png', 'doc/training-guides/basic-install-guide/section_neutron-ml2-network-node.xml', 'doc/training-guides/basic-install-guide/section_nova-verify.xml', 'doc/training-guides/basic-install-guide/section_ceilometer-install.xml', 'doc/training-guides/basic-install-guide/ch_ceilometer.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/api-endpoint_5_region_name.png', 'doc/training-guides/basic-install-guide/common/section_keystone-concepts.xml', 'doc/training-guides/basic-install-guide/common/figures/novnc/SCH_5009_V00_NUAC-VNC_OpenStack.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_2_register_admin_tenant_yes_no.png', 'doc/training-guides/basic-install-guide/section_launch-instance-neutron.xml', 'doc/training-guides/basic-install-guide/ch_networking.xml', 'doc/training-guides/basic-install-guide/figures/swift_install_arch.png', 'doc/training-guides/basic-install-guide/samples/glance-registry-paste.ini', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-buildingblocks.png', 'doc/training-guides/basic-install-guide/app_reserved_uids.xml', 'doc/training-guides/basic-install-guide/samples/test-stack.yml', 'doc/training-guides/basic-install-guide/ch_nova.xml', 'doc/training-guides/basic-install-guide/samples/keystone-paste.ini', 'doc/training-guides/basic-install-guide/section_ceilometer-glance.xml', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-install.xml', 'doc/training-guides/basic-install-guide/figures/basic-architecture.svg', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-example-install-arch.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage-features.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_keep_admin_pass.png', 'doc/training-guides/basic-install-guide/section_dashboard-install.xml', 'doc/training-guides/basic-install-guide/ch_glance.xml', 'doc/training-guides/basic-install-guide/figures/networking-interactions-swift.png', 'doc/training-guides/basic-install-guide/common/section_objectstorage-ringbuilder.xml', 'doc/training-guides/basic-install-guide/section_ceilometer-nova.xml', 'doc/training-guides/basic-install-guide/figures/installguide_arch-neutron.svg', 'doc/training-guides/basic-install-guide/figures/nova-external-2.png', 'doc/training-guides/basic-install-guide/samples/glance-api-paste.ini', 'doc/training-guides/basic-install-guide/ch_trove.xml', 'doc/training-guides/basic-install-guide/object-storage/section_start-storage-node-services.xml', 'doc/training-guides/basic-install-guide/section_glance-install.xml', 'doc/training-guides/basic-install-guide/common/figures/objectstorage.png', 'doc/training-guides/basic-install-guide/common/section_objectstorage-intro.xml', 'doc/training-guides/basic-install-guide/figures/nova-external.graffle', 'doc/training-guides/basic-install-guide/figures/swift_install_arch.svg', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/service_keystone_authtoken_server_hostname.png', 'doc/training-guides/basic-install-guide/samples/object-server.conf.txt', 'doc/training-guides/basic-install-guide/section_debconf-dbconfig-common.xml', 'doc/training-guides/basic-install-guide/common/figures/SCH_5002_V00_NUAC-Keystone.png', 'doc/training-guides/basic-install-guide/section_heat-install.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/api-endpoint_1_register_endpoint.png', 'doc/training-guides/basic-install-guide/figures/installguide_neutron-initial-networks.svg', 'doc/training-guides/basic-install-guide/section_dashboard-system-reqs.xml', 'doc/training-guides/basic-install-guide/figures/NOVA_ARCH.svg', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/api-endpoint_4_service_endpoint_ip_address.png', 'doc/training-guides/basic-install-guide/samples/glance-scrubber.conf', 'doc/training-guides/basic-install-guide/ch_horizon.xml', 'doc/training-guides/basic-install-guide/figures/NOVA_ARCH.png', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-replication.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_3_admin_user_name.png', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-nodes.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_1_admin_token.png', 'doc/training-guides/basic-install-guide/section_basics-prerequisites.xml', 'doc/training-guides/basic-install-guide/ch_debconf.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_7_register_endpoint.png', 'doc/training-guides/basic-install-guide/section_launch-instance-nova.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_5_mysql_app_password.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_6_admin_user_pass_confirm.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_2_db-types.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/rabbitmq-password.png', 'doc/training-guides/basic-install-guide/common/section_objectstorage-components.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/service_keystone_authtoken_tenant_admin_user.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_4_mysql_root_password.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_6_mysql_app_password_confirm.png', 'doc/training-guides/basic-install-guide/section_ceilometer-swift.xml', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-zones.png', 'doc/training-guides/basic-install-guide/section_cinder-controller.xml', 'doc/training-guides/basic-install-guide/section_basics-networking.xml', 'doc/training-guides/basic-install-guide/section_debconf-concepts.xml', 'doc/training-guides/basic-install-guide/figures/nova-external-2.svg', 'doc/training-guides/basic-install-guide/samples/network-interfaces.conf.txt', 'doc/training-guides/basic-install-guide/section_keystone-install.xml', 'doc/training-guides/basic-install-guide/roadmap.rst', 'doc/training-guides/basic-install-guide/samples/openrc.txt', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-usecase.png', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-verifying-install.xml', 'doc/training-guides/basic-install-guide/section_keystone-users.xml', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-partitions.png', 'doc/training-guides/basic-install-guide/figures/NOVA_install_arch.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_3_connection_method.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_used_for_remote_db.png', 'doc/training-guides/basic-install-guide/samples/account-server-1.conf.txt', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/service_keystone_authtoken_admin_password.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_4_admin_user_email.png', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-ring.png', 'doc/training-guides/basic-install-guide/ch_overview.xml', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-arch.png', 'doc/training-guides/basic-install-guide/ch_launch-instance.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage-arch.xml', 'doc/training-guides/basic-install-guide/section_debconf-keystone_authtoken.xml', 'doc/training-guides/basic-install-guide/section_basics-queue.xml', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-install-config-storage-nodes.xml', 'doc/training-guides/basic-install-guide/samples/glance-cache.conf', 'doc/training-guides/basic-install-guide/samples/glance-scrubber-paste.ini', 'doc/training-guides/basic-install-guide/samples/container-server.conf.txt', 'doc/training-guides/basic-install-guide/section_neutron-concepts.xml', 'doc/training-guides/basic-install-guide/section_nova-networking-compute-node.xml', 'doc/training-guides/basic-install-guide/section_trove-verify.xml', 'doc/training-guides/st-training-guides.xml', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-network-planning.xml', 'doc/training-guides/basic-install-guide/samples/glance-cache-paste.ini', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-sys-requirements.xml', 'doc/training-guides/basic-install-guide/figures/basic-architecture-networking.svg', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-accountscontainers.png', 'doc/training-guides/basic-install-guide/common/section_objectstorage-replication.xml', 'doc/training-guides/basic-install-guide/figures/installguide_arch-nova.svg', 'doc/training-guides/basic-install-guide/section_debconf-api-endpoints.xml', 'doc/training-guides/basic-install-guide/section_neutron-ml2-compute-node.xml', 'doc/training-guides/basic-install-guide/section_nova-networking-initial-network.xml', 'doc/training-guides/basic-install-guide/section_nova-compute-install.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_5_admin_user_pass.png', 'doc/training-guides/basic-install-guide/figures/nova-external-1.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/api-endpoint_2_keystone_server_ip.png', 'doc/training-guides/basic-install-guide/ch_basics.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/rabbitmq-user.png', 'doc/training-guides/basic-install-guide/section_nova-networking-controller-node.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/rabbitmq-host.png', 'doc/training-guides/basic-install-guide/bk-openstack-basic-install-guide.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/neutron_1_plugin_selection.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/neutron_2_networking_type.png', 'doc/training-guides/basic-install-guide/section_basics-networking-nova.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage-account-reaper.xml', 'doc/training-guides/basic-install-guide/figures/NOVA_install_arch.svg', 'doc/training-guides/basic-install-guide/samples/container-server-1.conf.txt', 'doc/training-guides/basic-install-guide/samples/glance-api.conf', 'doc/training-guides/basic-install-guide/samples/glance-registry.conf', 'doc/training-guides/basic-install-guide/samples/api-paste.ini', 'doc/training-guides/basic-install-guide/section_ceilometer-cinder.xml', 'doc/training-guides/basic-install-guide/samples/object-server-1.conf.txt', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/service_keystone_authtoken_admin_tenant_name.png', 'doc/training-guides/basic-install-guide/section_keystone-verify.xml', 'doc/training-guides/basic-install-guide/ch_cinder.xml', 'doc/training-guides/basic-install-guide/samples/swift.conf.txt', 'doc/training-guides/basic-install-guide/section_basics-ntp.xml', 'doc/training-guides/basic-install-guide/section_neutron-ovs-compute-node.xml', 'doc/training-guides/basic-install-guide/section_trove-install.xml', 'doc/training-guides/basic-install-guide/section_cinder-node.xml', 'doc/training-guides/basic-install-guide/figures/networking-interactions-swift.svg', 'doc/training-guides/basic-install-guide/section_neutron-initial-networks.xml', 'doc/training-guides/basic-install-guide/section_nova-controller-install.xml', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-install-config-proxy-node.xml', 'doc/training-guides/basic-install-guide/samples/account-server.conf.txt', 'doc/training-guides/basic-install-guide/section_cinder-verify.xml', 'doc/training-guides/basic-install-guide/section_neutron-ovs-network-node.xml', 'doc/training-guides/basic-install-guide/common/section_compute-configure-vnc.xml', 'doc/training-guides/basic-install-guide/ch_heat.xml', 'doc/training-guides/basic-install-guide/section_basics-passwords.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage_tenant-specific-image-storage.xml', 'doc/training-guides/basic-install-guide/figures/installguide_arch-nova.png', 'doc/training-guides/basic-install-guide/section_heat-verify.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/neutron_3_hypervisor_ip.png', 'doc/training-guides/basic-install-guide/section_neutron-ml2-controller-node.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/cf578d9d1016c45c0241d9da826e3fbc2abadcb2', 'message': 'Adds updated install guide content\n\nAdds install guides content to basic-install-guides folder. This content will\nsoon be modified, edited and pushed back to install gudies. It will be linked\nfrom inside install guide and the copy in training guides will be deleted.\n\nThis patch adds these files for easy transition and also to figure out\ndifferent changes to install guides without having to compromise on quality and\nalso to meet Juno2 release date.\n\nChange-Id: I8ad0860eae53304cf08448aa67f12b6e3ea9caae\nImplements: blueprint openstack-training-guides\n'}]",0,107583,cf578d9d1016c45c0241d9da826e3fbc2abadcb2,10,5,2,7007,,,0,"Adds updated install guide content

Adds install guides content to basic-install-guides folder. This content will
soon be modified, edited and pushed back to install gudies. It will be linked
from inside install guide and the copy in training guides will be deleted.

This patch adds these files for easy transition and also to figure out
different changes to install guides without having to compromise on quality and
also to meet Juno2 release date.

Change-Id: I8ad0860eae53304cf08448aa67f12b6e3ea9caae
Implements: blueprint openstack-training-guides
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/83/107583/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_1_configure-with-dbconfig-yes-no.png', 'doc/training-guides/basic-install-guide/section_keystone-services.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage-troubleshoot.xml', 'doc/training-guides/basic-install-guide/figures/installguide_arch-neutron.png', 'doc/training-guides/basic-install-guide/figures/nova-external-1.svg', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-adding-proxy-server.xml', 'doc/training-guides/basic-install-guide/section_basics-packages.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage-characteristics.xml', 'doc/training-guides/basic-install-guide/ch_swift.xml', 'doc/training-guides/basic-install-guide/section_basics-networking-neutron.xml', 'doc/training-guides/basic-install-guide/ch_keystone.xml', 'doc/training-guides/basic-install-guide/figures/installguide_neutron-initial-networks.png', 'doc/training-guides/basic-install-guide/section_glance-verify.xml', 'doc/training-guides/basic-install-guide/section_neutron-ovs-controller-node.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/api-endpoint_3_keystone_authtoken.png', 'doc/training-guides/basic-install-guide/section_basics-database.xml', 'doc/training-guides/basic-install-guide/section_ceilometer-verify.xml', 'doc/training-guides/basic-install-guide/section_debconf-preseeding.xml', 'doc/training-guides/basic-install-guide/section_debconf-rabbitmq.xml', 'doc/training-guides/basic-install-guide/ch_clients.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/glance-common_pipeline_flavor.png', 'doc/training-guides/basic-install-guide/section_neutron-ml2-network-node.xml', 'doc/training-guides/basic-install-guide/section_nova-verify.xml', 'doc/training-guides/basic-install-guide/section_ceilometer-install.xml', 'doc/training-guides/basic-install-guide/ch_ceilometer.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/api-endpoint_5_region_name.png', 'doc/training-guides/basic-install-guide/common/section_keystone-concepts.xml', 'doc/training-guides/basic-install-guide/common/figures/novnc/SCH_5009_V00_NUAC-VNC_OpenStack.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_2_register_admin_tenant_yes_no.png', 'doc/training-guides/basic-install-guide/section_launch-instance-neutron.xml', 'doc/training-guides/basic-install-guide/ch_networking.xml', 'doc/training-guides/basic-install-guide/figures/swift_install_arch.png', 'doc/training-guides/basic-install-guide/samples/glance-registry-paste.ini', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-buildingblocks.png', 'doc/training-guides/basic-install-guide/app_reserved_uids.xml', 'doc/training-guides/basic-install-guide/samples/test-stack.yml', 'doc/training-guides/basic-install-guide/ch_nova.xml', 'doc/training-guides/basic-install-guide/samples/keystone-paste.ini', 'doc/training-guides/basic-install-guide/section_ceilometer-glance.xml', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-install.xml', 'doc/training-guides/basic-install-guide/figures/basic-architecture.svg', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-example-install-arch.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage-features.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_keep_admin_pass.png', 'doc/training-guides/basic-install-guide/section_dashboard-install.xml', 'doc/training-guides/basic-install-guide/ch_glance.xml', 'doc/training-guides/basic-install-guide/figures/networking-interactions-swift.png', 'doc/training-guides/basic-install-guide/common/section_objectstorage-ringbuilder.xml', 'doc/training-guides/basic-install-guide/section_ceilometer-nova.xml', 'doc/training-guides/basic-install-guide/figures/installguide_arch-neutron.svg', 'doc/training-guides/basic-install-guide/figures/nova-external-2.png', 'doc/training-guides/basic-install-guide/samples/glance-api-paste.ini', 'doc/training-guides/basic-install-guide/ch_trove.xml', 'doc/training-guides/basic-install-guide/object-storage/section_start-storage-node-services.xml', 'doc/training-guides/basic-install-guide/section_glance-install.xml', 'doc/training-guides/basic-install-guide/common/figures/objectstorage.png', 'doc/training-guides/basic-install-guide/common/section_objectstorage-intro.xml', 'doc/training-guides/basic-install-guide/figures/nova-external.graffle', 'doc/training-guides/basic-install-guide/figures/swift_install_arch.svg', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/service_keystone_authtoken_server_hostname.png', 'doc/training-guides/basic-install-guide/samples/object-server.conf.txt', 'doc/training-guides/basic-install-guide/section_debconf-dbconfig-common.xml', 'doc/training-guides/basic-install-guide/common/figures/SCH_5002_V00_NUAC-Keystone.png', 'doc/training-guides/basic-install-guide/section_heat-install.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/api-endpoint_1_register_endpoint.png', 'doc/training-guides/basic-install-guide/figures/installguide_neutron-initial-networks.svg', 'doc/training-guides/basic-install-guide/section_dashboard-system-reqs.xml', 'doc/training-guides/basic-install-guide/figures/NOVA_ARCH.svg', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/api-endpoint_4_service_endpoint_ip_address.png', 'doc/training-guides/basic-install-guide/samples/glance-scrubber.conf', 'doc/training-guides/basic-install-guide/ch_horizon.xml', 'doc/training-guides/basic-install-guide/figures/NOVA_ARCH.png', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-replication.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_3_admin_user_name.png', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-nodes.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_1_admin_token.png', 'doc/training-guides/basic-install-guide/section_basics-prerequisites.xml', 'doc/training-guides/basic-install-guide/ch_debconf.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_7_register_endpoint.png', 'doc/training-guides/basic-install-guide/section_launch-instance-nova.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_5_mysql_app_password.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_6_admin_user_pass_confirm.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_2_db-types.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/rabbitmq-password.png', 'doc/training-guides/basic-install-guide/common/section_objectstorage-components.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/service_keystone_authtoken_tenant_admin_user.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_4_mysql_root_password.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_6_mysql_app_password_confirm.png', 'doc/training-guides/basic-install-guide/section_ceilometer-swift.xml', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-zones.png', 'doc/training-guides/basic-install-guide/section_cinder-controller.xml', 'doc/training-guides/basic-install-guide/section_basics-networking.xml', 'doc/training-guides/basic-install-guide/section_debconf-concepts.xml', 'doc/training-guides/basic-install-guide/figures/nova-external-2.svg', 'doc/training-guides/basic-install-guide/samples/network-interfaces.conf.txt', 'doc/training-guides/basic-install-guide/section_keystone-install.xml', 'doc/training-guides/basic-install-guide/roadmap.rst', 'doc/training-guides/basic-install-guide/samples/openrc.txt', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-usecase.png', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-verifying-install.xml', 'doc/training-guides/basic-install-guide/section_keystone-users.xml', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-partitions.png', 'doc/training-guides/basic-install-guide/figures/NOVA_install_arch.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_3_connection_method.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/dbconfig-common_used_for_remote_db.png', 'doc/training-guides/basic-install-guide/samples/account-server-1.conf.txt', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/service_keystone_authtoken_admin_password.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_4_admin_user_email.png', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-ring.png', 'doc/training-guides/basic-install-guide/ch_overview.xml', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-arch.png', 'doc/training-guides/basic-install-guide/ch_launch-instance.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage-arch.xml', 'doc/training-guides/basic-install-guide/section_debconf-keystone_authtoken.xml', 'doc/training-guides/basic-install-guide/section_basics-queue.xml', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-install-config-storage-nodes.xml', 'doc/training-guides/basic-install-guide/samples/glance-cache.conf', 'doc/training-guides/basic-install-guide/samples/glance-scrubber-paste.ini', 'doc/training-guides/basic-install-guide/samples/container-server.conf.txt', 'doc/training-guides/basic-install-guide/section_neutron-concepts.xml', 'doc/training-guides/basic-install-guide/section_nova-networking-compute-node.xml', 'doc/training-guides/basic-install-guide/section_trove-verify.xml', 'doc/training-guides/st-training-guides.xml', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-network-planning.xml', 'doc/training-guides/basic-install-guide/samples/glance-cache-paste.ini', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-sys-requirements.xml', 'doc/training-guides/basic-install-guide/figures/basic-architecture-networking.svg', 'doc/training-guides/basic-install-guide/common/figures/objectstorage-accountscontainers.png', 'doc/training-guides/basic-install-guide/common/section_objectstorage-replication.xml', 'doc/training-guides/basic-install-guide/figures/installguide_arch-nova.svg', 'doc/training-guides/basic-install-guide/section_debconf-api-endpoints.xml', 'doc/training-guides/basic-install-guide/section_neutron-ml2-compute-node.xml', 'doc/training-guides/basic-install-guide/section_nova-networking-initial-network.xml', 'doc/training-guides/basic-install-guide/section_nova-compute-install.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/keystone_5_admin_user_pass.png', 'doc/training-guides/basic-install-guide/figures/nova-external-1.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/api-endpoint_2_keystone_server_ip.png', 'doc/training-guides/basic-install-guide/ch_basics.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/rabbitmq-user.png', 'doc/training-guides/basic-install-guide/section_nova-networking-controller-node.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/rabbitmq-host.png', 'doc/training-guides/basic-install-guide/bk-openstack-basic-install-guide.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/neutron_1_plugin_selection.png', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/neutron_2_networking_type.png', 'doc/training-guides/basic-install-guide/section_basics-networking-nova.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage-account-reaper.xml', 'doc/training-guides/basic-install-guide/figures/NOVA_install_arch.svg', 'doc/training-guides/basic-install-guide/samples/container-server-1.conf.txt', 'doc/training-guides/basic-install-guide/samples/glance-api.conf', 'doc/training-guides/basic-install-guide/samples/glance-registry.conf', 'doc/training-guides/basic-install-guide/samples/api-paste.ini', 'doc/training-guides/basic-install-guide/section_ceilometer-cinder.xml', 'doc/training-guides/basic-install-guide/samples/object-server-1.conf.txt', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/service_keystone_authtoken_admin_tenant_name.png', 'doc/training-guides/basic-install-guide/section_keystone-verify.xml', 'doc/training-guides/basic-install-guide/ch_cinder.xml', 'doc/training-guides/basic-install-guide/samples/swift.conf.txt', 'doc/training-guides/basic-install-guide/section_basics-ntp.xml', 'doc/training-guides/basic-install-guide/section_neutron-ovs-compute-node.xml', 'doc/training-guides/basic-install-guide/section_trove-install.xml', 'doc/training-guides/basic-install-guide/section_cinder-node.xml', 'doc/training-guides/basic-install-guide/figures/networking-interactions-swift.svg', 'doc/training-guides/basic-install-guide/section_neutron-initial-networks.xml', 'doc/training-guides/basic-install-guide/section_nova-controller-install.xml', 'doc/training-guides/basic-install-guide/object-storage/section_object-storage-install-config-proxy-node.xml', 'doc/training-guides/basic-install-guide/samples/account-server.conf.txt', 'doc/training-guides/basic-install-guide/section_cinder-verify.xml', 'doc/training-guides/basic-install-guide/section_neutron-ovs-network-node.xml', 'doc/training-guides/basic-install-guide/common/section_compute-configure-vnc.xml', 'doc/training-guides/basic-install-guide/ch_heat.xml', 'doc/training-guides/basic-install-guide/section_basics-passwords.xml', 'doc/training-guides/basic-install-guide/common/section_objectstorage_tenant-specific-image-storage.xml', 'doc/training-guides/basic-install-guide/figures/installguide_arch-nova.png', 'doc/training-guides/basic-install-guide/section_heat-verify.xml', 'doc/training-guides/basic-install-guide/figures/debconf-screenshots/neutron_3_hypervisor_ip.png', 'doc/training-guides/basic-install-guide/section_neutron-ml2-controller-node.xml']",176,40b75b7adae2a4d2e7dc613630195a61698f381d,bp/openstack-training-guides,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""neutron-ml2-controller-node""> <title>Configure controller node</title> <procedure os=""ubuntu;rhel;centos;fedora;sles;opensuse""> <title>Prerequisites</title> <para>Before you configure OpenStack Networking (neutron), you must create a database and Identity service credentials including a user and service.</para> <step> <para>Connect to the database as the root user, create the <literal>neutron</literal> database, and grant the proper access to it:</para> <para>Replace <replaceable>NEUTRON_DBPASS</replaceable> with a suitable password.</para> <screen><prompt>$</prompt> <userinput>mysql -u root -p</userinput> <prompt>mysql></prompt> <userinput>CREATE DATABASE neutron;</userinput> <prompt>mysql></prompt> <userinput>GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \ IDENTIFIED BY '<replaceable>NEUTRON_DBPASS</replaceable>';</userinput> <prompt>mysql></prompt> <userinput>GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \ IDENTIFIED BY '<replaceable>NEUTRON_DBPASS</replaceable>';</userinput></screen> </step> <step> <para>Create Identity service credentials for Networking:</para> <substeps> <step> <para>Create the <literal>neutron</literal> user:</para> <para>Replace <replaceable>NEUTRON_PASS</replaceable> with a suitable password and <replaceable>neutron@example.com</replaceable> with a suitable e-mail address.</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name neutron --pass <replaceable>NEUTRON_PASS</replaceable> --email <replaceable>neutron@example.com</replaceable></userinput></screen> </step> <step> <para>Link the <literal>neutron</literal> user to the <literal>service</literal> tenant and <literal>admin</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone user-role-add --user neutron --tenant service --role admin</userinput></screen> </step> <step> <para>Create the <literal>neutron</literal> service:</para> <screen><prompt>$</prompt> <userinput>keystone service-create --name neutron --type network --description ""OpenStack Networking""</userinput></screen> </step> <step> <para>Create the service endpoint:</para> <screen><prompt>$</prompt> <userinput>keystone endpoint-create \ --service-id $(keystone service-list | awk '/ network / {print $2}') \ --publicurl http://<replaceable>controller</replaceable>:9696 \ --adminurl http://<replaceable>controller</replaceable>:9696 \ --internalurl http://<replaceable>controller</replaceable>:9696</userinput></screen> </step> </substeps> </step> </procedure> <procedure> <title>To install the Networking components</title> <step> <screen os=""ubuntu""><prompt>#</prompt> <userinput>apt-get install neutron-server neutron-plugin-ml2</userinput></screen> <screen os=""debian""><prompt>#</prompt> <userinput>apt-get install neutron-server</userinput></screen> <screen os=""rhel;centos;fedora""><prompt>#</prompt> <userinput>yum install openstack-neutron openstack-neutron-ml2 python-neutronclient</userinput></screen> <screen os=""sles;opensuse""><prompt>#</prompt> <userinput>zypper install openstack-neutron openstack-neutron-server</userinput></screen> <note os=""sles;opensuse""> <para>SUSE does not use a separate ML2 plug-in package.</para> </note> <note os=""debian""> <para>Debian does not use a separate ML2 plug-in package.</para> </note> </step> </procedure> <procedure> <title>To configure the Networking server component</title> <para>The Networking server component configuration includes the database, authentication mechanism, message broker, topology change notifier, and plug-in.</para> <step os=""debian""> <para>Respond to prompts for <link linkend=""debconf-dbconfig-common"">database management</link>, <link linkend=""debconf-keystone_authtoken"">Identity service credentials</link>, <link linkend=""debconf-api-endpoints"">service endpoint registration</link>, and <link linkend=""debconf-rabbitmq"">message broker credentials</link>.</para> </step> <step os=""debian""> <para>During the installation, you will also be prompted for which Networking plug-in to use. This will automatically fill the <option>core_plugin</option> directive in the <filename>/etc/neutron/neutron.conf</filename> file.</para> <informalfigure> <mediaobject> <imageobject> <imagedata scale=""50"" fileref=""figures/debconf-screenshots/neutron_1_plugin_selection.png"" /> </imageobject> </mediaobject> </informalfigure> <para>If the ML2 plug-in is selected, then the <option>core_plugin</option> option will be filled with <literal>neutron.plugins.ml2.plugin.Ml2Plugin</literal>, which is the full class name for the ML2 plug-in. In Debian, you cannot (yet) use the short names for the plug-ins. The <option>service_plugins</option> and <option>allow_overlapping_ips</option> options are filled with the appropriate values by default, so it is fine to not touch them.</para> </step> <step os=""rhel;centos;fedora;sles;opensuse""> <para>Configure Networking to use the database:</para> <para>Replace <replaceable>NEUTRON_DBPASS</replaceable> with a suitable password.</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf database connection \ mysql://neutron:<replaceable>NEUTRON_DBPASS</replaceable>@<replaceable>controller</replaceable>/neutron</userinput></screen> </step> <step os=""ubuntu""> <para>Configure Networking to use the database:</para> <substeps> <step> <para>Edit the <filename>/etc/neutron/neutron.conf</filename> file and add the following key to the <literal>[database]</literal> section:</para> <para>Replace <replaceable>NEUTRON_DBPASS</replaceable> with the password you chose for the database.</para> <programlisting language=""ini"">[database] ... connection = mysql://neutron:<replaceable>NEUTRON_DBPASS</replaceable>@<replaceable>controller</replaceable>/neutron</programlisting> </step> </substeps> </step> <step os=""rhel;centos;fedora;sles;opensuse""> <para>Configure Networking to use the Identity service for authentication:</para> <para>Replace <replaceable>NEUTRON_PASS</replaceable> with the password you chose for the <literal>neutron</literal> user in the Identity service.</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ auth_strategy keystone</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf keystone_authtoken \ auth_uri http://<replaceable>controller</replaceable>:5000</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf keystone_authtoken \ auth_host <replaceable>controller</replaceable></userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf keystone_authtoken \ auth_protocol http</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf keystone_authtoken \ auth_port 35357</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf keystone_authtoken \ admin_tenant_name service</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf keystone_authtoken \ admin_user neutron</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf keystone_authtoken \ admin_password <replaceable>NEUTRON_PASS</replaceable></userinput></screen> </step> <step os=""ubuntu""> <para>Configure Networking to use the Identity service for authentication:</para> <substeps> <step> <para>Edit the <filename>/etc/neutron/neutron.conf</filename> file and add the following key to the <literal>[DEFAULT]</literal> section:</para> <programlisting language=""ini"">[DEFAULT] ... auth_strategy = keystone</programlisting> <para>Add the following keys to the <literal>[keystone_authtoken]</literal> section:</para> <para>Replace <replaceable>NEUTRON_PASS</replaceable> with the password you chose for the <literal>neutron</literal> user in the Identity service.</para> <programlisting language=""ini"">[keystone_authtoken] ... auth_uri = http://<replaceable>controller</replaceable>:5000 auth_host = <replaceable>controller</replaceable> auth_protocol = http auth_port = 35357 admin_tenant_name = service admin_user = neutron admin_password = <replaceable>NEUTRON_PASS</replaceable></programlisting> </step> </substeps> </step> <step os=""sles;opensuse;rhel;centos;fedora""> <para>Configure Networking to use the message broker:</para> <para>Replace <replaceable>RABBIT_PASS</replaceable> with the password you chose for the <literal>guest</literal> account in <application>RabbitMQ</application>.</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ rpc_backend neutron.openstack.common.rpc.impl_kombu</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ rabbit_host controller</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ rabbit_userid guest</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ rabbit_password <replaceable>RABBIT_PASS</replaceable></userinput></screen> </step> <step os=""ubuntu""> <para>Configure Networking to use the message broker:</para> <substeps> <step> <para>Edit the <filename>/etc/neutron/neutron.conf</filename> file and add the following keys to the <literal>[DEFAULT]</literal> section:</para> <para>Replace <replaceable>RABBIT_PASS</replaceable> with the password you chose for the <literal>guest</literal> account in <application>RabbitMQ</application>.</para> <programlisting language=""ini"">[DEFAULT] ... rpc_backend = neutron.openstack.common.rpc.impl_kombu rabbit_host = <replaceable>controller</replaceable> rabbit_password = <replaceable>RABBIT_PASS</replaceable></programlisting> </step> </substeps> </step> <step os=""rhel;centos;fedora;sles;opensuse""> <para>Configure Networking to notify Compute about network topology changes:</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ notify_nova_on_port_status_changes True</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ notify_nova_on_port_data_changes True</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ nova_url http://<replaceable>controller</replaceable>:8774/v2</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ nova_admin_username nova</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ nova_admin_tenant_id $(keystone tenant-list | awk '/ service / { print $2 }')</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ nova_admin_password <replaceable>NOVA_PASS</replaceable></userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ nova_admin_auth_url http://<replaceable>controller</replaceable>:35357/v2.0</userinput></screen> </step> <step os=""ubuntu;debian""> <para>Configure Networking to notify Compute about network topology changes:</para> <para>Replace <replaceable>SERVICE_TENANT_ID</replaceable> with the <literal>service</literal> tenant identifier (id) in the Identity service and <replaceable>NOVA_PASS</replaceable> with the password you chose for the <literal>nova</literal> user in the Identity service.</para> <substeps> <step> <para>Edit the <filename>/etc/neutron/neutron.conf</filename> file and add the following keys to the <literal>[DEFAULT]</literal> section:</para> <programlisting language=""ini"">[DEFAULT] ... notify_nova_on_port_status_changes = True notify_nova_on_port_data_changes = True nova_url = http://<replaceable>controller</replaceable>:8774/v2 nova_admin_username = nova nova_admin_tenant_id = <replaceable>SERVICE_TENANT_ID</replaceable> nova_admin_password = <replaceable>NOVA_PASS</replaceable> nova_admin_auth_url = http://<replaceable>controller</replaceable>:35357/v2.0</programlisting> </step> </substeps> <note> <para>To obtain the <literal>service</literal> tenant identifier (id):</para> <screen><prompt>$</prompt> <userinput>source admin-openrc.sh</userinput> <prompt>$</prompt> <userinput>keystone tenant-get service</userinput> <computeroutput>+-------------+----------------------------------+ | Property | Value | +-------------+----------------------------------+ | description | Service Tenant | | enabled | True | | id | f727b5ec2ceb4d71bad86dfc414449bf | | name | service | +-------------+----------------------------------+</computeroutput></screen> </note> </step> <step os=""rhel;centos;fedora;sles;opensuse""> <para>Configure Networking to use the Modular Layer 2 (ML2) plug-in and associated services:</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ core_plugin ml2</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/neutron.conf DEFAULT \ service_plugins router</userinput></screen> <note> <para>We recommend adding <literal>verbose = True</literal> to the <literal>[DEFAULT]</literal> section in <filename>/etc/neutron/neutron.conf</filename> to assist with troubleshooting.</para> </note> </step> <step os=""ubuntu""> <para>Configure Networking to use the Modular Layer 2 (ML2) plug-in and associated services:</para> <substeps> <step> <para>Edit the <filename>/etc/neutron/neutron.conf</filename> file and add the following keys to the <literal>[DEFAULT]</literal> section:</para> <programlisting language=""ini"">[DEFAULT] ... core_plugin = ml2 service_plugins = router allow_overlapping_ips = True</programlisting> <note> <para>We recommend adding <literal>verbose = True</literal> to the <literal>[DEFAULT]</literal> section in <filename>/etc/neutron/neutron.conf</filename> to assist with troubleshooting.</para> </note> </step> </substeps> </step> </procedure> <procedure> <title>To configure the Modular Layer 2 (ML2) plug-in</title> <para>The ML2 plug-in uses the Open vSwitch (OVS) mechanism (agent) to build the virtual networking framework for instances. However, the controller node does not need the OVS agent or service because it does not handle instance network traffic.</para> <step os=""rhel;centos;fedora;sles;opensuse""> <para>Run the following commands:</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 \ type_drivers gre</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 \ tenant_network_types gre</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 \ mechanism_drivers openvswitch</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_gre \ tunnel_id_ranges 1:1000</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup \ firewall_driver neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup \ enable_security_group True</userinput></screen> </step> <step os=""ubuntu;debian""> <para>Edit the <filename>/etc/neutron/plugins/ml2/ml2_conf.ini</filename> file:</para> <para>Add the following keys to the <literal>[ml2]</literal> section:</para> <programlisting language=""ini"">[ml2] ... type_drivers = gre tenant_network_types = gre mechanism_drivers = openvswitch</programlisting> <para>Add the following key to the <literal>[ml2_type_gre]</literal> section:</para> <programlisting language=""ini"">[ml2_type_gre] ... tunnel_id_ranges = 1:1000</programlisting> <para>Add the <literal>[securitygroup]</literal> section and the following keys to it:</para> <programlisting language=""ini"">[securitygroup] ... firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver enable_security_group = True</programlisting> </step> </procedure> <procedure> <title>To configure Compute to use Networking</title> <para>By default, most distributions configure Compute to use legacy networking. You must reconfigure Compute to manage networks through Networking.</para> <step os=""rhel;centos;fedora;sles;opensuse""> <para>Run the following commands:</para> <para>Replace <replaceable>NEUTRON_PASS</replaceable> with the password you chose for the <literal>neutron</literal> user in the Identity service.</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ network_api_class nova.network.neutronv2.api.API</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ neutron_url http://<replaceable>controller</replaceable>:9696</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ neutron_auth_strategy keystone</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ neutron_admin_tenant_name service</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ neutron_admin_username neutron</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ neutron_admin_password <replaceable>NEUTRON_PASS</replaceable></userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ neutron_admin_auth_url http://<replaceable>controller</replaceable>:35357/v2.0</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ linuxnet_interface_driver nova.network.linux_net.LinuxOVSInterfaceDriver</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ firewall_driver nova.virt.firewall.NoopFirewallDriver</userinput> <prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT \ security_group_api neutron</userinput></screen> <note> <para>By default, Compute uses an internal firewall service. Since Networking includes a firewall service, you must disable the Compute firewall service by using the <literal>nova.virt.firewall.NoopFirewallDriver</literal> firewall driver.</para> </note> </step> <step os=""ubuntu;debian""> <para>Edit the <filename>/etc/nova/nova.conf</filename> and add the following keys to the <literal>[DEFAULT]</literal> section:</para> <para>Replace <replaceable>NEUTRON_PASS</replaceable> with the password you chose for the <literal>neutron</literal> user in the Identity service.</para> <programlisting language=""ini"">[DEFAULT] ... network_api_class = nova.network.neutronv2.api.API neutron_url = http://<replaceable>controller</replaceable>:9696 neutron_auth_strategy = keystone neutron_admin_tenant_name = service neutron_admin_username = neutron neutron_admin_password = <replaceable>NEUTRON_PASS</replaceable> neutron_admin_auth_url = http://<replaceable>controller</replaceable>:35357/v2.0 linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver security_group_api = neutron</programlisting> <note> <para>By default, Compute uses an internal firewall service. Since Networking includes a firewall service, you must disable the Compute firewall service by using the <literal>nova.virt.firewall.NoopFirewallDriver</literal> firewall driver.</para> </note> </step> </procedure> <procedure> <title>To finalize installation</title> <step os=""rhel;centos;fedora""> <para>The Networking service initialization scripts expect a symbolic link <filename>/etc/neutron/plugin.ini</filename> pointing to the configuration file associated with your chosen plug-in. Using ML2, for example, the symbolic link must point to <filename>/etc/neutron/plugins/ml2/ml2_conf.ini</filename>. If this symbolic link does not exist, create it using the following commands:</para> <screen><prompt>#</prompt> <userinput>ln -s plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini</userinput></screen> </step> <step os=""sles;opensuse""> <para>The Networking service initialization scripts expect the variable <literal>NEUTRON_PLUGIN_CONF</literal> in file <filename>/etc/sysconfig/neutron</filename> to reference the configuration file associated with your chosen plug-in. Using ML2, for example, edit the <filename>/etc/sysconfig/neutron</filename> file and add the following:</para> <programlisting>NEUTRON_PLUGIN_CONF=""/etc/neutron/plugins/ml2/ml2_conf.ini""</programlisting> </step> <step> <para>Restart the Compute services:</para> <screen os=""rhel;centos;fedora;sles;opensuse""><prompt>#</prompt> <userinput>service openstack-nova-api restart</userinput> <prompt>#</prompt> <userinput>service openstack-nova-scheduler restart</userinput> <prompt>#</prompt> <userinput>service openstack-nova-conductor restart</userinput></screen> <screen os=""ubuntu;debian""><prompt>#</prompt> <userinput>service nova-api restart</userinput> <prompt>#</prompt> <userinput>service nova-scheduler restart</userinput> <prompt>#</prompt> <userinput>service nova-conductor restart</userinput></screen> </step> <step os=""rhel;centos;fedora;sles;opensuse""> <para>Start the Networking service and configure it to start when the system boots:</para> <screen os=""rhel;centos;fedora""><prompt>#</prompt> <userinput>service neutron-server start</userinput> <prompt>#</prompt> <userinput>chkconfig neutron-server on</userinput></screen> <screen os=""sles;opensuse""><prompt>#</prompt> <userinput>service openstack-neutron start</userinput> <prompt>#</prompt> <userinput>chkconfig openstack-neutron on</userinput></screen> </step> <step os=""ubuntu;debian""> <para>Restart the Networking service:</para> <screen><prompt>#</prompt> <userinput>service neutron-server restart</userinput></screen> </step> </procedure> </section> ",,57739,0
openstack%2Fcinder~master~I305d2652709181bacd9f5b21f0201858f91f7a15,openstack/cinder,master,I305d2652709181bacd9f5b21f0201858f91f7a15,XIV volume manage/unmanage support,MERGED,2014-07-13 09:10:29.000000000,2014-07-18 05:03:15.000000000,2014-07-18 05:03:14.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 7198}, {'_account_id': 7420}, {'_account_id': 10213}]","[{'number': 1, 'created': '2014-07-13 09:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1e10e2253e613901e793f85b8d435997c7510b12', 'message': 'XIV volume manage/unmanage support\n\nXIV support for managing and unmanaging volumes.\nPartially Implements: blueprint add-export-import-volumes\n\nChange-Id: I305d2652709181bacd9f5b21f0201858f91f7a15\n'}, {'number': 2, 'created': '2014-07-15 18:00:15.000000000', 'files': ['cinder/tests/test_ibm_xiv_ds8k.py', 'cinder/volume/drivers/ibm/xiv_ds8k.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/65902674a95847490489c047dac465fa08c0a483', 'message': 'XIV volume manage/unmanage support\n\nXIV support for managing and unmanaging volumes.\n\nPartially Implements: blueprint add-export-import-volumes\n\nChange-Id: I305d2652709181bacd9f5b21f0201858f91f7a15\n'}]",1,106610,65902674a95847490489c047dac465fa08c0a483,20,7,2,10213,,,0,"XIV volume manage/unmanage support

XIV support for managing and unmanaging volumes.

Partially Implements: blueprint add-export-import-volumes

Change-Id: I305d2652709181bacd9f5b21f0201858f91f7a15
",git fetch https://review.opendev.org/openstack/cinder refs/changes/10/106610/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/ibm/xiv_ds8k.py'],1,1e10e2253e613901e793f85b8d435997c7510b12,bp/add-export-import-volumes," def manage_existing(self, volume, existing_ref): """"""Brings an existing backend storage object under Cinder management. existing_ref is passed straight through from the API request's manage_existing_ref value, and it is up to the driver how this should be interpreted. It should be sufficient to identify a storage object that the driver should somehow associate with the newly-created cinder volume structure. There are two ways to do this: 1. Rename the backend storage object so that it matches the, volume['name'] which is how drivers traditionally map between a cinder volume and the associated backend storage object. 2. Place some metadata on the volume, or somewhere in the backend, that allows other driver requests (e.g. delete, clone, attach, detach...) to locate the backend storage object when required. If the existing_ref doesn't make sense, or doesn't refer to an existing backend storage object, raise a ManageExistingInvalidReference exception. The volume may have a volume_type, and the driver can inspect that and compare against the properties of the referenced backend storage object. If they are incompatible, raise a ManageExistingVolumeTypeMismatch, specifying a reason for the failure. """""" return self.xiv_ds8k_proxy.manage_volume(volume, existing_ref) def manage_existing_get_size(self, volume, existing_ref): """"""Return size of volume to be managed by manage_existing."""""" return self.xiv_ds8k_proxy.manage_volume_get_size(volume, existing_ref) def unmanage(self, volume): """"""Removes the specified volume from Cinder management."""""" return self.xiv_ds8k_proxy.unmanage_volume(volume)",,40,0
openstack%2Fheat~master~I1892d0c19d0c6355bb5c88e4a0bc4daa59460b72,openstack/heat,master,I1892d0c19d0c6355bb5c88e4a0bc4daa59460b72,"Implement events pagination, sorting and filtering",MERGED,2014-07-03 04:09:32.000000000,2014-07-18 05:03:06.000000000,2014-07-18 05:03:06.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 8276}, {'_account_id': 8289}, {'_account_id': 8290}, {'_account_id': 9622}]","[{'number': 1, 'created': '2014-07-03 04:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/022515277a86c6fb8629fcc7f40ba8f3ac779218', 'message': 'Implement events pagination, sorting and filtering\n\nIt supports pagination(limit and marker),\nsorting(sort_keys and sort_dir) and filtering(filters) of\nthe results for events-list.\n\nImplements blueprint events-pagination\n\nChange-Id: I1892d0c19d0c6355bb5c88e4a0bc4daa59460b72\n'}, {'number': 2, 'created': '2014-07-03 07:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e68742159b3b2607bd12930b00fa3488f2484088', 'message': 'Implement events pagination, sorting and filtering\n\nIt supports pagination(limit and marker),\nsorting(sort_keys and sort_dir) and filtering(filters) of\nthe results for events-list.\n\nImplements blueprint events-pagination\n\nChange-Id: I1892d0c19d0c6355bb5c88e4a0bc4daa59460b72\n'}, {'number': 3, 'created': '2014-07-05 10:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/515a46b7b67916bb4ff29344e51015b0102cfae8', 'message': 'Implement events pagination, sorting and filtering\n\nIt supports pagination(limit and marker),\nsorting(sort_keys and sort_dir) and filtering(filters) of\nthe results for events-list.\n\nImplements blueprint events-pagination\n\nChange-Id: I1892d0c19d0c6355bb5c88e4a0bc4daa59460b72\n'}, {'number': 4, 'created': '2014-07-07 09:20:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e176cfdbcb887b0f3b2bcedacf951e40bc0dd750', 'message': 'Implement events pagination, sorting and filtering\n\nIt supports pagination(limit and marker),\nsorting(sort_keys and sort_dir) and filtering(filters) of\nthe results for events-list.\n\nImplements blueprint events-pagination\n\nChange-Id: I1892d0c19d0c6355bb5c88e4a0bc4daa59460b72\n'}, {'number': 5, 'created': '2014-07-08 08:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7e8b30d6bc2ca1aaeca61f435dd755f7578a79f3', 'message': 'Implement events pagination, sorting and filtering\n\nIt supports pagination(limit and marker),\nsorting(sort_keys and sort_dir) and filtering(filters) of\nthe results for events-list.\n\nImplements blueprint events-pagination\n\nChange-Id: I1892d0c19d0c6355bb5c88e4a0bc4daa59460b72\n'}, {'number': 6, 'created': '2014-07-15 04:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bfff25312125cf3f21480e03f23d50b10b4fe5e8', 'message': 'Implement events pagination, sorting and filtering\n\nIt supports pagination(limit and marker),\nsorting(sort_keys and sort_dir) and filtering(filters) of\nthe results for events-list.\n\nImplements blueprint events-pagination\n\nChange-Id: I1892d0c19d0c6355bb5c88e4a0bc4daa59460b72\n'}, {'number': 7, 'created': '2014-07-15 09:23:37.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/tests/test_rpc_client.py', 'heat/rpc/client.py', 'heat/db/api.py', 'heat/db/sqlalchemy/api.py', 'heat/tests/test_api_openstack_v1.py', 'heat/tests/test_api_cfn_v1.py', 'heat/api/openstack/v1/stacks.py', 'heat/api/openstack/v1/events.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0b50be300e9656c62a19d0fa2a3fec9cc9ba4119', 'message': 'Implement events pagination, sorting and filtering\n\nIt supports pagination(limit and marker),\nsorting(sort_keys and sort_dir) and filtering(filters) of\nthe results for events-list.\n\nImplements blueprint events-pagination\n\nChange-Id: I1892d0c19d0c6355bb5c88e4a0bc4daa59460b72\n'}]",12,104439,0b50be300e9656c62a19d0fa2a3fec9cc9ba4119,50,11,7,8289,,,0,"Implement events pagination, sorting and filtering

It supports pagination(limit and marker),
sorting(sort_keys and sort_dir) and filtering(filters) of
the results for events-list.

Implements blueprint events-pagination

Change-Id: I1892d0c19d0c6355bb5c88e4a0bc4daa59460b72
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/104439/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/rpc/client.py', 'heat/db/api.py', 'heat/db/sqlalchemy/api.py', 'heat/tests/test_api_openstack_v1.py', 'heat/api/openstack/v1/events.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/engine/service.py']",8,022515277a86c6fb8629fcc7f40ba8f3ac779218,bp/events-pagination," def list_events(self, cnxt, stack_identity, filters=None, limit=None, marker=None, sort_keys=None, sort_dir=None): It supports pagination (``limit`` and ``marker``), sorting (``sort_keys`` and ``sort_dir``) and filtering(filters) of the results. :param stack_identity: Name of the stack you want to get events for :param filters: a dict with attribute:value to filter the list :param limit: the number of events to list (integer or string) :param marker: the ID of the last event in the previous page :param sort_keys: an array of fields used to sort the list :param sort_dir: the direction of the sort ('asc' or 'desc'). events = db_api.event_get_all_by_stack(cnxt, st.id, limit=limit, marker=marker, sort_keys=sort_keys, sort_dir=sort_dir, filters=filters) else: events = db_api.event_get_all_by_tenant(cnxt, limit=limit, marker=marker, sort_keys=sort_keys, sort_dir=sort_dir, filters=filters)"," def list_events(self, cnxt, stack_identity): :param stack_identity: Name of the stack you want to get events for. events = db_api.event_get_all_by_stack(cnxt, st.id) else: events = db_api.event_get_all_by_tenant(cnxt)",391,38
openstack%2Ftempest~master~I7b0d64b1db19359e5ff81b7cbbebef0b11946a1b,openstack/tempest,master,I7b0d64b1db19359e5ff81b7cbbebef0b11946a1b,Verify get_instance_action attributes of Nova API,MERGED,2014-04-08 02:21:38.000000000,2014-07-18 05:02:58.000000000,2014-07-18 05:02:57.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5511}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-08 02:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0f0b94513e893929f09c056d0e30ceb1459be0b8', 'message': 'Verify get_instance_action attributes of Nova API\n\nThis patch adds the JSON schema for Nova V2 & V3 get_instance_actions\nAPI response and validate the response with added JSON schema\nto block the backward incompatibility change in the future.\n\nThe response body of get_instance_actions V2 API is below:\n\n{\n    ""instanceAction"": {\n        ""action"": ""reboot"",\n        ""events"": [\n            {\n                ""event"": ""schedule"",\n                ""finish_time"": ""2012-12-05 01:02:00.000000"",\n                ""result"": ""Success"",\n                ""start_time"": ""2012-12-05 01:00:02.000000"",\n                ""traceback"": """"\n            },\n            {\n                ""event"": ""compute_create"",\n                ""finish_time"": ""2012-12-05 01:04:00.000000"",\n                ""result"": ""Success"",\n                ""start_time"": ""2012-12-05 01:03:00.000000"",\n                ""traceback"": """"\n            }\n        ],\n        ""instance_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"",\n        ""message"": """",\n        ""project_id"": ""147"",\n        ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"",\n        ""start_time"": ""2012-12-05 00:00:00.000000"",\n        ""user_id"": ""789""\n    }\n}\n\nThe response body of get_instance_actions V3 API is below:\n\n{\n    ""instance_action"": {\n        ""action"": ""reboot"",\n        ""events"": [\n            {\n                ""event"": ""schedule"",\n                ""finish_time"": ""2012-12-05T01:02:00.000000"",\n                ""result"": ""Success"",\n                ""start_time"": ""2012-12-05T01:00:02.000000"",\n                ""traceback"": """"\n            },\n            {\n                ""event"": ""compute_create"",\n                ""finish_time"": ""2012-12-05T01:04:00.000000"",\n                ""result"": ""Success"",\n                ""start_time"": ""2012-12-05T01:03:00.000000"",\n                ""traceback"": """"\n            }\n        ],\n        ""instance_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"",\n        ""message"": """",\n        ""project_id"": ""147"",\n        ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"",\n        ""start_time"": ""2012-12-05T00:00:00.000000"",\n        ""user_id"": ""789""\n    }\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: I7b0d64b1db19359e5ff81b7cbbebef0b11946a1b\n'}, {'number': 2, 'created': '2014-04-08 03:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ae2880f379ac2885e90d7da96e00bfb55b985bce', 'message': 'Verify get_instance_action attributes of Nova API\n\nThis patch adds the JSON schema for Nova V2 & V3 get_instance_actions\nAPI response and validate the response with added JSON schema\nto block the backward incompatibility change in the future.\n\nThe response body of get_instance_actions V2 API is below:\n\n{\n    ""instanceAction"": {\n        ""action"": ""reboot"",\n        ""instance_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"",\n        ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"",\n        ""user_id"": ""789"",\n        ""project_id"": ""147"",\n        ""start_time"": ""2012-12-05 00:00:00.000000"",\n        ""message"": """",\n        ""events"": [\n            {\n                ""event"": ""schedule"",\n                ""start_time"": ""2012-12-05 01:00:02.000000"",\n                ""finish_time"": ""2012-12-05 01:02:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            },\n            {\n                ""event"": ""compute_create"",\n                ""start_time"": ""2012-12-05 01:03:00.000000"",\n                ""finish_time"": ""2012-12-05 01:04:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            }\n        ]\n    }\n}\n\nThe response body of get_instance_actions V3 API is below:\n\n{\n    ""instance_action"": {\n        ""action"": ""reboot"",\n        ""instance_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"",\n        ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"",\n        ""user_id"": ""789"",\n        ""project_id"": ""147"",\n        ""start_time"": ""2012-12-05T00:00:00.000000"",\n        ""message"": """",\n        ""events"": [\n            {\n                ""event"": ""schedule"",\n                ""start_time"": ""2012-12-05T01:00:02.000000"",\n                ""finish_time"": ""2012-12-05T01:02:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            },\n            {\n                ""event"": ""compute_create"",\n                ""start_time"": ""2012-12-05T01:03:00.000000"",\n                ""finish_time"": ""2012-12-05T01:04:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            }\n        ]\n    }\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: I7b0d64b1db19359e5ff81b7cbbebef0b11946a1b\n'}, {'number': 3, 'created': '2014-04-08 03:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6834e266cb9623c28454569f0f2f0ffcd5940409', 'message': 'Verify get_instance_action attributes of Nova API\n\nThis patch adds the JSON schema for Nova V2 & V3 get_instance_actions\nAPI response and validate the response with added JSON schema\nto block the backward incompatibility change in the future.\n\nThe response body of get_instance_actions V2 API is below:\n\n{\n    ""instanceAction"": {\n        ""action"": ""reboot"",\n        ""instance_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"",\n        ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"",\n        ""user_id"": ""789"",\n        ""project_id"": ""147"",\n        ""start_time"": ""2012-12-05 00:00:00.000000"",\n        ""message"": """",\n        ""events"": [\n            {\n                ""event"": ""schedule"",\n                ""start_time"": ""2012-12-05 01:00:02.000000"",\n                ""finish_time"": ""2012-12-05 01:02:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            },\n            {\n                ""event"": ""compute_create"",\n                ""start_time"": ""2012-12-05 01:03:00.000000"",\n                ""finish_time"": ""2012-12-05 01:04:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            }\n        ]\n    }\n}\n\nThe response body of get_instance_actions V3 API is below:\n\n{\n    ""instance_action"": {\n        ""action"": ""reboot"",\n        ""instance_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"",\n        ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"",\n        ""user_id"": ""789"",\n        ""project_id"": ""147"",\n        ""start_time"": ""2012-12-05T00:00:00.000000"",\n        ""message"": """",\n        ""events"": [\n            {\n                ""event"": ""schedule"",\n                ""start_time"": ""2012-12-05T01:00:02.000000"",\n                ""finish_time"": ""2012-12-05T01:02:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            },\n            {\n                ""event"": ""compute_create"",\n                ""start_time"": ""2012-12-05T01:03:00.000000"",\n                ""finish_time"": ""2012-12-05T01:04:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            }\n        ]\n    }\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: I7b0d64b1db19359e5ff81b7cbbebef0b11946a1b\n'}, {'number': 4, 'created': '2014-07-17 04:42:09.000000000', 'files': ['tempest/api_schema/compute/v3/servers.py', 'tempest/services/compute/json/servers_client.py', 'tempest/api_schema/compute/v2/servers.py', 'tempest/services/compute/v3/json/servers_client.py', 'tempest/api_schema/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4b41dfd3dae1050c7263c395febb0c907abd94b9', 'message': 'Verify get_instance_action attributes of Nova API\n\nThis patch adds the JSON schema for Nova V2 & V3 get_instance_actions\nAPI response and validate the response with added JSON schema\nto block the backward incompatibility change in the future.\n\nThe response body of get_instance_actions V2 API is below:\n{\n    ""instanceAction"": {\n        ""action"": ""reboot"",\n        ""instance_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"",\n        ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"",\n        ""user_id"": ""789"",\n        ""project_id"": ""147"",\n        ""start_time"": ""2012-12-05 00:00:00.000000"",\n        ""message"": """",\n        ""events"": [\n            {\n                ""event"": ""schedule"",\n                ""start_time"": ""2012-12-05 01:00:02.000000"",\n                ""finish_time"": ""2012-12-05 01:02:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            },\n            {\n                ""event"": ""compute_create"",\n                ""start_time"": ""2012-12-05 01:03:00.000000"",\n                ""finish_time"": ""2012-12-05 01:04:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            }\n        ]\n    }\n}\n\nThe response body of get_instance_actions V3 API is below:\n{\n    ""server_action"": {\n        ""action"": ""reboot"",\n        ""server_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"",\n        ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"",\n        ""user_id"": ""789"",\n        ""project_id"": ""147"",\n        ""start_time"": ""2012-12-05T00:00:00.000000"",\n        ""message"": """",\n        ""events"": [\n            {\n                ""event"": ""schedule"",\n                ""start_time"": ""2012-12-05T01:00:02.000000"",\n                ""finish_time"": ""2012-12-05T01:02:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            },\n            {\n                ""event"": ""compute_create"",\n                ""start_time"": ""2012-12-05T01:03:00.000000"",\n                ""finish_time"": ""2012-12-05T01:04:00.000000"",\n                ""result"": ""Success"",\n                ""traceback"": """"\n            }\n        ]\n    }\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: I7b0d64b1db19359e5ff81b7cbbebef0b11946a1b\n'}]",0,85887,4b41dfd3dae1050c7263c395febb0c907abd94b9,31,6,4,8556,,,0,"Verify get_instance_action attributes of Nova API

This patch adds the JSON schema for Nova V2 & V3 get_instance_actions
API response and validate the response with added JSON schema
to block the backward incompatibility change in the future.

The response body of get_instance_actions V2 API is below:
{
    ""instanceAction"": {
        ""action"": ""reboot"",
        ""instance_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"",
        ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"",
        ""user_id"": ""789"",
        ""project_id"": ""147"",
        ""start_time"": ""2012-12-05 00:00:00.000000"",
        ""message"": """",
        ""events"": [
            {
                ""event"": ""schedule"",
                ""start_time"": ""2012-12-05 01:00:02.000000"",
                ""finish_time"": ""2012-12-05 01:02:00.000000"",
                ""result"": ""Success"",
                ""traceback"": """"
            },
            {
                ""event"": ""compute_create"",
                ""start_time"": ""2012-12-05 01:03:00.000000"",
                ""finish_time"": ""2012-12-05 01:04:00.000000"",
                ""result"": ""Success"",
                ""traceback"": """"
            }
        ]
    }
}

The response body of get_instance_actions V3 API is below:
{
    ""server_action"": {
        ""action"": ""reboot"",
        ""server_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"",
        ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"",
        ""user_id"": ""789"",
        ""project_id"": ""147"",
        ""start_time"": ""2012-12-05T00:00:00.000000"",
        ""message"": """",
        ""events"": [
            {
                ""event"": ""schedule"",
                ""start_time"": ""2012-12-05T01:00:02.000000"",
                ""finish_time"": ""2012-12-05T01:02:00.000000"",
                ""result"": ""Success"",
                ""traceback"": """"
            },
            {
                ""event"": ""compute_create"",
                ""start_time"": ""2012-12-05T01:03:00.000000"",
                ""finish_time"": ""2012-12-05T01:04:00.000000"",
                ""result"": ""Success"",
                ""traceback"": """"
            }
        ]
    }
}

Partially implements blueprint nova-api-attribute-test

Change-Id: I7b0d64b1db19359e5ff81b7cbbebef0b11946a1b
",git fetch https://review.opendev.org/openstack/tempest refs/changes/87/85887/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api_schema/compute/v3/servers.py', 'tempest/services/compute/json/servers_client.py', 'tempest/api_schema/compute/v2/servers.py', 'tempest/services/compute/v3/json/servers_client.py', 'tempest/api_schema/compute/servers.py']",5,0f0b94513e893929f09c056d0e30ceb1459be0b8,bp/nova-api-attribute-test,"import copy instance_action_events = { 'type': 'array', 'items': { 'type': 'object', 'properties': { 'event': {'type': 'string'}, 'start_time': {'type': 'string'}, 'finish_time': {'type': 'string'}, 'result': {'type': 'string'}, 'traceback': {'type': ['string', 'null']} }, 'required': ['event', 'start_time', 'finish_time', 'result', 'traceback'] } } common_get_instance_action = copy.deepcopy(common_instance_action) common_get_instance_action['properties'].update({ 'events': instance_action_events}) common_get_instance_action['required'].extend(['events'])",,48,0
openstack%2Ftempest~master~I0b975548ff3656e8a052c79c7b9ffa1d8d721024,openstack/tempest,master,I0b975548ff3656e8a052c79c7b9ffa1d8d721024,Skip baremetal tests if driver not supported,MERGED,2014-06-25 20:21:40.000000000,2014-07-18 05:01:26.000000000,2014-07-18 05:01:25.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1420}, {'_account_id': 1921}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-25 20:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/88cd94ea6fc6f73cf7f6659ebd7e06b1839fa965', 'message': 'Skip baremetal tests if driver not supported\n\nAdds a new config option to the baremetal section for declaring the\ntarget driver to be used in the baremteal API tests.  The list of\nsupported drivers will be extended/removed as we support API testing\nagainst clouds with real drivers enabled.\n\nChange-Id: I0b975548ff3656e8a052c79c7b9ffa1d8d721024\nPartial-bug: #1334423.\n'}, {'number': 2, 'created': '2014-07-07 17:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/57407c7a6ca7b5eff75e503e3b205d65a8a2e9e3', 'message': 'Skip baremetal tests if driver not supported\n\nAdds a new config option to the baremetal section for declaring the\ntarget driver to be used in the baremteal API tests.  The list of\nsupported drivers will be extended/removed as we support API testing\nagainst clouds with real drivers enabled.\n\nChange-Id: I0b975548ff3656e8a052c79c7b9ffa1d8d721024\nPartial-bug: #1334423.\n'}, {'number': 3, 'created': '2014-07-11 02:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6841bb85671953aedddd963cd0ca0c87dbf17fa0', 'message': 'Skip baremetal tests if driver not supported\n\nAdds a new config option to the baremetal section for declaring the\ntarget driver to be used in the baremteal API tests.  The list of\nsupported drivers will be extended/removed as we support API testing\nagainst clouds with real drivers enabled.\n\nChange-Id: I0b975548ff3656e8a052c79c7b9ffa1d8d721024\nPartial-bug: #1334423.\n'}, {'number': 4, 'created': '2014-07-11 02:27:33.000000000', 'files': ['tempest/api/baremetal/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3e8f7968b7e72396a96fcbaa46afbb14b876e710', 'message': 'Skip baremetal tests if driver not supported\n\nAdds a list of supported Ironic drivers that can be used for its API tests and\nskips if the configured driver is not supported..  The list of supported\ndrivers will be extended/removed as we support API testing against clouds with\nreal drivers enabled.\n\nChange-Id: I0b975548ff3656e8a052c79c7b9ffa1d8d721024\nPartial-bug: #1334423.\n'}]",2,102628,3e8f7968b7e72396a96fcbaa46afbb14b876e710,55,13,4,1420,,,0,"Skip baremetal tests if driver not supported

Adds a list of supported Ironic drivers that can be used for its API tests and
skips if the configured driver is not supported..  The list of supported
drivers will be extended/removed as we support API testing against clouds with
real drivers enabled.

Change-Id: I0b975548ff3656e8a052c79c7b9ffa1d8d721024
Partial-bug: #1334423.
",git fetch https://review.opendev.org/openstack/tempest refs/changes/28/102628/3 && git format-patch -1 --stdout FETCH_HEAD,"['etc/tempest.conf.sample', 'tempest/api/baremetal/base.py', 'tempest/config.py', 'tempest/api/baremetal/test_drivers.py']",4,88cd94ea6fc6f73cf7f6659ebd7e06b1839fa965,baremetal_driver_config," self.assertIn(self.driver, [d['name'] for d in drivers['drivers']])"," self.assertIn('fake', [d['name'] for d in drivers['drivers']])",21,4
openstack%2Fironic~master~Ia1f9c5449612871a379377d11fb0fe91b0958026,openstack/ironic,master,Ia1f9c5449612871a379377d11fb0fe91b0958026,"ManagementInterface {set, get}_boot_device() to support 'persistent'",MERGED,2014-07-09 14:56:55.000000000,2014-07-18 04:48:43.000000000,2014-07-17 17:45:36.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7419}, {'_account_id': 7711}, {'_account_id': 8125}]","[{'number': 1, 'created': '2014-07-09 14:56:55.000000000', 'files': ['ironic/drivers/base.py', 'ironic/drivers/modules/fake.py', 'ironic/tests/drivers/test_fake.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4b3276e918238d213510a353e232bd6039bf18ad', 'message': ""ManagementInterface {set, get}_boot_device() to support 'persistent'\n\nIt's common for drivers to be able to set the boot device only for the\nnext boot (that's the default behavior for the IPMITool for example)\nbut it's also possible to set a boot device as persistent so that the\nconfiguration will persist across multiple boots. This patch is making\nthe 'persistent' parameter to be part of the method signature of the\nset_boot_device() method and also making the get_boot_device() method\nto return whether the device is set as persistent or not as part of\nthe response.\n\nImplements: blueprint new-management-interface\nChange-Id: Ia1f9c5449612871a379377d11fb0fe91b0958026\n""}]",0,105757,4b3276e918238d213510a353e232bd6039bf18ad,22,7,1,6773,,,0,"ManagementInterface {set, get}_boot_device() to support 'persistent'

It's common for drivers to be able to set the boot device only for the
next boot (that's the default behavior for the IPMITool for example)
but it's also possible to set a boot device as persistent so that the
configuration will persist across multiple boots. This patch is making
the 'persistent' parameter to be part of the method signature of the
set_boot_device() method and also making the get_boot_device() method
to return whether the device is set as persistent or not as part of
the response.

Implements: blueprint new-management-interface
Change-Id: Ia1f9c5449612871a379377d11fb0fe91b0958026
",git fetch https://review.opendev.org/openstack/ironic refs/changes/57/105757/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/base.py', 'ironic/drivers/modules/fake.py', 'ironic/tests/drivers/test_fake.py']",3,4b3276e918238d213510a353e232bd6039bf18ad,bp/new-management-interface," expected = {'boot_device': boot_devices.PXE, 'persistent': False} self.assertEqual(expected,"," self.assertEqual(boot_devices.PXE,",14,7
openstack%2Fhorizon~master~Ifbfa84a008d7b61e4b53f885793c5a1750dade3c,openstack/horizon,master,Ifbfa84a008d7b61e4b53f885793c5a1750dade3c,'Create Volume Snapshot' form should show the quota for snapshot,MERGED,2014-02-21 08:21:39.000000000,2014-07-18 04:24:51.000000000,2014-07-18 04:24:50.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1816}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 4428}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 8648}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9531}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 10247}, {'_account_id': 10295}]","[{'number': 1, 'created': '2014-02-21 08:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d4c169dca5ab1b8f7416415dc02039beec5c24f6', 'message': '\'Create Volume Snapshot\' form should show the quota for snapshot\n\nWhen creating a new volume snapshot the window shows the quota of number\nof volumes and what should be shown is the quota of snapshots.\nBasically, the code was pasted from ""Create Volume"" and nothing has been\nchanged to respect the equivalent quotas.\n\nChange-Id: Ifbfa84a008d7b61e4b53f885793c5a1750dade3c\nCloses-bug: 1282172\n'}, {'number': 2, 'created': '2014-02-28 03:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7537f2f0bf7b9bc74c1103acd05d1f72b8d9c5fb', 'message': '\'Create Volume Snapshot\' form should show the quota for snapshot\n\nWhen creating a new volume snapshot the window shows the quota of number\nof volumes and what should be shown is the quota of snapshots.\nBasically, the code was pasted from ""Create Volume"" and nothing has been\nchanged to respect the equivalent quotas.\n\nChange-Id: Ifbfa84a008d7b61e4b53f885793c5a1750dade3c\nCloses-bug: 1282172\n'}, {'number': 3, 'created': '2014-03-17 08:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/04e97d6f9280c5997891a560817318fe07c41430', 'message': '\'Create Volume Snapshot\' form should show the quota for snapshot\n\nWhen creating a new volume snapshot the window shows the quota of number\nof volumes and what should be shown is the quota of snapshots.\nBasically, the code was pasted from ""Create Volume"" and nothing has been\nchanged to respect the equivalent quotas.\n\nChange-Id: Ifbfa84a008d7b61e4b53f885793c5a1750dade3c\nCloses-bug: 1282172\n'}, {'number': 4, 'created': '2014-03-19 08:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/09e2f7aaed1f70ac53ffb6ec3d2dcfb54a362a59', 'message': '\'Create Volume Snapshot\' form should show the quota for snapshot\n\nWhen creating a new volume snapshot the window shows the quota of number\nof volumes and what should be shown is the quota of snapshots.\nBasically, the code was pasted from ""Create Volume"" and nothing has been\nchanged to respect the equivalent quotas.\n\nChange-Id: Ifbfa84a008d7b61e4b53f885793c5a1750dade3c\nCloses-bug: 1282172\n'}, {'number': 5, 'created': '2014-04-09 07:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b144f9e95531bd6c057ac76287db5f898cc4fee4', 'message': '\'Create Volume Snapshot\' form should show the quota for snapshot\n\nWhen creating a new volume snapshot the window shows the quota of number\nof volumes and what should be shown is the quota of snapshots.\nBasically, the code was pasted from ""Create Volume"" and nothing has been\nchanged to respect the equivalent quotas.\n\nChange-Id: Ifbfa84a008d7b61e4b53f885793c5a1750dade3c\nCloses-bug: 1282172\n'}, {'number': 6, 'created': '2014-05-07 00:40:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/02847342a2d0a82fefe947321a0649ce9389902d', 'message': '\'Create Volume Snapshot\' form should show the quota for snapshot\n\nWhen creating a new volume snapshot the window shows the quota of number\nof volumes and what should be shown is the quota of snapshots.\nBasically, the code was pasted from ""Create Volume"" and nothing has been\nchanged to respect the equivalent quotas.\n\nChange-Id: Ifbfa84a008d7b61e4b53f885793c5a1750dade3c\nCloses-bug: 1282172\n'}, {'number': 7, 'created': '2014-05-21 03:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/20ad23e4accdd89cd145d6db6cf8c284535fa088', 'message': '\'Create Volume Snapshot\' form should show the quota for snapshot\n\nWhen creating a new volume snapshot the window shows the quota of number\nof volumes and what should be shown is the quota of snapshots.\nBasically, the code was pasted from ""Create Volume"" and nothing has been\nchanged to respect the equivalent quotas.\n\nChange-Id: Ifbfa84a008d7b61e4b53f885793c5a1750dade3c\nCloses-bug: 1282172\n'}, {'number': 8, 'created': '2014-05-23 09:46:37.000000000', 'files': ['openstack_dashboard/dashboards/project/volumes/templates/volumes/volumes/_limits.html', 'openstack_dashboard/dashboards/project/volumes/templates/volumes/volumes/_snapshot_limits.html', 'openstack_dashboard/dashboards/project/volumes/snapshots/tests.py', 'openstack_dashboard/dashboards/project/volumes/templates/volumes/volumes/_create_snapshot.html', 'openstack_dashboard/usage/quotas.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/44a6df30fccd5b56eab1ebaf625f113d8c45c62e', 'message': '\'Create Volume Snapshot\' form should show the quota for snapshot\n\nWhen creating a new volume snapshot the window shows the quota of number\nof volumes and what should be shown is the quota of snapshots.\nBasically, the code was pasted from ""Create Volume"" and nothing has been\nchanged to respect the equivalent quotas.\n\nChange-Id: Ifbfa84a008d7b61e4b53f885793c5a1750dade3c\nCloses-bug: 1282172\n'}]",7,75338,44a6df30fccd5b56eab1ebaf625f113d8c45c62e,101,17,8,4428,,,0,"'Create Volume Snapshot' form should show the quota for snapshot

When creating a new volume snapshot the window shows the quota of number
of volumes and what should be shown is the quota of snapshots.
Basically, the code was pasted from ""Create Volume"" and nothing has been
changed to respect the equivalent quotas.

Change-Id: Ifbfa84a008d7b61e4b53f885793c5a1750dade3c
Closes-bug: 1282172
",git fetch https://review.opendev.org/openstack/horizon refs/changes/38/75338/8 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/volumes/templates/volumes/_create_snapshot.html', 'openstack_dashboard/dashboards/project/volumes/templates/volumes/_snapshot_limits.html', 'openstack_dashboard/usage/quotas.py']",3,d4c169dca5ab1b8f7416415dc02039beec5c24f6,bug/1282172, snapshots = cinder.volume_snapshot_list(request) limits['snapshotsUsed'] = len(snapshots),,29,1
openstack%2Ftempest~master~Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8,openstack/tempest,master,Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8,Added Heat Software Config-Deploy API tests,MERGED,2014-04-23 10:51:11.000000000,2014-07-18 04:12:55.000000000,2014-07-18 04:12:54.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 5196}, {'_account_id': 5292}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6796}, {'_account_id': 7872}, {'_account_id': 8824}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10090}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-23 10:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1e79664b98e6f902d419259b367f444b349718aa', 'message': 'Added HEAT Software Config-Deploy a test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 2, 'created': '2014-04-27 05:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/546745b790eb2346b590da18aa811cdcbbffee6d', 'message': 'Added HEAT Software Config-Deploy a test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 3, 'created': '2014-04-29 12:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/570e104a620cf0bcc0d3752c93e71a66ebdc0ef6', 'message': 'Added HEAT Software Config-Deploy a test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 4, 'created': '2014-04-30 13:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4fc9f40a3153e417f82a6b527472ba81698557ce', 'message': 'Added Heat Software Config-Deploy a test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 5, 'created': '2014-05-01 06:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/67334f30eba7862d37caebc157e88d0052098950', 'message': 'Added Heat Software Config-Deploy a test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 6, 'created': '2014-05-01 11:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bc8e0899f1b52dda90b39a2d72a1365acf9b37d3', 'message': 'Added Heat Software Config-Deploy a test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 7, 'created': '2014-05-07 10:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7b855c14cdf87029aa6dd440de22864b9c3df7f8', 'message': 'Added Heat Software Config-Deploy API test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 8, 'created': '2014-05-08 06:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf5d31911f2e03019ea45c8c050e3e30c2bbd5fb', 'message': 'Added Heat Software Config-Deploy API test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 9, 'created': '2014-05-19 09:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/842e9794dae8dc4ed1a8c39bb71034a2fce4aef2', 'message': 'Added Heat Software Config-Deploy API test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 10, 'created': '2014-05-19 10:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e53b1348ff699a84cb08ea4bb437014a9ec7a095', 'message': 'Added Heat Software Config-Deploy API test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 11, 'created': '2014-05-26 20:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a6b528b0cb79fb7aee0ff85d9e10515c00ce5264', 'message': 'Added Heat Software Config-Deploy API test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 12, 'created': '2014-06-05 11:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6f274e8b0a68c64f6e4d81cefd51e8930643e2c0', 'message': 'Added Heat Software Config-Deploy API test\n\nAdded functions to base and to the JSON client to support the new API\nAdded a small test to verify the calls\n\nAdded response and body testing to the test itself, not to base.py\nI added it there because it keeps base.py less susceptible to changes\nand gives me better control\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 13, 'created': '2014-06-25 05:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e7ae439a826a4d25939a7748a271939ca0fa64ba', 'message': 'Added Heat Software Config-Deploy API tests\n\nAdded functions to the JSON client to support the new software\nconfiguration API.\nSoftware configurations and deployments are tiered and dependant on each\nother so splitting the API calls to smaller tests is impossible.\nEach test verifies different things, this is how I tried to prevent the\ntests from being too bloated.\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 14, 'created': '2014-07-09 06:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9464332f6b08ffa8913eb8792fa9bdd398ca3c0f', 'message': 'Added Heat Software Config-Deploy API tests\n\nAdded functions to the JSON client to support the new software\nconfiguration API.\nSoftware configurations and deployments are tiered and dependant on each\nother so splitting the API calls to smaller tests is impossible.\nEach test verifies different things, this is how I tried to prevent the\ntests from being too bloated.\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 15, 'created': '2014-07-09 09:33:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/30b005c8533f940916d7fac7695a37f4f19ffe73', 'message': 'Added Heat Software Config-Deploy API tests\n\nAdded functions to the JSON client to support the new software\nconfiguration API.\nSoftware configurations and deployments are tiered and dependant on each\nother so splitting the API calls to smaller tests is impossible.\nEach test verifies different things, this is how I tried to prevent the\ntests from being too bloated.\n\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 16, 'created': '2014-07-10 13:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/837d0b6ab03111ee9264c4898049394ce13a03f8', 'message': 'Added Heat Software Config-Deploy API tests\n\nAdded functions to the JSON client to support the new software\nconfiguration API.\nSoftware configurations and deployments are tiered and dependant on each\nother so splitting the API calls to smaller tests is impossible.\nEach test verifies different things, this is how I tried to prevent the\ntests from being too bloated.\n\nCo-Authored-By: Steven Hardy <shardy@redhat.com>\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}, {'number': 17, 'created': '2014-07-16 11:22:28.000000000', 'files': ['tempest/services/orchestration/json/orchestration_client.py', 'tempest/api/orchestration/stacks/test_soft_conf.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2a63ee0a3ab3770d2988a088f191acba18b8f1d8', 'message': 'Added Heat Software Config-Deploy API tests\n\nAdded functions to the JSON client to support the new software\nconfiguration API.\nSoftware configurations and deployments are tiered and dependant on each\nother so splitting the API calls to smaller tests is impossible.\nEach test verifies different things, this is how I tried to prevent the\ntests from being too bloated.\n\nCo-Authored-By: Steven Hardy <shardy@redhat.com>\nChange-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8\n'}]",80,89790,2a63ee0a3ab3770d2988a088f191acba18b8f1d8,158,18,17,10090,,,0,"Added Heat Software Config-Deploy API tests

Added functions to the JSON client to support the new software
configuration API.
Software configurations and deployments are tiered and dependant on each
other so splitting the API calls to smaller tests is impossible.
Each test verifies different things, this is how I tried to prevent the
tests from being too bloated.

Co-Authored-By: Steven Hardy <shardy@redhat.com>
Change-Id: Ied896fcaf3cf4a80385b28235eb5f4af9cd182c8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/90/89790/16 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/orchestration/stacks/test_soft_conf.py', 'tempest/services/orchestration/json/orchestration_client.py', 'tempest/api/orchestration/base.py']",3,1e79664b98e6f902d419259b367f444b349718aa,cmyster_patch," @classmethod def create_soft_conf(cls, name, conf, group, inputs, outputs, options): resp, body = cls.client.create_soft_conf( name=name, conf=conf, group=group, inputs=inputs, outputs=outputs, options=options) return resp, body @classmethod def update_soft_deploy(cls, deploy_id, server_id, config_id, action, status, input_values, output_values, status_reason, signal_transport): resp, body = cls.client.update_soft_deploy( deploy_id=deploy_id, server_id=server_id, config_id=config_id, action=action, status=status, input_values=input_values, output_values=output_values, status_reason=status_reason, signal_transport=signal_transport) return resp, body",,284,0
openstack%2Fnova~master~Ie2ac7bb07635aba49e9af7e311e38dbc38610aa3,openstack/nova,master,Ie2ac7bb07635aba49e9af7e311e38dbc38610aa3,Use consistent request/response body for flavor extra_specs in v3,ABANDONED,2013-11-25 08:41:41.000000000,2014-07-18 04:08:04.000000000,,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 7040}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}]","[{'number': 1, 'created': '2013-11-25 08:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6018d8d3b9b8351a9d95bd1adfc88ede5ab6b136', 'message': 'Add \'extra_specs\' as root key for flavor extra_specs update in v3\n\nThe request body of creating extra_specs is \'{""extra_specs"": {""k"": ""v}}\'.\nBut the request body of updating extra_specs is \'{""k"": ""v""}\'. This is\ninconsistent. So add extra_specs as root key for update\'s request body.\nAnd modify related unittest and api samples.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Ie2ac7bb07635aba49e9af7e311e38dbc38610aa3\n'}, {'number': 2, 'created': '2013-12-02 08:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/724a575defd9fa065d629df0b8095ce4f5d501f5', 'message': 'Add \'extra_specs\' as root key for flavor extra_specs update in v3\n\nThe request body of creating extra_specs is \'{""extra_specs"": {""k"": ""v}}\'.\nBut the request body of updating extra_specs is \'{""k"": ""v""}\'. This is\ninconsistent. So add extra_specs as root key for update\'s request body.\nAnd modify related unittest and api samples.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Ie2ac7bb07635aba49e9af7e311e38dbc38610aa3\n'}, {'number': 3, 'created': '2013-12-02 08:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/308164ba6d324b63a19aa0da922f4bcd3ded7665', 'message': 'Use consistent request/response body for flavor extra_specs in v3\n\nThe request body of creating extra_specs is \'{""extra_specs"": {""k"": ""v}}\'.\nBut the request body of updating extra_specs is \'{""k"": ""v""}\'. This is\ninconsistent. So adds \'extra_spec\' as root key for update\'s request body.\nAlso corrects the singular form for the response of show. And modify related\nunittest and api samples.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Ie2ac7bb07635aba49e9af7e311e38dbc38610aa3\n'}, {'number': 4, 'created': '2013-12-03 07:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/76a96e5e03655b1bd6951240f1a40f4ee8ebb535', 'message': 'Use consistent request/response body for flavor extra_specs in v3\n\nThe request body of creating extra_specs is \'{""extra_specs"": {""k"": ""v}}\'.\nBut the request body of updating extra_specs is \'{""k"": ""v""}\'. This is\ninconsistent. So adds \'extra_spec\' as root key for update\'s request body.\nAlso corrects the singular form for the response of show. And modify related\nunittest and api samples.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Ie2ac7bb07635aba49e9af7e311e38dbc38610aa3\n'}, {'number': 5, 'created': '2014-02-17 07:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58acb2d7df508d55025908678ff20c2045fc17a3', 'message': 'Use consistent request/response body for flavor extra_specs in v3\n\nThe request body of creating extra_specs is \'{""extra_specs"": {""k"": ""v}}\'.\nBut the request body of updating extra_specs is \'{""k"": ""v""}\'. This is\ninconsistent. So adds \'extra_spec\' as root key for update\'s request body.\nAlso corrects the singular form for the response of show. And modify related\nunittest and api samples.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Ie2ac7bb07635aba49e9af7e311e38dbc38610aa3\n'}, {'number': 6, 'created': '2014-02-17 08:56:33.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/tests/integrated/v3/api_samples/flavor-extra-specs/flavor-extra-specs-update-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/flavor-extra-specs/flavor-extra-specs-update-req.json.tpl', 'doc/v3/api_samples/flavor-extra-specs/flavor-extra-specs-get-resp.json', 'doc/v3/api_samples/flavor-extra-specs/flavor-extra-specs-update-req.json', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors_extra_specs.py', 'nova/tests/integrated/v3/api_samples/flavor-extra-specs/flavor-extra-specs-get-resp.json.tpl', 'doc/v3/api_samples/flavor-extra-specs/flavor-extra-specs-update-resp.json'], 'web_link': 'https://opendev.org/openstack/nova/commit/861f458a59cc516d02ba93863e25656eb5f63140', 'message': 'Use consistent request/response body for flavor extra_specs in v3\n\nThe request body of creating extra_specs is \'{""extra_specs"": {""k"": ""v}}\'.\nBut the request body of updating extra_specs is \'{""k"": ""v""}\'. This is\ninconsistent. So adds \'extra_spec\' as root key for update\'s request body.\nAlso corrects the singular form for the response of show. And modify related\nunittest and api samples.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Ie2ac7bb07635aba49e9af7e311e38dbc38610aa3\n'}]",9,58218,861f458a59cc516d02ba93863e25656eb5f63140,51,9,6,5754,,,0,"Use consistent request/response body for flavor extra_specs in v3

The request body of creating extra_specs is '{""extra_specs"": {""k"": ""v}}'.
But the request body of updating extra_specs is '{""k"": ""v""}'. This is
inconsistent. So adds 'extra_spec' as root key for update's request body.
Also corrects the singular form for the response of show. And modify related
unittest and api samples.

Partially implements bp v3-api-inconsistencies
DocImpact

Change-Id: Ie2ac7bb07635aba49e9af7e311e38dbc38610aa3
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/58218/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/tests/integrated/v3/api_samples/flavor-extra-specs/flavor-extra-specs-update-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/flavor-extra-specs/flavor-extra-specs-update-req.json.tpl', 'doc/v3/api_samples/flavor-extra-specs/flavor-extra-specs-get-resp.json', 'doc/v3/api_samples/flavor-extra-specs/flavor-extra-specs-update-req.json', 'doc/v3/api_samples/flavor-extra-specs/flavor-extra-specs-update-req.xml', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors_extra_specs.py', 'nova/tests/integrated/v3/api_samples/flavor-extra-specs/flavor-extra-specs-update-req.xml.tpl', 'nova/tests/integrated/v3/api_samples/flavor-extra-specs/flavor-extra-specs-get-resp.json.tpl', 'doc/v3/api_samples/flavor-extra-specs/flavor-extra-specs-update-resp.json']",10,6018d8d3b9b8351a9d95bd1adfc88ede5ab6b136,bp/v3-api-inconsistencies," ""extra_specs"": { ""key1"": ""new_value1"" } } "," ""key1"": ""new_value1"" }",61,31
openstack%2Fnova~master~I6a05e7a90ae5cacff31851bcbd0e0df7a57fee1e,openstack/nova,master,I6a05e7a90ae5cacff31851bcbd0e0df7a57fee1e,Use 'project' instead of 'tenant' for v3 server's query parameters,ABANDONED,2013-11-25 14:17:41.000000000,2014-07-18 04:07:55.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 7040}, {'_account_id': 7494}, {'_account_id': 7882}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}]","[{'number': 1, 'created': '2013-11-25 14:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd02eed9cbf6c8f6500c09916d3ebc3b62a1ee96', 'message': ""Use 'project' instead of 'tenant' for v3 server's query parameters\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id', and use 'all_tenants'\ninstead of 'all_projects' for v3 server's query parameters.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I6a05e7a90ae5cacff31851bcbd0e0df7a57fee1e\n""}, {'number': 2, 'created': '2013-11-26 02:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5747dd0cb0c7f6b90d56076c98589f75b04ff5dd', 'message': ""Use 'project' instead of 'tenant' for v3 server's query parameters\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id', and use 'all_projects'\ninstead of 'all_tenants' for v3 server's query parameters.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I6a05e7a90ae5cacff31851bcbd0e0df7a57fee1e\n""}, {'number': 3, 'created': '2013-11-26 02:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3feea4bb4333527373c6f992a45a738dd2ad131a', 'message': ""Use 'project' instead of 'tenant' for v3 server's query parameters\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id', and use 'all_projects'\ninstead of 'all_tenants' for v3 server's query parameters.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I6a05e7a90ae5cacff31851bcbd0e0df7a57fee1e\n""}, {'number': 4, 'created': '2014-02-17 06:31:34.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8ba75092438d5d67cfe258ce448f922563e2599f', 'message': ""Use 'project' instead of 'tenant' for v3 server's query parameters\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id', and use 'all_projects'\ninstead of 'all_tenants' for v3 server's query parameters.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I6a05e7a90ae5cacff31851bcbd0e0df7a57fee1e\n""}]",2,58292,8ba75092438d5d67cfe258ce448f922563e2599f,72,13,4,5754,,,0,"Use 'project' instead of 'tenant' for v3 server's query parameters

For v3 api consistent, we prefer use 'project' instead of 'tenant'.
Discussion at:
http://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html

This patch use 'project_id' instead of 'tenant_id', and use 'all_projects'
instead of 'all_tenants' for v3 server's query parameters.

Partially implements bp v3-api-inconsistencies
DocImpact

Change-Id: I6a05e7a90ae5cacff31851bcbd0e0df7a57fee1e
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/58292/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py']",2,fd02eed9cbf6c8f6500c09916d3ebc3b62a1ee96,bp/v3-api-inconsistencies," '?all_projects=1&project_id=newfake', req = fakes.HTTPRequestV3.blank('/servers?project_id=newfake') req = fakes.HTTPRequestV3.blank('/servers?project_id=newfake', req = fakes.HTTPRequestV3.blank('/servers?all_projects', req = fakes.HTTPRequestV3.blank('/servers?all_projects=1', req = fakes.HTTPRequestV3.blank('/servers?all_projects=0', req = fakes.HTTPRequestV3.blank('/servers?all_projects=false', req = fakes.HTTPRequestV3.blank('/servers?all_projects=xxx', req = fakes.HTTPRequestV3.blank('/servers?all_projects=1') req = fakes.HTTPRequestV3.blank('/servers?all_projects=1')"," '?all_tenants=1&tenant_id=newfake', req = fakes.HTTPRequestV3.blank('/servers?tenant_id=newfake') req = fakes.HTTPRequestV3.blank('/servers?tenant_id=newfake', req = fakes.HTTPRequestV3.blank('/servers?all_tenants', req = fakes.HTTPRequestV3.blank('/servers?all_tenants=1', req = fakes.HTTPRequestV3.blank('/servers?all_tenants=0', req = fakes.HTTPRequestV3.blank('/servers?all_tenants=false', req = fakes.HTTPRequestV3.blank('/servers?all_tenants=xxx', req = fakes.HTTPRequestV3.blank('/servers?all_tenants=1') req = fakes.HTTPRequestV3.blank('/servers?all_tenants=1')",24,25
openstack%2Fnova~master~I07511f4bec4691fe41532663ba81485d23a9f49a,openstack/nova,master,I07511f4bec4691fe41532663ba81485d23a9f49a,Use 'project' instead of 'tenant' for flavor-access v3,ABANDONED,2013-11-26 07:04:15.000000000,2014-07-18 04:07:46.000000000,,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}]","[{'number': 1, 'created': '2013-11-26 07:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b126d6af430f4ec3464328f6e52fd27e73876dd8', 'message': ""Use 'project' instead of 'tenant' for flavor-access v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch rename the action name 'add/remove-tenant-access' to\n'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for\nthe response of flavor-access.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I07511f4bec4691fe41532663ba81485d23a9f49a\n""}, {'number': 2, 'created': '2013-11-27 02:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0990c7882cedbc3df9bc64a034a589fb84f53f23', 'message': ""Use 'project' instead of 'tenant' for flavor-access v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch rename the action name 'add/remove-tenant-access' to\n'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for\nthe response of flavor-access.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I07511f4bec4691fe41532663ba81485d23a9f49a\n""}, {'number': 3, 'created': '2013-11-27 06:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/885980d300ca1145b91339fbc68600314c08378d', 'message': ""Use 'project' instead of 'tenant' for flavor-access v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch rename the action name 'add/remove-tenant-access' to\n'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for\nthe response of flavor-access.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I07511f4bec4691fe41532663ba81485d23a9f49a\n""}, {'number': 4, 'created': '2013-12-02 07:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8643247a8d9b1d3d740b6dd7639643f7f87fcf3d', 'message': ""Use 'project' instead of 'tenant' for flavor-access v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch rename the action name 'add/remove-tenant-access' to\n'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for\nthe response of flavor-access.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I07511f4bec4691fe41532663ba81485d23a9f49a\n""}, {'number': 5, 'created': '2013-12-30 07:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/afd8e87151b4363ce2b2805d5967891a8d2389cd', 'message': ""Use 'project' instead of 'tenant' for flavor-access v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch rename the action name 'add/remove-tenant-access' to\n'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for\nthe response of flavor-access.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I07511f4bec4691fe41532663ba81485d23a9f49a\n""}, {'number': 6, 'created': '2013-12-30 07:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b698581ddd7827f9d86559daf6fba9ddc3d6da90', 'message': ""Use 'project' instead of 'tenant' for flavor-access v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch rename the action name 'add/remove-tenant-access' to\n'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for\nthe response of flavor-access.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I07511f4bec4691fe41532663ba81485d23a9f49a\n""}, {'number': 7, 'created': '2014-01-02 02:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cce5913b49bdecc93f2510ae90c89d76391be77d', 'message': ""Use 'project' instead of 'tenant' for flavor-access v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch rename the action name 'add/remove-tenant-access' to\n'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for\nthe response of flavor-access.\n\nPartial-Bug: #1265416\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I07511f4bec4691fe41532663ba81485d23a9f49a\n""}, {'number': 8, 'created': '2014-01-18 09:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea0ff810a779c884924e220c48a4c92ad306d33d', 'message': ""Use 'project' instead of 'tenant' for flavor-access v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch rename the action name 'add/remove-tenant-access' to\n'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for\nthe response of flavor-access.\n\nPartial-Bug: #1265416\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I07511f4bec4691fe41532663ba81485d23a9f49a\n""}, {'number': 9, 'created': '2014-02-17 06:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25c5debc320f803071795a9e0d9f385687dc3935', 'message': ""Use 'project' instead of 'tenant' for flavor-access v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch rename the action name 'add/remove-tenant-access' to\n'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for\nthe response of flavor-access.\n\nPartial-Bug: #1265416\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I07511f4bec4691fe41532663ba81485d23a9f49a\n""}, {'number': 10, 'created': '2014-02-17 07:55:11.000000000', 'files': ['doc/v3/api_samples/flavor-access/flavor-access-list-resp.json', 'nova/api/openstack/compute/schemas/v3/flavor_access.py', 'nova/tests/integrated/v3/api_samples/flavor-access/flavor-access-list-resp.json.tpl', 'nova/api/openstack/compute/plugins/v3/flavor_access.py', 'etc/nova/policy.json', 'nova/tests/integrated/v3/api_samples/flavor-access/flavor-access-remove-tenant-req.json.tpl', 'nova/tests/api/openstack/compute/plugins/v3/test_flavor_access.py', 'nova/tests/integrated/v3/api_samples/flavor-access/flavor-access-add-tenant-req.json.tpl', 'nova/tests/integrated/v3/test_flavor_access.py', 'nova/tests/integrated/v3/api_samples/flavor-access/flavor-access-add-project-req.json.tpl', 'nova/tests/api/openstack/compute/plugins/v3/test_flavor_manage.py', 'doc/v3/api_samples/flavor-access/flavor-access-remove-project-resp.json', 'doc/v3/api_samples/flavor-access/flavor-access-remove-tenant-req.json', 'doc/v3/api_samples/flavor-access/flavor-access-add-project-resp.json', 'nova/tests/integrated/v3/api_samples/flavor-access/flavor-access-remove-project-resp.json.tpl', 'doc/v3/api_samples/flavor-access/flavor-access-remove-project-req.json', 'nova/tests/fake_policy.py', 'doc/v3/api_samples/flavor-access/flavor-access-add-project-req.json', 'doc/v3/api_samples/flavor-access/flavor-access-add-tenant-req.json', 'nova/tests/integrated/v3/api_samples/flavor-access/flavor-access-add-project-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/flavor-access/flavor-access-remove-project-req.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/7395b0cebbde1f55b6a73bb51d738ccf21ef21a3', 'message': ""Use 'project' instead of 'tenant' for flavor-access v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch rename the action name 'add/remove-tenant-access' to\n'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for\nthe response of flavor-access.\n\nPartial-Bug: #1265416\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: I07511f4bec4691fe41532663ba81485d23a9f49a\n""}]",6,58450,7395b0cebbde1f55b6a73bb51d738ccf21ef21a3,65,9,10,5754,,,0,"Use 'project' instead of 'tenant' for flavor-access v3

For v3 api consistent, we prefer use 'project' instead of 'tenant'.
Discussion at:
http://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html

This patch rename the action name 'add/remove-tenant-access' to
'add/remove-project-access'. And use 'tenant_id' instead of 'project_id'for
the response of flavor-access.

Partial-Bug: #1265416
Partially implements bp v3-api-inconsistencies
DocImpact

Change-Id: I07511f4bec4691fe41532663ba81485d23a9f49a
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/58450/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-remove-tenant-req.xml.tpl', 'doc/v3/api_samples/os-flavor-access/flavor-access-add-tenant-resp.xml', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-remove-tenant-req.json.tpl', 'doc/v3/api_samples/os-flavor-access/flavor-access-add-tenant-req.xml', 'etc/nova/policy.json', 'doc/v3/api_samples/os-flavor-access/flavor-access-add-project-req.xml', 'doc/v3/api_samples/os-flavor-access/flavor-access-add-project-resp.xml', 'nova/tests/api/openstack/compute/plugins/v3/test_flavor_manage.py', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-list-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-add-project-req.json.tpl', 'doc/v3/api_samples/os-flavor-access/flavor-access-remove-tenant-resp.xml', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-add-tenant-resp.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-add-project-req.xml.tpl', 'nova/api/openstack/compute/plugins/v3/flavor_access.py', 'doc/v3/api_samples/os-flavor-access/flavor-access-remove-tenant-resp.json', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-add-tenant-req.json.tpl', 'doc/v3/api_samples/os-flavor-access/flavor-access-list-resp.xml', 'nova/tests/api/openstack/compute/plugins/v3/test_flavor_access.py', 'nova/tests/integrated/v3/test_flavor_access.py', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-remove-tenant-resp.xml.tpl', 'doc/v3/api_samples/os-flavor-access/flavor-access-remove-tenant-req.json', 'doc/v3/api_samples/os-flavor-access/flavor-access-add-project-resp.json', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-add-project-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-add-project-resp.xml.tpl', 'doc/v3/api_samples/os-flavor-access/flavor-access-add-tenant-req.json', 'doc/v3/api_samples/os-flavor-access/flavor-access-list-resp.json', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-add-tenant-req.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-list-resp.xml.tpl', 'nova/tests/fake_policy.py', 'nova/tests/integrated/v3/api_samples/os-flavor-access/flavor-access-remove-tenant-resp.json.tpl', 'doc/v3/api_samples/os-flavor-access/flavor-access-add-project-req.json', 'doc/v3/api_samples/os-flavor-access/flavor-access-remove-tenant-req.xml']",32,b126d6af430f4ec3464328f6e52fd27e73876dd8,bp/v3-api-inconsistencies,<remove_project_access> <project_id>fake_project</project_id> </remove_project_access>,<remove_tenant_access> <tenant_id>fake_tenant</tenant_id> </remove_tenant_access>,135,135
openstack%2Fnova~master~Icade951b0d17f0be80af4897870079cb7a5afcd9,openstack/nova,master,Icade951b0d17f0be80af4897870079cb7a5afcd9,Use 'project_id' instead of 'tenant_id' for the response of servers v3,ABANDONED,2013-11-26 07:49:29.000000000,2014-07-18 04:07:34.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}]","[{'number': 1, 'created': '2013-11-26 07:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/918df33a556b4903301b6f98b5cce058362b55b0', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}, {'number': 2, 'created': '2013-11-27 02:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b50f32ac060937971b1abf75e01b86d5b5947aa7', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}, {'number': 3, 'created': '2013-12-15 11:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bcd884c44d52905f07efa45a263ee2d52ce32042', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}, {'number': 4, 'created': '2013-12-17 02:33:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a7ec45edba986f0b06afa27306170368ce54f6b', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}, {'number': 6, 'created': '2013-12-17 05:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d8c103c2fb9b58b8304cf560038f833e57882834', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}, {'number': 5, 'created': '2013-12-17 05:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91643a7913fd723f20a7e2c9a673f3f065410ebc', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}, {'number': 7, 'created': '2014-01-20 07:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45c94f6bf096f39b569aaf7f14da0074999b7348', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}, {'number': 8, 'created': '2014-01-21 08:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7edcac9ac5c2a582550ac7311011cd97d7427d30', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}, {'number': 9, 'created': '2014-01-22 08:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0837260bee917af56689755adb023aca84b42017', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}, {'number': 10, 'created': '2014-02-17 06:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1371943b92b04138db802522f1ae5fbbbf16d17c', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}, {'number': 11, 'created': '2014-02-17 08:23:16.000000000', 'files': ['nova/tests/integrated/v3/api_samples/os-hide-server-addresses/servers-details-resp.json.tpl', 'doc/v3/api_samples/os-config-drive/server-config-drive-get-resp.json', 'doc/v3/api_samples/os-extended-status/servers-detail-resp.json', 'nova/api/openstack/compute/views/servers.py', 'nova/tests/integrated/v3/api_samples/os-access-ips/servers-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-status/server-get-resp.json.tpl', 'doc/v3/api_samples/all_extensions/servers-details-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-usage/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'doc/v3/api_samples/os-access-ips/server-action-rebuild-resp.json', 'doc/v3/api_samples/os-extended-availability-zone/server-get-resp.json', 'doc/v3/api_samples/os-rescue/server-get-resp-rescue.json', 'doc/v3/api_samples/os-server-usage/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/all_extensions/server-get-resp.json.tpl', 'doc/v3/api_samples/servers/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/servers/servers-details-resp.json.tpl', 'doc/v3/api_samples/os-extended-availability-zone/servers-detail-resp.json', 'doc/v3/api_samples/os-server-usage/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-volumes/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-volumes/server-get-resp.json.tpl', 'doc/v3/api_samples/os-access-ips/servers-details-resp.json', 'nova/tests/integrated/v3/api_samples/os-pci/server-get-resp.json.tpl', 'doc/v3/api_samples/os-extended-volumes/servers-detail-resp.json', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'doc/v3/api_samples/servers/servers-details-resp.json', 'doc/v3/api_samples/os-access-ips/server-put-resp.json', 'nova/tests/integrated/v3/api_samples/os-security-groups/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-usage/servers-detail-resp.json.tpl', 'doc/v3/api_samples/all_extensions/server-get-resp.json', 'doc/v3/api_samples/os-config-drive/servers-config-drive-details-resp.json', 'doc/v3/api_samples/os-security-groups/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-availability-zone/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-pci/servers-detail-resp.json.tpl', 'doc/v3/api_samples/os-security-groups/server-get-resp.json', 'doc/v3/api_samples/os-pci/servers-detail-resp.json', 'doc/v3/api_samples/os-hide-server-addresses/servers-details-resp.json', 'doc/v3/api_samples/os-extended-server-attributes/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-server-attributes/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-config-drive/server-config-drive-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-security-groups/server-get-resp.json.tpl', 'doc/v3/api_samples/os-extended-status/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-availability-zone/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/servers/server-get-resp.json.tpl', 'nova/api/openstack/compute/schemas/v3/server.rng', 'nova/tests/integrated/v3/api_samples/os-extended-status/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/all_extensions/servers-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-config-drive/servers-config-drive-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-put-resp.json.tpl', 'doc/v3/api_samples/servers/server-action-rebuild-resp.json', 'nova/tests/integrated/v3/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'doc/v3/api_samples/os-access-ips/server-get-resp.json', 'doc/v3/api_samples/os-extended-volumes/server-get-resp.json', 'doc/v3/api_samples/os-hide-server-addresses/server-get-resp.json', 'doc/v3/api_samples/os-pci/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-hide-server-addresses/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-get-resp.json.tpl', 'doc/v3/api_samples/os-rescue/server-get-resp-unrescue.json', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-action-rebuild-resp.json.tpl', 'doc/v3/api_samples/os-extended-server-attributes/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-server-attributes/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/servers/server-action-rebuild-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/38a81d07e4dc1f66db4ccc82532ff0385138d9a7', 'message': ""Use 'project_id' instead of 'tenant_id' for the response of servers v3\n\nFor v3 api consistent, we prefer use 'project' instead of 'tenant'.\nDiscussion at:\nhttp://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html\n\nThis patch use 'project_id' instead of 'tenant_id' for the response of\nserver's get, detail and rebuild.\n\nPartially implements bp v3-api-inconsistencies\nDocImpact\n\nChange-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9\n""}]",0,58458,38a81d07e4dc1f66db4ccc82532ff0385138d9a7,84,11,11,5754,,,0,"Use 'project_id' instead of 'tenant_id' for the response of servers v3

For v3 api consistent, we prefer use 'project' instead of 'tenant'.
Discussion at:
http://lists.openstack.org/pipermail/openstack-dev/2013-November/020222.html

This patch use 'project_id' instead of 'tenant_id' for the response of
server's get, detail and rebuild.

Partially implements bp v3-api-inconsistencies
DocImpact

Change-Id: Icade951b0d17f0be80af4897870079cb7a5afcd9
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/58458/10 && git format-patch -1 --stdout FETCH_HEAD,"['doc/v3/api_samples/os-server-usage/server-get-resp.xml', 'nova/tests/integrated/v3/api_samples/os-extended-status/server-get-resp.xml.tpl', 'doc/v3/api_samples/os-extended-status/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-disk-config/list-servers-detail-get.json.tpl', 'nova/tests/integrated/v3/api_samples/os-hide-server-addresses/server-get-resp.xml.tpl', 'doc/v3/api_samples/os-rescue/server-get-resp-unrescue.xml', 'doc/v3/api_samples/os-disk-config/server-update-put-resp.json', 'doc/v3/api_samples/all_extensions/servers-details-resp.json', 'doc/v3/api_samples/os-disk-config/list-servers-detail-get.json', 'doc/v3/api_samples/os-extended-server-attributes/servers-detail-resp.xml', 'nova/tests/integrated/v3/api_samples/servers/server-get-resp.xml.tpl', 'doc/v3/api_samples/all_extensions/server-get-resp.xml', 'nova/tests/integrated/v3/api_samples/os-server-usage/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-disk-config/list-servers-detail-get.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-server-attributes/servers-detail-resp.xml.tpl', 'doc/v3/api_samples/os-security-groups/servers-detail-resp.xml', 'nova/tests/integrated/v3/api_samples/os-extended-availability-zone/servers-detail-resp.xml.tpl', 'doc/v3/api_samples/os-access-ips/server-action-rebuild-resp.json', 'doc/v3/api_samples/os-extended-availability-zone/server-get-resp.json', 'doc/v3/api_samples/os-rescue/server-get-resp-rescue.json', 'doc/v3/api_samples/os-server-usage/servers-detail-resp.json', 'doc/v3/api_samples/servers/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/servers/servers-details-resp.json.tpl', 'doc/v3/api_samples/os-access-ips/servers-details-resp.xml', 'doc/v3/api_samples/os-server-usage/server-get-resp.json', 'doc/v3/api_samples/os-hide-server-addresses/server-get-resp.xml', 'nova/tests/integrated/v3/api_samples/os-extended-volumes/server-get-resp.json.tpl', 'doc/v3/api_samples/os-extended-status/server-get-resp.xml', 'doc/v3/api_samples/os-extended-volumes/servers-detail-resp.json', 'doc/v3/api_samples/os-access-ips/server-action-rebuild-resp.xml', 'doc/v3/api_samples/servers/servers-details-resp.json', 'doc/v3/api_samples/os-server-usage/servers-detail-resp.xml', 'nova/tests/integrated/v3/api_samples/all_extensions/servers-details-resp.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-server-usage/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-rescue/server-get-resp-unrescue.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-rescue/server-get-resp-rescue.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-status/servers-detail-resp.xml.tpl', 'doc/v3/api_samples/os-extended-server-attributes/server-get-resp.xml', 'doc/v3/api_samples/os-extended-server-attributes/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-disk-config/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-server-attributes/server-get-resp.json.tpl', 'doc/v3/api_samples/os-disk-config/list-servers-detail-get.xml', 'doc/v3/api_samples/os-extended-availability-zone/servers-detail-resp.xml', 'nova/tests/integrated/v3/api_samples/os-extended-volumes/servers-detail-resp.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-security-groups/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-usage/servers-detail-resp.xml.tpl', 'doc/v3/api_samples/os-rescue/server-get-resp-rescue.xml', 'nova/tests/integrated/v3/api_samples/os-extended-availability-zone/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-usage/server-get-resp.xml.tpl', 'doc/v3/api_samples/servers/servers-details-resp.xml', 'nova/api/openstack/compute/schemas/v3/server.rng', 'nova/tests/integrated/v3/api_samples/os-extended-status/servers-detail-resp.json.tpl', 'doc/v3/api_samples/servers/server-get-resp.xml', 'nova/tests/integrated/v3/api_samples/all_extensions/servers-details-resp.json.tpl', 'doc/v3/api_samples/os-hide-server-addresses/servers-details-resp.xml', 'doc/v3/api_samples/servers/server-action-rebuild-resp.json', 'nova/tests/integrated/v3/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'doc/v3/api_samples/os-extended-volumes/server-get-resp.json', 'doc/v3/api_samples/os-hide-server-addresses/server-get-resp.json', 'doc/v3/api_samples/os-extended-availability-zone/server-get-resp.xml', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-get-resp.json.tpl', 'doc/v3/api_samples/os-rescue/server-get-resp-unrescue.json', 'doc/v3/api_samples/os-extended-server-attributes/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-server-attributes/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/servers/servers-details-resp.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-hide-server-addresses/servers-details-resp.json.tpl', 'nova/api/openstack/compute/views/servers.py', 'doc/v3/api_samples/os-disk-config/server-update-put-resp.xml', 'nova/tests/integrated/v3/api_samples/os-access-ips/servers-details-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-status/server-get-resp.json.tpl', 'doc/v3/api_samples/os-access-ips/server-get-resp.xml', 'doc/v3/api_samples/servers/server-action-rebuild-resp.xml', 'doc/v3/api_samples/os-disk-config/server-get-resp.json', 'doc/v3/api_samples/os-security-groups/server-get-resp.xml', 'nova/tests/integrated/v3/api_samples/all_extensions/server-get-resp.xml.tpl', 'nova/tests/integrated/v3/api_samples/all_extensions/server-get-resp.json.tpl', 'doc/v3/api_samples/all_extensions/servers-details-resp.xml', 'doc/v3/api_samples/os-extended-availability-zone/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-disk-config/server-get-resp.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-volumes/servers-detail-resp.json.tpl', 'doc/v3/api_samples/os-access-ips/servers-details-resp.json', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'nova/tests/integrated/v3/api_samples/os-security-groups/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-access-ips/servers-details-resp.xml.tpl', 'doc/v3/api_samples/all_extensions/server-get-resp.json', 'doc/v3/api_samples/os-security-groups/servers-detail-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-availability-zone/servers-detail-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-hide-server-addresses/servers-details-resp.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-security-groups/servers-detail-resp.xml.tpl', 'doc/v3/api_samples/os-disk-config/server-action-rebuild-resp.xml', 'doc/v3/api_samples/os-disk-config/server-get-resp.xml', 'doc/v3/api_samples/os-security-groups/server-get-resp.json', 'doc/v3/api_samples/os-hide-server-addresses/servers-details-resp.json', 'nova/tests/integrated/v3/api_samples/os-extended-server-attributes/server-get-resp.xml.tpl', 'doc/v3/api_samples/os-extended-volumes/server-get-resp.xml', 'doc/v3/api_samples/os-extended-status/server-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-access-ips/server-get-resp.xml.tpl', 'nova/tests/integrated/v3/api_samples/servers/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/servers/server-action-rebuild-resp.xml.tpl', 'doc/v3/api_samples/os-disk-config/server-action-rebuild-resp.json', 'nova/tests/integrated/v3/api_samples/os-security-groups/server-get-resp.xml.tpl', 'doc/v3/api_samples/os-extended-volumes/servers-detail-resp.xml', 'doc/v3/api_samples/os-extended-status/servers-detail-resp.xml', 'doc/v3/api_samples/os-access-ips/server-get-resp.json', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/integrated/v3/api_samples/os-extended-availability-zone/server-get-resp.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-extended-volumes/server-get-resp.xml.tpl', 'nova/tests/integrated/v3/api_samples/os-hide-server-addresses/server-get-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/servers/server-action-rebuild-resp.json.tpl']",110,918df33a556b4903301b6f98b5cce058362b55b0,bp/v3-api-inconsistencies," ""project_id"": ""openstack"","," ""tenant_id"": ""openstack"",",121,121
openstack%2Fnova~master~I90b0c7386260228c0932640e271e6632b6805f97,openstack/nova,master,I90b0c7386260228c0932640e271e6632b6805f97,Split resize as extension from v3 servers core,ABANDONED,2013-12-01 10:26:42.000000000,2014-07-18 04:07:24.000000000,,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 7494}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}]","[{'number': 1, 'created': '2013-12-01 10:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf8867d0a29b70a1e93f5363b0eaee1e5a53f176', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 2, 'created': '2013-12-01 11:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3930fce8c159de597e1952b45693ab1bbbeee9d7', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 3, 'created': '2013-12-01 11:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac2f32c5a8dad6f2ebf5d4b946fcb9d93ca6fa00', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 4, 'created': '2013-12-30 06:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/318388f28a02a725e0becdfb3e7bc8f883a91403', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 5, 'created': '2014-01-17 10:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/efab0f0fc891bcdf0a4698b8b28173c48de8e144', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 6, 'created': '2014-01-18 09:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5491682226b5e2da5c5bcf2fe90a5b343576c6e3', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 7, 'created': '2014-01-21 02:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5bc4f3316bdab7bcbcb855ff155b987c23fdf313', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 8, 'created': '2014-01-21 09:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a86dd30661147510d2fa61b3d006fed99b4f33f', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 9, 'created': '2014-02-11 02:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f603121b379c999674eff971ededd363b8fe1e26', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 10, 'created': '2014-02-13 08:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89619ce611b729969e04754bac44c8bc050c67f6', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 11, 'created': '2014-02-13 09:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3385750beb937d465e6ed30502e40a41854559d', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 12, 'created': '2014-02-13 11:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/945a2b647fd282f3f53e15b211d4824e905f6e44', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}, {'number': 13, 'created': '2014-02-14 03:17:21.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/resize_server.py', 'nova/tests/integrated/v3/test_resize_server.py', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-action-confirm-resize.json.tpl', 'etc/nova/policy.json', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-action-revert-resize.json.tpl', 'doc/v3/api_samples/os-resize-server/server-post-req.json', 'nova/tests/integrated/v3/test_servers.py', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-post-req.json.tpl', 'doc/v3/api_samples/os-resize-server/server-action-resize.json', 'doc/v3/api_samples/os-resize-server/server-action-revert-resize.json', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'doc/v3/api_samples/os-resize-server/server-post-resp.json', 'nova/tests/fake_policy.py', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-post-resp.json.tpl', 'setup.cfg', 'doc/v3/api_samples/os-resize-server/server-action-confirm-resize.json', 'nova/tests/api/openstack/compute/plugins/v3/test_resize_server.py', 'nova/tests/api/openstack/compute/plugins/v3/test_server_actions.py', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-action-resize.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/88ed71cb1b01f7cb063535aaf9b81be3b3d7874c', 'message': 'Split resize as extension from v3 servers core\n\nMove the resize/confirm_resize/revert_resize actions out of servers\ncore api into its own extension. This allows more more selective enablement\nof features. Also split related tests from servers core tests.\n\nThe extension checking function move into common place that is convenient for\ncomsume by resize-server extension.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I90b0c7386260228c0932640e271e6632b6805f97\n'}]",5,59284,88ed71cb1b01f7cb063535aaf9b81be3b3d7874c,99,10,13,5754,,,0,"Split resize as extension from v3 servers core

Move the resize/confirm_resize/revert_resize actions out of servers
core api into its own extension. This allows more more selective enablement
of features. Also split related tests from servers core tests.

The extension checking function move into common place that is convenient for
comsume by resize-server extension.

Partially implements bp v3-api-core
DocImpact

Change-Id: I90b0c7386260228c0932640e271e6632b6805f97
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/59284/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/nova/policy.json', 'nova/tests/integrated/v3/test_servers.py', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-action-revert-resize.xml.tpl', 'doc/v3/api_samples/os-resize-server/server-post-req.xml', 'doc/v3/api_samples/os-resize-server/server-post-resp.json', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-post-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-post-resp.xml.tpl', 'nova/tests/api/openstack/compute/plugins/v3/test_resize_server.py', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-action-resize.json.tpl', 'nova/api/openstack/compute/plugins/v3/resize_server.py', 'nova/tests/integrated/v3/test_resize_server.py', 'doc/v3/api_samples/os-resize-server/server-action-revert-resize.xml', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-action-confirm-resize.json.tpl', 'doc/v3/api_samples/os-resize-server/server-action-confirm-resize.xml', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-action-revert-resize.json.tpl', 'doc/v3/api_samples/os-resize-server/server-post-req.json', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-post-req.json.tpl', 'doc/v3/api_samples/os-resize-server/server-action-resize.json', 'doc/v3/api_samples/os-resize-server/server-action-revert-resize.json', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'doc/v3/api_samples/os-resize-server/server-action-resize.xml', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-post-req.xml.tpl', 'nova/tests/api/openstack/compute/plugins/v3/test_disk_config.py', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-action-resize.xml.tpl', 'doc/v3/api_samples/os-resize-server/server-post-resp.xml', 'setup.cfg', 'doc/v3/api_samples/os-resize-server/server-action-confirm-resize.json', 'nova/tests/integrated/v3/api_samples/os-resize-server/server-action-confirm-resize.xml.tpl', 'nova/tests/api/openstack/compute/plugins/v3/test_server_actions.py', 'nova/api/openstack/extensions.py']",31,cf8867d0a29b70a1e93f5363b0eaee1e5a53f176,bp/v3-api-policy,"from oslo.config import cfgCONF = cfg.CONF def check_load_extension_point(required_function): def check_whiteblack_lists(ext): # Check whitelist is either empty or if not then the extension # is in the whitelist if (not CONF.osapi_v3.extensions_whitelist or ext.obj.alias in CONF.osapi_v3.extensions_whitelist): # Check the extension is not in the blacklist if ext.obj.alias not in CONF.osapi_v3.extensions_blacklist: return True else: LOG.warning(_(""Not loading %s because it is "" ""in the blacklist""), ext.obj.alias) return False else: LOG.warning( _(""Not loading %s because it is not in the whitelist""), ext.obj.alias) return False def check_load_extension(ext): if isinstance(ext.obj, V3APIExtensionBase): # Filter out for the existence of the required # function here rather than on every request. We # don't have a new abstract base class to reduce # duplication in the extensions as they may want # to implement multiple server (and other) entry # points if hasattr(ext.obj, 'server_create'): if hasattr(ext.obj, required_function): LOG.debug(_('extension %(ext_alias)s detected by ' 'servers extension for function %(func)s'), {'ext_alias': ext.obj.alias, 'func': required_function}) return check_whiteblack_lists(ext) else: LOG.debug( _('extension %(ext_alias)s is missing %(func)s'), {'ext_alias': ext.obj.alias, 'func': required_function}) return False else: return False return check_load_extension",,805,521
openstack%2Fnova~master~I6103707f0347e094603c645d1e44100b5b48c0e6,openstack/nova,master,I6103707f0347e094603c645d1e44100b5b48c0e6,Add decorator expected_errors for resize_server v3,ABANDONED,2013-12-01 10:26:43.000000000,2014-07-18 04:07:14.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4656}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}]","[{'number': 1, 'created': '2013-12-01 10:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f33953d0e36fc0352881329bffc69406f85842ba', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch add expected_errors for resize_server's actions\nthat required by v3 api. Also correct some exception catching.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}, {'number': 2, 'created': '2013-12-01 11:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56d9eb67402fed41a8610654a5f0270d7bb26c1f', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch add expected_errors for resize_server's actions\nthat required by v3 api. Also correct some exception catching.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}, {'number': 3, 'created': '2013-12-02 05:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc774f269cfcae9009062b9d39546c058c9e721a', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch adds expected_errors to resize_server's actions, which\nis required by the v3 API. Also corrects some exceptions thrown.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}, {'number': 4, 'created': '2013-12-30 06:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/520202978ef8ba539c109d80f9c050ff77196ffd', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch adds expected_errors to resize_server's actions, which\nis required by the v3 API. Also corrects some exceptions thrown.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}, {'number': 5, 'created': '2014-01-17 10:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a7e105f7a82c1397127e8366acb7490bb6b24df', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch adds expected_errors to resize_server's actions, which\nis required by the v3 API. Also corrects some exceptions thrown.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}, {'number': 6, 'created': '2014-01-18 09:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ecadfa1aa1175f6c74f0edca90e7f64549b0e787', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch adds expected_errors to resize_server's actions, which\nis required by the v3 API. Also corrects some exceptions thrown.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}, {'number': 7, 'created': '2014-02-11 02:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ccfd3ea7ec0f20ae7df38cdfba06411fa6aedee', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch adds expected_errors to resize_server's actions, which\nis required by the v3 API. Also corrects some exceptions thrown.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}, {'number': 8, 'created': '2014-02-13 08:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e087da3f68cab07010bf442c5f6c6b2cb34001a', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch adds expected_errors to resize_server's actions, which\nis required by the v3 API. Also corrects some exceptions thrown.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}, {'number': 9, 'created': '2014-02-13 09:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d5c45ae3c6aa8924aa1a3930214ac8ec2a607cd', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch adds expected_errors to resize_server's actions, which\nis required by the v3 API. Also corrects some exceptions thrown.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}, {'number': 10, 'created': '2014-02-13 11:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55b4c2e1c6ed3238e9ef2e6ccf1645d004738f9b', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch adds expected_errors to resize_server's actions, which\nis required by the v3 API. Also corrects some exceptions thrown.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}, {'number': 11, 'created': '2014-02-14 03:17:25.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/resize_server.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dbc7a537c993bac575958e3f6072339ebfa48ca5', 'message': ""Add decorator expected_errors for resize_server v3\n\nThis patch adds expected_errors to resize_server's actions, which\nis required by the v3 API. Also corrects some exceptions thrown.\n\nPartially implements bp v3-api-core\nDocImpact\n\nChange-Id: I6103707f0347e094603c645d1e44100b5b48c0e6\n""}]",4,59285,dbc7a537c993bac575958e3f6072339ebfa48ca5,95,10,11,5754,,,0,"Add decorator expected_errors for resize_server v3

This patch adds expected_errors to resize_server's actions, which
is required by the v3 API. Also corrects some exceptions thrown.

Partially implements bp v3-api-core
DocImpact

Change-Id: I6103707f0347e094603c645d1e44100b5b48c0e6
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/59285/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/resize_server.py', 'nova/tests/api/openstack/compute/plugins/v3/test_resize_server.py']",2,f33953d0e36fc0352881329bffc69406f85842ba,bp/v3-api-policy," raise exception.InstanceNotFound(instance_id='') self.assertRaises(webob.exc.HTTPRequestEntityTooLarge,"," raise exception.NotFound() self.assertRaises(exception.TooManyInstances,",8,3
openstack%2Fnova~master~I2936c41da32ee4afe05494936fdcb3593829fb5c,openstack/nova,master,I2936c41da32ee4afe05494936fdcb3593829fb5c,Add missed discoverable policy rules for flavor-manage v3,ABANDONED,2014-01-26 04:46:08.000000000,2014-07-18 04:06:56.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-01-26 04:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f774165d8c191b343e7f1247103ec363bcb2bfe', 'message': 'Add missed discoverable policy rules for v3 api\n\nAdd discoverable policy rule for v3 extension flavor-manage\nand os-instance-usage-audit-log\n\nChange-Id: I2936c41da32ee4afe05494936fdcb3593829fb5c\n'}, {'number': 2, 'created': '2014-02-10 08:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/82b10401f1dc0921f4b37d14e15816f2a4909658', 'message': 'Add missed discoverable policy rules for flavor-manage v3\n\nAdd discoverable policy rule for v3 extension flavor-manage.\n\nChange-Id: I2936c41da32ee4afe05494936fdcb3593829fb5c\n'}, {'number': 3, 'created': '2014-02-11 16:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df75bfc2035e0aff49368c75c1008bc0fc4d325f', 'message': 'Add missed discoverable policy rules for flavor-manage v3\n\nAdd discoverable policy rule for v3 extension flavor-manage.\n\nChange-Id: I2936c41da32ee4afe05494936fdcb3593829fb5c\n'}, {'number': 4, 'created': '2014-02-12 02:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b42dabc0c60248a1ccb06d165e28c2c3c239cac1', 'message': 'Add missed discoverable policy rules for flavor-manage v3\n\nAdd discoverable policy rule for v3 extension flavor-manage.\n\nChange-Id: I2936c41da32ee4afe05494936fdcb3593829fb5c\n'}, {'number': 5, 'created': '2014-07-01 11:16:26.000000000', 'files': ['etc/nova/policy.json'], 'web_link': 'https://opendev.org/openstack/nova/commit/e8185d7b252e4e0ffbc2d56ea930ac2250d4003f', 'message': 'Add missed discoverable policy rules for flavor-manage v3\n\nAdd discoverable policy rule for v3 extension flavor-manage.\n\nChange-Id: I2936c41da32ee4afe05494936fdcb3593829fb5c\n'}]",0,69168,e8185d7b252e4e0ffbc2d56ea930ac2250d4003f,44,7,5,5754,,,0,"Add missed discoverable policy rules for flavor-manage v3

Add discoverable policy rule for v3 extension flavor-manage.

Change-Id: I2936c41da32ee4afe05494936fdcb3593829fb5c
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/69168/5 && git format-patch -1 --stdout FETCH_HEAD,['etc/nova/policy.json'],1,8f774165d8c191b343e7f1247103ec363bcb2bfe,add_discoverable_flavor_manage," ""compute:v3:flavor-manage:discoverable"": """", ""compute_extension:v3:os-instance-usage-audit-log:discoverable"": """",",,2,0
openstack%2Fsolum~master~I871c0e7de0f7fd06ea36bbbb4fabf765845dab21,openstack/solum,master,I871c0e7de0f7fd06ea36bbbb4fabf765845dab21,WIP - busy on this,ABANDONED,2014-07-01 21:20:03.000000000,2014-07-18 03:56:25.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 9113}]","[{'number': 1, 'created': '2014-07-01 21:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/eb16402b9c15b9381149b57ed0868e0d06f3204b', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 2, 'created': '2014-07-02 06:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/895d7674037cda75b71ba7653f8d6a5cb5b51ac2', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 3, 'created': '2014-07-07 18:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/518cad3b522c2401554e9e22e36a304534a4dd86', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 4, 'created': '2014-07-08 22:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4c2c77973d8950269480ce19ace1495b1bec66a5', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 5, 'created': '2014-07-09 01:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/2b7ccb19892d6f2d7572183647ccfc9b856c021a', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 6, 'created': '2014-07-09 02:17:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/81ec487a88d8d4a4616a068b92ea87667835a68f', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 7, 'created': '2014-07-09 18:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/2d8ddd744e083c279cce5081e62fad87b822c8fc', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 8, 'created': '2014-07-09 20:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/45ff095e986a5ef3883a5c4aea20441e3e0e810d', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 9, 'created': '2014-07-14 10:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/d430ef9c0edca148e76787ab1f6b7d083f47011d', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 10, 'created': '2014-07-15 21:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/bb51d790dac9ee1dcf016a75fd0184dc8ef10d4e', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 11, 'created': '2014-07-16 10:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/78d9d1b4eb7bfebda388fa87a64b2cb2819becd9', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}, {'number': 12, 'created': '2014-07-17 09:42:23.000000000', 'files': ['assorted-scripts/clean_db.sh', 'etc/solum/workbooks/deploy.yaml', 'examples/plans/deploy.yaml', 'solum/api/handlers/pipeline_handler.py', 'contrib/lp-cedarish/docker/build-app', 'assorted-scripts/test.sh', 'etc/solum/templates/test.yaml'], 'web_link': 'https://opendev.org/openstack/solum/commit/0b1ba56e5a752c6510ecfde82e12e770deb4d879', 'message': 'WIP - busy on this\n\nto create a pipeline ./assorted-scripts/test.sh\nto cleanup for another run ./assorted-scripts/clean_db.sh\n\nChange-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21\n'}]",11,104002,0b1ba56e5a752c6510ecfde82e12e770deb4d879,50,5,12,4715,,,0,"WIP - busy on this

to create a pipeline ./assorted-scripts/test.sh
to cleanup for another run ./assorted-scripts/clean_db.sh

Change-Id: I871c0e7de0f7fd06ea36bbbb4fabf765845dab21
",git fetch https://review.opendev.org/openstack/solum refs/changes/02/104002/3 && git format-patch -1 --stdout FETCH_HEAD,"['assorted-scripts/clean_db.sh', 'contrib/lp-cedarish/vm-slug/build-app', 'assorted-scripts/test.sh', 'etc/solum/templates/test.yaml']",4,eb16402b9c15b9381149b57ed0868e0d06f3204b,new-api,parameters: resources: outputs: ,,68,0
openstack%2Fneutron~master~I2efb0c0f527f1fb22c4d4b07f6d280863f565648,openstack/neutron,master,I2efb0c0f527f1fb22c4d4b07f6d280863f565648,no quota for allowed address pair,MERGED,2014-07-17 15:06:15.000000000,2014-07-18 03:53:52.000000000,2014-07-17 20:54:48.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 9311}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-17 15:06:15.000000000', 'files': ['neutron/extensions/allowedaddresspairs.py', 'neutron/tests/unit/test_extension_allowedaddresspairs.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc6b07d4a37ef0db9906187611fec8e8753803cd', 'message': 'no quota for allowed address pair\n\nThere is no quota for allowed address pair. User can create unlimited\nallowed address pairs. I add quota for allowed address pairs.\n\nChange-Id: I2efb0c0f527f1fb22c4d4b07f6d280863f565648\nCloses-Bug: #1336207\n'}]",0,107734,dc6b07d4a37ef0db9906187611fec8e8753803cd,33,19,1,9820,,,0,"no quota for allowed address pair

There is no quota for allowed address pair. User can create unlimited
allowed address pairs. I add quota for allowed address pairs.

Change-Id: I2efb0c0f527f1fb22c4d4b07f6d280863f565648
Closes-Bug: #1336207
",git fetch https://review.opendev.org/openstack/neutron refs/changes/34/107734/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/extensions/allowedaddresspairs.py', 'neutron/tests/unit/test_extension_allowedaddresspairs.py']",2,dc6b07d4a37ef0db9906187611fec8e8753803cd,master,"from oslo.config import cfg def test_more_than_max_allowed_address_pair(self): cfg.CONF.set_default('max_allowed_address_pair', 3) address_pairs = [{'mac_address': '00:00:00:00:00:01', 'ip_address': '10.0.0.1'}, {'mac_address': '00:00:00:00:00:02', 'ip_address': '10.0.0.2'}, {'mac_address': '00:00:00:00:00:03', 'ip_address': '10.0.0.3'}, {'mac_address': '00:00:00:00:00:04', 'ip_address': '10.0.0.4'}] self._create_port_with_address_pairs(address_pairs, 400) def test_equal_to_max_allowed_address_pair(self): cfg.CONF.set_default('max_allowed_address_pair', 3) address_pairs = [{'mac_address': '00:00:00:00:00:01', 'ip_address': '10.0.0.1'}, {'mac_address': '00:00:00:00:00:02', 'ip_address': '10.0.0.2'}, {'mac_address': '00:00:00:00:00:03', 'ip_address': '10.0.0.3'}] self._create_port_with_address_pairs(address_pairs, 201) port = self.deserialize(self.fmt, res) if ret_code == 201: self._delete('ports', port['port']['id'])"," self.deserialize(self.fmt, res)",45,1
openstack%2Fironic~master~I682228e158132c628166e4d1e334c4003249d112,openstack/ironic,master,I682228e158132c628166e4d1e334c4003249d112,oslo.i18n migration,MERGED,2014-07-07 11:44:47.000000000,2014-07-18 03:52:49.000000000,2014-07-17 21:42:05.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 7882}, {'_account_id': 8106}]","[{'number': 1, 'created': '2014-07-07 11:44:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6eb9a4b05790d1d988cb010238291bca92edd45a', 'message': 'Initial oslo.i18n migration\n\nWith the release of oslo.i18n, the gettextutils module\nfrom oslo-incubator is no longer necessary.\n\nChange-Id: I682228e158132c628166e4d1e334c4003249d112\n'}, {'number': 2, 'created': '2014-07-15 07:32:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d3b89853b8e6badebd9c8f459ac44f6edd69fffa', 'message': 'oslo.i18n migration\n\nSwitch ironic to use oslo.i18n. A new i18n module has been\nadded under ironic with translation globals and imports the\nnecessary functions from oslo.i18n.\n\ngettextutils module is still needed in the nova ironic driver.\n\nChange-Id: I682228e158132c628166e4d1e334c4003249d112\n'}, {'number': 3, 'created': '2014-07-15 08:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1b8f2768a6eaad85859eda48039ec4a122c8e9a0', 'message': 'oslo.i18n migration\n\nSwitch ironic to use oslo.i18n. A new i18n module has been\nadded under ironic with translation globals and imports the\nnecessary functions from oslo.i18n.\n\ngettextutils module is still needed in the nova ironic driver.\n\nChange-Id: I682228e158132c628166e4d1e334c4003249d112\n'}, {'number': 4, 'created': '2014-07-15 13:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5844febed596c8057a7cee5cba3901d715ae6351', 'message': 'oslo.i18n migration\n\nSwitch ironic to use oslo.i18n. A new i18n module has been\nadded under ironic with translation globals and imports the\nnecessary functions from oslo.i18n.\n\ngettextutils module is still needed in the nova ironic driver.\n\nChange-Id: I682228e158132c628166e4d1e334c4003249d112\n'}, {'number': 5, 'created': '2014-07-16 21:53:17.000000000', 'files': ['ironic/cmd/__init__.py', 'ironic/common/exception.py', 'requirements.txt', 'ironic/api/app.wsgi', 'ironic/common/policy.py', 'ironic/common/i18n.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/61533bbe247af2a3f5d7fbc28b25a29ddd86e4c3', 'message': 'oslo.i18n migration\n\nSwitch ironic to use oslo.i18n. A new i18n module has been\nadded under ironic with translation globals and imports the\nnecessary functions from oslo.i18n.\n\ngettextutils module is still needed in the nova ironic driver.\n\nChange-Id: I682228e158132c628166e4d1e334c4003249d112\n'}]",5,105132,61533bbe247af2a3f5d7fbc28b25a29ddd86e4c3,44,7,5,1726,,,0,"oslo.i18n migration

Switch ironic to use oslo.i18n. A new i18n module has been
added under ironic with translation globals and imports the
necessary functions from oslo.i18n.

gettextutils module is still needed in the nova ironic driver.

Change-Id: I682228e158132c628166e4d1e334c4003249d112
",git fetch https://review.opendev.org/openstack/ironic refs/changes/32/105132/3 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/cmd/__init__.py', 'ironic/i18n.py', 'ironic/common/exception.py', 'requirements.txt', 'openstack-common.conf', 'ironic/api/app.wsgi', 'ironic/common/policy.py', 'tox.ini']",8,6eb9a4b05790d1d988cb010238291bca92edd45a,oslo.i18n,"import_exceptions = ironic.i18n._, testtools.matchers","import_exceptions = ironic.openstack.common.gettextutils._, ironic.openstack.common.gettextutils._LI, ironic.openstack.common.gettextutils._LW,ironic.openstack.common.gettextutils._LE, ironic.openstack.common.gettextutils._LC, testtools.matchers",35,26
openstack%2Fdesignate~master~Ie1e2c3e039c7d767a6563006c37b293cbb2295ff,openstack/designate,master,Ie1e2c3e039c7d767a6563006c37b293cbb2295ff,"Add docs for links, pagination, filtering",MERGED,2014-07-01 13:39:41.000000000,2014-07-18 03:35:56.000000000,2014-07-18 03:35:56.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 11626}]","[{'number': 1, 'created': '2014-07-01 13:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/bf8696e558f09faa2ae1d3aa06b5c17098bc175a', 'message': 'Add docs for links, pagination, filtering\n\nChange-Id: Ie1e2c3e039c7d767a6563006c37b293cbb2295ff\nImplements: blueprint collections-docs\n'}, {'number': 2, 'created': '2014-07-03 15:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/8ec0b920c369d7aabf6f19fcb7fe51be857e91f9', 'message': 'Add docs for links, pagination, filtering\n\nChange-Id: Ie1e2c3e039c7d767a6563006c37b293cbb2295ff\nImplements: blueprint collections-docs\n'}, {'number': 3, 'created': '2014-07-08 20:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/2c273b580a227a79b044d3fef7eeed5af9391789', 'message': 'Add docs for links, pagination, filtering\n\nChange-Id: Ie1e2c3e039c7d767a6563006c37b293cbb2295ff\nImplements: blueprint collections-docs\n'}, {'number': 4, 'created': '2014-07-08 22:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c95f00d1c7e313c722991ed9e8c0ee2a75938968', 'message': 'Add docs for links, pagination, filtering\n\nChange-Id: Ie1e2c3e039c7d767a6563006c37b293cbb2295ff\nImplements: blueprint collections-docs\n'}, {'number': 5, 'created': '2014-07-15 15:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/82fe4fed87e2c6afb74945e5d00f2671ca078e71', 'message': 'Add docs for links, pagination, filtering\n\nChange-Id: Ie1e2c3e039c7d767a6563006c37b293cbb2295ff\nImplements: blueprint collections-docs\n'}, {'number': 6, 'created': '2014-07-16 18:46:51.000000000', 'files': ['doc/source/rest/v2/collections.rst', 'doc/source/rest.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/f58c9a5b8b56cb1331ab6b6eef8ceee8c990c17d', 'message': 'Add docs for links, pagination, filtering\n\nChange-Id: Ie1e2c3e039c7d767a6563006c37b293cbb2295ff\nImplements: blueprint collections-docs\n'}]",21,103891,f58c9a5b8b56cb1331ab6b6eef8ceee8c990c17d,37,5,6,11626,,,0,"Add docs for links, pagination, filtering

Change-Id: Ie1e2c3e039c7d767a6563006c37b293cbb2295ff
Implements: blueprint collections-docs
",git fetch https://review.opendev.org/openstack/designate refs/changes/91/103891/6 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/rest/v2/collections.rst', 'doc/source/rest.rst']",2,bf8696e558f09faa2ae1d3aa06b5c17098bc175a,bp/collections-docs, rest/v2/collections,,221,0
openstack%2Fpython-openstackclient~master~Ie0f3a02e3c2eb87a88a0df94137ae815c8562abf,openstack/python-openstackclient,master,Ie0f3a02e3c2eb87a88a0df94137ae815c8562abf,Don't override private function in CommandManager,ABANDONED,2014-05-22 21:27:59.000000000,2014-07-18 03:27:14.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 6482}, {'_account_id': 7191}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-05-22 21:27:59.000000000', 'files': ['openstackclient/tests/common/test_commandmanager.py', 'openstackclient/common/commandmanager.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c958720f2a922fc6eaa04506cab74b0892b4a359', 'message': ""Don't override private function in CommandManager\n\nThis should be something we can expose in cliff. And you shouldn't do\nthat.\n\nChange-Id: Ie0f3a02e3c2eb87a88a0df94137ae815c8562abf\n""}]",0,95019,c958720f2a922fc6eaa04506cab74b0892b4a359,9,6,1,7191,,,0,"Don't override private function in CommandManager

This should be something we can expose in cliff. And you shouldn't do
that.

Change-Id: Ie0f3a02e3c2eb87a88a0df94137ae815c8562abf
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/19/95019/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/common/test_commandmanager.py', 'openstackclient/common/commandmanager.py']",2,c958720f2a922fc6eaa04506cab74b0892b4a359,privates," self.group_list = [namespace] def add_command_group(self, group): """"""Adds another group of command entrypoints"""""""," self.group_list = [] def _load_commands(self, group=None): if not group: group = self.namespace return def add_command_group(self, group=None): """"""Adds another group of command entrypoints"""""" if group: self._load_commands(group)",13,20
openstack%2Fpython-swiftclient~master~Ife0b6c98c975e074d4dad0a31145573b784747c5,openstack/python-swiftclient,master,Ife0b6c98c975e074d4dad0a31145573b784747c5,Adding Swift Temporary URL support,MERGED,2014-06-25 20:31:18.000000000,2014-07-18 03:22:42.000000000,2014-07-18 03:22:41.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7680}, {'_account_id': 8871}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 10380}]","[{'number': 1, 'created': '2014-06-25 20:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/9d9a3476fed186df7950139d1d57ae53911d973c', 'message': 'Adding Swift Temporary URL support\n\nTemporary URLs allow a user to sign an object URL with a shared\nsecret to so that the object can be downloaded without auth for\na specified amount of time.\n\nhttp://docs.openstack.org/trunk/config-reference/content/object-storage-tempurl.html\n\nChange-Id: Ife0b6c98c975e074d4dad0a31145573b784747c5\n'}, {'number': 2, 'created': '2014-06-30 18:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/9aab59d188ce3517c7df41fae6437989c171fd91', 'message': 'Adding Swift Temporary URL support\n\nTemporary URLs allow a user to sign an object URL with a shared\nsecret to so that the object can be downloaded without auth for\na specified amount of time.\n\nhttp://docs.openstack.org/trunk/config-reference/content/object-storage-tempurl.html\n\nChange-Id: Ife0b6c98c975e074d4dad0a31145573b784747c5\n'}, {'number': 3, 'created': '2014-06-30 18:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/6d8bb6c887a1936f7bb7783d1c7df97278a3ceec', 'message': 'Adding Swift Temporary URL support\n\nTemporary URLs allow a user to sign an object URL with a shared\nsecret to so that the object can be downloaded without auth for\na specified amount of time.\n\nhttp://docs.openstack.org/trunk/config-reference/content/object-storage-tempurl.html\n\nChange-Id: Ife0b6c98c975e074d4dad0a31145573b784747c5\n'}, {'number': 4, 'created': '2014-07-11 00:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/1abd7a6397ec8b1ee2a8b597ef74a16a2dd50daa', 'message': 'Adding Swift Temporary URL support\n\nTemporary URLs allow a user to sign an object URL with a shared\nsecret to so that the object can be downloaded without auth for\na specified amount of time.\n\nhttp://docs.openstack.org/trunk/config-reference/content/object-storage-tempurl.html\n\nChange-Id: Ife0b6c98c975e074d4dad0a31145573b784747c5\n'}, {'number': 5, 'created': '2014-07-11 17:51:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/e0261d867f1326be1def55dabdaa5f7acef898b3', 'message': 'Adding Swift Temporary URL support\n\nTemporary URLs allow a user to sign an object URL with a shared\nsecret to so that the object can be downloaded without auth for\na specified amount of time.\n\nhttp://docs.openstack.org/trunk/config-reference/content/object-storage-tempurl.html\n\nChange-Id: Ife0b6c98c975e074d4dad0a31145573b784747c5\n'}, {'number': 6, 'created': '2014-07-11 20:05:18.000000000', 'files': ['swiftclient/shell.py', 'tests/unit/test_utils.py', 'swiftclient/utils.py', 'tests/unit/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/def0e0a6435deee5c55b7859e1b132590ea0860c', 'message': 'Adding Swift Temporary URL support\n\nTemporary URLs allow a user to sign an object URL with a shared\nsecret to so that the object can be downloaded without auth for\na specified amount of time.\n\nhttp://docs.openstack.org/trunk/config-reference/content/object-storage-tempurl.html\n\nChange-Id: Ife0b6c98c975e074d4dad0a31145573b784747c5\n'}]",17,102632,def0e0a6435deee5c55b7859e1b132590ea0860c,68,9,6,10380,,,0,"Adding Swift Temporary URL support

Temporary URLs allow a user to sign an object URL with a shared
secret to so that the object can be downloaded without auth for
a specified amount of time.

http://docs.openstack.org/trunk/config-reference/content/object-storage-tempurl.html

Change-Id: Ife0b6c98c975e074d4dad0a31145573b784747c5
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/32/102632/4 && git format-patch -1 --stdout FETCH_HEAD,"['swiftclient/shell.py', 'tests/unit/test_utils.py', 'swiftclient/utils.py', 'tests/unit/test_shell.py']",4,9d9a3476fed186df7950139d1d57ae53911d973c,tempurl,"import swiftclient.utils @mock.patch('swiftclient.shell.generate_temp_url') def test_temp_url(self, temp_url): argv = ["""", ""tempurl"", ""/v1/AUTH_account/c/o"", ""secret_key"", ""60"", ""--method"", ""GET"", ""--method"", ""PUT"" ] temp_url.return_value = """" swiftclient.shell.main(argv) temp_url.assert_called_with( '/v1/AUTH_account/c/o', 60, 'secret_key', ['GET', 'PUT']) @mock.patch('swiftclient.shell.generate_temp_url') def test_temp_url_no_methods(self, temp_url): argv = ["""", ""tempurl"", ""/v1/AUTH_account/c/o"", ""secret_key"", ""60""] temp_url.return_value = """" swiftclient.shell.main(argv) temp_url.assert_called_with( '/v1/AUTH_account/c/o', 60, 'secret_key', ['GET', 'HEAD']) ",,173,2
openstack%2Fnova~master~I168af46d28629c8b2cf8adae856f0f66ae3ee922,openstack/nova,master,I168af46d28629c8b2cf8adae856f0f66ae3ee922,VMware: Consolidate fake_session in test_(vm|ds)_util,MERGED,2014-07-14 15:36:22.000000000,2014-07-18 03:22:31.000000000,2014-07-18 03:22:29.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 8871}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-14 15:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d470382dd58be0326957f77b55f1f89dce03f157', 'message': 'VMware: Consolidate fake_session in test_(vm|ds)_util\n\nBoth test_vm_util and test_ds_util contained a fake_session class.\nThe implementation of test_ds_util.fake_session was irrelevant to\nalmost all of its users, which was confusing.\n\nfake_session from these 2 modules is consolidated into fake. We now\nhave fake.FakeSession(), which expects _call_method and _wait_for_task\nto be mocked, and fake.FakeObjectRetrievalSession(), which is a\nutility object for faking the return of an object list.\n\nThe implementation details of test_ds_util.fake_session have been\npushed into test_file_exists and test_file_exists_fails, where they\nbelong.\n\nChange-Id: I168af46d28629c8b2cf8adae856f0f66ae3ee922\n'}, {'number': 2, 'created': '2014-07-14 16:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13350192429b7a44324c24d4dcee558dfb059e8f', 'message': 'VMware: Consolidate fake_session in test_(vm|ds)_util\n\nBoth test_vm_util and test_ds_util contained a fake_session class.\nThe implementation of test_ds_util.fake_session was irrelevant to\nalmost all of its users, which was confusing.\n\nfake_session from these 2 modules is consolidated into fake. We now\nhave fake.FakeSession(), which expects _call_method and _wait_for_task\nto be mocked, and fake.FakeObjectRetrievalSession(), which is a\nutility object for faking the return of an object list.\n\nThe implementation details of test_ds_util.fake_session have been\npushed into test_file_exists and test_file_exists_fails, where they\nbelong.\n\nChange-Id: I168af46d28629c8b2cf8adae856f0f66ae3ee922\n'}, {'number': 3, 'created': '2014-07-17 11:15:11.000000000', 'files': ['nova/tests/virt/vmwareapi/test_ds_util.py', 'nova/tests/virt/vmwareapi/test_vif.py', 'nova/tests/virt/vmwareapi/fake.py', 'nova/tests/virt/vmwareapi/test_vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/13b8714808af17f0976163ff5c65b509338f6adb', 'message': 'VMware: Consolidate fake_session in test_(vm|ds)_util\n\nBoth test_vm_util and test_ds_util contained a fake_session class.\nThe implementation of test_ds_util.fake_session was irrelevant to\nalmost all of its users, which was confusing.\n\nfake_session from these 2 modules is consolidated into fake. We now\nhave fake.FakeSession(), which expects _call_method and _wait_for_task\nto be mocked, and fake.FakeObjectRetrievalSession(), which is a\nutility object for faking the return of an object list.\n\nThe implementation details of test_ds_util.fake_session have been\npushed into test_file_exists and test_file_exists_fails, where they\nbelong.\n\nChange-Id: I168af46d28629c8b2cf8adae856f0f66ae3ee922\n'}]",0,106794,13b8714808af17f0976163ff5c65b509338f6adb,56,10,3,9555,,,0,"VMware: Consolidate fake_session in test_(vm|ds)_util

Both test_vm_util and test_ds_util contained a fake_session class.
The implementation of test_ds_util.fake_session was irrelevant to
almost all of its users, which was confusing.

fake_session from these 2 modules is consolidated into fake. We now
have fake.FakeSession(), which expects _call_method and _wait_for_task
to be mocked, and fake.FakeObjectRetrievalSession(), which is a
utility object for faking the return of an object list.

The implementation details of test_ds_util.fake_session have been
pushed into test_file_exists and test_file_exists_fails, where they
belong.

Change-Id: I168af46d28629c8b2cf8adae856f0f66ae3ee922
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/106794/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/vmwareapi/test_ds_util.py', 'nova/tests/virt/vmwareapi/test_vif.py', 'nova/tests/virt/vmwareapi/fake.py', 'nova/tests/virt/vmwareapi/test_vm_util.py']",4,d470382dd58be0326957f77b55f1f89dce03f157,bp/vmware-spawn-refactor," fake.FakeObjectRetrievalSession(fake_objects)) fake.FakeObjectRetrievalSession(fake_objects), None, None, datastore_valid_regex) session = fake.FakeSession() with mock.patch.object(session, '_call_method', fake_call_method): fake.FakeObjectRetrievalSession(fake0, fake1), None, None, regex) fake.FakeObjectRetrievalSession(fake_objects), None, None, datastore_valid_regex) fake.FakeObjectRetrievalSession(fake_objects), None, None, fake.FakeObjectRetrievalSession(None), host=""fake-host"") fake.FakeObjectRetrievalSession(None), cluster=""fake-cluster"") fake.FakeObjectRetrievalSession(fake_objects), fake_host_id, ['name']) fake.FakeObjectRetrievalSession(""""), 'fake_cluster') fake.FakeObjectRetrievalSession(""""), 'fake_cluster') fake.FakeObjectRetrievalSession(fake_objects), 'vm-123') fake.FakeObjectRetrievalSession(fake_objects), vm_ref) fake.FakeObjectRetrievalSession(fake_objects)) actual = vm_util.get_vnc_port( fake.FakeObjectRetrievalSession(fake_vms)) fake.FakeObjectRetrievalSession(fake_vms)) refs = vm_util.get_all_cluster_refs_by_name( fake.FakeObjectRetrievalSession(fake_objects), ['fake_cluster']) refs = vm_util.get_all_cluster_refs_by_name( fake.FakeObjectRetrievalSession(fake_objects), ['cluster']) refs = vm_util.get_all_cluster_refs_by_name( fake.FakeObjectRetrievalSession(fake_objects), ['cluster']) session = fake.FakeSession() session = fake.FakeSession() session = fake.FakeSession() session = fake.FakeSession() session = fake.FakeSession() session = fake.FakeSession() session = fake.FakeSession() fake.FakeObjectRetrievalSession(objects), objects, lst_properties) session = fake.FakeSession()","class fake_session(object): def __init__(self, *ret): self.ret = ret self.ind = 0 self.vim = fake.FakeVim() def _call_method(self, *args): # return fake objects in circular manner self.ind = (self.ind + 1) % len(self.ret) return self.ret[self.ind - 1] def _wait_for_task(self, task_ref): pass def _get_vim(self): return self.vim fake_session(fake_objects)) fake_session(fake_objects), None, None, datastore_valid_regex) session = fake_session() with mock.patch.object(fake_session, '_call_method', fake_call_method): fake_session(fake0, fake1), None, None, regex) fake_session(fake_objects), None, None, datastore_valid_regex) fake_session(fake_objects), None, None, fake_session(None), host=""fake-host"") fake_session(None), cluster=""fake-cluster"") fake_session(fake_objects), fake_host_id, ['name']) fake_session(""""), 'fake_cluster') fake_session(""""), 'fake_cluster') fake_session(fake_objects), 'vm-123') fake_session(fake_objects), vm_ref) fake_session(fake_objects)) actual = vm_util.get_vnc_port(fake_session(fake_vms)) fake_session(fake_vms)) refs = vm_util.get_all_cluster_refs_by_name(fake_session(fake_objects), ['fake_cluster']) refs = vm_util.get_all_cluster_refs_by_name(fake_session(fake_objects), ['cluster']) refs = vm_util.get_all_cluster_refs_by_name(fake_session(fake_objects), ['cluster']) session = fake_session() session = fake_session() session = fake_session() session = fake_session() session = fake_session() session = fake_session() session = fake_session() fake_session(objects), objects, lst_properties) session = fake_session()",109,100
openstack%2Fheat~stable%2Ficehouse~Id8af407bc23a602ce4ab7527f765567c2d396b61,openstack/heat,stable/icehouse,Id8af407bc23a602ce4ab7527f765567c2d396b61,Make the Heat keystoneclient plugin pick up the right region.,ABANDONED,2014-07-16 19:48:40.000000000,2014-07-18 02:45:26.000000000,,"[{'_account_id': 3}, {'_account_id': 7930}, {'_account_id': 10068}, {'_account_id': 11536}]","[{'number': 1, 'created': '2014-07-16 19:48:40.000000000', 'files': ['contrib/heat_keystoneclient_v2/heat_keystoneclient_v2/client.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c318037742ab1459a72ce0dd09458c0b18fd5a6f', 'message': 'Make the Heat keystoneclient plugin pick up the right region.\n\nThe Heat keystoneclient_v2 plugin did not allow users to specify\nthe region to authenicate. This patch fixed this issue by picking\nup the region name from config file.\n\nCloses-Bug: #1213291\nChange-Id: Id8af407bc23a602ce4ab7527f765567c2d396b61\n'}]",2,107483,c318037742ab1459a72ce0dd09458c0b18fd5a6f,7,4,1,11536,,,0,"Make the Heat keystoneclient plugin pick up the right region.

The Heat keystoneclient_v2 plugin did not allow users to specify
the region to authenicate. This patch fixed this issue by picking
up the region name from config file.

Closes-Bug: #1213291
Change-Id: Id8af407bc23a602ce4ab7527f765567c2d396b61
",git fetch https://review.opendev.org/openstack/heat refs/changes/83/107483/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/heat_keystoneclient_v2/heat_keystoneclient_v2/client.py'],1,c318037742ab1459a72ce0dd09458c0b18fd5a6f,bug/1213291," default_region_name = cfg.CONF.region_name_for_services kwargs.setdefault('region_name', default_region_name)",,2,0
openstack%2Fdiskimage-builder~master~Id6f4fae6acadfe2839b408fb2dd11fb65d65df6e,openstack/diskimage-builder,master,Id6f4fae6acadfe2839b408fb2dd11fb65d65df6e,Echo output when pkg-map fails,MERGED,2014-07-08 18:14:41.000000000,2014-07-18 02:43:13.000000000,2014-07-18 02:43:12.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 360}, {'_account_id': 1726}, {'_account_id': 7144}, {'_account_id': 8399}, {'_account_id': 9369}, {'_account_id': 9712}, {'_account_id': 10035}, {'_account_id': 10375}, {'_account_id': 12182}]","[{'number': 1, 'created': '2014-07-08 18:14:41.000000000', 'files': ['elements/opensuse/bin/install-packages', 'elements/yum/bin/install-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/3df0a0839460d4ea723605d67d5561fc2b1b3966', 'message': 'Echo output when pkg-map fails\n\nWhen the call to pkg-map fails, it prints the error to stdout. However,\nthis output is lost when pkg-map is executed in a subshell, so the\nactual error is never seen. This change adds an explicit echo so the\nerror is shown.\n\nChange-Id: Id6f4fae6acadfe2839b408fb2dd11fb65d65df6e\n'}]",0,105543,3df0a0839460d4ea723605d67d5561fc2b1b3966,31,11,1,7144,,,0,"Echo output when pkg-map fails

When the call to pkg-map fails, it prints the error to stdout. However,
this output is lost when pkg-map is executed in a subshell, so the
actual error is never seen. This change adds an explicit echo so the
error is shown.

Change-Id: Id6f4fae6acadfe2839b408fb2dd11fb65d65df6e
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/43/105543/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/opensuse/bin/install-packages', 'elements/yum/bin/install-packages']",2,3df0a0839460d4ea723605d67d5561fc2b1b3966,," if ! PKG_NAME=$(pkg-map --element $MAP_ELEMENT $i); then echo ""bin/pkg-map error. $PKG_NAME"" exit 1 fi", PKG_NAME=$(pkg-map --element $MAP_ELEMENT $i),8,2
openstack%2Fnova~master~I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4,openstack/nova,master,I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4,Add missing image to instance booted from volume,MERGED,2014-06-06 10:24:44.000000000,2014-07-18 02:39:49.000000000,2014-07-17 17:04:10.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 4428}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 8021}, {'_account_id': 8802}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-06 10:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8c026ea0d01cfee3847a75e1a2f7476cc64fa7e', 'message': 'Add missing image to instance related api\n\nWhen booting an instance from image (creates a new volume), the\nimage_ref for the instance will be None. And the API do not get\nthe image information for the instance also. So when we calling\nthe related API, we get """" for instance.image.\n\nChange-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4\nCloses-bug: 1317880\n'}, {'number': 2, 'created': '2014-06-09 01:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/31f27276caddb65b56a6af3761d2b4bcabafc2c6', 'message': 'Add missing image to instance related api\n\nWhen booting an instance from image (creates a new volume), the\nimage_ref for the instance will be None. And the API do not get\nthe image information for the instance also. So when we calling\nthe related API, we get """" for instance.image.\n\nChange-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4\nCloses-bug: 1317880\n'}, {'number': 3, 'created': '2014-06-11 01:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b50e8ac7eeb1eade2d21721ee7be10c5ac29b6b7', 'message': 'Add missing image to instance related api\n\nWhen booting an instance from image (creates a new volume), the\nimage_ref for the instance will be None. And the API do not get\nthe image information for the instance also. So when we calling\nthe related API, we get """" for instance.image.\n\nChange-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4\nCloses-bug: 1317880\n'}, {'number': 4, 'created': '2014-06-16 10:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9721c5aa6106db4d25dd6c020701a799a1a4e253', 'message': 'Add missing image to instance related api\n\nWhen booting an instance from image (creates a new volume), the\nimage_ref for the instance will be None. And the API do not get\nthe image information for the instance also. So when we calling\nthe related API, we get """" for instance.image.\n\nChange-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4\nCloses-bug: 1317880\n'}, {'number': 5, 'created': '2014-06-24 04:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eac67cbd14ef1f9506d00282f81bce1714a15efa', 'message': 'Add missing image to instance booted from volume\n\nWhen booting an instance from a volume, the image_ref for\nthe instance will be None. And the API do not get the image\ninformation for the instance also. So when we calling the\nrelated API, we get """" for instance.image.\n\nChange-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4\nCloses-bug: 1317880\n'}, {'number': 6, 'created': '2014-06-25 03:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45defac0696e082dd021d59b5de72c75831343cd', 'message': 'Add missing image to instance booted from volume\n\nWhen booting an instance from a volume, the image_ref for\nthe instance will be None. And the API do not get the image\ninformation for the instance also. So when we calling the\nrelated API, we get """" for instance.image.\n\nChange-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4\nCloses-bug: 1317880\n'}, {'number': 7, 'created': '2014-06-25 09:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80998ea1f2ebe1a39d0bc81aa2dd2245db83434a', 'message': 'Add missing image to instance booted from volume\n\nWhen booting an instance from a volume, the image_ref for\nthe instance will be None. And the API do not get the image\ninformation for the instance also. So when we calling the\nrelated API, we get """" for instance.image.\n\nChange-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4\nCloses-bug: 1317880\n'}, {'number': 8, 'created': '2014-06-26 02:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14a9ad8df923c9127073598c6c7e8896273c40ef', 'message': 'Add missing image to instance booted from volume\n\nWhen booting an instance from a volume, the image_ref for\nthe instance will be None. And the API do not get the image\ninformation for the instance also. So when we calling the\nrelated API, we get """" for instance.image.\n\nChange-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4\nCloses-bug: 1317880\n'}, {'number': 9, 'created': '2014-07-02 01:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12ff0b453647ee7d4c8b9f96a42b42da5d588398', 'message': 'Add missing image to instance booted from volume\n\nWhen booting an instance from a volume, the image_ref for\nthe instance will be None. And the API do not get the image\ninformation for the instance also. So when we calling the\nrelated API, we get """" for instance.image.\n\nChange-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4\nCloses-bug: 1317880\n'}, {'number': 10, 'created': '2014-07-09 03:43:15.000000000', 'files': ['nova/tests/objects/test_instance.py', 'nova/tests/api/openstack/compute/test_servers.py', 'nova/objects/instance.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c3191cf0ba5ad3dc2df8da2a2bf5c9d270fde9d9', 'message': 'Add missing image to instance booted from volume\n\nWhen booting an instance from a volume, the image_ref for\nthe instance will be None. And the API do not get the image\ninformation for the instance also. So when we calling the\nrelated API, we get """" for instance.image.\n\nChange-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4\nCloses-bug: 1317880\n'}]",25,98356,c3191cf0ba5ad3dc2df8da2a2bf5c9d270fde9d9,133,17,10,4428,,,0,"Add missing image to instance booted from volume

When booting an instance from a volume, the image_ref for
the instance will be None. And the API do not get the image
information for the instance also. So when we calling the
related API, we get """" for instance.image.

Change-Id: I3c35ab1d7c8bcec551fb5d67d0b44418266b32a4
Closes-bug: 1317880
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/98356/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/servers.py'],1,e8c026ea0d01cfee3847a75e1a2f7476cc64fa7e,bug/1317880,"from nova.objects import block_device as bdo for instance in instance_list: bdms = bdo.BlockDeviceMappingList.get_by_instance_uuid( context, instance.uuid) if self.compute_api.is_volume_backed_instance(context, instance, bdms): img = instance['image_ref'] if not img: props = bdms.root_metadata( context, self.compute_api.image_api, self.compute_api.volume_api) instance['image_ref'] = props['image_id'] bdms = bdo.BlockDeviceMappingList.get_by_instance_uuid( context, instance.uuid) if self.compute_api.is_volume_backed_instance(context, instance, bdms): img = instance['image_ref'] if not img: props = bdms.root_metadata( context, self.compute_api.image_api, self.compute_api.volume_api) instance['image_ref'] = props['image_id'] bdms = bdo.BlockDeviceMappingList.get_by_instance_uuid(",from nova.objects import block_device as block_device_obj bdms = block_device_obj.BlockDeviceMappingList.get_by_instance_uuid(,24,2
openstack%2Fneutron~master~Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e,openstack/neutron,master,Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e,L2 Model additions to support DVR,MERGED,2014-06-24 04:40:01.000000000,2014-07-18 02:33:03.000000000,2014-07-17 20:53:06.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 2888}, {'_account_id': 4149}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6854}, {'_account_id': 6876}, {'_account_id': 7016}, {'_account_id': 7249}, {'_account_id': 7448}, {'_account_id': 8253}, {'_account_id': 8279}, {'_account_id': 9008}, {'_account_id': 9093}, {'_account_id': 9200}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9885}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 12210}]","[{'number': 1, 'created': '2014-06-24 04:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/64dc88238051124a088d345d695d7dfedde9e65f', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 2, 'created': '2014-06-24 08:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/abaf54ae4f5057876d9ba392fecd82fff3e61cb9', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 3, 'created': '2014-06-25 00:14:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0fd6c9f0ff137a4e85bdec4c659c15b7636cc15c', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 4, 'created': '2014-06-25 20:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b537ff6d8ab7d6f58b01cf7213c192a7772bb7c', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 5, 'created': '2014-06-26 01:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b412d435bd22a4c43f4812eae60a85299bccb7c', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 6, 'created': '2014-06-26 11:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4cd7076c6f53dbbe1a8cfb508aacf09e875f98aa', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 7, 'created': '2014-06-27 00:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea652f0873540aeb168fb13688643f5016ae65cd', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\none is used to set DVR MAC addresses apart from\ntenant ones (every distributed router will have ports\nbeing created on compute hosts) and the other is used\nto enable dvr support in the L2 agent. This gives the\ncapability of rolling out the dvr functionality in\nstages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 8, 'created': '2014-06-27 03:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d48bbd03d500aa2f9ed24f71b8541fa7cc5dc7c', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\none is used to set DVR MAC addresses apart from\ntenant ones (every distributed router will have ports\nbeing created on compute hosts) and the other is used\nto enable dvr support in the L2 agent. This gives the\ncapability of rolling out the dvr functionality in\nstages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 9, 'created': '2014-06-27 18:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/42c8712c0760387719f1955199ea83e659e90e03', 'message': 'L2 Models additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\none is used to set DVR MAC addresses apart from\ntenant ones (every distributed router will have ports\nbeing created on compute hosts) and the other is used\nto enable dvr support in the L2 agent. This gives the\ncapability of rolling out the dvr functionality in\nstages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 10, 'created': '2014-06-28 01:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/846cbc9a2e9193eb0822af9d4ddf35d66d98f42c', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\none is used to set DVR MAC addresses apart from\ntenant ones (every distributed router will have ports\nbeing created on compute hosts) and the other is used\nto enable dvr support in the L2 agent. This gives the\ncapability of rolling out the dvr functionality in\nstages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 11, 'created': '2014-06-28 02:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4265a2de4e88dad0baefcccf8b46861fd388d976', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\none is used to set DVR MAC addresses apart from\ntenant ones (every distributed router will have ports\nbeing created on compute hosts) and the other is used\nto enable dvr support in the L2 agent. This gives the\ncapability of rolling out the dvr functionality in\nstages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 12, 'created': '2014-06-29 16:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd72a5440e9b587b1a558ad9af1b40948776e944', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n""}, {'number': 13, 'created': '2014-06-30 12:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/10acc161d4486255e7b95f600741c9e1c06cb333', 'message': 'L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\none is used to set DVR MAC addresses apart from\ntenant ones (every distributed router will have ports\nbeing created on compute hosts) and the other is used\nto enable dvr support in the L2 agent. This gives the\ncapability of rolling out the dvr functionality in\nstages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n'}, {'number': 14, 'created': '2014-06-30 20:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/729ee9ca4c3c183735f384beebd8efb5dda90991', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n""}, {'number': 15, 'created': '2014-06-30 21:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/437ac95a8fa827b8c53c6ae550d96fbcb84b9714', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\n""}, {'number': 16, 'created': '2014-06-30 23:08:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad6fdd43ae600a15b239536efe2586a4bb0818c7', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 17, 'created': '2014-06-30 23:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f33e770485ea79e42f03d0b6e81428909bb3e33', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 18, 'created': '2014-06-30 23:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ac17329cec98d468ffbc52f947618addaafb8916', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 19, 'created': '2014-07-01 07:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4699b126bf1c0d67ee818fc6ae38df0b7c177fc', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 20, 'created': '2014-07-01 14:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/faa5207957b54c7d8d1a78f50e75bf4dca617049', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 21, 'created': '2014-07-01 16:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d715bbb6d13cfa084deede0b29e5616bb19d5e49', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 22, 'created': '2014-07-01 21:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e70bcd91c914013ebaaa7eb8880fc1a426054d8', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 23, 'created': '2014-07-02 18:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8c2a684118c8acd63d682086783d8c8584ba459a', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 24, 'created': '2014-07-03 01:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9d108a65f2dbf53c779b91e3e27a655969853e60', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 25, 'created': '2014-07-07 15:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b8174a8a0bff13221d02315930c8e34d8b733ef', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 26, 'created': '2014-07-07 15:47:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e4d8a6a1cb243b9795bc70044b7315cdfc957f9', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 27, 'created': '2014-07-07 15:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9221e60a496ba74ca7de5c86551b43397de61ad', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 28, 'created': '2014-07-08 01:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/15772635e42f91c1ac5775f3cac7b9c8ceb30b7a', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 29, 'created': '2014-07-09 07:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e63fc2923909211f4de6ddd8c07d11da854f14d', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 30, 'created': '2014-07-09 21:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d74ac5f3928bf5366a00821eff4256bfbc366ec1', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 31, 'created': '2014-07-10 02:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d17ced38204f5922861c8f891ac72af71b12f7d', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 32, 'created': '2014-07-10 22:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/077f085ea81fe418b8ade7586e4d442178de983a', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 33, 'created': '2014-07-11 01:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/89e7800fae8617503bac7c008dfd8a37288b8598', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 34, 'created': '2014-07-11 17:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/71bab5163938f3180584c2e86306a33d723a8672', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 35, 'created': '2014-07-11 17:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/920805bf394f3316a4efc95f8b9086fd3c25b8f0', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 36, 'created': '2014-07-14 19:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a7d4ce0659a3cfcbf9c18f6703b385982047b83', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 37, 'created': '2014-07-16 00:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0434af5239ec59c32b44a3c75f12c4a97f18a15e', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 38, 'created': '2014-07-16 02:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/adbca427d76993321f0d33bb1d1467eebe966ea6', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 39, 'created': '2014-07-16 15:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13309e01f8a5c6cbd5765951b6f4c19ab62fb5e1', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 40, 'created': '2014-07-17 14:53:22.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/2026156eab2f_l2_dvr_models.py', 'neutron/db/migration/models/head.py', 'etc/neutron.conf', 'neutron/plugins/openvswitch/common/config.py', 'etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini', 'neutron/common/utils.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/plugins/ml2/drivers/l2pop/db.py', 'neutron/db/dvr_mac_db.py', 'neutron/plugins/ml2/models.py', 'neutron/plugins/ml2/db.py', 'neutron/tests/unit/ml2/db/__init__.py', 'neutron/extensions/dvr.py', 'neutron/tests/unit/db/test_dvr_mac_db.py', 'neutron/tests/unit/ml2/db/test_ml2_dvr_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/10579d28d71bd8aba88d7eb83c6a0e293cae616d', 'message': ""L2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}]",211,102101,10579d28d71bd8aba88d7eb83c6a0e293cae616d,758,39,40,748,,,0,"L2 Model additions to support DVR

This patch introduces the models, the DB migrations
and the config options required by the L2 layer to
support DVR east/west traffic.

These changes will be used by the control-plane made
of ML2, L2pop and L2 agent.

Two new configuration options have been introduced:
'dvr_base_mac' is used to set DVR MAC addresses apart
from tenant ones (every distributed router will have
ports being created on compute hosts) and
'enable_distributed_routing' is used to enable dvr
support in the L2 agent. This gives the capability of
rolling out the dvr functionality in stages.

Partially-implements: blueprint neutron-ovs-dvr

DocImpact

Change-Id: Iab6505f239d2c4c9bcbf4e32a292d7b4b5320c8e
Authored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>
Co-Authored-By: Armando Migliaccio <armamig@gmail.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/102101/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/2026156eab2f_l2_dvr_models.py', 'neutron/db/dvr_db.py', 'neutron/plugins/ml2/models.py', 'neutron/plugins/ml2/db.py', 'etc/neutron.conf', 'neutron/plugins/openvswitch/common/config.py', 'neutron/extensions/dvr.py', 'etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini', 'neutron/common/utils.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/plugins/ml2/drivers/l2pop/db.py']",11,64dc88238051124a088d345d695d7dfedde9e65f,bp/neutron-ovs-dvr," def get_network_ports(self, session, network_id, query=None, filters=None): with session.begin(subtransactions=True): if not query: query = session.query(ml2_models.PortBinding, agents_db.Agent) query = query.join(agents_db.Agent, agents_db.Agent.host == ml2_models.PortBinding.host) query = query.join(models_v2.Port) if filters: query.filter(filters) def get_nondvr_network_ports(self, session, network_id): non_dvr_ports = (models_v2.Port.device_owner != const.DEVICE_OWNER_ROUTER_INTF_DISTRIBUTED) return self.get_network_ports(filters=non_dvr_ports) def get_dvr_network_ports(self, session, network_id): query = session.query(ml2_models.DVRPortBinding, agents_db.Agent) query = query.join(agents_db.Agent, agents_db.Agent.host == ml2_models.DVRPortBinding.host) dvr_ports = (models_v2.Port.device_owner == const.DEVICE_OWNER_ROUTER_INTF_DISTRIBUTED) return self.get_network_ports(session, network_id, query=query, filters=dvr_ports) def get_agent_network_active_port_count(self, session, agent_host, query1 = query.join(ml2_models.PortBinding) query1 = query1.filter(models_v2.Port.network_id == network_id, models_v2.Port.status == const.PORT_STATUS_ACTIVE, models_v2.Port.device_owner != const.DEVICE_OWNER_ROUTER_INTF_DISTRIBUTED, ml2_models.PortBinding.host == agent_host) query2 = query.join(ml2_models.DVRPortBinding) query2 = query2.filter(models_v2.Port.network_id == network_id, ml2_models.DVRPortBinding.status == const.PORT_STATUS_ACTIVE, models_v2.Port.device_owner == const.DEVICE_OWNER_ROUTER_INTF_DISTRIBUTED, ml2_models.DVRPortBinding.host == agent_host) return (query1.count() + query2.count())"," def get_network_ports(self, session, network_id): with session.begin(subtransactions=True): query = session.query(ml2_models.PortBinding, agents_db.Agent) query = query.join(agents_db.Agent, agents_db.Agent.host == ml2_models.PortBinding.host) query = query.join(models_v2.Port) def get_agent_network_active_port_count(self, session, agent_host, query = query.join(ml2_models.PortBinding) query = query.filter(models_v2.Port.network_id == network_id, models_v2.Port.status == const.PORT_STATUS_ACTIVE, ml2_models.PortBinding.host == agent_host) return query.count()",448,16
openstack%2Ftempest~master~If0ab41d6062c83cee50f830ffd9428c1302fd997,openstack/tempest,master,If0ab41d6062c83cee50f830ffd9428c1302fd997,Fixed argument parsing in run script,MERGED,2014-06-01 18:30:23.000000000,2014-07-18 02:25:20.000000000,2014-07-18 02:25:20.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 7139}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11155}]","[{'number': 1, 'created': '2014-06-01 18:30:23.000000000', 'files': ['run_tempest.sh'], 'web_link': 'https://opendev.org/openstack/tempest/commit/866079825cb24abc349bd3aecac23e455b0fd898', 'message': 'Fixed argument parsing in run script\n\nReplaced += with = when adding arguments to the testrargs string\nto prevent the script from doubling in length with each additional\nargument.\n\nChange-Id: If0ab41d6062c83cee50f830ffd9428c1302fd997\nCloses-Bug: #1325405\n'}]",2,97120,866079825cb24abc349bd3aecac23e455b0fd898,61,10,1,11155,,,0,"Fixed argument parsing in run script

Replaced += with = when adding arguments to the testrargs string
to prevent the script from doubling in length with each additional
argument.

Change-Id: If0ab41d6062c83cee50f830ffd9428c1302fd997
Closes-Bug: #1325405
",git fetch https://review.opendev.org/openstack/tempest refs/changes/20/97120/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tempest.sh'],1,866079825cb24abc349bd3aecac23e455b0fd898,bug/1325405," *) testrargs=""$testrargs $1"";;"," *) testrargs+=""$testrargs $1"";;",1,1
openstack%2Ftempest~master~If0f8c2b71381be087694654969d7ea1483da7b17,openstack/tempest,master,If0f8c2b71381be087694654969d7ea1483da7b17,Correct misspelled words,MERGED,2014-07-15 13:30:27.000000000,2014-07-18 02:25:11.000000000,2014-07-18 02:25:11.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 6167}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8556}, {'_account_id': 8794}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10385}, {'_account_id': 11670}]","[{'number': 1, 'created': '2014-07-15 13:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/48068004f4bc2906b3bed3cb1fd1fceaba519dee', 'message': 'Correct misspelled words\n\nCorrect some misspelled words:\nresponCe => responSe,\nunkown => unkNow\ninfomation => infoRmation.\n\nChange-Id: If0f8c2b71381be087694654969d7ea1483da7b17\n'}, {'number': 2, 'created': '2014-07-15 14:54:58.000000000', 'files': ['tools/subunit-trace.py', 'tempest/tests/negative/test_negative_generators.py', 'tempest/scenario/test_load_balancer_basic.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e1d88999454991fb2abef51af9833cac6d2d8518', 'message': 'Correct misspelled words\n\nCorrect some misspelled words:\nresponCe => responSe,\nunkown => unkNown\ninfomation => infoRmation.\n\nChange-Id: If0f8c2b71381be087694654969d7ea1483da7b17\n'}]",2,107050,e1d88999454991fb2abef51af9833cac6d2d8518,29,11,2,8794,,,0,"Correct misspelled words

Correct some misspelled words:
responCe => responSe,
unkown => unkNown
infomation => infoRmation.

Change-Id: If0f8c2b71381be087694654969d7ea1483da7b17
",git fetch https://review.opendev.org/openstack/tempest refs/changes/50/107050/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/subunit-trace.py', 'tempest/tests/negative/test_negative_generators.py', 'tempest/scenario/test_load_balancer_basic.py']",3,48068004f4bc2906b3bed3cb1fd1fceaba519dee,misspellings, # Write a backend's response into a file, # Write a backend's responce into a file,4,4
openstack%2Fdevstack~master~I9697d71f3cb2d8d5da8fe7ffa8b3e1ade9d52afd,openstack/devstack,master,I9697d71f3cb2d8d5da8fe7ffa8b3e1ade9d52afd,Make apache restarts a little more forgiving,MERGED,2014-07-15 18:07:57.000000000,2014-07-18 02:25:08.000000000,2014-07-18 02:25:07.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 2903}, {'_account_id': 5638}, {'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-15 18:07:57.000000000', 'files': ['lib/apache'], 'web_link': 'https://opendev.org/openstack/devstack/commit/2df0046fa759481f793d9c51563728b21c7858d8', 'message': ""Make apache restarts a little more forgiving\n\nApache sometimes is slow to release the port (from the kernel's\nperspective) which can cause restarts of apache to fail due to the\nrequested port already being bound. This fix introduces a small sleep\nbetween the stop and start to help make apache deployments a bit\nmore resilient.\n\nChange-Id: I9697d71f3cb2d8d5da8fe7ffa8b3e1ade9d52afd\nCloses-Bug: #1342256\n""}]",7,107131,2df0046fa759481f793d9c51563728b21c7858d8,34,8,1,2903,,,0,"Make apache restarts a little more forgiving

Apache sometimes is slow to release the port (from the kernel's
perspective) which can cause restarts of apache to fail due to the
requested port already being bound. This fix introduces a small sleep
between the stop and start to help make apache deployments a bit
more resilient.

Change-Id: I9697d71f3cb2d8d5da8fe7ffa8b3e1ade9d52afd
Closes-Bug: #1342256
",git fetch https://review.opendev.org/openstack/devstack refs/changes/31/107131/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/apache'],1,2df0046fa759481f793d9c51563728b21c7858d8,bug/1342256," # Apache can be slow to stop, doing an explicit stop, sleep, start helps # to mitigate issues where apache will claim a port it's listening on is # still in use and fail to start. stop_service $APACHE_NAME sleep 3 start_service $APACHE_NAME", restart_service $APACHE_NAME,6,1
openstack%2Fcinder~master~I27191e0ba3d480d8ac00e2d183ae4717abcf9f8c,openstack/cinder,master,I27191e0ba3d480d8ac00e2d183ae4717abcf9f8c,Add volume driver for Huawei 18000 storage system,ABANDONED,2014-07-16 06:41:28.000000000,2014-07-18 02:17:05.000000000,,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 11811}, {'_account_id': 12017}]","[{'number': 1, 'created': '2014-07-16 06:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/445c8c0aff16e8fa62edc5cca30158734be67fb5', 'message': 'Add volume driver for Huawei 18000 storage system\n\nHuawei OceanStor 18000-series enterprise storage system is an optimum\nstorage platform for next-generation data centers that feature\nvirtualization, hybrid cloud, simplified IT, and low carbon footprints.\n\nThis patch add an iSCSI driver and a FC driver for Huawei 18000 storage\nsystem, using REST. We define a common module for both iSCSI driver and\nFC driver.\n\nChange-Id: I27191e0ba3d480d8ac00e2d183ae4717abcf9f8c\nImplements: blueprint huawei-18000-driver\n'}, {'number': 2, 'created': '2014-07-18 02:14:56.000000000', 'files': ['cinder/tests/test_huawei_18000.py', 'cinder/tests/test_huawei_hvs.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/volume/drivers/huawei/huawei_18000.py', 'cinder/volume/drivers/huawei/__init__.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/717f082ced002fa3d054724333237d2d2efd6745', 'message': 'Add volume driver for Huawei 18000 storage system\n\nHuawei OceanStor 18000-series enterprise storage system is an optimum\nstorage platform for next-generation data centers that feature\nvirtualization, hybrid cloud, simplified IT, and low carbon footprints.\n\nThis patch add an iSCSI driver and a FC driver for Huawei 18000 storage\nsystem, using REST. We define a common module for both iSCSI driver and\nFC driver.\n\nChange-Id: I27191e0ba3d480d8ac00e2d183ae4717abcf9f8c\nImplements: blueprint huawei-18000-driver\n'}]",9,107242,717f082ced002fa3d054724333237d2d2efd6745,10,4,2,6604,,,0,"Add volume driver for Huawei 18000 storage system

Huawei OceanStor 18000-series enterprise storage system is an optimum
storage platform for next-generation data centers that feature
virtualization, hybrid cloud, simplified IT, and low carbon footprints.

This patch add an iSCSI driver and a FC driver for Huawei 18000 storage
system, using REST. We define a common module for both iSCSI driver and
FC driver.

Change-Id: I27191e0ba3d480d8ac00e2d183ae4717abcf9f8c
Implements: blueprint huawei-18000-driver
",git fetch https://review.opendev.org/openstack/cinder refs/changes/42/107242/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_huawei_18000.py', 'cinder/tests/test_huawei_hvs.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/volume/drivers/huawei/huawei_18000.py', 'cinder/volume/drivers/huawei/__init__.py']",5,445c8c0aff16e8fa62edc5cca30158734be67fb5,bp/huawei-18000-driver,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 from cinder.volume.drivers.huawei import huawei_18000 '18000': huawei_18000} LOG.info(_('_instantiate_driver: Loading %(protocol)s driver for ' 'Huawei OceanStor %(product)s series storage arrays.') % {'protocol': protocol, 'product': product}) 'be set to either T, Dorado or 18000. ""Protocol"" should ' % {'product': str(product), 'protocol': str(protocol)})","from cinder.volume.drivers.huawei import huawei_hvs 'HVS': huawei_hvs} LOG.debug('_instantiate_driver: Loading %(protocol)s driver for ' 'Huawei OceanStor %(product)s series storage arrays.' % {'protocol': protocol, 'product': product}) 'be set to either T, Dorado or HVS. ""Protocol"" should ' % {'product': product, 'protocol': protocol})",1081,1189
openstack%2Ftempest~master~I00c4146148063f6b20396dcbd0c911a386e488b1,openstack/tempest,master,I00c4146148063f6b20396dcbd0c911a386e488b1,Skip hypervisor uptime test for baremetal,MERGED,2014-07-07 21:02:27.000000000,2014-07-18 02:05:08.000000000,2014-07-18 02:05:08.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 3099}, {'_account_id': 6167}, {'_account_id': 7126}, {'_account_id': 8556}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-07 21:02:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/96ad42ef1ac0d1abc3a542e19f102355afe53897', 'message': 'Skip hypervisor uptime test for baremetal\n\nBaremetal and ironic drivers have no concept of a hypervisor, thus\nthey do not implement the get_host_uptime() virt driver API call.\nWe would have to modify the underlying Tempest class that does the REST\ncalls to consider HTTP 501 (Not Implemented) successful, which would\naffect the entire test suite. Instead, we just skip this test if\nthe baremetal/ironic driver is enabled.\n\nChange-Id: I00c4146148063f6b20396dcbd0c911a386e488b1\nCloses-Bug: #1338711\n'}, {'number': 2, 'created': '2014-07-08 16:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a8882db37b69b7cba2cfa06a34b8cfebe98a2749', 'message': 'Skip hypervisor uptime test for baremetal\n\nBaremetal and ironic drivers have no concept of a hypervisor, thus\nthey do not implement the get_host_uptime() virt driver API call.\nWe would have to modify the underlying Tempest class that does the REST\ncalls to consider HTTP 501 (Not Implemented) successful, which would\naffect the entire test suite. Instead, we just skip this test if\nthe baremetal/ironic driver is enabled.\n\nChange-Id: I00c4146148063f6b20396dcbd0c911a386e488b1\nCloses-Bug: #1338711\n'}, {'number': 3, 'created': '2014-07-15 21:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c85143c49412ea02ca8e96798f47f7476a1c8ca9', 'message': 'Skip hypervisor uptime test for baremetal\n\nBaremetal and ironic drivers have no concept of a hypervisor, thus\nthey do not implement the get_host_uptime() virt driver API call.\nWe would have to modify the underlying Tempest class that does the REST\ncalls to consider HTTP 501 (Not Implemented) successful, which would\naffect the entire test suite. Instead, we just skip this test if\nthe baremetal/ironic driver is enabled.\n\nChange-Id: I00c4146148063f6b20396dcbd0c911a386e488b1\nCloses-Bug: #1338711\n'}, {'number': 4, 'created': '2014-07-15 21:50:20.000000000', 'files': ['tempest/api/compute/admin/test_hypervisor.py', 'tempest/api/compute/v3/admin/test_hypervisor.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/152b7812026917889c2081762a773d47393c85ec', 'message': 'Skip hypervisor uptime test for baremetal\n\nBaremetal and ironic drivers have no concept of a hypervisor, thus\nthey do not implement the get_host_uptime() virt driver API call.\nWe would have to modify the underlying Tempest class that does the REST\ncalls to consider HTTP 501 (Not Implemented) successful, which would\naffect the entire test suite. Instead, we just skip this test if\nthe baremetal/ironic driver is enabled.\n\nChange-Id: I00c4146148063f6b20396dcbd0c911a386e488b1\nCloses-Bug: #1338711\n'}]",7,105278,152b7812026917889c2081762a773d47393c85ec,41,8,4,3099,,,0,"Skip hypervisor uptime test for baremetal

Baremetal and ironic drivers have no concept of a hypervisor, thus
they do not implement the get_host_uptime() virt driver API call.
We would have to modify the underlying Tempest class that does the REST
calls to consider HTTP 501 (Not Implemented) successful, which would
affect the entire test suite. Instead, we just skip this test if
the baremetal/ironic driver is enabled.

Change-Id: I00c4146148063f6b20396dcbd0c911a386e488b1
Closes-Bug: #1338711
",git fetch https://review.opendev.org/openstack/tempest refs/changes/78/105278/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_hypervisor.py'],1,96ad42ef1ac0d1abc3a542e19f102355afe53897,dev,"import testtools from tempest import configCONF = config.CONF @testtools.skipIf(CONF.baremetal.driver_enabled, ""Baremetal does not support hypervisor uptime"")",,7,0
openstack%2Fmonasca-api~master~I8645a4dd8061d93503b499d5ea5ff5d05b181a50,openstack/monasca-api,master,I8645a4dd8061d93503b499d5ea5ff5d05b181a50,Test.,ABANDONED,2014-07-18 01:55:13.000000000,2014-07-18 02:01:44.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-18 01:55:13.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/3db8f3c79ec8b0154eed53a021a2e517f47dd252', 'message': 'Test.\n\nAdd a space to test gerrit account.\n\nChange-Id: I8645a4dd8061d93503b499d5ea5ff5d05b181a50\n'}]",0,107876,3db8f3c79ec8b0154eed53a021a2e517f47dd252,4,1,1,12512,,,0,"Test.

Add a space to test gerrit account.

Change-Id: I8645a4dd8061d93503b499d5ea5ff5d05b181a50
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/76/107876/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,3db8f3c79ec8b0154eed53a021a2e517f47dd252,test/test,limitations under the License. ,limitations under the License.,1,1
openstack%2Ftripleo-image-elements~master~I28c62fedc372c57e86566270b7e1e99b82a921a4,openstack/tripleo-image-elements,master,I28c62fedc372c57e86566270b7e1e99b82a921a4,"Revert ""Adds passthrough config for cinder rootwra",MERGED,2014-07-15 13:02:16.000000000,2014-07-18 01:41:39.000000000,2014-07-18 01:41:39.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 8153}, {'_account_id': 9369}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-07-15 13:02:16.000000000', 'files': ['elements/cinder/README.md', 'elements/cinder/os-apply-config/etc/cinder/rootwrap.d/passthrough.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0baa3af50bf86c17d5506d80da68e5238cdc09f5', 'message': 'Revert ""Adds passthrough config for cinder rootwra\n\nThis reverts commit 908a9f5dfe4d7174612c37a59b2a7fb4bb30fd68.\n\nThis config file is empty by default and breaks the ability\nto create cinder volumes with the following error from\noslo.rootwrap:\n\n  No section: \\\'Filters\\\'\\n\'\n\nChange-Id: I28c62fedc372c57e86566270b7e1e99b82a921a4\nCloses-bug: #1342101\n'}]",0,107041,0baa3af50bf86c17d5506d80da68e5238cdc09f5,26,6,1,360,,,0,"Revert ""Adds passthrough config for cinder rootwra

This reverts commit 908a9f5dfe4d7174612c37a59b2a7fb4bb30fd68.

This config file is empty by default and breaks the ability
to create cinder volumes with the following error from
oslo.rootwrap:

  No section: \'Filters\'\n'

Change-Id: I28c62fedc372c57e86566270b7e1e99b82a921a4
Closes-bug: #1342101
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/41/107041/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/cinder/README.md', 'elements/cinder/os-apply-config/etc/cinder/rootwrap.d/passthrough.conf']",2,0baa3af50bf86c17d5506d80da68e5238cdc09f5,revert_cinder_passthrough,,{{#cinder}} {{#rootwrap_config}} [{{{section}}}] {{#values}} {{#comment}} # {{{.}}} {{/comment}} {{#option}} {{{option}}}={{{value}}} {{/option}} {{/values}} {{/rootwrap_config}} {{/cinder}} ,1,36
openstack%2Fhorizon~master~If3a43b90f524aa780aac4ecece5dbbbbba75137b,openstack/horizon,master,If3a43b90f524aa780aac4ecece5dbbbbba75137b,fix Instance table's Flavor Detail popover not showing up,MERGED,2014-07-16 20:28:06.000000000,2014-07-18 01:16:06.000000000,2014-07-18 01:16:05.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 8090}, {'_account_id': 9576}, {'_account_id': 10295}]","[{'number': 1, 'created': '2014-07-16 20:28:06.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/templates/instances/_instance_flavor.html', 'openstack_dashboard/dashboards/project/instances/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0fc4d7f88fd65fa0911388f3cc8ee373e0dec0b5', 'message': ""fix Instance table's Flavor Detail popover not showing up\n\nUsing the Flavor ID as the unique ID for the popover causes\nproblems - if you have multiple instance with the same flavor,\nthe popover would not show up except for the first in the list.\n\nSolution is to have a unique ID using the instance ID.\n\nChange-Id: If3a43b90f524aa780aac4ecece5dbbbbba75137b\nCloses-Bug: #1342907\n""}]",2,107491,0fc4d7f88fd65fa0911388f3cc8ee373e0dec0b5,15,7,1,9622,,,0,"fix Instance table's Flavor Detail popover not showing up

Using the Flavor ID as the unique ID for the popover causes
problems - if you have multiple instance with the same flavor,
the popover would not show up except for the first in the list.

Solution is to have a unique ID using the instance ID.

Change-Id: If3a43b90f524aa780aac4ecece5dbbbbba75137b
Closes-Bug: #1342907
",git fetch https://review.opendev.org/openstack/horizon refs/changes/91/107491/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/instances/templates/instances/_instance_flavor.html', 'openstack_dashboard/dashboards/project/instances/tables.py']",2,0fc4d7f88fd65fa0911388f3cc8ee373e0dec0b5,bug/1342907," ""id"": instance.id,"," ""flavor_id"": instance.full_flavor.id,",3,3
openstack%2Ffuel-web~master~I0d83819a22177028bffbaca7d1f0e1499e8909c5,openstack/fuel-web,master,I0d83819a22177028bffbaca7d1f0e1499e8909c5,Mellanox Changes in deployment serializers,MERGED,2014-07-03 09:56:33.000000000,2014-07-18 00:48:27.000000000,2014-07-18 00:48:26.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8053}, {'_account_id': 8749}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11968}, {'_account_id': 12065}, {'_account_id': 12171}, {'_account_id': 12177}]","[{'number': 1, 'created': '2014-07-03 09:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1ddc9533bae717a9b85101c9984982f4633888b5', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 2, 'created': '2014-07-03 10:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/266a1a84e073b9547d6754506f8e992501e7695c', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 3, 'created': '2014-07-03 16:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a2ac43f409227c07ae1a776212716f29915a534e', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 4, 'created': '2014-07-03 17:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4b7664291e554c5b20f6548b3bc823afbe15fc4f', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 5, 'created': '2014-07-09 16:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/cc28c772ffabb7c80002e49853f99d5fa358119e', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 6, 'created': '2014-07-09 16:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9f0a86769211d1f870d6d7d9974a6ea9f80593ef', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 7, 'created': '2014-07-10 21:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3622d878e522e009e50d70c0c5657d1450c4dc48', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 8, 'created': '2014-07-10 21:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/10b19aef5605ae42c74aa88fb234eb287c7ffa4b', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 9, 'created': '2014-07-11 00:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7bae5c456f517ead6297c5e2c2a5dd2a10297de8', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 10, 'created': '2014-07-11 08:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fee72003cb28fb25e3ae788dfd80038d1860cbe9', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 11, 'created': '2014-07-15 11:55:19.000000000', 'files': ['nailgun/nailgun/orchestrator/deployment_serializers.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a9446e97aa98d48aa42bfff0b6c0e8556c92e7e0', 'message': 'Mellanox Changes in deployment serializers\n\nAdded Changes to deployment serializers, in case of Mellanox\nfeatures usage:\n  1. Changing network scheme to use a predefined name for storage interface,\n     in case of iSER usage.\n  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox\n     components (for attaching virtual functions to virtual machined).\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}]",5,104501,a9446e97aa98d48aa42bfff0b6c0e8556c92e7e0,83,13,11,11968,,,0,"Mellanox Changes in deployment serializers

Added Changes to deployment serializers, in case of Mellanox
features usage:
  1. Changing network scheme to use a predefined name for storage interface,
     in case of iSER usage.
  2. Adding physical port to mellanox astute.yaml in case of choosing Mellanox
     components (for attaching virtual functions to virtual machined).

partially implements: blueprint mellanox-features-support

Change-Id: I0d83819a22177028bffbaca7d1f0e1499e8909c5
Signed-off-by: Aviram Bar-Haim <aviramb@mellanox.com>
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/01/104501/8 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/orchestrator/deployment_serializers.py'],1,1ddc9533bae717a9b85101c9984982f4633888b5,mellanox," node_attrs = cls.mellanox_settings(node_attrs, node) return node_attrs @classmethod def mellanox_settings(cls, node_attrs, node): """"""Serialize mellanox node attrs, then it will be merged with common attributes, if mellanox plugin or iSER storage enabled. """""" # Get Mellanox data neutron_mellanox_data = \ node.cluster.attributes.editable\ .get('neutron_mellanox', {}) # Get storage data storage_data = node.cluster.attributes.editable.get('storage',{}) # Get network manager nm = objects.Node.get_network_manager(node) # Init mellanox dict node_attrs['neutron_mellanox'] = {} # Find Physical port for VFs generation if neutron_mellanox_data['plugin']['value'] == 'ethernet': node_attrs['neutron_mellanox']['physical_port'] = \ nm.get_node_network_by_netname(node.id, ""private"")['dev'] # Fix network scheme to have physical port for RDMA if iSER enabled if storage_data[""iser""][""value""]: node_attrs = cls.fix_iser_port(node_attrs, node, nm) return node_attrs @classmethod def fix_iser_port(cls, node_attrs, node, nm): """"""Change the iser port to eth_iser probed (VF on the HV) interface instead of br-storage. that change is made due to RDMA (Remote Direct Memory Access) limitation of working with physical interfaces. """""" # Set a new unique name for iSER virtual port iser_new_name = ""eth_iser0"" # Add iSER extra params to astute.yaml node_attrs['neutron_mellanox']['storage_parent'] = \ nm.get_node_network_by_netname(node.id, ""storage"")['dev'] node_attrs['neutron_mellanox']['iser_interface_name'] = iser_new_name # Set storage rule to iSER port node_attrs['network_scheme']['roles']['storage'] = iser_new_name # Set iSER endpoint with br-storage parameters node_attrs['network_scheme']['endpoints'][iser_new_name] = \ node_attrs['network_scheme']['endpoints'].pop(""br-storage"", None) node_attrs['network_scheme']['interfaces'][iser_new_name] = \ {'L2':{'vlan_splinters':""off""}}",,58,0
openstack%2Fmonasca-agent~master~I433900b95b5e223c359e9cb55565655810139177,openstack/monasca-agent,master,I433900b95b5e223c359e9cb55565655810139177,Initial tox setup and misc pep8 fixes.,MERGED,2014-07-18 00:08:42.000000000,2014-07-18 00:26:58.000000000,2014-07-18 00:26:58.000000000,"[{'_account_id': 3}, {'_account_id': 12108}]","[{'number': 1, 'created': '2014-07-18 00:08:42.000000000', 'files': ['monagent/collector/daemon.py', 'monagent/collector/checks_d/network.py', '.gitignore', 'tests/test_common.py', 'test-requirements.txt', 'monagent/collector/checks_d/gearmand.py', 'monagent/monstatsd/daemon.py', 'monagent/monstatsd/udp.py', 'monagent/collector/checks_d/mongo.py', 'monagent/common/config.py', 'requirements.txt', 'monagent/collector/checks_d/apache.py', 'monagent/collector/checks_d/process.py', 'tests/test_win32_event_log.py', 'monagent/collector/checks_d/kafka_consumer.py', 'monagent/collector/checks_d/elastic.py', 'tests/test_datadog.py', 'monagent/collector/checks_d/wmi_check.py', 'monagent/forwarder/transaction.py', 'monagent/collector/checks_d/zk.py', 'monagent/collector/checks_d/iis.py', 'monagent/collector/checks_d/tcp_check.py', 'monagent/monstatsd/reporter.py', 'monagent/collector/checks_d/rabbitmq.py', 'monagent/collector/checks/system/win32.py', 'monagent/collector/checks_d/directory.py', 'monagent/collector/checks/system/unix.py', 'monagent/collector/checks_d/lighttpd.py', 'tests/test_couchbase.py', 'monagent/collector/checks_d/mysql.py', 'monagent/collector/jmxfetch.py', 'monagent/collector/checks_d/redisdb.py', 'tests/test_cassandra.py', 'monagent/common/aggregator.py', 'monagent/collector/checks/datadog.py', 'tests/test_mongo.py', 'tests/test_redis.py', 'monagent/collector/checks/check.py', 'monagent/collector/checks_d/nagios_wrapper.py', 'monagent/collector/checks_d/docker.py', 'tox.ini', 'monagent/common/check_status.py', 'monagent/win32/gui.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/6b10dcd3506d9218740629190c7d2cff6c5b9824', 'message': 'Initial tox setup and misc pep8 fixes.\n\nChange-Id: I433900b95b5e223c359e9cb55565655810139177\n'}]",0,107862,6b10dcd3506d9218740629190c7d2cff6c5b9824,7,2,1,1976,,,0,"Initial tox setup and misc pep8 fixes.

Change-Id: I433900b95b5e223c359e9cb55565655810139177
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/62/107862/1 && git format-patch -1 --stdout FETCH_HEAD,"['monagent/collector/daemon.py', 'monagent/collector/checks_d/network.py', '.gitignore', 'tests/test_common.py', 'test-requirements.txt', 'monagent/collector/checks_d/gearmand.py', 'monagent/monstatsd/daemon.py', 'monagent/monstatsd/udp.py', 'monagent/collector/checks_d/mongo.py', 'monagent/common/config.py', 'requirements.txt', 'monagent/collector/checks_d/apache.py', 'monagent/collector/checks_d/process.py', 'tests/test_win32_event_log.py', 'monagent/collector/checks_d/kafka_consumer.py', 'monagent/collector/checks_d/elastic.py', 'tests/test_datadog.py', 'monagent/collector/checks_d/wmi_check.py', 'monagent/forwarder/transaction.py', 'monagent/collector/checks_d/zk.py', 'monagent/collector/checks_d/iis.py', 'monagent/collector/checks_d/tcp_check.py', 'monagent/monstatsd/reporter.py', 'monagent/collector/checks_d/rabbitmq.py', 'monagent/collector/checks/system/win32.py', 'monagent/collector/checks_d/directory.py', 'monagent/collector/checks/system/unix.py', 'monagent/collector/checks_d/lighttpd.py', 'tests/test_couchbase.py', 'monagent/collector/checks_d/mysql.py', 'monagent/collector/jmxfetch.py', 'monagent/collector/checks_d/redisdb.py', 'tests/test_cassandra.py', 'monagent/common/aggregator.py', 'monagent/collector/checks/datadog.py', 'tests/test_mongo.py', 'tests/test_redis.py', 'monagent/collector/checks/check.py', 'monagent/collector/checks_d/nagios_wrapper.py', 'monagent/collector/checks_d/docker.py', 'tox.ini', 'monagent/common/check_status.py', 'monagent/win32/gui.py']",43,6b10dcd3506d9218740629190c7d2cff6c5b9824,tox2," api_key, ok = QInputDialog.getText( None, ""Add your API KEY"", ""You must first set your api key in this file. You can find it here: https://app.datadoghq.com/account/settings#api"") self.connect( self.properties.menu_button, SIGNAL(""clicked()""), lambda: self.manager_menu.popup( self.properties.menu_button.mapToGlobal( QPoint( 0, 0))))"," api_key, ok = QInputDialog.getText(None, ""Add your API KEY"", ""You must first set your api key in this file. You can find it here: https://app.datadoghq.com/account/settings#api"") self.connect(self.properties.menu_button, SIGNAL(""clicked()""), lambda: self.manager_menu.popup(self.properties.menu_button.mapToGlobal(QPoint(0, 0))))",440,233
openstack%2Fmonasca-agent~master~Id49572b93e341e2558763583a43e081ed2c1b657,openstack/monasca-agent,master,Id49572b93e341e2558763583a43e081ed2c1b657,Added git review support,ABANDONED,2014-07-17 18:33:55.000000000,2014-07-18 00:24:11.000000000,,"[{'_account_id': 3}, {'_account_id': 12108}]","[{'number': 1, 'created': '2014-07-17 18:33:55.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/fff85ba17c80e03c1417d73fb3371638b972ba9d', 'message': 'Added git review support\n\nChange-Id: Id49572b93e341e2558763583a43e081ed2c1b657\n'}]",0,107792,fff85ba17c80e03c1417d73fb3371638b972ba9d,5,2,1,1976,,,0,"Added git review support

Change-Id: Id49572b93e341e2558763583a43e081ed2c1b657
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/92/107792/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,fff85ba17c80e03c1417d73fb3371638b972ba9d,tox,[gerrit] host=review.openstack.org port=29418 project=stackforge/monasca-agent.git,,4,0
openstack%2Fsecurity-doc~master~Ib20a4cff1b13fbeeffbc0b4866e514e4bf9e479e,openstack/security-doc,master,Ib20a4cff1b13fbeeffbc0b4866e514e4bf9e479e,Fix Networking title,MERGED,2014-07-15 19:17:47.000000000,2014-07-18 00:20:01.000000000,2014-07-18 00:20:00.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 2807}, {'_account_id': 6547}, {'_account_id': 7063}, {'_account_id': 9098}]","[{'number': 1, 'created': '2014-07-15 19:17:47.000000000', 'files': ['security-guide/ch_introduction-to-openstack.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/6f8d0dd379197ce64f1025dabf62d3bd54ffe4f5', 'message': 'Fix Networking title\n\nAll other sections do not include ""OpenStack"", let\'s remove it from\nNetworking as well.\n\nChange-Id: Ib20a4cff1b13fbeeffbc0b4866e514e4bf9e479e\nCloses-Bug: #1341851\n'}]",0,107159,6f8d0dd379197ce64f1025dabf62d3bd54ffe4f5,13,7,1,6547,,,0,"Fix Networking title

All other sections do not include ""OpenStack"", let's remove it from
Networking as well.

Change-Id: Ib20a4cff1b13fbeeffbc0b4866e514e4bf9e479e
Closes-Bug: #1341851
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/59/107159/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_introduction-to-openstack.xml'],1,6f8d0dd379197ce64f1025dabf62d3bd54ffe4f5,bug/1341851, <title>Networking</title>, <title>OpenStack Networking</title>,1,1
openstack%2Fmonasca-agent~master~I0d830f54ec18a5e1af20ffb8a7ad14caa9c6b0ce,openstack/monasca-agent,master,I0d830f54ec18a5e1af20ffb8a7ad14caa9c6b0ce,Add initial tox support,ABANDONED,2014-07-17 18:54:25.000000000,2014-07-18 00:11:01.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-17 18:54:25.000000000', 'files': ['requirements.txt', '.gitignore', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/f3716489fbc07c23e2b49f5ec40010cc296a7e5a', 'message': 'Add initial tox support\n\nChange-Id: I0d830f54ec18a5e1af20ffb8a7ad14caa9c6b0ce\n'}]",0,107796,f3716489fbc07c23e2b49f5ec40010cc296a7e5a,4,1,1,1976,,,0,"Add initial tox support

Change-Id: I0d830f54ec18a5e1af20ffb8a7ad14caa9c6b0ce
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/96/107796/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', '.gitignore', 'test-requirements.txt', 'tox.ini']",4,f3716489fbc07c23e2b49f5ec40010cc296a7e5a,tox,[tox] envlist = py27 minversion = 1.6 skipsdist = True [testenv:venv] commands = {posargs},,23,0
openstack%2Fmonasca-agent~master~I6e45851ee31faa72688c9929c6be8768a025624d,openstack/monasca-agent,master,I6e45851ee31faa72688c9929c6be8768a025624d,Added initial tox support. Fixed various pep8 violations.,ABANDONED,2014-07-17 21:55:58.000000000,2014-07-17 23:53:02.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-17 21:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/c70f07efd699f02a2e3b1197d0abebf72b980c47', 'message': 'Added initial tox support. Fixed various pep8 violations.\n\nChange-Id: I6e45851ee31faa72688c9929c6be8768a025624d\n'}, {'number': 2, 'created': '2014-07-17 22:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/352b5d2fae4c579829dd1773b2278e7c063ebe04', 'message': 'Added initial tox support. Fixed various pep8 violations.\n\nChange-Id: I6e45851ee31faa72688c9929c6be8768a025624d\n'}, {'number': 3, 'created': '2014-07-17 22:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/31c4e188ebfd2438fad7f82413ec0611a6999fcc', 'message': 'Added initial tox support. Fixed various pep8 violations.\n\nChange-Id: I6e45851ee31faa72688c9929c6be8768a025624d\n'}, {'number': 4, 'created': '2014-07-17 22:30:50.000000000', 'files': ['monagent/collector/daemon.py', 'tests/test_common.py', 'test-requirements.txt', 'monagent/collector/checks_d/gunicorn.py', 'monagent/collector/checks/services_checks.py', 'monagent/monstatsd/udp.py', 'tests/common.py', 'tests/test_solr.py', 'monagent/collector/checks_d/apache.py', 'monagent/collector/checks_d/haproxy.py', 'monagent/collector/checks_d/kafka_consumer.py', 'monagent/collector/checks_d/wmi_check.py', 'monagent/forwarder/transaction.py', 'monagent/common/keystone.py', 'tests/test_monstatsd.py', 'tests/test_elastic.py', 'monagent/collector/checks/system/win32.py', 'monagent/collector/checks/collector.py', 'monagent/collector/checks_d/jenkins.py', 'monagent/collector/checks_d/lighttpd.py', 'tests/test_couchbase.py', 'tests/test_cassandra.py', 'tests/test_gearman.py', 'monagent/collector/checks/datadog.py', 'monagent/collector/checks/check.py', 'monagent/collector/checks_d/nagios_wrapper.py', 'monagent/collector/checks_d/docker.py', 'tests/test_config.py', 'tox.ini', 'monagent/common/daemon.py', 'monagent/collector/checks_d/network.py', '.gitignore', 'monagent/collector/checks_d/gearmand.py', 'monagent/monstatsd/daemon.py', 'monagent/collector/dogstream/cassandra.py', 'monagent/collector/checks_d/http_check.py', 'monagent/collector/checks_d/host_alive.py', 'monagent/forwarder/daemon.py', 'monagent/collector/checks_d/mongo.py', 'monagent/common/config.py', 'monagent/forwarder/api/mon.py', 'requirements.txt', 'tests/test_tomcat.py', 'monagent/collector/checks_d/process.py', 'tests/test_java_jmx.py', 'monagent/common/util.py', 'tests/test_win32_event_log.py', 'tests/test_cassandra_jmx.py', 'monagent/collector/checks_d/elastic.py', 'tests/test_datadog.py', 'monagent/collector/checks_d/zk.py', 'monagent/collector/checks_d/iis.py', 'monagent/collector/checks_d/tcp_check.py', 'tests/test_system.py', 'monagent/monstatsd/reporter.py', 'monagent/collector/checks_d/rabbitmq.py', 'monagent/collector/checks_d/directory.py', 'tests/test_couch.py', 'tests/test_laconic.py', 'monagent/collector/checks/system/unix.py', 'monagent/collector/checks_d/mcache.py', 'monagent/collector/checks_d/couchbase.py', 'monagent/collector/checks_d/mysql.py', 'monagent/collector/jmxfetch.py', 'monagent/collector/checks_d/redisdb.py', 'monagent/common/aggregator.py', 'tests/test_haproxy.py', 'tests/test_mongo.py', 'tests/test_redis.py', 'monagent/common/check_status.py', 'monagent/win32/gui.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/af1cc787c3390c90ccbc65d5f33da97ca9efeb9e', 'message': 'Added initial tox support. Fixed various pep8 violations.\n\nChange-Id: I6e45851ee31faa72688c9929c6be8768a025624d\n'}]",0,107840,af1cc787c3390c90ccbc65d5f33da97ca9efeb9e,13,1,4,1976,,,0,"Added initial tox support. Fixed various pep8 violations.

Change-Id: I6e45851ee31faa72688c9929c6be8768a025624d
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/40/107840/1 && git format-patch -1 --stdout FETCH_HEAD,"['monagent/collector/daemon.py', 'tests/test_common.py', 'test-requirements.txt', 'monagent/collector/checks_d/gunicorn.py', 'monagent/collector/checks/services_checks.py', 'monagent/monstatsd/udp.py', 'tests/common.py', 'tests/test_solr.py', 'monagent/collector/checks_d/apache.py', 'monagent/collector/checks_d/haproxy.py', 'monagent/collector/checks_d/kafka_consumer.py', 'monagent/collector/checks_d/wmi_check.py', 'monagent/forwarder/transaction.py', 'monagent/common/keystone.py', 'tests/test_monstatsd.py', 'tests/test_elastic.py', 'monagent/collector/checks/system/win32.py', 'monagent/collector/checks/collector.py', 'monagent/collector/checks_d/jenkins.py', 'monagent/collector/checks_d/lighttpd.py', 'tests/test_couchbase.py', 'tests/test_cassandra.py', 'tests/test_gearman.py', 'monagent/collector/checks/datadog.py', 'monagent/collector/checks/check.py', 'monagent/collector/checks_d/nagios_wrapper.py', 'monagent/collector/checks_d/docker.py', 'tests/test_config.py', 'tox.ini', 'monagent/common/daemon.py', 'monagent/collector/checks_d/network.py', '.gitignore', 'monagent/collector/checks_d/gearmand.py', 'monagent/monstatsd/daemon.py', 'monagent/collector/dogstream/cassandra.py', 'monagent/collector/checks_d/http_check.py', 'monagent/collector/checks_d/host_alive.py', 'monagent/forwarder/daemon.py', 'monagent/collector/checks_d/mongo.py', 'monagent/common/config.py', 'monagent/forwarder/api/mon.py', 'requirements.txt', 'tests/test_tomcat.py', 'monagent/collector/checks_d/process.py', 'tests/test_java_jmx.py', 'monagent/common/util.py', 'tests/test_win32_event_log.py', 'tests/test_cassandra_jmx.py', 'monagent/collector/checks_d/elastic.py', 'tests/test_datadog.py', 'monagent/collector/checks_d/zk.py', 'monagent/collector/checks_d/iis.py', 'monagent/collector/checks_d/tcp_check.py', 'tests/test_system.py', 'monagent/monstatsd/reporter.py', 'monagent/collector/checks_d/rabbitmq.py', 'monagent/collector/checks_d/directory.py', 'tests/test_couch.py', 'tests/test_laconic.py', 'monagent/collector/checks/system/unix.py', 'monagent/collector/checks_d/mcache.py', 'monagent/collector/checks_d/couchbase.py', 'monagent/collector/checks_d/mysql.py', 'monagent/collector/jmxfetch.py', 'monagent/collector/checks_d/redisdb.py', 'monagent/common/aggregator.py', 'tests/test_haproxy.py', 'tests/test_mongo.py', 'tests/test_redis.py', 'monagent/common/check_status.py', 'monagent/win32/gui.py']",71,c70f07efd699f02a2e3b1197d0abebf72b980c47,tox," api_key, ok = QInputDialog.getText( None, ""Add your API KEY"", ""You must first set your api key in this file. You can find it here: https://app.datadoghq.com/account/settings#api"") self.connect( self.sysTray, SIGNAL(""activated(QSystemTrayIcon::ActivationReason)""), self.__icon_activated) get_config_path(), description=""Agent settings file: datadog.conf"") self.connect( self.properties.menu_button, SIGNAL(""clicked()""), lambda: self.manager_menu.popup( self.properties.menu_button.mapToGlobal( QPoint( 0, 0))))"," api_key, ok = QInputDialog.getText(None, ""Add your API KEY"", ""You must first set your api key in this file. You can find it here: https://app.datadoghq.com/account/settings#api"") self.connect(self.sysTray, SIGNAL( ""activated(QSystemTrayIcon::ActivationReason)""), self.__icon_activated) get_config_path(), description=""Agent settings file: datadog.conf"") self.connect(self.properties.menu_button, SIGNAL(""clicked()""), lambda: self.manager_menu.popup(self.properties.menu_button.mapToGlobal(QPoint(0, 0))))",1058,533
openstack%2Ftempest~master~Icdd8c3a2e6c9d3264afc141ad516ee06c6127336,openstack/tempest,master,Icdd8c3a2e6c9d3264afc141ad516ee06c6127336,Exclude volume tags while listing instance tags,MERGED,2014-04-07 11:55:15.000000000,2014-07-17 23:39:16.000000000,2014-07-17 23:39:15.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5538}, {'_account_id': 5803}, {'_account_id': 10385}, {'_account_id': 11224}]","[{'number': 1, 'created': '2014-04-07 11:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2193ed715aa9f1c77ca2122415fc6356d1c9d883', 'message': ""Exclude volume tags while listing instance tags.\n\nWhen a volume is attached to an instance and then detached, a metadata\ngets associated with the volume: 'readonly' = 'False', even if the volume\ndidn't have this entry before. The patch\nhttps://review.openstack.org/#/c/70085/ against Nova adds support for\nvolume tags, and as a result, it breaks a test case where we are\nasserting that no tags are left after deletion of them.\n\nSo this patch makes sure that we assert only for 'instance' tags, and\nnot volume tags.\n\nChange-Id: Icdd8c3a2e6c9d3264afc141ad516ee06c6127336\n""}, {'number': 2, 'created': '2014-04-07 13:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/03cb8a3700d2d1c8a7b23cf7f0afe27c0cbf6e7b', 'message': ""Exclude volume tags while listing instance tags\n\nWhen a volume is attached to an instance and then detached, a metadata\ngets associated with the volume: 'readonly' = 'False', even if the volume\ndidn't have this entry before. The patch\nhttps://review.openstack.org/#/c/70085/ against Nova adds support for\nvolume tags, and as a result, it breaks a test case where we are\nasserting that no tags are left after deletion of them.\n\nSo this patch makes sure that we assert only for 'instance' tags, and\nnot volume tags.\n\nChange-Id: Icdd8c3a2e6c9d3264afc141ad516ee06c6127336\n""}, {'number': 3, 'created': '2014-07-07 12:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c971c04e43516a5cc0f368ec8c347c9999d0ec19', 'message': ""Exclude volume tags while listing instance tags\n\nWhen a volume is attached to an instance and then detached, a metadata\ngets associated with the volume: 'readonly' = 'False', even if the volume\ndidn't have this entry before. The patch\nhttps://review.openstack.org/#/c/70085/ against Nova adds support for\nvolume tags, and as a result, it breaks a test case where we are\nasserting that no tags are left after deletion of them.\nSo this patch makes sure that we assert only for 'instance' tags, and\nnot volume tags.\n\nChange-Id: Icdd8c3a2e6c9d3264afc141ad516ee06c6127336\n""}, {'number': 4, 'created': '2014-07-07 12:34:14.000000000', 'files': ['tempest/thirdparty/boto/test_ec2_instance_run.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d0bea62e9efdb7b6cc7b6bac7f6bd0b314fc6204', 'message': ""Exclude volume tags while listing instance tags\n\nWhen a volume is attached to an instance and then detached, a metadata\ngets associated with the volume: 'readonly' = 'False', even if the volume\ndidn't have this entry before. The patch\nhttps://review.openstack.org/#/c/70085/ against Nova adds support for\nvolume tags, and as a result, it breaks a test case where we are\nasserting that no tags are left after deletion of them.\nSo this patch makes sure that we assert only for 'instance' tags, and\nnot volume tags.\n\nChange-Id: Icdd8c3a2e6c9d3264afc141ad516ee06c6127336\n""}]",2,85695,d0bea62e9efdb7b6cc7b6bac7f6bd0b314fc6204,29,7,4,5538,,,0,"Exclude volume tags while listing instance tags

When a volume is attached to an instance and then detached, a metadata
gets associated with the volume: 'readonly' = 'False', even if the volume
didn't have this entry before. The patch
https://review.openstack.org/#/c/70085/ against Nova adds support for
volume tags, and as a result, it breaks a test case where we are
asserting that no tags are left after deletion of them.
So this patch makes sure that we assert only for 'instance' tags, and
not volume tags.

Change-Id: Icdd8c3a2e6c9d3264afc141ad516ee06c6127336
",git fetch https://review.opendev.org/openstack/tempest refs/changes/95/85695/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/thirdparty/boto/test_ec2_instance_run.py'],1,2193ed715aa9f1c77ca2122415fc6356d1c9d883,fix_extra_tag, # NOTE: Volume-attach and detach causes metadata (tags) to be created # for the volume. So exclude them while asserting. tags = [tag for tag in tags if tag.res_type == 'instance'],,4,0
openstack%2Fnova~master~I31117eecba4f060cb9c7fc3d329f70fd369b168d,openstack/nova,master,I31117eecba4f060cb9c7fc3d329f70fd369b168d,Make BDM dict __init__ behave more like a dict,MERGED,2014-06-09 13:07:52.000000000,2014-07-17 23:39:05.000000000,2014-07-17 23:39:02.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10692}, {'_account_id': 11650}]","[{'number': 1, 'created': '2014-06-09 13:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca5a00c72466b96abd528941c271d348a3d55c51', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 2, 'created': '2014-06-11 16:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3957cc2c910e60e122330b6db45bc6809d30bcb', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 3, 'created': '2014-06-12 07:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd2ac2dd903b24684d85b64ac7672cb9d9888ce2', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 4, 'created': '2014-06-13 07:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f502084676cf542d2c4cec80c07d197bce08c22', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 5, 'created': '2014-06-13 15:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4a696f6b26ee054c357ac9e12f85e46a6191ae6', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 6, 'created': '2014-06-16 10:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0be3a0306165621d6cdb00aaf2df403270268014', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 7, 'created': '2014-06-17 10:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3229d6c4a31f98f8e21b80a64876ca55baa4f1e', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 8, 'created': '2014-06-17 11:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ff2476b5e41035cec652e858b9af3fab30d8eb7', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 9, 'created': '2014-07-02 13:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32ac32acbc003e6581591cfc0fefafc9364bd4f5', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 10, 'created': '2014-07-03 07:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15d6642f9d7c8c9b74482ac19dc37eb860e49698', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 11, 'created': '2014-07-04 16:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/abf02c47feca97cd1bc839219c70132837d148b3', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}, {'number': 12, 'created': '2014-07-17 09:11:21.000000000', 'files': ['nova/tests/test_block_device.py', 'nova/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/74c46be2f44c3d84f229a849a89c725a08a4a7fd', 'message': ""Make BDM dict __init__ behave more like a dict\n\nCurrently we can't pass values as kwargs to BlockDeviceDict classes.\nThis is a common way to call a dict constructor so it breaks the dict\nabstraction a bit.\n\nThis patch fixes it in a backward compatible way.\n\nChange-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d\n""}]",2,98780,74c46be2f44c3d84f229a849a89c725a08a4a7fd,107,15,12,5511,,,0,"Make BDM dict __init__ behave more like a dict

Currently we can't pass values as kwargs to BlockDeviceDict classes.
This is a common way to call a dict constructor so it breaks the dict
abstraction a bit.

This patch fixes it in a backward compatible way.

Change-Id: I31117eecba4f060cb9c7fc3d329f70fd369b168d
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/98780/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_block_device.py', 'nova/block_device.py']",2,ca5a00c72466b96abd528941c271d348a3d55c51,bp/compute-manager-objects-juno," def __init__(self, bdm_dict=None, do_not_default=None, **kwargs): bdm_dict = bdm_dict or kwargs"," def __init__(self, bdm_dict=None, do_not_default=None): bdm_dict = bdm_dict or {}",7,2
openstack%2Fheat~master~Ie4a616d6a2b056fe59877e2bec325f02b6d7a693,openstack/heat,master,Ie4a616d6a2b056fe59877e2bec325f02b6d7a693,Implement keystone client plugin,MERGED,2014-06-04 23:24:46.000000000,2014-07-17 23:38:50.000000000,2014-07-17 23:38:49.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-04 23:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/922a86ac9c3a7deec6af8dfd5d56d8db29fd1611', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\n\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\n\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\n\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 2, 'created': '2014-06-09 04:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/402ced89a5eb19ed330b113924ea20ccff38c987', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 3, 'created': '2014-06-09 22:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3aaa7a3f65f6e75c1d50d4e91a93a668f6b91ce4', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 4, 'created': '2014-06-10 02:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e356c9e607a113ec175fcaa4b111b06bdc538c11', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 5, 'created': '2014-06-10 05:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6f33fe119f9481606b4e7012e00f3ed8cf3b72ae', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 6, 'created': '2014-06-16 00:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c7c3c869b11073e15b7f69a60c9377b7cea53195', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 7, 'created': '2014-06-16 05:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0f07c39f13d2f363b371d72e9f0562ab54745033', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 8, 'created': '2014-06-17 05:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/97aeedff3a2b1713ca44a9f9bd17e09fba093017', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 9, 'created': '2014-06-17 23:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3ca7c58ff4e09cf47c654649e376697b1a3b5c98', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 10, 'created': '2014-06-18 00:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/678130e040f22a4ab0d3d8d80d8fbeb6bccc5a93', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 11, 'created': '2014-06-20 03:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/76cc5a4138e50450292eb7403a2f6f3c9b676e53', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 12, 'created': '2014-06-23 00:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d0a3696b2a56eb5a36ee128e0a9f116e3d9fe045', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 13, 'created': '2014-06-23 22:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a2e36992b779c93bc1fd003bac12e44a5ea619f9', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 14, 'created': '2014-06-26 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/54cf21c7e300207e3b6c3f4a41b95fab73c07f34', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 15, 'created': '2014-06-27 06:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d21a57ce7a9b550b77ca8f4b9f66a7d916eb961f', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 16, 'created': '2014-06-30 02:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d9454774a3615b9db5a0fcb57bf40bc8a442c2e8', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 17, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/569b71e153a6a03ac465f315743caf32b98e600a', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 18, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/01b250c83e619d8dcc30f3240c67fcf59de8ccaf', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\n\nThe barbican TestClient has been removed; it had limited practical\nvalue since it mocked all of the internal calls of the method it was\ntesting.\n\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 19, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bdd1e4f9efcee6d10b48025acc0e3a5e19511677', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\n\nThe barbican TestClient has been removed; it had limited practical\nvalue since it mocked all of the internal calls of the method it was\ntesting.\n\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 20, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f690da871bafe859917d25103c9b5fa09fe8a53d', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\n\nThe barbican TestClient has been removed; it had limited practical\nvalue since it mocked all of the internal calls of the method it was\ntesting.\n\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 21, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0073bd99c5c4bf0b3f0415ac7c609df612cc5e3d', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\n\nThe barbican TestClient has been removed; it had limited practical\nvalue since it mocked all of the internal calls of the method it was\ntesting.\n\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 22, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d48df3aed7136ec1d881ee63ccf43e52c629e9db', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\n\nThe barbican TestClient has been removed; it had limited practical\nvalue since it mocked all of the internal calls of the method it was\ntesting.\n\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 23, 'created': '2014-07-08 21:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0cced9b07717bfd0f1eace5f61340597ad8359a3', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\n\nThe barbican TestClient has been removed; it had limited practical\nvalue since it mocked all of the internal calls of the method it was\ntesting.\n\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}, {'number': 24, 'created': '2014-07-17 02:00:28.000000000', 'files': ['heat/tests/common.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_signal.py', 'heat/engine/clients/os/keystone.py', 'contrib/barbican/barbican/tests/test_clients.py', 'heat/tests/test_parser.py', 'setup.cfg', 'heat/engine/clients/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/bd4317e7b9760b55c70477472fc3f1c0997dc036', 'message': ""Implement keystone client plugin\n\nThis moves the client creation code out of Clients._keystone() into\nits own client plugin.\nThis is the last client to convert to a plugin, so supporting code\nto fetch a client from a non-plugin has been removed.\nIn a later change it would be worth considering moving methods\nin heat_keystoneclient.KeystoneClient into KeystoneClientPlugin\nso that calling Clients.client('keystone') returns the actual keystone\nclient rather than a wrapper.\n\nThe barbican TestClient has been removed; it had limited practical\nvalue since it mocked all of the internal calls of the method it was\ntesting.\n\nChange-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693\n""}]",2,97985,bd4317e7b9760b55c70477472fc3f1c0997dc036,116,17,24,4571,,,0,"Implement keystone client plugin

This moves the client creation code out of Clients._keystone() into
its own client plugin.
This is the last client to convert to a plugin, so supporting code
to fetch a client from a non-plugin has been removed.
In a later change it would be worth considering moving methods
in heat_keystoneclient.KeystoneClient into KeystoneClientPlugin
so that calling Clients.client('keystone') returns the actual keystone
client rather than a wrapper.

The barbican TestClient has been removed; it had limited practical
value since it mocked all of the internal calls of the method it was
testing.

Change-Id: Ie4a616d6a2b056fe59877e2bec325f02b6d7a693
",git fetch https://review.opendev.org/openstack/heat refs/changes/85/97985/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_vpc.py', 'heat/engine/clients/keystone.py', 'heat/tests/test_s3.py', 'heat/tests/test_signal.py', 'heat/tests/test_eip.py', 'heat/tests/test_parser.py', 'heat/tests/test_swift.py', 'heat/tests/test_neutron_autoscaling.py', 'heat/tests/test_heat_autoscaling_group.py', 'contrib/extraroute/extraroute/tests/test_extraroute.py', 'heat/tests/test_security_group.py', 'heat/tests/test_neutron_security_group.py', 'heat/tests/test_clients.py', 'heat/tests/test_neutron_firewall.py', 'heat/tests/test_neutron_loadbalancer.py', 'heat/tests/test_nova_floatingip.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_neutron_network_gateway.py', 'heat/tests/test_neutron.py', 'heat/tests/test_neutron_vpnservice.py', 'heat/tests/test_neutron_metering.py', 'heat/engine/clients/__init__.py']",22,922a86ac9c3a7deec6af8dfd5d56d8db29fd1611,bp/client-plugins,,"from heat.common import heat_keystoneclient as hkc self._clients = {} if name in self._clients: return self._clients[name] # call the local method _<name>() if a real client plugin # doesn't exist method_name = '_%s' % name if callable(getattr(self, method_name, None)): client = getattr(self, method_name)() self._clients[name] = client return client @property def auth_token(self): # if there is no auth token in the context # attempt to get one using the context username and password return self.context.auth_token or self.keystone().auth_token def _keystone(self): return hkc.KeystoneClient(self.context) def url_for(self, **kwargs): return self.keystone().url_for(**kwargs) ",201,197
openstack%2Fsecurity-doc~master~Ica262313576194c2ef811843aff99a76c659bc1e,openstack/security-doc,master,Ica262313576194c2ef811843aff99a76c659bc1e,Combining sentences and clarifying risk,ABANDONED,2014-07-17 22:03:53.000000000,2014-07-17 23:32:34.000000000,,"[{'_account_id': 3}, {'_account_id': 2807}]","[{'number': 1, 'created': '2014-07-17 22:03:53.000000000', 'files': ['security-guide/ch_hardening-the-virtualization-layers.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/b72c330da6bc0feef13298df5f00a7811d65be20', 'message': 'Combining sentences and clarifying risk\n\nCombined two sentences into one while more specifically addressing risk associated with this type of breach\n\nChange-Id: Ica262313576194c2ef811843aff99a76c659bc1e\nCloses-Bug: #1342331\n'}]",0,107842,b72c330da6bc0feef13298df5f00a7811d65be20,5,2,1,12325,,,0,"Combining sentences and clarifying risk

Combined two sentences into one while more specifically addressing risk associated with this type of breach

Change-Id: Ica262313576194c2ef811843aff99a76c659bc1e
Closes-Bug: #1342331
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/42/107842/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_hardening-the-virtualization-layers.xml'],1,b72c330da6bc0feef13298df5f00a7811d65be20,1342331," security domain. This is a significant breach as it is harder to reset the state of physical hardware than virtual hardware, and can lead to additional exposure such as access to the management network.</para>", security domain. This is a potential problem in any hardware sharing scenario. The problem is specific to this scenario because it is harder to reset the state of physical hardware than virtual hardware.</para>,4,4
openstack%2Fneutron~master~I550bcc2b245a85167d48cda03f7d8155fdea0213,openstack/neutron,master,I550bcc2b245a85167d48cda03f7d8155fdea0213,Flavor Framework implementation,ABANDONED,2014-07-17 11:57:57.000000000,2014-07-17 23:30:36.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 9885}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-17 11:57:57.000000000', 'files': ['neutron/db/migration/models/head.py', 'neutron/api/v2/base.py', 'neutron/tests/unit/test_flavors.py', 'neutron/plugins/common/constants.py', 'neutron/db/migration/alembic_migrations/versions/31337ec0ffee_flavors.py', 'neutron/manager.py', 'neutron/extensions/flavors.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/db/flavors_db.py', 'neutron/tests/unit/test_neutron_manager.py', 'etc/policy.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/df2fbc8bde8a49b5a0638f338bbdfd7f8d88fbe2', 'message': 'Flavor Framework implementation\n\nThis patch introduces API and DB plugin for flavor framework.\nAPI adds Flavors and Service Profiles which are resources\navailable only for admins to operate.\n\nThis framework then should be leveraged by advanced services\n\nImplements blueprint neutron-flavor-framework\nChange-Id: I550bcc2b245a85167d48cda03f7d8155fdea0213\n'}]",0,107661,df2fbc8bde8a49b5a0638f338bbdfd7f8d88fbe2,15,13,1,6072,,,0,"Flavor Framework implementation

This patch introduces API and DB plugin for flavor framework.
API adds Flavors and Service Profiles which are resources
available only for admins to operate.

This framework then should be leveraged by advanced services

Implements blueprint neutron-flavor-framework
Change-Id: I550bcc2b245a85167d48cda03f7d8155fdea0213
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/107661/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/models/head.py', 'neutron/api/v2/base.py', 'neutron/tests/unit/test_flavors.py', 'neutron/plugins/common/constants.py', 'neutron/db/migration/alembic_migrations/versions/31337ec0ffee_flavors.py', 'neutron/manager.py', 'neutron/extensions/flavors.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/db/flavors_db.py', 'neutron/tests/unit/test_neutron_manager.py', 'etc/policy.json']",11,df2fbc8bde8a49b5a0638f338bbdfd7f8d88fbe2,bp/neutron-flavor-framework," ""create_lsn"": ""rule:admin_only"", ""create_flavor"": ""rule:admin_only"", ""update_flavor"": ""rule:admin_only"", ""delete_flavor"": ""rule:admin_only"", ""get_flavors"": ""rule:regular_user"", ""get_flavor"": ""rule:regular_user"", ""create_service_profile"": ""rule:admin_only"", ""update_service_profile"": ""rule:admin_only"", ""delete_service_profile"": ""rule:admin_only"", ""get_service_profiles"": ""rule:admin_only"", ""get_service_profile"": ""rule:admin_only"""," ""create_lsn"": ""rule:admin_only""",1016,9
openstack%2Fmonasca-api~master~Ieafd28d3e41486f7c3dfd08fe4272272e1ee02ca,openstack/monasca-api,master,Ieafd28d3e41486f7c3dfd08fe4272272e1ee02ca,Change docker-version.,MERGED,2014-07-17 23:15:12.000000000,2014-07-17 23:19:52.000000000,2014-07-17 23:19:52.000000000,"[{'_account_id': 3}, {'_account_id': 2419}]","[{'number': 1, 'created': '2014-07-17 23:15:12.000000000', 'files': ['pom.xml'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/5d7fc4beb8715478f5c5472b96377852e51be095', 'message': 'Change docker-version.\n\nDowngrade docker-java version so that it is available in maven central.\n\nChange-Id: Ieafd28d3e41486f7c3dfd08fe4272272e1ee02ca\n'}]",0,107852,5d7fc4beb8715478f5c5472b96377852e51be095,7,2,1,12511,,,0,"Change docker-version.

Downgrade docker-java version so that it is available in maven central.

Change-Id: Ieafd28d3e41486f7c3dfd08fe4272272e1ee02ca
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/52/107852/1 && git format-patch -1 --stdout FETCH_HEAD,['pom.xml'],1,5d7fc4beb8715478f5c5472b96377852e51be095,enhancement/change-docker-java-version-for-maven-central, <version>0.9.0</version>, <version>0.9.1-SNAPSHOT</version>,1,1
openstack%2Ftraining-guides~master~Iff3235e059d43d1f9fb3925f4f669b6361c38f97,openstack/training-guides,master,Iff3235e059d43d1f9fb3925f4f669b6361c38f97,Imported Translations from Transifex,MERGED,2014-07-17 06:00:12.000000000,2014-07-17 23:17:32.000000000,2014-07-17 23:17:31.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 7007}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-07-17 06:00:12.000000000', 'files': ['doc/training-guides/locale/training-guides.pot'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/2d4f857ab1682f0932cbf52672037b13aa34ffef', 'message': 'Imported Translations from Transifex\n\nChange-Id: Iff3235e059d43d1f9fb3925f4f669b6361c38f97\n'}]",0,107563,2d4f857ab1682f0932cbf52672037b13aa34ffef,9,4,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Iff3235e059d43d1f9fb3925f4f669b6361c38f97
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/63/107563/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/locale/training-guides.pot'],1,2d4f857ab1682f0932cbf52672037b13aa34ffef,transifex/translations,"""POT-Creation-Date: 2014-07-17 06:00+0000\n""#: ./doc/training-guides/under-contruction-notice.xml:77(para) ./doc/training-guides/bk000-preface.xml:79(para)#: ./doc/training-guides/under-contruction-notice.xml:86(para) ./doc/training-guides/bk000-preface.xml:88(para)#: ./doc/training-guides/under-contruction-notice.xml:90(para) ./doc/training-guides/bk000-preface.xml:92(para)#: ./doc/training-guides/under-contruction-notice.xml:94(para) ./doc/training-guides/bk000-preface.xml:96(para)#: ./doc/training-guides/under-contruction-notice.xml:99(para) ./doc/training-guides/bk000-preface.xml:101(para)#: ./doc/training-guides/under-contruction-notice.xml:103(para) ./doc/training-guides/bk000-preface.xml:105(para)#: ./doc/training-guides/under-contruction-notice.xml:107(para) ./doc/training-guides/bk000-preface.xml:109(para)#: ./doc/training-guides/under-contruction-notice.xml:111(para)#: ./doc/training-guides/under-contruction-notice.xml:118(link) ./doc/training-guides/bk000-preface.xml:119(link)#: ./doc/training-guides/user-story-includes-template.xml:22(para) ./doc/training-guides/bk000-preface.xml:129(para) ./doc/training-guides/bk000-preface.xml:136(para) ./doc/training-guides/bk000-preface.xml:143(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:31(para) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:32(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:31(para) ./doc/training-guides/operator-guide/bk002-ch011-operator-network-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:35(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:42(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:49(para) ./doc/training-guides/operator-guide/bk002-ch005-operator-controller-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:22(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:29(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:36(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:43(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:25(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:32(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:39(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:46(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:53(para) ./doc/training-guides/operator-guide/bk002-ch008-operator-compute-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:22(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:29(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:36(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:31(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:47(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:54(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:61(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:68(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:75(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:33(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:27(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:34(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:41(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:48(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:55(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:33(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:31(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:47(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:54(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:61(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:68(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:75(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:82(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:25(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:32(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:39(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:46(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:53(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:15(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:22(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:29(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:36(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:43(para)#: ./doc/training-guides/bk000-preface.xml:129(None) ./doc/training-guides/bk000-preface.xml:136(None) ./doc/training-guides/bk000-preface.xml:143(None)msgid ""<emphasis role=\""bold\"">Pick a Bug:</emphasis> Once you have your tools ready to go, you can assign some work to yourself. Go to the <link href=\""https://bugs.launchpad.net/openstack-training-guides\"">Bugs</link> and assign a bug from the list to yourself.""#: ./doc/training-guides/bk000-preface.xml:69(para) msgid ""<emphasis role=\""bold\"">Create the Content:</emphasis> Each bug from the list will be a separate chunk of content that you will add to the openstack-manuals repository openstack-training sub-project. <link href=\""operator-getting-started-lab.html#operator-add-training-content\""> More details on creating training content here.</link>""#: ./doc/training-guides/bk000-preface.xml:115(link) msgid ""Training Bugs"" msgstr """" #: ./doc/training-guides/bk000-preface.xml:123(title)#: ./doc/training-guides/bk000-preface.xml:126(title)#: ./doc/training-guides/bk000-preface.xml:129(para) ./doc/training-guides/bk000-preface.xml:136(para) ./doc/training-guides/bk000-preface.xml:143(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:31(para) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:32(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:31(para) ./doc/training-guides/operator-guide/bk002-ch011-operator-network-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:35(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:42(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:49(para) ./doc/training-guides/operator-guide/bk002-ch005-operator-controller-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:22(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:29(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:36(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:43(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:25(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:32(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:39(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:46(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:53(para) ./doc/training-guides/operator-guide/bk002-ch008-operator-compute-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:22(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:29(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:36(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:31(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:47(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:54(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:61(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:68(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:75(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:33(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:27(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:34(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:41(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:48(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:55(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:33(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:31(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:47(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:54(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:61(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:68(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:75(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:82(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:25(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:32(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:39(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:46(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:53(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:15(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:22(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:29(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:36(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:43(para)#: ./doc/training-guides/bk000-preface.xml:129(link) ./doc/training-guides/bk000-preface.xml:136(link) ./doc/training-guides/bk000-preface.xml:143(link) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:17(link) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:24(link) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:31(link) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:17(link) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:32(link) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:17(link) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:24(link) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:31(link) ./doc/training-guides/operator-guide/bk002-ch011-operator-network-node-lab.xml:15(link) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:17(link) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:24(link) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:35(link) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:42(link) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:49(link) ./doc/training-guides/operator-guide/bk002-ch005-operator-controller-node-lab.xml:15(link) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:15(link) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:22(link) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:29(link) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:36(link) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:43(link) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:25(link) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:32(link) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:39(link) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:46(link) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:53(link) ./doc/training-guides/operator-guide/bk002-ch008-operator-compute-node-lab.xml:15(link) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:15(link) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:22(link) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:29(link) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:36(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:17(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:24(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:31(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:40(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:47(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:54(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:61(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:68(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:75(link) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:17(link) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:24(link) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:33(link) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:40(link) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:27(link) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:34(link) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:41(link) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:48(link) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:55(link) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:17(link) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:24(link) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:33(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:17(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:24(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:31(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:40(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:47(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:54(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:61(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:68(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:75(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:82(link) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:25(link) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:32(link) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:39(link) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:46(link) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:53(link) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:15(link) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:22(link) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:29(link) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:36(link) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:43(link)#: ./doc/training-guides/bk000-preface.xml:133(title)#: ./doc/training-guides/bk000-preface.xml:140(title)","""POT-Creation-Date: 2014-07-12 06:00+0000\n""#: ./doc/training-guides/under-contruction-notice.xml:77(para) ./doc/training-guides/bk000-preface.xml:83(para)#: ./doc/training-guides/under-contruction-notice.xml:86(para) ./doc/training-guides/bk000-preface.xml:92(para)#: ./doc/training-guides/under-contruction-notice.xml:90(para) ./doc/training-guides/bk000-preface.xml:96(para)#: ./doc/training-guides/under-contruction-notice.xml:94(para) ./doc/training-guides/bk000-preface.xml:100(para)#: ./doc/training-guides/under-contruction-notice.xml:99(para) ./doc/training-guides/bk000-preface.xml:105(para)#: ./doc/training-guides/under-contruction-notice.xml:103(para) ./doc/training-guides/bk000-preface.xml:109(para)#: ./doc/training-guides/under-contruction-notice.xml:107(para) ./doc/training-guides/bk000-preface.xml:113(para)#: ./doc/training-guides/under-contruction-notice.xml:111(para) ./doc/training-guides/bk000-preface.xml:117(para)#: ./doc/training-guides/under-contruction-notice.xml:118(link) ./doc/training-guides/bk000-preface.xml:124(link)#: ./doc/training-guides/user-story-includes-template.xml:22(para) ./doc/training-guides/bk000-preface.xml:134(para) ./doc/training-guides/bk000-preface.xml:141(para) ./doc/training-guides/bk000-preface.xml:148(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:31(para) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:32(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:31(para) ./doc/training-guides/operator-guide/bk002-ch011-operator-network-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:35(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:42(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:49(para) ./doc/training-guides/operator-guide/bk002-ch005-operator-controller-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:22(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:29(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:36(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:43(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:25(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:32(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:39(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:46(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:53(para) ./doc/training-guides/operator-guide/bk002-ch008-operator-compute-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:22(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:29(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:36(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:31(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:47(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:54(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:61(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:68(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:75(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:33(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:27(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:34(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:41(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:48(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:55(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:33(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:31(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:47(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:54(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:61(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:68(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:75(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:82(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:25(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:32(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:39(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:46(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:53(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:15(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:22(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:29(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:36(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:43(para)#: ./doc/training-guides/bk000-preface.xml:134(None) ./doc/training-guides/bk000-preface.xml:141(None) ./doc/training-guides/bk000-preface.xml:148(None)msgid ""<emphasis role=\""bold\"">Pick a Card:</emphasis> Once you have your tools ready to go, you can assign some work to yourself. Go to the <link href=\""https://trello.com/board/openstack-training/51d6e5fee37248fd5b003de9\"">Training Trello/KanBan storyboard</link> and assign a card / user story from the Sprint Backlog to yourself. If you do not have a Trello account, no problem, just create one. Email seanrob@yahoo-inc.com and you will have access.""#: ./doc/training-guides/bk000-preface.xml:73(para) msgid ""<emphasis role=\""bold\"">Create the Content:</emphasis> Each card / user story from the KanBan story board will be a separate chunk of content that you will add to the openstack-manuals repository openstack-training sub-project. <link href=\""operator-getting-started-lab.html#operator-add-training-content\""> More details on creating training content here.</link>""#: ./doc/training-guides/bk000-preface.xml:128(title)#: ./doc/training-guides/bk000-preface.xml:131(title)#: ./doc/training-guides/bk000-preface.xml:134(para) ./doc/training-guides/bk000-preface.xml:141(para) ./doc/training-guides/bk000-preface.xml:148(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:31(para) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:32(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:31(para) ./doc/training-guides/operator-guide/bk002-ch011-operator-network-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:17(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:24(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:35(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:42(para) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:49(para) ./doc/training-guides/operator-guide/bk002-ch005-operator-controller-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:22(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:29(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:36(para) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:43(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:25(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:32(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:39(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:46(para) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:53(para) ./doc/training-guides/operator-guide/bk002-ch008-operator-compute-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:15(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:22(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:29(para) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:36(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:31(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:47(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:54(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:61(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:68(para) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:75(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:33(para) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:27(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:34(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:41(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:48(para) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:55(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:33(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:17(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:24(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:31(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:40(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:47(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:54(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:61(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:68(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:75(para) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:82(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:25(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:32(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:39(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:46(para) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:53(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:15(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:22(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:29(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:36(para) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:43(para)#: ./doc/training-guides/bk000-preface.xml:134(link) ./doc/training-guides/bk000-preface.xml:141(link) ./doc/training-guides/bk000-preface.xml:148(link) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:17(link) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:24(link) ./doc/training-guides/operator-guide/bk002-ch004-operator-controller-node.xml:31(link) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:17(link) ./doc/training-guides/operator-guide/bk002-ch013-operator-object-storage-node.xml:32(link) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:17(link) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:24(link) ./doc/training-guides/operator-guide/bk002-ch007-operator-compute-node.xml:31(link) ./doc/training-guides/operator-guide/bk002-ch011-operator-network-node-lab.xml:15(link) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:17(link) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:24(link) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:35(link) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:42(link) ./doc/training-guides/operator-guide/bk002-ch010-operator-network-node.xml:49(link) ./doc/training-guides/operator-guide/bk002-ch005-operator-controller-node-lab.xml:15(link) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:15(link) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:22(link) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:29(link) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:36(link) ./doc/training-guides/operator-guide/bk002-ch002-operator-getting-started-lab.xml:43(link) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:25(link) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:32(link) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:39(link) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:46(link) ./doc/training-guides/operator-guide/bk002-ch001-operator-getting-started.xml:53(link) ./doc/training-guides/operator-guide/bk002-ch008-operator-compute-node-lab.xml:15(link) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:15(link) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:22(link) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:29(link) ./doc/training-guides/operator-guide/bk002-ch014-operator-object-storage-node-lab.xml:36(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:17(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:24(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:31(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:40(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:47(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:54(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:61(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:68(link) ./doc/training-guides/associate-guide/bk001-ch005-associate-compute-node.xml:75(link) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:17(link) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:24(link) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:33(link) ./doc/training-guides/associate-guide/bk001-ch007-associate-network-node.xml:40(link) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:27(link) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:34(link) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:41(link) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:48(link) ./doc/training-guides/associate-guide/bk001-ch001-associate-getting-started.xml:55(link) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:17(link) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:24(link) ./doc/training-guides/associate-guide/bk001-ch009-associate-object-storage-node.xml:33(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:17(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:24(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:31(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:40(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:47(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:54(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:61(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:68(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:75(link) ./doc/training-guides/associate-guide/bk001-ch003-associate-controller-node.xml:82(link) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:25(link) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:32(link) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:39(link) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:46(link) ./doc/training-guides/developer-guide/bk003-ch001-developer-getting-started.xml:53(link) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:15(link) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:22(link) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:29(link) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:36(link) ./doc/training-guides/developer-guide/bk003-ch002-developer-getting-started-lab.xml:43(link)#: ./doc/training-guides/bk000-preface.xml:138(title)#: ./doc/training-guides/bk000-preface.xml:145(title)",25,21
openstack%2Ffuel-library~stable%2F5.0~If8c64a565ebb86f545add145934d566d666ef073,openstack/fuel-library,stable/5.0,If8c64a565ebb86f545add145934d566d666ef073,Change resource generation type,MERGED,2014-07-17 16:18:18.000000000,2014-07-17 23:04:53.000000000,2014-07-17 23:04:52.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2014-07-17 16:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f41278aed9859f1a32bf1f3a4c54a9c7b3bdf825', 'message': 'Change resource generation type\n\nUse eval_generate to generate swift rings.\nThis will ensure that Ring_devices resource\nis completed only when all the Ring_*_devices\nis finished, thus ensuring that rebalance begins\nonly after all the devices were created.\n\nChange-Id: If8c64a565ebb86f545add145934d566d666ef073\nCloses-bug: #1305826\n'}, {'number': 4, 'created': '2014-07-17 17:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/082e76f18f5c03c56897229aaa1763912e50c35d', 'message': 'Change resource generation type\n\nUse eval_generate to generate swift rings.\nThis will ensure that Ring_devices resource\nis completed only when all the Ring_*_devices\nis finished, thus ensuring that rebalance begins\nonly after all the devices were created.\n\nAlso pin services start to rebalance end.\n\nChange-Id: If8c64a565ebb86f545add145934d566d666ef073\nCloses-bug: #1305826\n'}, {'number': 5, 'created': '2014-07-17 21:09:24.000000000', 'files': ['deployment/puppet/swift/lib/puppet/type/ring_devices.rb', 'deployment/puppet/swift/manifests/proxy.pp', 'deployment/puppet/swift/manifests/storage/generic.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b115bcfb57b8a99fc68b39f6be19b29b2e174464', 'message': 'Change resource generation type\n\nUse eval_generate to generate swift rings.\nThis will ensure that Ring_devices resource\nis completed only when all the Ring_*_devices\nis finished, thus ensuring that rebalance begins\nonly after all the devices were created.\n\nAlso pin services start to rebalance end.\n\nChange-Id: If8c64a565ebb86f545add145934d566d666ef073\nCloses-bug: #1305826\n'}]",0,107767,b115bcfb57b8a99fc68b39f6be19b29b2e174464,33,4,3,8786,,,0,"Change resource generation type

Use eval_generate to generate swift rings.
This will ensure that Ring_devices resource
is completed only when all the Ring_*_devices
is finished, thus ensuring that rebalance begins
only after all the devices were created.

Also pin services start to rebalance end.

Change-Id: If8c64a565ebb86f545add145934d566d666ef073
Closes-bug: #1305826
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/67/107767/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/swift/lib/puppet/type/ring_devices.rb'],1,f41278aed9859f1a32bf1f3a4c54a9c7b3bdf825,, def eval_generate, def generate,1,1
openstack%2Frequirements~stable%2Ficehouse~I7545bfce0130f31010a34d10663b6d901e507b69,openstack/requirements,stable/icehouse,I7545bfce0130f31010a34d10663b6d901e507b69,Add doc8 for taskflow testing build,ABANDONED,2014-06-19 18:54:38.000000000,2014-07-17 22:54:00.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-19 18:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/72fd571ff7bb95598818b5b0ba0eb2efd7cc2354', 'message': 'Add doc8 for taskflow testing build\n\nThis change adds doc8 to the stable/icehouse requirements list\nso the check-grenade-dsvm job, which tries to verify that the\nrequirements for the projects are correct across releases,\nwill allow taskflow to use doc8 as a testing time dependency.\n\nNothing else currently uses doc8 but taskflow will use it to\ncheck its own rst formatted documentation against the doc8 provided\nstyle and formatting checks.\n\nChange-Id: I7545bfce0130f31010a34d10663b6d901e507b69\n'}, {'number': 2, 'created': '2014-06-19 19:11:12.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ca58797a0d80c02fc7f00750519a82a41cb71443', 'message': 'Add doc8 for taskflow testing build\n\nThis change adds doc8 to the stable/icehouse requirements list\nso the check-grenade-dsvm job, which tries to verify that the\nrequirements for the projects are correct across releases,\nwill allow taskflow to use doc8 as a testing time dependency.\n\nNothing else currently uses doc8 but taskflow will use it to\ncheck its own rst formatted documentation against the doc8 provided\nstyle and formatting checks.\n\nChange-Id: I7545bfce0130f31010a34d10663b6d901e507b69\n'}]",0,101289,ca58797a0d80c02fc7f00750519a82a41cb71443,13,3,2,1297,,,0,"Add doc8 for taskflow testing build

This change adds doc8 to the stable/icehouse requirements list
so the check-grenade-dsvm job, which tries to verify that the
requirements for the projects are correct across releases,
will allow taskflow to use doc8 as a testing time dependency.

Nothing else currently uses doc8 but taskflow will use it to
check its own rst formatted documentation against the doc8 provided
style and formatting checks.

Change-Id: I7545bfce0130f31010a34d10663b6d901e507b69
",git fetch https://review.opendev.org/openstack/requirements refs/changes/89/101289/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,72fd571ff7bb95598818b5b0ba0eb2efd7cc2354,icehouse,doc8 # Apache-2.0,,1,0
openstack%2Frequirements~master~Ie9ac6f3245a06038c303f54c2cc231b5dba2d09e,openstack/requirements,master,Ie9ac6f3245a06038c303f54c2cc231b5dba2d09e,Add monotonic time library for python 2.x/3.x,ABANDONED,2014-04-11 01:55:14.000000000,2014-07-17 22:52:41.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2750}, {'_account_id': 4190}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-04-11 01:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/81492063f130fa2adb41935af0fa040e363d2363', 'message': 'Add monotonic time library for python 2.x\n\nMonotonic time is very useful for many different\nprojects that use time in a relative manner since\nit is resistant to ntpd adjustments or other time\nshifts.\n\nChange-Id: Ie9ac6f3245a06038c303f54c2cc231b5dba2d09e\n'}, {'number': 2, 'created': '2014-04-17 05:34:12.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7929e7b620df8a04f73906e81f5383d2333db43c', 'message': 'Add monotonic time library for python 2.x/3.x\n\nMonotonic time is very useful for many different\nprojects that use time in a relative manner since\nit is resistant to ntpd adjustments or other time\nshifts.\n\nChange-Id: Ie9ac6f3245a06038c303f54c2cc231b5dba2d09e\n'}]",1,86757,7929e7b620df8a04f73906e81f5383d2333db43c,23,5,2,1297,,,0,"Add monotonic time library for python 2.x/3.x

Monotonic time is very useful for many different
projects that use time in a relative manner since
it is resistant to ntpd adjustments or other time
shifts.

Change-Id: Ie9ac6f3245a06038c303f54c2cc231b5dba2d09e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/57/86757/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,81492063f130fa2adb41935af0fa040e363d2363,,Monotime # only required on python 2 (python 3 has this built-in),,1,0
openstack%2Foslo.messaging~master~I4c197dcfa40aef44940d6cd8272176f34fd09e2e,openstack/oslo.messaging,master,I4c197dcfa40aef44940d6cd8272176f34fd09e2e,Add a zookeeper based matchmaker,ABANDONED,2014-03-12 01:28:29.000000000,2014-07-17 22:51:03.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 6159}, {'_account_id': 7536}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-03-12 01:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d4a25b3feb7db295831b8693a26879301b2d2275', 'message': 'Add a zookeeper based matchmaker\n\nChange-Id: I4c197dcfa40aef44940d6cd8272176f34fd09e2e\n'}, {'number': 2, 'created': '2014-03-13 00:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b0863ca3e71c58439cd49d1d040a36ec94f4f5af', 'message': 'Add a zookeeper based matchmaker\n\nChange-Id: I4c197dcfa40aef44940d6cd8272176f34fd09e2e\n'}, {'number': 3, 'created': '2014-04-10 01:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9bb23f9852d7a363888799df2374f876d1fa2239', 'message': 'Add a zookeeper based matchmaker\n\nChange-Id: I4c197dcfa40aef44940d6cd8272176f34fd09e2e\n'}, {'number': 4, 'created': '2014-04-10 02:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/528635574250047f3ade9ddcaf59e63a4c29c380', 'message': 'Add a zookeeper based matchmaker\n\nChange-Id: I4c197dcfa40aef44940d6cd8272176f34fd09e2e\n'}, {'number': 5, 'created': '2014-04-10 22:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/72de66a6b7aa45c12228dc7bc8ab1d255f474d1c', 'message': 'Add a zookeeper based matchmaker\n\nChange-Id: I4c197dcfa40aef44940d6cd8272176f34fd09e2e\n'}, {'number': 6, 'created': '2014-04-11 14:59:59.000000000', 'files': ['oslo/messaging/_drivers/matchmaker_zookeeper.py', 'requirements.txt', 'test-requirements.txt', 'tests/test_matchmaker_zookeeper.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/93e5be424fcffc70a726a117aa6d221844ef589c', 'message': 'Add a zookeeper based matchmaker\n\nChange-Id: I4c197dcfa40aef44940d6cd8272176f34fd09e2e\n'}]",7,79825,93e5be424fcffc70a726a117aa6d221844ef589c,30,5,6,1297,,,0,"Add a zookeeper based matchmaker

Change-Id: I4c197dcfa40aef44940d6cd8272176f34fd09e2e
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/25/79825/6 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/matchmaker_zookeeper.py', 'requirements.txt']",2,d4a25b3feb7db295831b8693a26879301b2d2275,zookeeper, # for the zookeeper matchmaker kazoo>=0.9,,147,0
openstack%2Fsecurity-doc~master~I7fa1cddcd3d7507491c1591689b85e8b18f50e1d,openstack/security-doc,master,I7fa1cddcd3d7507491c1591689b85e8b18f50e1d,SO 27K standard updated for 2013,ABANDONED,2014-07-16 18:34:26.000000000,2014-07-17 22:39:44.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7063}]","[{'number': 1, 'created': '2014-07-16 18:34:26.000000000', 'files': ['security-guide/ch_compliance-activities.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/574276a2149cc8fbcf4a8606c0879f638324ebda', 'message': 'SO 27K standard updated for 2013\n\nChange-Id: I7fa1cddcd3d7507491c1591689b85e8b18f50e1d\n'}]",0,107465,574276a2149cc8fbcf4a8606c0879f638324ebda,7,3,1,12326,,,0,"SO 27K standard updated for 2013

Change-Id: I7fa1cddcd3d7507491c1591689b85e8b18f50e1d
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/65/107465/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_compliance-activities.xml'],1,574276a2149cc8fbcf4a8606c0879f638324ebda,standardsupdates," <para>An Information Security Management System (ISMS) is a comprehensive set of policies and processes that an organization creates and maintains to manage risk to information assets. The most common ISMS for cloud deployments is <link xlink:href=""http://www.27000.org/iso-27001.htm"">ISO/IEC 27001/2</link>, which creates a solid foundation of security controls and practices for achieving more stringent compliance certifications. This standard was updated in 2013 to reflect the growing use of cloud services and places more emphasis on measuring and evaluating how well an organisation's ISMS is performing.</para>"," <para>An Information Security Management System (ISMS) is a comprehensive set of policies and processes that an organization creates and maintains to manage risk to information assets. The most common ISMS for cloud deployments is <link xlink:href=""http://www.27000.org/iso-27001.htm"">ISO/IEC 27001/2</link>, which creates a solid foundation of security controls and practices for achieving more stringent compliance certifications. This standard has been updated in 2013 to reflect the growing use of cloud services and places more emphasis on measuring and evaluating how well an organisation's ISMS is performing.</para>",8,1
openstack%2Fdesignate~master~I37822944087385f582181cac3d908287c728d88d,openstack/designate,master,I37822944087385f582181cac3d908287c728d88d,Ensure eventlet monkey patching happens as early as possible,MERGED,2014-07-17 19:21:13.000000000,2014-07-17 22:39:05.000000000,2014-07-17 22:39:04.000000000,"[{'_account_id': 3}, {'_account_id': 8094}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-07-17 19:21:13.000000000', 'files': ['designate/cmd/__init__.py', 'designate/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/0c22ba07994d37a1726303588c4392d193909bdf', 'message': 'Ensure eventlet monkey patching happens as early as possible\n\nChange-Id: I37822944087385f582181cac3d908287c728d88d\nCloses-Bug: 1343526\n'}]",0,107807,0c22ba07994d37a1726303588c4392d193909bdf,8,3,1,741,,,0,"Ensure eventlet monkey patching happens as early as possible

Change-Id: I37822944087385f582181cac3d908287c728d88d
Closes-Bug: 1343526
",git fetch https://review.opendev.org/openstack/designate refs/changes/07/107807/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/cmd/__init__.py', 'designate/__init__.py']",2,0c22ba07994d37a1726303588c4392d193909bdf,bug/1343526,import eventlet eventlet.monkey_patch(os=False) ,,4,18
openstack%2Fdesignate~master~I7577e33800d947023b9bc939a76f7f78d20c2fb8,openstack/designate,master,I7577e33800d947023b9bc939a76f7f78d20c2fb8,PowerDNS: Ensure each greenthread uses it's own Session instance,MERGED,2014-07-17 20:18:01.000000000,2014-07-17 22:32:24.000000000,2014-07-17 22:32:24.000000000,"[{'_account_id': 3}, {'_account_id': 8094}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-07-17 20:18:01.000000000', 'files': ['designate/backend/impl_powerdns/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/97197c5605089384820a64401981a0d2314afa61', 'message': ""PowerDNS: Ensure each greenthread uses it's own Session instance\n\nThis uses a thread local store, allowing each greenthread to\nhave it's own session stored correctly. Without this, each\ngreenthread may end up using a single global session, which\nleads to bad things happening.\n\nSee also I1ceb33d2bcb531d444ad05cf6cf74b6edd4e7d39\n\nChange-Id: I7577e33800d947023b9bc939a76f7f78d20c2fb8\nCloses-Bug: 1343561\n""}]",0,107817,97197c5605089384820a64401981a0d2314afa61,8,3,1,741,,,0,"PowerDNS: Ensure each greenthread uses it's own Session instance

This uses a thread local store, allowing each greenthread to
have it's own session stored correctly. Without this, each
greenthread may end up using a single global session, which
leads to bad things happening.

See also I1ceb33d2bcb531d444ad05cf6cf74b6edd4e7d39

Change-Id: I7577e33800d947023b9bc939a76f7f78d20c2fb8
Closes-Bug: 1343561
",git fetch https://review.opendev.org/openstack/designate refs/changes/17/107817/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/backend/impl_powerdns/__init__.py'],1,97197c5605089384820a64401981a0d2314afa61,bug/1343561,"import threadingfrom designate.sqlalchemy import sessionLOCAL_STORE = threading.local() @property def session(self): # NOTE: This uses a thread local store, allowing each greenthread to # have it's own session stored correctly. Without this, each # greenthread may end up using a single global session, which # leads to bad things happening. global LOCAL_STORE if not hasattr(LOCAL_STORE, 'session'): LOCAL_STORE.session = session.get_session(self.name) return LOCAL_STORE.session",from designate.sqlalchemy.session import get_session self.session = get_session(self.name),15,2
openstack%2Fheat~master~Iee6e2abbf13173c17d92f47b8a7efe207c29a984,openstack/heat,master,Iee6e2abbf13173c17d92f47b8a7efe207c29a984,Make sure we can create an empty template,MERGED,2014-07-09 22:08:12.000000000,2014-07-17 22:30:26.000000000,2014-07-16 20:38:31.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7239}, {'_account_id': 7761}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-07-09 22:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/24473154af66a175dc44e013e1b6294769e121a5', 'message': 'Make sure we can create an empty hot template\n\nChange-Id: Iee6e2abbf13173c17d92f47b8a7efe207c29a984\nCloses-bug: #1339893\n'}, {'number': 2, 'created': '2014-07-09 22:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a6cc3573384499bd132b61351d06868956041e6e', 'message': 'Make sure we can create an empty template\n\nThe initial bug was for HOT, but this fixes the same issue\nin CFN too.\n\nChange-Id: Iee6e2abbf13173c17d92f47b8a7efe207c29a984\nCloses-bug: #1339893\n'}, {'number': 3, 'created': '2014-07-09 22:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5d7885891675c795201270c393d22f6c092d0075', 'message': 'Make sure we can create an empty template\n\nThe initial bug was for HOT, but this fixes the same issue\nin CFN too.\n\nChange-Id: Iee6e2abbf13173c17d92f47b8a7efe207c29a984\nCloses-bug: #1339893\n'}, {'number': 4, 'created': '2014-07-14 00:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3ffeba9710f75a83906a89f2fef3dd2a6db4e891', 'message': 'Make sure we can create an empty template\n\nThe initial bug was for HOT, but this fixes the same issue\nin CFN too.\n\n1) all calls to template[section] should return {} and not\n   None by default (hot was correct, but not cfn)\n2) the validate needs to access the raw template ""self.t"" so\n   make sure we have a similar logic there too.\n3) when warning for zero resources, look for len(resoruces) == 0 not\n   None.\n\n\nChange-Id: Iee6e2abbf13173c17d92f47b8a7efe207c29a984\nCloses-bug: #1339893\n'}, {'number': 5, 'created': '2014-07-14 11:31:11.000000000', 'files': ['heat/engine/template.py', 'heat/tests/test_empty_stack.py', 'heat/engine/cfn/template.py', 'heat/tests/test_template.py', 'heat/engine/hot/template.py', 'heat/tests/test_hot.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f6894260caa29c883a930095b086a3710fd86b8c', 'message': 'Make sure we can create an empty template\n\nThe initial bug was for HOT, but this fixes the same issue\nin CFN too.\n\n1) all calls to template[section] should return {} and not\n   None by default (hot was correct, but not cfn)\n2) the validate needs to access the raw template ""self.t"" so\n   make sure we have a similar logic there too.\n3) when warning for zero resources, look for len(resoruces) == 0 not\n   None.\n\nChange-Id: Iee6e2abbf13173c17d92f47b8a7efe207c29a984\nCloses-bug: #1339893\n'}]",12,105894,f6894260caa29c883a930095b086a3710fd86b8c,40,11,5,4715,,,0,"Make sure we can create an empty template

The initial bug was for HOT, but this fixes the same issue
in CFN too.

1) all calls to template[section] should return {} and not
   None by default (hot was correct, but not cfn)
2) the validate needs to access the raw template ""self.t"" so
   make sure we have a similar logic there too.
3) when warning for zero resources, look for len(resoruces) == 0 not
   None.

Change-Id: Iee6e2abbf13173c17d92f47b8a7efe207c29a984
Closes-bug: #1339893
",git fetch https://review.opendev.org/openstack/heat refs/changes/94/105894/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot/template.py', 'heat/tests/test_hot.py']",2,24473154af66a175dc44e013e1b6294769e121a5,empty_template, self.assertIsNone(stack.validate()),,5,2
openstack%2Fopenstack-manuals~master~Ib8457a3c93b8c9acda8225c5795dc626485d64c4,openstack/openstack-manuals,master,Ib8457a3c93b8c9acda8225c5795dc626485d64c4,Added documentation for trove-manage,MERGED,2014-07-16 19:48:54.000000000,2014-07-17 22:20:36.000000000,2014-07-17 22:20:35.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6772}, {'_account_id': 10215}]","[{'number': 1, 'created': '2014-07-16 19:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2f0e68dbc3f235676b4c804d23f561a06f03d9bd', 'message': 'Added documentation for trove-manage\n\nNo documentation was being generated for the trove-manage CLI of the\ndatabase project. Since *-manage CLIs are now supported by the\nopenstack-auto-commands tool, this has been added to the CLI\nreference manual.\n\nA current version of the trove-manage .xml file is included.\n\nChange-Id: Ib8457a3c93b8c9acda8225c5795dc626485d64c4\nCloses-Bug: #1338798\n'}, {'number': 2, 'created': '2014-07-16 22:45:01.000000000', 'files': ['doc/cli-reference/bk-cli-reference.xml', 'doc/common/ch_cli_trove-manage_commands.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9681fcfc588a864d230c278338224e805ad57321', 'message': 'Added documentation for trove-manage\n\nNo documentation was being generated for the trove-manage CLI of the\ndatabase project. Since *-manage CLIs are now supported by the\nopenstack-auto-commands tool, this has been added to the CLI\nreference manual.\n\nA current version of the trove-manage .xml file is included.\n\nChange-Id: Ib8457a3c93b8c9acda8225c5795dc626485d64c4\nCloses-Bug: #1338798\n'}]",0,107484,9681fcfc588a864d230c278338224e805ad57321,14,5,2,10215,,,0,"Added documentation for trove-manage

No documentation was being generated for the trove-manage CLI of the
database project. Since *-manage CLIs are now supported by the
openstack-auto-commands tool, this has been added to the CLI
reference manual.

A current version of the trove-manage .xml file is included.

Change-Id: Ib8457a3c93b8c9acda8225c5795dc626485d64c4
Closes-Bug: #1338798
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/84/107484/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/cli-reference/bk-cli-reference.xml', 'doc/common/ch_cli_trove-manage_commands.xml']",2,2f0e68dbc3f235676b4c804d23f561a06f03d9bd,bug/1338798,"<?xml version=""1.0"" encoding=""UTF-8""?> <chapter xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""trove-manageclient_commands""> <!-- This file is automatically generated, do not edit --> <?dbhtml stop-chunking?> <title>Database Service Management command-line client</title> <para>The <command>trove-manage</command> client is the command-line interface (CLI) for the Database Management Utility and its extensions. This chapter documents <command>trove-manage</command> version 2014.2. </para> <para>For help on a specific <command>trove-manage</command> command, enter: </para> <screen><prompt>$</prompt> <userinput><command>trove-manage</command> <replaceable>COMMAND</replaceable> <option>--help</option></userinput></screen> <section xml:id=""trove-manageclient_command_usage""> <title>trove-manage usage</title> <screen><computeroutput>usage: trove-manage [-h] [--config-dir DIR] [--config-file PATH] [--debug] [--log-config-append PATH] [--log-date-format DATE_FORMAT] [--log-dir LOG_DIR] [--log-file PATH] [--log-format FORMAT] [--nodebug] [--nouse-syslog] [--nouse-syslog-rfc-format] [--noverbose] [--syslog-log-facility SYSLOG_LOG_FACILITY] [--use-syslog] [--use-syslog-rfc-format] [--verbose] [--version] {db_sync,db_upgrade,db_downgrade,datastore_update,datastore_version_update,db_recreate} ...</computeroutput></screen> </section> <section xml:id=""trove-manageclient_command_optional""> <title>trove-manage optional arguments</title> <variablelist wordsize=""10""> <varlistentry> <term><command>-h, --help</command></term> <listitem> <para> show this help message and exit </para> </listitem> </varlistentry> <varlistentry> <term><command>--config-dir DIR</command></term> <listitem> <para> Path to a config directory to pull *.conf files from. This file set is sorted, so as to provide a predictable parse order if individual options are over-ridden. The set is parsed after the file(s) specified via previous --config-file, arguments hence over-ridden options in the directory take precedence. </para> </listitem> </varlistentry> <varlistentry> <term><command>--config-file PATH</command></term> <listitem> <para> Path to a config file to use. Multiple config files can be specified, with values in later files taking precedence. The default files used are: None. </para> </listitem> </varlistentry> <varlistentry> <term><command>--debug, -d</command></term> <listitem> <para> Print debugging output (set logging level to DEBUG instead of default WARNING level). </para> </listitem> </varlistentry> <varlistentry> <term><command>--log-config-append PATH, --log_config PATH</command></term> <listitem> <para> The name of a logging configuration file. This file is appended to any existing logging configuration files. For details about logging configuration files, see the Python logging module documentation. </para> </listitem> </varlistentry> <varlistentry> <term><command>--log-date-format DATE_FORMAT</command></term> <listitem> <para> Format string for %(asctime)s in log records. Default: None . </para> </listitem> </varlistentry> <varlistentry> <term><command>--log-dir LOG_DIR, --logdir LOG_DIR</command></term> <listitem> <para> (Optional) The base directory used for relative --log- file paths. </para> </listitem> </varlistentry> <varlistentry> <term><command>--log-file PATH, --logfile PATH</command></term> <listitem> <para> (Optional) Name of log file to output to. If no default is set, logging will go to stdout. </para> </listitem> </varlistentry> <varlistentry> <term><command>--log-format FORMAT</command></term> <listitem> <para> <emphasis>DEPRECATED</emphasis>. A logging.Formatter log message format string which may use any of the available logging.LogRecord attributes. This option is deprecated. Please use logging_context_format_string and logging_default_format_string instead. </para> </listitem> </varlistentry> <varlistentry> <term><command>--nodebug</command></term> <listitem> <para> The inverse of --debug </para> </listitem> </varlistentry> <varlistentry> <term><command>--nouse-syslog</command></term> <listitem> <para> The inverse of --use-syslog </para> </listitem> </varlistentry> <varlistentry> <term><command>--nouse-syslog-rfc-format</command></term> <listitem> <para> The inverse of --use-syslog-rfc-format </para> </listitem> </varlistentry> <varlistentry> <term><command>--noverbose</command></term> <listitem> <para> The inverse of --verbose </para> </listitem> </varlistentry> <varlistentry> <term><command>--syslog-log-facility SYSLOG_LOG_FACILITY</command></term> <listitem> <para> Syslog facility to receive log lines. </para> </listitem> </varlistentry> <varlistentry> <term><command>--use-syslog</command></term> <listitem> <para> Use syslog for logging. Existing syslog format is <emphasis>DEPRECATED</emphasis> during I, and will change in J to honor RFC5424. </para> </listitem> </varlistentry> <varlistentry> <term><command>--use-syslog-rfc-format</command></term> <listitem> <para> (Optional) Enables or disables syslog rfc5424 format for logging. If enabled, prefixes the MSG part of the syslog message with APP-NAME (RFC5424). The format without the APP-NAME is deprecated in I, and will be removed in J. </para> </listitem> </varlistentry> <varlistentry> <term><command>--verbose, -v</command></term> <listitem> <para> Print more verbose output (set logging level to INFO instead of default WARNING level). </para> </listitem> </varlistentry> <varlistentry> <term><command>--version</command></term> <listitem> <para> show program's version number and exit </para> </listitem> </varlistentry> </variablelist> </section> <section xml:id=""trove-manageclient_subcommand_datastore_update""> <title>trove-manage datastore_update command</title> <screen><computeroutput>usage: trove-manage datastore_update [-h] datastore_name default_version</computeroutput></screen> <para> Add a datastore to Trove. If the datastore exists, the default version will be updated. </para> <variablelist wordsize=""10""> <title>Positional arguments</title> <varlistentry> <term><command>datastore_name</command></term> <listitem> <para> The name of the datastore. </para> </listitem> </varlistentry> <varlistentry> <term><command>default_version</command></term> <listitem> <para> The name or ID of the default datastore version. If adding a new datastore, pass in an empty string. </para> </listitem> </varlistentry> </variablelist> <variablelist wordsize=""10""> <title>Optional arguments</title> <varlistentry> <term><command>-h, --help</command></term> <listitem> <para> show this help message and exit </para> </listitem> </varlistentry> </variablelist> </section> <section xml:id=""trove-manageclient_subcommand_datastore_version_update""> <title>trove-manage datastore_version_update command</title> <screen><computeroutput>usage: trove-manage datastore_version_update [-h] datastore version_name manager image_id packages active</computeroutput></screen> <para> Add a datastore version to trove. If the datastore version already exists, all values except the datastore name and version will be updated. </para> <variablelist wordsize=""10""> <title>Positional arguments</title> <varlistentry> <term><command>datastore</command></term> <listitem> <para> The name of the datastore. </para> </listitem> </varlistentry> <varlistentry> <term><command>version_name</command></term> <listitem> <para> The name of the datastore version. </para> </listitem> </varlistentry> <varlistentry> <term><command>manager</command></term> <listitem> <para> The name of the manager that Trove should use to administer the datastore. </para> </listitem> </varlistentry> <varlistentry> <term><command>image_id</command></term> <listitem> <para> The Glance ID of the image used to create a new Trove instance of the datastore version. </para> </listitem> </varlistentry> <varlistentry> <term><command>packages</command></term> <listitem> <para> The packages of the datastore version that are installed on the guest image. </para> </listitem> </varlistentry> <varlistentry> <term><command>active</command></term> <listitem> <para> Whether the datastore version is active or not. Accepted values are 0 and 1. </para> </listitem> </varlistentry> </variablelist> <variablelist wordsize=""10""> <title>Optional arguments</title> <varlistentry> <term><command>-h, --help</command></term> <listitem> <para> show this help message and exit </para> </listitem> </varlistentry> </variablelist> </section> <section xml:id=""trove-manageclient_subcommand_db_downgrade""> <title>trove-manage db_downgrade command</title> <screen><computeroutput>usage: trove-manage db_downgrade [-h] [--repo_path REPO_PATH] version</computeroutput></screen> <para> Downgrade the database to the specified version. </para> <variablelist wordsize=""10""> <title>Positional arguments</title> <varlistentry> <term><command>version</command></term> <listitem> <para> Version to downgrade to. </para> </listitem> </varlistentry> </variablelist> <variablelist wordsize=""10""> <title>Optional arguments</title> <varlistentry> <term><command>-h, --help</command></term> <listitem> <para> show this help message and exit </para> </listitem> </varlistentry> <varlistentry> <term><command>--repo_path REPO_PATH</command></term> <listitem> <para> SQLAlchemy Migrate repository path. </para> </listitem> </varlistentry> </variablelist> </section> <section xml:id=""trove-manageclient_subcommand_db_recreate""> <title>trove-manage db_recreate command</title> <screen><computeroutput>usage: trove-manage db_recreate [-h] repo_path</computeroutput></screen> <para> Drop the database and recreate it. </para> <variablelist wordsize=""10""> <title>Positional arguments</title> <varlistentry> <term><command>repo_path</command></term> <listitem> <para> SQLAlchemy Migrate repository path. </para> </listitem> </varlistentry> </variablelist> <variablelist wordsize=""10""> <title>Optional arguments</title> <varlistentry> <term><command>-h, --help</command></term> <listitem> <para> show this help message and exit </para> </listitem> </varlistentry> </variablelist> </section> <section xml:id=""trove-manageclient_subcommand_db_sync""> <title>trove-manage db_sync command</title> <screen><computeroutput>usage: trove-manage db_sync [-h] [--repo_path REPO_PATH]</computeroutput></screen> <para> Populate the database structure with the current version needed by Trove. </para> <variablelist wordsize=""10""> <title>Optional arguments</title> <varlistentry> <term><command>-h, --help</command></term> <listitem> <para> show this help message and exit </para> </listitem> </varlistentry> <varlistentry> <term><command>--repo_path REPO_PATH</command></term> <listitem> <para> SQLAlchemy Migrate repository path. </para> </listitem> </varlistentry> </variablelist> </section> <section xml:id=""trove-manageclient_subcommand_db_upgrade""> <title>trove-manage db_upgrade command</title> <screen><computeroutput>usage: trove-manage db_upgrade [-h] [--version VERSION] [--repo_path REPO_PATH]</computeroutput></screen> <para> Upgrade the database to the specified version. </para> <variablelist wordsize=""10""> <title>Optional arguments</title> <varlistentry> <term><command>-h, --help</command></term> <listitem> <para> show this help message and exit </para> </listitem> </varlistentry> <varlistentry> <term><command>--version VERSION</command></term> <listitem> <para> Version to upgrade to. Defaults to the current version. </para> </listitem> </varlistentry> <varlistentry> <term><command>--repo_path REPO_PATH</command></term> <listitem> <para> SQLAlchemy Migrate repository path. </para> </listitem> </varlistentry> </variablelist> </section> </chapter> ",,446,0
openstack%2Fopenstack-manuals~master~I64e20dcaf10ab7cf07c12844e8d70ebce62cf822,openstack/openstack-manuals,master,I64e20dcaf10ab7cf07c12844e8d70ebce62cf822,fix the broken link of the CentOS mirror page.,MERGED,2014-07-17 13:01:24.000000000,2014-07-17 22:20:14.000000000,2014-07-17 22:20:14.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 6843}]","[{'number': 1, 'created': '2014-07-17 13:01:24.000000000', 'files': ['doc/image-guide/section_centos-example.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0763517d2ec83193ce29b1a9a86fd6357ef143ef', 'message': 'fix the broken link of the CentOS mirror page.\n\nChange-Id: I64e20dcaf10ab7cf07c12844e8d70ebce62cf822\nCloses-Bug: 1343023\n'}]",0,107679,0763517d2ec83193ce29b1a9a86fd6357ef143ef,9,4,1,10497,,,0,"fix the broken link of the CentOS mirror page.

Change-Id: I64e20dcaf10ab7cf07c12844e8d70ebce62cf822
Closes-Bug: 1343023
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/107679/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/image-guide/section_centos-example.xml'],1,0763517d2ec83193ce29b1a9a86fd6357ef143ef,bug/1343023," xlink:href=""http://www.centos.org/download/mirrors/"">CentOS <para>See <link xlink:href=""http://www.centos.org/download/mirrors/"""," xlink:href=""http://www.centos.org/modules/tinycontent/index.php?id=30"">CentOS <para>See <link xlink:href=""http://www.centos.org/modules/tinycontent/index.php?id=30""",2,2
openstack%2Fmonasca-api~master~If0bb96b506c1b89aa6252d05ffad81a7912e5a7c,openstack/monasca-api,master,If0bb96b506c1b89aa6252d05ffad81a7912e5a7c,Migrate docker images to monasca repo.,MERGED,2014-07-17 21:28:33.000000000,2014-07-17 21:58:27.000000000,2014-07-17 21:58:27.000000000,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 11809}]","[{'number': 1, 'created': '2014-07-17 21:28:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/804132381a379b5a807d10ebebebf77a89a62b55', 'message': 'Migrate docker images to monasca repo.\n\nChange-Id: If0bb96b506c1b89aa6252d05ffad81a7912e5a7c\n'}, {'number': 2, 'created': '2014-07-17 21:44:25.000000000', 'files': ['src/test/java/com/hpcloud/mon/integration/docker/ITInfluxDBTest.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/34fb8b1350cbb878766322adade4ad44bb28be2a', 'message': 'Migrate docker images to monasca repo.\n\nUse standard naming conventions.\n\nChange-Id: If0bb96b506c1b89aa6252d05ffad81a7912e5a7c\n'}]",0,107835,34fb8b1350cbb878766322adade4ad44bb28be2a,11,3,2,12511,,,0,"Migrate docker images to monasca repo.

Use standard naming conventions.

Change-Id: If0bb96b506c1b89aa6252d05ffad81a7912e5a7c
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/35/107835/1 && git format-patch -1 --stdout FETCH_HEAD,['src/test/java/com/hpcloud/mon/integration/docker/ITInfluxDBTest.java'],1,804132381a379b5a807d10ebebebf77a89a62b55,enhancement/migrate-docker-images-to-monasca,"import java.io.File; import java.io.FileFilter; import java.io.IOException; private final static String DDIETERLY_INFLUXDB_V1 = ""monasca/api-integ-tests-influxdb""; private static final String DDIETERLY_MYSQL_V1 = ""monasca/api-integ-tests-mysql""; private static final String DDIETERLY_KAFKA_V1 = ""monasca/api-integ-tests-kafka""; try { runKafka(); runInfluxDB(); runMYSQL(); runAPI(); } catch (Exception e) { System.err.println(""Failed to setup environment""); System.err.println(e); tearDown(); } File log = new File(""mon-api-integration-test.log"");","import java.io.*; private final static String DDIETERLY_INFLUXDB_V1 = ""ddieterly/influxdb:v1""; private static final String DDIETERLY_MYSQL_V1 = ""ddieterly/mysql:v1""; private static final String DDIETERLY_KAFKA_V1 = ""ddieterly/kafka:v1""; runKafka(); runInfluxDB(); runMYSQL(); runAPI(); File log = new File(""mon-api-integration-test.log"");",19,10
openstack%2Fcinder~master~I79e705f3852e8aa34034015199d56a8b23aeb8ef,openstack/cinder,master,I79e705f3852e8aa34034015199d56a8b23aeb8ef,Enable lazy translation for Cinder,MERGED,2014-07-08 19:17:48.000000000,2014-07-17 21:56:01.000000000,2014-07-17 21:56:00.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9533}, {'_account_id': 12017}]","[{'number': 1, 'created': '2014-07-08 19:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/66bda01299ecb72caf421ba701bc3c665203b22a', 'message': ""Enable lazy translation for Cinder\n\nThis patch is the final step for getting lazy translation\nre-enabled for Cinder.  It removes the use of gettextutils.install()\nwhich is no longer needed with the addition of the explicit import\nof _() in all of Cinder's files.  The configuration of 'cinder' catalog\nis handled by gettextutils.\n\nThe install() function is replaced by gettextutils.enable_lazy() which\nproperly enables lazy translation when _() or _LX() is used.\n\nChange-Id: I79e705f3852e8aa34034015199d56a8b23aeb8ef\nImplements-Blueprint: i18n-enablement\n""}, {'number': 2, 'created': '2014-07-08 19:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/681f10e19225af8108f1ef0a464d2dee4dc76799', 'message': ""Enable lazy translation for Cinder\n\nThis patch is the final step for getting lazy translation\nre-enabled for Cinder.  It removes the use of gettextutils.install()\nwhich is no longer needed with the addition of the explicit import\nof _() in all of Cinder's files.  The configuration of 'cinder' catalog\nis handled by gettextutils.\n\nThe install() function is replaced by gettextutils.enable_lazy() which\nproperly enables lazy translation when _() or _LX() is used.\n\nChange-Id: I79e705f3852e8aa34034015199d56a8b23aeb8ef\nImplements-Blueprint: i18n-enablement\n""}, {'number': 3, 'created': '2014-07-09 21:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d7cb716f9e9fd9b713ac10dcffececc1994724a0', 'message': ""Enable lazy translation for Cinder\n\nThis patch is the final step for getting lazy translation\nre-enabled for Cinder.  It removes the use of gettextutils.install()\nwhich is no longer needed with the addition of the explicit import\nof _() in all of Cinder's files.  The configuration of 'cinder' catalog\nis handled by gettextutils.\n\nThe install() function is replaced by gettextutils.enable_lazy() which\nproperly enables lazy translation when _() or _LX() is used.\n\nChange-Id: I79e705f3852e8aa34034015199d56a8b23aeb8ef\nImplements-Blueprint: i18n-enablement\n""}, {'number': 4, 'created': '2014-07-17 13:40:11.000000000', 'files': ['bin/cinder-all', 'bin/cinder-manage', 'bin/cinder-clear-rabbit-queues', 'bin/cinder-scheduler', 'cinder/db/sqlalchemy/migrate_repo/manage.py', 'bin/cinder-volume', 'bin/cinder-backup', 'bin/cinder-volume-usage-audit', 'bin/cinder-api', 'cinder/db/sqlalchemy/migrate_repo/versions/021_add_default_quota_class.py', 'bin/cinder-rtstool'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce86dbaa96e555c696c1306833e3d0717dfaf2d2', 'message': ""Enable lazy translation for Cinder\n\nThis patch is the final step for getting lazy translation\nre-enabled for Cinder.  It removes the use of gettextutils.install()\nwhich is no longer needed with the addition of the explicit import\nof _() in all of Cinder's files.  The configuration of 'cinder' catalog\nis handled by gettextutils.\n\nThe install() function is replaced by gettextutils.enable_lazy() which\nproperly enables lazy translation when _() or _LX() is used.\n\nChange-Id: I79e705f3852e8aa34034015199d56a8b23aeb8ef\nImplements-Blueprint: i18n-enablement\n""}]",3,105561,ce86dbaa96e555c696c1306833e3d0717dfaf2d2,29,7,4,7198,,,0,"Enable lazy translation for Cinder

This patch is the final step for getting lazy translation
re-enabled for Cinder.  It removes the use of gettextutils.install()
which is no longer needed with the addition of the explicit import
of _() in all of Cinder's files.  The configuration of 'cinder' catalog
is handled by gettextutils.

The install() function is replaced by gettextutils.enable_lazy() which
properly enables lazy translation when _() or _LX() is used.

Change-Id: I79e705f3852e8aa34034015199d56a8b23aeb8ef
Implements-Blueprint: i18n-enablement
",git fetch https://review.opendev.org/openstack/cinder refs/changes/61/105561/2 && git format-patch -1 --stdout FETCH_HEAD,"['bin/cinder-all', 'bin/cinder-manage', 'bin/cinder-clear-rabbit-queues', 'bin/cinder-scheduler', 'cinder/db/sqlalchemy/migrate_repo/manage.py', 'bin/cinder-volume', 'bin/cinder-backup', 'bin/cinder-volume-usage-audit', 'bin/cinder-api', 'bin/cinder-rtstool']",10,66bda01299ecb72caf421ba701bc3c665203b22a,bp/i18n-enablement,gettext.enable_lazy(),,10,9
openstack%2Fcongress~master~Ie816aac0762b31655ee6028ffdd1ae4050c407aa,openstack/congress,master,Ie816aac0762b31655ee6028ffdd1ae4050c407aa,Make tests in test_webservice run,MERGED,2014-07-16 20:56:30.000000000,2014-07-17 21:45:01.000000000,2014-07-17 21:45:01.000000000,"[{'_account_id': 3}, {'_account_id': 6923}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-07-16 20:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/01a8fd3bb2cfac90bc8c9f36c10f0bdf5638afd6', 'message': 'Make tests in test_webserice run\n\nPreviously the tests in test_webservice were not being run as its\ntest directory was missing __init__.py. This patch also moves this test\nto congress/tests/api/\n\nChange-Id: Ie816aac0762b31655ee6028ffdd1ae4050c407aa\ncloses-bug: 1342957\n'}, {'number': 2, 'created': '2014-07-16 20:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/01c066bc29b683042a099a6ffc100d368a47759b', 'message': 'Make tests in test_webserice run\n\nPreviously the tests in test_webservice were not being run as its\ntest directory was missing __init__.py. This patch also moves this test\nto congress/tests/api/\n\nChange-Id: Ie816aac0762b31655ee6028ffdd1ae4050c407aa\ncloses-bug: 1342957\n'}, {'number': 3, 'created': '2014-07-16 20:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/2f74410c93a4d761a6fb3d913ea6bec87fd3085c', 'message': 'Make tests in test_webservice run\n\nPreviously the tests in test_webservice were not being run as its\ntest directory was missing __init__.py. This patch also moves this test\nto congress/tests/api/\n\nChange-Id: Ie816aac0762b31655ee6028ffdd1ae4050c407aa\ncloses-bug: 1342957\n'}, {'number': 4, 'created': '2014-07-16 21:13:47.000000000', 'files': ['congress/tests/api/test_webservice.py', 'congress/tests/api/__init__.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/2324db30f462717c24348af89c7aa5d19be787e8', 'message': 'Make tests in test_webservice run\n\nPreviously the tests in test_webservice were not being run as its\ntest directory was missing __init__.py. This patch also moves this file\nto congress/tests/api/\n\nChange-Id: Ie816aac0762b31655ee6028ffdd1ae4050c407aa\ncloses-bug: 1342957\n'}]",0,107497,2324db30f462717c24348af89c7aa5d19be787e8,17,4,4,4395,,,0,"Make tests in test_webservice run

Previously the tests in test_webservice were not being run as its
test directory was missing __init__.py. This patch also moves this file
to congress/tests/api/

Change-Id: Ie816aac0762b31655ee6028ffdd1ae4050c407aa
closes-bug: 1342957
",git fetch https://review.opendev.org/openstack/congress refs/changes/97/107497/4 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/api/test_webservice.py', 'congress/tests/api/__init__.py']",2,01a8fd3bb2cfac90bc8c9f36c10f0bdf5638afd6,bp/keystone-integration,,,1,1
openstack%2Fpython-keystoneclient~master~Ia0ecee0508c9a29774fb3b5af277876dde7448cd,openstack/python-keystoneclient,master,Ia0ecee0508c9a29774fb3b5af277876dde7448cd,Create HTTP methods mixin object,ABANDONED,2014-06-04 04:04:33.000000000,2014-07-17 21:43:51.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 8871}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-06-04 04:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/425179311416a7212ddcadc24be2bd2824449a08', 'message': 'Create HTTP methods mixin object\n\nThe pattern of having HTTP methods that simply call back to a request\nfunction with the method filled in is repeated in a number of places.\nAbstract that into something reusable.\n\nThere are no additional tests as there are no changes in functionality\nand the existing methods are well covered.\n\nChange-Id: Ia0ecee0508c9a29774fb3b5af277876dde7448cd\n'}, {'number': 2, 'created': '2014-06-10 22:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/7e9c3788b6278dc6bec31dfa6ce6e9134e449987', 'message': 'Create HTTP methods mixin object\n\nThe pattern of having HTTP methods that simply call back to a request\nfunction with the method filled in is repeated in a number of places.\nAbstract that into something reusable.\n\nThere are no additional tests as there are no changes in functionality\nand the existing methods are well covered.\n\nChange-Id: Ia0ecee0508c9a29774fb3b5af277876dde7448cd\n'}, {'number': 3, 'created': '2014-06-10 23:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/c7eb3269765612fde1e835a8b37eb560173024e2', 'message': 'Create HTTP methods mixin object\n\nThe pattern of having HTTP methods that simply call back to a request\nfunction with the method filled in is repeated in a number of places.\nAbstract that into something reusable.\n\nThere are no additional tests as there are no changes in functionality\nand the existing methods are well covered.\n\nChange-Id: Ia0ecee0508c9a29774fb3b5af277876dde7448cd\n'}, {'number': 4, 'created': '2014-06-11 23:14:33.000000000', 'files': ['keystoneclient/baseclient.py', 'keystoneclient/tests/test_baseclient.py', 'keystoneclient/httpclient.py', 'keystoneclient/session.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/de11a2f30abd412cbac9d8fbffc54085186edd43', 'message': 'Create HTTP methods mixin object\n\nThe pattern of having HTTP methods that simply call back to a request\nfunction with the method filled in is repeated in a number of places.\nAbstract that into something reusable.\n\nThere are no additional tests as there are no changes in functionality\nand the existing methods are well covered.\n\nChange-Id: Ia0ecee0508c9a29774fb3b5af277876dde7448cd\n'}]",12,97680,de11a2f30abd412cbac9d8fbffc54085186edd43,37,10,4,7191,,,0,"Create HTTP methods mixin object

The pattern of having HTTP methods that simply call back to a request
function with the method filled in is repeated in a number of places.
Abstract that into something reusable.

There are no additional tests as there are no changes in functionality
and the existing methods are well covered.

Change-Id: Ia0ecee0508c9a29774fb3b5af277876dde7448cd
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/80/97680/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/baseclient.py', 'keystoneclient/httpclient.py', 'keystoneclient/session.py']",3,425179311416a7212ddcadc24be2bd2824449a08,mixin,from keystoneclient import baseclientclass Session(baseclient.HttpMethodsBase):,"class Session(object): def head(self, url, **kwargs): return self.request(url, 'HEAD', **kwargs) def get(self, url, **kwargs): return self.request(url, 'GET', **kwargs) def post(self, url, **kwargs): return self.request(url, 'POST', **kwargs) def put(self, url, **kwargs): return self.request(url, 'PUT', **kwargs) def delete(self, url, **kwargs): return self.request(url, 'DELETE', **kwargs) def patch(self, url, **kwargs): return self.request(url, 'PATCH', **kwargs) ",32,56
openstack%2Ffuel-library~master~If8c64a565ebb86f545add145934d566d666ef073,openstack/fuel-library,master,If8c64a565ebb86f545add145934d566d666ef073,Change resource generation type,MERGED,2014-07-17 15:29:14.000000000,2014-07-17 21:33:46.000000000,2014-07-17 21:33:46.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2014-07-17 15:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/eb85e79b51511fe9cfe0a0a178d8ce50fe68d99b', 'message': 'Change resource generation type\n\nUse eval_generate to generate swift rings.\nThis will ensure that Ring_devices resource\nis completed only when all the Ring_*_devices\nis finished, thus ensuring that rebalance begins\nonly after all the devices were created.\n\nChange-Id: If8c64a565ebb86f545add145934d566d666ef073\nCloses-bug: #1305826\n'}, {'number': 2, 'created': '2014-07-17 17:48:40.000000000', 'files': ['deployment/puppet/swift/lib/puppet/type/ring_devices.rb', 'deployment/puppet/swift/manifests/proxy.pp', 'deployment/puppet/swift/manifests/storage/generic.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/65014034df4a6e31438fd5414ea0f6207cf3c4dc', 'message': 'Change resource generation type\n\nUse eval_generate to generate swift rings.\nThis will ensure that Ring_devices resource\nis completed only when all the Ring_*_devices\nis finished, thus ensuring that rebalance begins\nonly after all the devices were created.\n\nAlso pin services start to rebalance end.\n\nChange-Id: If8c64a565ebb86f545add145934d566d666ef073\nCloses-bug: #1305826\n'}]",0,107749,65014034df4a6e31438fd5414ea0f6207cf3c4dc,21,5,2,8786,,,0,"Change resource generation type

Use eval_generate to generate swift rings.
This will ensure that Ring_devices resource
is completed only when all the Ring_*_devices
is finished, thus ensuring that rebalance begins
only after all the devices were created.

Also pin services start to rebalance end.

Change-Id: If8c64a565ebb86f545add145934d566d666ef073
Closes-bug: #1305826
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/49/107749/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/swift/lib/puppet/type/ring_devices.rb'],1,eb85e79b51511fe9cfe0a0a178d8ce50fe68d99b,master, def eval_generate, def generate,1,1
openstack%2Fmonasca-ui~master~I5d6d64241bc4dd115a64da65f51255cf77fc9651,openstack/monasca-ui,master,I5d6d64241bc4dd115a64da65f51255cf77fc9651,setup.cfg and README name change,MERGED,2014-07-17 21:08:27.000000000,2014-07-17 21:18:30.000000000,2014-07-17 21:18:29.000000000,"[{'_account_id': 3}, {'_account_id': 11809}]","[{'number': 1, 'created': '2014-07-17 21:08:27.000000000', 'files': ['setup.cfg', 'README.md'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/9bbaec3af62c8a1c297b4b8ef80d0b3b6df4c242', 'message': 'setup.cfg and README name change\n\nChange-Id: I5d6d64241bc4dd115a64da65f51255cf77fc9651\n'}]",0,107831,9bbaec3af62c8a1c297b4b8ef80d0b3b6df4c242,7,2,1,12133,,,0,"setup.cfg and README name change

Change-Id: I5d6d64241bc4dd115a64da65f51255cf77fc9651
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/31/107831/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'README.md']",2,9bbaec3af62c8a1c297b4b8ef80d0b3b6df4c242,name-change,monasca-ui ========== Monasca UI This monasca UI is implemented as a horizon plugin that adds a panel.,mon-ui ====== Monitoring UI This monitoring UI is implemented as a horizon plugin that adds a panel.,7,7
openstack%2Ffuel-main~master~I46c9f293981dcd396b5d3666367c0ed48e641a23,openstack/fuel-main,master,I46c9f293981dcd396b5d3666367c0ed48e641a23,Added bootstrap support to Mellanox connectX 3-pro,MERGED,2014-06-19 07:45:18.000000000,2014-07-17 21:16:02.000000000,2014-07-17 21:16:02.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8797}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 10068}, {'_account_id': 11968}, {'_account_id': 12065}, {'_account_id': 12171}]","[{'number': 1, 'created': '2014-06-19 07:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0eefd85ff943e511759a7e1df3e75b61866028f2', 'message': 'Added bootstrap support to Mellanox connectX 3-pro\n\n1. libmlx4 to requirements RPM.\n2. module files extraction and module configurations for eth.\n3. module initialization in rc.local\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n\nChange-Id: I46c9f293981dcd396b5d3666367c0ed48e641a23\n'}, {'number': 2, 'created': '2014-07-14 13:36:45.000000000', 'files': ['requirements-rpm.txt', 'bootstrap/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9e0786b54f449d5afa266c3397b8d845999ae404', 'message': 'Added bootstrap support to Mellanox connectX 3-pro\n\n1. libmlx4 to requirements RPM.\n2. Module files extraction.\n3. Module configurations for Ethernet in /etc/ folder.\n   The new /etc/modprobe.d/libmlx.conf will load mellanox\n   Ethernet module (mlx4_en) only if the default core\n   module is loaded (mlx4_core).\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n\nChange-Id: I46c9f293981dcd396b5d3666367c0ed48e641a23\n'}]",3,101126,9e0786b54f449d5afa266c3397b8d845999ae404,36,14,2,11968,,,0,"Added bootstrap support to Mellanox connectX 3-pro

1. libmlx4 to requirements RPM.
2. Module files extraction.
3. Module configurations for Ethernet in /etc/ folder.
   The new /etc/modprobe.d/libmlx.conf will load mellanox
   Ethernet module (mlx4_en) only if the default core
   module is loaded (mlx4_core).

partially implements: blueprint mellanox-features-support
Signed-off-by: Aviram Bar-Haim <aviramb@mellanox.com>

Change-Id: I46c9f293981dcd396b5d3666367c0ed48e641a23
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/26/101126/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-rpm.txt', 'bootstrap/module.mk', 'bootstrap/sync/etc/rc.d/rc.local']",3,0eefd85ff943e511759a7e1df3e75b61866028f2,mellanox,# Adding Mellanox Eth Support modprobe mlx4_en ,,9,0
openstack%2Ftripleo-ci~master~I66ba23685ee23d975831fbbc4661f96ded037abf,openstack/tripleo-ci,master,I66ba23685ee23d975831fbbc4661f96ded037abf,Add some docs descibing tripleo CI,MERGED,2014-06-12 16:28:22.000000000,2014-07-17 20:59:46.000000000,2014-07-17 20:59:46.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 6554}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-06-12 16:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e67c01af5c8bc87aa8b75091d75635cf8fe466d8', 'message': 'Add some docs descibing tripleo CI\n\nIts not much but its a start.\n\nChange-Id: I66ba23685ee23d975831fbbc4661f96ded037abf\n'}, {'number': 2, 'created': '2014-06-13 12:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1a64ece0bf241028e7038e2531a167722373a0eb', 'message': 'Add some docs descibing tripleo CI\n\nIts not much but its a start.\n\nChange-Id: I66ba23685ee23d975831fbbc4661f96ded037abf\n'}, {'number': 3, 'created': '2014-07-01 11:29:25.000000000', 'files': ['docs/TripleO-ci.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b24bb0c6f31a01556286dce403e0dd73fd9cac93', 'message': 'Add some docs descibing tripleo CI\n\nIts not much but its a start.\n\nChange-Id: I66ba23685ee23d975831fbbc4661f96ded037abf\n'}]",21,99708,b24bb0c6f31a01556286dce403e0dd73fd9cac93,36,10,3,1926,,,0,"Add some docs descibing tripleo CI

Its not much but its a start.

Change-Id: I66ba23685ee23d975831fbbc4661f96ded037abf
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/08/99708/3 && git format-patch -1 --stdout FETCH_HEAD,['docs/TripleO-ci.rst'],1,e67c01af5c8bc87aa8b75091d75635cf8fe466d8,ci-docs,"Tripleo CI ========== Introduction ------------ TripleO CI is designed to run devtest[1] in a virtualized baremetal environment. We do this by pre creating a Test Environment (TE) containing a number on libvirt domains on their own ovs bridge and making them available to instances on a openstack cloud (ci-overcloud). Each CI job consists of a single worker node (kvm instance on an ci-overcloud) along with a TE. The TE is held in a ""locked"" state for the duration of the CI test and held exclusively for the worker node. the TripleO CI process is changing fairly quickly with plans in place to improve its reliability/speed and consistency[2] Infrastructure -------------- The tripleo CI infrastructure is currently run on 2 separate clouds (R1 and R2). Each region contains * ci-overcloud : traditional kvm openstack cloud * Should have an allocation of public floating IP available (1 per worker node) * Should have defined a test network which is managed by neutron in the ci-overcloud but should also be made available to TE hosts. * TE Hosts : each hosting X number of actual test environments Test Environments ----------------- Each test environment host (TE Host) contains a number of TE's (this number depends on resources available on the host). Each test environment will contain a seed libvirt domain along with a number of baremetal nodes e.g. :: $ sudo virsh list --all | grep _2 217 baremetalbrbm3_2 running - baremetalbrbm1_2 shut off - baremetalbrbm2_2 shut off 215 seed_2 running The seed has been defined with 2 nics, the first ""public interface"" is on an ovs-bridge (br-ctlplane) which is shared with seeds from other TE's and a physical nic, this will give the seed access to the ci-overcloud. The second ""private interface"" is on a ovs bridge specific to that TE and is shared with the interfaces from the other domains on its TE e.g. the private bridge of TE 2 above might look something like this :: Bridge ""brbm2"" Port ""vnet11"" Interface ""vnet10"" Port ""vnet10"" Interface ""vnet10"" Port ""brbm2"" Interface ""brbm2"" type: internal The MAC address for the TE Host has been used to register a port with neutron on the ci-overcloud this allows instances on the ci-overcloud to communicate with the TE host (to copy across images, start the seed etc...) The MAC address for the public interface of each TE seed on each TE hosts has also used to register a port with neutron on the ci-overcloud, this allows instances on the ci-overcloud to communicate with the seed during devtest. It also provides a route to the instances on the private bridge so the ci instances can communicate with the undercloud or overcloud. Each TE has associated with with a ""testenv-worker"". This worker registers itself with a geard broker. A ci instance can then request a TE via a geard broker. A testenv-worker will respond with details about its TE and remain ""locked"" until the ci instance releases it. CI Overcloud Test Sequence -------------------------- * Developer submits patch to gerrit * Zuul requests an instance on the ci-overcloud for each job it needs to run * Nodepool makes an instance available (it keeps a pool of nodes ready) * The ci node is handed over a jenkins server where the job is started * jenkins runs the script devstack-gate/devstack-vm-gate-wrap.sh[3], among other things devstack-gate sets the revision of repositories on the instance to the revision that needs to be tested (in /opt/stack/new/) * Once the instance has been setup the tripleo-ci/toci_gate_test.sh[4] is run, this is a wrapper around tripleo-ci primarily responsible for ensuring we don't continue with the rest of CI without an allocated TE * ./testenv-client is used to talk to geard * testenv-worker on one of the TE hosts will respond providing some json describing it's TE (including MAC's, IP's, resources etc...). This TE is now locked until CI is finished or a time-out occurs. * toci_devtest.sh is called with the details for the TE (in $TE_DATAFILE) * ssh key are installed on the ci instance (a private key was included in the TE json file), this will give us restricted access to do some operations on the TE Host * For each of the repositories in /opt/stack/new/ set DIB_REPOLOCATION_*, these are used during disk image builds (see the source-repositories element) * Run components from devtest - in as much as is possible this should be the same as a local devtest run with a few notable differences * libvirt domains are never undefined and redefined as the TE has been pre setup, instead they are simply destroyed * The seed image is copied over ssh to the TE host using dd * We ssh to the TE host to start the seed * When the seed boots it gets an IP from the ci-overcloud dhcp agent (we had registered its MAC with the overcloud) * For each instance started during the test grab a tarball containing relevant logs and config files * exit from toci_devtest.sh (releasing the TE) * Jenkins then archives off the instance all of the files in the workspace logs directory * The ci instance is deleted Infrastructure Setup -------------------- Setting up a ci-overcloud and TE hosts is currently a fairly manual process with a lot of work under way to help automate it. This section currently only gives pointers to various relevant scripts, but will be a lot more consumable soon as various scripts are matured. We also make the assumption here that you already have a running ironic ( or nova-bm) cloud with a number of available baremetal instances * deploying a ci overcloud * devtest_overcloud.sh can be used to deploy a ci-overcloud, see http://git.openstack.org/cgit/openstack/tripleo-image-elements/tree/elements/tripleo-cd/deploy-ci-overcloud * preparing a ci overcloud * Once an overcloud is deployed it requires certain images/networks/quotas etc... there is a script currently in progress to do this preparation to an overcloud https://review.openstack.org/#/c/90146/ * setting up TE hosts * TE host images need to be built and deployed https://review.openstack.org/#/c/90146/ References ---------- - [1] http://docs.openstack.org/developer/tripleo-incubator/devtest.html - [2] https://review.openstack.org/#/c/95026/ - [3] http://git.openstack.org/cgit/openstack-infra/devstack-gate/ - [4] http://git.openstack.org/cgit/openstack-infra/tripleo-ci/ ",,146,0
openstack%2Ftraining-guides~master~Ic70187b21655db55958fc5848009d663fbe6a928,openstack/training-guides,master,Ic70187b21655db55958fc5848009d663fbe6a928,Update the wiki link for Training Guides,MERGED,2014-07-17 05:00:12.000000000,2014-07-17 20:56:49.000000000,2014-07-17 20:56:49.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7007}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-07-17 05:00:12.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/a043015815f727aeb8ddabbb55e2e9fdc3604b49', 'message': 'Update the wiki link for Training Guides\n\nChange-Id: Ic70187b21655db55958fc5848009d663fbe6a928\n'}]",0,107559,a043015815f727aeb8ddabbb55e2e9fdc3604b49,8,4,1,11105,,,0,"Update the wiki link for Training Guides

Change-Id: Ic70187b21655db55958fc5848009d663fbe6a928
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/59/107559/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,a043015815f727aeb8ddabbb55e2e9fdc3604b49,,<https://wiki.openstack.org/wiki/Training-guides>`_.,<https://wiki.openstack.org/wiki/Training-manuals>`_.,1,1
openstack%2Fnova~master~I1f9ef23a8569252b5b6fa660d0d200b1702056d0,openstack/nova,master,I1f9ef23a8569252b5b6fa660d0d200b1702056d0,Cleanup and gate on hacking E713 rule,MERGED,2014-07-16 20:14:35.000000000,2014-07-17 20:55:01.000000000,2014-07-17 20:54:58.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-16 20:14:35.000000000', 'files': ['nova/exception.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/scheduler/filters/affinity_filter.py', 'nova/utils.py', 'nova/virt/vmwareapi/vm_util.py', 'tox.ini', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/51e604f87eadf7f14b37bcc6350900892ece8eca', 'message': 'Cleanup and gate on hacking E713 rule\n\nThis fixes the offending instances of the rule\nand removes it from the ignore list in tox.ini\nso that we can gate on the E713 rule.\n\nChange-Id: I1f9ef23a8569252b5b6fa660d0d200b1702056d0\n'}]",0,107486,51e604f87eadf7f14b37bcc6350900892ece8eca,13,7,1,6873,,,0,"Cleanup and gate on hacking E713 rule

This fixes the offending instances of the rule
and removes it from the ignore list in tox.ini
so that we can gate on the E713 rule.

Change-Id: I1f9ef23a8569252b5b6fa660d0d200b1702056d0
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/107486/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/scheduler/filters/affinity_filter.py', 'nova/utils.py', 'nova/virt/vmwareapi/vm_util.py', 'tox.ini', 'nova/api/openstack/compute/servers.py']",7,51e604f87eadf7f14b37bcc6350900892ece8eca,pep8-E713, if ('changePassword' not in body, if (not 'changePassword' in body,9,9
openstack%2Ffuel-astute~master~I2b71ec429ac1982f3df585423ca0818b294d8210,openstack/fuel-astute,master,I2b71ec429ac1982f3df585423ca0818b294d8210,Wipe each partition for all disks when removing nodes,MERGED,2014-07-17 18:36:36.000000000,2014-07-17 20:49:27.000000000,2014-07-17 20:40:12.000000000,"[{'_account_id': 3}, {'_account_id': 8776}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-17 18:36:36.000000000', 'files': ['mcagents/erase_node.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/9f1e69aa3a2fe7a6093fa50596d6931826d93a09', 'message': 'Wipe each partition for all disks when removing nodes\n\nIf partitions are not wiped then old formatted filesystems\nwill show up if a parititon is created at the same point as\nthe previous one. This will cause ceph-deploy to fail when\nbringing up an OSD. Ceph will see an XFS filesystem and the\ncorrect partition GUID and auto-mount the partition prior to\nactivating the OSD.\n\nChange-Id: I2b71ec429ac1982f3df585423ca0818b294d8210\nCloses-bug: #1323343\n'}]",0,107793,9f1e69aa3a2fe7a6093fa50596d6931826d93a09,11,4,1,8829,,,0,"Wipe each partition for all disks when removing nodes

If partitions are not wiped then old formatted filesystems
will show up if a parititon is created at the same point as
the previous one. This will cause ceph-deploy to fail when
bringing up an OSD. Ceph will see an XFS filesystem and the
correct partition GUID and auto-mount the partition prior to
activating the OSD.

Change-Id: I2b71ec429ac1982f3df585423ca0818b294d8210
Closes-bug: #1323343
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/93/107793/1 && git format-patch -1 --stdout FETCH_HEAD,['mcagents/erase_node.rb'],1,9f1e69aa3a2fe7a6093fa50596d6931826d93a09,bug/1323343," erase_partitions(dev[:name]) def erase_partitions(dev) Dir[""/dev/#{dev}[0-9]*""].each do |part| system(""dd if=/dev/zero of=#{part} bs=1M count=10 oflag=direct"") end end ",,7,0
openstack%2Fneutron-specs~master~I9cf7fc30dc4fbc0c1ac73bbd85b6d4983a8b0ee8,openstack/neutron-specs,master,I9cf7fc30dc4fbc0c1ac73bbd85b6d4983a8b0ee8,Cisco VPNaaS with in-band Cisco CSR router,MERGED,2014-07-03 20:11:51.000000000,2014-07-17 19:42:50.000000000,2014-07-17 19:42:50.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 6659}, {'_account_id': 6995}, {'_account_id': 7448}]","[{'number': 1, 'created': '2014-07-03 20:11:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/983230557e233dfb511622f4828f11e253b6fe73', 'message': 'Cisco VPNaaS with in-band Cisco CSR router\n\nBlueprint spec for enhancing the Cisco VPNaaS driver to\nuse the Cisco CSR router service VM as being introduced\nby the cisco-routing-service-vm.\n\nChange-Id: I9cf7fc30dc4fbc0c1ac73bbd85b6d4983a8b0ee8\nImplements: blueprint cisco-vpnaas-with-cisco-csr-router\n'}, {'number': 2, 'created': '2014-07-11 15:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4fc0569e79ed0b8c3a7e4490aeda16e76f475106', 'message': 'Cisco VPNaaS with in-band Cisco CSR router\n\nBlueprint spec for enhancing the Cisco VPNaaS driver to\nuse the Cisco CSR router service VM as being introduced\nby the cisco-routing-service-vm.\n\nChange-Id: I9cf7fc30dc4fbc0c1ac73bbd85b6d4983a8b0ee8\nImplements: blueprint cisco-vpnaas-with-cisco-csr-router\n'}, {'number': 3, 'created': '2014-07-15 19:29:30.000000000', 'files': ['specs/juno/cisco-vpnaas-with-cisco-csr-router.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ae5c33468bcfa701f1b53447fca786763f36d454', 'message': 'Cisco VPNaaS with in-band Cisco CSR router\n\nBlueprint spec for enhancing the Cisco VPNaaS driver to\nuse the Cisco CSR router service VM as being introduced\nby the cisco-routing-service-vm.\n\nIncludes update to remove dependency on other blueprints.\n\nChange-Id: I9cf7fc30dc4fbc0c1ac73bbd85b6d4983a8b0ee8\nImplements: blueprint cisco-vpnaas-with-cisco-csr-router\n'}]",6,104668,ae5c33468bcfa701f1b53447fca786763f36d454,29,8,3,6659,,,0,"Cisco VPNaaS with in-band Cisco CSR router

Blueprint spec for enhancing the Cisco VPNaaS driver to
use the Cisco CSR router service VM as being introduced
by the cisco-routing-service-vm.

Includes update to remove dependency on other blueprints.

Change-Id: I9cf7fc30dc4fbc0c1ac73bbd85b6d4983a8b0ee8
Implements: blueprint cisco-vpnaas-with-cisco-csr-router
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/68/104668/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/cisco-vpnaas-with-cisco-csr-router.rst'],1,983230557e233dfb511622f4828f11e253b6fe73,bp/spec,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Cisco VPNaaS with in-band Cisco CSR router ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/cisco-vpnaas-with-cisco-csr-router Enhance the Cisco IPSec site-to-site VPNaaS solution, by integrating it with a Cisco Cloud Services Router (CSR) running as a Neutron router. Problem description =================== In the current Proof of Concept Cisco VPNaaS, a Cisco CSR VM runs out-of-band from OpenStack, and parallel to a reference Neutron router. The Cisco CSR is started manually, and independently of OpenStack. the router is statically provisioned and information on the Cisco CSR is stored in an .ini file for use by the Cisco VPNaaS driver. When a VPN IPSec site-to-site connection is established, the VPNaaS drivers use the .ini information to communicate with the Cisco CSR and configure the VPN IPSec site-to-site connection. A packet redirect is configured on the Neutron router, to send all packets for the remote end, to the Cisco CSR. The issues with this are: * Cisco CSR is manually started and provisioned for use. * Static configuration of all Cisco CSRs is established before Neutron startup. * We are effectively using two routers to provide VPNaaS capability. Proposed change =============== A separate blueprint, cisco-routing-service-vm, will be providing a Cisco CSR VM as a Neutron router, dynamically creating and provisioning the Cisco CSR when a router specifying this type is created. This blueprint proposes to update the Cisco VPNaaS driver to work with this ""in-band"" Cisco CSR. The VPNaaS driver will obtain information (dynamically) on the Cisco CSR from Neutron, so that the VPN IPSec connection can then be provisioned. Combined, these two blueprints will allow automatic creation and provisioning of Cisco CSRs, dynamic provisioning of VPNaaS connections, and eliminate the need for a second router and packet redirection. Alternatives ------------ With the current out-of-band Cisco CSR, the VPNaaS driver could re-read the .ini file whenever it changes to obtain updated router information. That allows dynamically creating VPNaaS connections, but still requires manual start-up and provisioning of the CSR (and use of dual routers). Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- Eliminates the need for operator to manually start and provision the Cisco CSR and create the .ini file. Performance Impact ------------------ No effect to the VPNaaS performance. Other deployer impact --------------------- Deployment becomes much easier. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: pmichali Work Items ---------- * Removal of device driver code that reads the .ini file with Cisco CSR info. * Modification of service driver to obtain Cisco CSR info and pass to device driver. * Modification of the device driver to use the passed information, instead of .ini file info. * Update unit tests to reflect changes made. Dependencies ============ * Requires the cisco-routing-service-vm blueprint implementation, which provides the Cisco CSR as a Neutron router and manages the life-cycle of the router. Testing ======= Unit tests will be updated accordingly. The cisco-routing-service-vm BP will have Tempest tests. Currently, there are no Tempest fucntional tests for VPNaaS, but as they become available, third-party tests will be created for the Cisco CSR implementation. Documentation Impact ==================== None. References ========== * Out-of-band VPN setup: http://docwiki.cisco.com/wiki/Install_and_Setup_of_Cisco_Cloud_Services_Router_(CSR)_for_OpenStack_VPN ",,161,0
openstack%2Fnova~master~I59e748db7a943d5a36d75ef63b2a1ec458c58937,openstack/nova,master,I59e748db7a943d5a36d75ef63b2a1ec458c58937,Deallocate the network if rescheduling for Ironic,MERGED,2014-07-16 21:48:03.000000000,2014-07-17 19:36:47.000000000,2014-07-17 19:36:44.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5805}, {'_account_id': 7461}, {'_account_id': 8688}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-16 21:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bda769e8f4e5e6917c2915caec6f15eaabe5a9dc', 'message': ""Deallocate the network if rescheduling for Ironic\n\nIronic (and any other driver that limits the allowed MAC addresses\non an instance will fail if the rescheduled instance runs on a node\nthat has a different constraint for MAC addresses. To deal with this\nwe deallocate the network (rather than e.g. trying to lazy update it)\nbecause Nova can't know what the implications of leaving the network\nallocated are *when MAC limits are in place* - and we expect them to\nbe in place when external systems are constrained, so being conservative is a\ngood idea.\n\nChange-Id: I59e748db7a943d5a36d75ef63b2a1ec458c58937\nCloses-Bug: #1342919\n""}, {'number': 2, 'created': '2014-07-16 22:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8cda17be0db6dba81f701620688aea821eb3db9', 'message': ""Deallocate the network if rescheduling for Ironic\n\nIronic (and any other driver that limits the allowed MAC addresses\non an instance will fail if the rescheduled instance runs on a node\nthat has a different constraint for MAC addresses. To deal with this\nwe deallocate the network (rather than e.g. trying to lazy update it)\nbecause Nova can't know what the implications of leaving the network\nallocated are *when MAC limits are in place* - and we expect them to\nbe in place when external systems are constrained, so being\nconservative is a good idea.\n\nThere were two places at fault here: the deprecated codepath for\nbuilding instances, and the new one which checked\ndhcp_options_for_instance which is not always set, even when macs\nare being set - and macs is the key issue. Drivers can always update\nDHCP options on each boot to deal with a new host being used.\n\nChange-Id: I59e748db7a943d5a36d75ef63b2a1ec458c58937\nCloses-Bug: #1342919\n""}, {'number': 3, 'created': '2014-07-16 23:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48e7f0a6e04d98d20d0ae5a84f1724ca888dab1b', 'message': ""Deallocate the network if rescheduling for Ironic\n\nIronic (and any other driver that limits the allowed MAC addresses\non an instance will fail if the rescheduled instance runs on a node\nthat has a different constraint for MAC addresses. To deal with this\nwe deallocate the network (rather than e.g. trying to lazy update it)\nbecause Nova can't know what the implications of leaving the network\nallocated are *when MAC limits are in place* - and we expect them to\nbe in place when external systems are constrained, so being\nconservative is a good idea.\n\nHowever the code to trigger this looked at dhcp options (which drivers\ncan safely update pre-boot) not MAC addresses (which can cause conflicts\nin Neutron if left in-place).\n\nChange-Id: I59e748db7a943d5a36d75ef63b2a1ec458c58937\nCloses-Bug: #1342919\n""}, {'number': 4, 'created': '2014-07-17 02:07:05.000000000', 'files': ['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/963ad71af4750e28745b6de262da11816b403801', 'message': ""Deallocate the network if rescheduling for Ironic\n\nIronic (and any other driver that limits the allowed MAC addresses\non an instance will fail if the rescheduled instance runs on a node\nthat has a different constraint for MAC addresses. To deal with this\nwe deallocate the network (rather than e.g. trying to lazy update it)\nbecause Nova can't know what the implications of leaving the network\nallocated are *when MAC limits are in place* - and we expect them to\nbe in place when external systems are constrained, so being\nconservative is a good idea.\n\nHowever the code to trigger this looked at dhcp options (which drivers\ncan safely update pre-boot) not MAC addresses (which can cause conflicts\nin Neutron if left in-place).\n\nChange-Id: I59e748db7a943d5a36d75ef63b2a1ec458c58937\nCloses-Bug: #1342919\n""}]",3,107511,963ad71af4750e28745b6de262da11816b403801,27,9,4,4190,,,0,"Deallocate the network if rescheduling for Ironic

Ironic (and any other driver that limits the allowed MAC addresses
on an instance will fail if the rescheduled instance runs on a node
that has a different constraint for MAC addresses. To deal with this
we deallocate the network (rather than e.g. trying to lazy update it)
because Nova can't know what the implications of leaving the network
allocated are *when MAC limits are in place* - and we expect them to
be in place when external systems are constrained, so being
conservative is a good idea.

However the code to trigger this looked at dhcp options (which drivers
can safely update pre-boot) not MAC addresses (which can cause conflicts
in Neutron if left in-place).

Change-Id: I59e748db7a943d5a36d75ef63b2a1ec458c58937
Closes-Bug: #1342919
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/107511/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,bda769e8f4e5e6917c2915caec6f15eaabe5a9dc,patch107511," def cleanup_network(network_info, context, instance, deallocate): """"""Helper to wrap up our use of network_info."""""" if network_info is not None: network_info.wait(do_raise=False) if deallocate: try: self._deallocate_network(context, instance) except Exception: msg = _('Failed to dealloc network ' 'for failed instance') LOG.exception(msg, instance=instance) macs = None cleanup_network(network_info, context, instance, True) cleanup_network(network_info, context, instance, False) cleanup_network(network_info, context, instance, True) cleanup_network(network_info, context, instance, macs is not None) # try to re-schedule instance:"," # Make sure the async call finishes if network_info is not None: network_info.wait(do_raise=False) try: self._deallocate_network(context, instance) except Exception: msg = _('Failed to dealloc network ' 'for deleted instance') LOG.exception(msg, instance=instance) # Make sure the async call finishes if network_info is not None: network_info.wait(do_raise=False) if network_info is not None: network_info.wait(do_raise=False) try: self._deallocate_network(context, instance) except Exception: msg = _('Failed to dealloc network ' 'for failed instance') LOG.exception(msg, instance=instance) # try to re-schedule instance: # Make sure the async call finishes if network_info is not None: network_info.wait(do_raise=False)",16,23
openstack%2Fpython-troveclient~master~I11796e8aa6e475790838db44206e8ed85ebb1505,openstack/python-troveclient,master,I11796e8aa6e475790838db44206e8ed85ebb1505,Use JSON instead of json in the parameter descriptions,MERGED,2014-07-01 13:17:57.000000000,2014-07-17 19:36:00.000000000,2014-07-17 19:35:59.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8871}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-07-01 13:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/a36aa07c4868cac0230331888646d31a55128095', 'message': 'Use JSON instead of json in the parameter descriptions\n\nChange-Id: I11796e8aa6e475790838db44206e8ed85ebb1505\n'}, {'number': 2, 'created': '2014-07-16 10:43:51.000000000', 'files': ['README.rst', 'troveclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/50361060467586f2fa4879ae24d618a4fbfa8f5c', 'message': ""Use JSON instead of json in the parameter descriptions\n\nThis change only changes the wording of a help string. It should\nbe 'JSON' instead of 'json'.\n\nChange-Id: I11796e8aa6e475790838db44206e8ed85ebb1505\n""}]",2,103882,50361060467586f2fa4879ae24d618a4fbfa8f5c,35,8,2,167,,,0,"Use JSON instead of json in the parameter descriptions

This change only changes the wording of a help string. It should
be 'JSON' instead of 'json'.

Change-Id: I11796e8aa6e475790838db44206e8ed85ebb1505
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/82/103882/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'troveclient/shell.py']",2,a36aa07c4868cac0230331888646d31a55128095,json_to_JSON, help='Output JSON instead of prettyprint. ', help='Output json instead of prettyprint. ',2,2
openstack%2Fsecurity-doc~master~Id341af16cbdbc5437303951d45ed6a3c321eabb3,openstack/security-doc,master,Id341af16cbdbc5437303951d45ed6a3c321eabb3,Add reference to SSL/TLS chapter,MERGED,2014-07-17 19:12:06.000000000,2014-07-17 19:30:53.000000000,2014-07-17 19:30:52.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7063}]","[{'number': 1, 'created': '2014-07-17 19:12:06.000000000', 'files': ['security-guide/ch_compute.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/c9e5124872a1bc5c209ac4cb8e75536c99eae0c4', 'message': 'Add reference to SSL/TLS chapter\n\nWhile discussing about lack of encryption for remote desktop,\nincorrect and obsolete information was provided. This checkin fixes it\nby removing incorrect statement and providing a link to the chapter on\nSSL/ TLS\n\nCloses-Bug: #1342280\nChange-Id: Id341af16cbdbc5437303951d45ed6a3c321eabb3\n'}]",0,107802,c9e5124872a1bc5c209ac4cb8e75536c99eae0c4,8,3,1,8560,,,0,"Add reference to SSL/TLS chapter

While discussing about lack of encryption for remote desktop,
incorrect and obsolete information was provided. This checkin fixes it
by removing incorrect statement and providing a link to the chapter on
SSL/ TLS

Closes-Bug: #1342280
Change-Id: Id341af16cbdbc5437303951d45ed6a3c321eabb3
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/02/107802/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_compute.xml'],1,c9e5124872a1bc5c209ac4cb8e75536c99eae0c4,bug/1342280," SSL can be enabled to encrypt the VNC traffic. Please refer to <link linkend=""introduction-to-ssl-tls"">Introduction to SSL/TLS</link> for appropriate recommendations.</para>", SSL can be enabled to encrypt the VNC traffic.</para>,1,1
openstack%2Fheat~master~I0068c1eaf19464c39348823160b665f538fec583,openstack/heat,master,I0068c1eaf19464c39348823160b665f538fec583,Adding own child_template for AutoScalingGroup,MERGED,2014-05-23 11:20:18.000000000,2014-07-17 19:22:53.000000000,2014-07-17 19:22:52.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6800}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8435}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-05-23 11:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5e81a92b0e41e776612f1011d5478f0ec14793a7', 'message': 'Adding own child_template for AutoScalingGroup\n\nResource AutoScalingGroup fails during preview, because uses parent\nchild_template function function with invalid property Size. So\nAutoScalingGroup should has own child_template with correct properties.\n\nChange-Id: I0068c1eaf19464c39348823160b665f538fec583\nCloses-Bug: #1322583\n'}, {'number': 2, 'created': '2014-05-23 12:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b8dc63378bd378d78639f94655b659f60df45fd0', 'message': 'Adding own child_template for AutoScalingGroup\n\nResource AutoScalingGroup fails during preview, because uses parent\nchild_template function function with invalid property Size. So\nAutoScalingGroup should has own child_template with correct properties.\n\nChange-Id: I0068c1eaf19464c39348823160b665f538fec583\nCloses-Bug: #1322583\n'}, {'number': 3, 'created': '2014-06-02 06:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/685fc66f3d0a4235cdb1ba1c7701c9d187e55aca', 'message': 'Adding own child_template for AutoScalingGroup\n\nResource AutoScalingGroup fails during preview, because uses parent\nchild_template function function with invalid property Size. So\nAutoScalingGroup should has own child_template with correct properties.\n\nChange-Id: I0068c1eaf19464c39348823160b665f538fec583\nCloses-Bug: #1322583\n'}, {'number': 4, 'created': '2014-06-16 13:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3cf6908b9f7320f0672c0ecc64ca35338a2bf9e3', 'message': 'Adding own child_template for AutoScalingGroup\n\nResource AutoScalingGroup fails during preview, because it uses the\nparent child_template function with an invalid property Size. So\nAutoScalingGroup should have its own child_template with correct\nproperties.\n\nChange-Id: I0068c1eaf19464c39348823160b665f538fec583\nCloses-Bug: #1322583\n'}, {'number': 5, 'created': '2014-06-18 08:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/05a6462e352aebe498ad7ff0652e2eef32bc911f', 'message': 'Adding own child_template for AutoScalingGroup\n\nResource AutoScalingGroup fails during preview, because it uses the\nparent child_template function with an invalid property Size. So\nAutoScalingGroup should have its own child_template with correct\nproperties.\n\nChange-Id: I0068c1eaf19464c39348823160b665f538fec583\nCloses-Bug: #1322583\n'}, {'number': 6, 'created': '2014-06-20 11:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/89735486b1bd6b67e18624d660201805cc497021', 'message': 'Adding own child_template for AutoScalingGroup\n\nResource AutoScalingGroup fails during preview, because it uses the\nparent child_template function with an invalid property Size. So\nAutoScalingGroup should have its own child_template with correct\nproperties. Also new method child_template is used during handle_create.\n\nChange-Id: I0068c1eaf19464c39348823160b665f538fec583\nCloses-Bug: #1322583\n'}, {'number': 7, 'created': '2014-07-08 07:47:35.000000000', 'files': ['heat/engine/resources/autoscaling.py', 'heat/tests/test_autoscaling.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/042eb7472cf1842bfc56cdc60b45b60a23285b95', 'message': 'Adding own child_template for AutoScalingGroup\n\nResource AutoScalingGroup fails during preview, because it uses the\nparent child_template function with an invalid property Size. So\nAutoScalingGroup should have its own child_template with correct\nproperties. Also new method child_template is used during handle_create.\n\nChange-Id: I0068c1eaf19464c39348823160b665f538fec583\nCloses-Bug: #1322583\n'}]",13,95142,042eb7472cf1842bfc56cdc60b45b60a23285b95,68,10,7,6577,,,0,"Adding own child_template for AutoScalingGroup

Resource AutoScalingGroup fails during preview, because it uses the
parent child_template function with an invalid property Size. So
AutoScalingGroup should have its own child_template with correct
properties. Also new method child_template is used during handle_create.

Change-Id: I0068c1eaf19464c39348823160b665f538fec583
Closes-Bug: #1322583
",git fetch https://review.opendev.org/openstack/heat refs/changes/42/95142/6 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/autoscaling.py', 'heat/tests/test_autoscaling.py']",2,5e81a92b0e41e776612f1011d5478f0ec14793a7,95142," def test_child_template(self): json_snippet = {'Properties': {'MinSize': 2, 'MaxSize': 5, 'LaunchConfigurationName': 'foo'}} t = template_format.parse(as_template) stack = utils.parse_stack(t, params=self.params) rsrc = asc.AutoScalingGroup('asg', json_snippet, stack) rsrc._create_template = mock.Mock(return_value='tpl') self.assertEqual('tpl', rsrc.child_template()) rsrc._create_template.assert_called_once_with(2) ",,20,0
openstack%2Fpython-keystoneclient~master~I33378512593a0cdbc0db0def171b66911aba8708,openstack/python-keystoneclient,master,I33378512593a0cdbc0db0def171b66911aba8708,Sync with oslo-incubator fd90c34a9,MERGED,2014-07-01 20:56:40.000000000,2014-07-17 19:22:50.000000000,2014-07-17 19:22:49.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 7191}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-07-01 20:56:40.000000000', 'files': ['keystoneclient/openstack/common/uuidutils.py', 'keystoneclient/openstack/common/apiclient/exceptions.py', 'keystoneclient/openstack/common/apiclient/base.py', 'keystoneclient/openstack/common/timeutils.py', 'keystoneclient/openstack/common/jsonutils.py', 'keystoneclient/openstack/common/gettextutils.py', 'keystoneclient/openstack/common/apiclient/fake_client.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/a94050f446deb2cc58c069f2226037852deed96d', 'message': ""Sync with oslo-incubator fd90c34a9\n\nThis syncs python-keystoneclient with oslo-incubator commit hash\nfd90c34a914ef98e0c7ccdbf823d9b6d04aa436b\n\nFirst, remove the existing code to cleanup:\n    $ rm -r keystoneclient/openstack/*\n\nThen, sync from oslo-incubator:\n    $ python update.py ../python-keystoneclient\n\nCommits since last sync (caed79d):\n----------------------------------\nde4adbc pep8: fixed multiple violations\ne42e77f Restore UUID and human-ID bash completion\n250cd88 Fixed a new pep8 error and a small typo\n9e88af1 fixed typos found by RETF rules\n0d7296f Add kwargs to jsonutils.load(s) functions\n822e09b Don't slugify names that don't exist\n\nChange-Id: I33378512593a0cdbc0db0def171b66911aba8708\n""}]",0,103997,a94050f446deb2cc58c069f2226037852deed96d,13,4,1,6486,,,0,"Sync with oslo-incubator fd90c34a9

This syncs python-keystoneclient with oslo-incubator commit hash
fd90c34a914ef98e0c7ccdbf823d9b6d04aa436b

First, remove the existing code to cleanup:
    $ rm -r keystoneclient/openstack/*

Then, sync from oslo-incubator:
    $ python update.py ../python-keystoneclient

Commits since last sync (caed79d):
----------------------------------
de4adbc pep8: fixed multiple violations
e42e77f Restore UUID and human-ID bash completion
250cd88 Fixed a new pep8 error and a small typo
9e88af1 fixed typos found by RETF rules
0d7296f Add kwargs to jsonutils.load(s) functions
822e09b Don't slugify names that don't exist

Change-Id: I33378512593a0cdbc0db0def171b66911aba8708
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/97/103997/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/openstack/common/uuidutils.py', 'keystoneclient/openstack/common/apiclient/exceptions.py', 'keystoneclient/openstack/common/apiclient/base.py', 'keystoneclient/openstack/common/timeutils.py', 'keystoneclient/openstack/common/jsonutils.py', 'keystoneclient/openstack/common/apiclient/fake_client.py', 'keystoneclient/openstack/common/gettextutils.py']",7,a94050f446deb2cc58c069f2226037852deed96d,oslo-config-fixture," for (locale_, alias) in six.iteritems(aliases): if locale_ in language_list and alias not in language_list:"," for (locale, alias) in six.iteritems(aliases): if locale in language_list and alias not in language_list:",69,14
openstack%2Fhorizon~master~Iec3fb81e1fd85c653418b27d54b10c439fb3fa30,openstack/horizon,master,Iec3fb81e1fd85c653418b27d54b10c439fb3fa30,Initial support for datastore in Horizon,MERGED,2014-04-28 20:01:23.000000000,2014-07-17 19:22:46.000000000,2014-07-17 19:22:45.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1925}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 5293}, {'_account_id': 5623}, {'_account_id': 6268}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 9746}, {'_account_id': 9750}, {'_account_id': 9895}, {'_account_id': 9981}, {'_account_id': 10139}, {'_account_id': 10295}]","[{'number': 10, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0c60fe51dcb1bef7d96a8b958c717265299747a5', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type and version dropdown in Launch Instance\nAdded datastore type and version in Instance List and Details\n\nUpdated tox to use latest (master) python-troveclient (needed for datastore api)\n\nAdded unittests\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 11, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/540ae1f662520d2b72a9a41e3731a7ef9ed73db7', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type and version dropdown in Launch Instance\nAdded datastore type and version in Instance List and Details\n\nUpdated tox to use latest (master) python-troveclient (needed for datastore api)\n\nAdded unittests\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 8, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b1e327fe38fcb1722b58600857b6cb0c3e4d6930', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type and version dropdown in Launch Instance\nAdded datastore type and version in Instance List and Details\n\nUpdated tox to use latest (master) python-troveclient (needed for datastore api)\n\nAdded unittests\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 9, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e16239f3e26db6c74f26417a6d09b2722d5cb250', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type and version dropdown in Launch Instance\nAdded datastore type and version in Instance List and Details\n\nUpdated tox to use latest (master) python-troveclient (needed for datastore api)\n\nAdded unittests\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 14, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3323a2f44c2cc75a003820f67a9629f0dd5d6b9f', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type dropdown in Launch Instance\nAdded datastore version dropdown in Launch Instance\n\nAdded datastore type and version columns in Instance Table\n\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nThe following behavior has been implemented for Launch Instance:\n- Initially, only the datastore type dropdown is shown\n- If there is only 1 datastore type, it will be auto selected\n- Once a datastore type is selected, the datastore version dropdown will appear\n- Datastore versions will be populated dynamically per the datastore type chosen\n- If there is only 1 datastore version, it will be auto selected\n- Last chosen datastore version (for that datastore type) will be saved when switching between the various datastore types\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 15, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/95aff619ffdc36363cb752da646cf8a9dab55ca5', 'message': 'Initial support for datastore in Horizon (using 2 dropdowns)\n\nAdded datastore type dropdown in Launch Instance\nAdded datastore version dropdown in Launch Instance\n\nAdded datastore type and version columns in Instance Table\n\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nThe following behavior has been implemented for Launch Instance:\n- Initially, only the datastore type dropdown is shown\n- If there is only 1 datastore type, it will be auto selected\n- Once a datastore type is selected, the datastore version dropdown will appear\n- Datastore versions will be populated dynamically per the datastore type chosen\n- If there is only 1 datastore version, it will be auto selected\n- Last chosen datastore version (for that datastore type) will be saved when switching between the various datastore types\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 12, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0ecfb7be6035034061140942c7d5f1540e54440c', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type dropdown in Launch Instance\nAdded datastore version dropdown in Launch Instance\n\nAdded datastore type and version columns in Instance Table\n\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nThe following behavior has been implemented for Launch Instance:\n- Initially, only the datastore type dropdown is shown\n- If there is only 1 datastore type, it will be auto selected\n- Once a datastore type is selected, the datastore version dropdown will appear\n- Datastore versions will be populated dynamically per the datastore type chosen\n- If there is only 1 datastore version, it will be auto selected\n- Last chosen datastore version (for that datastore type) will be saved when switching between the various datastore types\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 13, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/72791da73c968f14a2d559fcb69a739e642f2138', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type dropdown in Launch Instance\nAdded datastore version dropdown in Launch Instance\n\nAdded datastore type and version columns in Instance Table\n\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nThe following behavior has been implemented for Launch Instance:\n- Initially, only the datastore type dropdown is shown\n- If there is only 1 datastore type, it will be auto selected\n- Once a datastore type is selected, the datastore version dropdown will appear\n- Datastore versions will be populated dynamically per the datastore type chosen\n- If there is only 1 datastore version, it will be auto selected\n- Last chosen datastore version (for that datastore type) will be saved when switching between the various datastore types\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/89c0bba73393cf1b04189117744142eeb423cb49', 'message': 'Initial support for datastore in Horizon\n\nAdds datastore type and version dropdown in Launch Instance\nAdds datastore type and version in Instance List and Details\n\nUpdate tox to use latest (master) python-troveclient (needed for datastore api)\n\nImplements: blueprint datastore-support\n\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/298898ad8bc8a974c8d2fb21e8a8eb76be7779b4', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type and version dropdown in Launch Instance\nAdded datastore type and version in Instance List and Details\n\nUpdated tox to use latest (master) python-troveclient (needed for datastore api)\n\nAdded unit tests\n\nImplements: blueprint datastore-support\n\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/918cffbca48f22295bd160730b1200319825a304', 'message': 'Initial support for datastore in Horizon\n\nAdds datastore type and version dropdown in Launch Instance\nAdds datastore type and version in Instance List and Details\n\nImplements: blueprint datastore-support\n\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 6, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/04e6250b0efd06072d4b50463915f93713967c26', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type and version dropdown in Launch Instance\nAdded datastore type and version in Instance List and Details\n\nUpdated tox to use latest (master) python-troveclient (needed for datastore api)\n\nAdded unit tests\n\nImplements: blueprint datastore-support\n\nAuthor:   Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 7, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b9088744346b5b7128ad32bd12ec3b957c71a574', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type and version dropdown in Launch Instance\nAdded datastore type and version in Instance List and Details\n\nUpdated tox to use latest (master) python-troveclient (needed for datastore api)\n\nAdded unit tests\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/090c4e38a8f8fde57faca34181764b0924f19b02', 'message': 'Initial support for datastore in Horizon\n\nAdded datastore type and version dropdown in Launch Instance\nAdded datastore type and version in Instance List and Details\n\nUpdated tox to use latest (master) python-troveclient (needed for datastore api)\n\nAdded unit tests\n\nImplements: blueprint datastore-support\n\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 5, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f62aaeb52ec1bb8008946a4fe15ee356a1d541a7', 'message': 'Author:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\n\nInitial support for datastore in Horizon\n\nAdded datastore type and version dropdown in Launch Instance\nAdded datastore type and version in Instance List and Details\n\nUpdated tox to use latest (master) python-troveclient (needed for datastore api)\n\nAdded unit tests\n\nImplements: blueprint datastore-support\n\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n'}, {'number': 16, 'created': '2014-06-11 19:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a762bb64d15e0dbab579ebb8f3aa3c8be096d049', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nPatchset #16+ has single dropdown approach with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nPatchset #15 has double dropdown approach with the following behavior:\n- Initially, only the datastore type dropdown is shown\n- If there is only 1 datastore type, it will be auto selected\n- Once a datastore type is selected, the datastore version dropdown will appear\n- Datastore versions will be populated dynamically per the datastore type chosen\n- If there is only 1 datastore version, it will be auto selected\n- Last chosen datastore version (for that datastore type) will be saved when switching between the various datastore types\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 17, 'created': '2014-06-11 19:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/abecc2eda07ccd7dca77eb16969186b7a15cafd3', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nPatchset #16+ has single dropdown approach with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nPatchset #15 has double dropdown approach with the following behavior:\n- Initially, only the datastore type dropdown is shown\n- If there is only 1 datastore type, it will be auto selected\n- Once a datastore type is selected, the datastore version dropdown will appear\n- Datastore versions will be populated dynamically per the datastore type chosen\n- If there is only 1 datastore version, it will be auto selected\n- Last chosen datastore version (for that datastore type) will be saved when switching between the various datastore types\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 18, 'created': '2014-06-12 20:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0429efa44ae28ff4babf5569a29d1f36189bc371', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nPatchset #16+ has single dropdown approach with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nPatchset #15 has double dropdown approach with the following behavior:\n- Initially, only the datastore type dropdown is shown\n- If there is only 1 datastore type, it will be auto selected\n- Once a datastore type is selected, the datastore version dropdown will appear\n- Datastore versions will be populated dynamically per the datastore type chosen\n- If there is only 1 datastore version, it will be auto selected\n- Last chosen datastore version (for that datastore type) will be saved when switching between the various datastore types\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 19, 'created': '2014-06-18 19:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6f7c3e8a4056eadb06b7c415f646204f99e71f3f', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nPatchset #16+ has single dropdown approach with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nPatchset #15 has double dropdown approach with the following behavior:\n- Initially, only the datastore type dropdown is shown\n- If there is only 1 datastore type, it will be auto selected\n- Once a datastore type is selected, the datastore version dropdown will appear\n- Datastore versions will be populated dynamically per the datastore type chosen\n- If there is only 1 datastore version, it will be auto selected\n- Last chosen datastore version (for that datastore type) will be saved when switching between the various datastore types\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 20, 'created': '2014-06-18 20:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0ebcb21c0d6720c361f0a9d2cbec0021899c89a8', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nPatchset #16+ has single dropdown approach with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nPatchset #15 has double dropdown approach with the following behavior:\n- Initially, only the datastore type dropdown is shown\n- If there is only 1 datastore type, it will be auto selected\n- Once a datastore type is selected, the datastore version dropdown will appear\n- Datastore versions will be populated dynamically per the datastore type chosen\n- If there is only 1 datastore version, it will be auto selected\n- Last chosen datastore version (for that datastore type) will be saved when switching between the various datastore types\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 21, 'created': '2014-06-19 06:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4197d1947f5f35bcb2835e17edb2fd6712a5bb3d', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 22, 'created': '2014-06-26 21:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/67f359d4e8816f147b29afb797c0f177d5fbf864', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 23, 'created': '2014-06-26 22:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/50ff473fe1597b1c16b55d1b6ace524206a6f209', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 24, 'created': '2014-06-27 17:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4060f2ea4e8f33c6e5c251c3375f12a1de66e93d', 'message': ""Initial support for datastore in horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 25, 'created': '2014-07-07 18:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4c8aaae95bdd55165a70356ec4671e8d113ad1e9', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 26, 'created': '2014-07-07 18:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/82be3cb1ed535d9dc4a8afa18c9ca035b28a1576', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 27, 'created': '2014-07-08 21:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/454fbb41ece24f044c55d69e005eb6da7e99fc44', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 28, 'created': '2014-07-08 23:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/64f736e30039ba48ff6e920a3cfec575dd36fecb', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 29, 'created': '2014-07-09 19:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/186c88c5d042270b99f391883fa964fc5de83b97', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 30, 'created': '2014-07-09 21:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/46c12cca78f0bfeba6b6e51089a886d6e665fee3', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 31, 'created': '2014-07-09 22:05:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e17e1581f955ed0c57316af58e1a7186af19febe', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 32, 'created': '2014-07-14 22:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c5dd8217082ad4b35a15f3935a30ddd72639367d', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 33, 'created': '2014-07-16 21:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/19da7cd35c2d53da1871394ded13d0bae755cd9c', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 34, 'created': '2014-07-16 22:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8efac4cbabf95c36bf79c303df1b46d414993118', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 35, 'created': '2014-07-17 04:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3d7e567449e746dc63f7091be8ca8f20b278ce75', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}, {'number': 36, 'created': '2014-07-17 16:08:53.000000000', 'files': ['openstack_dashboard/dashboards/project/databases/tabs.py', 'openstack_dashboard/dashboards/project/databases/templates/databases/_detail_overview_redis.html', 'openstack_dashboard/api/trove.py', 'openstack_dashboard/dashboards/project/databases/templates/databases/_detail_overview_mysql.html', 'openstack_dashboard/dashboards/project/databases/templates/databases/_detail_overview_cassandra.html', 'openstack_dashboard/dashboards/project/databases/templates/databases/_detail_overview_couchbase.html', 'openstack_dashboard/dashboards/project/databases/templates/databases/_detail_overview_mongodb.html', 'openstack_dashboard/dashboards/project/databases/workflows/create_instance.py', 'openstack_dashboard/dashboards/project/databases/tables.py', 'openstack_dashboard/dashboards/project/databases/tests.py', 'openstack_dashboard/dashboards/project/databases/views.py', 'openstack_dashboard/dashboards/project/databases/templates/databases/_detail_overview.html', 'openstack_dashboard/test/test_data/trove_data.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2ccb279461cd3c3ee4e87a952e60c872144dfeee', 'message': ""Initial support for datastore in Horizon\n\nAdded datastore type and version columns in Instance Table\nAdded datastore type and version in Instance Details\nAdded appropriate Connection Examples (for each datastore type) in Instance Details\n\nLaunch Database has single dropdown with the following behavior:\n- Auto select only if there's one datastore type and version\n- Otherwise, enforce user to choose one\n- Single dropdown uses optgroups to group versions for each datastore type\n\nImplements: blueprint datastore-support\n\nAuthor:    Michael Yu <michayu@ebaysf.com>\nCo-Authored-By:    Ramashri Umale <rumale@ebaysf.com>\nChange-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30\n""}]",100,75269,2ccb279461cd3c3ee4e87a952e60c872144dfeee,208,18,36,9895,,,0,"Initial support for datastore in Horizon

Added datastore type and version columns in Instance Table
Added datastore type and version in Instance Details
Added appropriate Connection Examples (for each datastore type) in Instance Details

Launch Database has single dropdown with the following behavior:
- Auto select only if there's one datastore type and version
- Otherwise, enforce user to choose one
- Single dropdown uses optgroups to group versions for each datastore type

Implements: blueprint datastore-support

Author:    Michael Yu <michayu@ebaysf.com>
Co-Authored-By:    Ramashri Umale <rumale@ebaysf.com>
Change-Id: Iec3fb81e1fd85c653418b27d54b10c439fb3fa30
",git fetch https://review.opendev.org/openstack/horizon refs/changes/69/75269/34 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/trove.py', 'openstack_dashboard/dashboards/project/databases/templates/databases/_detail_overview.html', 'requirements.txt', 'test-requirements.txt', 'openstack_dashboard/dashboards/project/databases/workflows/create_instance.py', 'openstack_dashboard/test/test_data/trove_data.py', 'horizon/templates/horizon/_scripts.html', 'horizon/static/horizon/js/horizon.databases.js', 'openstack_dashboard/dashboards/project/databases/tables.py', 'openstack_dashboard/dashboards/project/databases/tests.py']",10,0c60fe51dcb1bef7d96a8b958c717265299747a5,bp/datastore-support," {api.trove: ('instance_list', 'instance_get', 'flavor_list')}) # Mock instance get api.trove.instance_get(IsA(http.HttpRequest), IsA(str))\ .AndReturn(self.databases.list()[0]) # Mock instance get api.trove.instance_get(IsA(http.HttpRequest), IsA(str))\ .AndReturn(self.databases.list()[1]) {api.trove: ('instance_list', 'flavor_list', 'instance_get')}) # Mock instance get api.trove.instance_get(IsA(http.HttpRequest), IsA(str))\ .AndReturn(self.databases.list()[0]) # Mock instance get api.trove.instance_get(IsA(http.HttpRequest), IsA(str))\ .AndReturn(self.databases.list()[1]) {api.trove: ('instance_list', 'flavor_list', 'instance_get')}) last_record = databases[1] # Mock instance get api.trove.instance_get(IsA(http.HttpRequest), IsA(str))\ .AndReturn(self.databases.list()[0]) # Mock instance get api.trove.instance_get(IsA(http.HttpRequest), IsA(str))\ .AndReturn(self.databases.list()[1]) {api.trove: ('instance_list', 'flavor_list', 'instance_get')}) # Mock instance get api.trove.instance_get(IsA(http.HttpRequest), IsA(str))\ .AndReturn(self.databases.list()[0]) # Mock instance get api.trove.instance_get(IsA(http.HttpRequest), IsA(str))\ .AndReturn(self.databases.list()[1]) api.trove: ('flavor_list', 'backup_list', 'datastore_list', 'datastore_version_list')}) # Mock datastores api.trove.datastore_list(IsA(http.HttpRequest))\ .AndReturn(self.datastores.list()) # Mock datastore versions api.trove.datastore_version_list(IsA(http.HttpRequest), IsA(str)).AndReturn(self.datastore_versions.list()) api.trove: ('flavor_list', 'backup_list', 'instance_create', 'datastore_list', 'datastore_version_list')}) # Mock datastores api.trove.datastore_list(IsA(http.HttpRequest))\ .AndReturn(self.datastores.list()) # Mock datastore versions api.trove.datastore_version_list(IsA(http.HttpRequest), IsA(str)).AndReturn(self.datastore_versions.list()) datastore=IsA(unicode), datastore_version=IsA(unicode), 'datastore': '537fb940-b5eb-40d9-bdbd-91a3dcb9c17d', 'datastore_version': '390a6d52-8347-4e00-8e4c-f4fa9cf96ae9' api.trove: ('flavor_list', 'backup_list', 'instance_create', 'datastore_list', 'datastore_version_list')}) # Mock datastores api.trove.datastore_list(IsA(http.HttpRequest))\ .AndReturn(self.datastores.list()) # Mock datastore versions api.trove.datastore_version_list(IsA(http.HttpRequest), IsA(str)).AndReturn(self.datastore_versions.list()) datastore=IsA(unicode), datastore_version=IsA(unicode), 'datastore': '537fb940-b5eb-40d9-bdbd-91a3dcb9c17d', 'datastore_version': '390a6d52-8347-4e00-8e4c-f4fa9cf96ae9'"," {api.trove: ('instance_list', 'flavor_list')}) {api.trove: ('instance_list', 'flavor_list')}) {api.trove: ('instance_list', 'flavor_list')}) last_record = databases[-1] {api.trove: ('instance_list', 'flavor_list')}) api.trove: ('flavor_list', 'backup_list',)}) api.trove: ('flavor_list', 'backup_list', 'instance_create',)}) api.trove: ('flavor_list', 'backup_list', 'instance_create',)})",387,21
openstack%2Fsecurity-doc~master~Iaa87b362205cdd7da68b826e682e93ab1f575a2b,openstack/security-doc,master,Iaa87b362205cdd7da68b826e682e93ab1f575a2b,Fix Style Issues,MERGED,2014-07-16 22:22:39.000000000,2014-07-17 19:12:39.000000000,2014-07-17 19:12:39.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2807}, {'_account_id': 6547}, {'_account_id': 7063}]","[{'number': 1, 'created': '2014-07-16 22:22:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/4b07379e7c99e2fa3bb7431de93ae9e2b5bc3cf8', 'message': 'Fix Style Issues\nCloses_Bug : 1341845\n\nChange-Id: Iaa87b362205cdd7da68b826e682e93ab1f575a2b\n'}, {'number': 2, 'created': '2014-07-17 18:57:28.000000000', 'files': ['security-guide/ch_dashboard.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/6d35e454d96bb49550fb2ca487af69063244586a', 'message': 'Fix Style Issues\n\nRewrote a sentence to fix grammatical errors\nMoved the fixed sentence to earlier paragraph for better reading\n\nCloses-Bug: #1341845\nChange-Id: Iaa87b362205cdd7da68b826e682e93ab1f575a2b\n'}]",2,107516,6d35e454d96bb49550fb2ca487af69063244586a,16,5,2,8560,,,0,"Fix Style Issues

Rewrote a sentence to fix grammatical errors
Moved the fixed sentence to earlier paragraph for better reading

Closes-Bug: #1341845
Change-Id: Iaa87b362205cdd7da68b826e682e93ab1f575a2b
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/16/107516/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_dashboard.xml'],1,4b07379e7c99e2fa3bb7431de93ae9e2b5bc3cf8,bug/1341845, <uri>https://horizon/</uri>. These recommendations are based on the limitations of browser same-origin-policy.</para> <para>The recommendations in this guide cannot, <uri>https://horizon/</uri>.</para> <para>This recommendation is based on the limitations browser same-origin-policy. The recommendations in this guide cannot,3,3
openstack%2Fsecurity-doc~master~Id65ba7c9adc934f41c8001c7f75cf3e83ca29441,openstack/security-doc,master,Id65ba7c9adc934f41c8001c7f75cf3e83ca29441,Capitalize Linux,MERGED,2014-07-17 19:03:16.000000000,2014-07-17 19:12:33.000000000,2014-07-17 19:12:33.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2807}, {'_account_id': 7063}, {'_account_id': 12325}]","[{'number': 1, 'created': '2014-07-17 19:03:16.000000000', 'files': ['security-guide/ch_hardening-the-virtualization-layers.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/e2577504ae3318bad7909e1cc9e822fd3b9aff58', 'message': 'Capitalize Linux\n\nChange-Id: Id65ba7c9adc934f41c8001c7f75cf3e83ca29441\nCloses-Bug: #1342823\n'}]",0,107800,e2577504ae3318bad7909e1cc9e822fd3b9aff58,10,5,1,6547,,,0,"Capitalize Linux

Change-Id: Id65ba7c9adc934f41c8001c7f75cf3e83ca29441
Closes-Bug: #1342823
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/00/107800/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_hardening-the-virtualization-layers.xml'],1,e2577504ae3318bad7909e1cc9e822fd3b9aff58,bug/1342823," Many modern Linux distributions already build QEMU with modern Linux kernels support ASLR), when the executable"," Many modern linux distributions already build QEMU with modern linux kernels support ASLR), when the executable",2,2
openstack%2Fsecurity-doc~master~I0631579ecf09708989d88bbfdfa897ca9904a7d2,openstack/security-doc,master,I0631579ecf09708989d88bbfdfa897ca9904a7d2,Fix VMware misspelling,MERGED,2014-07-17 19:00:55.000000000,2014-07-17 19:12:28.000000000,2014-07-17 19:12:27.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2807}]","[{'number': 1, 'created': '2014-07-17 19:00:55.000000000', 'files': ['security-guide/ch_hypervisor-selection.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/e8088710af2aacd7eaa9e14354f69dba5d1709d1', 'message': 'Fix VMware misspelling\n\nChange-Id: I0631579ecf09708989d88bbfdfa897ca9904a7d2\nCloses-Bug: #1342939\n'}]",0,107798,e8088710af2aacd7eaa9e14354f69dba5d1709d1,8,3,1,6547,,,0,"Fix VMware misspelling

Change-Id: I0631579ecf09708989d88bbfdfa897ca9904a7d2
Closes-Bug: #1342939
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/98/107798/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_hypervisor-selection.xml'],1,e8088710af2aacd7eaa9e14354f69dba5d1709d1,bug/1342939, and VMware have achieved Common Criteria Certification their, and VMWare have achieved Common Criteria Certification their,1,1
openstack%2Fsahara-image-elements~master~I5368b45e9fd984f5e2082dd31a15a6d45065a9da,openstack/sahara-image-elements,master,I5368b45e9fd984f5e2082dd31a15a6d45065a9da,Bump Hadoop to 2.4.1 version,MERGED,2014-07-16 10:26:31.000000000,2014-07-17 19:05:00.000000000,2014-07-17 19:05:00.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-16 10:26:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/8720a5d28ba2b8d9128192d29da12191e3387bf4', 'message': 'Bump Hadoop to 2.4.1 version\n\nChange-Id: I5368b45e9fd984f5e2082dd31a15a6d45065a9da\n'}, {'number': 2, 'created': '2014-07-16 14:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/3695fb7719f2b566c0927938d65f71cc2daa9d19', 'message': 'Bump Hadoop to 2.4.1 version\n\nChange-Id: I5368b45e9fd984f5e2082dd31a15a6d45065a9da\n'}, {'number': 3, 'created': '2014-07-16 15:57:23.000000000', 'files': ['elements/oozie/install.d/50-setup-oozie', 'diskimage-create/diskimage-create.sh', 'elements/oozie/root.d/0-check'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/98694844be18c28939d0dc9c4585e9be827c5689', 'message': 'Bump Hadoop to 2.4.1 version\n\nChange-Id: I5368b45e9fd984f5e2082dd31a15a6d45065a9da\n'}]",0,107304,98694844be18c28939d0dc9c4585e9be827c5689,36,8,3,7710,,,0,"Bump Hadoop to 2.4.1 version

Change-Id: I5368b45e9fd984f5e2082dd31a15a6d45065a9da
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/04/107304/2 && git format-patch -1 --stdout FETCH_HEAD,['diskimage-create/diskimage-create.sh'],1,8720a5d28ba2b8d9128192d29da12191e3387bf4,," export OOZIE_HADOOP_V2_4_DOWNLOAD_URL=${OOZIE_HADOOP_V2_4_DOWNLOAD_URL:-""http://sahara-files.mirantis.com/oozie-4.0.1-hadoop-2.4.1.tar.gz""} export HADOOP_V2_4_NATIVE_LIBS_DOWNLOAD_URL=${HADOOP_V2_4_NATIVE_LIBS_DOWNLOAD_URL:-""http://sahara-files.mirantis.com/hadoop-2.4.1-native-libs.tar.gz""} export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_4:-""2.4.1""} export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_4:-""2.4.1""} export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_4:-""2.4.1""}"," export OOZIE_HADOOP_V2_4_DOWNLOAD_URL=${OOZIE_HADOOP_V2_4_DOWNLOAD_URL:-""http://sahara-files.mirantis.com/oozie-4.0.1-hadoop-2.4.0.tar.gz""} export HADOOP_V2_4_NATIVE_LIBS_DOWNLOAD_URL=${HADOOP_V2_4_NATIVE_LIBS_DOWNLOAD_URL:-""http://sahara-files.mirantis.com/hadoop-2.4.0-native-libs.tar.gz""} export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_4:-""2.4.0""} export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_4:-""2.4.0""} export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_4:-""2.4.0""}",5,5
openstack%2Fmonasca-agent~master~If185188e91776243b9cb0696d38c6cd5d6cf5f77,openstack/monasca-agent,master,If185188e91776243b9cb0696d38c6cd5d6cf5f77,Added initial tox support,ABANDONED,2014-07-17 18:33:55.000000000,2014-07-17 18:51:46.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-17 18:33:55.000000000', 'files': ['requirements.txt', '.gitignore', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/4dee7e6fd0dff65d66c4faca06605f5bc4b3f8b3', 'message': 'Added initial tox support\n\nChange-Id: If185188e91776243b9cb0696d38c6cd5d6cf5f77\n'}]",0,107791,4dee7e6fd0dff65d66c4faca06605f5bc4b3f8b3,4,1,1,1976,,,0,"Added initial tox support

Change-Id: If185188e91776243b9cb0696d38c6cd5d6cf5f77
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/91/107791/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', '.gitignore', 'test-requirements.txt', 'tox.ini']",4,4dee7e6fd0dff65d66c4faca06605f5bc4b3f8b3,tox,"[tox] envlist = py27,pep8 minversion = 1.6 skipsdist = True [testenv] usedevelop = True install_command = pip install -U {opts} {packages} setenv = VIRTUAL_ENV={envdir} DISCOVER_DIRECTORY=tests deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = nosetests ""{posargs}"" whitelist_externals = bash [testenv:pep8] commands = flake8 {posargs} [testenv:venv] commands = {posargs} [flake8] # H501 Reformat line lengths ignore = E501 show-source = true builtins = _ exclude=.venv,.git,.tox,dist,doc,*lib/python*,*egg,tools",,45,0
openstack%2Fnova~master~I5fb3dd1601324c6be4f4d159166f5cacbec16a7e,openstack/nova,master,I5fb3dd1601324c6be4f4d159166f5cacbec16a7e,Virt: fix typo (flavour should be flavor),MERGED,2014-07-15 06:17:05.000000000,2014-07-17 18:49:49.000000000,2014-07-16 15:25:29.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 8276}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-15 06:17:05.000000000', 'files': ['nova/virt/hardware.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/21cd55bb1d7dd29e32a515fefd8c578186f0089c', 'message': 'Virt: fix typo (flavour should be flavor)\n\nCommit 0c74df4962f256d9bc17b57c22ea45ece94e2f1a added support\nwhich used the word flavour. Flavour is the preferred\nspelling throughout the rest of the English-speaking world, but\nflavor is preferrred spelling for OpenStack.\n\nTrivialFix\n\nChange-Id: I5fb3dd1601324c6be4f4d159166f5cacbec16a7e\n'}]",2,106949,21cd55bb1d7dd29e32a515fefd8c578186f0089c,32,11,1,1653,,,0,"Virt: fix typo (flavour should be flavor)

Commit 0c74df4962f256d9bc17b57c22ea45ece94e2f1a added support
which used the word flavour. Flavour is the preferred
spelling throughout the rest of the English-speaking world, but
flavor is preferrred spelling for OpenStack.

TrivialFix

Change-Id: I5fb3dd1601324c6be4f4d159166f5cacbec16a7e
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/106949/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hardware.py', 'nova/tests/virt/libvirt/test_driver.py']",2,21cd55bb1d7dd29e32a515fefd8c578186f0089c,flavor-vs-flavour," fake_flavor = flavor_obj.Flavor.get_by_id( fake_flavor.extra_specs = {'hw_watchdog_action': 'none'} return_value=fake_flavor): fake_flavor = flavor_obj.Flavor.get_by_id( fake_flavor.extra_specs = {'hw_watchdog_action': 'none'} return_value=fake_flavor): fake_flavor = flavor_obj.Flavor.get_by_id( fake_flavor.extra_specs = {'hw_rng:allowed': 'True'} return_value=fake_flavor): fake_flavor = flavor_obj.Flavor.get_by_id( fake_flavor.extra_specs = {'hw_rng:allowed': 'True', 'hw_rng:rate_bytes': '1024', 'hw_rng:rate_period': '2'} return_value=fake_flavor): fake_flavor = flavor_obj.Flavor.get_by_id( fake_flavor.extra_specs = {'hw_rng:allowed': 'True'} return_value=fake_flavor), fake_flavor = flavor_obj.Flavor.get_by_id( fake_flavor.extra_specs = {'hw_rng:allowed': 'True'} return_value=fake_flavor), fake_flavor = flavor_obj.Flavor.get_by_id( fake_flavor.vcpus = 8 fake_flavor.extra_specs = {'hw:cpu_max_sockets': '4'} return_value=fake_flavor):"," fake_flavour = flavor_obj.Flavor.get_by_id( fake_flavour.extra_specs = {'hw_watchdog_action': 'none'} return_value=fake_flavour): fake_flavour = flavor_obj.Flavor.get_by_id( fake_flavour.extra_specs = {'hw_watchdog_action': 'none'} return_value=fake_flavour): fake_flavour = flavor_obj.Flavor.get_by_id( fake_flavour.extra_specs = {'hw_rng:allowed': 'True'} return_value=fake_flavour): fake_flavour = flavor_obj.Flavor.get_by_id( fake_flavour.extra_specs = {'hw_rng:allowed': 'True', 'hw_rng:rate_bytes': '1024', 'hw_rng:rate_period': '2'} return_value=fake_flavour): fake_flavour = flavor_obj.Flavor.get_by_id( fake_flavour.extra_specs = {'hw_rng:allowed': 'True'} return_value=fake_flavour), fake_flavour = flavor_obj.Flavor.get_by_id( fake_flavour.extra_specs = {'hw_rng:allowed': 'True'} return_value=fake_flavour), fake_flavour = flavor_obj.Flavor.get_by_id( fake_flavour.vcpus = 8 fake_flavour.extra_specs = {'hw:cpu_max_sockets': '4'} return_value=fake_flavour):",25,25
openstack%2Ftripleo-incubator~master~I63536c38c205d5eb45e3825915dc9c19238cb344,openstack/tripleo-incubator,master,I63536c38c205d5eb45e3825915dc9c19238cb344,Add IPMI route to ctlplane,ABANDONED,2014-07-08 16:44:02.000000000,2014-07-17 18:46:50.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-08 16:44:02.000000000', 'files': ['scripts/devtest_seed.sh', 'scripts/setup-neutron'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/b594b39a1ca3357d0f79ac4758f494c28416a9e4', 'message': 'Add IPMI route to ctlplane\n\nAdd route to IPMI network to ctlplane to be pushed out with DHCP.\n\nChange-Id: I63536c38c205d5eb45e3825915dc9c19238cb344\n'}]",0,105522,b594b39a1ca3357d0f79ac4758f494c28416a9e4,5,1,1,1926,,,0,"Add IPMI route to ctlplane

Add route to IPMI network to ctlplane to be pushed out with DHCP.

Change-Id: I63536c38c205d5eb45e3825915dc9c19238cb344
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/22/105522/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/devtest_seed.sh', 'scripts/setup-neutron']",2,b594b39a1ca3357d0f79ac4758f494c28416a9e4,(detached,"# Routes pushed out on subnet via DHCP e.g. 1.2.3.0/24,nexthop=1.2.3.4 ADDITIONAL_ROUTE=${12:-""""} SUBNET_ID=$(neutron subnet-create --ip_version 4 ${ALLOCATION_POOL:+--allocation-pool $ALLOCATION_POOL} ${NETWORK_GATEWAY:+--gateway $NETWORK_GATEWAY} $NET_ID $NETWORK_CIDR $SUBNET_EXTRA ${ADDITIONAL_ROUTE:+--host-route destination=$ADDITIONAL_ROUTE} | grep ' id ' | awk '{print $4}')",SUBNET_ID=$(neutron subnet-create --ip_version 4 ${ALLOCATION_POOL:+--allocation-pool $ALLOCATION_POOL} ${NETWORK_GATEWAY:+--gateway $NETWORK_GATEWAY} $NET_ID $NETWORK_CIDR $SUBNET_EXTRA | grep ' id ' | awk '{print $4}'),5,3
openstack%2Fmonasca-notification~master~I793a384cbba604c6c543c524c6c32217c590346a,openstack/monasca-notification,master,I793a384cbba604c6c543c524c6c32217c590346a,Added virtual env to the tox.ini so the push to pypi will work correctly,MERGED,2014-07-17 15:55:26.000000000,2014-07-17 18:41:36.000000000,2014-07-17 18:41:36.000000000,"[{'_account_id': 3}, {'_account_id': 11094}, {'_account_id': 11809}]","[{'number': 1, 'created': '2014-07-17 15:55:26.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/aab28f8138630cc5c50521376aebb378a33875e5', 'message': 'Added virtual env to the tox.ini so the push to pypi will work correctly\n\nChange-Id: I793a384cbba604c6c543c524c6c32217c590346a\n'}]",0,107762,aab28f8138630cc5c50521376aebb378a33875e5,21,3,1,11094,,,0,"Added virtual env to the tox.ini so the push to pypi will work correctly

Change-Id: I793a384cbba604c6c543c524c6c32217c590346a
",git fetch https://review.opendev.org/openstack/monasca-notification refs/changes/62/107762/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,aab28f8138630cc5c50521376aebb378a33875e5,,setenv = VIRTUAL_ENV={envdir} usedevelop = True install_command = pip install -U {opts} {packages}commands = nosetests[testenv:venv] commands = {posargs} ,commands = nosetests,7,1
openstack%2Fpuppet-neutron~master~I42a5a045b777e42e5c99cea16a0fbc6ed145d73b,openstack/puppet-neutron,master,I42a5a045b777e42e5c99cea16a0fbc6ed145d73b,Add ability to configure dhcp_agent_notification,MERGED,2014-07-08 01:50:31.000000000,2014-07-17 18:39:40.000000000,2014-07-17 18:39:39.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-07-08 01:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/2c53482fd4e86183852e09f53a250ca89296b012', 'message': 'Add ability to configure dhcp_agent_notification\n\nAdd a new dhcp_agent_notification parameter to allow its configuration.\n\nInstallation without any DHCP agents should have this option disabled\nto avoid these kinds of error messages in Neutron logs:\n\n- No more DHCP agents\n- Unable to schedule network XXX: no agents available;\n  will retry on subsequent port creation events.\n- Will not send event port_create_end for network XXX:\n  no agent available.\n\nChange-Id: I42a5a045b777e42e5c99cea16a0fbc6ed145d73b\n'}, {'number': 2, 'created': '2014-07-14 15:45:01.000000000', 'files': ['spec/classes/neutron_init_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/0346d48d19eb172713b166e13a6df9e8b4bd99ba', 'message': 'Add ability to configure dhcp_agent_notification\n\nAdd a new dhcp_agent_notification parameter to allow its configuration.\n\nInstallation without any DHCP agents should have this option disabled\nto avoid these kinds of error messages in Neutron logs:\n\n- No more DHCP agents\n- Unable to schedule network XXX: no agents available;\n  will retry on subsequent port creation events.\n- Will not send event port_create_end for network XXX:\n  no agent available.\n\nChange-Id: I42a5a045b777e42e5c99cea16a0fbc6ed145d73b\n'}]",0,105323,0346d48d19eb172713b166e13a6df9e8b4bd99ba,17,3,2,7156,,,0,"Add ability to configure dhcp_agent_notification

Add a new dhcp_agent_notification parameter to allow its configuration.

Installation without any DHCP agents should have this option disabled
to avoid these kinds of error messages in Neutron logs:

- No more DHCP agents
- Unable to schedule network XXX: no agents available;
  will retry on subsequent port creation events.
- Will not send event port_create_end for network XXX:
  no agent available.

Change-Id: I42a5a045b777e42e5c99cea16a0fbc6ed145d73b
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/23/105323/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_init_spec.rb', 'manifests/init.pp']",2,2c53482fd4e86183852e09f53a250ca89296b012,dhcp_agent_notification,"# [*dhcp_agent_notification*] # (optional) Allow sending resource operation notification to DHCP agent. # Defaults to true # $dhcp_agent_notification = true, 'DEFAULT/dhcp_agent_notification': value => $dhcp_agent_notification;",,7,0
openstack%2Ftripleo-image-elements~master~I716b9e6f3c8d36c56749b7de0915e5a3d2eb1973,openstack/tripleo-image-elements,master,I716b9e6f3c8d36c56749b7de0915e5a3d2eb1973,Move libvirt's qemu configuration dir to state fs,MERGED,2014-07-16 18:15:27.000000000,2014-07-17 18:34:37.000000000,2014-07-17 18:34:36.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6449}, {'_account_id': 8399}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-07-16 18:15:27.000000000', 'files': ['elements/nova-kvm/install.d/81-nova-kvm', 'elements/nova-kvm/element-deps'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/81ebbdce33cb695a5c6b40e06cf5102220be791f', 'message': ""Move libvirt's qemu configuration dir to state fs\n\nWe need libvirt domain entries created by Nova in to persist across\nimage upgrades.  Otherwise, instances are effectively removed from the\nhypervisor after a new image deploys with an empty libvirt config tree.\nThis registers /etc/libvirt/qemu as a stateful path and ensures persistent\ndomain configurations across upgrades.\n\nThis reapplies a previously reverted fix, this time including the proper\nelement-deps.\n\nChange-Id: I716b9e6f3c8d36c56749b7de0915e5a3d2eb1973\nCloses-bug: #1336115\n""}]",0,107461,81ebbdce33cb695a5c6b40e06cf5102220be791f,14,5,1,1420,,,0,"Move libvirt's qemu configuration dir to state fs

We need libvirt domain entries created by Nova in to persist across
image upgrades.  Otherwise, instances are effectively removed from the
hypervisor after a new image deploys with an empty libvirt config tree.
This registers /etc/libvirt/qemu as a stateful path and ensures persistent
domain configurations across upgrades.

This reapplies a previously reverted fix, this time including the proper
element-deps.

Change-Id: I716b9e6f3c8d36c56749b7de0915e5a3d2eb1973
Closes-bug: #1336115
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/61/107461/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/nova-kvm/install.d/81-nova-kvm', 'elements/nova-kvm/element-deps']",2,81ebbdce33cb695a5c6b40e06cf5102220be791f,qemu_stateful_2,use-ephemeral,,3,0
openstack%2Fkeystone~master~Id9ff5e4e22125c54b5793bc42819fb4d1ef6dc90,openstack/keystone,master,Id9ff5e4e22125c54b5793bc42819fb4d1ef6dc90,Add revocation extension to default pipeline,MERGED,2014-07-11 19:23:39.000000000,2014-07-17 18:25:33.000000000,2014-07-17 18:25:32.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 11045}, {'_account_id': 11333}, {'_account_id': 11387}, {'_account_id': 11717}]","[{'number': 1, 'created': '2014-07-11 19:23:39.000000000', 'files': ['etc/keystone-paste.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/41d29fd72269023aca2fccf19e1f38d5e0a1dd77', 'message': 'Add revocation extension to default pipeline\n\nSince this extension will have an impact across many projects\nwithin OpenStack, it should be on by default.\n\nChange-Id: Id9ff5e4e22125c54b5793bc42819fb4d1ef6dc90\n'}]",0,106474,41d29fd72269023aca2fccf19e1f38d5e0a1dd77,26,19,1,6482,,,0,"Add revocation extension to default pipeline

Since this extension will have an impact across many projects
within OpenStack, it should be on by default.

Change-Id: Id9ff5e4e22125c54b5793bc42819fb4d1ef6dc90
",git fetch https://review.opendev.org/openstack/keystone refs/changes/74/106474/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/keystone-paste.ini'],1,41d29fd72269023aca2fccf19e1f38d5e0a1dd77,ay3,pipeline = sizelimit url_normalize build_auth_context token_auth admin_token_auth xml_body_v3 json_body ec2_extension_v3 s3_extension simple_cert_extension revoke_extension service_v3,pipeline = sizelimit url_normalize build_auth_context token_auth admin_token_auth xml_body_v3 json_body ec2_extension_v3 s3_extension simple_cert_extension service_v3,1,1
openstack%2Ffuel-library~stable%2F5.0~I4ab98cd77d29d986d202051b7e66c8abb13e4c15,openstack/fuel-library,stable/5.0,I4ab98cd77d29d986d202051b7e66c8abb13e4c15,Update logfile ownership for syslog in Ubuntu,MERGED,2014-07-16 10:01:47.000000000,2014-07-17 18:23:52.000000000,2014-07-17 18:23:52.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-16 10:01:47.000000000', 'files': ['deployment/puppet/rsyslog/manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3315d10e113c3778c1f35c0c90ea88e9da92dcf8', 'message': 'Update logfile ownership for syslog in Ubuntu\n\nWith $FileGroup:$FileOwner = root:adm, we would have some\nsyslog logfiles inaccessible then syslog running user would\nbe changed from root to syslog.\nroot:adm should not be set for syslog logfiles since\nwe use syslog:syslog as drop-provilege-to as well\n(http://www.rsyslog.com/doc/droppriv.html)\n\nCloses-bug: #1308684\n\nChange-Id: I4ab98cd77d29d986d202051b7e66c8abb13e4c15\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,107294,3315d10e113c3778c1f35c0c90ea88e9da92dcf8,15,4,1,6926,,,0,"Update logfile ownership for syslog in Ubuntu

With $FileGroup:$FileOwner = root:adm, we would have some
syslog logfiles inaccessible then syslog running user would
be changed from root to syslog.
root:adm should not be set for syslog logfiles since
we use syslog:syslog as drop-provilege-to as well
(http://www.rsyslog.com/doc/droppriv.html)

Closes-bug: #1308684

Change-Id: I4ab98cd77d29d986d202051b7e66c8abb13e4c15
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/94/107294/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/rsyslog/manifests/params.pp'],1,3315d10e113c3778c1f35c0c90ea88e9da92dcf8,, $log_user = 'syslog' $log_group = 'syslog', $log_user = 'root' $log_group = 'adm',2,2
openstack%2Fkeystone~master~I3d2419786d1f6c25b69c29629a47892fa682129d,openstack/keystone,master,I3d2419786d1f6c25b69c29629a47892fa682129d,Update docs to reflect new db_sync behaviour,MERGED,2014-07-11 15:36:26.000000000,2014-07-17 18:22:04.000000000,2014-07-17 18:22:03.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 11717}]","[{'number': 1, 'created': '2014-07-11 15:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/09779a537b7ff5c5a6b75187edf5621780be001a', 'message': 'Update docs to reflect new db_sync behaviour\n\nIn the extension specific configuration docs, we ask that the user\nalways migrate the extension, however now that we migrate certain\nextensions by default, we can mark those steps as optional.\n\nChange-Id: I3d2419786d1f6c25b69c29629a47892fa682129d\n'}, {'number': 2, 'created': '2014-07-11 15:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7387188527542fe2de1cddbc3989b3ccf456ac56', 'message': 'Update docs to reflect new db_sync behaviour\n\nIn the extension specific configuration docs, we ask that the user\nalways migrate the extension, however now that we migrate certain\nextensions by default, we can mark those steps as optional.\n\nChange-Id: I3d2419786d1f6c25b69c29629a47892fa682129d\n'}, {'number': 3, 'created': '2014-07-11 18:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5986862d6d5877dcd2f83524d35d5a309d161944', 'message': 'Update docs to reflect new db_sync behaviour\n\nIn the extension specific configuration docs, we ask that the user\nalways migrate the extension, however now that we migrate certain\nextensions by default, we can mark those steps as optional.\n\nChange-Id: I3d2419786d1f6c25b69c29629a47892fa682129d\n'}, {'number': 4, 'created': '2014-07-11 19:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ea717b363a044f7cc25087fb258243a9c790f8fd', 'message': 'Update docs to reflect new db_sync behaviour\n\nIn the extension specific configuration docs, we ask that the user\nalways migrate the extension, however now that we migrate certain\nextensions by default, we can mark those steps as optional.\n\nChange-Id: I3d2419786d1f6c25b69c29629a47892fa682129d\n'}, {'number': 5, 'created': '2014-07-11 19:22:17.000000000', 'files': ['doc/source/extensions/revoke.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/aa16653bcfc961e57167e732f4433bc0025facb5', 'message': 'Update docs to reflect new db_sync behaviour\n\nIn the extension specific configuration docs, we ask that the user\nalways migrate the extension, however now that we migrate certain\nextensions by default, we can mark those steps as optional.\n\nChange-Id: I3d2419786d1f6c25b69c29629a47892fa682129d\n'}]",1,106407,aa16653bcfc961e57167e732f4433bc0025facb5,24,14,5,6482,,,0,"Update docs to reflect new db_sync behaviour

In the extension specific configuration docs, we ask that the user
always migrate the extension, however now that we migrate certain
extensions by default, we can mark those steps as optional.

Change-Id: I3d2419786d1f6c25b69c29629a47892fa682129d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/07/106407/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/extensions/revoke.rst', 'doc/source/extensions/endpoint_filter.rst', 'doc/source/extensions/federation.rst', 'doc/source/extensions/oauth1.rst']",4,09779a537b7ff5c5a6b75187edf5621780be001a,ay2,"4. Optionally, create the OAuth1 extension tables if using the provided SQL backend. For example:: Note that as of the Juno release this extension is now migrated by default.",4. Create the OAuth1 extension tables if using the provided SQL backend. For example::,15,8
openstack%2Fkeystone~master~Ia5646ebae049eec296bd10826dfd57bf6b7761af,openstack/keystone,master,Ia5646ebae049eec296bd10826dfd57bf6b7761af,LDAP: Added documentation for debug_level option,MERGED,2014-05-21 17:20:13.000000000,2014-07-17 18:21:56.000000000,2014-07-17 18:21:55.000000000,"[{'_account_id': 3}, {'_account_id': 220}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8871}, {'_account_id': 9500}, {'_account_id': 9751}, {'_account_id': 10068}, {'_account_id': 11045}, {'_account_id': 11155}, {'_account_id': 11333}, {'_account_id': 11387}, {'_account_id': 11717}]","[{'number': 1, 'created': '2014-05-21 17:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3d673ce8b08d93dab950085936f9e4c36bc33f90', 'message': 'LDAP: Added documentation for debug_level option\n\nChange-Id: Ia5646ebae049eec296bd10826dfd57bf6b7761af\nCloses-Bug: #1319564\n'}, {'number': 2, 'created': '2014-06-17 20:55:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/63b76c50ac7f4f90b3596a0b8bba5b95e95621a6', 'message': 'LDAP: Added documentation for debug_level option\n\nChange-Id: Ia5646ebae049eec296bd10826dfd57bf6b7761af\nCloses-Bug: #1319564\n'}, {'number': 3, 'created': '2014-06-28 01:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b072f8ec8c17c3057fa2e3e79ffa03b02f472d32', 'message': 'LDAP: Added documentation for debug_level option\n\nChange-Id: Ia5646ebae049eec296bd10826dfd57bf6b7761af\nCloses-Bug: #1319564\n'}, {'number': 4, 'created': '2014-06-28 01:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a7dfdfd31a26315acefdeeb64b19dee5bb3ac41f', 'message': 'LDAP: Added documentation for debug_level option\n\nChange-Id: Ia5646ebae049eec296bd10826dfd57bf6b7761af\nCloses-Bug: #1319564\n'}, {'number': 5, 'created': '2014-06-29 15:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dab9879a0aba856d3908e066f9b9f23f1ea3dc5c', 'message': 'LDAP: Added documentation for debug_level option\n\nChange-Id: Ia5646ebae049eec296bd10826dfd57bf6b7761af\nCloses-Bug: #1319564\n'}, {'number': 6, 'created': '2014-07-01 14:14:50.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e6d86c324c152a239a2937966e715bbec4b41884', 'message': 'LDAP: Added documentation for debug_level option\n\nChange-Id: Ia5646ebae049eec296bd10826dfd57bf6b7761af\nCloses-Bug: #1319564\n'}]",14,94679,e6d86c324c152a239a2937966e715bbec4b41884,80,17,6,11155,,,0,"LDAP: Added documentation for debug_level option

Change-Id: Ia5646ebae049eec296bd10826dfd57bf6b7761af
Closes-Bug: #1319564
",git fetch https://review.opendev.org/openstack/keystone refs/changes/79/94679/6 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,3d673ce8b08d93dab950085936f9e4c36bc33f90,debug_ldap_docs,"Debugging LDAP -------------- If you're having trouble with LDAP connections, performance, or field mappings, setting ``debug_level`` is used to enable debugging:: debug_level = 4095 This setting in turn sets OPT_DEBUG_LEVEL in the underlying python library. This field is a bit mask (integer). Although some flags may be server specific, most are documented in the OpenLDAP manpages. Commonly used values include 255 and 4095, with 4095 being more verbose. Having this setting enabled will negatively impact performance.",,13,0
openstack%2Ftripleo-heat-templates~master~Ifd4f4b12cd51e23313826288797cc00ba3cd1754,openstack/tripleo-heat-templates,master,Ifd4f4b12cd51e23313826288797cc00ba3cd1754,make glance.host point to controller_virtual_ip,MERGED,2014-07-10 04:47:58.000000000,2014-07-17 18:19:57.000000000,2014-07-17 18:19:57.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-07-10 04:47:58.000000000', 'files': ['overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/687b100b4c8731c97fb542db42709f2de05a5881', 'message': 'make glance.host point to controller_virtual_ip\n\nPreviously glance.host was pointing to the local controller_host\nwhich would have requests to glance from other services to fail\nif the local glance daemon was unavailable.\n\nChange-Id: Ifd4f4b12cd51e23313826288797cc00ba3cd1754\n'}]",0,105964,687b100b4c8731c97fb542db42709f2de05a5881,11,3,1,6796,,,0,"make glance.host point to controller_virtual_ip

Previously glance.host was pointing to the local controller_host
which would have requests to glance from other services to fail
if the local glance daemon was unavailable.

Change-Id: Ifd4f4b12cd51e23313826288797cc00ba3cd1754
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/64/105964/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-source.yaml'],1,687b100b4c8731c97fb542db42709f2de05a5881,glance_virtual, get_input: controller_virtual_ip, get_input: controller_host,1,1
openstack%2Ffuel-library~master~I4ab98cd77d29d986d202051b7e66c8abb13e4c15,openstack/fuel-library,master,I4ab98cd77d29d986d202051b7e66c8abb13e4c15,Update logfile ownership for syslog in Ubuntu,MERGED,2014-07-16 09:32:36.000000000,2014-07-17 18:19:31.000000000,2014-07-17 18:19:31.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-07-16 09:32:36.000000000', 'files': ['deployment/puppet/rsyslog/manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c3efecb85c45b9f4987163ea8bff737bf317762e', 'message': 'Update logfile ownership for syslog in Ubuntu\n\nWith $FileGroup:$FileOwner = root:adm, we would have some\nsyslog logfiles inaccessible then syslog running user would\nbe changed from root to syslog.\nroot:adm should not be set for syslog logfiles since\nwe use syslog:syslog as drop-provilege-to as well\n(http://www.rsyslog.com/doc/droppriv.html)\n\nCloses-bug: #1308684\n\nChange-Id: I4ab98cd77d29d986d202051b7e66c8abb13e4c15\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,107273,c3efecb85c45b9f4987163ea8bff737bf317762e,16,6,1,6926,,,0,"Update logfile ownership for syslog in Ubuntu

With $FileGroup:$FileOwner = root:adm, we would have some
syslog logfiles inaccessible then syslog running user would
be changed from root to syslog.
root:adm should not be set for syslog logfiles since
we use syslog:syslog as drop-provilege-to as well
(http://www.rsyslog.com/doc/droppriv.html)

Closes-bug: #1308684

Change-Id: I4ab98cd77d29d986d202051b7e66c8abb13e4c15
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/73/107273/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/rsyslog/manifests/params.pp'],1,c3efecb85c45b9f4987163ea8bff737bf317762e,fix1308684, $log_user = 'syslog' $log_group = 'syslog', $log_user = 'root' $log_group = 'adm',2,2
openstack%2Ftripleo-heat-templates~master~Ifc484d6a6086d9872210aa576f21d326f60b7d35,openstack/tripleo-heat-templates,master,Ifc484d6a6086d9872210aa576f21d326f60b7d35,use ControlVirtualInterface for keepalived VRRP,MERGED,2014-07-10 03:50:56.000000000,2014-07-17 18:19:06.000000000,2014-07-17 18:19:04.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-07-10 03:50:56.000000000', 'files': ['overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/96e18ecc90539c86c0456c9f87b8b4c6ed8704dd', 'message': 'use ControlVirtualInterface for keepalived VRRP\n\nChange keepalived.keepalive_interface so that it uses the actual\nControlVirtualInterface (bridge) for VRRP rather than the bridged\ninterface (NeutronPublicInterface).\n\nFixes the issue which caused keepalived to bring up the VIP on\nall control nodes.\n\nChange-Id: Ifc484d6a6086d9872210aa576f21d326f60b7d35\n'}]",3,105959,96e18ecc90539c86c0456c9f87b8b4c6ed8704dd,22,5,1,6796,,,0,"use ControlVirtualInterface for keepalived VRRP

Change keepalived.keepalive_interface so that it uses the actual
ControlVirtualInterface (bridge) for VRRP rather than the bridged
interface (NeutronPublicInterface).

Fixes the issue which caused keepalived to bring up the VIP on
all control nodes.

Change-Id: Ifc484d6a6086d9872210aa576f21d326f60b7d35
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/59/105959/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-source.yaml'],1,96e18ecc90539c86c0456c9f87b8b4c6ed8704dd,keepalived_vrrp, Ref: ControlVirtualInterface, Ref: NeutronPublicInterface,1,1
openstack%2Ftripleo-heat-templates~master~I728e05926f2de0e867fb8e8c74c63947da7d987a,openstack/tripleo-heat-templates,master,I728e05926f2de0e867fb8e8c74c63947da7d987a,add Horizon caches backend definition (memcached),MERGED,2014-07-07 22:14:25.000000000,2014-07-17 18:15:15.000000000,2014-07-17 18:15:15.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-07-07 22:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d5d5122a1f10d7e28e6d2d59be5c4c3f336d530f', 'message': 'add Horizon caches backend and location definition\n\nThis change adds into the overcloud-source template two new keys\ndefining the Horizon caches backend class and location.\n\nThe backend type is defaults to Memcached (LocalMem is not\nrecommended for production use) and the list of locations is\ndefaulted to the list of the controller nodes. The memcached\nelement is also set as dependency.\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I728e05926f2de0e867fb8e8c74c63947da7d987a\n'}, {'number': 2, 'created': '2014-07-07 22:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f55703cdd1a39d3c979c0b126b680dad96ea509b', 'message': 'add Horizon caches backend and location definition\n\nThis change adds into the overcloud-source template two new keys\ndefining the Horizon caches backend class and location.\n\nThe backend type defaults to Memcached (LocalMem is not\nrecommended for production use) and the location list is\ndefaulted to the list of the controller nodes.\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I728e05926f2de0e867fb8e8c74c63947da7d987a\n'}, {'number': 3, 'created': '2014-07-08 11:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9c16098f6e0cd86ec2161fc1a1c6e651d6c33fd7', 'message': 'add Horizon caches backend and location definition\n\nThis change adds into the overcloud-source template two new keys\ndefining the Horizon caches backend class and location.\n\nThe backend type defaults to Memcached (LocalMem is not\nrecommended for production use) and the location list is\ndefaulted to the list of the controller nodes.\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I728e05926f2de0e867fb8e8c74c63947da7d987a\n'}, {'number': 4, 'created': '2014-07-08 13:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b161b12af53c6c4e17998de9723308ea8639a368', 'message': 'add Horizon caches backend and location definition\n\nThis change adds into the overcloud-source template two new keys\ndefining the Horizon caches backend class and location.\n\nThe backend type defaults to Memcached (LocalMem is not\nrecommended for production use) and the location list is\ndefaulted to the list of the controller nodes.\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I728e05926f2de0e867fb8e8c74c63947da7d987a\n'}, {'number': 5, 'created': '2014-07-08 21:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7bb74f27fb2546b951dee20fa6be1664d3a12604', 'message': 'add Horizon caches backend and location definition\n\nThis change adds into the overcloud-source template two new keys\ndefining the Horizon caches backend class and location.\n\nThe backend type defaults to Memcached (LocalMem is not\nrecommended for production use) and the location_nodes list is\ndefaulted to the list of the controller nodes.\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I728e05926f2de0e867fb8e8c74c63947da7d987a'}, {'number': 6, 'created': '2014-07-09 11:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e9fa002a1fd8ef08372c41b97db62f0deb700128', 'message': 'add Horizon caches backend definition\n\nThis change adds into the overcloud-source template a structure\ndefining the Horizon caches backend to use (memcached) and its\nproperties (memcached nodes location).\n\nThe backend class defaults to Memcached (LocalMem is not\nrecommended for production use) and the location_nodes key is\ndefaulted to the list of the controller nodes.\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I728e05926f2de0e867fb8e8c74c63947da7d987a'}, {'number': 7, 'created': '2014-07-09 11:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c984e6d2acce8a747c6a04c4113d1ba48067882b', 'message': 'add Horizon caches backend definition (memcached)\n\nThis change adds into the overcloud-source template a structure\nmeant to define memcached as the Horizon caches backend plus one of its\nproperties (the memcached nodes location) in a key named location_nodes.\n\nThe location_nodes key is defaulted to the list of the controller nodes.\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I728e05926f2de0e867fb8e8c74c63947da7d987a'}, {'number': 8, 'created': '2014-07-10 05:14:10.000000000', 'files': ['overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7682ec28f7f25ec550b4bd601577229abee98d89', 'message': 'add Horizon caches backend definition (memcached)\n\nThis change adds into the overcloud-source template a structure\nname horizon.caches meant to define the Horizon caches backend.\nIt defaults to using memcached and provides a list of the\nmemcached nodes in horizon.caches.memcached.nodes\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I728e05926f2de0e867fb8e8c74c63947da7d987a\n'}]",5,105289,7682ec28f7f25ec550b4bd601577229abee98d89,43,5,8,6796,,,0,"add Horizon caches backend definition (memcached)

This change adds into the overcloud-source template a structure
name horizon.caches meant to define the Horizon caches backend.
It defaults to using memcached and provides a list of the
memcached nodes in horizon.caches.memcached.nodes

Related to blueprint tripleo-icehouse-ha-production-configuration

Change-Id: I728e05926f2de0e867fb8e8c74c63947da7d987a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/89/105289/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-source.yaml'],1,d5d5122a1f10d7e28e6d2d59be5c4c3f336d530f,bp/tripleo-icehouse-ha-production-configuration," horizon: caches: backend: 'django.core.cache.backends.memcached.MemcachedCache' location: Merge::Map: controller0: name: {""Fn::Select"": [ name, {""Fn::GetAtt"": [controller0, show]} ] }",,8,0
openstack%2Fmurano-dashboard~master~I420ec5ef8b80f70daefc36d469ee0f31b86be0eb,openstack/murano-dashboard,master,I420ec5ef8b80f70daefc36d469ee0f31b86be0eb,Generate test package archive with different fqn,ABANDONED,2014-07-15 10:26:19.000000000,2014-07-17 18:05:08.000000000,,"[{'_account_id': 3}, {'_account_id': 7613}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-07-15 10:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/94cc645d08da723df96ebac762f9d1babf6f01ca', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 2, 'created': '2014-07-15 10:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/48cd756d34fad251357c66df33943979ad17e407', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 3, 'created': '2014-07-15 10:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/3dbe2ac584a84ac9b5eb7d53ba6ac7e9625ae303', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 4, 'created': '2014-07-15 12:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/05e144376ee22d14b0834435cde5881faae662de', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 5, 'created': '2014-07-15 13:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/2a44148ae085f3068ee15ff86d952c79d1cf68d8', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 6, 'created': '2014-07-15 14:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/6cd5a38120bde88e82e0d597bc0d39caed9f8dca', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 7, 'created': '2014-07-16 07:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/c25ec240186e78263f3841347a051a8b733c2d91', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 8, 'created': '2014-07-16 08:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/e186719bc7690281d29038737166311368132b40', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 9, 'created': '2014-07-16 10:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/d0d82fad2306ca5eaaefba98d8f7cc1ff3b7dba0', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 10, 'created': '2014-07-16 13:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/a3e05e42800c2489fb83e1772c7112fafd174e36', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 11, 'created': '2014-07-16 15:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/b6fa86cef1560486a6808481bc56535bc8a642ed', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}, {'number': 12, 'created': '2014-07-17 11:09:18.000000000', 'files': ['functionaltests/utils.py', 'functionaltests/base.py', 'functionaltests/sanity_check.py', 'functionaltests/MockApp/manifest.yaml'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/617bb4ecfaac1ed22c94603212b657f1382042cc', 'message': 'Generate test package archive with different fqn\n\nAfter this patch app-incubator is not needed for test run\nUse muranoclient insted of request module\n\nChange-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb\n'}]",0,106984,617bb4ecfaac1ed22c94603212b657f1382042cc,61,3,12,7549,,,0,"Generate test package archive with different fqn

After this patch app-incubator is not needed for test run
Use muranoclient insted of request module

Change-Id: I420ec5ef8b80f70daefc36d469ee0f31b86be0eb
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/84/106984/11 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/utils.py', 'functionaltests/base.py', 'functionaltests/MockApp/manifest.yaml']",3,94cc645d08da723df96ebac762f9d1babf6f01ca,refactor_func_tests,,"Format: 1.0 Type: Application FullName: io.murano.apps.MockApp Name: MockApp Description: | MockApp for webUI tests Author: 'Mirantis, Inc' Tags: [test] Classes: io.murano.apps.MockApp: mock_muranopl.yaml UI: mock_ui.yaml ",52,47
openstack%2Fpython-manilaclient~master~I024a90c407e2bd8f25f58935ab8a4241e038f3a8,openstack/python-manilaclient,master,I024a90c407e2bd8f25f58935ab8a4241e038f3a8,Reuse exceptions from common apiclient code,MERGED,2014-07-14 13:10:59.000000000,2014-07-17 18:04:58.000000000,2014-07-17 18:04:57.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7173}, {'_account_id': 7534}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-07-14 13:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/c2f5e0e4eaec00fbd4ceb2ddb7c6992b3e7b9d7c', 'message': ""Reuse exceptions from common apiclient code\n\napiclient package from common code has 'exceptions' module,\nso, lets reuse its exceptions and leave defined only one\nexception that is absent there - NoTokenLookupException.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I024a90c407e2bd8f25f58935ab8a4241e038f3a8\n""}, {'number': 2, 'created': '2014-07-14 15:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/43be7b41475d61d5afc06d7f1deee4ce580eac4c', 'message': ""Reuse exceptions from common apiclient code\n\napiclient package from common code has 'exceptions' module,\nso, lets reuse its exceptions and leave defined only one\nexception that is absent there - NoTokenLookupException.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I024a90c407e2bd8f25f58935ab8a4241e038f3a8\n""}, {'number': 3, 'created': '2014-07-14 16:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/dcce1e22d5ce575dc68f3e92d31d34bb4baf04ce', 'message': ""Reuse exceptions from common apiclient code\n\napiclient package from common code has 'exceptions' module,\nso, lets reuse its exceptions and leave defined only one\nexception that is absent there - NoTokenLookupException.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I024a90c407e2bd8f25f58935ab8a4241e038f3a8\n""}, {'number': 4, 'created': '2014-07-15 06:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/8ae16d992383355c707693a3b58eb1ca57ef1f6d', 'message': ""Reuse exceptions from common apiclient code\n\napiclient package from common code has 'exceptions' module,\nso, lets reuse its exceptions and leave defined only one\nexception that is absent there - NoTokenLookupException.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I024a90c407e2bd8f25f58935ab8a4241e038f3a8\n""}, {'number': 5, 'created': '2014-07-15 06:28:29.000000000', 'files': ['manilaclient/exceptions.py', 'tests/utils.py', 'manilaclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/73e29db9686918600b5bd6469cb3d51c96c7d595', 'message': ""Reuse exceptions from common apiclient code\n\napiclient package from common code has 'exceptions' module,\nso, lets reuse its exceptions and leave defined only one\nexception that is absent there - NoTokenLookupException.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I024a90c407e2bd8f25f58935ab8a4241e038f3a8\n""}]",2,106761,73e29db9686918600b5bd6469cb3d51c96c7d595,23,5,5,8851,,,0,"Reuse exceptions from common apiclient code

apiclient package from common code has 'exceptions' module,
so, lets reuse its exceptions and leave defined only one
exception that is absent there - NoTokenLookupException.

Partially implements: blueprint use-common-code

Change-Id: I024a90c407e2bd8f25f58935ab8a4241e038f3a8
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/61/106761/3 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/exceptions.py', 'manilaclient/client.py']",2,c2f5e0e4eaec00fbd4ceb2ddb7c6992b3e7b9d7c,bp/use-common-code," raise exceptions.from_response(resp, method, url) method = None if hasattr(resp, 'request') and hasattr(resp.request, 'method'): method = resp.request.method raise exceptions.from_response(resp, method, url) method = 'GET' resp, body = self.request(url, method, headers=headers) raise exceptions.from_response(resp, method, url)"," raise exceptions.from_response(resp, body) raise exceptions.from_response(resp, body) resp, body = self.request(url, 'GET', headers=headers) raise exceptions.from_response(resp, body)",18,139
openstack%2Fmurano-dashboard~master~If00fc5b6ed641b4caf5bb3ae93d0d52c6f5be50d,openstack/murano-dashboard,master,If00fc5b6ed641b4caf5bb3ae93d0d52c6f5be50d,Remove checkbox column from environments table,MERGED,2014-07-17 16:31:58.000000000,2014-07-17 18:00:30.000000000,2014-07-17 18:00:29.000000000,"[{'_account_id': 3}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 10063}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-07-17 16:31:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ef5fd543b609f9aa8d923cdc5cb1fd89d6ce240b', 'message': 'Removed checkbox column from environments table\n\nChange-Id: If00fc5b6ed641b4caf5bb3ae93d0d52c6f5be50d\n'}, {'number': 2, 'created': '2014-07-17 17:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/4282e4cb72e2a35aaf519788ee7a6034bb327917', 'message': 'Removed checkbox column from environments table\n\nChange-Id: If00fc5b6ed641b4caf5bb3ae93d0d52c6f5be50d\nCloses-Bug: 1342253\n'}, {'number': 3, 'created': '2014-07-17 17:14:49.000000000', 'files': ['muranodashboard/environments/tables.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f9e2d7ec63dc82d4def69fab685f6bff67c6ca50', 'message': 'Remove checkbox column from environments table\n\nChange-Id: If00fc5b6ed641b4caf5bb3ae93d0d52c6f5be50d\nCloses-Bug: 1342253\n'}]",0,107770,f9e2d7ec63dc82d4def69fab685f6bff67c6ca50,22,5,3,12455,,,0,"Remove checkbox column from environments table

Change-Id: If00fc5b6ed641b4caf5bb3ae93d0d52c6f5be50d
Closes-Bug: 1342253
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/70/107770/2 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/environments/tables.py'],1,ef5fd543b609f9aa8d923cdc5cb1fd89d6ce240b,bug/1342253, multi_select = False,,1,0
openstack%2Fcinder~master~I5b30265609b65804f2da77d9daa84b640de7939c,openstack/cinder,master,I5b30265609b65804f2da77d9daa84b640de7939c,Handle volumes no longer existing in resume delete,MERGED,2014-05-22 21:33:31.000000000,2014-07-17 17:43:30.000000000,2014-06-11 04:22:12.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 8247}, {'_account_id': 8556}, {'_account_id': 8874}, {'_account_id': 9450}, {'_account_id': 9533}, {'_account_id': 9751}, {'_account_id': 10069}]","[{'number': 1, 'created': '2014-05-22 21:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9c81c42aa04a53e217713ca51250f9c05371230a', 'message': ""Handle volumes no longer existing in resume delete\n\ninit_host resumes deletes for volumes with a status of 'deleting'. It\ndoes these sequentially, and sometimes a volume could be deleted under\nit, causing a bad stacktrace. This will gracefully handle those\nsituations and move on. Added coverage for resume volume delete being\nsuccessful as well.\n\nChange-Id: I5b30265609b65804f2da77d9daa84b640de7939c\nCloses-Bug: #1322340\n""}, {'number': 2, 'created': '2014-05-22 21:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ae5aaf83e295db080640819f28af60edd18fcd56', 'message': ""Handle volumes no longer existing in resume delete\n\ninit_host resumes deletes for volumes with a status of 'deleting'. It\ndoes these sequentially, and sometimes a volume could be deleted under\nit, causing a bad stacktrace. This will gracefully handle those\nsituations and move on. Added coverage for resume volume delete being\nsuccessful as well.\n\nChange-Id: I5b30265609b65804f2da77d9daa84b640de7939c\nCloses-Bug: #1322340\n""}, {'number': 3, 'created': '2014-05-23 18:27:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b3878e774292c1c7871a3892c0f509435256265', 'message': ""Handle volumes no longer existing in resume delete\n\ninit_host resumes deletes for volumes with a status of 'deleting'. It\ndoes these sequentially, and sometimes a volume could be deleted under\nit, causing a bad stacktrace. This will gracefully handle those\nsituations and move on. Added coverage for resume volume delete being\nsuccessful as well.\n\nChange-Id: I5b30265609b65804f2da77d9daa84b640de7939c\nCloses-Bug: #1322340\n""}, {'number': 4, 'created': '2014-05-27 20:46:11.000000000', 'files': ['cinder/volume/manager.py', 'cinder/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b8a064f10a4dad097ef40f401015897cf9b424c3', 'message': ""Handle volumes no longer existing in resume delete\n\ninit_host resumes deletes for volumes with a status of 'deleting'. It\ndoes these sequentially, and sometimes a volume could be deleted under\nit, causing a bad stacktrace. This will gracefully handle those\nsituations and move on. Added coverage for resume volume delete being\nsuccessful as well.\n\nChange-Id: I5b30265609b65804f2da77d9daa84b640de7939c\nCloses-Bug: #1322340\n""}]",7,95020,b8a064f10a4dad097ef40f401015897cf9b424c3,41,12,4,170,,,0,"Handle volumes no longer existing in resume delete

init_host resumes deletes for volumes with a status of 'deleting'. It
does these sequentially, and sometimes a volume could be deleted under
it, causing a bad stacktrace. This will gracefully handle those
situations and move on. Added coverage for resume volume delete being
successful as well.

Change-Id: I5b30265609b65804f2da77d9daa84b640de7939c
Closes-Bug: #1322340
",git fetch https://review.opendev.org/openstack/cinder refs/changes/20/95020/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/tests/test_volume.py']",2,9c81c42aa04a53e217713ca51250f9c05371230a,bug/1322340," def test_init_host_resumes_deletes(self): """"""init_host will resume deleting volume in deleting status."""""" volume = tests_utils.create_volume(self.context, status='deleting', size=0, host=CONF.host) volume_id = volume['id'] self.volume.init_host() self.assertRaises(exception.VolumeNotFound, db.volume_get, context.get_admin_context(), volume_id) @mock.patch('cinder.volume.manager.VolumeManager.delete_volume') def test_init_host_resumes_deletes_volume_not_exist(self, mock_delete): """"""init_host continues to resume if a volume is deleted under it."""""" mock_delete.side_effect = exception.VolumeNotFound( volume_id='12345678-1234-5678-1234-567812345678') tests_utils.create_volume(self.context, status='deleting', size=0, host=CONF.host) self.volume.init_host() self.assertTrue(mock_delete.called) ",,24,2
openstack%2Fmonasca-persister~master~I80e97af2667b800471e7f86c8a24ed5b1524e65d,openstack/monasca-persister,master,I80e97af2667b800471e7f86c8a24ed5b1524e65d,Fixed code formatting to follow guidelines.,MERGED,2014-07-17 17:20:17.000000000,2014-07-17 17:36:37.000000000,2014-07-17 17:36:37.000000000,"[{'_account_id': 3}, {'_account_id': 11182}]","[{'number': 1, 'created': '2014-07-17 17:20:17.000000000', 'files': ['src/main/java/com/hpcloud/mon/persister/configuration/InfluxDBConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/dbi/DBIProvider.java', 'src/main/java/com/hpcloud/mon/persister/repository/VerticaMetricsConstants.java', 'src/main/java/com/hpcloud/mon/persister/configuration/KafkaConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/repository/VerticaRepository.java', 'src/main/java/com/hpcloud/mon/persister/repository/InfluxDBAlarmRepository.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/MetricHandlerFactory.java', 'src/main/java/com/hpcloud/mon/persister/configuration/DisruptorConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaMetricsConsumerRunnableBasic.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaStreamsProvider.java', 'src/main/java/com/hpcloud/mon/persister/configuration/MonPersisterConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaMetricsConsumerRunnableBasicFactory.java', 'src/main/java/com/hpcloud/mon/persister/consumer/AlarmStateTransitionsConsumer.java', 'src/main/java/com/hpcloud/mon/persister/configuration/DeduperConfiguration.java', 'src/test/java/com/hpcloud/mon/persister/Test.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/AlarmStateTransitionedEventFactory.java', 'src/main/java/com/hpcloud/mon/persister/configuration/DatabaseConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/AlarmHistoryDisruptorProvider.java', 'src/main/java/com/hpcloud/mon/persister/resource/PlaceHolder.java', 'src/main/java/com/hpcloud/mon/persister/resource/Resource.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaMetricsConsumer.java', 'src/main/java/com/hpcloud/mon/persister/consumer/MetricsConsumer.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/ManagedDisruptor.java', 'src/main/java/com/hpcloud/mon/persister/repository/MetricRepository.java', 'src/main/java/com/hpcloud/mon/persister/configuration/MetricConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/MetricFactory.java', 'src/main/java/com/hpcloud/mon/persister/repository/AlarmRepository.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaAlarmStateTransitionConsumer.java', 'src/main/java/com/hpcloud/mon/persister/healthcheck/SimpleHealthCheck.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/AlarmStateHistoryDisruptor.java', 'src/main/java/com/hpcloud/mon/persister/configuration/AlarmHistoryConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaConsumer.java', 'src/main/java/com/hpcloud/mon/persister/MonPersisterApplication.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/AlarmStateTransitionedEventHandlerFactory.java', 'src/main/java/com/hpcloud/mon/persister/repository/Sha1HashId.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/MetricDisruptor.java', 'src/main/java/com/hpcloud/mon/persister/consumer/Consumer.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/MetricDisruptorProvider.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaAlarmStateTransitionConsumerRunnableBasic.java', 'src/test/java/com/hpcloud/mon/persister/MonPersisterConsumerTest.java', 'src/main/java/com/hpcloud/mon/persister/MonPersisterModule.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaStreams.java', 'src/main/java/com/hpcloud/mon/persister/configuration/OutputProcessorConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/repository/RepositoryCommitHeartbeat.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/DisruptorExceptionHandler.java', 'src/main/java/com/hpcloud/mon/persister/repository/VerticaAlarmRepository.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/AlarmStateTransitionedEventHandler.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaAlarmStateTransitionConsumerRunnableBasicFactory.java', 'src/main/java/com/hpcloud/mon/persister/repository/InfluxDBMetricRepository.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/AlarmStateTransitionedEventHolder.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/MetricHolder.java', 'src/main/java/com/hpcloud/mon/persister/repository/VerticaMetricRepository.java', 'src/main/java/com/hpcloud/mon/persister/configuration/VerticaMetricRepositoryConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/MetricHandler.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/FlushableHandler.java'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/d39d97fd11b4b462d96bbdc341e1f24be4f4b3d6', 'message': 'Fixed code formatting to follow guidelines.\n\nMade some changes to remove warnings about generics.\n\nRemoved unused instance properties.\n\nChange-Id: I80e97af2667b800471e7f86c8a24ed5b1524e65d\n'}]",0,107777,d39d97fd11b4b462d96bbdc341e1f24be4f4b3d6,8,2,1,11809,,,0,"Fixed code formatting to follow guidelines.

Made some changes to remove warnings about generics.

Removed unused instance properties.

Change-Id: I80e97af2667b800471e7f86c8a24ed5b1524e65d
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/77/107777/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/main/java/com/hpcloud/mon/persister/configuration/InfluxDBConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/dbi/DBIProvider.java', 'src/main/java/com/hpcloud/mon/persister/repository/VerticaMetricsConstants.java', 'src/main/java/com/hpcloud/mon/persister/configuration/KafkaConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/repository/VerticaRepository.java', 'src/main/java/com/hpcloud/mon/persister/repository/InfluxDBAlarmRepository.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/MetricHandlerFactory.java', 'src/main/java/com/hpcloud/mon/persister/configuration/DisruptorConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaMetricsConsumerRunnableBasic.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaStreamsProvider.java', 'src/main/java/com/hpcloud/mon/persister/configuration/MonPersisterConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaMetricsConsumerRunnableBasicFactory.java', 'src/main/java/com/hpcloud/mon/persister/consumer/AlarmStateTransitionsConsumer.java', 'src/main/java/com/hpcloud/mon/persister/configuration/DeduperConfiguration.java', 'src/test/java/com/hpcloud/mon/persister/Test.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/AlarmStateTransitionedEventFactory.java', 'src/main/java/com/hpcloud/mon/persister/configuration/DatabaseConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/AlarmHistoryDisruptorProvider.java', 'src/main/java/com/hpcloud/mon/persister/resource/PlaceHolder.java', 'src/main/java/com/hpcloud/mon/persister/resource/Resource.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaMetricsConsumer.java', 'src/main/java/com/hpcloud/mon/persister/consumer/MetricsConsumer.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/ManagedDisruptor.java', 'src/main/java/com/hpcloud/mon/persister/repository/MetricRepository.java', 'src/main/java/com/hpcloud/mon/persister/configuration/MetricConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/MetricFactory.java', 'src/main/java/com/hpcloud/mon/persister/repository/AlarmRepository.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaAlarmStateTransitionConsumer.java', 'src/main/java/com/hpcloud/mon/persister/healthcheck/SimpleHealthCheck.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/AlarmStateHistoryDisruptor.java', 'src/main/java/com/hpcloud/mon/persister/configuration/AlarmHistoryConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaConsumer.java', 'src/main/java/com/hpcloud/mon/persister/MonPersisterApplication.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/AlarmStateTransitionedEventHandlerFactory.java', 'src/main/java/com/hpcloud/mon/persister/repository/Sha1HashId.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/MetricDisruptor.java', 'src/main/java/com/hpcloud/mon/persister/consumer/Consumer.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/MetricDisruptorProvider.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaAlarmStateTransitionConsumerRunnableBasic.java', 'src/test/java/com/hpcloud/mon/persister/MonPersisterConsumerTest.java', 'src/main/java/com/hpcloud/mon/persister/MonPersisterModule.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaStreams.java', 'src/main/java/com/hpcloud/mon/persister/configuration/OutputProcessorConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/repository/RepositoryCommitHeartbeat.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/DisruptorExceptionHandler.java', 'src/main/java/com/hpcloud/mon/persister/repository/VerticaAlarmRepository.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/AlarmStateTransitionedEventHandler.java', 'src/main/java/com/hpcloud/mon/persister/consumer/KafkaAlarmStateTransitionConsumerRunnableBasicFactory.java', 'src/main/java/com/hpcloud/mon/persister/repository/InfluxDBMetricRepository.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/AlarmStateTransitionedEventHolder.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/MetricHolder.java', 'src/main/java/com/hpcloud/mon/persister/repository/VerticaMetricRepository.java', 'src/main/java/com/hpcloud/mon/persister/configuration/VerticaMetricRepositoryConfiguration.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/MetricHandler.java', 'src/main/java/com/hpcloud/mon/persister/disruptor/event/FlushableHandler.java']",55,d39d97fd11b4b462d96bbdc341e1f24be4f4b3d6,fix_format,,,2142,1895
openstack%2Fsecurity-doc~master~I8d2e77e32e3fdfdacdfc494cd4fe2b105b189f5b,openstack/security-doc,master,I8d2e77e32e3fdfdacdfc494cd4fe2b105b189f5b,Imported Translations from Transifex,MERGED,2014-07-17 06:05:42.000000000,2014-07-17 17:34:19.000000000,2014-07-17 17:34:19.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2807}]","[{'number': 1, 'created': '2014-07-17 06:05:42.000000000', 'files': ['security-guide/locale/security-guide.pot'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/c14f57c7e299c76ed1e8f26f02a4a4892657a3eb', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8d2e77e32e3fdfdacdfc494cd4fe2b105b189f5b\n'}]",0,107565,c14f57c7e299c76ed1e8f26f02a4a4892657a3eb,10,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I8d2e77e32e3fdfdacdfc494cd4fe2b105b189f5b
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/65/107565/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/locale/security-guide.pot'],1,c14f57c7e299c76ed1e8f26f02a4a4892657a3eb,transifex/translations,"""POT-Creation-Date: 2014-07-17 06:05+0000\n""msgid ""The OpenStack Identity service (keystone) supports multiple methods of authentication, including user name &amp; password, LDAP, and external authentication methods. Upon successful authentication, The Identity Service provides the user with an authorization token used for subsequent service requests.""msgid ""The Identity Service supports client authentication for SSL which may be enabled. SSL client authentication provides an additional authentication factor, in addition to the user name / password, that provides greater reliability on user identification. It reduces the risk of unauthorized access when user names and passwords may be compromised. However, there is additional administrative overhead and cost to issue certificates to users that may not be feasible in every deployment.""msgid ""The Identity V3 API supports multiple domains. Users of different domains may be represented in different authentication back ends and even have different attributes that must be mapped to a single set of roles and privileges, that are used in the policy definitions to access the various service resources.""msgid ""The ability to encrypt volumes depends on the service back ends chosen. Some back ends may not support this at all.""msgid ""Block storage supports a variety of mechanisms for supplying mountable volumes. It is outside the scope of this guide to specify recommendations for each Block Storage back-end driver. For the purpose of performance, many storage protocols are unencrypted. Some protocols such as iSCSI can provide authentication and encrypted sessions, it is our recommendation to enable these features.""msgid ""The OpenStack Security Group would like to acknowledge contributions from the following organizations that were instrumental in making this book possible. The organizations are:""msgid ""Simple Authentication and Security Layer (SASL) is a framework for authentication and data security in Internet protocols. Both RabbitMQ and Qpid offer SASL and other pluggable authentication mechanisms beyond simple user names and passwords that allow for increased authentication security. While RabbitMQ supports SASL, support in OpenStack does not currently allow for requesting a specific SASL authentication mechanism. RabbitMQ support in OpenStack allows for either user name and password authentication over an unencrypted connection or user name and password in conjunction with X.509 client certificates to establish the secure SSL connection.""msgid ""We recommend configuring X.509 client certificates on all the OpenStack service nodes for client connections to the messaging queue and where possible (currently only Qpid) perform authentication with X.509 client certificates. When using user names and passwords, accounts should be created per-service and node for finer grained auditability of access to the queue.""#: ./security-guide/ch_database-access-control.xml:109(None) ./security-guide/ch_database-access-control.xml:112(None)msgid ""Each of the core OpenStack services (Compute, Identity, Networking, Block Storage) store state and configuration information in databases. In this chapter, we discuss how databases are used currently in OpenStack. We also explore security concerns, and the security ramifications of database back end choices.""#: ./security-guide/ch_database-access-control.xml:26(title) ./security-guide/ch_database-access-control.xml:104(title)msgid ""Given the risks around access to the database, we strongly recommend that unique database user accounts be created per node needing access to the database. Doing this facilitates better analysis and auditing for ensuring compliance or in the event of a compromise of a node allows you to isolate the compromised host by removing access for that node to the database upon detection. When creating these per service endpoint database user accounts, care should be taken to ensure that they are configured to require SSL. Alternatively, for increased security it is recommended that the database accounts be configured using X.509 certificate authentication in addition to user names and passwords.""msgid ""If your database server is configured to require X.509 certificates for authentication you will need to specify the appropriate SQLAlchemy query parameters for the database back end. These parameters specify the certificate, private key, and certificate authority information for use with the initial connection string.""#: ./security-guide/ch_database-access-control.xml:99(para)#: ./security-guide/ch_database-access-control.xml:105(para)#: ./security-guide/ch_database-access-control.xml:106(para)#: ./security-guide/ch_database-access-control.xml:107(para)#: ./security-guide/ch_database-access-control.xml:115(para)#: ./security-guide/ch_database-access-control.xml:116(para)#: ./security-guide/ch_database-access-control.xml:117(para)#: ./security-guide/ch_database-access-control.xml:123(para)#: ./security-guide/ch_database-access-control.xml:124(para)msgid ""The management security domain is where services interact. Sometimes referred to as the \""control plane\"", the networks in this domain transport confidential data such as configuration parameters, user names, and passwords. Command and Control traffic typically resides in this domain, which necessitates strong integrity requirements. Access to this domain should be highly restricted and monitored. At the same time, this domain should still employ all of the security best practices described in this guide.""msgid ""Privacy concerns for public and private cloud users are typically diametrically opposed. The data generated and stored in private clouds is normally owned by the operator of the cloud, who is able to deploy technologies such as data loss prevention (DLP) protection, file inspection, deep packet inspection and prescriptive firewalling. In contrast, privacy is one of the primary barriers for the adoption of public cloud infrastructures, as many of the previously mentioned controls do not exist.""msgid ""A consumer can store objects, modify them, or access them using the HTTP protocol and REST APIs. Backend components of Object Storage use different protocols for keeping the information synchronized in a redundant cluster of services. For more details on the API and the back-end components see the <link href=\""http://docs.openstack.org/api/openstack-object-storage/1.0/content/\"">OpenStack Storage documentation</link>.""msgid ""It is recommended that you configure each service to run under a non-root (UID 0) service account. One recommendation is the user name \""swift\"" with primary group \""swift.\""""msgid ""Object Storage uses wsgi to provide a middleware for authentication of end-point clients. The authentication provider defines what roles and user types exist. Some use traditional user name and password credentials while others may leverage API key tokens or even client-side x.509 SSL certificates. Custom providers can be integrated in using the wsgi model.""msgid ""Session back end""msgid ""Horizon's default session back end (<literal>django.contrib.sessions.backends.signed_cookies</literal>) stores user data in <emphasis>signed</emphasis> but <emphasis>unencrypted </emphasis>cookies stored in the browser. This approach allows the most simple session back-end scaling since each dashboard instance is stateless, but it comes at the cost of <emphasis>storing sensitive access tokens in the client browser</emphasis> and transmitting them with every request. This back end ensures that session data has not been tampered with, but the data itself is not encrypted other than the encryption provided by HTTPS.""msgid ""If your architecture allows it, we recommend using <literal>django.contrib.sessions.backends.cache</literal> as your session back end with memcache as the cache. Memcache must not be exposed publicly, and should communicate over a secured private channel. If you choose to use the signed cookies back end, refer to the Django documentation understand the security trade-offs.""msgid ""For further details, consult the <link href=\""https://docs.djangoproject.com/en/1.5/topics/http/sessions/#configuring-the-session-engine\"">Django session back end documentation</link>.""#: ./security-guide/ch_forensics-and-incident-response.xml:48(title) ./security-guide/ch_continuous-systems-management.xml:276(title) ./security-guide/ch_management-interfaces.xml:93(title) ./security-guide/ch_management-interfaces.xml:163(title) ./security-guide/ch_management-interfaces.xml:202(title) ./security-guide/ch_compute.xml:60(title) ./security-guide/ch_compute.xml:107(title)msgid ""In addition to restricting database communications to the management network, we also strongly recommend that the cloud administrator configure their database back end to require SSL. Using SSL for the database client connections protects the communications from tampering and eavesdropping. As will be discussed in the next section, using SSL also provides the framework for doing database user authentication through X.509 certificates (commonly referred to as PKI). Below is guidance on how SSL is typically configured for the two popular database back ends MySQL and PostgreSQL.""#: ./security-guide/ch_continuous-systems-management.xml:250(title) ./security-guide/ch_management-interfaces.xml:60(title) ./security-guide/ch_management-interfaces.xml:120(title) ./security-guide/ch_management-interfaces.xml:153(title) ./security-guide/ch_management-interfaces.xml:177(title) ./security-guide/ch_compute.xml:45(title) ./security-guide/ch_compute.xml:91(title)msgid ""OpenStack endpoints are HTTP services providing APIs to both end-users on public networks and to other OpenStack services on the management network. It is highly recommended that all of these requests, both internal and external, operate over SSL. To achieve this goal, API services must be deployed behind a SSL proxy that can establish and terminate SSL sessions. The following table offers a non-exhaustive list of open source software that can be used for this purpose:""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:16(link) ./security-guide/ch_ssl-proxies-and-http-services.xml:111(title)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:19(link) ./security-guide/ch_ssl-proxies-and-http-services.xml:165(title)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:22(link) ./security-guide/ch_ssl-proxies-and-http-services.xml:204(title)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:25(link)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:28(para) msgid ""In cases where software termination offers insufficient performance, hardware accelerators may be worth exploring as an alternative option. It is important to be mindful of the size of requests that will be processed by any chosen SSL proxy.""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:32(title)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:33(para) msgid ""Below we provide sample recommended configuration settings for enabling SSL in some of the more popular web servers/SSL terminators. Note that we have SSL v3 enabled in some of these examples as this will be required in many deployments for client compatibility.""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:36(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:40(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:44(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:47(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:49(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:50(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:51(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:52(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:56(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:58(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:62(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:64(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:68(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:70(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:74(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:76(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:80(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:82(para) msgid ""Disallows clear text.""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:86(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:88(para) msgid ""Disallows export encryption algorithms, which by design tend to be weak, typically using 40 and 56 bit keys.""msgid ""US Export restrictions on cryptography systems have been lifted and no longer need to be supported.""msgid ""!LOW:!MEDIUM""msgid ""Disallows low (56 or 64 bit long keys) and medium (128 bit long keys) ciphers because of their vulnerability to brute force attacks (example 2-DES). This rule still permits Triple Data Encryption Standard (Triple DES) also known as Triple Data Encryption Algorithm (TDEA) and the Advanced Encryption Standard (AES), each of which has keys greater than equal to 128 bits and thus more secure."" msgstr """" #: ./security-guide/ch_ssl-proxies-and-http-services.xml:104(code) msgid ""Protocols"" msgstr """" #: ./security-guide/ch_ssl-proxies-and-http-services.xml:106(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:112(para) msgid ""This Pound example enables <literal>AES-NI</literal> acceleration, which helps to improve performance on systems with processors that support this feature.""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:166(para) msgid ""This stud example enables SSL v3 for client compatibility. The <emphasis role=\""italic\"">ciphers</emphasis> line can be tweaked based on your needs, however this is a reasonable starting place.""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:205(para) msgid ""This nginx example requires TLS v1.1 or v1.2 for maximum security. The <option>ssl_ciphers</option> line can be tweaked based on your needs, however this is a reasonable starting place.""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:223(title) ./security-guide/glossary-terms.xml:335(primary)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:248(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:272(title)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:273(para) msgid ""We recommend that all production deployments use HTTP strict transport security (HSTS). This header prevents browsers from making insecure connections after they have made a single secure one. If you have deployed your HTTP services on a public or an untrusted domain, HSTS is especially important. To enable HSTS, configure your web server to send a header like this with all requests:""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:279(para) msgid ""Start with a short timeout of 1 day during testing, and raise it to one year after testing has shown that you have not introduced problems for users. Note that once this header is set to a large timeout, it is (by design) very difficult to disable.""msgid ""Database back end considerations""msgid ""Security references for database back ends""#: ./security-guide/ch_management-interfaces.xml:18(para) ./security-guide/ch_management-interfaces.xml:98(title)#: ./security-guide/ch_management-interfaces.xml:21(para) ./security-guide/ch_management-interfaces.xml:131(title)#: ./security-guide/ch_management-interfaces.xml:41(title) ./security-guide/ch_management-interfaces.xml:106(title) ./security-guide/ch_compute.xml:22(title) ./security-guide/ch_compute.xml:68(title)msgid ""Both the horizon web service and the OpenStack API it uses to communicate with the back end are susceptible to web attack vectors such as denial of service and must be monitored.""#: ./security-guide/ch_management-interfaces.xml:74(para)#: ./security-guide/ch_management-interfaces.xml:84(para)#: ./security-guide/ch_management-interfaces.xml:94(citetitle)#: ./security-guide/ch_management-interfaces.xml:99(para)#: ./security-guide/ch_management-interfaces.xml:108(para)#: ./security-guide/ch_management-interfaces.xml:115(para)#: ./security-guide/ch_management-interfaces.xml:122(para)#: ./security-guide/ch_management-interfaces.xml:125(para)#: ./security-guide/ch_management-interfaces.xml:132(para)#: ./security-guide/ch_management-interfaces.xml:134(title)#: ./security-guide/ch_management-interfaces.xml:135(para)#: ./security-guide/ch_management-interfaces.xml:136(para)#: ./security-guide/ch_management-interfaces.xml:137(para)#: ./security-guide/ch_management-interfaces.xml:138(para)#: ./security-guide/ch_management-interfaces.xml:142(title)#: ./security-guide/ch_management-interfaces.xml:143(para)#: ./security-guide/ch_management-interfaces.xml:155(para)#: ./security-guide/ch_management-interfaces.xml:158(para)#: ./security-guide/ch_management-interfaces.xml:164(para)#: ./security-guide/ch_management-interfaces.xml:165(para)#: ./security-guide/ch_management-interfaces.xml:169(title)#: ./security-guide/ch_management-interfaces.xml:170(para)#: ./security-guide/ch_management-interfaces.xml:179(para)#: ./security-guide/ch_management-interfaces.xml:182(para)#: ./security-guide/ch_management-interfaces.xml:185(para)#: ./security-guide/ch_management-interfaces.xml:194(para)#: ./security-guide/ch_management-interfaces.xml:199(para)#: ./security-guide/ch_management-interfaces.xml:203(link)#: ./security-guide/ch_data-privacy-concerns.xml:108(para) ./security-guide/ch_data-privacy-concerns.xml:140(title)#: ./security-guide/ch_data-privacy-concerns.xml:111(para) ./security-guide/ch_data-privacy-concerns.xml:147(title)msgid ""Some back ends such as ZFS will support copy-on-write to prevent data exposure. In these cases, reads from unwritten blocks will always return zero. Other back ends such as LVM may not natively support this, thus the Block Storage plug-in takes the responsibility to override previously written blocks before handing them to users. It is important to review what assurances your chosen volume back end provides and to see what mediations may be available for those assurances not provided.""#: ./security-guide/ch_data-privacy-concerns.xml:137(para)#: ./security-guide/ch_data-privacy-concerns.xml:141(para)#: ./security-guide/ch_data-privacy-concerns.xml:142(para)#: ./security-guide/ch_data-privacy-concerns.xml:143(para)#: ./security-guide/ch_data-privacy-concerns.xml:144(para)#: ./security-guide/ch_data-privacy-concerns.xml:148(para)#: ./security-guide/ch_data-privacy-concerns.xml:155(para)msgid ""A hybrid cloud is defined by NIST as a composition of two or more distinct cloud infrastructures, such as private, community, or public, that remain unique entities, but are bound together by standardized or proprietary technology that enables data and application portability, such as cloud bursting for load balancing between clouds. For example an online retailer may have their advertising and catalogue presented on a public cloud that allows for elastic provisioning. This would enable them to handle seasonal loads in a flexible, cost-effective fashion. Once a customer begins to process their order, they are transferred to the more secure private cloud back end that is PCI compliant.""msgid ""OpenStack relies on messaging for internal communication between several of its services. By default, OpenStack uses message queues based on the Advanced Message Queue Protocol (<glossterm baseform=\""Advanced Message Queuing Protocol (AMQP)\"">AMQP </glossterm>). Similar to most OpenStack services, it supports pluggable components. Today the implementation back end could be <glossterm>RabbitMQ</glossterm>, <glossterm>Qpid</glossterm>, or <glossterm>ZeroMQ</glossterm>.""#: ./security-guide/ch_compute.xml:54(para) msgid ""By default, the remote desktop traffic is not encrypted. SSL can be enabled to encrypt the VNC traffic.""#: ./security-guide/ch_compute.xml:62(link) msgid ""Using SSL encryption with nova novncproxy"" msgstr """" #: ./security-guide/ch_compute.xml:65(title)#: ./security-guide/ch_compute.xml:66(para)#: ./security-guide/ch_compute.xml:70(para)#: ./security-guide/ch_compute.xml:79(para)#: ./security-guide/ch_compute.xml:84(title)#: ./security-guide/ch_compute.xml:86(para)#: ./security-guide/ch_compute.xml:93(para)#: ./security-guide/ch_compute.xml:99(para)#: ./security-guide/ch_compute.xml:102(para)#: ./security-guide/ch_compute.xml:108(link)#: ./security-guide/ch_compute.xml:109(link)#: ./security-guide/ch_compute.xml:110(link)","""POT-Creation-Date: 2014-07-16 06:04+0000\n""msgid ""The OpenStack Identity service (keystone) supports multiple methods of authentication, including username &amp; password, LDAP, and external authentication methods. Upon successful authentication, The Identity Service provides the user with an authorization token used for subsequent service requests.""msgid ""The Identity Service supports client authentication for SSL which may be enabled. SSL client authentication provides an additional authentication factor, in addition to the username / password, that provides greater reliability on user identification. It reduces the risk of unauthorized access when user names and passwords may be compromised. However, there is additional administrative overhead and cost to issue certificates to users that may not be feasible in every deployment.""msgid ""The Identity V3 API supports multiple domains. Users of different domains may be represented in different authentication backends and even have different attributes that must be mapped to a single set of roles and privileges, that are used in the policy definitions to access the various service resources.""msgid ""The ability to encrypt volumes depends on the service backends chosen. Some backends may not support this at all.""msgid ""Block storage supports a variety of mechanisms for supplying mountable volumes. It is outside the scope of this guide to specify recommendations for each Block Storage backend driver. For the purpose of performance, many storage protocols are unencrypted. Some protocols such as iSCSI can provide authentication and encrypted sessions, it is our recommendation to enable these features.""msgid ""The OpenStack Security Group would like to acknowledge contributions from the following organizations who were instrumental in making this book possible. These are:""msgid ""Simple Authentication and Security Layer (SASL) is a framework for authentication and data security in Internet protocols. Both RabbitMQ and Qpid offer SASL and other pluggable authentication mechanisms beyond simple usernames and passwords that allow for increased authentication security. While RabbitMQ supports SASL, support in OpenStack does not currently allow for requesting a specific SASL authentication mechanism. RabbitMQ support in OpenStack allows for either username and password authentication over an unencrypted connection or username and password in conjunction with X.509 client certificates to establish the secure SSL connection.""msgid ""We recommend configuring X.509 client certificates on all the OpenStack service nodes for client connections to the messaging queue and where possible (currently only Qpid) perform authentication with X.509 client certificates. When using usernames and passwords, accounts should be created per-service and node for finer grained auditability of access to the queue.""#: ./security-guide/ch_database-access-control.xml:104(None) ./security-guide/ch_database-access-control.xml:107(None)msgid ""Each of the core OpenStack services (Compute, Identity, Networking, Block Storage) store state and configuration information in databases. In this chapter, we discuss how databases are used currently in OpenStack. We also explore security concerns, and the security ramifications of database backend choices.""#: ./security-guide/ch_database-access-control.xml:26(title) ./security-guide/ch_database-access-control.xml:99(title)msgid ""Given the risks around access to the database, we strongly recommend that unique database user accounts be created per node needing access to the database. Doing this facilitates better analysis and auditing for ensuring compliance or in the event of a compromise of a node allows you to isolate the compromised host by removing access for that node to the database upon detection. When creating these per service endpoint database user accounts, care should be taken to ensure that they are configured to require SSL. Alternatively, for increased security it is recommended that the database accounts be configured using X.509 certificate authentication in addition to usernames and passwords.""msgid ""If your database server is configured to require X.509 certificates for authentication you will need to specify the appropriate SQLAlchemy query parameters for the database backend. These parameters specify the certificate, private key, and certificate authority information for use with the initial connection string.""#: ./security-guide/ch_database-access-control.xml:94(para)#: ./security-guide/ch_database-access-control.xml:100(para)#: ./security-guide/ch_database-access-control.xml:101(para)#: ./security-guide/ch_database-access-control.xml:102(para)#: ./security-guide/ch_database-access-control.xml:110(para)#: ./security-guide/ch_database-access-control.xml:111(para)#: ./security-guide/ch_database-access-control.xml:112(para)#: ./security-guide/ch_database-access-control.xml:118(para)#: ./security-guide/ch_database-access-control.xml:119(para)msgid ""The management security domain is where services interact. Sometimes referred to as the \""control plane\"", the networks in this domain transport confidential data such as configuration parameters, usernames, and passwords. Command and Control traffic typically resides in this domain, which necessitates strong integrity requirements. Access to this domain should be highly restricted and monitored. At the same time, this domain should still employ all of the security best practices described in this guide.""msgid ""Privacy concerns for public and private cloud users are typically diametrically opposed. The data generated and stored in private clouds is normally owned by the operator of the cloud, who is able to deploy technologies such as data loss prevention (DLP) protection, file inspection, deep packet inspection and prescriptive firewalling. In contrast, privacy is one of the primary barriers to adoption for the public cloud, as many of these controls do not exist.""msgid ""A consumer can store objects, modify them, or access them using the HTTP protocol and REST APIs. Backend components of Object Storage use different protocols for keeping the information synchronized in a redundant cluster of services. For more details on the API and the backend components see the <link href=\""http://docs.openstack.org/api/openstack-object-storage/1.0/content/\"">OpenStack Storage documentation</link>.""msgid ""It is recommended that you configure each service to run under a non-root (UID 0) service account. One recommendation is the username \""swift\"" with primary group \""swift.\""""msgid ""Object Storage uses wsgi to provide a middleware for authentication of end-point clients. The authentication provider defines what roles and user types exist. Some use traditional username and password credentials while others may leverage API key tokens or even client-side x.509 SSL certificates. Custom providers can be integrated in using the wsgi model.""msgid ""Session back-end""msgid ""Horizon's default session back-end (<literal>django.contrib.sessions.backends.signed_cookies</literal>) stores user data in <emphasis>signed</emphasis> but <emphasis>unencrypted </emphasis>cookies stored in the browser. This approach allows the most simple session backend scaling since each dashboard instance is stateless, but it comes at the cost of <emphasis>storing sensitive access tokens in the client browser</emphasis> and transmitting them with every request. This backend ensures that session data has not been tampered with, but the data itself is not encrypted other than the encryption provided by HTTPS.""msgid ""If your architecture allows it, we recommend using <literal>django.contrib.sessions.backends.cache</literal> as your session backend with memcache as the cache. Memcache must not be exposed publicly, and should communicate over a secured private channel. If you choose to use the signed cookies backend, refer to the Django documentation understand the security trade-offs.""msgid ""For further details, consult the <link href=\""https://docs.djangoproject.com/en/1.5/topics/http/sessions/#configuring-the-session-engine\"">Django session backend documentation</link>.""#: ./security-guide/ch_forensics-and-incident-response.xml:48(title) ./security-guide/ch_continuous-systems-management.xml:276(title) ./security-guide/ch_management-interfaces.xml:90(title) ./security-guide/ch_management-interfaces.xml:160(title) ./security-guide/ch_management-interfaces.xml:199(title) ./security-guide/ch_compute.xml:60(title) ./security-guide/ch_compute.xml:106(title)msgid ""In addition to restricting database communications to the management network, we also strongly recommend that the cloud administrator configure their database backend to require SSL. Using SSL for the database client connections protects the communications from tampering and eavesdropping. As will be discussed in the next section, using SSL also provides the framework for doing database user authentication through X.509 certificates (commonly referred to as PKI). Below is guidance on how SSL is typically configured for the two popular database backends MySQL and PostgreSQL.""#: ./security-guide/ch_continuous-systems-management.xml:250(title) ./security-guide/ch_management-interfaces.xml:60(title) ./security-guide/ch_management-interfaces.xml:117(title) ./security-guide/ch_management-interfaces.xml:150(title) ./security-guide/ch_management-interfaces.xml:174(title) ./security-guide/ch_compute.xml:45(title) ./security-guide/ch_compute.xml:90(title)msgid ""OpenStack endpoints are HTTP services providing APIs to both end-users on public networks and to other OpenStack services within the same deployment operating over the management network. It is highly recommended these requests, both those internal and external, operate over SSL.""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:10(para) msgid ""In order for API requests to be encrypted by SSL it's necessary to position the API services behind a proxy that will establish and terminate SSL sessions. The following table offers a non-exhaustive list of software services that can proxy SSL traffic for API requests:"" msgstr """" #: ./security-guide/ch_ssl-proxies-and-http-services.xml:12(link)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:15(link) ./security-guide/ch_ssl-proxies-and-http-services.xml:153(title)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:18(link) ./security-guide/ch_ssl-proxies-and-http-services.xml:191(title)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:21(link)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:24(para) msgid ""Hardware appliance SSL acceleration proxies""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:27(para) msgid ""It is important to be mindful of the size of requests that will be processed by any chosen SSL proxy."" msgstr """" #: ./security-guide/ch_ssl-proxies-and-http-services.xml:29(title)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:30(para) msgid ""Below we provide some sample recommended configuration settings for enabling SSL in some of the more popular web servers/SSL terminators. Note that we have SSL v3 enabled in some of these examples as this will be required in many deployments for client compatibility.""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:31(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:35(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:39(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:42(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:44(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:45(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:46(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:47(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:51(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:53(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:57(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:59(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:63(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:65(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:69(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:71(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:75(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:77(para) msgid ""Disallows clear text""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:81(code)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:83(para) msgid ""Disallows export encryption algorithms, which by design tend to were weak, typically using 40 and 56 bit keys."" msgstr """" #: ./security-guide/ch_ssl-proxies-and-http-services.xml:84(para) msgid ""US Export restrictions on cryptography systems have been lifted and no longer need to be supported."" msgstr """" #: ./security-guide/ch_ssl-proxies-and-http-services.xml:88(code) msgid ""!LOW:!MEDIUM""msgid ""Disallows low (keys 56 or 64 bits long) and medium (128 bit long keys) ciphers because of their vulnerability to brute force attacks (example 2-DES). This constraint leaves acceptable Triple Data Encryption Standard (Triple DES) also known as Triple Data Encryption Algorithm (TDEA) and the Advanced Encryption Standard (AES), each of which has keys greater than equal to 128 bits and thus more secure.""msgid ""Protocols""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:101(title) msgid ""Pound - with AES-NI acceleration""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:154(para) msgid ""This stud example enables SSL v3 for client compatibility. The ciphers line can be tweaked based on your needs, however this is a reasonable starting place.""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:192(para) msgid ""This nginx example requires TLS v1.1 or v1.2 for maximum security. The ssl_ciphers line can be tweaked based on your needs, however this is a reasonable starting place.""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:208(title) ./security-guide/glossary-terms.xml:335(primary)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:233(para)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:257(title)#: ./security-guide/ch_ssl-proxies-and-http-services.xml:258(para) msgid ""We recommend that all production deployments use HSTS. This header prevents browsers from making insecure connections after they have made a single secure one. If you have deployed your HTTP services on a public or an untrusted domain, HSTS is especially important. To enable HSTS, configure your web server to send a header like this with all requests:""#: ./security-guide/ch_ssl-proxies-and-http-services.xml:260(para) msgid ""Start with a short timeout of 1 day during testing, and raise it to one year after testing has shown that you haven't introduced problems for users. Note that once this header is set to a large timeout, it is (by design) very difficult to disable.""msgid ""Database back-end considerations""msgid ""Security references for database back-ends""#: ./security-guide/ch_management-interfaces.xml:18(para) ./security-guide/ch_management-interfaces.xml:95(title)#: ./security-guide/ch_management-interfaces.xml:21(para) ./security-guide/ch_management-interfaces.xml:128(title)#: ./security-guide/ch_management-interfaces.xml:41(title) ./security-guide/ch_management-interfaces.xml:103(title) ./security-guide/ch_compute.xml:22(title) ./security-guide/ch_compute.xml:67(title)msgid ""Both the horizon web service and the OpenStack API it uses to communicate with the back-end are susceptible to web attack vectors such as denial of service and must be monitored.""#: ./security-guide/ch_management-interfaces.xml:71(para)#: ./security-guide/ch_management-interfaces.xml:81(para)#: ./security-guide/ch_management-interfaces.xml:91(citetitle)#: ./security-guide/ch_management-interfaces.xml:96(para)#: ./security-guide/ch_management-interfaces.xml:105(para)#: ./security-guide/ch_management-interfaces.xml:112(para)#: ./security-guide/ch_management-interfaces.xml:119(para)#: ./security-guide/ch_management-interfaces.xml:122(para)#: ./security-guide/ch_management-interfaces.xml:129(para)#: ./security-guide/ch_management-interfaces.xml:131(title)#: ./security-guide/ch_management-interfaces.xml:132(para)#: ./security-guide/ch_management-interfaces.xml:133(para)#: ./security-guide/ch_management-interfaces.xml:134(para)#: ./security-guide/ch_management-interfaces.xml:135(para)#: ./security-guide/ch_management-interfaces.xml:139(title)#: ./security-guide/ch_management-interfaces.xml:140(para)#: ./security-guide/ch_management-interfaces.xml:152(para)#: ./security-guide/ch_management-interfaces.xml:155(para)#: ./security-guide/ch_management-interfaces.xml:161(para)#: ./security-guide/ch_management-interfaces.xml:162(para)#: ./security-guide/ch_management-interfaces.xml:166(title)#: ./security-guide/ch_management-interfaces.xml:167(para)#: ./security-guide/ch_management-interfaces.xml:176(para)#: ./security-guide/ch_management-interfaces.xml:179(para)#: ./security-guide/ch_management-interfaces.xml:182(para)#: ./security-guide/ch_management-interfaces.xml:191(para)#: ./security-guide/ch_management-interfaces.xml:196(para)#: ./security-guide/ch_management-interfaces.xml:200(link)#: ./security-guide/ch_data-privacy-concerns.xml:108(para) ./security-guide/ch_data-privacy-concerns.xml:132(title)#: ./security-guide/ch_data-privacy-concerns.xml:111(para) ./security-guide/ch_data-privacy-concerns.xml:139(title)msgid ""Some backends such as ZFS will support copy-on-write to prevent data exposure. In these cases, reads from unwritten blocks will always return zero. Other backends such as LVM may not natively support this, thus the Block Storage plug-in takes the responsibility to override previously written blocks before handing them to users. It is important to review what assurances your chosen volume backend provides and to see what mediations may be available for those assurances not provided.""#: ./security-guide/ch_data-privacy-concerns.xml:129(para)#: ./security-guide/ch_data-privacy-concerns.xml:133(para)#: ./security-guide/ch_data-privacy-concerns.xml:134(para)#: ./security-guide/ch_data-privacy-concerns.xml:135(para)#: ./security-guide/ch_data-privacy-concerns.xml:136(para)#: ./security-guide/ch_data-privacy-concerns.xml:140(para)#: ./security-guide/ch_data-privacy-concerns.xml:147(para)msgid ""A hybrid cloud is defined by NIST as a composition of two or more distinct cloud infrastructures, such as private, community, or public, that remain unique entities, but are bound together by standardized or proprietary technology that enables data and application portability, such as cloud bursting for load balancing between clouds. For example an online retailer may have their advertising and catalogue presented on a public cloud that allows for elastic provisioning. This would enable them to handle seasonal loads in a flexible, cost-effective fashion. Once a customer begins to process their order, they are transferred to the more secure private cloud backend that is PCI compliant.""msgid ""OpenStack relies on messaging for internal communication between several of its services. By default, OpenStack uses message queues based on the Advanced Message Queue Protocol (<glossterm baseform=\""Advanced Message Queuing Protocol (AMQP)\"">AMQP </glossterm>). Similar to most OpenStack services, it supports pluggable components. Today the implementation backend could be <glossterm>RabbitMQ</glossterm>, <glossterm>Qpid</glossterm>, or <glossterm>ZeroMQ</glossterm>.""#. TODO - check if havana had this feature #: ./security-guide/ch_compute.xml:55(para) msgid ""By default, the remote desktop traffic is not encrypted. Havana is expected to have VNC connections secured by Kerberos.""#: ./security-guide/ch_compute.xml:64(title)#: ./security-guide/ch_compute.xml:65(para)#: ./security-guide/ch_compute.xml:69(para)#: ./security-guide/ch_compute.xml:78(para)#: ./security-guide/ch_compute.xml:83(title)#: ./security-guide/ch_compute.xml:85(para)#: ./security-guide/ch_compute.xml:92(para)#: ./security-guide/ch_compute.xml:98(para)#: ./security-guide/ch_compute.xml:101(para)#: ./security-guide/ch_compute.xml:107(link)#: ./security-guide/ch_compute.xml:108(link)#: ./security-guide/ch_compute.xml:109(link)",154,159
openstack%2Ftrove~master~If71f78e50f8a9b3acfd1e9d02c8271f17c4ebee7,openstack/trove,master,If71f78e50f8a9b3acfd1e9d02c8271f17c4ebee7,Ensure routing key is specified in the address for a direct producer,MERGED,2014-06-09 21:09:24.000000000,2014-07-17 17:32:30.000000000,2014-07-17 17:32:30.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 5892}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 10215}]","[{'number': 1, 'created': '2014-06-09 21:09:24.000000000', 'files': ['trove/openstack/common/rpc/impl_qpid.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/117c18cbd9d5ab3970ad3775e156862f256a924a', 'message': ""Ensure routing key is specified in the address for a direct producer\n\nThis change is already merged in oslo-incubator.  Note that this is\nnot a clean merge of the fix, as Trove's copy of rpc from\noslo-incubator is *VERY* far out of date.  However, the bug still\nexisted in the code.  The fix just looks slightly different.\n\nOriginal commit message body includes:\n\n    Porting this fix from oslo.messaging.  This fixes the impl_qpid.py\n    driver to allow it to work with the latest stable upstream QPID broker\n    (version 0.28).  See the Apache Qpid Jira bug\n    https://issues.apache.org/jira/browse/QPID-5557\n\nChange-Id: If71f78e50f8a9b3acfd1e9d02c8271f17c4ebee7\nRelated-Bug: #1300318\n""}]",0,98900,117c18cbd9d5ab3970ad3775e156862f256a924a,27,8,1,1561,,,0,"Ensure routing key is specified in the address for a direct producer

This change is already merged in oslo-incubator.  Note that this is
not a clean merge of the fix, as Trove's copy of rpc from
oslo-incubator is *VERY* far out of date.  However, the bug still
existed in the code.  The fix just looks slightly different.

Original commit message body includes:

    Porting this fix from oslo.messaging.  This fixes the impl_qpid.py
    driver to allow it to work with the latest stable upstream QPID broker
    (version 0.28).  See the Apache Qpid Jira bug
    https://issues.apache.org/jira/browse/QPID-5557

Change-Id: If71f78e50f8a9b3acfd1e9d02c8271f17c4ebee7
Related-Bug: #1300318
",git fetch https://review.opendev.org/openstack/trove refs/changes/00/98900/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/openstack/common/rpc/impl_qpid.py'],1,117c18cbd9d5ab3970ad3775e156862f256a924a,(detached," node_name = ""%s/%s"" % (msg_id, msg_id) super(DirectPublisher, self).__init__(session, node_name,"," super(DirectPublisher, self).__init__(session, msg_id,",2,1
openstack%2Fkeystone~stable%2Fhavana~If70a4114d73c71a1304cce6e937b0048213e730f,openstack/keystone,stable/havana,If70a4114d73c71a1304cce6e937b0048213e730f,add stevedore for testing with Keystoneclient master,MERGED,2014-07-15 09:43:12.000000000,2014-07-17 17:21:04.000000000,2014-07-17 17:21:04.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1955}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-07-15 09:43:12.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6131b3f5c0112d74198e13a78d56e9b77707ad00', 'message': 'add stevedore for testing with Keystoneclient master\n\nstable/* tests run with Keystoneclient master and stevedore\ndependency was introduced by ""Plugin loading from config objects""\nhttps://github.com/openstack/python-keystoneclient/commit/5c91ede44768ebbb2fff12f9a7c93e63b9bbd56d\n\nChange-Id: If70a4114d73c71a1304cce6e937b0048213e730f\n'}]",0,106974,6131b3f5c0112d74198e13a78d56e9b77707ad00,9,4,1,1955,,,0,"add stevedore for testing with Keystoneclient master

stable/* tests run with Keystoneclient master and stevedore
dependency was introduced by ""Plugin loading from config objects""
https://github.com/openstack/python-keystoneclient/commit/5c91ede44768ebbb2fff12f9a7c93e63b9bbd56d

Change-Id: If70a4114d73c71a1304cce6e937b0048213e730f
",git fetch https://review.opendev.org/openstack/keystone refs/changes/74/106974/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,6131b3f5c0112d74198e13a78d56e9b77707ad00,havana-stevedore,# for keystoneclient Plugin loading from config objects stevedore>=0.10,,2,0
openstack%2Fnova~master~If1c6ec30c6f49009ef42f9a3b3df1594783b0ae5,openstack/nova,master,If1c6ec30c6f49009ef42f9a3b3df1594783b0ae5,Defer raising an exception when deleting volumes,MERGED,2014-07-14 21:41:05.000000000,2014-07-17 17:15:09.000000000,2014-07-17 15:24:39.000000000,"[{'_account_id': 3}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 6167}, {'_account_id': 8430}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-14 21:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/507a2bb90ec7facd4dd1b12c75d8775461c3bce7', 'message': 'Defer raising an exception when deleting volumes\n\nWhen looping through block device mappings to delete volumes with\ndelete_on_terminate set the loop should not exit on an exception.\nInstead the loop will continue and the last exception can optionally be\nraised.\n\nChange-Id: If1c6ec30c6f49009ef42f9a3b3df1594783b0ae5\nCloses-Bug: #1341738\n'}, {'number': 2, 'created': '2014-07-15 18:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42a9ecdfb0c60f339fe11c4b0f925c9bdd4a4b7f', 'message': 'Defer raising an exception when deleting volumes\n\nWhen looping through block device mappings to delete volumes with\ndelete_on_terminate set the loop should not exit on an exception.\nInstead the loop will continue and the last exception can optionally be\nraised.\n\nChange-Id: If1c6ec30c6f49009ef42f9a3b3df1594783b0ae5\nCloses-Bug: #1341738\n'}, {'number': 3, 'created': '2014-07-15 19:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98322fb47b273073c6cd98c3c983a77432284a4b', 'message': 'Defer raising an exception when deleting volumes\n\nWhen looping through block device mappings to delete volumes with\ndelete_on_terminate set the loop should not exit on an exception.\nInstead the loop will continue and the last exception can optionally be\nraised.\n\nChange-Id: If1c6ec30c6f49009ef42f9a3b3df1594783b0ae5\nCloses-Bug: #1341738\n'}, {'number': 4, 'created': '2014-07-15 20:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74f6302b28dc4e935567806ae843ada8e50b5dd3', 'message': 'Defer raising an exception when deleting volumes\n\nWhen looping through block device mappings to delete volumes with\ndelete_on_terminate set the loop should not exit on an exception.\nInstead the loop will continue and the last exception can optionally be\nraised.\n\nChange-Id: If1c6ec30c6f49009ef42f9a3b3df1594783b0ae5\nCloses-Bug: #1341738\n'}, {'number': 5, 'created': '2014-07-16 17:30:16.000000000', 'files': ['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/70feb102ae86d3421e46a07710e4cbab35408d02', 'message': 'Defer raising an exception when deleting volumes\n\nWhen looping through block device mappings to delete volumes with\ndelete_on_terminate set the loop should not exit on an exception.\nInstead the loop will continue and the last exception can optionally be\nraised.\n\nChange-Id: If1c6ec30c6f49009ef42f9a3b3df1594783b0ae5\nCloses-Bug: #1341738\n'}]",6,106879,70feb102ae86d3421e46a07710e4cbab35408d02,56,12,5,5441,,,0,"Defer raising an exception when deleting volumes

When looping through block device mappings to delete volumes with
delete_on_terminate set the loop should not exit on an exception.
Instead the loop will continue and the last exception can optionally be
raised.

Change-Id: If1c6ec30c6f49009ef42f9a3b3df1594783b0ae5
Closes-Bug: #1341738
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/106879/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",3,507a2bb90ec7facd4dd1b12c75d8775461c3bce7,bug/1336127," mox.IgnoreArg(), raise_exc=True) mox.IgnoreArg(), raise_exc=True) mox.IgnoreArg(), raise_exc=True)"," def test_delete_instance_succedes_on_volume_fail(self): instance = self._create_fake_instance_obj() def fake_cleanup_volumes(context, instance): raise test.TestingException() self.stubs.Set(self.compute, '_cleanup_volumes', fake_cleanup_volumes) self.compute._delete_instance(self.context, instance, [], self.none_quotas) mox.IgnoreArg()) mox.IgnoreArg()) mox.IgnoreArg())",23,27
openstack%2Fglance_store~master~I56778033497318d54b90c3e43e02933e3c2a0720,openstack/glance_store,master,I56778033497318d54b90c3e43e02933e3c2a0720,Remove version string from setup.cfg,MERGED,2014-07-17 07:50:42.000000000,2014-07-17 17:08:10.000000000,2014-07-17 17:08:10.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-17 07:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/194b518d91b8a747b3bde14689cf69a5d7bff813', 'message': 'Remove version string from setup.cfg\n\nPypi jobs take care of setting up the version number based on the tag\nname.\n\nChange-Id: I56778033497318d54b90c3e43e02933e3c2a0720\n'}, {'number': 2, 'created': '2014-07-17 07:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/d68b2b6f10a5900c7f35981cc58af8a2bf3dfac0', 'message': 'Remove version string from setup.cfg\n\nPypi jobs take care of setting up the version number based on the tag\nname.\n\nChange-Id: I56778033497318d54b90c3e43e02933e3c2a0720\n'}, {'number': 3, 'created': '2014-07-17 08:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/fde413e367f2c16dd108d5f998f21f56ebdc2eb1', 'message': 'Remove version string from setup.cfg\n\nPypi jobs take care of setting up the version number based on the tag\nname.\n\nChange-Id: I56778033497318d54b90c3e43e02933e3c2a0720\n'}, {'number': 4, 'created': '2014-07-17 08:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/60ec31fe210fd02a852d0fcbd41bb0308f0aac5a', 'message': 'Remove version string from setup.cfg\n\nPypi jobs take care of setting up the version number based on the tag\nname.\n\nChange-Id: I56778033497318d54b90c3e43e02933e3c2a0720\n'}, {'number': 5, 'created': '2014-07-17 09:53:30.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/8f386b2ed133c86b32324a6830b00b54a3ce3a22', 'message': 'Remove version string from setup.cfg\n\nPypi jobs take care of setting up the version number based on the tag\nname.\n\nChange-Id: I56778033497318d54b90c3e43e02933e3c2a0720\n'}]",0,107579,8f386b2ed133c86b32324a6830b00b54a3ce3a22,23,3,5,6159,,,0,"Remove version string from setup.cfg

Pypi jobs take care of setting up the version number based on the tag
name.

Change-Id: I56778033497318d54b90c3e43e02933e3c2a0720
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/79/107579/3 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,194b518d91b8a747b3bde14689cf69a5d7bff813,,,version = 2014.1,0,1
openstack%2Fneutron~master~I5d4f439cc7ffe125cea9ed3407b70645587a739a,openstack/neutron,master,I5d4f439cc7ffe125cea9ed3407b70645587a739a,VPNaaS Cisco REST client enhance CSR create,MERGED,2014-07-08 02:32:45.000000000,2014-07-17 17:04:10.000000000,2014-07-16 21:04:02.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-08 02:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/244c376ea182d056cfe00c079fa7c431cb9f9ca7', 'message': 'VPNaaS Cisco REST client enhance CSR create\n\nFor the create of the REST client object that represents a Cisco CSR,\nall of the info needed were passed in as separate parameters. This\nchange just uses a dict instead, so that additional parameters can\nbe added w/o changing the API.\n\nChange-Id: I5d4f439cc7ffe125cea9ed3407b70645587a739a\nCloses-Bug: 1336478\n'}, {'number': 2, 'created': '2014-07-16 14:06:00.000000000', 'files': ['neutron/tests/unit/services/vpn/device_drivers/cisco_csr_mock.py', 'neutron/tests/unit/services/vpn/device_drivers/notest_cisco_csr_rest.py', 'neutron/services/vpn/device_drivers/cisco_ipsec.py', 'neutron/services/vpn/device_drivers/cisco_csr_rest_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/787fecb99909f47714ad1fbc77384a8f606b2baa', 'message': 'VPNaaS Cisco REST client enhance CSR create\n\nFor the create of the REST client object that represents a Cisco CSR,\nall of the info needed were passed in as separate parameters. This\nchange just uses a dict instead, so that additional parameters can\nbe added w/o changing the API.\n\nUpdated the currently unused UT module, just so that it can be used\nlocally and stays up-to-date until it can be converted to use the\nnew requests-mock package.\n\nChange-Id: I5d4f439cc7ffe125cea9ed3407b70645587a739a\nCloses-Bug: 1336478\n'}]",2,105335,787fecb99909f47714ad1fbc77384a8f606b2baa,42,20,2,6659,,,0,"VPNaaS Cisco REST client enhance CSR create

For the create of the REST client object that represents a Cisco CSR,
all of the info needed were passed in as separate parameters. This
change just uses a dict instead, so that additional parameters can
be added w/o changing the API.

Updated the currently unused UT module, just so that it can be used
locally and stays up-to-date until it can be converted to use the
new requests-mock package.

Change-Id: I5d4f439cc7ffe125cea9ed3407b70645587a739a
Closes-Bug: 1336478
",git fetch https://review.opendev.org/openstack/neutron refs/changes/35/105335/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/vpn/device_drivers/_test_cisco_csr_rest.py', 'neutron/services/vpn/device_drivers/cisco_ipsec.py', 'neutron/services/vpn/device_drivers/cisco_csr_rest_client.py']",3,244c376ea182d056cfe00c079fa7c431cb9f9ca7,bug/1336478," def __init__(self, settings): self.host = settings['rest_mgmt'] self.tunnel_ip = settings['tunnel_ip'] self.auth = (settings['username'], settings['password']) self.timeout = settings.get('timeout')"," def __init__(self, host, tunnel_ip, username, password, timeout=None): self.host = host self.tunnel_ip = tunnel_ip self.auth = (username, password) self.timeout = timeout",43,34
openstack%2Foslo.vmware~master~I61abc5879e71a7f5e5f46d2ec88404923e0423d8,openstack/oslo.vmware,master,I61abc5879e71a7f5e5f46d2ec88404923e0423d8,Store PBM wsdl in the oslo.vmware git repository,MERGED,2014-06-25 02:17:07.000000000,2014-07-17 17:04:06.000000000,2014-07-17 17:04:06.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5638}, {'_account_id': 8027}, {'_account_id': 8759}, {'_account_id': 9171}, {'_account_id': 9172}, {'_account_id': 9555}]","[{'number': 1, 'created': '2014-06-25 02:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/c346012aa2fafda467861824aa89304c4c067174', 'message': 'Store PBM wsdl in the oslo.vmware git repository\n\nCurrently, Cinder stores the PBM WSDL files in its own repository\n(see commit: 10c5c93925abe3d34c4430e0ed852d8358fb2353). Now that other\nprojects are leveraging SPBM, we need to provide them the ability\nto directly access those WSDL files without having to store them or\nreferencing them.\n\nThis patch (strongly inspires by the patch mentioned above) adds two\nutility APIs to pbm.py and unit tests for it:\n- get_pbm_wsdl_location()\n- get_vc_version()\n\nChange-Id: I61abc5879e71a7f5e5f46d2ec88404923e0423d8\n'}, {'number': 2, 'created': '2014-07-10 02:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/2135f80da075e6526ed66bf1cee223c84a4d1431', 'message': 'Store PBM wsdl in the oslo.vmware git repository\n\nCurrently, Cinder stores the PBM WSDL files in its own repository\n(see commit: 10c5c93925abe3d34c4430e0ed852d8358fb2353). Now that other\nprojects are leveraging SPBM, we need to provide them the ability\nto directly access those WSDL files without having to store them or\nreferencing them.\n\nThis patch (strongly inspired by the patch mentioned above) adds two\nutility APIs and unit tests for it:\n- get_pbm_wsdl_location()\n- get_vc_version()\n\nChange-Id: I61abc5879e71a7f5e5f46d2ec88404923e0423d8\n'}, {'number': 3, 'created': '2014-07-10 23:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/4f249b64f67a216ee76572cb7cae3021626f651c', 'message': 'Store PBM wsdl in the oslo.vmware git repository\n\nCurrently, Cinder stores the PBM WSDL files in its own repository\n(see commit: 10c5c93925abe3d34c4430e0ed852d8358fb2353). Now that other\nprojects are leveraging SPBM, we need to provide them the ability\nto directly access those WSDL files without having to store them or\nreferencing them.\n\nThis patch (strongly inspired by the patch mentioned above) adds two\nutility APIs and unit tests for it:\n- get_pbm_wsdl_location()\n- get_vc_version()\n\nChange-Id: I61abc5879e71a7f5e5f46d2ec88404923e0423d8\n'}, {'number': 4, 'created': '2014-07-11 19:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/d65bb044c22d28cd97ff2441b32d6146a5a72fee', 'message': 'Store PBM wsdl in the oslo.vmware git repository\n\nCurrently, Cinder stores the PBM WSDL files in its own repository\n(see commit: 10c5c93925abe3d34c4430e0ed852d8358fb2353). Now that other\nprojects are leveraging SPBM, we need to provide them the ability\nto directly access those WSDL files without having to store them or\nreferencing them.\n\nThis patch (strongly inspired by the patch mentioned above) adds two\nutility APIs and unit tests for it:\n- get_pbm_wsdl_location()\n- get_vc_version()\n\nChange-Id: I61abc5879e71a7f5e5f46d2ec88404923e0423d8\n'}, {'number': 5, 'created': '2014-07-16 20:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/6bd905b47425791a3f8a1788286635a6c22dcd59', 'message': 'Store PBM wsdl in the oslo.vmware git repository\n\nCurrently, Cinder stores the PBM WSDL files in its own repository\n(see commit: 10c5c93925abe3d34c4430e0ed852d8358fb2353). Now that other\nprojects are leveraging SPBM, we need to provide them the ability\nto directly access those WSDL files without having to store them or\nreferencing them.\n\nThis patch (strongly inspired by the patch mentioned above) adds two\nutility APIs and unit tests for it:\n- get_pbm_wsdl_location()\n- get_vc_version()\n\nChange-Id: I61abc5879e71a7f5e5f46d2ec88404923e0423d8\n'}, {'number': 6, 'created': '2014-07-16 21:35:21.000000000', 'files': ['oslo/vmware/wsdl/5.5/pbmService.wsdl', 'oslo/vmware/wsdl/5.5/pbm-types.xsd', 'oslo/vmware/pbm.py', 'oslo/vmware/wsdl/5.5/pbm-messagetypes.xsd', 'oslo/vmware/wsdl/5.5/pbm.wsdl', 'tests/test_vim_util.py', 'oslo/vmware/vim_util.py', 'tox.ini', 'tests/test_pbm.py', 'oslo/vmware/wsdl/5.5/core-types.xsd'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/dbcb5f9d1e1cdd601e7539f220880c0e2220a83a', 'message': 'Store PBM wsdl in the oslo.vmware git repository\n\nCurrently, Cinder stores the PBM WSDL files in its own repository\n(see commit: 10c5c93925abe3d34c4430e0ed852d8358fb2353). Now that other\nprojects are leveraging SPBM, we need to provide them the ability\nto directly access those WSDL files without having to store them or\nreferencing them.\n\nThis patch (strongly inspired by the patch mentioned above) adds two\nutility APIs and unit tests for it:\n- get_pbm_wsdl_location()\n- get_vc_version()\n\nChange-Id: I61abc5879e71a7f5e5f46d2ec88404923e0423d8\n'}]",17,102409,dbcb5f9d1e1cdd601e7539f220880c0e2220a83a,43,8,6,8759,,,0,"Store PBM wsdl in the oslo.vmware git repository

Currently, Cinder stores the PBM WSDL files in its own repository
(see commit: 10c5c93925abe3d34c4430e0ed852d8358fb2353). Now that other
projects are leveraging SPBM, we need to provide them the ability
to directly access those WSDL files without having to store them or
referencing them.

This patch (strongly inspired by the patch mentioned above) adds two
utility APIs and unit tests for it:
- get_pbm_wsdl_location()
- get_vc_version()

Change-Id: I61abc5879e71a7f5e5f46d2ec88404923e0423d8
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/09/102409/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/vmware/wsdl/5.5/pbmService.wsdl', 'oslo/vmware/wsdl/5.5/pbm-types.xsd', 'oslo/vmware/pbm.py', 'oslo/vmware/wsdl/5.5/pbm-messagetypes.xsd', 'oslo/vmware/wsdl/5.5/pbm.wsdl', 'tox.ini', 'oslo/vmware/wsdl/5.5/core-types.xsd', 'tests/test_pbm.py']",8,c346012aa2fafda467861824aa89304c4c067174,store_wsdl,"from distutils import version as dist_version import os DEFAULT_VC_VERSION = '5.5' def test_get_pbm_wsdl_location(self): # no version returns None wsdl = pbm.get_pbm_wsdl_location(None) self.assertIsNone(wsdl) def expected_wsdl(version): driver_dir = os.path.join(os.path.dirname(__file__), '..', 'oslo', 'vmware') driver_abs_dir = os.path.abspath(driver_dir) return 'file://' + os.path.join(driver_abs_dir, 'wsdl', version, 'pbmService.wsdl') # verify wsdl path for different version strings with mock.patch('os.path.exists') as path_exists: path_exists.return_value = True wsdl = pbm.get_pbm_wsdl_location( dist_version.LooseVersion('5')) self.assertEqual(expected_wsdl('5'), wsdl) wsdl = pbm.get_pbm_wsdl_location( dist_version.LooseVersion('5.5')) self.assertEqual(expected_wsdl('5.5'), wsdl) wsdl = pbm.get_pbm_wsdl_location( dist_version.LooseVersion('5.5.1')) self.assertEqual(expected_wsdl('5.5'), wsdl) # if wsdl path does not exist, then it returns None path_exists.return_value = False wsdl = pbm.get_pbm_wsdl_location(dist_version.LooseVersion('5.5')) self.assertIsNone(wsdl) def test_get_vc_version(self): session = mock.Mock() session.vim.service_content.about.version = '6.0.1' version = pbm.get_vc_version(session) self.assertEqual(dist_version.LooseVersion('6.0.1'), version)",,2119,1
openstack%2Ftripleo-image-elements~master~Ida5826633634dfb486329debd9d3e765d2f11f8b,openstack/tripleo-image-elements,master,Ida5826633634dfb486329debd9d3e765d2f11f8b,Add new sosreport element,MERGED,2014-07-03 15:44:44.000000000,2014-07-17 16:51:50.000000000,2014-07-17 16:51:49.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 741}, {'_account_id': 6153}, {'_account_id': 6488}, {'_account_id': 6969}, {'_account_id': 7144}, {'_account_id': 7579}, {'_account_id': 8399}, {'_account_id': 8688}]","[{'number': 1, 'created': '2014-07-03 15:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e33e8f690c75ff2c04495bcc1aa379dd646078e7', 'message': 'Add new sosreport element\n\nProvide an element that enables support information to be generated\non a running tripleo server.\n\nThis would allow for targeted data collection in CI runs, and is a\ngenerally useful tool for diagnosing failures in a remote tripleo\ninstallation.\n\nChange-Id: Ida5826633634dfb486329debd9d3e765d2f11f8b\n'}, {'number': 2, 'created': '2014-07-07 10:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4f1eef6a617b0b5b5ae29c037fdf55a23ebb1c43', 'message': 'Add new sosreport element\n\nProvide an element that enables support information to be generated\non a running tripleo server.\n\nThis would allow for targeted data collection in CI runs, and is a\ngenerally useful tool for diagnosing failures in a remote tripleo\ninstallation.\n\nChange-Id: Ida5826633634dfb486329debd9d3e765d2f11f8b\n'}, {'number': 3, 'created': '2014-07-07 10:57:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/224ba2ae7be458ef968641e4e9923c9d0e004064', 'message': 'Add new sosreport element\n\nProvide an element that enables support information to be generated\non a running tripleo server.\n\nThis would allow for targeted data collection in CI runs, and is a\ngenerally useful tool for diagnosing failures in a remote tripleo\ninstallation.\n\nChange-Id: Ida5826633634dfb486329debd9d3e765d2f11f8b\n'}, {'number': 4, 'created': '2014-07-08 03:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8e12957e13df8426a985ae37df18aae4d7b4524f', 'message': 'Add new sosreport element\n\nProvide an element that enables support information to be generated\non a running tripleo server.\n\nThis would allow for targeted data collection in CI runs, and is a\ngenerally useful tool for diagnosing failures in a remote tripleo\ninstallation.\n\nChange-Id: Ida5826633634dfb486329debd9d3e765d2f11f8b\n'}, {'number': 5, 'created': '2014-07-14 15:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/098b6af2926bf537aa2a8fea46a1674d84597229', 'message': 'Add new sosreport element\n\nProvide an element that enables support information to be generated\non a running tripleo server.\n\nThis would allow for targeted data collection in CI runs, and is a\ngenerally useful tool for diagnosing failures in a remote tripleo\ninstallation.\n\nChange-Id: Ida5826633634dfb486329debd9d3e765d2f11f8b\n'}, {'number': 6, 'created': '2014-07-14 17:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3f5c2d9ce5d3bc6638bf97fc3062978b464892f2', 'message': 'Add new sosreport element\n\nProvide an element that enables support information to be generated\non a running tripleo server.\n\nThis would allow for targeted data collection in CI runs, and is a\ngenerally useful tool for diagnosing failures in a remote tripleo\ninstallation.\n\nChange-Id: Ida5826633634dfb486329debd9d3e765d2f11f8b\n'}, {'number': 7, 'created': '2014-07-15 18:01:49.000000000', 'files': ['elements/sosreport/extra-data.d/90-sos-plugins', 'elements/sosreport/environment.d/90-sos-plugins-env', 'elements/sosreport/install.d/65-sosreport', 'elements/sosreport/pkg-map', 'elements/sosreport/cleanup.d/90-sos-tmp-plugins', 'elements/sosreport/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e9f736c71810008b582ed1053bc2bc404198124a', 'message': 'Add new sosreport element\n\nProvide an element that enables support information to be generated\non a running tripleo server.\n\nThis would allow for targeted data collection in CI runs, and is a\ngenerally useful tool for diagnosing failures in a remote tripleo\ninstallation.\n\nChange-Id: Ida5826633634dfb486329debd9d3e765d2f11f8b\n'}]",16,104593,e9f736c71810008b582ed1053bc2bc404198124a,56,10,7,215,,,0,"Add new sosreport element

Provide an element that enables support information to be generated
on a running tripleo server.

This would allow for targeted data collection in CI runs, and is a
generally useful tool for diagnosing failures in a remote tripleo
installation.

Change-Id: Ida5826633634dfb486329debd9d3e765d2f11f8b
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/93/104593/4 && git format-patch -1 --stdout FETCH_HEAD,"['elements/sosreport/extra-data.d/90-sos-plugins', 'elements/sosreport/environment.d/90-sos-plugins-env', 'elements/sosreport/install.d/65-sosreport', 'elements/sosreport/pkg-map', 'elements/sosreport/README.md']",5,e33e8f690c75ff2c04495bcc1aa379dd646078e7,master,"Add sosreport to built images ============================= This element adds sosreport to the image, for use as a log retrieval tool. See [sosreport](https://github.com/sosreport/sos) on github for more information. It provides the ability for plugins to be provided by other elements through the use of sos.d in the element. All ""\*.py"" files found in the sos.d directory will be added to the plugins directory for use by sosreport. ",,88,0
openstack%2Fdesignate~master~I1ceb33d2bcb531d444ad05cf6cf74b6edd4e7d39,openstack/designate,master,I1ceb33d2bcb531d444ad05cf6cf74b6edd4e7d39,Ensure each greenthread uses it's own Session instance,MERGED,2014-07-17 10:53:07.000000000,2014-07-17 16:37:44.000000000,2014-07-17 16:37:44.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8130}]","[{'number': 1, 'created': '2014-07-17 10:53:07.000000000', 'files': ['designate/storage/impl_sqlalchemy/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/750095459b4f31ade70a65fc89e7a2084e4cbb50', 'message': ""Ensure each greenthread uses it's own Session instance\n\nThis uses a thread local store, allowing each greenthread to\nhave it's own session stored correctly. Without this, each\ngreenthread may end up using a single global session, which\nleads to bad things happening.\n\nChange-Id: I1ceb33d2bcb531d444ad05cf6cf74b6edd4e7d39\nCloses-Bug: 1343211\n""}]",0,107644,750095459b4f31ade70a65fc89e7a2084e4cbb50,8,5,1,741,,,0,"Ensure each greenthread uses it's own Session instance

This uses a thread local store, allowing each greenthread to
have it's own session stored correctly. Without this, each
greenthread may end up using a single global session, which
leads to bad things happening.

Change-Id: I1ceb33d2bcb531d444ad05cf6cf74b6edd4e7d39
Closes-Bug: 1343211
",git fetch https://review.opendev.org/openstack/designate refs/changes/44/107644/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/storage/impl_sqlalchemy/__init__.py'],1,750095459b4f31ade70a65fc89e7a2084e4cbb50,bug/1343211,"import threadingLOCAL_STORE = threading.local() @property def session(self): # NOTE: This uses a thread local store, allowing each greenthread to # have it's own session stored correctly. Without this, each # greenthread may end up using a single global session, which # leads to bad things happening. global LOCAL_STORE if not hasattr(LOCAL_STORE, 'session'): LOCAL_STORE.session = session.get_session(self.name) return LOCAL_STORE.session", self.session = session.get_session(self.name),15,1
openstack%2Frally~master~Icea34148f6e505a8a8765151324c566f773f6f4e,openstack/rally,master,Icea34148f6e505a8a8765151324c566f773f6f4e,Added Sahara client,MERGED,2014-07-17 13:27:48.000000000,2014-07-17 16:31:39.000000000,2014-07-17 16:31:39.000000000,"[{'_account_id': 3}, {'_account_id': 6124}, {'_account_id': 6172}, {'_account_id': 6786}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-07-17 13:27:48.000000000', 'files': ['requirements.txt', 'tests/test_osclients.py', 'tests/fakes.py', 'rally/osclients.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/6331392578d322443ec979f1522c093f0b2d89e6', 'message': 'Added Sahara client\n\nThe client is required for further Sahara benchmarking.\n\nChange-Id: Icea34148f6e505a8a8765151324c566f773f6f4e\n'}]",0,107692,6331392578d322443ec979f1522c093f0b2d89e6,10,5,1,7132,,,0,"Added Sahara client

The client is required for further Sahara benchmarking.

Change-Id: Icea34148f6e505a8a8765151324c566f773f6f4e
",git fetch https://review.opendev.org/openstack/rally refs/changes/92/107692/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tests/test_osclients.py', 'tests/fakes.py', 'rally/osclients.py']",4,6331392578d322443ec979f1522c093f0b2d89e6,sahara,"from saharaclient import client as sahara def sahara(self, version='1.1'): """"""Return Sahara client."""""" client = sahara.Client(version, username=self.endpoint.username, api_key=self.endpoint.password, project_name=self.endpoint.tenant_name, auth_url=self.endpoint.auth_url) return client @cached",,41,0
openstack%2Ffuel-web~master~Idfb363f94b07b8cf8fdee2fbfdfb16d723d8f514,openstack/fuel-web,master,Idfb363f94b07b8cf8fdee2fbfdfb16d723d8f514,Added fuel_agent,ABANDONED,2014-06-02 14:47:50.000000000,2014-07-17 16:23:16.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-02 14:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/90a952558c891130b14e686a153b7a8b66b115e0', 'message': 'Added fuel_agent\n\nDo not review. Work in progress.\n\nChange-Id: Idfb363f94b07b8cf8fdee2fbfdfb16d723d8f514\n'}, {'number': 2, 'created': '2014-06-03 14:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d2ec3a1ba0591bd2e9dc8d4a5b9c308d4d6c07c6', 'message': 'Added fuel_agent\n\nDo not review. Work in progress.\n\nChange-Id: Idfb363f94b07b8cf8fdee2fbfdfb16d723d8f514\n'}, {'number': 3, 'created': '2014-06-03 14:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bb59993dbaeb45b83d3c53256235d5905479ab0f', 'message': 'Added fuel_agent\n\nDo not review. Work in progress.\n\nChange-Id: Idfb363f94b07b8cf8fdee2fbfdfb16d723d8f514\n'}, {'number': 4, 'created': '2014-06-10 08:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b06390038632ddcdaf0f5a67f8b338d10c78feff', 'message': 'Added fuel_agent\n\nDo not review. Work in progress.\n\nChange-Id: Idfb363f94b07b8cf8fdee2fbfdfb16d723d8f514\n'}, {'number': 5, 'created': '2014-06-10 12:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/000a18671048aa5ff9ce2b648647adcc6a9c8163', 'message': 'Added fuel_agent\n\nDo not review. Work in progress.\n\nChange-Id: Idfb363f94b07b8cf8fdee2fbfdfb16d723d8f514\n'}, {'number': 6, 'created': '2014-06-11 12:48:54.000000000', 'files': ['fuel_agent/tools/config/generate_sample.sh', 'fuel_agent/tools/config/oslo.config.generator.rc', 'fuel_agent/.testr.conf', 'fuel_agent/fuel_agent/openstack/common/config/__init__.py', 'fuel_agent/fuel_agent/image.py', 'fuel_agent/tools/with_venv.sh', 'fuel_agent/fuel_agent/openstack/common/jsonutils.py', 'fuel_agent/fuel_agent/openstack/common/local.py', 'fuel_agent/requirements.txt', 'fuel_agent/fuel_agent/cmd/provision.py', 'fuel_agent/test-requirements.txt', 'fuel_agent/fuel_agent/tests/test_nailgun_partition.py', 'fuel_agent/fuel_agent/tests/__init__.py', 'fuel_agent/fuel_agent/openstack/common/config/generator.py', 'fuel_agent/fuel_agent/tests/test_utils.py', 'fuel_agent/fuel_agent/partition.py', 'fuel_agent/fuel_agent/hardware_utils.py', 'fuel_agent/fuel_agent/driver/nailgun/__init__.py', 'fuel_agent/setup.py', 'fuel_agent/tox.ini', 'fuel_agent/fuel_agent/openstack/common/gettextutils.py', 'fuel_agent/tools/config/check_uptodate.sh', 'fuel_agent/etc/fuel_agent/fuel_agent.conf', 'fuel_agent/fuel_agent/__init__.py', 'fuel_agent/fuel_agent/tests/test_hardware_utils.py', 'fuel_agent/fuel_agent/cmd/__init__.py', 'fuel_agent/setup.cfg', 'fuel_agent/openstack-common.conf', 'fuel_agent/README.md', 'fuel_agent/fuel_agent/driver/__init__.py', 'fuel_agent/fuel_agent/openstack/common/importutils.py', 'fuel_agent/fuel_agent/openstack/common/log.py', 'fuel_agent/fuel_agent/configdrive.py', 'fuel_agent/fuel_agent/utils.py', 'fuel_agent/fuel_agent/openstack/__init__.py', 'fuel_agent/fuel_agent/errors.py', 'fuel_agent/fuel_agent/openstack/common/timeutils.py', 'fuel_agent/fuel_agent/openstack/common/processutils.py', 'fuel_agent/fuel_agent/openstack/common/strutils.py', 'fuel_agent/fuel_agent/cmd/agent.py', 'fuel_agent/fuel_agent/openstack/common/__init__.py', 'fuel_agent/fuel_agent/driver/nailgun/partition.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a3409aeff87533fa861f25760894b5242275f465', 'message': 'Added fuel_agent\n\nDo not review. Work in progress.\n\nChange-Id: Idfb363f94b07b8cf8fdee2fbfdfb16d723d8f514\n'}]",0,97258,a3409aeff87533fa861f25760894b5242275f465,43,3,6,3009,,,0,"Added fuel_agent

Do not review. Work in progress.

Change-Id: Idfb363f94b07b8cf8fdee2fbfdfb16d723d8f514
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/58/97258/5 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_agent/tools/config/generate_sample.sh', 'fuel_agent/tools/config/oslo.config.generator.rc', 'fuel_agent/.testr.conf', 'fuel_agent/fuel_agent/openstack/common/config/__init__.py', 'fuel_agent/fuel_agent/tests/disk_utils.py', 'fuel_agent/tools/with_venv.sh', 'fuel_agent/fuel_agent/openstack/common/jsonutils.py', 'fuel_agent/fuel_agent/openstack/common/local.py', 'fuel_agent/requirements.txt', 'fuel_agent/fuel_agent/cmd/provision.py', 'fuel_agent/test-requirements.txt', 'fuel_agent/fuel_agent/tests/__init__.py', 'fuel_agent/fuel_agent/openstack/common/config/generator.py', 'fuel_agent/setup.py', 'fuel_agent/tox.ini', 'fuel_agent/fuel_agent/openstack/common/gettextutils.py', 'fuel_agent/tools/config/check_uptodate.sh', 'fuel_agent/etc/fuel_agent/fuel_agent.conf', 'fuel_agent/fuel_agent/__init__.py', 'fuel_agent/fuel_agent/tests/utils.py', 'fuel_agent/fuel_agent/cmd/__init__.py', 'fuel_agent/setup.cfg', 'fuel_agent/openstack-common.conf', 'fuel_agent/README.md', 'fuel_agent/fuel_agent/openstack/common/importutils.py', 'fuel_agent/fuel_agent/openstack/common/log.py', 'fuel_agent/fuel_agent/utils.py', 'fuel_agent/fuel_agent/openstack/__init__.py', 'fuel_agent/fuel_agent/disk_utils.py', 'fuel_agent/fuel_agent/openstack/common/timeutils.py', 'fuel_agent/fuel_agent/openstack/common/processutils.py', 'fuel_agent/fuel_agent/openstack/common/strutils.py', 'fuel_agent/fuel_agent/cmd/agent.py', 'fuel_agent/fuel_agent/openstack/common/__init__.py', 'fuel_agent/fuel_agent/partition/__init__.py']",35,90a952558c891130b14e686a153b7a8b66b115e0,imagebased, ,,3915,0
openstack%2Fhorizon~master~If5c8f3cba31f6e613ec17af81cff8d15cd2f8f19,openstack/horizon,master,If5c8f3cba31f6e613ec17af81cff8d15cd2f8f19,Don't recommend setting SESSION_COOKIE_HTTPONLY,MERGED,2014-07-08 13:55:00.000000000,2014-07-17 16:17:01.000000000,2014-07-17 16:17:00.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 6610}, {'_account_id': 8871}, {'_account_id': 9500}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 10540}, {'_account_id': 12231}]","[{'number': 1, 'created': '2014-07-08 13:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b39fd1aebf8163f6f4766327d0faea356b976f9d', 'message': 'Remove SESSION_COOKIE_HTTPONLY from recommenations\n\nThis setting is already the default, so there is no need to recommand that\npeople set this option to prevent cross site scripting.\n\nCloses-Bug: 1333407\nChange-Id: If5c8f3cba31f6e613ec17af81cff8d15cd2f8f19\n'}, {'number': 2, 'created': '2014-07-08 13:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0a871560aa23934d1d3b477a5d9f8ac26a4b8454', 'message': 'Remove SESSION_COOKIE_HTTPONLY from recommenations\n\nThis setting is already the default, so there is no need to recommend that\npeople set this option to prevent cross site scripting.\n\nCloses-Bug: 1333407\nChange-Id: If5c8f3cba31f6e613ec17af81cff8d15cd2f8f19\n'}, {'number': 3, 'created': '2014-07-08 13:58:28.000000000', 'files': ['doc/source/topics/deployment.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0560c7399cd20b8cf8d3258dcca70014ef185283', 'message': ""Don't recommend setting SESSION_COOKIE_HTTPONLY\n\nThis setting is already defaults to true, so there is no need to\nrecommend that people set this option to prevent cross site scripting.\n\nCloses-Bug: 1333407\nChange-Id: If5c8f3cba31f6e613ec17af81cff8d15cd2f8f19\n""}]",0,105458,0560c7399cd20b8cf8d3258dcca70014ef185283,25,13,3,10540,,,0,"Don't recommend setting SESSION_COOKIE_HTTPONLY

This setting is already defaults to true, so there is no need to
recommend that people set this option to prevent cross site scripting.

Closes-Bug: 1333407
Change-Id: If5c8f3cba31f6e613ec17af81cff8d15cd2f8f19
",git fetch https://review.opendev.org/openstack/horizon refs/changes/58/105458/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/topics/deployment.rst'],1,b39fd1aebf8163f6f4766327d0faea356b976f9d,bug/1333407,, SESSION_COOKIE_HTTPONLY = True,0,1
openstack%2Ftrove~master~I05139291ffff40de25859040b9431eb8af0954ac,openstack/trove,master,I05139291ffff40de25859040b9431eb8af0954ac,Adding image build procedure docs,ABANDONED,2014-07-16 15:24:01.000000000,2014-07-17 16:08:14.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 10295}]","[{'number': 1, 'created': '2014-07-16 15:24:01.000000000', 'files': ['doc/source/dev/manual_install.rst', 'doc/source/dev/image_building.rst', 'doc/source/dev/trove_cassandra_ubuntu.tdl'], 'web_link': 'https://opendev.org/openstack/trove/commit/bac5a94f55ba06ea16172f39113db01fbadc010c', 'message': ""Adding image build procedure docs\n\nReasons:\n - there's a huge lack of documentation related\n   to image building procedure.\n\nChanges:\n - heat-jeos (Oz) image building doc added\n\nChange-Id: I05139291ffff40de25859040b9431eb8af0954ac\nCloses-Bug: #1342697\n""}]",11,107422,bac5a94f55ba06ea16172f39113db01fbadc010c,16,6,1,8415,,,0,"Adding image build procedure docs

Reasons:
 - there's a huge lack of documentation related
   to image building procedure.

Changes:
 - heat-jeos (Oz) image building doc added

Change-Id: I05139291ffff40de25859040b9431eb8af0954ac
Closes-Bug: #1342697
",git fetch https://review.opendev.org/openstack/trove refs/changes/22/107422/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/dev/manual_install.rst', 'doc/source/dev/image_building.rst', 'doc/source/dev/trove_cassandra_ubuntu.tdl']",3,bac5a94f55ba06ea16172f39113db01fbadc010c,doc-improve,"<template> <name>U12-04-x86_64-cfntools</name> <os> <name>Ubuntu</name> <version>12.04</version> <arch>x86_64</arch> <install type='iso'> <iso>file:/var/lib/libvirt/images/ubuntu-12.04.4-server-amd64.iso</iso> </install> </os> <description>Ubuntu 12.04</description> <commands> <command name='lockroot'> passwd -l root </command> <command name='commands'> apt-get -y update apt-get -y upgrade apt-get -y install python-argparse cloud-init python-psutil apt-get -y remove python-boto pip install 'boto==2.5.2' heat-cfntools cfn-create-aws-symlinks --source /usr/local/bin apt-get install curl echo ""deb http://debian.datastax.com/community stable main"" >> /etc/apt/sources.list.d/cassandra.sources.list curl -L http://debian.datastax.com/debian/repo_key | sudo apt-key add - apt-get install cassandra -qy --force-yes wget https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py python ez_setup.py wget https://raw.github.com/pypa/pip/master/contrib/get-pip.py python get-pip.py mkdir -p ${HOME}/trove cd ${HOME}/trove git init git pull https://github.com/openstack/trove pip install -r requirements.txt python setup.py install echo -e ""#/bin/bash \n trove-guestagent --config-file=/etc/trove-guestagent.conf --config-file=/etc/guest_info \n"" > ${HOME}/trove-guestagent.sh chmod 755 ${HOME}/trove-guestagent.sh sudo ln -s ${HOME}/trove-guestagent.sh /etc/init.d/trove-guestagent update-rc.d trove-guestagent enable </command> </commands> </template> ",,188,1
openstack%2Fzaqar~master~Ibd5bf949fb5c66e8269832120fb53bb91f282d89,openstack/zaqar,master,Ibd5bf949fb5c66e8269832120fb53bb91f282d89,Sort requirement files in alphabetical order,ABANDONED,2014-02-28 06:08:26.000000000,2014-07-17 16:06:56.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 7642}]","[{'number': 1, 'created': '2014-02-28 06:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9a242868bc2a7adc5361d22f687a31b183132d45', 'message': 'Sort requirement files in alphabetical order\n\nSort requirement files in alphabetical order and enforce pep8 check.\n\nPartial-Bug: #1285478\n\nChange-Id: Ibd5bf949fb5c66e8269832120fb53bb91f282d89\n'}, {'number': 2, 'created': '2014-03-04 07:44:50.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'tools/requirements_style_check.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/2fe1efc090510d6424894de15fe44b90be80ae06', 'message': 'Sort requirement files in alphabetical order\n\nSort requirement files in alphabetical order and enforce pep8 check.\n\nPartial-Bug: #1285478\n\nChange-Id: Ibd5bf949fb5c66e8269832120fb53bb91f282d89\n'}]",6,77078,2fe1efc090510d6424894de15fe44b90be80ae06,17,5,2,7642,,,0,"Sort requirement files in alphabetical order

Sort requirement files in alphabetical order and enforce pep8 check.

Partial-Bug: #1285478

Change-Id: Ibd5bf949fb5c66e8269832120fb53bb91f282d89
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/78/77078/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'tools/requirements_style_check.sh', 'tox.ini']",4,9a242868bc2a7adc5361d22f687a31b183132d45,bug/1285478,commands = flake8 {toxinidir}/tools/requirements_style_check.sh requirements.txt test-requirements.txt,commands = flake8,48,16
openstack%2Fzaqar~master~Ib9b8c39cbf43c117aa9e28bef86afd5d10745cb1,openstack/zaqar,master,Ib9b8c39cbf43c117aa9e28bef86afd5d10745cb1,Imported Translations from Transifex,MERGED,2014-07-15 06:06:50.000000000,2014-07-17 16:05:21.000000000,2014-07-17 16:05:21.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-07-15 06:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f6601ef159872125f763cd46db1aeef45254abb0', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib9b8c39cbf43c117aa9e28bef86afd5d10745cb1\n'}, {'number': 2, 'created': '2014-07-16 06:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e965a0d86947608bd2fe892eb857b98335ea693b', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib9b8c39cbf43c117aa9e28bef86afd5d10745cb1\n'}, {'number': 3, 'created': '2014-07-17 06:07:16.000000000', 'files': ['marconi/locale/marconi-log-critical.pot', 'marconi/locale/pt_BR/LC_MESSAGES/marconi-log-critical.po', 'marconi/locale/pt_BR/LC_MESSAGES/marconi-log-info.po', 'marconi/locale/pt_BR/LC_MESSAGES/marconi-log-warning.po', 'marconi/locale/marconi-log-info.pot', 'marconi/locale/pt_BR/LC_MESSAGES/marconi.po', 'marconi/locale/marconi.pot', 'marconi/locale/marconi-log-warning.pot', 'marconi/locale/pt_BR/LC_MESSAGES/marconi-log-error.po', 'marconi/locale/marconi-log-error.pot'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/53f3fa69832702e847bc2e0c41f4119f2ccc2ce8', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib9b8c39cbf43c117aa9e28bef86afd5d10745cb1\n'}]",0,106944,53f3fa69832702e847bc2e0c41f4119f2ccc2ce8,20,5,3,11131,,,0,"Imported Translations from Transifex

Change-Id: Ib9b8c39cbf43c117aa9e28bef86afd5d10745cb1
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/44/106944/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/locale/marconi-log-critical.pot', 'marconi/locale/pt_BR/LC_MESSAGES/marconi-log-critical.po', 'marconi/locale/pt_BR/LC_MESSAGES/marconi-log-info.po', 'marconi/locale/marconi-log-info.pot', 'marconi/locale/pt_BR/LC_MESSAGES/marconi-log-warning.po', 'marconi/locale/pt_BR/LC_MESSAGES/marconi.po', 'marconi/locale/marconi-log-warning.pot', 'marconi/locale/pt_BR/LC_MESSAGES/marconi-log-error.po', 'marconi/locale/marconi-log-error.pot']",9,f6601ef159872125f763cd46db1aeef45254abb0,transifex/translations,"# Translations template for marconi. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the marconi project. # FIRST AUTHOR <EMAIL@ADDRESS>, 2014. # #, fuzzy msgid """" msgstr """" ""Project-Id-Version: marconi 2014.2.dev61.gddabc98\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-07-15 06:06+0000\n"" ""PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"" ""Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"" ""Language-Team: LANGUAGE <LL@li.org>\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=utf-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" #: marconi/openstack/common/excutils.py:76 #, python-format msgid ""Original exception being dropped: %s"" msgstr """" #: marconi/openstack/common/excutils.py:105 #, python-format msgid ""Unexpected exception occurred %d time(s)... retrying."" msgstr """" #: marconi/openstack/common/lockutils.py:120 #, python-format msgid ""Could not release the acquired lock `%s`"" msgstr """" ",,607,0
openstack%2Ffuel-web~master~I824aa3f480eafdc84f45ade961dcb55200b096a3,openstack/fuel-web,master,I824aa3f480eafdc84f45ade961dcb55200b096a3,Revert tox.ini to use old python by default,MERGED,2014-07-15 10:40:26.000000000,2014-07-17 16:01:17.000000000,2014-07-17 16:01:16.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9977}]","[{'number': 1, 'created': '2014-07-15 10:40:26.000000000', 'files': ['nailgun/tox.ini'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/02157968d34f1a4c5557d45560f104db312ea7e9', 'message': 'Revert tox.ini to use old python by default\n\nCloses-Bug: #1332330\n\nChange-Id: I824aa3f480eafdc84f45ade961dcb55200b096a3\n'}]",0,106988,02157968d34f1a4c5557d45560f104db312ea7e9,14,5,1,8053,,,0,"Revert tox.ini to use old python by default

Closes-Bug: #1332330

Change-Id: I824aa3f480eafdc84f45ade961dcb55200b096a3
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/88/106988/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/tox.ini'],1,02157968d34f1a4c5557d45560f104db312ea7e9,deadsnake,,basepython = python,0,1
openstack%2Fheat-translator~master~Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8,openstack/heat-translator,master,Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8,Enhanced tosca validation,MERGED,2014-07-03 08:48:04.000000000,2014-07-17 16:00:41.000000000,2014-07-17 16:00:40.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7193}, {'_account_id': 9591}, {'_account_id': 9992}, {'_account_id': 10818}, {'_account_id': 10856}, {'_account_id': 11349}, {'_account_id': 11355}, {'_account_id': 11602}]","[{'number': 1, 'created': '2014-07-03 08:48:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/0421626b7a737f17e5adab7ddbb0ddb6a9c45d7b', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8\n'}, {'number': 2, 'created': '2014-07-03 09:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/15e285c4a5ba7224f8ebcec1e3a64a6449272aa3', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8\n'}, {'number': 3, 'created': '2014-07-03 10:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/63356b78149c0f2686dd6dae48aa1e138b8f1902', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8\n'}, {'number': 4, 'created': '2014-07-03 10:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/5cd1b235ff0068c568153a4c80a73585369b94e0', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8\n'}, {'number': 5, 'created': '2014-07-04 06:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/02e018142613113901a8074e8490644fb39441ac', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8\n'}, {'number': 6, 'created': '2014-07-04 06:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/d7153b77be8d3c1e3d4d357716ee5a0e97c13489', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8\n'}, {'number': 7, 'created': '2014-07-09 07:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/7c8f4530eed85896de0664f71933b8cb48c173b8', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8\n'}, {'number': 8, 'created': '2014-07-11 07:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/0d401b8d105d0eaa8f7716269dfbea0835ffb1ed', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8\n'}, {'number': 9, 'created': '2014-07-15 10:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/38e4a7d4419b5ebc771fd26ea628299110b46a51', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8'}, {'number': 10, 'created': '2014-07-15 10:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/28231d287199ad3f5c2ff881dfc6c9935f1fda4e', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8'}, {'number': 11, 'created': '2014-07-15 10:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/eb7e2d136882a30cddd1648d15699eaf557bff71', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8'}, {'number': 12, 'created': '2014-07-16 08:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/61b24b846da5ff9532a8772d388500cfa90cad24', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8'}, {'number': 13, 'created': '2014-07-16 08:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/f3ac3ccf6574b69ece5d9f867dc95aea57518663', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8'}, {'number': 14, 'created': '2014-07-17 11:17:19.000000000', 'files': ['translator/toscalib/utils/yamlparser.py', 'translator/toscalib/tests/data/test_tosca_top_level_error2.yaml', 'translator/toscalib/tosca_template.py', 'translator/toscalib/parameters.py', 'translator/toscalib/elements/interfaces.py', 'translator/toscalib/nodetemplate.py', 'translator/toscalib/tests/test_toscatplvalidation.py', 'translator/toscalib/common/__init__.py', 'translator/toscalib/tests/test_exception.py', 'translator/toscalib/common/exception.py', 'translator/toscalib/tests/test_toscadef.py', 'translator/toscalib/elements/nodetype.py', 'translator/toscalib/tests/data/test_tosca_top_level_error1.yaml'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/ae70ab835b85a00f94ca19c0e0db78c0e447ad33', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8\n'}]",62,104479,ae70ab835b85a00f94ca19c0e0db78c0e447ad33,70,10,14,10856,,,0,"Enhanced tosca validation

Using new exception class instead of built-in exception types.
Added validation for tosca template field names.

Partially implements: blueprint tosca-validation
Implements: blueprint check-key-definition

Change-Id: Ib6aadffc8922154f5b86da29ea29c9b603f4cfd8
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/79/104479/14 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/utils/yamlparser.py', 'translator/toscalib/tests/data/test_tosca_top_level_error2.yaml', 'translator/toscalib/tosca_template.py', 'translator/toscalib/parameters.py', 'translator/toscalib/elements/interfaces.py', 'translator/toscalib/nodetemplate.py', 'translator/toscalib/tests/test_toscatplvalidation.py', 'translator/toscalib/common/__init__.py', 'translator/toscalib/tests/test_exception.py', 'translator/toscalib/common/exception.py', 'translator/toscalib/elements/nodetype.py', 'translator/toscalib/tests/data/test_tosca_top_level_error1.yaml']",12,0421626b7a737f17e5adab7ddbb0ddb6a9c45d7b,bp/tosca-validation,"description: > TOSCA simple profile missing version section. inputs: cpus: type: integer description: Number of CPUs for the server. constraints: - valid_values: [ 1, 2, 4, 8 ] node_templates: server: type: tosca.nodes.Compute properties: # compute properties (flavor) disk_size: 10 num_cpus: { get_input: cpus } mem_size: 4096 # host image properties os_arch: x86_64 os_type: Linux os_distribution: Fedora os_version: 18 outputs: server_address: description: IP address of server instance. value: { get_property: [server, ip_address] } ",,748,49
openstack%2Fdesignate~master~If46e82fe0089677d04e814c612c4b7210d90a599,openstack/designate,master,If46e82fe0089677d04e814c612c4b7210d90a599,Attach records to RecordSet objects,MERGED,2014-07-09 21:31:38.000000000,2014-07-17 16:00:09.000000000,2014-07-17 16:00:08.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8130}]","[{'number': 1, 'created': '2014-07-09 21:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c77d1e56eb4de2cd6d5d54aa9bc49ee7a2c3db09', 'message': 'WIP: Attach records to RecordSet objects\n\nChange-Id: If46e82fe0089677d04e814c612c4b7210d90a599\n'}, {'number': 2, 'created': '2014-07-09 22:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/01c6296f5d09bef898027cea312db93aad2bf853', 'message': 'WIP: Attach records to RecordSet objects\n\nChange-Id: If46e82fe0089677d04e814c612c4b7210d90a599\n'}, {'number': 3, 'created': '2014-07-09 23:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e04ae5ac2ddb921e921283a60528b2b3ba35ed27', 'message': 'WIP: Attach records to RecordSet objects\n\nChange-Id: If46e82fe0089677d04e814c612c4b7210d90a599\n'}, {'number': 4, 'created': '2014-07-12 09:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c5d4c6c3538096cc35ad5c8f0011e73ab0ae9919', 'message': 'WIP: Attach records to RecordSet objects\n\nChange-Id: If46e82fe0089677d04e814c612c4b7210d90a599\n'}, {'number': 5, 'created': '2014-07-14 17:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/d805cbd7f82235a5d62936d1a43f4d9e4e131350', 'message': 'WIP: Attach records to RecordSet objects\n\nChange-Id: If46e82fe0089677d04e814c612c4b7210d90a599\n'}, {'number': 6, 'created': '2014-07-14 17:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/ee371f0873e02afae127f0801677c879d4f13387', 'message': 'Attach records to RecordSet objects\n\nChange-Id: If46e82fe0089677d04e814c612c4b7210d90a599\n'}, {'number': 7, 'created': '2014-07-17 14:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/2009e473e3b79ab3fd9ecdd84fede351863b4a45', 'message': 'Attach records to RecordSet objects\n\nChange-Id: If46e82fe0089677d04e814c612c4b7210d90a599\n'}, {'number': 8, 'created': '2014-07-17 14:39:50.000000000', 'files': ['designate/tests/__init__.py', 'designate/objects/recordset.py', 'designate/tests/test_storage/__init__.py', 'designate/storage/impl_sqlalchemy/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/1dea2e7bde22c59e6d49897db9c79c89681d0e76', 'message': 'Attach records to RecordSet objects\n\nChange-Id: If46e82fe0089677d04e814c612c4b7210d90a599\n'}]",8,105887,1dea2e7bde22c59e6d49897db9c79c89681d0e76,28,5,8,741,,,0,"Attach records to RecordSet objects

Change-Id: If46e82fe0089677d04e814c612c4b7210d90a599
",git fetch https://review.opendev.org/openstack/designate refs/changes/87/105887/8 && git format-patch -1 --stdout FETCH_HEAD,"['designate/objects/recordset.py', 'designate/tests/test_storage/__init__.py', 'designate/storage/impl_sqlalchemy/__init__.py']",3,c77d1e56eb4de2cd6d5d54aa9bc49ee7a2c3db09,objects-everywhere,"def _set_object_from_model(obj, model, **extra): if fieldname in extra.keys(): obj[fieldname] = extra[fieldname] else: obj[fieldname] = getattr(model, fieldname)def _set_listobject_from_models(obj, models, map=None): for model in models: extra = {} if map is not None: extra = map(model) _set_object_from_model(obj.LIST_ITEM_TYPE(), model, **extra)) records = _set_listobject_from_models( objects.RecordList(), recordset.records) return _set_object_from_model(objects.RecordSet(), recordset, records=records) def map(recordset): return { 'records': _set_listobject_from_models( objects.RecordList(), recordset.records) } return _set_listobject_from_models( objects.RecordSetList(), recordsets, map=map) records = _set_listobject_from_models( objects.RecordList(), recordset.records) return _set_object_from_model(objects.RecordSet(), recordset, records=records)","def _set_object_from_model(obj, model): obj[fieldname] = getattr(model, fieldname)def _set_listobject_from_models(obj, models): for model in models: _set_object_from_model(obj.LIST_ITEM_TYPE(), model)) return _set_object_from_model(objects.RecordSet(), recordset) return _set_listobject_from_models(objects.RecordSetList(), recordsets) return _set_object_from_model(objects.RecordSet(), recordset)",103,8
openstack%2Ffuel-web~master~Ida76317dd5fdc5e3813c3b4279b5db5239d6c754,openstack/fuel-web,master,Ida76317dd5fdc5e3813c3b4279b5db5239d6c754,Added UI restrictions for Mellanox features,MERGED,2014-07-08 12:03:13.000000000,2014-07-17 15:56:36.000000000,2014-07-17 15:56:36.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 11968}, {'_account_id': 12171}]","[{'number': 1, 'created': '2014-07-08 12:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/51d573a775ff0c374e1408ad50d6640111fd652c', 'message': 'Added UI restrictions for Mellanox features\n\nThis commit includes changes in UI restrictions:\n  1. Restrict nova-network with Mellanox plugin.\n  2. Block ports bonding in case of iSER storage or Mellanox\n     SR-IOV plugin.\n  3. Move virtual functions number box near SR-IOV feature.\n  4. Add probed VF limitation explanation to iSER checkbox.\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: Ida76317dd5fdc5e3813c3b4279b5db5239d6c754\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 2, 'created': '2014-07-09 16:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e74f31e16911bd29511e8ad59a4d2edf5352798d', 'message': 'Added UI restrictions for Mellanox features\n\nThis commit includes changes in UI restrictions:\n  1. Restrict nova-network with Mellanox plugin.\n  2. Block ports bonding in case of iSER storage or Mellanox\n     SR-IOV plugin.\n  3. Move virtual functions number box near SR-IOV feature.\n  4. Add probed VF limitation explanation to iSER checkbox.\n\npartially implements: blueprint mellanox-features-support\n\nChange-Id: Ida76317dd5fdc5e3813c3b4279b5db5239d6c754\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 3, 'created': '2014-07-10 23:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e132b0b7155a7fffd30efb8ac2402b1d9449c9cb', 'message': 'Added UI restrictions for Mellanox features\n\nThis commit includes changes in UI restrictions:\n  1. Restrict nova-network and GRE with Mellanox plugin.\n  2. Block ports bonding in case of iSER storage or Mellanox\n     SR-IOV plugin.\n  3. Add probed VF limitation explanation to iSER checkbox.\n\ncloses-bug: #1336867\npartially implements: blueprint mellanox-features-support\n\nChange-Id: Ida76317dd5fdc5e3813c3b4279b5db5239d6c754\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}, {'number': 4, 'created': '2014-07-15 11:53:18.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a435908dbaaa985488f1181fa42205b5f26cba4b', 'message': 'Added UI restrictions for Mellanox features\n\nThis commit includes changes in UI restrictions:\n  1. Restrict nova-network and GRE with Mellanox plugin.\n  2. Block ports bonding in case of iSER storage or Mellanox\n     SR-IOV plugin.\n  3. Add probed VF limitation explanation to iSER checkbox.\n\ncloses-bug: #1336867\npartially implements: blueprint mellanox-features-support\n\nChange-Id: Ida76317dd5fdc5e3813c3b4279b5db5239d6c754\nSigned-off-by: Aviram Bar-Haim <aviramb@mellanox.com>\n'}]",8,105437,a435908dbaaa985488f1181fa42205b5f26cba4b,33,6,4,11968,,,0,"Added UI restrictions for Mellanox features

This commit includes changes in UI restrictions:
  1. Restrict nova-network and GRE with Mellanox plugin.
  2. Block ports bonding in case of iSER storage or Mellanox
     SR-IOV plugin.
  3. Add probed VF limitation explanation to iSER checkbox.

closes-bug: #1336867
partially implements: blueprint mellanox-features-support

Change-Id: Ida76317dd5fdc5e3813c3b4279b5db5239d6c754
Signed-off-by: Aviram Bar-Haim <aviramb@mellanox.com>
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/37/105437/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.js']",2,51d573a775ff0c374e1408ad50d6640111fd652c,mellanox," var cluster_settings = this.model.get(""settings"").attributes; var iser_disabled = cluster_settings.storage.iser.value != true; var mellanox_sriov_disabled = cluster_settings.neutron_mellanox.plugin.value != ""ethernet""; return !this.isLocked() && this.model.get('net_provider') == 'neutron' && iser_disabled && mellanox_sriov_disabled;", return !this.isLocked() && this.model.get('net_provider') == 'neutron';,8,5
openstack%2Fmonasca-ui~master~Ibde9a55f4e3259887aa3961fe6bcdfb595ad59c4,openstack/monasca-ui,master,Ibde9a55f4e3259887aa3961fe6bcdfb595ad59c4,Add .gitreview and tox.ini files,MERGED,2014-07-16 22:39:47.000000000,2014-07-17 15:56:16.000000000,2014-07-17 15:56:16.000000000,"[{'_account_id': 3}, {'_account_id': 11094}]","[{'number': 1, 'created': '2014-07-16 22:39:47.000000000', 'files': ['.gitreview', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/a14ccfa39044e9b53c36fbb890ecd62432611431', 'message': 'Add .gitreview and tox.ini files\n\nChange-Id: Ibde9a55f4e3259887aa3961fe6bcdfb595ad59c4\n'}]",0,107522,a14ccfa39044e9b53c36fbb890ecd62432611431,7,2,1,12133,,,0,"Add .gitreview and tox.ini files

Change-Id: Ibde9a55f4e3259887aa3961fe6bcdfb595ad59c4
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/22/107522/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'tox.ini']",2,a14ccfa39044e9b53c36fbb890ecd62432611431,add-gitreview,"[tox] envlist = py27,pep8 minversion = 1.6 skipsdist = True [testenv] usedevelop = True install_command = pip install -U {opts} {packages} setenv = VIRTUAL_ENV={envdir} deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = /bin/bash run_tests.sh -N {posargs} [testenv:pep8] commands = /bin/bash run_tests.sh -N --pep8 [testenv:venv] commands = {posargs} [testenv:cover] commands = /bin/bash run_tests.sh -N --coverage {posargs} [tox:jenkins] downloadcache = ~/cache/pip [flake8] builtins = _ exclude = .venv,.git,.tox,dist,*openstack/common*,*lib/python*,*egg,build,panel_template,dash_template,local_settings.py,*/local/*,*/test/test_plugins/* # E127 continuation line over-indented for visual indent # E128 continuation line under-indented for visual indent # H701 empty localization string # H702 Formatting operation should be outside of localization method call # H803 git commit title should not end with period (disabled on purpose, see bug #1236621) ignore = E127,E128,H701,H702,H803 select = H236 ",,39,0
openstack%2Ffuel-web~master~I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790,openstack/fuel-web,master,I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790,Added UI changes for Mellanox features,MERGED,2014-06-29 18:43:48.000000000,2014-07-17 15:55:27.000000000,2014-07-17 15:55:27.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 10068}, {'_account_id': 11968}, {'_account_id': 12065}]","[{'number': 1, 'created': '2014-06-29 18:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e654cce721e4feb0ed442e5c34c7323f6a6e27f2', 'message': 'Added UI changes for Mellanox features\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}, {'number': 2, 'created': '2014-06-29 18:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2aaa66cb3fd643b3621dca0e4e97214b04b34372', 'message': 'Added UI changes for Mellanox features\n\n1. UI changes for iSER\n2. UI changes for SR-IOV\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}, {'number': 3, 'created': '2014-06-30 06:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d2488825e0b9812bc8307c97182a1720d8bb111f', 'message': 'Added UI changes for Mellanox features\n\n1. UI changes for iSER\n2. UI changes for SR-IOV\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}, {'number': 4, 'created': '2014-07-03 16:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/30f37e8b08976ecf37af5e899330652a90d38c44', 'message': 'Added UI changes for Mellanox features\n\n1. UI changes for iSER\n2. UI changes for SR-IOV\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}, {'number': 5, 'created': '2014-07-08 12:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7e6ab73f1010f9431b47bcb81ddf341f72b0dde3', 'message': 'Added UI changes for Mellanox features\n\n1. UI changes for iSER\n2. UI changes for SR-IOV\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}, {'number': 6, 'created': '2014-07-09 16:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/746d3a5d1236fc819076fb32adba3c69dd342bbd', 'message': 'Added UI changes for Mellanox features\n\n1. UI changes for iSER\n2. UI changes for SR-IOV\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}, {'number': 7, 'created': '2014-07-10 14:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c751b7d328029ae7c723ec9093df8f393b9d959d', 'message': 'Added UI changes for Mellanox features\n\n1. UI changes for iSER\n2. UI changes for SR-IOV\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}, {'number': 8, 'created': '2014-07-10 15:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/53156fdce6cd51441b0a53017a1574a999a69278', 'message': 'Added UI changes for Mellanox features\n\n1. UI changes for iSER\n2. UI changes for SR-IOV\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}, {'number': 9, 'created': '2014-07-10 21:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/071dbc970ac0b7d57e82d0b0e801c21baac45602', 'message': 'Added UI changes for Mellanox features\n\n1. UI changes for iSER\n2. UI changes for SR-IOV\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}, {'number': 10, 'created': '2014-07-10 23:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b2ed81f99d704a1526cc78f0f411039a806c6809', 'message': 'Added UI changes for Mellanox features\n\n1. UI changes for iSER\n2. UI changes for SR-IOV\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}, {'number': 11, 'created': '2014-07-15 11:53:18.000000000', 'files': ['nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/nailgun/orchestrator/provisioning_serializers.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4da2d785f8bbf97e4597f62c7af3a107fb379c77', 'message': 'Added UI changes for Mellanox features\n\n1. UI changes for iSER\n2. UI changes for SR-IOV\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790\n'}]",1,103425,4da2d785f8bbf97e4597f62c7af3a107fb379c77,81,8,11,12171,,,0,"Added UI changes for Mellanox features

1. UI changes for iSER
2. UI changes for SR-IOV

partially implements: blueprint mellanox-features-support
Signed-off-by: Moshe Levi <moshele@mellanox.com>

Change-Id: I0c59b9663b87d4e8ef6c7bf6f28a2605e48ef790
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/25/103425/3 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/nailgun/orchestrator/provisioning_serializers.py']",2,e654cce721e4feb0ed442e5c34c7323f6a6e27f2,mellanox," 'mlnx_vf_num': cluster_attrs['neutron_mellanox']['vf_num'], 'mlnx_plugin_mode': cluster_attrs['neutron_mellanox']['plugin'], 'mlnx_iser_enabled': cluster_attrs['storage']['iser'],",,44,0
openstack%2Fcinder~master~I3cf1f1d63d5f8bd8ffd007104691f914e3fd8538,openstack/cinder,master,I3cf1f1d63d5f8bd8ffd007104691f914e3fd8538,Explicitly import _() in Cinder code,MERGED,2014-07-08 01:15:21.000000000,2014-07-17 15:52:39.000000000,2014-07-17 15:52:39.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 6601}, {'_account_id': 7198}, {'_account_id': 7219}, {'_account_id': 9008}, {'_account_id': 9533}, {'_account_id': 9751}, {'_account_id': 12017}]","[{'number': 1, 'created': '2014-07-08 01:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/16402a9f3359654fb16275a710b5fe7f4dbd0af1', 'message': 'Explicitly import _() in Cinder code\n\nTo ensure that logs are properly translated and logged to\nthe Cinder log files (using the Cinder message catalogs)\nwe need to explicitly import _() in any python files that\nuse the _() function.\n\nCloses-bug: 1306275\nRelated-Blueprint: i18n-enablement\nChange-Id: I3cf1f1d63d5f8bd8ffd007104691f914e3fd8538\n'}, {'number': 2, 'created': '2014-07-08 01:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6754eaa750380166c3030f364f42d94b3892f7ed', 'message': 'Explicitly import _() in Cinder code\n\nTo ensure that logs are properly translated and logged to\nthe Cinder log files (using the Cinder message catalogs)\nwe need to explicitly import _() in any python files that\nuse the _() function.\n\nCloses-bug: 1306275\nRelated-Blueprint: i18n-enablement\nChange-Id: I3cf1f1d63d5f8bd8ffd007104691f914e3fd8538\n'}, {'number': 3, 'created': '2014-07-08 19:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f5f6183076b68739443b321c66a9515db271e673', 'message': 'Explicitly import _() in Cinder code\n\nTo ensure that logs are properly translated and logged to\nthe Cinder log files (using the Cinder message catalogs)\nwe need to explicitly import _() in any python files that\nuse the _() function.\n\nCloses-bug: 1306275\nRelated-Blueprint: i18n-enablement\nChange-Id: I3cf1f1d63d5f8bd8ffd007104691f914e3fd8538\n'}, {'number': 4, 'created': '2014-07-09 21:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/74c62b87b7f55103f79ebda0c7ea965a173a8d85', 'message': 'Explicitly import _() in Cinder code\n\nTo ensure that logs are properly translated and logged to\nthe Cinder log files (using the Cinder message catalogs)\nwe need to explicitly import _() in any python files that\nuse the _() function.\n\nCloses-bug: 1306275\nRelated-Blueprint: i18n-enablement\nChange-Id: I3cf1f1d63d5f8bd8ffd007104691f914e3fd8538\n'}, {'number': 5, 'created': '2014-07-17 04:41:07.000000000', 'files': ['cinder/scheduler/filter_scheduler.py', 'cinder/volume/manager.py', 'cinder/service.py', 'cinder/backup/api.py', 'cinder/tests/test_misc.py', 'cinder/volume/drivers/vmware/vim.py', 'cinder/api/v1/volume_metadata.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/db/sqlalchemy/api.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/tests/api/contrib/test_backups.py', 'cinder/volume/drivers/netapp/api.py', 'cinder/api/openstack/__init__.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/api/contrib/volume_unmanage.py', 'cinder/api/contrib/extended_snapshot_attributes.py', 'cinder/api/openstack/urlmap.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/api/v2/limits.py', 'cinder/volume/drivers/san/hp/hp_lefthand_iscsi.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/api/contrib/volume_actions.py', 'cinder/volume/drivers/coraid.py', 'cinder/volume/drivers/zadara.py', 'cinder/tests/test_ibm_xiv_ds8k.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/scheduler/driver.py', 'cinder/volume/drivers/nexenta/iscsi.py', 'cinder/transfer/api.py', 'cinder/api/contrib/scheduler_hints.py', 'cinder/api/contrib/qos_specs_manage.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/volume/drivers/emc/emc_smis_iscsi.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py', 'cinder/db/sqlalchemy/migrate_repo/versions/010_add_transfers_table.py', 'cinder/volume/drivers/hds/hds.py', 'cinder/volume/drivers/san/hp/hp_msa_common.py', 'cinder/volume/utils.py', 'cinder/tests/test_backup_ceph.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/tests/brick/test_brick_remotefs.py', 'cinder/api/contrib/types_manage.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/volume/drivers/huawei/huawei_utils.py', 'cinder/tests/test_glusterfs.py', 'cinder/db/sqlalchemy/migrate_repo/versions/017_add_encryption_information.py', 'cinder/scheduler/flows/create_volume.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/zonemanager/fc_zone_manager.py', 'cinder/scheduler/host_manager.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/volume/drivers/vmware/read_write_util.py', 'cinder/tests/test_volume_types.py', 'cinder/api/v2/volumes.py', 'cinder/db/sqlalchemy/migrate_repo/versions/009_add_snapshot_metadata_table.py', 'cinder/api/contrib/volume_manage.py', 'cinder/tests/test_netapp.py', 'cinder/api/sizelimit.py', 'cinder/db/sqlalchemy/migrate_repo/versions/008_add_backup.py', 'cinder/volume/drivers/lvm.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/api/extensions.py', 'cinder/api/common.py', 'cinder/api/v1/volumes.py', 'cinder/wsgi.py', 'cinder/volume/drivers/eqlx.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py', 'cinder/db/sqlalchemy/migrate_repo/versions/015_drop_migrations_table.py', 'cinder/backup/drivers/swift.py', 'cinder/image/image_utils.py', 'cinder/api/contrib/backups.py', 'cinder/volume/drivers/san/solaris.py', 'cinder/scheduler/filters/capacity_filter.py', 'cinder/api/contrib/volume_transfer.py', 'cinder/api/v2/snapshots.py', 'cinder/api/openstack/wsgi.py', 'cinder/volume/drivers/huawei/__init__.py', 'cinder/volume/drivers/huawei/huawei_t.py', 'cinder/api/middleware/fault.py', 'cinder/volume/flows/api/create_volume.py', 'cinder/api/contrib/admin_actions.py', 'cinder/scheduler/manager.py', 'cinder/scheduler/scheduler_options.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/api/v2/types.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/api/contrib/types_extra_specs.py', 'cinder/db/sqlalchemy/migrate_repo/versions/001_cinder_init.py', 'cinder/volume/drivers/vmware/api.py', 'cinder/volume/drivers/sheepdog.py', 'cinder/tests/integrated/api/client.py', 'cinder/volume/drivers/vmware/error_util.py', 'cinder/db/sqlalchemy/migrate_repo/versions/016_drop_sm_tables.py', 'cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/solidfire.py', 'cinder/zonemanager/fc_san_lookup_service.py', 'cinder/context.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/api/contrib/snapshot_actions.py', 'cinder/backup/driver.py', 'cinder/volume/drivers/huawei/ssh_common.py', 'cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/emc/emc_smis_common.py', 'cinder/volume/drivers/hds/iscsi.py', 'cinder/db/sqlalchemy/migrate_repo/versions/018_add_qos_specs.py', 'cinder/volume/drivers/ibm/storwize_svc/ssh.py', 'cinder/api/contrib/quota_classes.py', 'cinder/volume/flows/common.py', 'cinder/common/sqlalchemyutils.py', 'cinder/tests/test_rbd.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/volume/drivers/nexenta/utils.py', 'cinder/backup/drivers/tsm.py', 'cinder/volume/drivers/scality.py', 'cinder/volume/api.py', 'cinder/api/v1/snapshot_metadata.py', 'cinder/backup/manager.py', 'cinder/volume/drivers/block_device.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/api/v2/volume_metadata.py', 'cinder/api/contrib/volume_type_encryption.py', 'cinder/volume/volume_types.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/san/san.py', 'cinder/api/auth.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/db/sqlalchemy/migrate_repo/versions/003_glance_metadata.py', 'cinder/db/sqlalchemy/migrate_repo/versions/020_add_volume_admin_metadata_table.py', 'cinder/volume/drivers/netapp/ssc_utils.py', 'cinder/volume/flows/manager/manage_existing.py', 'cinder/api/openstack/volume/versions.py', 'cinder/api/openstack/volume/__init__.py', 'cinder/backup/drivers/ceph.py', 'cinder/quota.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'cinder/tests/fake_driver.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/quota_utils.py', 'cinder/volume/drivers/nexenta/jsonrpc.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/db/sqlalchemy/migrate_repo/versions/002_quota_class.py', 'cinder/image/glance.py', 'cinder/api/v2/snapshot_metadata.py', 'cinder/api/contrib/services.py', 'cinder/api/middleware/sizelimit.py', 'cinder/flow_utils.py', 'cinder/volume/drivers/vmware/vmware_images.py', 'cinder/volume/qos_specs.py', 'cinder/db/sqlalchemy/migration.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/api/xmlutil.py', 'cinder/api/contrib/hosts.py', 'cinder/utils.py', 'cinder/api/v1/snapshots.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/eafcc41e82ced6d72d1cfe0105e44c383f28a23a', 'message': 'Explicitly import _() in Cinder code\n\nTo ensure that logs are properly translated and logged to\nthe Cinder log files (using the Cinder message catalogs)\nwe need to explicitly import _() in any python files that\nuse the _() function.\n\nCloses-bug: 1306275\nRelated-Blueprint: i18n-enablement\nChange-Id: I3cf1f1d63d5f8bd8ffd007104691f914e3fd8538\n'}]",0,105315,eafcc41e82ced6d72d1cfe0105e44c383f28a23a,44,10,5,7198,,,0,"Explicitly import _() in Cinder code

To ensure that logs are properly translated and logged to
the Cinder log files (using the Cinder message catalogs)
we need to explicitly import _() in any python files that
use the _() function.

Closes-bug: 1306275
Related-Blueprint: i18n-enablement
Change-Id: I3cf1f1d63d5f8bd8ffd007104691f914e3fd8538
",git fetch https://review.opendev.org/openstack/cinder refs/changes/15/105315/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/filter_scheduler.py', 'cinder/volume/manager.py', 'cinder/service.py', 'cinder/backup/api.py', 'cinder/tests/test_misc.py', 'cinder/volume/drivers/vmware/vim.py', 'cinder/api/v1/volume_metadata.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/db/sqlalchemy/api.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/tests/api/contrib/test_backups.py', 'cinder/volume/drivers/netapp/api.py', 'cinder/api/openstack/__init__.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/api/contrib/volume_unmanage.py', 'cinder/api/contrib/extended_snapshot_attributes.py', 'cinder/api/openstack/urlmap.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/api/v2/limits.py', 'cinder/volume/drivers/san/hp/hp_lefthand_iscsi.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/api/contrib/volume_actions.py', 'cinder/volume/drivers/coraid.py', 'cinder/volume/drivers/zadara.py', 'cinder/tests/test_ibm_xiv_ds8k.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/scheduler/driver.py', 'cinder/volume/drivers/nexenta/iscsi.py', 'cinder/transfer/api.py', 'cinder/api/contrib/scheduler_hints.py', 'cinder/api/contrib/qos_specs_manage.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/volume/drivers/emc/emc_smis_iscsi.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py', 'cinder/db/sqlalchemy/migrate_repo/versions/010_add_transfers_table.py', 'cinder/volume/drivers/hds/hds.py', 'cinder/volume/drivers/san/hp/hp_msa_common.py', 'cinder/volume/utils.py', 'cinder/tests/test_backup_ceph.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/tests/brick/test_brick_remotefs.py', 'cinder/api/contrib/types_manage.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/volume/drivers/huawei/huawei_utils.py', 'cinder/tests/test_glusterfs.py', 'cinder/db/sqlalchemy/migrate_repo/versions/017_add_encryption_information.py', 'cinder/scheduler/flows/create_volume.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/zonemanager/fc_zone_manager.py', 'cinder/scheduler/host_manager.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/volume/drivers/vmware/read_write_util.py', 'cinder/tests/test_volume_types.py', 'cinder/api/v2/volumes.py', 'cinder/db/sqlalchemy/migrate_repo/versions/009_add_snapshot_metadata_table.py', 'cinder/api/contrib/volume_manage.py', 'cinder/tests/test_netapp.py', 'cinder/api/sizelimit.py', 'cinder/db/sqlalchemy/migrate_repo/versions/008_add_backup.py', 'cinder/volume/drivers/lvm.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/api/extensions.py', 'cinder/api/common.py', 'cinder/api/v1/volumes.py', 'cinder/wsgi.py', 'cinder/volume/drivers/eqlx.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py', 'cinder/db/sqlalchemy/migrate_repo/versions/015_drop_migrations_table.py', 'cinder/backup/drivers/swift.py', 'cinder/image/image_utils.py', 'cinder/api/contrib/backups.py', 'cinder/volume/drivers/san/solaris.py', 'cinder/scheduler/filters/capacity_filter.py', 'cinder/api/contrib/volume_transfer.py', 'cinder/api/v2/snapshots.py', 'cinder/api/openstack/wsgi.py', 'cinder/volume/drivers/huawei/__init__.py', 'cinder/volume/drivers/huawei/huawei_t.py', 'cinder/api/middleware/fault.py', 'cinder/volume/flows/api/create_volume.py', 'cinder/api/contrib/admin_actions.py', 'cinder/scheduler/manager.py', 'cinder/scheduler/scheduler_options.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/api/v2/types.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/api/contrib/types_extra_specs.py', 'cinder/db/sqlalchemy/migrate_repo/versions/001_cinder_init.py', 'cinder/volume/drivers/vmware/api.py', 'cinder/volume/drivers/sheepdog.py', 'cinder/tests/integrated/api/client.py', 'cinder/volume/drivers/vmware/error_util.py', 'cinder/db/sqlalchemy/migrate_repo/versions/016_drop_sm_tables.py', 'cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/solidfire.py', 'cinder/zonemanager/fc_san_lookup_service.py', 'cinder/context.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/api/contrib/snapshot_actions.py', 'cinder/backup/driver.py', 'cinder/volume/drivers/huawei/ssh_common.py', 'cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/emc/emc_smis_common.py', 'cinder/volume/drivers/hds/iscsi.py', 'cinder/db/sqlalchemy/migrate_repo/versions/018_add_qos_specs.py', 'cinder/volume/drivers/ibm/storwize_svc/ssh.py', 'cinder/api/contrib/quota_classes.py', 'cinder/volume/flows/common.py', 'cinder/common/sqlalchemyutils.py', 'cinder/tests/test_rbd.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/volume/drivers/nexenta/utils.py', 'cinder/backup/drivers/tsm.py', 'cinder/volume/drivers/scality.py', 'cinder/volume/api.py', 'cinder/api/v1/snapshot_metadata.py', 'cinder/backup/manager.py', 'cinder/volume/drivers/block_device.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/api/v2/volume_metadata.py', 'cinder/api/contrib/volume_type_encryption.py', 'cinder/volume/volume_types.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/san/san.py', 'cinder/api/auth.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/db/sqlalchemy/migrate_repo/versions/003_glance_metadata.py', 'cinder/db/sqlalchemy/migrate_repo/versions/020_add_volume_admin_metadata_table.py', 'cinder/volume/drivers/netapp/ssc_utils.py', 'cinder/volume/flows/manager/manage_existing.py', 'cinder/api/openstack/volume/versions.py', 'cinder/api/openstack/volume/__init__.py', 'cinder/backup/drivers/ceph.py', 'cinder/quota.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'cinder/tests/fake_driver.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/quota_utils.py', 'cinder/volume/drivers/nexenta/jsonrpc.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/db/sqlalchemy/migrate_repo/versions/002_quota_class.py', 'cinder/image/glance.py', 'cinder/api/v2/snapshot_metadata.py', 'cinder/api/contrib/services.py', 'cinder/volume/driver.py', 'cinder/api/middleware/sizelimit.py', 'cinder/flow_utils.py', 'cinder/volume/drivers/vmware/vmware_images.py', 'cinder/volume/qos_specs.py', 'cinder/db/sqlalchemy/migration.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/api/xmlutil.py', 'cinder/api/contrib/hosts.py', 'cinder/utils.py', 'cinder/api/v1/snapshots.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py']",162,16402a9f3359654fb16275a710b5fe7f4dbd0af1,bp/i18n-enablement,from cinder.openstack.common.gettextutils import _,,162,0
openstack%2Fopenstack-doc-tools~master~I94aa3a02f7bbe2e88beb510551a2aff76ed24f8a,openstack/openstack-doc-tools,master,I94aa3a02f7bbe2e88beb510551a2aff76ed24f8a,Removed trailing whitespace from help output,MERGED,2014-07-16 22:31:06.000000000,2014-07-17 15:48:48.000000000,2014-07-17 15:48:48.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 10215}]","[{'number': 1, 'created': '2014-07-16 22:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/351b578243db4cbd5acef90a1803877eb93fbe46', 'message': 'Removed trailing whitespace from help output\n\nSome of the output help from *-manage CLIs (eg. trove-manage) have\nwhitespace at the end of the line.\nThis causes the gate-openstack-manuals-tox-checkniceness test to fail\non the generated .xml files.\n\nTrailing white-space is now stripped off by the tool before writing the\n.xml file.\n\nChange-Id: I94aa3a02f7bbe2e88beb510551a2aff76ed24f8a\nCloses-Bug: #1342988\n'}, {'number': 2, 'created': '2014-07-17 15:05:59.000000000', 'files': ['os_doc_tools/commands.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/de741f0a2e9beb4aad90cd1d599177b47e658732', 'message': 'Removed trailing whitespace from help output\n\nSome of the output help from *-manage CLIs (eg. trove-manage) have\nwhitespace at the end of the line.\nThis causes the gate-openstack-manuals-tox-checkniceness test to fail\non the generated .xml files.\n\nTrailing white-space is now stripped off by the tool before writing the\n.xml file.\n\nChange-Id: I94aa3a02f7bbe2e88beb510551a2aff76ed24f8a\nCloses-Bug: #1342988\n'}]",2,107520,de741f0a2e9beb4aad90cd1d599177b47e658732,13,4,2,10215,,,0,"Removed trailing whitespace from help output

Some of the output help from *-manage CLIs (eg. trove-manage) have
whitespace at the end of the line.
This causes the gate-openstack-manuals-tox-checkniceness test to fail
on the generated .xml files.

Trailing white-space is now stripped off by the tool before writing the
.xml file.

Change-Id: I94aa3a02f7bbe2e88beb510551a2aff76ed24f8a
Closes-Bug: #1342988
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/20/107520/1 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/commands.py'],1,351b578243db4cbd5acef90a1803877eb93fbe46,1342988," os_file.write(""\n%s"" % (xline.rstrip()))"," os_file.write(""\n%s"" % (xline))",1,1
openstack%2Fcinder~master~I934b79cd4b799736c815f373cb3976b0daecf1a2,openstack/cinder,master,I934b79cd4b799736c815f373cb3976b0daecf1a2,Enable hacking check H104,ABANDONED,2014-07-16 18:17:46.000000000,2014-07-17 15:45:09.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1773}, {'_account_id': 7219}]","[{'number': 1, 'created': '2014-07-16 18:17:46.000000000', 'files': ['cinder/openstack/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder/commit/52bfa638f908c9eac2f09ca622f9ed7d53b808e9', 'message': 'Enable hacking check H104\n\n* [H104] Files with no code shouldn’t contain any license\n         header nor comments, and must be left completely empty.\n\nChange-Id: I934b79cd4b799736c815f373cb3976b0daecf1a2\n'}]",1,107462,52bfa638f908c9eac2f09ca622f9ed7d53b808e9,7,4,1,167,,,0,"Enable hacking check H104

* [H104] Files with no code shouldn’t contain any license
         header nor comments, and must be left completely empty.

Change-Id: I934b79cd4b799736c815f373cb3976b0daecf1a2
",git fetch https://review.opendev.org/openstack/cinder refs/changes/62/107462/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/openstack/__init__.py', 'tox.ini']",2,52bfa638f908c9eac2f09ca622f9ed7d53b808e9,enable_h104,"ignore = E251,E265,E711,E712,E713,F402,F841,H302,H305,H307,H402,H405,H803,H904","ignore = E251,E265,E711,E712,E713,F402,F841,H104,H302,H305,H307,H402,H405,H803,H904",1,16
openstack%2Fglance_store~master~Iae29da39792b14d248ba39faf556056066b0b074,openstack/glance_store,master,Iae29da39792b14d248ba39faf556056066b0b074,Add .gitreview,ABANDONED,2014-07-16 17:54:06.000000000,2014-07-17 15:43:33.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-07-16 17:54:06.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/8c72df133d18ab06ead6dcc38234f13d6dc55d5b', 'message': 'Add .gitreview\n\nAdd the usual .gitreview file so that ""git review -s"" works.\n\nChange-Id: Iae29da39792b14d248ba39faf556056066b0b074\n'}]",0,107449,8c72df133d18ab06ead6dcc38234f13d6dc55d5b,7,3,1,6547,,,0,"Add .gitreview

Add the usual .gitreview file so that ""git review -s"" works.

Change-Id: Iae29da39792b14d248ba39faf556056066b0b074
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/49/107449/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,8c72df133d18ab06ead6dcc38234f13d6dc55d5b,gitreview,[gerrit] host=review.openstack.org port=29418 project=openstack/glance.store.git ,,4,0
openstack%2Fmurano-deployment~master~I4c07d4c55ee8833449b03294749710c3b9b568dc,openstack/murano-deployment,master,I4c07d4c55ee8833449b03294749710c3b9b568dc,jenkins jobs update,MERGED,2014-07-17 12:31:50.000000000,2014-07-17 15:35:18.000000000,2014-07-17 15:35:17.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 8824}]","[{'number': 1, 'created': '2014-07-17 12:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/10a6a71540b2fcfcf5da3dbb6d57f990a7c8a6eb', 'message': 'jenkins jobs update\n\n* add proper yaml multiline in jjb yaml jobs definition\n* add collect artifacts if job fails into jjb job definition macros\n* remove prepare_incubator_at function and its call from dashboard test job\n* add sh -xe to the documentation build job launch\n\nChange-Id: I4c07d4c55ee8833449b03294749710c3b9b568dc\nCloses-Bug: 1340140\n'}, {'number': 2, 'created': '2014-07-17 15:22:08.000000000', 'files': ['murano-ci/jobs/murano-engine-app-deployment-tests-centos.yaml', 'murano-ci/jobs/macros.yaml', 'murano-ci/jobs/murano-engine-app-deployment-tests-ubuntu.yaml', 'murano-ci/scripts/murano-dashboard-integration-tests.sh', 'murano-ci/jobs/murano-dashboard-integration-tests-centos.yaml', 'murano-ci/infra/deploy_component_new.sh', 'murano-ci/jobs/murano-dashboard-integration-tests-ubuntu.yaml', 'murano-ci/jobs/Build_documentation.yaml'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/7f09c1d6fcfa90b7af3f4ecd6324590686a9d9e2', 'message': 'jenkins jobs update\n\n* add proper yaml multiline in jjb yaml jobs definition\n* add collect artifacts if job fails into jjb job definition macros\n* remove prepare_incubator_at function and its call from dashboard test job\n* add sh -xe to the documentation build job launch\n\nChange-Id: I4c07d4c55ee8833449b03294749710c3b9b568dc\nCloses-Bug: 1340140\n'}]",1,107668,7f09c1d6fcfa90b7af3f4ecd6324590686a9d9e2,16,6,2,7613,,,0,"jenkins jobs update

* add proper yaml multiline in jjb yaml jobs definition
* add collect artifacts if job fails into jjb job definition macros
* remove prepare_incubator_at function and its call from dashboard test job
* add sh -xe to the documentation build job launch

Change-Id: I4c07d4c55ee8833449b03294749710c3b9b568dc
Closes-Bug: 1340140
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/68/107668/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano-ci/jobs/murano-engine-app-deployment-tests-centos.yaml', 'murano-ci/jobs/macros.yaml', 'murano-ci/jobs/murano-engine-app-deployment-tests-ubuntu.yaml', 'murano-ci/scripts/murano-dashboard-integration-tests.sh', 'murano-ci/jobs/murano-dashboard-integration-tests-centos.yaml', 'murano-ci/infra/deploy_component_new.sh', 'murano-ci/jobs/murano-dashboard-integration-tests-ubuntu.yaml', 'murano-ci/jobs/Build_documentation.yaml']",8,10a6a71540b2fcfcf5da3dbb6d57f990a7c8a6eb,bug/1340140, sh -xe murano-deployment/docs-builder/builder.sh, sh murano-deployment/docs-builder/builder.sh,31,42
openstack%2Fdevstack-gate~master~I76ce718b6c7298af6c4cda9e74e87c4bfef7b643,openstack/devstack-gate,master,I76ce718b6c7298af6c4cda9e74e87c4bfef7b643,multi node-dg-setup-poc Working draft,ABANDONED,2014-07-17 14:48:12.000000000,2014-07-17 15:27:12.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-17 14:48:12.000000000', 'files': ['sub_node_prepare.sh', 'devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh', 'functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/82bd382bfec051e748c0f2dde8c15206b581afdf', 'message': 'multi node-dg-setup-poc Working draft\n\nTODO: remove extra set -x\nTODO: Use the feature grid\nTODO: MTU size handling\nTODO: tunneling with n-net linux bridge?\n\nChange-Id: I76ce718b6c7298af6c4cda9e74e87c4bfef7b643\n'}]",0,107727,82bd382bfec051e748c0f2dde8c15206b581afdf,3,1,1,5803,,,0,"multi node-dg-setup-poc Working draft

TODO: remove extra set -x
TODO: Use the feature grid
TODO: MTU size handling
TODO: tunneling with n-net linux bridge?

Change-Id: I76ce718b6c7298af6c4cda9e74e87c4bfef7b643
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/27/107727/1 && git format-patch -1 --stdout FETCH_HEAD,"['sub_node_prepare.sh', 'devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh', 'functions.sh']",4,82bd382bfec051e748c0f2dde8c15206b581afdf,multi-poc,"function remote_command { local ssh_opts=""-o PasswordAuthentication=no -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o ConnectionAttempts=4"" local dest_host=$1 shift ssh $ssh_opts $dest_host ""$@"" } function remote_copy_dir { local dest_host=$1 local src_dir=$2 local dest_dir=$3 remote_command ""$dest_host"" mkdir -p ""$dest_dir"" rsync -avz ""$src_dir"" ""${dest_host}:$dest_dir"" } function remote_copy_file { local ssh_opts=""-o PasswordAuthentication=no -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o ConnectionAttempts=4"" local src=$1 local dest=$2 shift scp $ssh_opts ""$src"" ""$dest"" }",,206,39
openstack%2Fkeystone-specs~master~I6b72466397823967d8183f01e57d46d717003b25,openstack/keystone-specs,master,I6b72466397823967d8183f01e57d46d717003b25,Propose Specification for non-persistent-tokens,MERGED,2014-05-28 00:11:27.000000000,2014-07-17 15:24:36.000000000,2014-06-27 16:49:02.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1091}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7232}, {'_account_id': 7823}, {'_account_id': 8978}, {'_account_id': 9060}, {'_account_id': 11045}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-05-28 00:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/3aec706a01eae1388fb385dab91953f330e224b3', 'message': 'Add spec for non-persistent-tokens\n\nAdd specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 2, 'created': '2014-05-28 00:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/59cd4e6c3ae1fe0f3fe8c9db999b9c6d8e2c65b0', 'message': 'Add spec for non-persistent-tokens\n\nAdd specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 3, 'created': '2014-05-29 22:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/b0066d4136dcd453239fb9c42215910315e5e2c3', 'message': 'Add spec for non-persistent-tokens\n\nAdd specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 4, 'created': '2014-06-01 17:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e408e2ef79b8222c9b808b2cbe592a14807527b1', 'message': 'Add spec for non-persistent-tokens\n\nAdd specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 5, 'created': '2014-06-02 22:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/084dec523d3bd8be9021fe93d6fbb22962537b02', 'message': 'Add spec for non-persistent-tokens\n\nAdd specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 6, 'created': '2014-06-02 22:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/0f12601f8b9f0b2fb227d663b91e44ccbec392b1', 'message': 'Add spec for non-persistent-tokens\n\nAdd specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 7, 'created': '2014-06-02 22:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/cf6f3e92a3cdfb59ddda096766923b539b9d7485', 'message': 'Add spec for non-persistent-tokens\n\nAdd specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 8, 'created': '2014-06-04 05:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/efb792766423fb0d6ede819858548129fda8e663', 'message': 'Add spec for non-persistent-tokens\n\nAdd specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 9, 'created': '2014-06-04 20:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/8b4a20e89c12316eaab0c48289a98838abdb539a', 'message': 'Add spec for non-persistent-tokens\n\nAdd specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 10, 'created': '2014-06-13 17:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/658c3725a870dfbfee4da45406c08c7417db42da', 'message': 'Add spec for non-persistent-tokens\n\nAdd specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 11, 'created': '2014-06-13 17:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/56d2b0380ad1b46271b1be7072193d8c7e0dcade', 'message': 'Propose Specification for non-persistent-tokens\n\nProposes specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 12, 'created': '2014-06-22 16:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/d9c31b1781e2268531d00973b34b1400df3d2784', 'message': 'Propose Specification for non-persistent-tokens\n\nProposes specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}, {'number': 13, 'created': '2014-06-23 02:04:59.000000000', 'files': ['specs/juno/non-persistent-tokens.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/050cf5a942f79fde8d02a402d61763aeaab4c8a7', 'message': 'Propose Specification for non-persistent-tokens\n\nProposes specification for the non-persistent PKI token provider and\nassociated work.\n\nChange-Id: I6b72466397823967d8183f01e57d46d717003b25\n'}]",123,95976,050cf5a942f79fde8d02a402d61763aeaab4c8a7,85,18,13,2903,,,0,"Propose Specification for non-persistent-tokens

Proposes specification for the non-persistent PKI token provider and
associated work.

Change-Id: I6b72466397823967d8183f01e57d46d717003b25
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/76/95976/9 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/non-persistent-tokens.rst'],1,3aec706a01eae1388fb385dab91953f330e224b3,persistence,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================== Non-persistent tokens ===================== With the addition of the revocation events system it is now possible to implement a token provider that does not require enumeration of the tokens for revocation purposes. This change will eliminate the need for persisting token information to a backend (SQL, Memcached, etc). Existing Launchpad BP:: https://blueprints.launchpad.net/keystone/+spec/ephemeral-pki-tokens Problem Description =================== Currently there is significant overhead in managing the persistence backend for the Token data. This administrative and performance overhead manifests in a number of ways: * SQL Backend sees significant bloat in the DB causing poor performance, significant consumption of storage resources. * Memcached (and largely all Key-Value-Store backends) show poor handling of the required enumeration of each user's tokens to handle revocations under the Token Revocation List. Even with the revocation events, the overhead in running the backing store can be significant while providing little added value Proposed Change =============== The change will be to eliminate the need to persist tokens to any form of stable storage. When using the new non-persistent token provider, UUID will not be available. Alternatives ------------ Incremental improvement to the storage backend drivers could be used instead of the non-persistent tokens. However, these incremental improvements would not ease the administrative or resource overhead as simply not requiring any persistence of the token. Long term, these incremental improvements would drive towards non-persistent tokens, as that becomes the simplest/most maintainable solution (no risk of data loss or data corruption in the backing store, no long-term memory/storage overhead, etc). Data Model Impact ----------------- The general data model for the token (in-memory) will change to be a uniform object (ensuring consistent model extracted from the versioned-token-format). The token db table will be maintained to accommodate backwards compatibility and use of the providers (notably UUID) that require persistence. The token data table will be migrated to support the new consistent token object format. JSON Schema for each token version will need to be developed for complete validation as part of the conversion from the versioned-token-format to the internal token object. REST API Impact --------------- The REST API will not be directly impacted. The use of UUID tokens will not work with the non-persistent token provider. Security Impact --------------- The internal token format will be changed to be consistent. Externally facing use and format of the token should not be impacted. All cases of PKI tokens will be decoded (in a similar fashion to auth_token middleware) in memory instead of making calls to the DB (limited cases) instead of referencing data stored in the token DB table. Notifications Impact -------------------- None Other End User Impact --------------------- When the new provider is used (non-persistent-token-provider) only PKI tokens will be issued, and the short-hash version of the token cannot be used to interact with Keystone. Performance Impact ------------------ Generally speaking this change should reduce load on the system and resource consumption by not requiring persistence of Token data. Tokens will need to be decoded via CMS, raising the CPU cost of handling tokens via the v2.0 GET and HEAD (validate and check) mechanisms because the data will not be stored outside of the PKI signed token data. Other Deployer Impact --------------------- Deployers will need to leverage the Revocation Events system instead of the Token Revocation List to utilize the non-persistent-token-provider. Developer Impact ---------------- All references to token_api.get_token() (excluding the UUID token provider) will cease to be available. Direct lookup of token data without decoding the PKI token (when PKI tokens are used) will not be available. Any interaction with token data will be done in a consistent manner through the new uniform token object, eliminating the need for specific code handling a versioned token dictionary. Implementation ============== Assignee(s) ----------- Primary assignee: Morgan Fainberg (mdrnstm) Other contributors: Adam Young (ayoung) Work Items ---------- * Uniform Token Object Development * Token Validation / Conversion to Uniform Token Object (including db migration) * Keystone AuthContextMiddleware updated to always do CMS decode of PKI tokens. * Elimination of all calls to token_api.get_token except when using the UUID token provider. * Implementation of non-persistent-PKI-token-provider Dependencies ============ * This spec depends (for validation code path) on https://blueprints.launchpad.net/keystone/+spec/keystone-api-validation * This spec depends on full revocation event support (auth_token middleware) Testing ======= * A Tempest scenario will be needed to test the non-persistent token provider deployment. * Unit tests will be required to exercise the non-persisted provider independent of the UUID backend. * Initially an alternate test scenario will be needed to validate the non- persistent token provider. Once revocation events becomes the default deployment method, the non-persistent provider should become default as well. Documentation Impact ==================== Documentation on deploying with revocation events and non-persistent PKI token provider will need to be included (configuration changes). References ========== * Under ""Token Revocation"":: http://dolphm.com/openstack-icehouse-design-summit-outcomes-for-keystone/ * https://blueprints.launchpad.net/keystone/+spec/reuse-token * https://blueprints.launchpad.net/keystone/+spec/ephemeral-pki-tokens ",,192,0
openstack%2Foslo.db~master~If19137cc81959031764c1b78f990b67a8912a304,openstack/oslo.db,master,If19137cc81959031764c1b78f990b67a8912a304,Enable skipped tests from test_models.py,MERGED,2014-05-20 13:19:01.000000000,2014-07-17 15:18:05.000000000,2014-07-17 15:18:04.000000000,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 6928}, {'_account_id': 7331}, {'_account_id': 7491}, {'_account_id': 7536}, {'_account_id': 8871}, {'_account_id': 11816}, {'_account_id': 12000}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-05-20 13:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/9a4d9a9312732078364dea2e13eb179fcbda25e6', 'message': 'Enable skipped tests from test_models.py\n\nEnable test_modelbase_iteritems and test_modelbase_iter which were\nalways skipped. These tests need a mapped object instead of\nModelBase instance.\n\nRefactor ModelBaseTest a bit - move creation of ModelBase and\nExtraKeysModel instances to setUp().\n\nRefactor test_modelbase_iteritems and test_modelbase_iter\nto check if we can iterate over columns and extra_keys.\n\nCloses-Bug: #1312220\n\nChange-Id: If19137cc81959031764c1b78f990b67a8912a304\n'}, {'number': 2, 'created': '2014-07-15 13:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/1653055fd81e3803eeab06966e43e9c94cc9ae0f', 'message': 'Enable skipped tests from test_models.py\n\nEnable test_modelbase_iteritems and test_modelbase_iter which were\nalways skipped. These tests need a mapped object instead of\nModelBase instance.\n\nRefactor ModelBaseTest a bit - move creation of ModelBase and\nExtraKeysModel instances to setUp().\n\nRefactor test_modelbase_iteritems and test_modelbase_iter\nto check if we can iterate over columns and extra_keys.\n\nCo-Authored-By: Oleksii Chuprykov <ochuprykov@mirantis.com>\n\nCloses-Bug: #1312220\n\nChange-Id: If19137cc81959031764c1b78f990b67a8912a304\n'}, {'number': 3, 'created': '2014-07-15 14:09:26.000000000', 'files': ['tests/sqlalchemy/test_models.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/35afdf17463eb970b04e8762988ef2274d622d96', 'message': 'Enable skipped tests from test_models.py\n\nEnable test_modelbase_iteritems and test_modelbase_iter which were\nalways skipped. These tests need a mapped object instead of\nModelBase instance.\n\nRefactor ModelBaseTest a bit - move creation of ModelBase and\nExtraKeysModel instances to setUp().\n\nRefactor test_modelbase_iteritems and test_modelbase_iter\nto check if we can iterate over columns and extra_keys.\n\nCo-Authored-By: Oleksii Chuprykov <ochuprykov@mirantis.com>\n\nCloses-Bug: #1312220\n\nChange-Id: If19137cc81959031764c1b78f990b67a8912a304\n'}]",7,94361,35afdf17463eb970b04e8762988ef2274d622d96,43,10,3,7331,,,0,"Enable skipped tests from test_models.py

Enable test_modelbase_iteritems and test_modelbase_iter which were
always skipped. These tests need a mapped object instead of
ModelBase instance.

Refactor ModelBaseTest a bit - move creation of ModelBase and
ExtraKeysModel instances to setUp().

Refactor test_modelbase_iteritems and test_modelbase_iter
to check if we can iterate over columns and extra_keys.

Co-Authored-By: Oleksii Chuprykov <ochuprykov@mirantis.com>

Closes-Bug: #1312220

Change-Id: If19137cc81959031764c1b78f990b67a8912a304
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/61/94361/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/sqlalchemy/test_models.py'],1,9a4d9a9312732078364dea2e13eb179fcbda25e6,bug/1312220," def setUp(self): super(ModelBaseTest, self).setUp() self.mb = models.ModelBase() self.ekm = ExtraKeysModel() self.mb['world'] = 'hello' self.assertEqual(self.mb['world'], 'hello') self.mb.update(h) for key in h.keys(): self.assertEqual(self.mb[key], h[key]) expected = { 'id': None, 'smth': None, 'name': 'NAME', 'a': '1', 'b': '2', } self.ekm.update(h) found_items = 0 for key, value in self.ekm.iteritems(): self.assertEqual(expected[key], value) found_items += 1 self.assertEqual(len(expected), found_items) expected = { 'id': None, 'smth': None, 'name': 'NAME', } i = iter(self.ekm) self.assertEqual(expected[r[0]], r[1]) self.assertEqual(len(expected), found_items) self.assertEqual(self.mb._extra_keys, []) self.assertEqual(self.ekm._extra_keys, ['name']) data = dict(self.ekm)"," mb = models.ModelBase() mb['world'] = 'hello' self.assertEqual(mb['world'], 'hello') mb = models.ModelBase() mb.update(h) for key in h.keys(): self.assertEqual(mb[key], h[key]) self.skipTest(""Requires DB"") mb = models.ModelBase() mb.update(h) for key, value in mb.iteritems(): self.assertEqual(h[key], value) self.skipTest(""Requires DB"") mb = models.ModelBase() h = {'a': '1', 'b': '2'} mb.update(h) i = iter(mb) min_items = len(h) self.assertTrue(r in h) self.assertEqual(min_items, found_items) mb = models.ModelBase() self.assertEqual(mb._extra_keys, []) ekm = ExtraKeysModel() self.assertEqual(ekm._extra_keys, ['name']) item = ExtraKeysModel() data = dict(item)",33,27
openstack%2Ffuel-main~master~I86834cb62beac981e8c3defb8b2d90bafafb84b6,openstack/fuel-main,master,I86834cb62beac981e8c3defb8b2d90bafafb84b6,Fail docker build if puppet fails,MERGED,2014-07-15 12:57:07.000000000,2014-07-17 15:04:40.000000000,2014-07-17 15:04:40.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9977}]","[{'number': 1, 'created': '2014-07-15 12:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a6ae530808fbbc165ef65409fde7b7aaaef9f309', 'message': 'Fail docker build if puppet fails\n\nPuppet does not return non-zero exit code if\nthere are errors during deployment.\n\nFIXME: Cobbler has iptables bugs. Implement at future date.\n\nChange-Id: I86834cb62beac981e8c3defb8b2d90bafafb84b6\nCloses-Bug: #1337288\n'}, {'number': 2, 'created': '2014-07-16 08:00:08.000000000', 'files': ['docker/rsync/Dockerfile', 'docker/mcollective/Dockerfile', 'docker/astute/Dockerfile', 'docker/ostf/Dockerfile', 'docker/keystone/Dockerfile', 'docker/rsyslog/Dockerfile', 'docker/nailgun/Dockerfile', 'docker/nginx/Dockerfile', 'docker/rabbitmq/Dockerfile'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/95f1a60a5a2cc987edd4a257fd875355d64a25f9', 'message': 'Fail docker build if puppet fails\n\nPuppet does not return non-zero exit code if\nthere are errors during deployment.\n\nFIXME: Cobbler has iptables bugs. Implement at future date.\n\nChange-Id: I86834cb62beac981e8c3defb8b2d90bafafb84b6\nCloses-Bug: #1337288\n'}]",1,107039,95f1a60a5a2cc987edd4a257fd875355d64a25f9,20,5,2,7195,,,0,"Fail docker build if puppet fails

Puppet does not return non-zero exit code if
there are errors during deployment.

FIXME: Cobbler has iptables bugs. Implement at future date.

Change-Id: I86834cb62beac981e8c3defb8b2d90bafafb84b6
Closes-Bug: #1337288
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/39/107039/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/rsync/Dockerfile', 'docker/mcollective/Dockerfile', 'docker/astute/Dockerfile', 'docker/ostf/Dockerfile', 'docker/keystone/Dockerfile', 'docker/rsyslog/Dockerfile', 'docker/nailgun/Dockerfile', 'docker/nginx/Dockerfile', 'docker/rabbitmq/Dockerfile']",9,a6ae530808fbbc165ef65409fde7b7aaaef9f309,bug/1337288,RUN mkdir -p /var/lib/hiera /var/log/rabbitmq; touch /var/lib/hiera/common.yaml;puppet apply --detailed-exitcodes -d -v /etc/puppet/modules/nailgun/examples/rabbitmq-only.pp; [ $? -lt 4 ],RUN mkdir -p /var/lib/hiera /var/log/rabbitmq; touch /var/lib/hiera/common.yaml;/usr/bin/puppet apply -v /etc/puppet/modules/nailgun/examples/rabbitmq-only.pp,9,10
openstack%2Ffuel-library~master~Ibc47b3a970756fd7ed49e7fd5558bf24929f7a76,openstack/fuel-library,master,Ibc47b3a970756fd7ed49e7fd5558bf24929f7a76,Ensure web service starts before cobbler sync,MERGED,2014-07-08 13:37:21.000000000,2014-07-17 14:57:58.000000000,2014-07-17 14:57:57.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-08 13:37:21.000000000', 'files': ['deployment/puppet/cobbler/manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c9dc047f8065820f99716b47d162037148147edf', 'message': 'Ensure web service starts before cobbler sync\n\nAn issue occurs on certain deployment types\n(mainly virtual) that causes cobbler sync to\nfail because httpd is not ready yet. Adding a\nservice check should cover this case.\n\nChange-Id: Ibc47b3a970756fd7ed49e7fd5558bf24929f7a76\nCloses-Bug: #1338552\n'}]",0,105449,c9dc047f8065820f99716b47d162037148147edf,15,5,1,7195,,,0,"Ensure web service starts before cobbler sync

An issue occurs on certain deployment types
(mainly virtual) that causes cobbler sync to
fail because httpd is not ready yet. Adding a
service check should cover this case.

Change-Id: Ibc47b3a970756fd7ed49e7fd5558bf24929f7a76
Closes-Bug: #1338552
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/49/105449/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cobbler/manifests/server.pp'],1,c9dc047f8065820f99716b47d162037148147edf,cobbler_wait_httpd," exec { ""wait_for_web_service"": command => '[ $(curl --connect-timeout 1 -s -w %{http_code} http://127.0.0.1:80/ -o /dev/null) -lt 500 ]', require => Service[$cobbler_web_service], subscribe => Service[$cobbler_web_service], tries => 60, try_sleep => 1, } Exec['wait_for_web_service'],",,9,0
openstack%2Fqa-specs~master~If9c7da9d8194b60a25ebb90033ab6bbbba56e4da,openstack/qa-specs,master,If9c7da9d8194b60a25ebb90033ab6bbbba56e4da,move scenario tests to tempest client,MERGED,2014-07-14 11:44:21.000000000,2014-07-17 14:57:04.000000000,2014-07-17 14:57:04.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 8556}]","[{'number': 1, 'created': '2014-07-14 11:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/4a1c59cc0f1d379502460d3b901d4a7ff2929247', 'message': 'move scenario tests to tempest client\n\nspec to move the scenario tests to tempest client.\n\nChange-Id: If9c7da9d8194b60a25ebb90033ab6bbbba56e4da\n'}, {'number': 2, 'created': '2014-07-17 14:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/eee86a5ee7a52d6dd063e44e21bb4ee520095e3f', 'message': 'move scenario tests to tempest client\n\nspec to move the scenario tests to tempest client.\n\nPartially implements: blueprint tempest-client-scenarios\nChange-Id: If9c7da9d8194b60a25ebb90033ab6bbbba56e4da\n'}, {'number': 3, 'created': '2014-07-17 14:44:19.000000000', 'files': ['specs/tempest-client-scenarios.rst'], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/e8ba49a9a27ba75cd44bdb87c4f323752e884f88', 'message': 'move scenario tests to tempest client\n\nspec to move the scenario tests to tempest client.\n\nPartially implements: blueprint tempest-client-scenarios\nChange-Id: If9c7da9d8194b60a25ebb90033ab6bbbba56e4da\n'}]",5,106738,e8ba49a9a27ba75cd44bdb87c4f323752e884f88,18,6,3,2750,,,0,"move scenario tests to tempest client

spec to move the scenario tests to tempest client.

Partially implements: blueprint tempest-client-scenarios
Change-Id: If9c7da9d8194b60a25ebb90033ab6bbbba56e4da
",git fetch https://review.opendev.org/openstack/qa-specs refs/changes/38/106738/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/tempest-client-scenarios.rst'],1,4a1c59cc0f1d379502460d3b901d4a7ff2929247,scenario,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================= Tempest Client for Scenario Tests ================================= https://blueprints.launchpad.net/tempest/+spec/tempest-client-scenarios Tempest currently has tests using 2 different OpenStack clients. The first is a client written in Tempest for testability and debugability. The second is the various native clients. This adds debt to the Tempest code that we should remove. Problem description =================== As Tempest grew up we grew tests that included poking directly at the raw API with our own client, as well as through the various native clients for the projects. As the volume of tests have grown, and some of the complexities in Tempest (like tenant isolation) have shown up, the 2 client strategy has become problematic. 1. It means that various abstractions need to be built above the clients to do things like waiting for resources to be created, handling tenant isolation, and doing safe cleanup. 2. The debugging output is radically different depending on the client that has failed. We can fix and react to a debuability issue in the Tempest client in tree. Addressing something as simple as reduction of extraneous token messages needs to be landed in 10 trees before it's fixed in a tempest run. 3. It's demotivating to work on the code. Proposed change =============== We do a wholesale cut over of the openstack clients to the Tempest client in all the scenario tests. We remove the abstractions that were built just for these clients. Alternatives ------------ Keep things as they are. This however has begun to be a top issue impacting gate debugability. Implementation ============== Assignee(s) ----------- Primary assignee: None (Will attempt to push this through during the code sprint in Darmstadt) Work Items ---------- - replace official clients in tempest/scenario with tempest clients - add hacking rule to provide use of official clients - remove tenant isolation abstraction Dependencies ============ None Referenences ============ Mailing list discussion - http://lists.openstack.org/pipermail/openstack-dev/2014-July/039879.html ",,82,0
openstack%2Frally~master~I26db0295d6c1ded6c2443e390f3b9c184c6619b9,openstack/rally,master,I26db0295d6c1ded6c2443e390f3b9c184c6619b9,Update Tempest Config Generator,MERGED,2014-07-17 13:56:16.000000000,2014-07-17 14:48:21.000000000,2014-07-17 14:48:20.000000000,"[{'_account_id': 3}, {'_account_id': 6124}, {'_account_id': 7369}, {'_account_id': 9545}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-07-17 13:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e5c799e9dd4ce16d52d0d19cd1ae215a0c5bda85', 'message': 'Update func to remove self\n\nChange-Id: I26db0295d6c1ded6c2443e390f3b9c184c6619b9\nCloses-Bug:#1343294\n'}, {'number': 2, 'created': '2014-07-17 14:10:25.000000000', 'files': ['rally/verification/verifiers/tempest/config.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/453cf81052577310cf67463f5b32eb705b36bed9', 'message': 'Update Tempest Config Generator\n\nUpdated method func inside generator method\nto remove self\n\nChange-Id: I26db0295d6c1ded6c2443e390f3b9c184c6619b9\nCloses-Bug:#1343294\n'}]",2,107711,453cf81052577310cf67463f5b32eb705b36bed9,14,5,2,11105,,,0,"Update Tempest Config Generator

Updated method func inside generator method
to remove self

Change-Id: I26db0295d6c1ded6c2443e390f3b9c184c6619b9
Closes-Bug:#1343294
",git fetch https://review.opendev.org/openstack/rally refs/changes/11/107711/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/verification/verifiers/tempest/config.py'],1,e5c799e9dd4ce16d52d0d19cd1ae215a0c5bda85,smallfix, func(), func(self),1,1
openstack%2Ftripleo-incubator~master~I41cfd0e5dfdf583492a65e3684bb812c0792084a,openstack/tripleo-incubator,master,I41cfd0e5dfdf583492a65e3684bb812c0792084a,Improve readability of long JQ expression,MERGED,2014-06-12 14:57:31.000000000,2014-07-17 14:35:06.000000000,2014-07-17 14:35:05.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1926}, {'_account_id': 4330}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 7579}, {'_account_id': 8399}, {'_account_id': 8688}, {'_account_id': 9536}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-06-12 14:57:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/5c5affbe1af03561b83e4687f571750a5091bdfc', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 2, 'created': '2014-06-12 14:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ac62f6811680062d794c3c73d87e5fe5096d3bee', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 3, 'created': '2014-06-12 14:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/1ab077d2a64de69bc5083375e52b90f9fd39561c', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 4, 'created': '2014-06-12 17:00:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e7fcff3ccff54b50f4dbcbe4c3cf3b4a0fdabc15', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 5, 'created': '2014-06-13 12:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/64d6cb44a5aa90155f71281ff9457ffde1386278', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 6, 'created': '2014-06-13 16:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/fd27629568dc2b82c5ab430fa15b4934d7d44012', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 7, 'created': '2014-06-13 16:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f7763e2b948d6ea8b8a5ea5df718b30e9ad35136', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 8, 'created': '2014-06-16 10:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/1947f5a5c0dab77318a6c6bc8244060100d215f1', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 9, 'created': '2014-06-17 11:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/486ecff1046946fde32af1926546f678a4867858', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 10, 'created': '2014-06-17 11:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/072636794926a721733c04e6b8d0915b8aa0e1ef', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 11, 'created': '2014-06-17 13:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/9f7089209a8eaf4cdacc91c6181062a78e16f72c', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 12, 'created': '2014-06-17 13:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/55d241248aabc2b0dd948ed8c8a5e332a247418b', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 13, 'created': '2014-06-18 12:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ca4a4865a6e2a3ef1d256f6bb91ffa001f5a7a53', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 14, 'created': '2014-06-25 16:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/3b7abe59120d2db22edd5d6363fd75337dafbdae', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 15, 'created': '2014-07-02 15:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/85a9a29bf6284653743a0d3b993fec3ebc74472d', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 16, 'created': '2014-07-03 11:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/50c74412816203b6f178ceea05eececeb92ee67e', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 17, 'created': '2014-07-03 11:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f9f8cb8e69b68f252cafa4af34415fb4e1fccdc0', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 18, 'created': '2014-07-03 14:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/37df322368b3f696706a52f5de5c8f0821bc7da4', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 19, 'created': '2014-07-14 12:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/df70739bd3448fbecd21b9b752ac7f0a8f04ed28', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}, {'number': 20, 'created': '2014-07-16 09:45:56.000000000', 'files': ['scripts/devtest_seed.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/1eeb857babb7e78cfbb71f31337a2495ebb3993d', 'message': 'Improve readability of long JQ expression\n\nInline single value from cidr.json.\n\nLine everything up.\n\nUnify expressions doing similar things.\n\nCo-Author: Alexis Lee <alexisl@hp.com>\nChange-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a\n'}]",4,99681,1eeb857babb7e78cfbb71f31337a2495ebb3993d,108,11,20,10373,,,0,"Improve readability of long JQ expression

Inline single value from cidr.json.

Line everything up.

Unify expressions doing similar things.

Co-Author: Alexis Lee <alexisl@hp.com>
Change-Id: I41cfd0e5dfdf583492a65e3684bb812c0792084a
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/81/99681/20 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_seed.sh'],1,5c5affbe1af03561b83e4687f571750a5091bdfc,seed_callback,".[1] as $config | ($config[""baremetal-network""].seed.ip // ""192.0.2.1"") as $bm_seed_ip | .[0] | .bootstack += {""public_interface_ip"": ($bm_seed_ip + ""/'""${BM_NETWORK_CIDR##*/}""'""), ""masquerade_networks"": ($config[""baremetal-network""].cidr // ""192.0.2.0/24"") } | .heat |= ( .watch_server_url=""http://"" + $bm_seed_ip + "":8003"" | .waitcondition_server_url=""http://"" + $bm_seed_ip + "":8000/v1/waitcondition"" | .metadata_server_url=""http://"" + $bm_seed_ip + "":8000"") | . + {""local-ipv4"": $bm_seed_ip, ""completion-signal"": (""http://"" + $config[""host-ip""] + "":'""${SEED_COMP_PORT:=27414}""'""), ""instance-id"": ""'""${SEED_IMAGE_ID:=seedImageID}""'"" } ' tmp_local.json $TE_DATAFILE > local.json","# FIXME: Once we support jq 1.3 we can use --arg here instead of writing # cidr.json as the 3rd input file echo ""{ \""cidr\"": \""${BM_NETWORK_CIDR##*/}\"" }"" > cidr.json.[1] as $config | .[2] as $cidr_config | ($config[""baremetal-network""].seed.ip // ""192.0.2.1"") as $bm_seed_ip | ($config[""host-ip""]) as $bm_host | (.[0].heat |= ( .watch_server_url=""http://"" + $bm_seed_ip + "":8003""| .waitcondition_server_url=""http://"" + $bm_seed_ip + "":8000/v1/waitcondition""| .metadata_server_url=""http://"" + $bm_seed_ip + "":8000""))| (.[0][""local-ipv4""] = $bm_seed_ip)| (.[0].bootstack.public_interface_ip = $bm_seed_ip + ""/"" + $cidr_config.cidr)| (.[0].bootstack.masquerade_networks = ($config[""baremetal-network""].cidr // ""192.0.2.0/24""))| (.[0][""completion-signal""] = ""http://"" + $bm_host + "":'""${SEED_COMP_PORT:=27414}""'"")| (.[0][""instance-id""] = ""'""${SEED_IMAGE_ID:=seedImageID}""'"")| .[0]' tmp_local.json $TE_DATAFILE cidr.json > local.jsonrm cidr.json ",15,19
openstack%2Fglance_store~master~I5c78af7334cb39e6d32afe7ca342f91c5521d30b,openstack/glance_store,master,I5c78af7334cb39e6d32afe7ca342f91c5521d30b,Add .gitreview to the repo,MERGED,2014-07-17 07:50:42.000000000,2014-07-17 14:34:59.000000000,2014-07-17 14:34:59.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-07-17 07:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/adcc3566ce6d26373fbf43a4e9036011f8435e91', 'message': 'Add .gitreview to the repo\n\nChange-Id: I5c78af7334cb39e6d32afe7ca342f91c5521d30b\n'}, {'number': 2, 'created': '2014-07-17 07:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/80c5b8c24996e49c44e6664c0859d02c947843b5', 'message': 'Add .gitreview to the repo\n\nThis patch also removes `swift` related code until we port it.\n\nChange-Id: I5c78af7334cb39e6d32afe7ca342f91c5521d30b\n'}, {'number': 3, 'created': '2014-07-17 08:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/67bd51ba7921e6b1246e9a1854aee31c03a05773', 'message': 'Add .gitreview to the repo\n\nThis patch also removes `swift` related code until we port it.\n\nChange-Id: I5c78af7334cb39e6d32afe7ca342f91c5521d30b\n'}, {'number': 4, 'created': '2014-07-17 08:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/99629c961b6ee3afa0eccab3c9007161da97da38', 'message': 'Add .gitreview to the repo\n\nThis patch also removes `swift` related code until we port it.\n\nChange-Id: I5c78af7334cb39e6d32afe7ca342f91c5521d30b\n'}, {'number': 5, 'created': '2014-07-17 09:53:30.000000000', 'files': ['glance/store/_drivers/vmware_datastore.py', 'doc/source/index.rst', 'requirements.txt', 'glance/store/_drivers/swift.py', '.gitreview', 'test-requirements.txt', 'doc/source/conf.py', 'tests/unit/test_swift_store.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/2450528776035950898607dc0436da0515934244', 'message': 'Add .gitreview to the repo\n\nThis patch also removes `swift` related code until we port it.\n\nChange-Id: I5c78af7334cb39e6d32afe7ca342f91c5521d30b\n'}]",0,107578,2450528776035950898607dc0436da0515934244,17,3,5,6159,,,0,"Add .gitreview to the repo

This patch also removes `swift` related code until we port it.

Change-Id: I5c78af7334cb39e6d32afe7ca342f91c5521d30b
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/78/107578/4 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,adcc3566ce6d26373fbf43a4e9036011f8435e91,,[gerrit] host=review.openstack.org port=29418 project=openstack/glance.store.git ,,4,0
openstack%2Fneutron~master~I43134ef4a9e01aac1967fb7b69ad36f96cde04c0,openstack/neutron,master,I43134ef4a9e01aac1967fb7b69ad36f96cde04c0,Fix a log typo in ML2 manager.bind_port(),MERGED,2014-07-13 08:54:18.000000000,2014-07-17 14:18:58.000000000,2014-07-17 10:41:14.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7805}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 11825}]","[{'number': 1, 'created': '2014-07-13 08:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/42d151233779b404213e72054f9ffbfb1519d7ff', 'message': 'Fix a log typo in ML2 manager.bind_port()\n\nChange-Id: I43134ef4a9e01aac1967fb7b69ad36f96cde04c0\n'}, {'number': 2, 'created': '2014-07-17 02:02:35.000000000', 'files': ['neutron/plugins/ml2/managers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/57011b901f0c26c840c207e007e392ba9ff5890b', 'message': 'Fix a log typo in ML2 manager.bind_port()\n\nChange-Id: I43134ef4a9e01aac1967fb7b69ad36f96cde04c0\n'}]",2,106608,57011b901f0c26c840c207e007e392ba9ff5890b,49,25,2,7805,,,0,"Fix a log typo in ML2 manager.bind_port()

Change-Id: I43134ef4a9e01aac1967fb7b69ad36f96cde04c0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/106608/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/managers.py'],1,42d151233779b404213e72054f9ffbfb1519d7ff,fix-ml2-log," ""profile: %(profile)s, """," ""profile: %(profile)s""",1,1
openstack%2Ffuel-web~master~I9bc5d7f4a3de76dd09fb8e45f5d50969e8f19138,openstack/fuel-web,master,I9bc5d7f4a3de76dd09fb8e45f5d50969e8f19138,Set default repos/puppets for releases,MERGED,2014-07-17 09:36:08.000000000,2014-07-17 14:17:18.000000000,2014-07-17 14:17:17.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-07-17 09:36:08.000000000', 'files': ['nailgun/nailgun/settings.yaml', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5c28cd5511e2acd2a6277b67ec979af0632ffea2', 'message': 'Set default repos/puppets for releases\n\nSince Fuel 5.1 repos/puppets paths are sent by Nailgun to Astute.\nSo we need to set defaults here, and remove them from Astute in\norder to make our code more clear and centralized.\n\nChange-Id: I9bc5d7f4a3de76dd09fb8e45f5d50969e8f19138\nCloses-Bug: #1342168\n'}]",0,107614,5c28cd5511e2acd2a6277b67ec979af0632ffea2,13,6,1,10391,,,0,"Set default repos/puppets for releases

Since Fuel 5.1 repos/puppets paths are sent by Nailgun to Astute.
So we need to set defaults here, and remove them from Astute in
order to make our code more clear and centralized.

Change-Id: I9bc5d7f4a3de76dd09fb8e45f5d50969e8f19138
Closes-Bug: #1342168
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/14/107614/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/settings.yaml', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py']",3,5c28cd5511e2acd2a6277b67ec979af0632ffea2,bug/1342168," def test_repo_and_puppet_data_w_orch_data(self): def test_repo_and_puppet_data_wo_orch_data(self): release_id = self.env.create_release().id cluster_id = self.env.create( cluster_kwargs={ 'release_id': release_id }, nodes_kwargs=[ {'roles': ['controller'], 'pending_addition': True} ] )[""id""] cluster = self.db.query(Cluster).get(cluster_id) objects.NodeCollection.prepare_for_deployment(cluster.nodes) facts = self.serializer.serialize(cluster, cluster.nodes) self.assertEqual(1, len(facts)) fact = facts[0] self.assertEqual( fact['repo_metadata'], { 'nailgun': 'http://127.0.0.1:8080/centos/fuelweb/x86_64' } ) self.assertEqual( fact['puppet_modules_source'], 'rsync://127.0.0.1:/puppet/modules/' ) self.assertEqual( fact['puppet_manifests_source'], 'rsync://127.0.0.1:/puppet/manifests/' ) ", def test_repo_and_puppet_data(self):,59,2
openstack%2Ffuel-web~stable%2F5.0~Id56c6f547840eccddadda76835773e02bc3d4cde,openstack/fuel-web,stable/5.0,Id56c6f547840eccddadda76835773e02bc3d4cde,Style fix for Network tunnel ip range label,MERGED,2014-07-17 12:44:18.000000000,2014-07-17 14:09:19.000000000,2014-07-17 13:01:38.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-17 12:44:18.000000000', 'files': ['nailgun/static/css/styles.less'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/17444180b7e8c0c454488e63a05693881168f76a', 'message': 'Style fix for Network tunnel ip range label\n\nchanged width\n\nChange-Id: Id56c6f547840eccddadda76835773e02bc3d4cde\nCloses-bug: 1343190\n(cherry picked from commit f05bcfc1159436b06357a60d8f6ad6fd2f7c9f7f)\n'}]",0,107674,17444180b7e8c0c454488e63a05693881168f76a,17,3,1,9091,,,0,"Style fix for Network tunnel ip range label

changed width

Change-Id: Id56c6f547840eccddadda76835773e02bc3d4cde
Closes-bug: 1343190
(cherry picked from commit f05bcfc1159436b06357a60d8f6ad6fd2f7c9f7f)
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/74/107674/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/css/styles.less'],1,17444180b7e8c0c454488e63a05693881168f76a,, &.mini > div { width: 104px; } , &.mini > div { width: 133px; } ,1,1
openstack%2Foslo-specs~master~I7ee2ad7acb830116f937021bfa37e3b56bace118,openstack/oslo-specs,master,I7ee2ad7acb830116f937021bfa37e3b56bace118,Add vmware-new-vim to juno,ABANDONED,2014-06-13 15:04:44.000000000,2014-07-17 14:08:37.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 9172}, {'_account_id': 9555}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-06-13 15:04:44.000000000', 'files': ['specs/juno/vmware-new-vim.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/005a10972b968f0946ecf755f8f5957ef03188f4', 'message': 'Add vmware-new-vim to juno\n\nChange-Id: I7ee2ad7acb830116f937021bfa37e3b56bace118\n'}]",23,99952,005a10972b968f0946ecf755f8f5957ef03188f4,11,5,1,9555,,,0,"Add vmware-new-vim to juno

Change-Id: I7ee2ad7acb830116f937021bfa37e3b56bace118
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/52/99952/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/vmware-new-vim.rst'],1,005a10972b968f0946ecf755f8f5957ef03188f4,vmware-new-vim,".. ============================= New VIM api for VMware ============================= https://blueprints.launchpad.net/oslo/+spec/vmware-new-vim Openstack VMware drivers access vSphere using an internal api. This internal api shows all the signs of 'organic' growth: * Its implementation is hard to read, validate and debug * It is hard to use * It is lacking correctness features which consequently go mostly unimplemented It is not a large amount of code, but it is widely used. Improving it would improve a large amount of code. The corollary is that changing it will also require changing a lot of code. Problem description =================== The vim API is split between api.py, vim.py and vim_util.py. The separation of responsibilities between api.py and vim.py is confused at best. Error handling in particular is extremely strange. vim_util.py is a collection of functions which rely heavily on details from the other 2, and is consequently not independent. Following any vim problem requires jumping continuously between these 3 files. The VMwareAPISession.invoke_api() method takes as arguments a module and a method name, which it introspects and calls. The module is always vim_util, and the thing which it calls is not a vSphere api, despite its name. The VMwareAPISession object does not encapsulate a VMware API session. In fact, the session is not strongly represented anywhere, despite being critical. Proposed change =============== Vim and PBM are accessed through new Vim and PBM classes:: vim = Vim(protocol, host, port, path, username, password, max_retry_duration, max_sleep_time) pbm = PBM(...as Vim...) These new classes would have a common base class which implemented all common functionality, which is almost everything described in this blueprint. N.B. I'm currently undecided on session sharing between vim and pbm. The current implementation shares a cookie between the two. It's not clear to me exactly why we do this. If we continued sharing a session then PBM would take Vim as an argument instead of username and password. Discuss. Calling a remote API is done through a proxy object, which is really just syntactic sugar round a call() method:: results = vim.api.RetrievePropertiesEx(pc, specSet=specs, options=options) This is a bare interface which does no session management. It raises any exceptions which occur without retrying. Session management is done through one of two interfaces, depending on the usage requirements. When the requirement is simply to make a single API call in a valid session and retry automatically on failure:: results = vim.auto.RetrievePropertiesEx(pc, specSet=specs, options=options) Sometimes a 'session transaction' is required. This is a block of code which must be re-executed in its entirety if any session-related failure occurs. This is implemented through the use of a transaction object:: t = vim.session_transaction() while t.retry(): with t: foo = vim.api.Foo() vim.api.Bar(foo) Note that the bare interface is used within the transaction. Many api calls take complex objects as arguments. These are currently created by directly using the suds objects factory. I propose a wrapper round this with some additional syntactic sugar:: pfs = vim.create_object('PropertyFilterSpec', { 'objectSet': [vim.create_object('ObjectSpec', { 'obj': task })], 'propSet': [vim.create_object('PropertySpec', { 'pathSet': ['info'], 'type': 'Task' })] }) As part of a general code cleanup, I would also move all vim_util functions into the vim object. I have additional proposals for: * Caching * Better interface to RetrievePropertiesEx * Use of WaitForUpdatesEx * Implement task waiting with WaitForUpdatesEx * Deprecate get_objects() I will deal with them separately. Alternatives ------------ It remains an open question whether we should stick with suds or move to pyVmomi. If I were to implement this today I would use suds as it is already a requirement, it is mature and well-known. However, pyVmomi has a much nicer syntax and has been recently open sourced. Assuming it matures into a stable project, we should consider moving to it. The structure of this blueprint would remain unchanged if we moved to pyVmomi. Specifically we would still require transaction handling, as pyVmomi doesn't cover this. Impact on Existing APIs ----------------------- This blueprint describes a replacement API, not an evolution. Moving to it would require a large amount of mechanical change. The old API could be implemented using the new API if required, and both could live in parallel. Ideally though, a project would implement the new API in its entirety in one hit. Security impact --------------- This change continues to require a vSphere username and password. It does not change their usage in any way which impacts security. Performance Impact ------------------ This code would be called extensive by vmware drivers. I don't anticipate any significant performance difference between the new and old versions. Configuration Impact -------------------- max_retry_duration: Total length of time, in seconds, after which session failure retries will stop and a failure will be returned. Default: no limit. max_sleep_time: Retry will use incremental backoff. The maximum length of time, in seconds, between reconnection attempts. Default: 60. Developer Impact ---------------- Using the new api would require a rewrite of all code which touched it. This is the preferred option. As the change would be mechanical, this should be achievable. If that were unpalatable, we could provide an implementation of the old api which could be used in parallel. Implementation ============== Assignee(s) ----------- Primary assignee: mbooth-9 Other contributors: None Milestones ---------- Juno Work Items ---------- * Write new API * Implement in Glance * Implement in other projects, including Nova Documentation Impact ==================== There should be no user-visible impact of this change (other than squashed bugs and improved reliability). Dependencies ============ None pyVmomi under discussion. References ========== None .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,213,0
openstack%2Ftempest~master~Ic331e47ffa0512179429176579f1e4a6caa82dfc,openstack/tempest,master,Ic331e47ffa0512179429176579f1e4a6caa82dfc,Adjust stress test documentation,MERGED,2014-07-17 08:43:16.000000000,2014-07-17 14:03:16.000000000,2014-07-17 14:03:15.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-17 08:43:16.000000000', 'files': ['tempest/README.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a58e851bd3aa6ddc3d5ba0e7cac3db1ed79b0fa2', 'message': 'Adjust stress test documentation\n\nBe more concrete about the stress test framework capabilities.\n\nChange-Id: Ic331e47ffa0512179429176579f1e4a6caa82dfc\n'}]",0,107592,a58e851bd3aa6ddc3d5ba0e7cac3db1ed79b0fa2,9,4,1,7872,,,0,"Adjust stress test documentation

Be more concrete about the stress test framework capabilities.

Change-Id: Ic331e47ffa0512179429176579f1e4a6caa82dfc
",git fetch https://review.opendev.org/openstack/tempest refs/changes/92/107592/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/README.rst'],1,a58e851bd3aa6ddc3d5ba0e7cac3db1ed79b0fa2,fix_stress_docu,Stress tests are designed to stress an OpenStack environment by running a high workload against it and seeing what breaks. The stress test framework runs several test jobs in parallel and can run any existing test in Tempest as a stress job.,"Stress tests are designed to stress an OpenStack environment by running a high workload against it and seeing what breaks. Tools may be provided to help detect breaks (stack traces in the logs). TODO: old stress tests deleted, new_stress that david is working on moves into here. ",4,7
openstack%2Ffuel-web~master~I9754d674d4289c0dc0c430e465810ef7d15d47b1,openstack/fuel-web,master,I9754d674d4289c0dc0c430e465810ef7d15d47b1,Fixes setting visibility,MERGED,2014-07-17 10:09:35.000000000,2014-07-17 13:58:18.000000000,2014-07-17 13:58:18.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-07-17 10:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/558a8ccd2a92a64367ff5d5c71bb0cf9742844db', 'message': 'Fixes setting visibility\n\nCloses-Bug:#1343160\n\nChange-Id: I9754d674d4289c0dc0c430e465810ef7d15d47b1\n'}, {'number': 2, 'created': '2014-07-17 10:14:17.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/settings_tab.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d57c74973c97bc82a39df3fef33af81352ee9cb7', 'message': 'Fixes setting visibility\n\nCloses-Bug:#1343160\n\nChange-Id: I9754d674d4289c0dc0c430e465810ef7d15d47b1\n'}]",0,107625,d57c74973c97bc82a39df3fef33af81352ee9cb7,16,5,2,8766,,,0,"Fixes setting visibility

Closes-Bug:#1343160

Change-Id: I9754d674d4289c0dc0c430e465810ef7d15d47b1
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/25/107625/2 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/cluster_page_tabs/settings_tab.js'],1,558a8ccd2a92a64367ff5d5c71bb0cf9742844db,bug/1343160," observe: [settingPath + '.value', settingPath + '.visible'], onGet: function(value) { return value[0]; }, onSet: function(value) { return [value, setting.visible]; }, $el.parents('.setting-container').toggleClass('hide', !isVisible); observe: [settingPath + '.visible', settingPath + '.values'], onGet: function(value) { return value[1]; }, visible: function(value) { return setting.visible && value[index].visible;"," observe: settingPath + '.value', $el.parents('.parameter-box:first').toggleClass('hide', !isVisible); observe: settingPath + '.visible', visible: function() { return setting.visible && option.visible;",14,5
openstack%2Fneutron~master~I31c9d210ca77284b91426877333bd51bf2909ef0,openstack/neutron,master,I31c9d210ca77284b91426877333bd51bf2909ef0,Fix pep8 violations,ABANDONED,2014-07-11 00:53:24.000000000,2014-07-17 13:55:48.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9885}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-11 00:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8c5dff28044f2eb5e06a15cc6c48560c166548f7', 'message': ""Fix pep8 violations\n\nThese seem to have been introduced by:\n\ncbd89e75d34c048c15c52dc828b1df7443c540d6\n\nLocally I get\n\nF401 '...' imported but unused\n\nIt turns out these are no longer needed, but I\ndon't understand why the pep8 gate did not complain;\na version mismatch somewhere?\n\nChange-Id: I31c9d210ca77284b91426877333bd51bf2909ef0\n""}, {'number': 2, 'created': '2014-07-14 18:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88a0f406832ccd3261e79e9c9a11aacbdb3f7459', 'message': ""Fix pep8 violations\n\nThese seem to have been introduced by:\n\ncbd89e75d34c048c15c52dc828b1df7443c540d6\n\nLocally I get\n\nF401 '...' imported but unused\n\nIt turns out these are no longer needed, but I\ndon't understand why the pep8 gate did not complain;\na version mismatch somewhere?\n\nChange-Id: I31c9d210ca77284b91426877333bd51bf2909ef0\n""}, {'number': 3, 'created': '2014-07-17 00:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fdb9c2f3c58f0c097b02fe451901a1bc01f8fd72', 'message': ""Fix pep8 violations\n\nThese seem to have been introduced by:\n\ncbd89e75d34c048c15c52dc828b1df7443c540d6\n\nLocally I get\n\nF401 '...' imported but unused\n\nIt turns out these are no longer needed, but I\ndon't understand why the pep8 gate did not complain;\na version mismatch somewhere?\n\nChange-Id: I31c9d210ca77284b91426877333bd51bf2909ef0\n""}]",0,106220,fdb9c2f3c58f0c097b02fe451901a1bc01f8fd72,66,24,3,748,,,0,"Fix pep8 violations

These seem to have been introduced by:

cbd89e75d34c048c15c52dc828b1df7443c540d6

Locally I get

F401 '...' imported but unused

It turns out these are no longer needed, but I
don't understand why the pep8 gate did not complain;
a version mismatch somewhere?

Change-Id: I31c9d210ca77284b91426877333bd51bf2909ef0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/106220/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/db_base_plugin_v2.py', 'neutron/db/common_db_mixin.py']",2,8c5dff28044f2eb5e06a15cc6c48560c166548f7,pep8-fixes,,from oslo.config import cfgfrom neutron.plugins.common import constants as service_constants,0,4
openstack%2Ffuel-library~master~I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff,openstack/fuel-library,master,I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff,Implemantation of VMware NSX integration,MERGED,2014-04-09 13:43:16.000000000,2014-07-17 13:27:18.000000000,2014-07-17 13:27:18.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7185}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11427}]","[{'number': 1, 'created': '2014-04-09 13:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/60e84ba77975d15fed0291ff548b9a648eea018a', 'message': 'Implemantation of NSX integration\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 2, 'created': '2014-04-11 11:08:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1e1c1603e082e8f025ba6a932e4da5430f4e824f', 'message': 'Implemantation of NSX integration\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 3, 'created': '2014-04-14 14:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b1e542fa0529a360a64cd63c1631cfc8678be532', 'message': 'Implemantation of NSX integration\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 4, 'created': '2014-06-17 11:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9a4c603a44b1cc6ae6c0d5e3947f6d022c5df8e0', 'message': 'Implemantation of VMware NSX integration\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 5, 'created': '2014-06-25 11:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8323f14e558723562b332b195ddc5bfd010dc307', 'message': 'Implemantation of VMware NSX integration\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 6, 'created': '2014-06-26 08:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7a6a95e421139453c1072bdd8e49c8854a5124a0', 'message': 'Implemantation of VMware NSX integration\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 7, 'created': '2014-06-26 13:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3ba82354ec1a7cd52fb38bc7305a3d5f37b7bd5b', 'message': 'Implemantation of VMware NSX integration\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 8, 'created': '2014-06-26 21:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0c62ae71979f785257005adfbc5704cce7fbceea', 'message': 'Implemantation of VMware NSX integration\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 9, 'created': '2014-06-27 13:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/92b060a498cecbd73ca3075cc9a1271b2014e5c1', 'message': 'Implemantation of VMware NSX integration\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 10, 'created': '2014-07-07 16:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/69e0c37535550b62bbac96e6130570919a330bf7', 'message': 'Implemantation of VMware NSX integration\n\nAdded new puppet module for Neutron NSX plugin integration.\nSome hacks added.\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 11, 'created': '2014-07-08 07:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5ba0647d7db5be0792bb328b6cc9ccf842d53fd6', 'message': 'Implemantation of VMware NSX integration\n\nAdded new puppet module for Neutron NSX plugin integration.\n* Separate classes for compute/controller\n* Some additional paramenters required from Nailgun\n* Some strange hacks with Anchors\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 12, 'created': '2014-07-08 11:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f4ed1135014f8d00568e2970bb390933ad4147e7', 'message': 'Implemantation of VMware NSX integration\n\nAdded new puppet module for Neutron NSX plugin integration.\n* Separate classes for compute/controller\n* Some additional paramenters required from Nailgun\n* Hide some strange hacks with Anchors\n* Add rdpkg and rrpm package managers in order to download\n  packages from remote web-server using mask for a package name.\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 13, 'created': '2014-07-08 14:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/598ba97fe243599179b685041ac75454220a96ba', 'message': 'Implemantation of VMware NSX integration\n\nAdded new puppet module for Neutron NSX plugin integration.\n* Separate classes for compute/controller\n* Some additional paramenters required from Nailgun\n* Hide some strange hacks with Anchors\n* Add rdpkg and rrpm package managers in order to download\n  packages from remote web-server using mask for a package name.\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 14, 'created': '2014-07-08 17:04:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2621cc21901796ff5f43100ae056f682fa78d4b0', 'message': 'Implemantation of VMware NSX integration\n\nAdded new puppet module for Neutron NSX plugin integration.\n* Separate classes for compute/controller\n* Some additional paramenters required from Nailgun\n* Hide some strange hacks with Anchors\n* Add rdpkg and rrpm package managers in order to download\n  packages from remote web-server using mask for a package name.\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 15, 'created': '2014-07-09 08:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2ffdf8b3051437df62c192847b182a37156999b3', 'message': 'Implemantation of VMware NSX integration\n\nAdded new puppet module for Neutron NSX plugin integration.\n* Separate classes for compute/controller\n* Some additional paramenters required from Nailgun\n* Hide some strange hacks with Anchors\n* Add rdpkg and rrpm package managers in order to download\n  packages from remote web-server using mask for a package name.\n* Fix sanitaze_neutron_config to merge boolean values.\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 16, 'created': '2014-07-09 18:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/769ec0f40b7cd698a61efb5b61cef4898540052e', 'message': 'Implemantation of VMware NSX integration\n\nAdded new puppet module for Neutron NSX plugin integration.\n* Separate classes for compute/controller\n* Some additional paramenters required from Nailgun\n* Hide some strange hacks with Anchors\n* Add rdpkg and rrpm package managers in order to download\n  packages from remote web-server using mask for a package name.\n* Fix sanitaze_neutron_config to merge boolean values.\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 17, 'created': '2014-07-09 18:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/db92476cb634e620ce7932d80311fe81e69b9ebc', 'message': 'Implemantation of VMware NSX integration\n\nAdded new puppet module for Neutron NSX plugin integration.\n* Separate classes for compute/controller\n* Some additional paramenters required from Nailgun\n* Hide some strange hacks with Anchors\n* Add rdpkg and rrpm package managers in order to download\n  packages from remote web-server using mask for a package name.\n* Fix sanitaze_neutron_config to merge boolean values.\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 18, 'created': '2014-07-14 13:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5b990e0c4ca2f83995b12fd0e47a90bc8b4172f7', 'message': 'Implemantation of VMware NSX integration\n\nAdded new puppet module for Neutron NSX plugin integration.\n* Separate classes for compute/controller\n* Some additional paramenters required from Nailgun\n* Hide some strange hacks with Anchors\n* Add rdpkg and rrpm package managers in order to download\n  packages from remote web-server using mask for a package name.\n* Fix sanitaze_neutron_config to merge boolean values.\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}, {'number': 19, 'created': '2014-07-17 10:48:46.000000000', 'files': ['deployment/puppet/plugin_neutronnsx/lib/puppet/provider/l2_nsx_bridge/ovs.rb', 'deployment/puppet/plugin_neutronnsx/lib/puppet/provider/neutron_plugin_vmware/ini_setting.rb', 'deployment/puppet/l23network/manifests/l2.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/plugin_neutronnsx/manifests/alter_neutron_server.pp', 'deployment/puppet/plugin_neutronnsx/spec/unit/puppet/provider/package/rdpkg_spec.rb', 'deployment/puppet/plugin_neutronnsx/lib/puppet/provider/package/rrpm.rb', 'deployment/puppet/plugin_neutronnsx/manifests/init.pp', 'deployment/puppet/plugin_neutronnsx/Gemfile', 'deployment/puppet/plugin_neutronnsx/manifests/params.pp', 'deployment/puppet/plugin_neutronnsx/spec/unit/puppet/provider/l2_ovs_nsx/ovs_spec.rb', 'deployment/puppet/plugin_neutronnsx/manifests/stop_neutron_agents.pp', 'deployment/puppet/plugin_neutronnsx/lib/puppet/provider/l2_ovs_nsx/ovs.rb', 'deployment/puppet/neutron/lib/puppet/parser/functions/sanitize_neutron_config.rb', 'deployment/puppet/plugin_neutronnsx/lib/puppet/type/l2_ovs_nsx.rb', 'deployment/puppet/plugin_neutronnsx/manifests/bridges.pp', 'deployment/puppet/plugin_neutronnsx/Rakefile', 'deployment/puppet/plugin_neutronnsx/lib/puppet/parser/functions/get_connector_address.rb', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp', 'deployment/puppet/plugin_neutronnsx/manifests/install_ovs.pp', 'deployment/puppet/plugin_neutronnsx/spec/spec_helper.rb', 'deployment/puppet/plugin_neutronnsx/lib/puppet/type/neutron_plugin_vmware.rb', 'deployment/puppet/plugin_neutronnsx/lib/puppet/provider/package/rdpkg.rb', 'deployment/puppet/plugin_neutronnsx/lib/puppet/type/l2_nsx_bridge.rb', 'deployment/puppet/plugin_neutronnsx/spec/unit/puppet/functions/get_connector_address_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/74c28c179eee393c6cfef4d4cda9ce1b35bcbb81', 'message': 'Implemantation of VMware NSX integration\n\nAdded new puppet module for Neutron NSX plugin integration.\n* Separate classes for compute/controller\n* Some additional paramenters required from Nailgun\n* Hide some strange hacks with Anchors\n* Add rdpkg and rrpm package managers in order to download\n  packages from remote web-server using mask for a package name.\n* Fix sanitaze_neutron_config to merge boolean values.\n\nChange-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff\nImplements: blueprint neutron-nsx-plugin-integration\n'}]",94,86329,74c28c179eee393c6cfef4d4cda9ce1b35bcbb81,138,12,19,7185,,,0,"Implemantation of VMware NSX integration

Added new puppet module for Neutron NSX plugin integration.
* Separate classes for compute/controller
* Some additional paramenters required from Nailgun
* Hide some strange hacks with Anchors
* Add rdpkg and rrpm package managers in order to download
  packages from remote web-server using mask for a package name.
* Fix sanitaze_neutron_config to merge boolean values.

Change-Id: I94e7bf2fccc289d0d52fc3d3018db268ec4f7fff
Implements: blueprint neutron-nsx-plugin-integration
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/29/86329/16 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/plugin_neutronnsx/lib/puppet/provider/neutron_plugin_nicira/ini_setting.rb', 'deployment/puppet/plugin_neutronnsx/spec/unit/puppet/provider/l2_ovs_nicira/ovs_spec.rb', 'deployment/puppet/plugin_neutronnsx/manifests/params.pp', 'deployment/puppet/plugin_neutronnsx/lib/puppet/type/l2_nicira_bridge.rb', 'deployment/puppet/galera/files/ocf/mysql-wss', 'deployment/puppet/plugin_neutronnsx/Rakefile', 'deployment/puppet/plugin_neutronnsx/lib/puppet/provider/l2_nicira_bridge/ovs.rb', 'deployment/puppet/l23network/manifests/l2.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/plugin_neutronnsx/lib/puppet/parser/functions/get_connector_address.rb', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp', 'deployment/puppet/plugin_neutronnsx/manifests/install_ovs.pp', 'deployment/puppet/plugin_neutronnsx/spec/spec_helper.rb', 'deployment/puppet/plugin_neutronnsx/lib/puppet/provider/l2_ovs_nicira/ovs.rb', 'deployment/puppet/plugin_neutronnsx/lib/puppet/type/neutron_plugin_nicira.rb', 'deployment/puppet/plugin_neutronnsx/lib/puppet/provider/package/rdpkg.rb', 'deployment/puppet/plugin_neutronnsx/lib/puppet/type/l2_ovs_nicira.rb', 'deployment/puppet/plugin_neutronnsx/manifests/init.pp', 'deployment/puppet/plugin_neutronnsx/manifests/nicira.pp', 'deployment/puppet/plugin_neutronnsx/Gemfile', 'deployment/puppet/plugin_neutronnsx/spec/unit/puppet/functions/get_connector_address_spec.rb']",21,60e84ba77975d15fed0291ff548b9a648eea018a,bp/neutron-nsx-plugin-integration,"require 'spec_helper' describe Puppet::Parser::Functions.function(:get_connector_address) do let(:scope) { PuppetlabsSpec::PuppetInternals.scope } describe ""when calling from puppet"" do it ""should not compile without parameters"" do Puppet[:code] = 'get_connector_address()' expect { scope.compiler.compile }.to raise_error(Puppet::ParseError,/Wrong number of arguments/) end end describe ""when calling on the scope instance"" do let :fuel_settings do { 'fqdn' => 'node-42.domain.tld', 'nodes' => [ { 'storage_netmask' => '255.255.255.0', 'uid' => '41', 'public_address' => '172.18.198.140', 'internal_netmask' => '255.255.255.0', 'fqdn' => 'node-41.domain.tld', 'role' => 'controller', 'public_netmask' => '255.255.255.224', 'internal_address' => '192.168.0.2', 'storage_address' => '192.168.1.2', 'name' => 'node-41', },{ 'storage_netmask' => '255.255.255.0', 'uid' => '42', 'public_address' => '172.18.198.141', 'internal_netmask' => '255.255.255.0', 'fqdn' => 'node-42.domain.tld', 'role' => 'compute', 'public_netmask' => '255.255.255.224', 'internal_address' => '192.168.0.3', 'storage_address' => '192.168.1.3', 'name' => 'node-42', } ] } end it ""should return connector addres"" do fuel_settings['nsx_plugin'] = {'nvp_controllers' => '192.168.0.100,192.168.0.101'} connector_addr = scope.function_get_connector_address([fuel_settings]) connector_addr.should == '192.168.0.3' end it ""should return pubblc for non-Fuel networks"" do fuel_settings['nsx_plugin'] = {'nvp_controllers' => '10.20.0.1,10.20.0.2'} scope.function_get_connector_address([fuel_settings]).should == '172.18.198.141' end it ""should raise if fqdn not found"" do fuel_settings['nsx_plugin'] = {'nvp_controllers' => '192.168.0.100,192.168.0.101'} fuel_settings['fqdn'] = 'node-1.domain.tld' expect { scope.function_get_connector_address([fuel_settings]) }.to raise_error(Puppet::ParseError, /not found/) end end end ",,675,22
openstack%2Fsahara~master~I8f742c472a20650f8c7f2a01bcaefb6eff232123,openstack/sahara,master,I8f742c472a20650f8c7f2a01bcaefb6eff232123,Bump Hadoop to 2.4.1 version,MERGED,2014-07-16 10:13:31.000000000,2014-07-17 13:10:10.000000000,2014-07-17 13:10:09.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-16 10:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a456441bb7618aa9e25006427c754ae121dad105', 'message': 'Bump Hadoop to 2.4.1 version\n\nChange-Id: I8f742c472a20650f8c7f2a01bcaefb6eff232123\n'}, {'number': 2, 'created': '2014-07-16 16:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4d607fc09f7edf164b566397f9a855ae2400f7f6', 'message': 'Bump Hadoop to 2.4.1 version\n\nChange-Id: I8f742c472a20650f8c7f2a01bcaefb6eff232123\n'}, {'number': 3, 'created': '2014-07-17 09:17:02.000000000', 'files': ['sahara/plugins/vanilla/v2_4_1/__init__.py', 'sahara/plugins/vanilla/v2_4_1/resources/hdfs-default.xml', 'sahara/plugins/vanilla/v2_4_1/config_helper.py', 'sahara/plugins/vanilla/v2_4_1/resources/README.rst', 'sahara/plugins/vanilla/v2_4_1/resources/mapred-default.xml', 'sahara/plugins/vanilla/v2_4_1/resources/core-default.xml', 'sahara/plugins/vanilla/v2_4_1/resources/oozie-default.xml', 'sahara/plugins/vanilla/v2_4_1/versionhandler.py', 'MANIFEST.in', 'sahara/plugins/vanilla/v2_4_1/resources/yarn-default.xml'], 'web_link': 'https://opendev.org/openstack/sahara/commit/79c0961fe72c04781a2dbbfbf1614e7153846829', 'message': 'Bump Hadoop to 2.4.1 version\n\nChange-Id: I8f742c472a20650f8c7f2a01bcaefb6eff232123\n'}]",0,107296,79c0961fe72c04781a2dbbfbf1614e7153846829,24,6,3,7710,,,0,"Bump Hadoop to 2.4.1 version

Change-Id: I8f742c472a20650f8c7f2a01bcaefb6eff232123
",git fetch https://review.opendev.org/openstack/sahara refs/changes/96/107296/3 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/vanilla/v2_4_1/__init__.py', 'sahara/plugins/vanilla/v2_4_1/resources/hdfs-default.xml', 'sahara/plugins/vanilla/v2_4_1/config_helper.py', 'sahara/plugins/vanilla/v2_4_1/resources/README.rst', 'sahara/plugins/vanilla/v2_4_1/resources/mapred-default.xml', 'sahara/plugins/vanilla/v2_4_1/resources/core-default.xml', 'sahara/plugins/vanilla/v2_4_1/resources/oozie-default.xml', 'sahara/plugins/vanilla/v2_4_1/versionhandler.py', 'MANIFEST.in', 'sahara/plugins/vanilla/v2_4_1/resources/yarn-default.xml']",10,a456441bb7618aa9e25006427c754ae121dad105,hadoop-2-4-1, <value>false</value> <value>${hadoop.tmp.dir}/yarn/timeline</value> <value>${hadoop.tmp.dir}/yarn/timeline/generic-history</value>, <value>true</value> <value>${yarn.log.dir}/timeline</value> <value>${hadoop.log.dir}/yarn/system/history</value>,15,15
openstack%2Fsahara~master~I90126132ed195d19cd06c3287859da46675100d8,openstack/sahara,master,I90126132ed195d19cd06c3287859da46675100d8,Imported Translations from Transifex,MERGED,2014-07-17 06:10:49.000000000,2014-07-17 13:10:03.000000000,2014-07-17 13:10:02.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 7125}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-07-17 06:10:49.000000000', 'files': ['sahara/locale/en_GB/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara-log-info.pot', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara-log-error.pot', 'sahara/locale/vi_VN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/ja/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/sahara-log-warning.pot', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/ko_KR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-info.po'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7f127eef30765cc918ab5f8b8d4a0a49651568ce', 'message': 'Imported Translations from Transifex\n\nChange-Id: I90126132ed195d19cd06c3287859da46675100d8\n'}]",0,107568,7f127eef30765cc918ab5f8b8d4a0a49651568ce,11,4,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I90126132ed195d19cd06c3287859da46675100d8
",git fetch https://review.opendev.org/openstack/sahara refs/changes/68/107568/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/locale/en_GB/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara-log-info.pot', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara-log-error.pot', 'sahara/locale/vi_VN/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/ja/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/sahara-log-warning.pot', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/ko_KR/LC_MESSAGES/sahara-log-error.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara.pot', 'sahara/locale/fr/LC_MESSAGES/sahara-log-warning.po', 'sahara/locale/de/LC_MESSAGES/sahara-log-info.po']",25,7f127eef30765cc918ab5f8b8d4a0a49651568ce,transifex/translations,"""POT-Creation-Date: 2014-07-17 06:10+0000\n"" ""PO-Revision-Date: 2014-07-16 14:42+0000\n""#: sahara/openstack/common/lockutils.py:82 #, python-format msgid ""Created lock path: %s"" msgstr ""Sperrpfad erzeugt: %s"" #: sahara/openstack/common/lockutils.py:251 #, python-format msgid ""Failed to remove file %(file)s"" msgstr ""Löschen der Datei %(file)s fehlgeschlagen"" ","""POT-Creation-Date: 2014-06-09 06:01+0000\n"" ""PO-Revision-Date: 2014-06-08 15:32+0000\n""",339,437
openstack%2Fheat~master~I7320e3a95895b894cc53ebb77ebb220482f990c1,openstack/heat,master,I7320e3a95895b894cc53ebb77ebb220482f990c1,Expose recent docker features in the resource,MERGED,2014-07-10 17:46:35.000000000,2014-07-17 12:58:03.000000000,2014-07-17 12:58:01.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 4715}, {'_account_id': 7193}, {'_account_id': 7385}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-10 17:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a506fc39907926aa6fb8580f30c826300bacd62b', 'message': 'Expose recent docker features in the resource\n\nThis adds the name, port_bindings and links properties to the docker\ncontainer resource which are passed to container creation and start.\nThis also removes properties which were never implemented.\n\nChange-Id: I7320e3a95895b894cc53ebb77ebb220482f990c1\n'}, {'number': 2, 'created': '2014-07-17 05:55:06.000000000', 'files': ['contrib/docker/docker/tests/test_docker_container.py', 'contrib/docker/docker/tests/fake_docker_client.py', 'contrib/docker/docker/resources/docker_container.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6906fd12b6d14cf9b0317cd68c5316da75858f94', 'message': 'Expose recent docker features in the resource\n\nThis adds the name, port_bindings and links properties to the docker\ncontainer resource which are passed to container creation and start.\nThis also removes properties which were never implemented.\n\nChange-Id: I7320e3a95895b894cc53ebb77ebb220482f990c1\n'}]",1,106120,6906fd12b6d14cf9b0317cd68c5316da75858f94,25,6,2,7385,,,0,"Expose recent docker features in the resource

This adds the name, port_bindings and links properties to the docker
container resource which are passed to container creation and start.
This also removes properties which were never implemented.

Change-Id: I7320e3a95895b894cc53ebb77ebb220482f990c1
",git fetch https://review.opendev.org/openstack/heat refs/changes/20/106120/2 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/docker/docker/tests/test_docker_container.py', 'contrib/docker/docker/tests/fake_docker_client.py', 'contrib/docker/docker/resources/docker_container.py']",3,a506fc39907926aa6fb8580f30c826300bacd62b,docker-features," DOCKER_ENDPOINT, HOSTNAME, USER, MEMORY, PORT_SPECS, PRIVILEGED, TTY, OPEN_STDIN, STDIN_ONCE, ENV, CMD, DNS, IMAGE, VOLUMES, VOLUMES_FROM, PORT_BINDINGS, LINKS, NAME, 'docker_endpoint', 'hostname', 'user', 'memory', 'port_specs', 'privileged', 'tty', 'open_stdin', 'stdin_once', 'env', 'cmd', 'dns', 'image', 'volumes', 'volumes_from', 'port_bindings', 'links', 'name' 'will be used).'), _('Hostname of the container.'), _('Username or UID.'), _('Memory limit (Bytes).'), _('TCP/UDP ports mapping.'), PORT_BINDINGS: properties.Schema( properties.Schema.MAP, _('TCP/UDP ports bindings'), ), LINKS: properties.Schema( properties.Schema.MAP, _('Links to other containers.'), ), NAME: properties.Schema( properties.Schema.STRING, _('Name of the container.'), ), _('Enable extended privileges.'), _('Allocate a pseudo-tty.'), _('Open stdin.'), _('If true, close stdin after the 1 attached client disconnects.'), _('Set environment variables.'), _('Command to run after spawning the container.'), _('Set custom dns servers.'), _('Image name.') _('Create a bind mount.'), _('Mount all specified volumes.'), _('Container info.') _('Container network info.') _('Container ip address.') _('Container ip gateway.') _('Container TCP ports.') _('Container UDP ports.') _('Container logs.') _('Container first logs line.') _('Container last logs line.') 'name': self.properties[self.NAME] client.pull(self.properties[self.IMAGE]) if self.properties[self.PORT_BINDINGS]: kwargs['port_bindings'] = self.properties[self.PORT_BINDINGS] if self.properties[self.LINKS]: kwargs['links'] = self.properties[self.LINKS]"," DOCKER_ENDPOINT, HOSTNAME, USER, MEMORY, ATTACH_STDIN, ATTACH_STDOUT, ATTACH_STDERR, PORT_SPECS, PRIVILEGED, TTY, OPEN_STDIN, STDIN_ONCE, ENV, CMD, DNS, IMAGE, VOLUMES, VOLUMES_FROM, 'docker_endpoint', 'hostname', 'user', 'memory', 'attach_stdin', 'attach_stdout', 'attach_stderr', 'port_specs', 'privileged', 'tty', 'open_stdin', 'stdin_once', 'env', 'cmd', 'dns', 'image', 'volumes', 'volumes_from', 'will be used)'), _('Hostname of the container'), _('Username or UID'), _('Memory limit (Bytes)'), ATTACH_STDIN: properties.Schema( properties.Schema.BOOLEAN, _('Attach to the process\' standard input'), default=False ), ATTACH_STDOUT: properties.Schema( properties.Schema.BOOLEAN, _('Attach to the process\' standard output'), default=True ), ATTACH_STDERR: properties.Schema( properties.Schema.BOOLEAN, _('Attach to the process\' standard error'), default=True ), _('TCP/UDP ports mapping'), _('Enable extended privileges'), _('Allocate a pseudo-tty'), _('Open stdin'), _('If true, close stdin after the 1 attached client disconnects'), _('Set environment variables'), default=None _('Command to run after spawning the container'), _('Set custom dns servers'), default=None _('Image name') _('Create a bind mount'), _('Mount all specified volumes'), _('Container info') _('Container network info') _('Container ip address') _('Container ip gateway') _('Container TCP ports') _('Container UDP ports') _('Container logs') _('Container first logs line') _('Container last logs line')",103,55
openstack%2Fheat~master~I6f4666728c5ecadb1d9d081fb825a77cd598fd47,openstack/heat,master,I6f4666728c5ecadb1d9d081fb825a77cd598fd47,heat_keystoneclient add get_user_token,MERGED,2014-06-26 16:56:10.000000000,2014-07-17 12:47:13.000000000,2014-07-17 12:47:12.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6498}, {'_account_id': 7193}, {'_account_id': 7385}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-26 16:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4ec8c9b94ef02e04fcc629ff4e2abb2c4817b416', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 2, 'created': '2014-07-02 16:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8b9c8bb333be2dae1818480ec739c43a25fbf784', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 3, 'created': '2014-07-03 13:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f071cd69da790a25aa131ac627ccd0db812f865f', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 4, 'created': '2014-07-03 15:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f0ff413cd9e3e1d13b26dbc4af129a252d073ea1', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 5, 'created': '2014-07-08 09:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3c4d365e0d51671c57c31c6c4314aae25a2dc05a', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 6, 'created': '2014-07-08 14:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d68e1f86a0461335fa0a92f29a6842729e4cc8a9', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 7, 'created': '2014-07-08 15:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6e27f3237b99feb421cf77fd4ab60356ee7ae2ef', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 8, 'created': '2014-07-08 18:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eda617ac1b89bf8c6c3de3eca4bcb41c39da94fa', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 9, 'created': '2014-07-10 16:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7bf6e48afd8ca3d4147d0d5108909785891d65f7', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 10, 'created': '2014-07-11 16:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5cc9860e88bf0790512616e1588b2c120745bf05', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 11, 'created': '2014-07-14 17:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ff3dccf9c636dd98fe20b0b3da4109a9120bbfc3', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 12, 'created': '2014-07-15 13:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8237d3a0a5066026ac7d3613cfb3779f9b038647', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 13, 'created': '2014-07-16 12:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/184e703efe6d58af534cd50028a12fec88feb846', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}, {'number': 14, 'created': '2014-07-16 18:11:27.000000000', 'files': ['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/1e72de9e886c5c0c619a68041080391006677cab', 'message': 'heat_keystoneclient add get_user_token\n\nAdd a function which takes a stack domain username/password and\nreturns a token - this is for ""one time"" use, e.g for callback\nsignals to wait conditions via the native API.\n\nblueprint: native-waitcondition\n\nChange-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47\n'}]",13,102885,1e72de9e886c5c0c619a68041080391006677cab,64,7,14,4328,,,0,"heat_keystoneclient add get_user_token

Add a function which takes a stack domain username/password and
returns a token - this is for ""one time"" use, e.g for callback
signals to wait conditions via the native API.

blueprint: native-waitcondition

Change-Id: I6f4666728c5ecadb1d9d081fb825a77cd598fd47
",git fetch https://review.opendev.org/openstack/heat refs/changes/85/102885/14 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py']",2,4ec8c9b94ef02e04fcc629ff4e2abb2c4817b416,bp/native-waitcondition6,"import moxfrom keystoneclient.auth.identity import v3 as ks_auth_v3from keystoneclient import session as ks_session def test_stack_domain_user_token(self): """"""Test stack_domain_user_token function."""""" self.m.StubOutWithMock(ks_auth_v3, 'Password') ks_auth_v3.Password(auth_url='http://server.test:5000/v3', username='duser', password='apassw', project_id='aproject', user_domain_id='adomain123').AndReturn('dummyauth') dummysession = self.m.CreateMockAnything() dummyresp = self.m.CreateMockAnything() dummyresp.headers = {'X-Subject-Token': 'dummytoken'} dummysession.post('http://server.test:5000/v3/auth/tokens?nocatalog', authenticated=False, headers={'Accept': 'application/json'}, json=mox.IgnoreArg()).AndReturn(dummyresp) self.m.StubOutWithMock(ks_session, 'Session') ks_session.Session(auth='dummyauth').AndReturn(dummysession) self.m.ReplayAll() ctx = utils.dummy_context() ctx.trust_id = None heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) token = heat_ks_client.stack_domain_user_token( username='duser', project_id='aproject', password='apassw') self.assertEqual('dummytoken', token) def test_stack_domain_user_token_err_nodomain(self): """"""Test stack_domain_user_token error path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) self.assertRaises(exception.Error, heat_ks_client.stack_domain_user_token, username='user', project_id='aproject', password='password') ",,76,0
openstack%2Ffuel-web~master~Id56c6f547840eccddadda76835773e02bc3d4cde,openstack/fuel-web,master,Id56c6f547840eccddadda76835773e02bc3d4cde,Style fix for Network tunnel ip range label,MERGED,2014-07-17 10:01:13.000000000,2014-07-17 12:44:19.000000000,2014-07-17 12:38:03.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8970}, {'_account_id': 8971}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-07-17 10:01:13.000000000', 'files': ['nailgun/static/css/styles.less'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f05bcfc1159436b06357a60d8f6ad6fd2f7c9f7f', 'message': 'Style fix for Network tunnel ip range label\n\nchanged width\n\nChange-Id: Id56c6f547840eccddadda76835773e02bc3d4cde\nCloses-bug: 1343190\n'}]",0,107620,f05bcfc1159436b06357a60d8f6ad6fd2f7c9f7f,13,6,1,9091,,,0,"Style fix for Network tunnel ip range label

changed width

Change-Id: Id56c6f547840eccddadda76835773e02bc3d4cde
Closes-bug: 1343190
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/20/107620/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/css/styles.less'],1,f05bcfc1159436b06357a60d8f6ad6fd2f7c9f7f,bug/1343190, &.mini > div { width: 104px; } , &.mini > div { width: 133px; } ,1,1
openstack%2Fpython-manilaclient~master~Id83f55201ef01a9c3f7ee37406ac6070c4b14c5e,openstack/python-manilaclient,master,Id83f55201ef01a9c3f7ee37406ac6070c4b14c5e,Fix run_tests.sh,MERGED,2014-07-16 06:08:27.000000000,2014-07-17 12:39:59.000000000,2014-07-17 00:55:38.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7173}, {'_account_id': 7534}]","[{'number': 1, 'created': '2014-07-16 06:08:27.000000000', 'files': ['tools/install_venv.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/ab702bcce324686f74c724f105ddb00fc6f01891', 'message': 'Fix run_tests.sh\n\nWith merge of commit:\nhttps://github.com/stackforge/python-manilaclient/commit/ce35f9b847ab21df6f8e8aa6791b3c628cd68a1b\n\nFile run_tests.sh became broken, it tries to use old names of renamed files with dependencies:\ntools/pip-requires → requirements.txt\ntools/test-requires → test-requirements.txt\n\nChange-Id: Id83f55201ef01a9c3f7ee37406ac6070c4b14c5e\nCloses-Bug: #1342538\n'}]",0,107238,ab702bcce324686f74c724f105ddb00fc6f01891,10,4,1,8851,,,0,"Fix run_tests.sh

With merge of commit:
https://github.com/stackforge/python-manilaclient/commit/ce35f9b847ab21df6f8e8aa6791b3c628cd68a1b

File run_tests.sh became broken, it tries to use old names of renamed files with dependencies:
tools/pip-requires → requirements.txt
tools/test-requires → test-requirements.txt

Change-Id: Id83f55201ef01a9c3f7ee37406ac6070c4b14c5e
Closes-Bug: #1342538
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/38/107238/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_venv.py'],1,ab702bcce324686f74c724f105ddb00fc6f01891,master,"PIP_REQUIRES = os.path.join(ROOT, 'requirements.txt') TEST_REQUIRES = os.path.join(ROOT, 'test-requirements.txt')","PIP_REQUIRES = os.path.join(ROOT, 'tools', 'pip-requires') TEST_REQUIRES = os.path.join(ROOT, 'tools', 'test-requires')",2,2
openstack%2Fsolum~master~I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b,openstack/solum,master,I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b,Add execution table to link to mistral,MERGED,2014-06-02 11:32:43.000000000,2014-07-17 12:24:36.000000000,2014-07-17 12:24:35.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 7227}, {'_account_id': 8443}, {'_account_id': 9095}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-06-02 11:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/032037c74910176fe1f1735dd6740b3e105166b6', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 2, 'created': '2014-06-04 11:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4546184c07b65afebc878a3870e49ddd61ce725f', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 3, 'created': '2014-06-05 02:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/c6543321a5970dca24d8f9edb7d8a5331fc19fc8', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 4, 'created': '2014-06-11 12:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/bf6989c423c1809e4b43d1aa0080d72af8f9cc3b', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 5, 'created': '2014-06-12 02:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/41960bb2760a34be93a5975c8484308e8755a194', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 6, 'created': '2014-06-16 13:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/87b6639ae163b25193ee86a534fd979fc7b8e8ce', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 7, 'created': '2014-06-17 02:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/936b5df33da28b31a77843c558db74755b1bd685', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 8, 'created': '2014-06-18 11:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b1a342b8d4a84ef09ba5de5aad16614184e3fafb', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 9, 'created': '2014-06-19 11:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/57e30575c5a2f0868a27503f0c6f6c26115e2f64', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 10, 'created': '2014-06-23 01:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/600e6762a16bdb208768f5c6f835f198e7dfefcc', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 11, 'created': '2014-06-24 11:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/0241f4aab2c1ffecf1d9562e669421ef8df25b62', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 12, 'created': '2014-06-24 11:42:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1fcb3b424f2a16f14385f608e1469e5fccef6dd8', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 13, 'created': '2014-07-01 21:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5dd2fe61484453c5299472198358c5c553ac5e21', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 14, 'created': '2014-07-02 06:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/354722a88e15b2224895e0e524af1006a6802797', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 15, 'created': '2014-07-07 18:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/800c02f5f39953bd5b0fe8c0364eba903f458a9d', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 16, 'created': '2014-07-08 22:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/8e854f185dbb4ae9d545aa30dfea2b6c26ad9343', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 17, 'created': '2014-07-09 01:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1ad0731efbad037dfc828e4018de78d269cd341d', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 18, 'created': '2014-07-09 18:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5d39313372bd7d66081601959c202bf664d628b3', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 19, 'created': '2014-07-09 20:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6f5ab9f3ab29741fa0ab870fd04d6aa7a06445eb', 'message': 'Add execution table to link to mistral\n\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 20, 'created': '2014-07-14 10:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/f75a546ff2e6a2e410e081c85c43580c4c765919', 'message': 'Add execution table to link to mistral\n\nThis is to keep track of the mistral executions that\nare done for solum on each git push. This allows the\nUI to be able to get detailed information on each pipeline\nexection.\n\nhttps://blueprints.launchpad.net/solum/+spec/pipeline\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 21, 'created': '2014-07-15 21:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/c75d357163b681cd6eba1df7a8ff17329f0a2b4b', 'message': 'Add execution table to link to mistral\n\nThis is to keep track of the mistral executions that\nare done for solum on each git push. This allows the\nUI to be able to get detailed information on each pipeline\nexection.\n\nhttps://blueprints.launchpad.net/solum/+spec/pipeline\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 22, 'created': '2014-07-16 10:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b89a8f6f17e53e914f6e7c101ffbdc1350c7eb4b', 'message': 'Add execution table to link to mistral\n\nThis is to keep track of the mistral executions that\nare done for solum on each git push. This allows the\nUI to be able to get detailed information on each pipeline\nexection.\n\nhttps://blueprints.launchpad.net/solum/+spec/pipeline\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}, {'number': 23, 'created': '2014-07-17 09:42:23.000000000', 'files': ['solum/api/controllers/v1/datamodel/execution.py', 'doc/source/develop_applications/webapi/v1.rst', 'solum/api/controllers/v1/pipeline.py', 'solum/objects/sqlalchemy/pipeline.py', 'solum/tests/fakes.py', 'solum/tests/objects/test_execution.py', 'solum/objects/execution.py', 'solum/objects/sqlalchemy/migration/alembic_migrations/versions/498adc6185ae_create_initial_db_schema.py', 'solum/api/controllers/v1/execution.py', 'solum/objects/sqlalchemy/execution.py', 'solum/objects/sqlalchemy/__init__.py', 'solum/api/handlers/pipeline_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/5987fb4b10d1df99aeb7d01b2b8a18372abc39de', 'message': 'Add execution table to link to mistral\n\nThis is to keep track of the mistral executions that\nare done for solum on each git push. This allows the\nUI to be able to get detailed information on each pipeline\nexection.\n\nhttps://blueprints.launchpad.net/solum/+spec/pipeline\nChange-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b\n'}]",13,97209,5987fb4b10d1df99aeb7d01b2b8a18372abc39de,119,10,23,4715,,,0,"Add execution table to link to mistral

This is to keep track of the mistral executions that
are done for solum on each git push. This allows the
UI to be able to get detailed information on each pipeline
exection.

https://blueprints.launchpad.net/solum/+spec/pipeline
Change-Id: I10d3e6b911dd5e18973c5b5f9bfe83d88352df2b
",git fetch https://review.opendev.org/openstack/solum refs/changes/09/97209/11 && git format-patch -1 --stdout FETCH_HEAD,"['solum/api/controllers/v1/datamodel/execution.py', 'solum/objects/execution.py', 'doc/source/develop_applications/webapi/v1.rst', 'solum/objects/sqlalchemy/migration/alembic_migrations/versions/498adc6185ae_create_initial_db_schema.py', 'solum/api/controllers/v1/execution.py', 'solum/api/controllers/v1/pipeline.py', 'solum/objects/sqlalchemy/execution.py', 'solum/objects/sqlalchemy/pipeline.py', 'solum/api/handlers/pipeline_handler.py']",9,032037c74910176fe1f1735dd6740b3e105166b6,new-api, ex_obj = objects.registry.Execution() ex_obj.uuid = resp.id ex_obj.pipeline_id = pipeline.id ex_obj.create(self.context), # TODO(asalkeld) store the execution_uuid LOG.info(resp),155,2
openstack%2Fceilometer~master~I22d999c506a30d4ca6b8dd7e9de501570257b99e,openstack/ceilometer,master,I22d999c506a30d4ca6b8dd7e9de501570257b99e,Fix incorrect use of timestamp in test,MERGED,2014-07-12 15:22:08.000000000,2014-07-17 12:22:47.000000000,2014-07-17 12:22:46.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 4715}, {'_account_id': 8052}, {'_account_id': 8871}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-07-12 15:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5a17f0c62683d4e83b09d280a9fff8efb6bc090f', 'message': 'Fix incorrect use of timestamp in test\n\nThe timestamp used has a very slim chance of being in\na different second than actually desired which would\ntickle the bug. The bug itself is simply that the\nmapping between sample and timestamp was incorrect.\n\nChange-Id: I22d999c506a30d4ca6b8dd7e9de501570257b99e\nCloses-bug: 1341142\n'}, {'number': 2, 'created': '2014-07-14 13:10:57.000000000', 'files': ['ceilometer/tests/network/statistics/test_statistics.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dac40f8297d1f291419dfae17c79084a272a5c5e', 'message': ""Fix incorrect use of timestamp in test\n\nThe timestamp used has a very slim chance of being in\na different second than actually desired which would\ntickle the bug. The bug itself is simply that the\nmapping between sample and timestamp was incorrect.\n\nTo make sure that there isn't confusion over distinct\ntimestamps, _make_timestamps has been changed so that\nif multiple timestamps are requested, each is a second\nafter the previous.\n\nChange-Id: I22d999c506a30d4ca6b8dd7e9de501570257b99e\nCloses-bug: 1341142\n""}]",1,106564,dac40f8297d1f291419dfae17c79084a272a5c5e,32,6,2,11564,,,0,"Fix incorrect use of timestamp in test

The timestamp used has a very slim chance of being in
a different second than actually desired which would
tickle the bug. The bug itself is simply that the
mapping between sample and timestamp was incorrect.

To make sure that there isn't confusion over distinct
timestamps, _make_timestamps has been changed so that
if multiple timestamps are requested, each is a second
after the previous.

Change-Id: I22d999c506a30d4ca6b8dd7e9de501570257b99e
Closes-bug: 1341142
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/64/106564/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/network/statistics/test_statistics.py'],1,5a17f0c62683d4e83b09d280a9fff8efb6bc090f,bug/1341142," self._assert_sample(samples[0], 1, 'a', {'spam': 'egg'}, times[0])"," self._assert_sample(samples[0], 1, 'a', {'spam': 'egg'}, times[2])",1,1
openstack%2Foslo.vmware~master~Ie5b84b3cc3913ab57f7ab487349557781cc4157a,openstack/oslo.vmware,master,Ie5b84b3cc3913ab57f7ab487349557781cc4157a,Add constant for ESX datacenter path (HTTP access),MERGED,2014-07-17 00:11:57.000000000,2014-07-17 12:22:45.000000000,2014-07-17 12:22:44.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5638}, {'_account_id': 6981}, {'_account_id': 8759}]","[{'number': 1, 'created': '2014-07-17 00:11:57.000000000', 'files': ['oslo/vmware/constants.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/b3b340764c2f98e9e6393c9e259a7dd7b697167b', 'message': 'Add constant for ESX datacenter path (HTTP access)\n\nThis patch adds a constant.py file to store the constants needed in\nthe VMware ecosystem. A new constant is added for the ESX datacenter\npath when using http access to datastores.\n\nChange-Id: Ie5b84b3cc3913ab57f7ab487349557781cc4157a\n'}]",0,107534,b3b340764c2f98e9e6393c9e259a7dd7b697167b,11,5,1,8759,,,0,"Add constant for ESX datacenter path (HTTP access)

This patch adds a constant.py file to store the constants needed in
the VMware ecosystem. A new constant is added for the ESX datacenter
path when using http access to datastores.

Change-Id: Ie5b84b3cc3913ab57f7ab487349557781cc4157a
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/34/107534/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/vmware/constants.py'],1,b3b340764c2f98e9e6393c9e259a7dd7b697167b,add_const,"# Copyright (c) 2014 VMware, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Shared constants across the VMware ecosystem. """""" # Datacenter path for HTTP access to datastores if the target server is an ESX/ # ESXi system: http://goo.gl/B5Htr8 for more information. ESX_DATACENTER_PATH = 'ha-datacenter' ",,23,0
openstack%2Fneutron~master~I06dfea1170a6b2a649f4e1efe4bf70b7cee0eacb,openstack/neutron,master,I06dfea1170a6b2a649f4e1efe4bf70b7cee0eacb,Fixes port update failure when device ID is not updated,MERGED,2014-07-08 14:37:04.000000000,2014-07-17 12:06:34.000000000,2014-07-16 21:42:30.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1689}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 7062}, {'_account_id': 9008}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9885}, {'_account_id': 9925}, {'_account_id': 10068}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10182}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10387}, {'_account_id': 12271}]","[{'number': 1, 'created': '2014-07-08 14:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ac1ac160ea3d95ceba066146e5c4e82e6345e966', 'message': 'Fixes port update failure when device ID does not need to be updated\n\nThe updation was failing because the changed_device_id variable was undeclared.\nThis fix declares the variable with a default value at the beginning of the\nmethod.\n\nChange-Id: I06dfea1170a6b2a649f4e1efe4bf70b7cee0eacb\nImplements: bug Port update crashes when device ID does not need to be updated\nCloses-Bug: 1337787\n'}, {'number': 2, 'created': '2014-07-15 18:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b78ebb8602f275a6600c6bb29b7c8b6b20964e8e', 'message': 'Fixes port update failure when device ID does not need to be updated\n\nThe updation was failing because the changed_device_id variable was undeclared.\nThis fix declares the variable with a default value at the beginning of the\nmethod.\n\nChange-Id: I06dfea1170a6b2a649f4e1efe4bf70b7cee0eacb\nImplements: bug Port update crashes when device ID does not need to be updated\nCloses-Bug: 1337787\n'}, {'number': 3, 'created': '2014-07-15 18:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/47bdef0b7520d4d79c57e6ad1c7fe6b1cff83bee', 'message': 'Fixes port update failure when device ID is not updated\n\nThe updation was failing because the changed_device_id variable\nwas undeclared.This fix declares the variable with a default value\nat the beginning of the method.\n\nChange-Id: I06dfea1170a6b2a649f4e1efe4bf70b7cee0eacb\nCloses-Bug: 1337787\n'}, {'number': 4, 'created': '2014-07-16 08:45:25.000000000', 'files': ['neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee86bf175e7ee79720462338a0d0988e6e8342c1', 'message': 'Fixes port update failure when device ID is not updated\n\nThe updation was failing because the changed_device_id variable\nwas undeclared.This fix declares the variable with a default value\nat the beginning of the method.\n\nChange-Id: I06dfea1170a6b2a649f4e1efe4bf70b7cee0eacb\nCloses-Bug: 1337787\n'}]",1,105471,ee86bf175e7ee79720462338a0d0988e6e8342c1,77,25,4,12271,,,0,"Fixes port update failure when device ID is not updated

The updation was failing because the changed_device_id variable
was undeclared.This fix declares the variable with a default value
at the beginning of the method.

Change-Id: I06dfea1170a6b2a649f4e1efe4bf70b7cee0eacb
Closes-Bug: 1337787
",git fetch https://review.opendev.org/openstack/neutron refs/changes/71/105471/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,ac1ac160ea3d95ceba066146e5c4e82e6345e966,bug/1337787, changed_device_id = False,,1,0
openstack%2Ffuel-web~master~I4e7144777f96a8d2346c8d92d47a54654ec4b19b,openstack/fuel-web,master,I4e7144777f96a8d2346c8d92d47a54654ec4b19b,Settings layout fixes,MERGED,2014-07-16 14:36:10.000000000,2014-07-17 12:00:10.000000000,2014-07-17 10:58:29.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-07-16 14:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f27b0e843adeec3cfbb4ec7bc67c95119dc8f92e', 'message': 'Settings layout fixes\n\nCloses-Bug:#1340084\n\nChange-Id: I4e7144777f96a8d2346c8d92d47a54654ec4b19b\n'}, {'number': 2, 'created': '2014-07-16 15:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fd4aafa525ea532deb6a22c7c81ec913a959c0e6', 'message': 'Settings layout fixes\n\nCloses-Bug:#1340084\n\nChange-Id: I4e7144777f96a8d2346c8d92d47a54654ec4b19b\n'}, {'number': 3, 'created': '2014-07-17 09:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/71aeab1a71bea89c2433748aa7b47b6c45cf5e11', 'message': 'Settings layout fixes\n\nCloses-Bug:#1340084\n\nChange-Id: I4e7144777f96a8d2346c8d92d47a54654ec4b19b\n'}, {'number': 4, 'created': '2014-07-17 10:09:35.000000000', 'files': ['nailgun/static/templates/cluster/settings_group.html', 'nailgun/static/css/styles.less'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0e3c2168248336a625642087d8387b192d822f58', 'message': 'Settings layout fixes\n\nCloses-Bug:#1340084\n\nChange-Id: I4e7144777f96a8d2346c8d92d47a54654ec4b19b\n'}]",4,107408,0e3c2168248336a625642087d8387b192d822f58,38,6,4,9730,,,0,"Settings layout fixes

Closes-Bug:#1340084

Change-Id: I4e7144777f96a8d2346c8d92d47a54654ec4b19b
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/08/107408/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/css/styles.less', 'nailgun/static/templates/cluster/settings_group.html']",2,f27b0e843adeec3cfbb4ec7bc67c95119dc8f92e,bug/1343160,"<div class=""settings-group table-wrapper"" data-settings-group=""<%- groupName %>""> <div class=""table-colspan setting-container""> <label class=""parameter-box clearfix""> <div class=""table-colspan setting-container""> </div> <div class=""parameter-box clearfix tablerow-wrapper setting-container"">","<div class=""settings-group"" data-settings-group=""<%- groupName %>""> <div class=""table-wrapper""> <label class=""parameter-box clearfix""> <div class=""table-wrapper""> </div> <div class=""table-wrapper""> <div class=""parameter-box clearfix tablerow-wrapper""> </div>",21,13
openstack%2Foslo.db~master~I38595d6bcceee84ef0ca7d88dae5617c006ba8c1,openstack/oslo.db,master,I38595d6bcceee84ef0ca7d88dae5617c006ba8c1,Move all db exception to exception.py,MERGED,2014-07-14 14:39:28.000000000,2014-07-17 11:36:17.000000000,2014-07-17 11:36:17.000000000,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 10068}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-07-14 14:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/83c06e1ddb906d4ba07196ec66099cdc65c0fdca', 'message': 'Extraction classes from package\n\nMoving InvalidSortKey, ColumnError  from oslo/db/sqlalchemy/utils.py to oslo/db/exception.py for ease of use\n\nChange-Id: I38595d6bcceee84ef0ca7d88dae5617c006ba8c1\n'}, {'number': 2, 'created': '2014-07-14 15:21:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/55e72cbc0dc6e16ba808c942f3a1b640fb99c7bb', 'message': 'Extraction classes from package\n\nMoving InvalidSortKey, ColumnError  from oslo/db/sqlalchemy/utils.py to oslo/db/exception.py for ease of use.\nAdd references in utils.py to exception py for backwards compatibility.\n\nChange-Id: I38595d6bcceee84ef0ca7d88dae5617c006ba8c1\n'}, {'number': 3, 'created': '2014-07-14 15:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/42a63b180210f5603c813276de4dba868d381925', 'message': 'Move all db exception to exception.py\n\nMoving InvalidSortKey, ColumnError  from oslo/db/sqlalchemy/utils.py to\noslo/db/exception.py for ease of use.\nAdd references in utils.py to exception py for backwards compatibility.\n\nChange-Id: I38595d6bcceee84ef0ca7d88dae5617c006ba8c1\n'}, {'number': 4, 'created': '2014-07-15 14:22:00.000000000', 'files': ['tests/sqlalchemy/test_utils.py', 'oslo/db/sqlalchemy/utils.py', 'oslo/db/exception.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/108e2bddb4fd44b023170deeb86893c342295fd5', 'message': 'Move all db exception to exception.py\n\nMoving InvalidSortKey, ColumnError  from oslo/db/sqlalchemy/utils.py to\noslo/db/exception.py for ease of use.\nAdd references in utils.py to exception py for backwards compatibility.\n\nChange-Id: I38595d6bcceee84ef0ca7d88dae5617c006ba8c1\n'}]",10,106782,108e2bddb4fd44b023170deeb86893c342295fd5,24,5,4,12363,,,0,"Move all db exception to exception.py

Moving InvalidSortKey, ColumnError  from oslo/db/sqlalchemy/utils.py to
oslo/db/exception.py for ease of use.
Add references in utils.py to exception py for backwards compatibility.

Change-Id: I38595d6bcceee84ef0ca7d88dae5617c006ba8c1
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/82/106782/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/sqlalchemy/test_utils.py', 'oslo/db/sqlalchemy/utils.py', 'oslo/db/exception.py']",3,83c06e1ddb906d4ba07196ec66099cdc65c0fdca,exc_fix," class InvalidSortKey(Exception): message = _(""Sort key supplied was not valid."") class ColumnError(Exception): """"""Error raised when no column or an invalid column is found.""""""",,19,17
openstack%2Fnova~master~I554352ea14e6b3306176e7524502e005cebd8c16,openstack/nova,master,I554352ea14e6b3306176e7524502e005cebd8c16,libvirt: fix recent test changes to work on libvirt < 0.9.13,MERGED,2014-07-15 16:21:23.000000000,2014-07-17 11:36:06.000000000,2014-07-17 11:36:04.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6167}, {'_account_id': 6698}, {'_account_id': 6873}, {'_account_id': 8430}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-15 16:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a37e85fe6aca346e7c0092176cff7c274c7d0a87', 'message': ""libvirt: fix recent test changes to work on libvirt < 0.9.13\n\nThe newly used 'listAllDomains' method was only introduced in\nlibvirt 0.9.13. Although the driver code was written to cope\nwith older libvirt, the test suite code itself would fail\nwhen faced with such an old libvirt because it was trying to\nmock out methods which did not exist.\n\nThe fix here recognises that since '_list_instance_domains_fast'\nand '_list_instance_domains_slow' both have explicit test cases,\nthere is no point in mocking out the low level 'listAllDomains'\nmethod all all the other test cases. Instead we can mock out\nthe much higher level '_list_instance_domains' which means we\navoid any interaction with libvirt in these test cases. The\nopportunity is taken to convert the tests in question to use\n'mock' instead of 'mox' since it also simplifies the code.\n\nFinally the test for '_list_instance_domains_fast' can simply\nbe skipped if the 'listAllDomains' method does not exist.\n\nCloses-bug: 1341729\nChange-Id: I554352ea14e6b3306176e7524502e005cebd8c16\n""}, {'number': 2, 'created': '2014-07-15 16:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f3c884106535daf64d7a95066b69d7f972b01f5', 'message': ""libvirt: fix recent test changes to work on libvirt < 0.9.13\n\nThe newly used 'listAllDomains' method was only introduced in\nlibvirt 0.9.13. Although the driver code was written to cope\nwith older libvirt, the test suite code itself would fail\nwhen faced with such an old libvirt because it was trying to\nmock out methods which did not exist.\n\nThe fix here recognises that since '_list_instance_domains_fast'\nand '_list_instance_domains_slow' both have explicit test cases,\nthere is no point in mocking out the low level 'listAllDomains'\nmethod all all the other test cases. Instead we can mock out\nthe much higher level '_list_instance_domains' which means we\navoid any interaction with libvirt in these test cases. The\nopportunity is taken to convert the tests in question to use\n'mock' instead of 'mox' since it also simplifies the code.\n\nFinally the test for '_list_instance_domains_fast' can simply\nbe skipped if the 'listAllDomains' method does not exist.\n\nCloses-bug: 1341729\nChange-Id: I554352ea14e6b3306176e7524502e005cebd8c16\n""}, {'number': 3, 'created': '2014-07-16 09:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ed7cef1155ccb56917a052731356a74c5a57016', 'message': ""libvirt: fix recent test changes to work on libvirt < 0.9.13\n\nThe newly used 'listAllDomains' method was only introduced in\nlibvirt 0.9.13. Although the driver code was written to cope\nwith older libvirt, the test suite code itself would fail\nwhen faced with such an old libvirt because it was trying to\nmock out methods which did not exist.\n\nThe fix here recognises that since '_list_instance_domains_fast'\nand '_list_instance_domains_slow' both have explicit test cases,\nthere is no point in mocking out the low level 'listAllDomains'\nmethod all all the other test cases. Instead we can mock out\nthe much higher level '_list_instance_domains' which means we\navoid any interaction with libvirt in these test cases. The\nopportunity is taken to convert the tests in question to use\n'mock' instead of 'mox' since it also simplifies the code.\n\nFinally in the test for '_list_instance_domains_fasta' simply\ndefine the constants that will be used, just in case libvirt\ndoes not already have them\n\nCloses-bug: 1341729\nChange-Id: I554352ea14e6b3306176e7524502e005cebd8c16\n""}, {'number': 4, 'created': '2014-07-16 10:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f6935f8ff67b91f673157b30497a1650416e2ee', 'message': ""libvirt: fix recent test changes to work on libvirt < 0.9.13\n\nThe newly used 'listAllDomains' method was only introduced in\nlibvirt 0.9.13. Although the driver code was written to cope\nwith older libvirt, the test suite code itself would fail\nwhen faced with such an old libvirt because it was trying to\nmock out methods which did not exist.\n\nThe fix here recognises that since '_list_instance_domains_fast'\nand '_list_instance_domains_slow' both have explicit test cases,\nthere is no point in mocking out the low level 'listAllDomains'\nmethod all all the other test cases. Instead we can mock out\nthe much higher level '_list_instance_domains' which means we\navoid any interaction with libvirt in these test cases. The\nopportunity is taken to convert the tests in question to use\n'mock' instead of 'mox' since it also simplifies the code.\n\nFinally in the test for '_list_instance_domains_fasta' simply\nskip the test if libvirt is too old to have the required\nconstants defined.\n\nCloses-bug: 1341729\nChange-Id: I554352ea14e6b3306176e7524502e005cebd8c16\n""}, {'number': 5, 'created': '2014-07-16 11:36:49.000000000', 'files': ['nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ee57c65fa26d0be473be9d5e55748abd6693ad0d', 'message': ""libvirt: fix recent test changes to work on libvirt < 0.9.13\n\nThe newly used 'listAllDomains' method was only introduced in\nlibvirt 0.9.13. Although the driver code was written to cope\nwith older libvirt, the test suite code itself would fail\nwhen faced with such an old libvirt because it was trying to\nmock out methods which did not exist.\n\nThe fix here recognises that since '_list_instance_domains_fast'\nand '_list_instance_domains_slow' both have explicit test cases,\nthere is no point in mocking out the low level 'listAllDomains'\nmethod in all the other test cases. Instead we can mock out\nthe much higher level '_list_instance_domains' which means we\navoid any interaction with libvirt in these test cases. The\nopportunity is taken to convert the tests in question to use\n'mock' instead of 'mox' since it also simplifies the code.\n\nFinally in the test for '_list_instance_domains_fast' simply\nskip the test if libvirt is too old to have the required\nconstants defined.\n\nCloses-bug: 1341729\nChange-Id: I554352ea14e6b3306176e7524502e005cebd8c16\n""}]",7,107101,ee57c65fa26d0be473be9d5e55748abd6693ad0d,72,13,5,1779,,,0,"libvirt: fix recent test changes to work on libvirt < 0.9.13

The newly used 'listAllDomains' method was only introduced in
libvirt 0.9.13. Although the driver code was written to cope
with older libvirt, the test suite code itself would fail
when faced with such an old libvirt because it was trying to
mock out methods which did not exist.

The fix here recognises that since '_list_instance_domains_fast'
and '_list_instance_domains_slow' both have explicit test cases,
there is no point in mocking out the low level 'listAllDomains'
method in all the other test cases. Instead we can mock out
the much higher level '_list_instance_domains' which means we
avoid any interaction with libvirt in these test cases. The
opportunity is taken to convert the tests in question to use
'mock' instead of 'mox' since it also simplifies the code.

Finally in the test for '_list_instance_domains_fast' simply
skip the test if libvirt is too old to have the required
constants defined.

Closes-bug: 1341729
Change-Id: I554352ea14e6b3306176e7524502e005cebd8c16
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/107101/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_driver.py'],1,a37e85fe6aca346e7c0092176cff7c274c7d0a87,bug/1341729," if not hasattr(libvirt.virConnect, 'listAllDomains'): return @mock.patch.object(libvirt_driver.LibvirtDriver, ""_list_instance_domains_fast"") def test_list_instance_domains_filtering(self, mock_list): mock_list.return_value = [vm0, vm1, vm2] mock_list.assert_called_with(True) mock_list.return_value = [vm0, vm1, vm2, vm3, vm4] mock_list.assert_called_with(False) mock_list.return_value = [vm0, vm1, vm2] mock_list.assert_called_with(True) @mock.patch.object(libvirt_driver.LibvirtDriver, ""_list_instance_domains"") def test_list_instances(self, mock_list): mock_list.return_value = [vm1, vm2, vm3, vm4] @mock.patch.object(libvirt_driver.LibvirtDriver, ""_list_instance_domains"") def test_list_instance_uuids(self, mock_list): mock_list.return_value = [vm1, vm2, vm3, vm4] mock_list.assert_called_with(only_running=False) @mock.patch.object(libvirt_driver.LibvirtDriver, ""_list_instance_domains"") def test_get_all_block_devices(self, mock_list): mock_list.return_value = [ FakeVirtDomain(xml[0], id=3, name=""instance00000001""), FakeVirtDomain(xml[1], id=1, name=""instance00000002""), FakeVirtDomain(xml[2], id=5, name=""instance00000003"")] mock_list.assert_called_with() @mock.patch.object(libvirt_driver.LibvirtDriver, ""_list_instance_domains"") def test_failing_vcpu_count(self, mock_list): mock_list.return_value = [ DiagFakeDomain(None), DiagFakeDomain(5)] mock_list.assert_called_with() @mock.patch.object(libvirt_driver.LibvirtDriver, ""_list_instance_domains"") def test_failing_vcpu_count_none(self, mock_list): mock_list.return_value = [DiagFakeDomain()] mock_list.assert_called_with() @mock.patch.object(libvirt_driver.LibvirtDriver, ""_list_instance_domains"") def test_get_memory_used_xen(self, mock_list): mock_list.return_value =[ DiagFakeDomain(0, 15814), DiagFakeDomain(1, 750), DiagFakeDomain(2, 1042)]"," def test_list_instance_domains_filtering(self): def fake_list_all(flags): vms = [] if flags & libvirt.VIR_CONNECT_LIST_DOMAINS_ACTIVE: vms.extend([vm0, vm1, vm2]) if flags & libvirt.VIR_CONNECT_LIST_DOMAINS_INACTIVE: vms.extend([vm3, vm4]) return vms self.mox.StubOutWithMock(libvirt_driver.LibvirtDriver, '_conn') libvirt_driver.LibvirtDriver._conn.listAllDomains = fake_list_all self.mox.ReplayAll() def test_list_instances(self): def fake_list_all(flags): vms = [] if flags & libvirt.VIR_CONNECT_LIST_DOMAINS_ACTIVE: vms.extend([vm1, vm2]) if flags & libvirt.VIR_CONNECT_LIST_DOMAINS_INACTIVE: vms.extend([vm3, vm4]) return vms self.mox.StubOutWithMock(libvirt_driver.LibvirtDriver, '_conn') libvirt_driver.LibvirtDriver._conn.listAllDomains = fake_list_all self.mox.ReplayAll() def test_list_instance_uuids(self): def fake_list_all(flags): vms = [] if flags & libvirt.VIR_CONNECT_LIST_DOMAINS_ACTIVE: vms.extend([vm1, vm2]) if flags & libvirt.VIR_CONNECT_LIST_DOMAINS_INACTIVE: vms.extend([vm3, vm4]) return vms self.mox.StubOutWithMock(libvirt_driver.LibvirtDriver, '_conn') libvirt_driver.LibvirtDriver._conn.listAllDomains = fake_list_all self.mox.ReplayAll() def test_get_all_block_devices(self): def fake_list_all(flags): return [FakeVirtDomain(xml[0], id=3, name=""instance00000001""), FakeVirtDomain(xml[1], id=1, name=""instance00000002""), FakeVirtDomain(xml[2], id=5, name=""instance00000003"")] self.mox.StubOutWithMock(libvirt_driver.LibvirtDriver, '_conn') libvirt_driver.LibvirtDriver._conn.listAllDomains = fake_list_all self.mox.ReplayAll() def test_failing_vcpu_count(self): def fake_list_all(flags): return [DiagFakeDomain(None), DiagFakeDomain(5)] self.mox.StubOutWithMock(libvirt_driver.LibvirtDriver, '_conn') libvirt_driver.LibvirtDriver._conn.listAllDomains = fake_list_all self.mox.ReplayAll() def test_failing_vcpu_count_none(self): def fake_list_all(flags): return [DiagFakeDomain()] self.mox.StubOutWithMock(libvirt_driver.LibvirtDriver, '_conn') libvirt_driver.LibvirtDriver._conn.listAllDomains = fake_list_all self.mox.ReplayAll() def test_get_memory_used_xen(self): def fake_list_all(flags): return [DiagFakeDomain(0, 15814), DiagFakeDomain(1, 750), DiagFakeDomain(2, 1042)] libvirt_driver.LibvirtDriver._conn.listAllDomains = fake_list_all",47,68
openstack%2Fheat~master~Ie14906b6cc605d6db49a5153ffa27f82debcc430,openstack/heat,master,Ie14906b6cc605d6db49a5153ffa27f82debcc430,Implement heat client plugin,MERGED,2014-06-04 23:24:46.000000000,2014-07-17 11:36:00.000000000,2014-07-17 11:35:59.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-04 23:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2f3bb18d809a71ad62eb15c2e8ecc7e6eca4c792', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 2, 'created': '2014-06-09 04:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/edb443fdcd0c7d12191a5b5ce2c87e0fa4c61b27', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 3, 'created': '2014-06-09 22:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1c7d9703394658adaf250d33598ef3b45b276d96', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 4, 'created': '2014-06-10 02:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/40e9d6750e0b6b479d6a0cede0ebcb1b8a0aafb4', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 5, 'created': '2014-06-10 05:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9485a2149945b2c122d08969e6abf6bd033ddf0c', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 6, 'created': '2014-06-16 00:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0450886b02bb4b25e38f1147571bab78b347fc1b', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 7, 'created': '2014-06-16 05:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/88b50e232702cf2e592b488aa01b4601b0fcc2d4', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 8, 'created': '2014-06-17 05:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b48f45a7c8024e0f3c1300a75d0ca0152f7ecc3d', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 9, 'created': '2014-06-17 23:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/55abbb9d67abf82f53fd1c461a71cd1c42cb1aa8', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 10, 'created': '2014-06-18 00:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5f51cc83585bdc7bd1867b34e3a6cb75fbd62aef', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 11, 'created': '2014-06-20 03:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/280921bac86f938d8b60514566d4a7420f8f2be8', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 12, 'created': '2014-06-23 00:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0132c63f16bd88f9d5e586e62ab18ab9ba4a71c3', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 13, 'created': '2014-06-23 22:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f64265bdcf4e8c469e4fab4b2cbe05456cc738aa', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 14, 'created': '2014-06-26 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/64cda01efeef4bcad546994116ab5c581c67ea16', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 15, 'created': '2014-06-27 06:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/99500611e4a7f36b62c68aff5fd4ce2babacfb2f', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 16, 'created': '2014-06-30 02:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5023409ffe325b5a3d66606229b2721f3542eab4', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 17, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/171cdbbf071e24784f88020684cc6dc1e14050b2', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 18, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/92efa07e20d961a1ee1ff20314bb53514b974d1c', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 19, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aaf496353fada926682b19768bbfa76766c247fd', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 20, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b8403e8c15445b49e5e19d2f308c464527218111', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 21, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/36a9bd5aa4805f3e25fa05f3bbf6ca9f9389955c', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 22, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0302d3c866c3ef2a5ea23e78d86e63c3763c0361', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 23, 'created': '2014-07-08 21:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/295b62178e449996dd66a664a48136c1ea907742', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}, {'number': 24, 'created': '2014-07-17 02:00:28.000000000', 'files': ['heat/engine/clients/os/heat_plugin.py', 'setup.cfg', 'heat/tests/test_clients.py', 'heat/engine/clients/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/cc1ffff771b3276f2f4644d2ecadadc708572a0f', 'message': 'Implement heat client plugin\n\nThis moves the client creation code out of Clients._heat() into\nits own client plugin.\n\nClients._get_client_option is no longer used, so has been deleted\n\nChange-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430\n'}]",3,97984,cc1ffff771b3276f2f4644d2ecadadc708572a0f,97,18,24,4571,,,0,"Implement heat client plugin

This moves the client creation code out of Clients._heat() into
its own client plugin.

Clients._get_client_option is no longer used, so has been deleted

Change-Id: Ie14906b6cc605d6db49a5153ffa27f82debcc430
",git fetch https://review.opendev.org/openstack/heat refs/changes/84/97984/17 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/clients/heat_plugin.py', 'heat/engine/clients/__init__.py']",2,2f3bb18d809a71ad62eb15c2e8ecc7e6eca4c792,bp/client-plugins,,"from heatclient import client as heatclient def _get_client_option(self, client, option): try: group_name = 'clients_' + client cfg.CONF.import_opt(option, 'heat.common.config', group=group_name) return getattr(getattr(cfg.CONF, group_name), option) except (cfg.NoSuchGroupError, cfg.NoSuchOptError): cfg.CONF.import_opt(option, 'heat.common.config', group='clients') return getattr(cfg.CONF.clients, option) def _get_heat_url(self): heat_url = self._get_client_option('heat', 'url') if heat_url: tenant_id = self.context.tenant_id heat_url = heat_url % {'tenant_id': tenant_id} return heat_url def _heat(self): con = self.context endpoint_type = self._get_client_option('heat', 'endpoint_type') args = { 'auth_url': con.auth_url, 'token': self.auth_token, 'username': None, 'password': None, 'ca_file': self._get_client_option('heat', 'ca_file'), 'cert_file': self._get_client_option('heat', 'cert_file'), 'key_file': self._get_client_option('heat', 'key_file'), 'insecure': self._get_client_option('heat', 'insecure') } endpoint = self._get_heat_url() if not endpoint: endpoint = self.url_for(service_type='orchestration', endpoint_type=endpoint_type) return heatclient.Client('1', endpoint, **args) ",51,39
openstack%2Fheat~master~Id4961c4d9678d7bfe3739128843c41921cc8a34b,openstack/heat,master,Id4961c4d9678d7bfe3739128843c41921cc8a34b,Implement ceilometer client plugin,MERGED,2014-06-04 23:24:46.000000000,2014-07-17 11:35:56.000000000,2014-07-17 11:35:56.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-06-04 23:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/68a09a4761eb9ddb4c53aa737ddf2842433a349d', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 2, 'created': '2014-06-09 04:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/302bfcb67ce47e52ee8cfefdaee5bcd2a53e5aa3', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 3, 'created': '2014-06-09 22:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/580a161a06e0a9dfdcdc37fb82174364b01b0f7b', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 4, 'created': '2014-06-10 02:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/451a1a61f92b11a700efe7d770cc76663b4d50cc', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 5, 'created': '2014-06-10 05:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ecc5a4e460e4511b5bd1f99e8123eec23d7d3ab6', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 6, 'created': '2014-06-16 00:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e5d86ba3f8b0ec9c6c275c2ebacb1ce44c7dc722', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 7, 'created': '2014-06-16 05:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d85a6b2c0b097e36dc32be0f1969ad095866cb8e', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 8, 'created': '2014-06-17 05:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1ac3ae23952f2f0181ec2305413681fc42055d8a', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 9, 'created': '2014-06-17 23:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/80eb5f15060c27cad5b410234dd4c58921c09459', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 10, 'created': '2014-06-18 00:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e13aab83a4a1bafa2d0b6bd5d78012ce33b21a7e', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 11, 'created': '2014-06-20 03:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5ead009b4af457273c6baa1d24170a2dc249dd7d', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 12, 'created': '2014-06-23 00:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4253ce01acd2c7365a7685b4ec00ba7e56a298c5', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 13, 'created': '2014-06-23 22:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d14206c3861f666c025399c23e7a91dd591bbc7e', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 14, 'created': '2014-06-26 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/154087189975b9e7924bbacf2cdb1531416e17ed', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 15, 'created': '2014-06-27 06:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/80c27112ff1fff9a4caa5d826c33799cb3f682fc', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 16, 'created': '2014-06-30 02:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ae71bde9a499fc7c0551a4448722966940f35185', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 17, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/70702c78efa6e05c9d6588ae4c56939551dbd563', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 18, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/baf8fe124a5620b46c9dec56fab8403e2f25e795', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 19, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/20071b2e9bee1b0efc41105212bdd0be3b54cb49', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 20, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2b0d7393dcfd459bc399006cccdba296812fcf70', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 21, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/50e232a2066683f509c419a228b741d76b7c418a', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 22, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/05f28c2692c2b5bf559ff0ac0d59f7634a6eecc1', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 23, 'created': '2014-07-08 21:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/43923fb378aa3c393b489fb44562530cebdd8496', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}, {'number': 24, 'created': '2014-07-17 02:00:28.000000000', 'files': ['heat/engine/watchrule.py', 'heat/engine/clients/os/ceilometer.py', 'setup.cfg', 'heat/tests/test_ceilometer_alarm.py', 'heat/engine/clients/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/bbea94577f6135935badc573b20164be3bcdc95c', 'message': 'Implement ceilometer client plugin\n\nThis moves the client creation code out of Clients._ceilometer() into\nits own client plugin.\n\nCeilometer is an integrated project, and python-ceilometerclient\nis a dependency, so the import is now mandatory.\n\nChange-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b\n'}]",0,97983,bbea94577f6135935badc573b20164be3bcdc95c,103,18,24,4571,,,0,"Implement ceilometer client plugin

This moves the client creation code out of Clients._ceilometer() into
its own client plugin.

Ceilometer is an integrated project, and python-ceilometerclient
is a dependency, so the import is now mandatory.

Change-Id: Id4961c4d9678d7bfe3739128843c41921cc8a34b
",git fetch https://review.opendev.org/openstack/heat refs/changes/83/97983/24 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/clients/ceilometer.py', 'heat/tests/test_ceilometer_alarm.py', 'heat/engine/clients/__init__.py']",3,68a09a4761eb9ddb4c53aa737ddf2842433a349d,bp/client-plugins,,"try: from ceilometerclient import client as ceilometerclient except ImportError: ceilometerclient = None LOG.info(_('ceilometerclient not available')) def _ceilometer(self): if ceilometerclient is None: return None con = self.context endpoint_type = self._get_client_option('ceilometer', 'endpoint_type') endpoint = self.url_for(service_type='metering', endpoint_type=endpoint_type) args = { 'auth_url': con.auth_url, 'service_type': 'metering', 'project_id': con.tenant, 'token': lambda: self.auth_token, 'endpoint_type': endpoint_type, 'ca_file': self._get_client_option('ceilometer', 'ca_file'), 'cert_file': self._get_client_option('ceilometer', 'cert_file'), 'key_file': self._get_client_option('ceilometer', 'key_file'), 'insecure': self._get_client_option('ceilometer', 'insecure') } return ceilometerclient.Client('2', endpoint, **args) ",46,36
openstack%2Fheat~master~I89d290f6a38488779e77ff11bdfdd64c159a57e8,openstack/heat,master,I89d290f6a38488779e77ff11bdfdd64c159a57e8,Implement trove client plugin,MERGED,2014-06-04 23:24:46.000000000,2014-07-17 11:31:20.000000000,2014-07-17 11:31:20.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 5293}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7193}, {'_account_id': 7236}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-04 23:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0a3767aa7363cee7d23d96410adafdf0681e7850', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 2, 'created': '2014-06-09 04:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d9d8cdcc1d0e4cc2fa66c80ba73cade65a009349', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 3, 'created': '2014-06-09 22:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/02d8bdd73e58dfd0f594ba773e23783872f7beeb', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 4, 'created': '2014-06-10 02:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f42d778bf05e5ad1c1b9753d7275c2e607eaaf89', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 5, 'created': '2014-06-10 05:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2151a99dc1ef78f7509985faf5644d23c0c97c63', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 6, 'created': '2014-06-16 00:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ef3f0b07067d0342cf21a29d36f37520f5e44273', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 7, 'created': '2014-06-16 05:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9eb2e9cc89fc3afce988a4a89a583b65d36a60bc', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 8, 'created': '2014-06-17 05:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/013cf71a1674b8e13485636a4033150132fdccab', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 9, 'created': '2014-06-17 23:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8c6dcf9bd502406030afdc58bcc2cb60baf1f30f', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 10, 'created': '2014-06-18 00:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/db912cb6b7d7d18a7c700404e06e3bdfb1a416ec', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 11, 'created': '2014-06-20 03:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d68a81b3febd1be535b841613815a0b85d479588', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 12, 'created': '2014-06-23 00:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/71c035aa829351ea50fbd143448d2057d6795953', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 13, 'created': '2014-06-23 22:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/201197aa683fa2305cd659b8d6ed8c65302eb894', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 14, 'created': '2014-06-26 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d35f01c8c5d8495c7c47817e945e30afaffd0379', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 15, 'created': '2014-06-27 06:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0a5e3e5c7027561584908568bfc8e18f69d6d794', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 16, 'created': '2014-06-30 02:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eb81af8c5bd7f660a97bde285b38d0603c3a3839', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 17, 'created': '2014-06-30 05:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9755d92aac08a7461f7a4cf5057771f807f6e6e4', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 18, 'created': '2014-07-01 23:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/978a730c0b92fb474f6df966a59e0e628f55379f', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 19, 'created': '2014-07-04 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5f4f62a3b5d14546d5d7ec6c2f478b8be9ff82ff', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 20, 'created': '2014-07-06 22:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/248882c44c75714b1d631aac1185435d03eca6e6', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 21, 'created': '2014-07-07 02:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a6d04855ff9e4897b17219ffc23d80911be66546', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 22, 'created': '2014-07-08 04:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e569ba0af264d6bc2b6847101f809ec79d2f64a7', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 23, 'created': '2014-07-08 21:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1681dc13390790be49c7a9ca2c31e7e2a18bc0e9', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}, {'number': 24, 'created': '2014-07-17 02:00:28.000000000', 'files': ['heat/tests/test_os_database.py', 'heat/engine/resources/os_database.py', 'setup.cfg', 'heat/engine/clients/__init__.py', 'heat/engine/clients/os/trove.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e247c291ed5c38a9dfeecbda462e949b92c88ab1', 'message': 'Implement trove client plugin\n\nThis moves the client creation code out of Clients._trove() into\nits own client plugin.\n\nTrove is an integrated project, and python-troveclient is a dependency,\nso the import is now mandatory.\n\nChange-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8\n'}]",5,97982,e247c291ed5c38a9dfeecbda462e949b92c88ab1,107,19,24,4571,,,0,"Implement trove client plugin

This moves the client creation code out of Clients._trove() into
its own client plugin.

Trove is an integrated project, and python-troveclient is a dependency,
so the import is now mandatory.

Change-Id: I89d290f6a38488779e77ff11bdfdd64c159a57e8
",git fetch https://review.opendev.org/openstack/heat refs/changes/82/97982/9 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_os_database.py', 'heat/engine/clients/trove.py', 'heat/engine/resources/os_database.py', 'heat/engine/clients/__init__.py']",4,0a3767aa7363cee7d23d96410adafdf0681e7850,bp/client-plugins,," try: from troveclient import client as troveclient except ImportError: troveclient = None LOG.info(_('troveclient not available')) def _trove(self): if troveclient is None: return None con = self.context endpoint_type = self._get_client_option('trove', 'endpoint_type') args = { 'service_type': 'database', 'auth_url': con.auth_url, 'proxy_token': con.auth_token, 'username': None, 'password': None, 'cacert': self._get_client_option('trove', 'ca_file'), 'insecure': self._get_client_option('trove', 'insecure'), 'endpoint_type': endpoint_type } client = troveclient.Client('1.0', **args) management_url = self.url_for(service_type='database', endpoint_type=endpoint_type) client.client.auth_token = con.auth_token client.client.management_url = management_url return client ",49,34
openstack%2Fheat-translator~master~Ic7a0f88157ddf89f8fc3247b76cdfc16a1670b9f,openstack/heat-translator,master,Ic7a0f88157ddf89f8fc3247b76cdfc16a1670b9f,Enhanced tosca validation,ABANDONED,2014-07-17 07:33:51.000000000,2014-07-17 11:31:10.000000000,,"[{'_account_id': 3}, {'_account_id': 7193}]","[{'number': 1, 'created': '2014-07-17 07:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/271af292fe55222df0fc773612920c4daf11c4db', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ic7a0f88157ddf89f8fc3247b76cdfc16a1670b9f\n'}, {'number': 2, 'created': '2014-07-17 10:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/d980e8644110ffc53fa1ad576c0a814015f09867', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ic7a0f88157ddf89f8fc3247b76cdfc16a1670b9f\n'}, {'number': 3, 'created': '2014-07-17 11:05:57.000000000', 'files': ['translator/toscalib/utils/yamlparser.py', 'translator/toscalib/tests/data/test_tosca_top_level_error2.yaml', 'translator/toscalib/tosca_template.py', 'translator/toscalib/parameters.py', 'translator/toscalib/elements/interfaces.py', 'translator/toscalib/nodetemplate.py', 'translator/toscalib/tests/test_toscatplvalidation.py', 'translator/toscalib/common/__init__.py', 'translator/toscalib/tests/test_exception.py', 'translator/toscalib/common/exception.py', 'translator/toscalib/tests/test_toscadef.py', 'translator/toscalib/elements/nodetype.py', 'translator/toscalib/tests/data/test_tosca_top_level_error1.yaml'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/040eb54f5beffe7da51bb3a3ac875ab8b07ad96e', 'message': 'Enhanced tosca validation\n\nUsing new exception class instead of built-in exception types.\nAdded validation for tosca template field names.\n\nPartially implements: blueprint tosca-validation\nImplements: blueprint check-key-definition\n\nChange-Id: Ic7a0f88157ddf89f8fc3247b76cdfc16a1670b9f\n'}]",0,107575,040eb54f5beffe7da51bb3a3ac875ab8b07ad96e,11,2,3,10856,,,0,"Enhanced tosca validation

Using new exception class instead of built-in exception types.
Added validation for tosca template field names.

Partially implements: blueprint tosca-validation
Implements: blueprint check-key-definition

Change-Id: Ic7a0f88157ddf89f8fc3247b76cdfc16a1670b9f
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/75/107575/1 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/utils/yamlparser.py', 'translator/toscalib/tests/data/test_tosca_top_level_error2.yaml', 'translator/toscalib/tosca_template.py', 'translator/toscalib/parameters.py', 'translator/toscalib/elements/interfaces.py', 'translator/toscalib/nodetemplate.py', 'translator/toscalib/tests/test_toscatplvalidation.py', 'translator/toscalib/common/__init__.py', 'translator/toscalib/tests/test_exception.py', 'translator/toscalib/common/exception.py', 'translator/toscalib/tests/test_toscadef.py', 'translator/toscalib/elements/nodetype.py', 'translator/toscalib/tests/data/test_tosca_top_level_error1.yaml']",13,271af292fe55222df0fc773612920c4daf11c4db,bp/tosca-validation,"description: > TOSCA simple profile missing version section. inputs: cpus: type: integer description: Number of CPUs for the server. constraints: - valid_values: [ 1, 2, 4, 8 ] node_templates: server: type: tosca.nodes.Compute properties: # compute properties (flavor) disk_size: 10 num_cpus: { get_input: cpus } mem_size: 4096 # host image properties os_arch: x86_64 os_type: Linux os_distribution: Fedora os_version: 18 outputs: server_address: description: IP address of server instance. value: { get_property: [server, ip_address] } ",,819,50
openstack%2Ftrove~master~I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6,openstack/trove,master,I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6,Fix tracking of SG's provisioned by Heat,MERGED,2014-05-30 15:13:08.000000000,2014-07-17 11:26:58.000000000,2014-07-17 11:26:58.000000000,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}, {'_account_id': 9683}]","[{'number': 1, 'created': '2014-05-30 15:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3aa069e0a83deccc1d1de007d46361a39f1b69b6', 'message': ""Track security group provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as a part of Heat stack.\n - Trove should create two records:\n   - security groups itself (security groups table);\n   - security group association to an actual instance;\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 2, 'created': '2014-05-30 15:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1789d68730c5ac322d07efe371317e61a31d4689', 'message': ""Track security group provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of Heat stack.\n - Trove should create two records:\n   - security groups itself (security groups table);\n   - security group association to an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 3, 'created': '2014-05-30 15:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/37a4ffde8196c22a68be864d1a413507b33efc9e', 'message': ""Track security group provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of Heat stack.\n - Trove should create two records:\n   - security groups itself (security groups table);\n   - security group association to an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 4, 'created': '2014-05-30 15:59:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1acae44a802fe3bccc5d89bc2c94cbffdebfd619', 'message': ""Track security group provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of Heat stack.\n - Trove should create two records:\n   - security groups itself (security groups table);\n   - security group association to an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 5, 'created': '2014-05-30 20:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6eb872e6c6c15986ae183cd03a5b330ad27062ca', 'message': ""Track security group provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of stack.\n - Trove should create two records for security group tracking:\n   - security group;\n   - security group association with an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 6, 'created': '2014-05-30 21:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ef5955b1928e7df1e04f9e0505805f9af0b439ba', 'message': ""Fix tracking of SG's provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of stack.\n - Trove should create two records for security group tracking:\n   - security group;\n   - security group association with an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228""}, {'number': 7, 'created': '2014-06-03 12:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a0c103c7ac5aa4fe295157b2f4733a202d1feee9', 'message': ""Fix tracking of SG's provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of stack.\n - Trove should create two records for security group tracking:\n   - security group;\n   - security group association with an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 8, 'created': '2014-06-03 12:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6d456e6362fdc859d2d11a6260680874973f77d0', 'message': ""Fix tracking of SG's provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of stack.\n - Trove should create two records for security group tracking:\n   - security group;\n   - security group association with an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 9, 'created': '2014-06-04 12:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5ac05e1a914c48bccf17dde9a6e3d539beec9555', 'message': ""Fix tracking of SG's provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of stack.\n - Trove should create two records for security group tracking:\n   - security group;\n   - security group association with an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 10, 'created': '2014-06-23 09:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1b2504781b65e91c8a01f138ae3320d391c56138', 'message': ""Fix tracking of SG's provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of stack.\n - Trove should create two records for security group tracking:\n   - security group;\n   - security group association with an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 11, 'created': '2014-06-26 09:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/2f589bc8dd0ee1355f5ddc284a86542a17082711', 'message': ""Fix tracking of SG's provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of stack.\n - Trove should create two records for security group tracking:\n   - security group;\n   - security group association with an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 12, 'created': '2014-06-26 10:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1cef16d64bc4d67b9709186149b1fc51570f0aa5', 'message': ""Fix tracking of SG's provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of stack.\n - Trove should create two records for security group tracking:\n   - security group;\n   - security group association with an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 13, 'created': '2014-07-01 08:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3573c9cbf45db704028f0fb4211108c8b3a18295', 'message': ""Fix tracking of SG's provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of stack.\n - Trove should create two records for security group tracking:\n   - security group;\n   - security group association with an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}, {'number': 14, 'created': '2014-07-03 11:02:14.000000000', 'files': ['trove/taskmanager/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/98f0fb6f7898c4389da442cee8a4dfdaf071d58b', 'message': ""Fix tracking of SG's provisioned by Heat\n\nReasons:\n - Trove doesn't track security group that was created as\n   a part of stack.\n - Trove should create two records for security group tracking:\n   - security group;\n   - security group association with an actual instance;\n\nChanges:\n - Adding security groups registration right after stack creation.\n\nChange-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6\nCloses-Bug: #1276228\n""}]",13,96795,98f0fb6f7898c4389da442cee8a4dfdaf071d58b,128,11,14,8415,,,0,"Fix tracking of SG's provisioned by Heat

Reasons:
 - Trove doesn't track security group that was created as
   a part of stack.
 - Trove should create two records for security group tracking:
   - security group;
   - security group association with an actual instance;

Changes:
 - Adding security groups registration right after stack creation.

Change-Id: I1f55c27ecbd5ad76c869eae7197b8c24720fc1e6
Closes-Bug: #1276228
",git fetch https://review.opendev.org/openstack/trove refs/changes/95/96795/3 && git format-patch -1 --stdout FETCH_HEAD,['trove/taskmanager/models.py'],1,3aa069e0a83deccc1d1de007d46361a39f1b69b6,bug/1276228,"from trove.extensions.security_group.models import SecurityGroupInstanceAssociation # noqa resource = client.resources.get(stack.id, 'DatastoreSG') name = ""%s_%s"" % (CONF.trove_security_group_name_prefix, self.id) description = _(""Security Group for %s"") % self.id SecurityGroup.create(id=resource.physical_resource_id, name=name, description=description) SecurityGroupInstanceAssociation.create( security_group_id=resource.physical_resource_id, instance_id=self.id) ",,10,0
openstack%2Ffuel-main~stable%2F4.1~I892deb9dbd90ad04e1a7350641e0a392a20f04a9,openstack/fuel-main,stable/4.1,I892deb9dbd90ad04e1a7350641e0a392a20f04a9,Added test for checking cluster scalability,ABANDONED,2014-07-17 10:47:58.000000000,2014-07-17 11:19:00.000000000,,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-07-17 10:47:58.000000000', 'files': ['fuelweb_test/tests/test_ha.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f94738f9f16d9c8c7dbfedcdf3e3967a6f781ea3', 'message': 'Added test for checking cluster scalability\n\nChange-Id: I892deb9dbd90ad04e1a7350641e0a392a20f04a9\nCloses-Bug: #1310626\n(cherry picked from commit 1a2f36a9efc0c43d5a0266791c6cadc663be3f5d)\n'}]",0,107643,f94738f9f16d9c8c7dbfedcdf3e3967a6f781ea3,6,5,1,10136,,,0,"Added test for checking cluster scalability

Change-Id: I892deb9dbd90ad04e1a7350641e0a392a20f04a9
Closes-Bug: #1310626
(cherry picked from commit 1a2f36a9efc0c43d5a0266791c6cadc663be3f5d)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/43/107643/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_ha.py'],1,f94738f9f16d9c8c7dbfedcdf3e3967a6f781ea3,,"import re from proboscis.asserts import assert_true @test(groups=[""thread_4"", ""ha""]) class TestHaFlatScalability(TestBasic): @test(depends_on=[SetupEnvironment.prepare_slaves_5], groups=[""ha_flat_scalability""]) @log_snapshot_on_error def ha_flat_scalability(self): """"""Check HA mode on scalability Scenario: 1. Create cluster 2. Add 1 controller node 3. Deploy the cluster 4. Add 2 controller nodes 5. Deploy changes 6. Run network verification 7. Add 2 controller nodes 8. Deploy changes 9. Run network verification 10. Run OSTF Snapshot ha_flat_scalability """""" self.env.revert_snapshot(""ready_with_5_slaves"") cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=DEPLOYMENT_MODE_HA ) self.fuel_web.update_nodes( cluster_id, { 'slave-01': ['controller'] } ) self.fuel_web.deploy_cluster_wait(cluster_id) self.fuel_web.update_nodes( cluster_id, {'slave-02': ['controller'], 'slave-03': ['controller']}, True, False ) self.fuel_web.deploy_cluster_wait(cluster_id) for devops_node in self.env.nodes().slaves[:3]: self.fuel_web.assert_pacemaker( devops_node.name, self.env.nodes().slaves[:3], []) self.fuel_web.update_nodes( cluster_id, {'slave-04': ['controller'], 'slave-05': ['controller']}, True, False ) self.fuel_web.deploy_cluster_wait(cluster_id) for devops_node in self.env.nodes().slaves[:5]: ret = self.fuel_web.get_pacemaker_status(devops_node.name) assert_true( re.search('vip__management_old\s+\(ocf::mirantis:ns_IPaddr2\):' '\s+Started node', ret), 'vip management started') assert_true( re.search('vip__public_old\s+\(ocf::mirantis:ns_IPaddr2\):' '\s+Started node', ret), 'vip public started') self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['ha', 'sanity'], should_fail=2, failed_test_name=['Check internet connectivity from a compute', 'Check DNS resolution on compute node']) self.env.make_snapshot(""ha_flat_scalability"")",,74,0
openstack%2Foslo-incubator~master~I3ceeba831ad93980ecf889e28bfdabf6204a9489,openstack/oslo-incubator,master,I3ceeba831ad93980ecf889e28bfdabf6204a9489,Fix tests.unit.reports.* with python3.4,MERGED,2014-07-09 14:29:06.000000000,2014-07-17 11:18:06.000000000,2014-07-17 11:18:05.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 12022}]","[{'number': 1, 'created': '2014-07-09 14:29:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/27568f00c59faa334f4260f35642d2709ecff58b', 'message': 'Fix tests.unit.reports.* with python3.4\n\nSort all reports alphabetically to avoid dict key order issues in python2 or python3.\n\nChange-Id: I3ceeba831ad93980ecf889e28bfdabf6204a9489\n'}, {'number': 2, 'created': '2014-07-16 15:56:11.000000000', 'files': ['tests/unit/reports/test_openstack_generators.py', 'openstack/common/report/views/json/generic.py', 'tests/unit/reports/test_views.py', 'tests/unit/reports/test_guru_meditation_report.py', 'openstack/common/report/views/xml/generic.py', 'openstack/common/report/views/text/generic.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/ee3082dd57af6500bc91f307338866f3ca7dc057', 'message': 'Fix tests.unit.reports.* with python3.4\n\nSort all reports alphabetically to avoid dict key order issues in python2 or python3.\n\nChange-Id: I3ceeba831ad93980ecf889e28bfdabf6204a9489\n'}]",2,105749,ee3082dd57af6500bc91f307338866f3ca7dc057,19,4,2,12022,,,0,"Fix tests.unit.reports.* with python3.4

Sort all reports alphabetically to avoid dict key order issues in python2 or python3.

Change-Id: I3ceeba831ad93980ecf889e28bfdabf6204a9489
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/49/105749/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/reports/test_openstack_generators.py', 'openstack/common/report/views/json/generic.py', 'tests/unit/reports/test_views.py', 'tests/unit/reports/test_guru_meditation_report.py', 'openstack/common/report/views/xml/generic.py', 'openstack/common/report/views/text/generic.py']",6,27568f00c59faa334f4260f35642d2709ecff58b,test-python3," for key in sorted(root): for val in sorted(root, key=lambda obj: str(obj)):", for key in root: for val in root:,32,31
openstack%2Ffuel-library~master~Ib54ff5baf1308fab66bff4b1cc33e058c6b431a7,openstack/fuel-library,master,Ib54ff5baf1308fab66bff4b1cc33e058c6b431a7,Mellanox OFED support OEM firmware,MERGED,2014-07-09 17:18:07.000000000,2014-07-17 11:14:17.000000000,2014-07-17 11:14:17.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11968}, {'_account_id': 12065}, {'_account_id': 12177}]","[{'number': 1, 'created': '2014-07-09 17:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/502d77a6f13e5b3dba939a0a284cbdf85ee842f0', 'message': 'Mellanox OFED support OEM firmware\n\n  1. create wrapper script in mlnx-ofed-light (change in mlnx-ofed-light-2.2.0-3)\n  2. update ofed_install_with_sriov to call wrapper script\n\nCloses-bug: #1336668\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: Ib54ff5baf1308fab66bff4b1cc33e058c6b431a7\n'}, {'number': 2, 'created': '2014-07-10 07:46:21.000000000', 'files': ['deployment/puppet/cobbler/templates/snippets/ofed_install_with_sriov.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d0710bb38ad1bd56f6457ad7e48fa0353ddf25fe', 'message': 'Mellanox OFED support OEM firmware\n\n  1. create wrapper script in mlnx-ofed-light (change in mlnx-ofed-light-2.2.0-3)\n  2. update ofed_install_with_sriov to call wrapper script\n\nCloses-bug: #1336668\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: Ib54ff5baf1308fab66bff4b1cc33e058c6b431a7\n'}]",0,105798,d0710bb38ad1bd56f6457ad7e48fa0353ddf25fe,21,11,2,12171,,,0,"Mellanox OFED support OEM firmware

  1. create wrapper script in mlnx-ofed-light (change in mlnx-ofed-light-2.2.0-3)
  2. update ofed_install_with_sriov to call wrapper script

Closes-bug: #1336668
partially implements: blueprint mellanox-features-support
Signed-off-by: Moshe Levi <moshele@mellanox.com>

Change-Id: Ib54ff5baf1308fab66bff4b1cc33e058c6b431a7
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/98/105798/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cobbler/templates/snippets/ofed_install_with_sriov.erb'],1,502d77a6f13e5b3dba939a0a284cbdf85ee842f0,mellanox,"#set $mlnx_mode=$getVar('mlnx_plugin_mode','disabled') #set $iser_enabled=$getVar('mlnx_iser_enabled','false')#set $ofed_install_cmd=""/opt/ofed/install_ofed.sh""#set $mlnx4_core_file=""/etc/modprobe.d/mlx4_core.conf""#set $mlnx4_core_file = ""/target"" + $mlnx4_core_file + "" && \\""#set $mlnx_option_cmd=""echo -e \""%s\"" > %s"" % ($mlnx_opt, $mlnx4_core_file)","#set mlnx_mode=$getVar('mlnx_plugin_mode','disabled') #set iser_enabled=$getVar('mlnx_iser_enabled','false')#set ofed_install_cmd=""/usr/bin/perl /opt/ofed/MLNX_OFED_light/mlnxofedinstall -q --enable-sriov""#set mlnx4_core_file=""/etc/modprobe.d/mlx4_core.conf""#set mlnx4_core_file = ""/target"" + $mlnx4_core_file + "" && \\""#set mlnx_option_cmd=""echo -e \""%s\"" > %s"" % ($mlnx_opt, $mlnx4_core_file)",6,6
openstack%2Fironic~master~Ib7338e956e6d1a29c92594174e277cf884086912,openstack/ironic,master,Ib7338e956e6d1a29c92594174e277cf884086912,Fix database migration with SQLite,ABANDONED,2014-07-16 14:35:12.000000000,2014-07-17 11:10:19.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}]","[{'number': 1, 'created': '2014-07-16 14:35:12.000000000', 'files': ['ironic/db/sqlalchemy/alembic/versions/3bea56f25597_add_unique_constraint_to_instance_uuid.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/900a69e2d16db2d6db3fde3eadd20c46a5f4efdf', 'message': 'Fix database migration with SQLite\n\nSQLite does not seem to support ALTER for constraints, making\nmigration 3bea56f25597_add_unique_constraint_to_instance_uuid fail.\nThis patch turns error into a warning.\n\nChange-Id: Ib7338e956e6d1a29c92594174e277cf884086912\n'}]",0,107407,900a69e2d16db2d6db3fde3eadd20c46a5f4efdf,7,3,1,10239,,,0,"Fix database migration with SQLite

SQLite does not seem to support ALTER for constraints, making
migration 3bea56f25597_add_unique_constraint_to_instance_uuid fail.
This patch turns error into a warning.

Change-Id: Ib7338e956e6d1a29c92594174e277cf884086912
",git fetch https://review.opendev.org/openstack/ironic refs/changes/07/107407/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/db/sqlalchemy/alembic/versions/3bea56f25597_add_unique_constraint_to_instance_uuid.py'],1,900a69e2d16db2d6db3fde3eadd20c46a5f4efdf,fix-sqlite-migration,"from ironic.openstack.common import log as logging LOG = logging.getLogger(__name__) try: op.create_unique_constraint(""uniq_nodes0instance_uuid"", ""nodes"", [""instance_uuid""]) op.drop_index('node_instance_uuid', 'nodes') except NotImplementedError as exc: LOG.warn(str(exc)) try: op.drop_constraint(""uniq_nodes0instance_uuid"", ""nodes"") op.create_index('node_instance_uuid', 'nodes', ['instance_uuid']) except NotImplementedError as exc: LOG.warn(str(exc))"," op.create_unique_constraint(""uniq_nodes0instance_uuid"", ""nodes"", [""instance_uuid""]) op.drop_index('node_instance_uuid', 'nodes') op.drop_constraint(""uniq_nodes0instance_uuid"", ""nodes"") op.create_index('node_instance_uuid', 'nodes', ['instance_uuid'])",16,5
openstack%2Ffuel-library~master~I10d1e26aff99f6d6360a6de6f1f385d1c28157d9,openstack/fuel-library,master,I10d1e26aff99f6d6360a6de6f1f385d1c28157d9,Adding OFED drivers installation,MERGED,2014-06-29 19:25:29.000000000,2014-07-17 10:58:46.000000000,2014-07-17 10:58:46.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11968}, {'_account_id': 12065}, {'_account_id': 12171}, {'_account_id': 12177}]","[{'number': 1, 'created': '2014-06-29 19:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/89724a4d8007365a204936fc6f2df8b435019f47', 'message': 'Adding OFED drivers installation\n\n1. adding OFED pre req to CentOS if mlnx enabled\n2. adding OFED installation at kickstart postinstall\n3. adding OFED pre req to Ubuntu if mlnx enabled\n4. adding OFED installation to preseed late command\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I10d1e26aff99f6d6360a6de6f1f385d1c28157d9\n'}, {'number': 2, 'created': '2014-07-01 14:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/15dcc63ec88eb560d2eb9078a9c6282f3e5f59a9', 'message': 'Adding OFED drivers installation\n\n1. adding OFED pre req to CentOS if mlnx enabled\n2. adding OFED installation at kickstart postinstall\n3. adding OFED pre req to Ubuntu if mlnx enabled\n4. adding OFED installation to preseed late command\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I10d1e26aff99f6d6360a6de6f1f385d1c28157d9\n'}, {'number': 3, 'created': '2014-07-09 17:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f035e41636ca2e89714b25391b9afc6f26003db4', 'message': 'Adding OFED drivers installation\n\n1. adding OFED pre req to CentOS if mlnx enabled\n2. adding OFED installation at kickstart postinstall\n3. adding OFED pre req to Ubuntu if mlnx enabled\n4. adding OFED installation to preseed late command\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I10d1e26aff99f6d6360a6de6f1f385d1c28157d9\n'}, {'number': 4, 'created': '2014-07-10 07:46:11.000000000', 'files': ['deployment/puppet/cobbler/templates/preseed/ubuntu-1204.preseed.erb', 'deployment/puppet/cobbler/templates/kickstart/centos.ks.erb', 'deployment/puppet/cobbler/templates/snippets/centos_ofed_prereq_pkgs_if_enabled.erb', 'deployment/puppet/cobbler/manifests/snippets.pp', 'deployment/puppet/cobbler/templates/snippets/ofed_install_with_sriov.erb', 'deployment/puppet/cobbler/templates/snippets/ubuntu_packages.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/111216618e87d69b943a03a6419352a08a64025a', 'message': 'Adding OFED drivers installation\n\n1. adding OFED pre req to CentOS if mlnx enabled\n2. adding OFED installation at kickstart postinstall\n3. adding OFED pre req to Ubuntu if mlnx enabled\n4. adding OFED installation to preseed late command\n\npartially implements: blueprint mellanox-features-support\nSigned-off-by: Moshe Levi <moshele@mellanox.com>\n\nChange-Id: I10d1e26aff99f6d6360a6de6f1f385d1c28157d9\n'}]",4,103427,111216618e87d69b943a03a6419352a08a64025a,43,12,4,12171,,,0,"Adding OFED drivers installation

1. adding OFED pre req to CentOS if mlnx enabled
2. adding OFED installation at kickstart postinstall
3. adding OFED pre req to Ubuntu if mlnx enabled
4. adding OFED installation to preseed late command

partially implements: blueprint mellanox-features-support
Signed-off-by: Moshe Levi <moshele@mellanox.com>

Change-Id: I10d1e26aff99f6d6360a6de6f1f385d1c28157d9
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/27/103427/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/cobbler/templates/preseed/ubuntu-1204.preseed.erb', 'deployment/puppet/cobbler/templates/kickstart/centos.ks.erb', 'deployment/puppet/cobbler/templates/snippets/centos_ofed_prereq_pkgs_if_enabled.erb', 'deployment/puppet/cobbler/templates/snippets/ubuntu_ofed_install_with_sriov.erb', 'deployment/puppet/cobbler/manifests/snippets.pp', 'deployment/puppet/cobbler/templates/snippets/centos_ofed_install_with_sriov.erb', 'deployment/puppet/cobbler/templates/snippets/ubuntu_packages.erb']",7,89724a4d8007365a204936fc6f2df8b435019f47,mellanox,"#set mlnx_mode=$getVar('mlnx_plugin_mode','disabled') #if $mlnx_mode != ""disabled"" #silent $pkgsel_packages.append(""mlnx-ofed-light"") #silent $pkgsel_packages.append(""libnl1"") #silent $pkgsel_packages.append(""linux-headers-$(uname -r)"") #silent $pkgsel_packages.append(""dkms"") #end if ",,73,0
openstack%2Ffuel-main~master~Ie06f76b462bf236fd06998d0236f90cbff792afb,openstack/fuel-main,master,Ie06f76b462bf236fd06998d0236f90cbff792afb,Add OSTF to the 'migrate_vm_backed_with_ceph' test,MERGED,2014-06-03 14:54:17.000000000,2014-07-17 10:55:27.000000000,2014-06-03 16:35:14.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10068}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-06-03 14:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/bfd46df4558303d935c370448628485be77ae0c0', 'message': ""Add OSTF to the 'migrate_vm_backed_with_ceph' test\n\nPerforming of OSTF checks was missed after environment deployment is done and it should be added to the test as described in the scenario.\n\nChange-Id: Ie06f76b462bf236fd06998d0236f90cbff792afb\nCloses-Bug: #1324567\n""}, {'number': 2, 'created': '2014-06-03 16:10:06.000000000', 'files': ['fuelweb_test/tests/test_ceph.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2c19e7ed2755d69167bc94a6e95509e66b81e93f', 'message': ""Add OSTF to the 'migrate_vm_backed_with_ceph' test\n\nPerforming of OSTF checks was missed after \nenvironment deployment is done and it should be added\nto the test as described in the scenario.\n\nChange-Id: Ie06f76b462bf236fd06998d0236f90cbff792afb\nCloses-Bug: #1324567\n""}]",0,97525,2c19e7ed2755d69167bc94a6e95509e66b81e93f,18,6,2,11081,,,0,"Add OSTF to the 'migrate_vm_backed_with_ceph' test

Performing of OSTF checks was missed after 
environment deployment is done and it should be added
to the test as described in the scenario.

Change-Id: Ie06f76b462bf236fd06998d0236f90cbff792afb
Closes-Bug: #1324567
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/25/97525/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_ceph.py'],1,bfd46df4558303d935c370448628485be77ae0c0,bug/1324567," # Copyright 2014 Mirantis, Inc. def _check(): # Run volume test several times with hope that it pass test_path = map_ostf.OSTF_TEST_MAPPING.get( 'Create volume and attach it to instance') logger.debug('Start to run test {0}'.format(test_path)) self.fuel_web.run_single_ostf_test( cluster_id, test_sets=['smoke'], test_name=test_path, should_fail=0) try: _check() except AssertionError: logger.debug(AssertionError) logger.debug(""Test failed from first probe,"" "" we sleep 60 second try one more time "" ""and if it fails again - test will fails "") time.sleep(60) _check() # Run ostf self.fuel_web.run_ostf(cluster_id) ","# Copyright 2014 Mirantis, Inc.",23,1
openstack%2Ffuel-main~master~I892deb9dbd90ad04e1a7350641e0a392a20f04a9,openstack/fuel-main,master,I892deb9dbd90ad04e1a7350641e0a392a20f04a9,Added test for checking cluster scalability,MERGED,2014-04-22 16:27:07.000000000,2014-07-17 10:47:58.000000000,2014-06-04 11:07:17.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8839}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-04-22 16:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a10661c17e37d82dae727e4ca953ebc12a63ead4', 'message': 'Added test for checking cluster scalability\n\nChange-Id: I892deb9dbd90ad04e1a7350641e0a392a20f04a9\nCloses-Bug: #1310626\n'}, {'number': 2, 'created': '2014-04-22 16:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e61f1767fc0eacd4d46247cc187ca086a78119f6', 'message': 'Added test for checking cluster scalability\n\nChange-Id: I892deb9dbd90ad04e1a7350641e0a392a20f04a9\nCloses-Bug: #1310626\n'}, {'number': 3, 'created': '2014-04-24 12:02:06.000000000', 'files': ['fuelweb_test/tests/test_ha.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1a2f36a9efc0c43d5a0266791c6cadc663be3f5d', 'message': 'Added test for checking cluster scalability\n\nChange-Id: I892deb9dbd90ad04e1a7350641e0a392a20f04a9\nCloses-Bug: #1310626\n'}]",1,89633,1a2f36a9efc0c43d5a0266791c6cadc663be3f5d,25,6,3,10136,,,0,"Added test for checking cluster scalability

Change-Id: I892deb9dbd90ad04e1a7350641e0a392a20f04a9
Closes-Bug: #1310626
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/33/89633/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_ha.py'],1,a10661c17e37d82dae727e4ca953ebc12a63ead4,haScalabilityTest," @test(groups=[""thread_4"", ""ha""]) class TestHaFlatScalability(TestBasic): @test(depends_on=[SetupEnvironment.prepare_slaves_5], groups=[""ha_flat_scalability""]) @log_snapshot_on_error def ha_flat_scalability(self): """"""Check HA mode on scalability Scenario: 1. Create cluster 2. Add 1 controller node 3. Deploy the cluster 4. Add 2 controller nodes 5. Deploy changes 6. Run network verification 7. Add 2 controller nodes 8. Deploy changes 9. Run network verification 10. Run OSTF Snapshot ha_flat_scalability """""" self.env.revert_snapshot(""ready_with_5_slaves"") cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=DEPLOYMENT_MODE_HA ) self.fuel_web.update_nodes( cluster_id, { 'slave-01': ['controller'] } ) self.fuel_web.deploy_cluster_wait(cluster_id) self.fuel_web.update_nodes( cluster_id, {'slave-02': ['controller'], 'slave-03': ['controller']}, True, False ) self.fuel_web.deploy_cluster_wait(cluster_id) self.fuel_web.verify_network(cluster_id) self.fuel_web.update_nodes( cluster_id, {'slave-04': ['controller'], 'slave-05': ['controller']}, True, False ) self.fuel_web.deploy_cluster_wait(cluster_id) self.fuel_web.verify_network(cluster_id) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['ha', 'sanity'], should_fail=2, failed_test_name=['Check internet connectivity from a compute', 'Check DNS resolution on compute node']) self.env.make_snapshot(""ha_flat_scalability"")",,61,0
openstack%2Fheat~master~Ib5103b88ec3f9ccd9d516032c6a13dc2fa4bcb5e,openstack/heat,master,Ib5103b88ec3f9ccd9d516032c6a13dc2fa4bcb5e,Stop overriding CONF.default_log_levels per binary,MERGED,2014-06-04 07:06:51.000000000,2014-07-17 10:41:31.000000000,2014-07-17 10:41:31.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4715}, {'_account_id': 7385}, {'_account_id': 8246}]","[{'number': 1, 'created': '2014-06-04 07:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/49890f26dcbd7d9f05ab627249afbfa6dc47f4ad', 'message': ""Stop overriding CONF.default_log_levels per binary\n\nOverriding CONF.default_log_levels means we loose some explicitly set\ndefault values such as 'iso8601=WARN'. Also explicitly overriding\nCONF.default_log_levels means that default_log_levels cannot be set in a\nconfig file.\n\nChange-Id: Ib5103b88ec3f9ccd9d516032c6a13dc2fa4bcb5e\n""}, {'number': 2, 'created': '2014-06-17 22:43:57.000000000', 'files': ['bin/heat-api-cloudwatch', 'bin/heat-api-cfn', 'bin/heat-api', 'bin/heat-engine'], 'web_link': 'https://opendev.org/openstack/heat/commit/8208c64df3966e43bca767edd634bd85da30554b', 'message': ""Stop overriding CONF.default_log_levels per binary\n\nOverriding CONF.default_log_levels means we loose some explicitly set\ndefault values such as 'iso8601=WARN'. Also explicitly overriding\nCONF.default_log_levels means that default_log_levels cannot be set in a\nconfig file.\n\nChange-Id: Ib5103b88ec3f9ccd9d516032c6a13dc2fa4bcb5e\n""}]",0,97697,8208c64df3966e43bca767edd634bd85da30554b,18,5,2,1849,,,0,"Stop overriding CONF.default_log_levels per binary

Overriding CONF.default_log_levels means we loose some explicitly set
default values such as 'iso8601=WARN'. Also explicitly overriding
CONF.default_log_levels means that default_log_levels cannot be set in a
config file.

Change-Id: Ib5103b88ec3f9ccd9d516032c6a13dc2fa4bcb5e
",git fetch https://review.opendev.org/openstack/heat refs/changes/97/97697/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/heat-api-cloudwatch', 'bin/heat-api-cfn', 'bin/heat-api', 'bin/heat-engine']",4,49890f26dcbd7d9f05ab627249afbfa6dc47f4ad,log_levels,," cfg.CONF.default_log_levels = ['amqplib=WARN', 'sqlalchemy=WARN', 'qpid.messaging=INFO', 'keystone=INFO', 'eventlet.wsgi.server=WARN', ]",1,22
openstack%2Fheat~master~I6bd0568fdf5301b876c40acddc73542bcfc224e3,openstack/heat,master,I6bd0568fdf5301b876c40acddc73542bcfc224e3,Pass user_creds_id when creating backup stack,MERGED,2014-07-16 18:03:50.000000000,2014-07-17 10:41:23.000000000,2014-07-17 10:41:23.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-16 18:03:50.000000000', 'files': ['heat/engine/parser.py', 'heat/tests/test_parser.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/523e517fa7bf17d4a211413f62abbd07a594a4d7', 'message': ""Pass user_creds_id when creating backup stack\n\nWhen creating a backup stack on update, we don't want to create a\nnew user_creds record, or update won't work with a trust-scoped\ntoken.  So instead pass the existing stack user_creds_id in to the\nconstructor when creating the backup stack.\n\nThe current behavior is actually doubly wrong, since we don't delete\nuser_creds records when deleting the backup stack, so the stale\ncreds records are probably left behind in the DB.\n\nChange-Id: I6bd0568fdf5301b876c40acddc73542bcfc224e3\nPartial-Bug: #1342593\n""}]",0,107455,523e517fa7bf17d4a211413f62abbd07a594a4d7,15,5,1,4328,,,0,"Pass user_creds_id when creating backup stack

When creating a backup stack on update, we don't want to create a
new user_creds record, or update won't work with a trust-scoped
token.  So instead pass the existing stack user_creds_id in to the
constructor when creating the backup stack.

The current behavior is actually doubly wrong, since we don't delete
user_creds records when deleting the backup stack, so the stale
creds records are probably left behind in the DB.

Change-Id: I6bd0568fdf5301b876c40acddc73542bcfc224e3
Partial-Bug: #1342593
",git fetch https://review.opendev.org/openstack/heat refs/changes/55/107455/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/parser.py', 'heat/tests/test_parser.py']",2,523e517fa7bf17d4a211413f62abbd07a594a4d7,bug/1342593_2," def test_backup_copies_user_creds_id(self): ctx_init = utils.dummy_context(user='my_user', password='my_pass') ctx_init.request_id = self.ctx.request_id creds = db_api.user_creds_create(ctx_init) self.stack = parser.Stack(self.ctx, 'creds_init', self.tmpl, user_creds_id=creds.id) self.stack.store() self.assertEqual(creds.id, self.stack.user_creds_id) backup = self.stack._backup_stack() self.assertEqual(creds.id, backup.user_creds_id) ",,14,1
openstack%2Ffuel-main~master~Ic1c6397f5eb73694162b0c01b83bcdd11e27cb54,openstack/fuel-main,master,Ic1c6397f5eb73694162b0c01b83bcdd11e27cb54,Add all neutron packages to requirements,MERGED,2014-07-03 18:04:52.000000000,2014-07-17 10:29:49.000000000,2014-07-15 16:21:30.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8797}, {'_account_id': 8935}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-03 18:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/70f7107f79e028b91dbbe5895cd63ff0e45500fd', 'message': 'Add all neutron packages to requirements\n\nIt has come up in several requests that we should have packages present for\n all of the neutron components so that any patches we might have included are\n present in the repos on the fuel-master.\n\nThis is not intended to be a ""fuel suppports ..."" but rather enables users to\n customize their deployment accordingly and not have to find packages that\n where not built from the same sources which would cause more problems for\n them.\n\nCloses-bug: #1330610\nRelated-blueprint: ml2-neutron\n\nChange-Id: Ic1c6397f5eb73694162b0c01b83bcdd11e27cb54\n'}, {'number': 2, 'created': '2014-07-15 15:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0bfabe1e80fd63029fec38e8f4192b144146e655', 'message': 'Add all neutron packages to requirements\n\nIt has come up in several requests that we should have packages present for \n all of the neutron components so that any patches we might have included are\n present in the repos on the fuel-master.\n\nThis is not intended to be a ""fuel suppports ..."" but rather enables users to\n customize their deployment accordingly and not have to find packages that\n where not built from the same sources which would cause more problems for\n them.\n\nCloses-bug: #1330610\nRelated-blueprint: ml2-neutron\n\nChange-Id: Ic1c6397f5eb73694162b0c01b83bcdd11e27cb54'}, {'number': 3, 'created': '2014-07-15 15:34:10.000000000', 'files': ['requirements-rpm.txt', 'requirements-deb.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7c588780261f6d61259e21c74ce6f4cf14b3910e', 'message': 'Add all neutron packages to requirements\n\nIt has come up in several requests that we should have packages present for\n all of the neutron components so that any patches we might have included are\n present in the repos on the fuel-master.\n\nThis is not intended to be a ""fuel suppports ..."" but rather enables users to\n customize their deployment accordingly and not have to find packages that\n where not built from the same sources which would cause more problems for\n them.\n\nCloses-bug: #1330610\nRelated-blueprint: ml2-neutron\n\nChange-Id: Ic1c6397f5eb73694162b0c01b83bcdd11e27cb54\n'}]",0,104633,7c588780261f6d61259e21c74ce6f4cf14b3910e,36,8,3,8797,,,0,"Add all neutron packages to requirements

It has come up in several requests that we should have packages present for
 all of the neutron components so that any patches we might have included are
 present in the repos on the fuel-master.

This is not intended to be a ""fuel suppports ..."" but rather enables users to
 customize their deployment accordingly and not have to find packages that
 where not built from the same sources which would cause more problems for
 them.

Closes-bug: #1330610
Related-blueprint: ml2-neutron

Change-Id: Ic1c6397f5eb73694162b0c01b83bcdd11e27cb54
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/33/104633/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-rpm.txt', 'requirements-deb.txt']",2,70f7107f79e028b91dbbe5895cd63ff0e45500fd,bp/ml2-neutron,neutron-lbaas-agentneutron-metering-agent neutron-plugin-bigswitch-agent neutron-plugin-bigswitch neutron-plugin-brocade neutron-plugin-cisco neutron-plugin-hyperv neutron-plugin-ibm-agent neutron-plugin-ibm neutron-plugin-linuxbridge-agent neutron-plugin-linuxbridge neutron-plugin-metaplugin neutron-plugin-metering-agent neutron-plugin-midonet neutron-plugin-ml2 neutron-plugin-mlnx-agent neutron-plugin-mlnx neutron-plugin-nec-agent neutron-plugin-nec neutron-plugin-nicira neutron-plugin-oneconvergence-agent neutron-plugin-oneconvergence neutron-plugin-openflow-agentneutron-plugin-openvswitch neutron-plugin-plumgrid neutron-plugin-ryu-agent neutron-plugin-ryuneutron-plugin-vpn-agentneutron-vpn-agent,neutron-plugin-ml2neutron-plugin-openvswitch,46,4
openstack%2Ffuel-main~master~Ia9b78e6c0e02cb2abc1be62cfe01c69767b3eb53,openstack/fuel-main,master,Ia9b78e6c0e02cb2abc1be62cfe01c69767b3eb53,Change requirements for MySQL 5.6,ABANDONED,2014-07-16 08:57:39.000000000,2014-07-17 10:28:27.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-16 08:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b2b98bb5771e3cc238efa0a7f205a1da2b72df5c', 'message': 'Change requirements for MySQL 5.6\n\n- Add MySQL 5.6 to Ubuntu\n- Add percona-xtrabackup to CentOS and Ubuntu\n\nChange-Id: Ia9b78e6c0e02cb2abc1be62cfe01c69767b3eb53\n'}, {'number': 2, 'created': '2014-07-16 10:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/65c42d9c223251e1bb448317f4b767978d5fa16c', 'message': 'Change requirements for MySQL 5.6\n\n- Add MySQL 5.6 to Ubuntu\n\nChange-Id: Ia9b78e6c0e02cb2abc1be62cfe01c69767b3eb53\n'}, {'number': 3, 'created': '2014-07-16 12:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1b4d82e17d523853215d12a223855017ebac0c25', 'message': 'Change requirements for MySQL 5.6\n\n- Add MySQL 5.6 to Ubuntu\n\nChange-Id: Ia9b78e6c0e02cb2abc1be62cfe01c69767b3eb53\n'}, {'number': 4, 'created': '2014-07-16 12:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6773b099e14067a419f19da1256e3348e5d6cc0b', 'message': 'Change requirements for MySQL 5.6\n\n- Add MySQL 5.6 to Ubuntu\n\nChange-Id: Ia9b78e6c0e02cb2abc1be62cfe01c69767b3eb53\n'}, {'number': 5, 'created': '2014-07-16 12:15:09.000000000', 'files': ['requirements-deb.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2e18aedab82ed4118d280243d0934826b9829124', 'message': 'Change requirements for MySQL 5.6\n\n- Add MySQL 5.6 to Ubuntu\n\nChange-Id: Ia9b78e6c0e02cb2abc1be62cfe01c69767b3eb53\n'}]",0,107261,2e18aedab82ed4118d280243d0934826b9829124,36,2,5,11090,,,0,"Change requirements for MySQL 5.6

- Add MySQL 5.6 to Ubuntu

Change-Id: Ia9b78e6c0e02cb2abc1be62cfe01c69767b3eb53
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/61/107261/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-rpm.txt', 'requirements-deb.txt']",2,b2b98bb5771e3cc238efa0a7f205a1da2b72df5c,mysql5.6,mysql-client-wsrep-5.6percona-xtrabackup,mysql-client mysql-common,3,2
openstack%2Fneutron~master~I61f36c4c5b498622b512b77c187701dc549d44b4,openstack/neutron,master,I61f36c4c5b498622b512b77c187701dc549d44b4,Add oslotest for test-requirements.txt,ABANDONED,2014-07-14 15:07:53.000000000,2014-07-17 10:25:03.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6849}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-14 15:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f5f7c3b5412cef218bb9a2a34b95479b5a7fa224', 'message': 'Add oslotest for test-requirements.txt\n\nThis is needed for adding test that checks equality of models and\nmigrations https://review.openstack.org/76520.\n\nChange-Id: I61f36c4c5b498622b512b77c187701dc549d44b4\n'}, {'number': 2, 'created': '2014-07-14 15:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/abcebd358ab7450c7901bce6839494e448e98540', 'message': 'Add oslotest in test-requirements.txt\n\nThis is needed for adding test that checks equality of models and\nmigrations https://review.openstack.org/76520.\n\nChange-Id: I61f36c4c5b498622b512b77c187701dc549d44b4\n'}, {'number': 3, 'created': '2014-07-16 07:36:26.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/367c8f733ec7f6e3fe4fa1fefd475da501492d27', 'message': 'Add oslotest for test-requirements.txt\n\nThis is needed for adding test that checks equality of models and\nmigrations https://review.openstack.org/76520.\n\nChange-Id: I61f36c4c5b498622b512b77c187701dc549d44b4\n'}]",3,106789,367c8f733ec7f6e3fe4fa1fefd475da501492d27,44,19,3,7249,,,0,"Add oslotest for test-requirements.txt

This is needed for adding test that checks equality of models and
migrations https://review.openstack.org/76520.

Change-Id: I61f36c4c5b498622b512b77c187701dc549d44b4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/106789/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,f5f7c3b5412cef218bb9a2a34b95479b5a7fa224,add_oslotest,oslotest,,1,0
openstack%2Fkeystone~master~I524113ccc4a00e8363b2f9c418a3754f482b44d0,openstack/keystone,master,I524113ccc4a00e8363b2f9c418a3754f482b44d0,Fixes the order of assertEqual arguments,MERGED,2014-03-03 07:27:00.000000000,2014-07-17 09:58:44.000000000,2014-07-17 09:58:44.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 5046}, {'_account_id': 6348}, {'_account_id': 6460}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 8978}, {'_account_id': 9533}, {'_account_id': 9751}, {'_account_id': 10500}, {'_account_id': 11045}, {'_account_id': 11333}, {'_account_id': 11387}, {'_account_id': 11717}]","[{'number': 1, 'created': '2014-03-03 07:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ca7124ac1ea54fc337c10e0f1764edbf30424f07', 'message': ""Fix the order of assertEqual arguments(pemutils, v3_catalog, etc)\n\nassertEqual method's arguments should be in\n('expected', 'actual') order.\n\nChange-Id: I524113ccc4a00e8363b2f9c418a3754f482b44d0\nPartial-Bug: #1277104\n""}, {'number': 2, 'created': '2014-03-31 07:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4f957359a0f5fa76a755f51db5254508c829b44c', 'message': ""Fix the order of assertEqual arguments(pemutils, v3_catalog, etc)\n\nassertEqual method's arguments should be in\n('expected', 'actual') order.\n\nChange-Id: I524113ccc4a00e8363b2f9c418a3754f482b44d0\nPartial-Bug: #1277104\n""}, {'number': 3, 'created': '2014-06-24 15:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6f9bc87b2f7ff86875c01a82cabddd5af264d0e6', 'message': ""Fix the order of assertEqual arguments(pemutils, v3_catalog, etc)\n\nassertEqual method's arguments should be in\n('expected', 'actual') order.\n\nChange-Id: I524113ccc4a00e8363b2f9c418a3754f482b44d0\nPartial-Bug: #1277104\n""}, {'number': 4, 'created': '2014-06-26 06:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8624716287e5457fa851047ae53f9d8250bed43e', 'message': ""Fix the order of assertEqual arguments(pemutils, v3_catalog, etc)\n\nassertEqual method's arguments should be in\n('expected', 'actual') order.\n\nChange-Id: I524113ccc4a00e8363b2f9c418a3754f482b44d0\nPartial-Bug: #1277104\n""}, {'number': 5, 'created': '2014-07-01 07:12:20.000000000', 'files': ['keystone/tests/test_v3_catalog.py', 'keystone/tests/test_sql_upgrade.py', 'keystone/tests/test_token_provider.py', 'keystone/tests/test_url_middleware.py', 'keystone/tests/test_utils.py', 'keystone/tests/test_pemutils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9d12ec57a25b3af64cc45b3cf27c2a6f3f569a8a', 'message': ""Fixes the order of assertEqual arguments\n\nassertEqual method's arguments should be in\n('expected', 'actual') order.\n\nChange-Id: I524113ccc4a00e8363b2f9c418a3754f482b44d0\nPartial-Bug: #1277104\n""}]",9,77514,9d12ec57a25b3af64cc45b3cf27c2a6f3f569a8a,86,18,5,6348,,,0,"Fixes the order of assertEqual arguments

assertEqual method's arguments should be in
('expected', 'actual') order.

Change-Id: I524113ccc4a00e8363b2f9c418a3754f482b44d0
Partial-Bug: #1277104
",git fetch https://review.opendev.org/openstack/keystone refs/changes/14/77514/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_v3_catalog.py', 'keystone/tests/test_sql_upgrade.py', 'keystone/tests/test_token_provider.py', 'keystone/tests/test_url_middleware.py', 'keystone/tests/test_utils.py', 'keystone/tests/test_pemutils.py']",6,ca7124ac1ea54fc337c10e0f1764edbf30424f07,assertEqual_order_pemutils," self.assertEqual(0, len(parse_results)) self.assertEqual(False, pemutils.is_pem(text)) self.assertEqual(1, len(parse_results)) self.assertEqual(1, len(parse_results)) self.assertEqual(count, len(parse_results)) self.assertEqual(1, len(parse_results)) self.assertEqual(count, len(parse_results))"," self.assertEqual(len(parse_results), 0) self.assertEqual(pemutils.is_pem(text), False) self.assertEqual(len(parse_results), 1) self.assertEqual(len(parse_results), 1) self.assertEqual(len(parse_results), count) self.assertEqual(len(parse_results), 1) self.assertEqual(len(parse_results), count)",139,139
openstack%2Ffuel-astute~master~I9fd09804821884b8c450ef3dc026435a8583be26,openstack/fuel-astute,master,I9fd09804821884b8c450ef3dc026435a8583be26,Give more clear message about orchestrator logs,MERGED,2014-07-16 06:28:51.000000000,2014-07-17 09:48:33.000000000,2014-07-16 09:01:22.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8749}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-16 06:28:51.000000000', 'files': ['lib/astute/server/server.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/d90cad0130da014eded5c21fa5f31054ce999dac', 'message': 'Give more clear message about orchestrator logs\n\nShow more specify message about logs: Astute\ninstead of Orchestrator\n\nChange-Id: I9fd09804821884b8c450ef3dc026435a8583be26\nCloses-Bug: #1336398\n'}]",0,107241,d90cad0130da014eded5c21fa5f31054ce999dac,13,4,1,8776,,,0,"Give more clear message about orchestrator logs

Show more specify message about logs: Astute
instead of Orchestrator

Change-Id: I9fd09804821884b8c450ef3dc026435a8583be26
Closes-Bug: #1336398
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/41/107241/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/astute/server/server.rb'],1,d90cad0130da014eded5c21fa5f31054ce999dac,bug/1336398," 'error' => ""Error occurred while running method '#{message['method']}'. Inspect Astute logs for the details"""," 'error' => ""Error occurred while running method '#{message['method']}'. Inspect Orchestrator logs for the details.""",1,1
openstack%2Ftempest~master~Iea1ad2d11620bdd30692d7a11af8963531379c14,openstack/tempest,master,Iea1ad2d11620bdd30692d7a11af8963531379c14,Make javelin check logging a bit better,MERGED,2014-07-16 13:41:39.000000000,2014-07-17 09:45:53.000000000,2014-07-17 09:45:52.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-16 13:41:39.000000000', 'files': ['tempest/cmd/javelin.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/618c9fb2942b6f381ebfdc91bf7e30c65fa6a529', 'message': ""Make javelin check logging a bit better\n\nAdd some more logging to javelin to help us figure out where 'check' is\nfailing.\n\nChange-Id: Iea1ad2d11620bdd30692d7a11af8963531379c14\n""}]",0,107385,618c9fb2942b6f381ebfdc91bf7e30c65fa6a529,15,7,1,1849,,,0,"Make javelin check logging a bit better

Add some more logging to javelin to help us figure out where 'check' is
failing.

Change-Id: Iea1ad2d11620bdd30692d7a11af8963531379c14
",git fetch https://review.opendev.org/openstack/tempest refs/changes/85/107385/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/javelin.py'],1,618c9fb2942b6f381ebfdc91bf7e30c65fa6a529,javelin," LOG.info(""Collecting users"") LOG.info(""checking users"") LOG.info(""checking objects"") LOG.info(""checking servers"") LOG.info(""checking volumes"")"," LOG.info(""Creating users"")",5,1
openstack%2Fdevstack-gate~master~I03219e0ba5dfbf27801f65995cb8521db7c2c382,openstack/devstack-gate,master,I03219e0ba5dfbf27801f65995cb8521db7c2c382,Use different passwords for different tasks,MERGED,2014-07-16 08:25:12.000000000,2014-07-17 09:32:29.000000000,2014-07-17 09:32:29.000000000,"[{'_account_id': 3}, {'_account_id': 1446}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-16 08:25:12.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/d24d3ccacc031c207615392ada7b61e67e288a34', 'message': 'Use different passwords for different tasks\n\nThis way, we can find problems with using the wrong variable\n\nChange-Id: I03219e0ba5dfbf27801f65995cb8521db7c2c382\n'}]",0,107254,d24d3ccacc031c207615392ada7b61e67e288a34,26,5,1,1446,,,0,"Use different passwords for different tasks

This way, we can find problems with using the wrong variable

Change-Id: I03219e0ba5dfbf27801f65995cb8521db7c2c382
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/54/107254/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,d24d3ccacc031c207615392ada7b61e67e288a34,,MYSQL_PASSWORD=secretmysql DATABASE_PASSWORD=secretdatabase RABBIT_PASSWORD=secretrabbit ADMIN_PASSWORD=secretadmin SERVICE_PASSWORD=secretservice,MYSQL_PASSWORD=secret DATABASE_PASSWORD=secret RABBIT_PASSWORD=secret ADMIN_PASSWORD=secret SERVICE_PASSWORD=secret,5,5
openstack%2Fceilometer~master~Ia5937026018bb5441b7a5b6d82ce074889dfe78b,openstack/ceilometer,master,Ia5937026018bb5441b7a5b6d82ce074889dfe78b,Fix typos in code comments & docstrings,MERGED,2014-07-03 04:28:06.000000000,2014-07-17 09:31:41.000000000,2014-07-17 09:31:40.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 10295}, {'_account_id': 11564}, {'_account_id': 12160}]","[{'number': 1, 'created': '2014-07-03 04:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9b4dd143d11fd4fd61fcc37b34e03dac861f9cee', 'message': 'Fix typos in code comments & docstrings\n\nChange-Id: Ia5937026018bb5441b7a5b6d82ce074889dfe78b\n'}, {'number': 2, 'created': '2014-07-10 08:48:55.000000000', 'files': ['ceilometer/image/glance.py', 'ceilometer/event/converter.py', 'ceilometer/api/app.py', 'ceilometer/storage/hbase/utils.py', 'ceilometer/storage/mongo/utils.py', 'ceilometer/publisher/rpc.py', 'ceilometer/tests/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/156d91d193d5efdbbc1c9f74b239ac0556c08a07', 'message': 'Fix typos in code comments & docstrings\n\nConflicts:\n\tceilometer/storage/mongo/utils.py\n\nChange-Id: Ia5937026018bb5441b7a5b6d82ce074889dfe78b\n'}]",0,104444,156d91d193d5efdbbc1c9f74b239ac0556c08a07,28,10,2,12160,,,0,"Fix typos in code comments & docstrings

Conflicts:
	ceilometer/storage/mongo/utils.py

Change-Id: Ia5937026018bb5441b7a5b6d82ce074889dfe78b
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/44/104444/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/image/glance.py', 'ceilometer/event/converter.py', 'ceilometer/api/app.py', 'ceilometer/storage/hbase/utils.py', 'ceilometer/storage/mongo/utils.py', 'ceilometer/publisher/rpc.py', 'ceilometer/tests/image/test_glance.py']",7,9b4dd143d11fd4fd61fcc37b34e03dac861f9cee,fix/typo, # Tests whether the iter_images method returns a unique image, # Tests whether the iter_images method returns an unique image,9,9
openstack%2Foslo.db~master~I536c681dc2defc99b21c9a9fc8c85567cad1ab2c,openstack/oslo.db,master,I536c681dc2defc99b21c9a9fc8c85567cad1ab2c,Make test_project_filter_allow_none pass SA 0.7.x,ABANDONED,2014-07-16 10:57:13.000000000,2014-07-17 09:31:40.000000000,,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 6928}, {'_account_id': 7491}, {'_account_id': 8871}, {'_account_id': 11816}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-07-16 10:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/dc01e99ae5e06b2c13f610d42f95fdf9cd494010', 'message': 'Modification to test_utils.py for sqla_07 test passing\n\nChange the function argument depending on version of sqlalchemy\n\nCloses-Bug: 1342184\n\nChange-Id: I536c681dc2defc99b21c9a9fc8c85567cad1ab2c\n'}, {'number': 2, 'created': '2014-07-16 15:34:16.000000000', 'files': ['tests/sqlalchemy/test_utils.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/edc501fb7a327320f240f906de45dfd0405e97f0', 'message': 'Make test_project_filter_allow_none pass SA 0.7.x\n\nChange the function argument depending on version of sqlalchemy\nfor test passing\n\nCloses-Bug: 1342184\n\nChange-Id: I536c681dc2defc99b21c9a9fc8c85567cad1ab2c\n'}]",6,107317,edc501fb7a327320f240f906de45dfd0405e97f0,16,7,2,12363,,,0,"Make test_project_filter_allow_none pass SA 0.7.x

Change the function argument depending on version of sqlalchemy
for test passing

Closes-Bug: 1342184

Change-Id: I536c681dc2defc99b21c9a9fc8c85567cad1ab2c
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/17/107317/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/sqlalchemy/test_utils.py'],1,dc01e99ae5e06b2c13f610d42f95fdf9cd494010,bug/1342184," if SA_VERSION[0] == 0 and SA_VERSION[1] == 7: second_arg = ':project_id_2' else: second_arg = 'NULL' ' IN (:project_id_1, {0})'.format(second_arg)"," ' IN (:project_id_1, NULL)'",5,2
openstack%2Fhorizon~master~Idab13aae6eb0d96df89638d319b3f94d54d6c6ca,openstack/horizon,master,Idab13aae6eb0d96df89638d319b3f94d54d6c6ca,Identify the flavor popover by the instance ID,ABANDONED,2014-07-17 09:13:13.000000000,2014-07-17 09:29:03.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6610}]","[{'number': 1, 'created': '2014-07-17 09:13:13.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/templates/instances/_instance_flavor.html', 'openstack_dashboard/dashboards/project/instances/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b5b973cbcdc18be5e969bd10b5e61455c78edab8', 'message': 'Identify the flavor popover by the instance ID\n\nThe popover of the flavor details have to be identified by the instance ID\nand not by the flavor ID. When having multiple instances in a listing with\nthe same flavor the identification with the flavor ID is not working.\n\nChange-Id: Idab13aae6eb0d96df89638d319b3f94d54d6c6ca\n'}]",0,107600,b5b973cbcdc18be5e969bd10b5e61455c78edab8,5,3,1,167,,,0,"Identify the flavor popover by the instance ID

The popover of the flavor details have to be identified by the instance ID
and not by the flavor ID. When having multiple instances in a listing with
the same flavor the identification with the flavor ID is not working.

Change-Id: Idab13aae6eb0d96df89638d319b3f94d54d6c6ca
",git fetch https://review.opendev.org/openstack/horizon refs/changes/00/107600/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/instances/templates/instances/_instance_flavor.html', 'openstack_dashboard/dashboards/project/instances/tables.py']",2,b5b973cbcdc18be5e969bd10b5e61455c78edab8,use_instance_id_instead_of_flavor_id," ""instance_id"": instance.id,"," ""flavor_id"": instance.full_flavor.id,",3,3
openstack%2Ffuel-web~master~I344dba3f2b998429a862833e5ad42d13c7babdf6,openstack/fuel-web,master,I344dba3f2b998429a862833e5ad42d13c7babdf6,[Settings tab] Support of dropdown control,MERGED,2014-07-03 15:10:37.000000000,2014-07-17 09:25:44.000000000,2014-07-17 09:25:44.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-07-03 15:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bdb063cc1c0d25e9b40d559dc646ec1829550107', 'message': '[Settings tab] Support of dropdown control\n\nChange-Id: I344dba3f2b998429a862833e5ad42d13c7babdf6\n'}, {'number': 2, 'created': '2014-07-03 15:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bed5623e55dbf43674770132f94054efe722c6da', 'message': '[Settings tab] Support of dropdown control\n\ncloses-Bug: #1330967\n\nChange-Id: I344dba3f2b998429a862833e5ad42d13c7babdf6\n'}, {'number': 3, 'created': '2014-07-04 12:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/75d4c8816cd0b7b91e6733d2950b6a171dcb22f9', 'message': '[Settings tab] Support of dropdown control\n\ncloses-Bug: #1330967\n\nChange-Id: I344dba3f2b998429a862833e5ad42d13c7babdf6\n'}, {'number': 4, 'created': '2014-07-11 09:23:55.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/settings_tab.js', 'nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/templates/cluster/settings_group.html'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fe241a63a852f1eae1b772068ea8fbb0a68c72c5', 'message': '[Settings tab] Support of dropdown control\n\ncloses-Bug: #1330967\n\nChange-Id: I344dba3f2b998429a862833e5ad42d13c7babdf6\n'}]",0,104578,fe241a63a852f1eae1b772068ea8fbb0a68c72c5,38,6,4,8766,,,0,"[Settings tab] Support of dropdown control

closes-Bug: #1330967

Change-Id: I344dba3f2b998429a862833e5ad42d13c7babdf6
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/78/104578/4 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/cluster_page_tabs/settings_tab.js', 'nailgun/static/templates/cluster/settings_group.html']",2,bdb063cc1c0d25e9b40d559dc646ec1829550107,bug/1330967," <% } else if (setting.type == 'dropdown') { %> <div class=""parameter-box clearfix tablerow-wrapper""> <div class=""openstack-sub-title parameter-name""><%- $.t(ns + settingName + '.label', {defaultValue: setting.label}) %></div> <div class=""parameter-control""> <select name=""<%- groupName + '.' + settingName %>"" <%= disabled %>> <% _.each(setting.values, function(option) { %> <option value=""<%- option.data %>""><%- option.label %></option> <% }) %> </select> </div> <div class=""parameter-description description""> <%- setting.description ? $.t(ns + settingName + '.description', {defaultValue: setting.description}) : '' %> </div> <div class=""parameter-description validation-error""></div> </div>",,16,1
openstack%2Fnova~master~I1253661f74dae822be9dc9fe1fdab861ebd64bc9,openstack/nova,master,I1253661f74dae822be9dc9fe1fdab861ebd64bc9,Make sure that metadata handler uses constant_time_compare(),MERGED,2014-07-17 00:31:47.000000000,2014-07-17 09:25:07.000000000,2014-07-17 09:25:04.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7473}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-17 00:31:47.000000000', 'files': ['nova/tests/test_metadata.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e0331cfe9d49f25b8a23f5fc473f610415bb07ac', 'message': ""Make sure that metadata handler uses constant_time_compare()\n\nThis adds a test to ensure that the new behavior of the metadata\nAPI handler persists. It's important that it uses the special\nconstant_time_compare() method.\n\nChange-Id: I1253661f74dae822be9dc9fe1fdab861ebd64bc9\n""}]",0,107540,e0331cfe9d49f25b8a23f5fc473f610415bb07ac,12,7,1,4393,,,0,"Make sure that metadata handler uses constant_time_compare()

This adds a test to ensure that the new behavior of the metadata
API handler persists. It's important that it uses the special
constant_time_compare() method.

Change-Id: I1253661f74dae822be9dc9fe1fdab861ebd64bc9
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/107540/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/test_metadata.py'],1,e0331cfe9d49f25b8a23f5fc473f610415bb07ac,bug/1325128-master," @mock.patch('nova.utils.constant_time_compare') def test_by_instance_id_uses_constant_time_compare(self, mock_compare): mock_compare.side_effect = test.TestingException req = webob.Request.blank('/') hnd = handler.MetadataRequestHandler() req.headers['X-Instance-ID'] = 'fake-inst' req.headers['X-Tenant-ID'] = 'fake-proj' self.assertRaises(test.TestingException, hnd._handle_instance_id_request, req) self.assertEqual(1, mock_compare.call_count) ",,15,0
openstack%2Fheat~master~I2056c89437e8df2a59726b60c3c12f19f713d84d,openstack/heat,master,I2056c89437e8df2a59726b60c3c12f19f713d84d,Fix early resource property value validation,MERGED,2014-05-09 16:11:04.000000000,2014-07-17 09:24:56.000000000,2014-07-17 09:24:55.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6488}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7230}, {'_account_id': 7239}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 7395}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 11939}]","[{'number': 1, 'created': '2014-05-09 16:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/686225d3abe176b0614239194cb0c7a6636ccd4f', 'message': ""Skip resource property value validation in (INIT,COMPLETE) state\n\nCurrently resource property validation may fail if resource it\ndepends on is not created.\nThis change skips property values validation if the resource is\nin ('INIT', 'COMPLETE') state and also has dependency on at least\none other resource\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n""}, {'number': 2, 'created': '2014-05-14 17:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fd80e9c5ecb26b6c5108ba2f2213fb5c9faacef8', 'message': ""Skip resource property value validation in (INIT,COMPLETE) state\n\nCurrently resource property validation may fail if resource it\ndepends on is not created.\nThis change skips property values validation if the resource is\nin ('INIT', 'COMPLETE') state and also has dependency on at least\none other resource\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n""}, {'number': 3, 'created': '2014-05-14 21:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f96e95fb0ceea5db45bece46f6d88d8f091a9275', 'message': ""Fix early resource property value validation\n\nCurrently resource property validation may fail if resource it\ndepends on is not created.\n\nThis change skips property values validation if the resource is\nin ('INIT', 'COMPLETE') state and also has dependency on at least\none other resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\nCo-Authored-By: Clint Byrum <clint@fewbar.com>\n""}, {'number': 4, 'created': '2014-05-22 20:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/81cf4e5de84700bb92af038abd10243e4028d5e3', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation may fail if resource it\ndepends on is not created.\n\nThis change skips a property validation if its intrinsic function\nresolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}, {'number': 5, 'created': '2014-06-02 21:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b280ac5db51b7e08550c53d3df24c56197d0b968', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation may fail if resource it\ndepends on is not created.\n\nThis change skips a property constraint validation if its intrinsic\nfunction resolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}, {'number': 6, 'created': '2014-06-03 13:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ee5f116254f8acc3f66c3cbaed0ededbb21d12dc', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation may fail if resource it\ndepends on is not created.\n\nThis change skips a property constraint validation if its intrinsic\nfunction resolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}, {'number': 7, 'created': '2014-06-11 18:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d4b8d554afd142ab5ae250b9582b922d78398eb4', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation may fail if resource it\ndepends on is not created.\n\nThis change skips a property constraint validation if its intrinsic\nfunction resolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}, {'number': 8, 'created': '2014-06-23 13:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/17618bb6ca1b084609be503bc71aef09d149c58f', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation may fail if resource it\ndepends on is not created.\n\nThis change skips a property constraint validation if its intrinsic\nfunction resolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}, {'number': 9, 'created': '2014-06-26 19:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cf1e00f31d435b5656d5bd384657c57ef4795d05', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation may fail if resource it\ndepends on is not created.\n\nThis change skips a property constraint validation if its intrinsic\nfunction resolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}, {'number': 10, 'created': '2014-07-08 18:24:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d82dc4d174be54d2a6599f9f9ffc141a7f0fb143', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation fails if resource it\ndepends on is not created.\n\nThis change skips a property constraint validation if its intrinsic\nfunction resolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}, {'number': 11, 'created': '2014-07-09 18:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/542de79b5eaaa7d6245cb53dc8a64208a3d2fb52', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation fails if resource it\ndepends on is not created.\n\nThis change skips a property constraint validation if its intrinsic\nfunction resolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}, {'number': 12, 'created': '2014-07-09 19:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/83e2293e77328e092f8b4a4dd416872443d2c1da', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation fails if resource it\ndepends on is not created.\n\nThis change skips a property constraint validation if its intrinsic\nfunction resolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}, {'number': 13, 'created': '2014-07-10 15:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6da5e0e75b83aebc0e7101385d1dd04050c0b11b', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation fails if resource it\ndepends on is not created.\n\nThis change skips a property constraint validation if its intrinsic\nfunction resolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}, {'number': 14, 'created': '2014-07-11 17:03:27.000000000', 'files': ['heat/tests/test_properties.py', 'heat/engine/properties.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5022808e9d2904ae061e6ad584d3215792ff7c39', 'message': 'Fix early resource property value validation\n\nCurrently resource property validation fails if resource it\ndepends on is not created.\n\nThis change skips a property constraint validation if its intrinsic\nfunction resolution does not find the dependant resource.\n\nChange-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d\nPartial-Bug: #1317636\n'}]",11,93080,5022808e9d2904ae061e6ad584d3215792ff7c39,106,19,14,7230,,,0,"Fix early resource property value validation

Currently resource property validation fails if resource it
depends on is not created.

This change skips a property constraint validation if its intrinsic
function resolution does not find the dependant resource.

Change-Id: I2056c89437e8df2a59726b60c3c12f19f713d84d
Partial-Bug: #1317636
",git fetch https://review.opendev.org/openstack/heat refs/changes/80/93080/12 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resource.py'],1,686225d3abe176b0614239194cb0c7a6636ccd4f,bug/1317636," # If this resource is in ('INIT', 'COMPLETE') state and also # has dependency on at least one other resource, then do not validate # the property values if self.state == ('INIT', 'COMPLETE') and ( len(self.stack.dependencies.graph()[self]) > 0): return self.properties.validate(with_value=False) else: return self.properties.validate()", return self.properties.validate(),8,1
openstack%2Fmurano~master~I85892d6e0fa373d31754e6830ce44f9c528f79d4,openstack/murano,master,I85892d6e0fa373d31754e6830ce44f9c528f79d4,Adds Continue macro to MuranoPL,MERGED,2014-07-04 16:46:50.000000000,2014-07-17 09:15:50.000000000,2014-07-17 09:15:49.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 8127}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-07-04 16:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a2d2b7a23bc02578114e2796f1c821ec472b9fd2', 'message': 'Adds Continue macro to MuranoPL\n\nContinue is a complimentary operator to Break\n\nChange-Id: I85892d6e0fa373d31754e6830ce44f9c528f79d4\nImplements: blueprint muranopl-continue-operator\n'}, {'number': 2, 'created': '2014-07-12 13:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/bd6de0ccc563429d111c42b8a7978f7540a14506', 'message': 'Adds Continue macro to MuranoPL\n\nContinue is a complimentary operator to Break\n\nChange-Id: I85892d6e0fa373d31754e6830ce44f9c528f79d4\nImplements: blueprint muranopl-continue-operator\n'}, {'number': 3, 'created': '2014-07-16 09:32:42.000000000', 'files': ['murano/dsl/exceptions.py', 'murano/tests/dsl/meta/MacroExamples.yaml', 'murano/dsl/macros.py', 'murano/tests/dsl/test_macros.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/aaa2a4174268ab30c5b916020d67eb72f98dcdf0', 'message': 'Adds Continue macro to MuranoPL\n\nContinue is a complimentary operator to Break\n\nChange-Id: I85892d6e0fa373d31754e6830ce44f9c528f79d4\nImplements: blueprint muranopl-continue-operator\n'}]",0,104934,aaa2a4174268ab30c5b916020d67eb72f98dcdf0,33,10,3,7226,,,0,"Adds Continue macro to MuranoPL

Continue is a complimentary operator to Break

Change-Id: I85892d6e0fa373d31754e6830ce44f9c528f79d4
Implements: blueprint muranopl-continue-operator
",git fetch https://review.opendev.org/openstack/murano refs/changes/34/104934/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/dsl/exceptions.py', 'murano/tests/dsl/meta/MacroExamples.yaml', 'murano/dsl/macros.py', 'murano/tests/dsl/test_macros.py']",4,a2d2b7a23bc02578114e2796f1c821ec472b9fd2,bp/muranopl-continue-operator," def test_continue(self): self.assertRaises(exceptions.DslInvalidOperationError, self._runner.testContinue) self.assertEqual([0, 1, 2, 5, 6, 'method_continue'], self.traces) ",,41,1
openstack%2Fmurano~master~Ie17240c2d343014ce3da9ddc6577cf93cf99b106,openstack/murano,master,Ie17240c2d343014ce3da9ddc6577cf93cf99b106,Unit tests for macro blocks,MERGED,2014-07-03 19:10:46.000000000,2014-07-17 09:14:21.000000000,2014-07-17 09:14:21.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 8127}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-07-03 19:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/d5d59cf124a9891661b1913af3deb79404367a00', 'message': 'Unit tests for macro blocks\n\nAlso:\n * fixes local variable scope for several macro\n * make thrown exceptions be more descriptive\n * parsing error happened when Limit for ParallelCode was integer (and not expression)\n * improved Break support\n\nChange-Id: Ie17240c2d343014ce3da9ddc6577cf93cf99b106\nCloses-Bug: #1337512\nPartial-Bug: #1316786\n'}, {'number': 2, 'created': '2014-07-03 19:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/1fc1244984ebd47fc0d41b5a65ea2b65b0f0dcaf', 'message': 'Unit tests for macro blocks\n\nAlso:\n * fixes local variable scope for several macro\n * make thrown exceptions be more descriptive\n * parsing error happened when Limit for ParallelCode was integer (and not expression)\n * improved Break support\n\nChange-Id: Ie17240c2d343014ce3da9ddc6577cf93cf99b106\nCloses-Bug: #1337512\nPartial-Bug: #1316786\n'}, {'number': 3, 'created': '2014-07-12 13:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/fa85d1e934f4761d48f1af415b73fcb15ab2f69f', 'message': 'Unit tests for macro blocks\n\nAlso:\n * fixes local variable scope for several macro\n * make thrown exceptions be more descriptive\n * parsing error happened when Limit for ParallelCode was integer (and not expression)\n * improved Break support\n\nChange-Id: Ie17240c2d343014ce3da9ddc6577cf93cf99b106\nCloses-Bug: #1337512\nPartial-Bug: #1316786\n'}, {'number': 4, 'created': '2014-07-16 09:32:30.000000000', 'files': ['murano/dsl/exceptions.py', 'murano/tests/dsl/meta/MacroExamples.yaml', 'murano/dsl/macros.py', 'murano/tests/dsl/test_macros.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/9a39c31cb985e84e7800bc1136430b08eea7f6dd', 'message': 'Unit tests for macro blocks\n\nAlso:\n * fixes local variable scope for several macro\n * make thrown exceptions be more descriptive\n * parsing error happened when Limit for ParallelCode was integer (and not expression)\n * improved Break support\n\nChange-Id: Ie17240c2d343014ce3da9ddc6577cf93cf99b106\nCloses-Bug: #1337512\nPartial-Bug: #1316786\n'}]",0,104651,9a39c31cb985e84e7800bc1136430b08eea7f6dd,34,9,4,7226,,,0,"Unit tests for macro blocks

Also:
 * fixes local variable scope for several macro
 * make thrown exceptions be more descriptive
 * parsing error happened when Limit for ParallelCode was integer (and not expression)
 * improved Break support

Change-Id: Ie17240c2d343014ce3da9ddc6577cf93cf99b106
Closes-Bug: #1337512
Partial-Bug: #1316786
",git fetch https://review.opendev.org/openstack/murano refs/changes/51/104651/4 && git format-patch -1 --stdout FETCH_HEAD,"['murano/dsl/exceptions.py', 'murano/tests/dsl/meta/MacroExamples.yaml', 'murano/dsl/macros.py', 'murano/tests/dsl/test_macros.py']",4,d5d59cf124a9891661b1913af3deb79404367a00,bug/1337512,"# Copyright (c) 2014 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from murano.dsl import exceptions from murano.tests.dsl.foundation import object_model as om from murano.tests.dsl.foundation import test_case class TestMacros(test_case.DslTestCase): def setUp(self): super(TestMacros, self).setUp() self._runner = self.new_runner(om.Object('MacroExamples')) def test_if(self): self.assertEqual('gt', self._runner.testIf(6)) self.assertEqual('def', self._runner.testIf(4)) self.assertEqual('gt', self._runner.testIfElse(6)) self.assertEqual('lt', self._runner.testIfElse(4)) def test_while(self): self.assertEqual(0, self._runner.testWhile(3)) self.assertEqual([3, 2, 1], self.traces) def test_for(self): self.assertIsNone(self._runner.testFor()) self.assertEqual(['x', 'y', 'z', 2, 5, 10], self.traces) def test_repeat(self): self._runner.testRepeat(4) self.assertEqual(['run', 'run', 'run', 'run'], self.traces) def test_break(self): self.assertRaises(exceptions.DslInvalidOperationError, self._runner.testBreak) self.assertEqual([0, 1, 2, 'breaking', 'method_break'], self.traces) def test_match(self): self.assertEqual('y', self._runner.testMatch(1)) self.assertEqual('x', self._runner.testMatch(2)) self.assertEqual('z', self._runner.testMatch(3)) self.assertIsNone(self._runner.testMatch(0)) self.assertEqual('y', self._runner.testMatchDefault(1)) self.assertEqual('x', self._runner.testMatchDefault(2)) self.assertEqual('z', self._runner.testMatchDefault(3)) self.assertEqual('def', self._runner.testMatchDefault(0)) def test_switch(self): self.assertIsNone(self._runner.testSwitch(20)) self.assertEqual(['gt'], self.traces) del self.traces self.assertIsNone(self._runner.testSwitch(200)) self.assertEqual(['gt', 'gt100'], self.traces) del self.traces self.assertIsNone(self._runner.testSwitch(2)) self.assertEqual(['lt'], self.traces) del self.traces self.assertIsNone(self._runner.testSwitchDefault(20)) self.assertEqual(['gt'], self.traces) del self.traces self.assertIsNone(self._runner.testSwitchDefault(200)) self.assertEqual(['gt', 'gt100'], self.traces) del self.traces self.assertIsNone(self._runner.testSwitchDefault(-20)) self.assertEqual(['lt'], self.traces) del self.traces self.assertIsNone(self._runner.testSwitchDefault(5)) self.assertEqual(['def'], self.traces) def test_code_block(self): self.assertEqual(123, self._runner.testCodeBlock()) self.assertEqual(['a', 123], self.traces) def test_parallel(self): self.assertIsNone(self._runner.testParallel()) self.assertEqual(['enter', 'enter', 'exit', 'exit'], self.traces) def test_parallel_with_limit(self): self.assertIsNone(self._runner.testParallelWithLimit()) self.assertEqual(['enter', 'enter', 'exit', 'exit', 'enter', 'exit'], self.traces) def test_scope_within_macro(self): self.assertEqual( 87654321, self._runner.testScopeWithinMacro() )",,360,49
openstack%2Fnova~master~I7374f2edc6f03c7da59cf73ae91a87147e53d0de,openstack/nova,master,I7374f2edc6f03c7da59cf73ae91a87147e53d0de,Avoid possible timing attack in metadata api,MERGED,2014-07-16 14:11:08.000000000,2014-07-17 09:13:14.000000000,2014-07-17 09:13:11.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 7473}, {'_account_id': 7680}, {'_account_id': 8871}, {'_account_id': 9107}, {'_account_id': 9311}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-16 14:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eeebbccf5a59fabdc89834aef449a315c9fd96e9', 'message': 'Avoid possible timing attack in metadata api\n\nIntroduce a constant time comparison function to\nnova utils for comparing authentication tokens.\nOriginal code taken from:\n\nhttps://github.com/openstack/python-keystoneclient/blob/master/keystoneclient/middleware/memcache_crypt.py#L86\n\nChange-Id: I7374f2edc6f03c7da59cf73ae91a87147e53d0de\nCloses-bug: #1325128\n'}, {'number': 2, 'created': '2014-07-16 15:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08dd563b7a374f6abfc012bbe04688be30da3b61', 'message': 'Avoid possible timing attack in metadata api\n\nIntroduce a constant time comparison function to\nnova utils for comparing authentication tokens.\nOriginal code taken from:\n\nhttps://github.com/openstack/python-keystoneclient/blob/master/keystoneclient/middleware/memcache_crypt.py#L86\n\nChange-Id: I7374f2edc6f03c7da59cf73ae91a87147e53d0de\nCloses-bug: #1325128\n'}, {'number': 3, 'created': '2014-07-16 20:56:35.000000000', 'files': ['nova/api/metadata/handler.py', 'nova/utils.py', 'nova/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4a60c6a655006b2882331844664fac5cf67c5f34', 'message': 'Avoid possible timing attack in metadata api\n\nIntroduce a constant time comparison function to\nnova utils for comparing authentication tokens.\n\nChange-Id: I7374f2edc6f03c7da59cf73ae91a87147e53d0de\nCloses-bug: #1325128\n'}]",9,107396,4a60c6a655006b2882331844664fac5cf67c5f34,45,15,3,7473,,,0,"Avoid possible timing attack in metadata api

Introduce a constant time comparison function to
nova utils for comparing authentication tokens.

Change-Id: I7374f2edc6f03c7da59cf73ae91a87147e53d0de
Closes-bug: #1325128
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/107396/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/metadata/handler.py', 'nova/utils.py', 'nova/tests/test_utils.py']",3,eeebbccf5a59fabdc89834aef449a315c9fd96e9,bug/1325128-master," class ConstantTimeCompareTestCase(test.NoDBTestCase): def test_constant_time_compare(self): self.assertTrue(utils.constant_time_compare(""abcd1234"", ""abcd1234"")) self.assertFalse(utils.constant_time_compare(""abcd1234"", ""a"")) self.assertFalse(utils.constant_time_compare(""abcd1234"", ""ABCD234""))",,35,1
openstack%2Fsahara~master~Id1499cf85b7dc84ea369bb718fd3ab63306dfe2b,openstack/sahara,master,Id1499cf85b7dc84ea369bb718fd3ab63306dfe2b,Fix creating cluster with Vanilla 2.4.0 plugin,MERGED,2014-07-16 16:32:34.000000000,2014-07-17 09:04:10.000000000,2014-07-17 09:04:10.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-16 16:32:34.000000000', 'files': ['sahara/plugins/vanilla/v2_4_0/versionhandler.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4d100bd282a940d131ee6828a955c1da87816593', 'message': 'Fix creating cluster with Vanilla 2.4.0 plugin\n\nFixes bug: #1342821\n\nChange-Id: Id1499cf85b7dc84ea369bb718fd3ab63306dfe2b\n'}]",0,107436,4d100bd282a940d131ee6828a955c1da87816593,15,7,1,7710,,,0,"Fix creating cluster with Vanilla 2.4.0 plugin

Fixes bug: #1342821

Change-Id: Id1499cf85b7dc84ea369bb718fd3ab63306dfe2b
",git fetch https://review.opendev.org/openstack/sahara refs/changes/36/107436/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/plugins/vanilla/v2_4_0/versionhandler.py'],1,4d100bd282a940d131ee6828a955c1da87816593,fix-2.4.0," vl.validate_cluster_creating(self.pctx, cluster)", vl.validate_cluster_creating(cluster),1,1
openstack%2Frally~master~I22ea2ddcf5c1a58697286ff292fb6a2a5fcaaee6,openstack/rally,master,I22ea2ddcf5c1a58697286ff292fb6a2a5fcaaee6,Update the way hard & soft reboots are displayed in task result,MERGED,2014-07-16 12:15:03.000000000,2014-07-17 09:00:47.000000000,2014-07-17 09:00:47.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 9545}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-07-16 12:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a7ab76026facec9bcd32c7d721f20a3992a18468', 'message': 'Update the way hard & soft reboots are displayed in task result\n\nCurrently the task result output does not distinguish between\nnova hard and soft reboots. Following patch add this function.\nThe hard reboot will displayed as is nova.reboot_server and\nsoft reboot will be displayed as nova.soft_reboot_server.\n\nChange-Id: I22ea2ddcf5c1a58697286ff292fb6a2a5fcaaee6\nCloses-Bug: #1342138\n'}, {'number': 2, 'created': '2014-07-16 12:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ee11a38c1d8cd1b965c5fed583f62b3f0a5fd28c', 'message': 'Update the way hard & soft reboots are displayed in task result\n\nCurrently the task result output does not distinguish between\nnova hard and soft reboots. Following patch add this function.\nThe hard reboot will displayed as is nova.reboot_server and\nsoft reboot will be displayed as nova.soft_reboot_server.\n\nChange-Id: I22ea2ddcf5c1a58697286ff292fb6a2a5fcaaee6\nCloses-Bug:#1342138\n'}, {'number': 3, 'created': '2014-07-16 13:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7a0e00ee31fb2db1e1e75fff3f4f4af9a4e047b7', 'message': 'Update the way hard & soft reboots are displayed in task result\n\nCurrently the task result output does not distinguish between\nnova hard and soft reboots. Following patch add this function.\nThe hard reboot will displayed as is nova.reboot_server and\nsoft reboot will be displayed as nova.soft_reboot_server.\n\nChange-Id: I22ea2ddcf5c1a58697286ff292fb6a2a5fcaaee6\nCloses-Bug:#1342138\n'}, {'number': 4, 'created': '2014-07-16 15:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1b757d8a1270eedc24982182b0d989b9c05d66f8', 'message': 'Update the way hard & soft reboots are displayed in task result\n\nCurrently the task result output does not distinguish between\nnova hard and soft reboots. Following patch add this function.\nThe hard reboot will displayed as is nova.reboot_server and\nsoft reboot will be displayed as nova.soft_reboot_server.\n\nChange-Id: I22ea2ddcf5c1a58697286ff292fb6a2a5fcaaee6\nCloses-Bug:#1342138\n'}, {'number': 5, 'created': '2014-07-17 03:04:15.000000000', 'files': ['rally/benchmark/scenarios/nova/utils.py', 'tests/benchmark/scenarios/nova/test_utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'tests/benchmark/scenarios/nova/test_servers.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b58310074f8720ae44f7589551eb45896beaa71e', 'message': 'Update the way hard & soft reboots are displayed in task result\n\nCurrently the task result output does not distinguish between\nnova hard and soft reboots. Following patch add this function.\nThe hard reboot will displayed as is nova.reboot_server and\nsoft reboot will be displayed as nova.soft_reboot_server.\n\nChange-Id: I22ea2ddcf5c1a58697286ff292fb6a2a5fcaaee6\nCloses-Bug:#1342138\n'}]",5,107339,b58310074f8720ae44f7589551eb45896beaa71e,27,4,5,11105,,,0,"Update the way hard & soft reboots are displayed in task result

Currently the task result output does not distinguish between
nova hard and soft reboots. Following patch add this function.
The hard reboot will displayed as is nova.reboot_server and
soft reboot will be displayed as nova.soft_reboot_server.

Change-Id: I22ea2ddcf5c1a58697286ff292fb6a2a5fcaaee6
Closes-Bug:#1342138
",git fetch https://review.opendev.org/openstack/rally refs/changes/39/107339/5 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/nova/utils.py', 'tests/benchmark/scenarios/nova/test_utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'tests/benchmark/scenarios/nova/test_servers.py']",4,a7ab76026facec9bcd32c7d721f20a3992a18468,bug/1342138," server_calls.append(mock.call(fake_server)) scenario._soft_reboot_server = mock.MagicMock() server_calls.append(mock.call(fake_server)) if soft: self.assertEqual(5, scenario._soft_reboot_server.call_count, ""Reboot not called 5 times"") scenario._soft_reboot_server.assert_has_calls(server_calls) else: self.assertEqual(5, scenario._reboot_server.call_count, ""Reboot not called 5 times"") scenario._reboot_server.assert_has_calls(server_calls)"," server_calls.append(mock.call(fake_server, soft=False)) server_calls.append(mock.call(fake_server, soft=soft)) self.assertEqual(5, scenario._reboot_server.call_count, ""Reboot not called 5 times"") scenario._reboot_server.assert_has_calls(server_calls)",50,14
openstack%2Ftrove~master~I97fb0f63b595409d8d4c01f09fdae608c2769d5a,openstack/trove,master,I97fb0f63b595409d8d4c01f09fdae608c2769d5a,datastore opts loaded with module entrypoint,ABANDONED,2014-03-12 19:38:33.000000000,2014-07-17 08:55:37.000000000,,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 1925}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 7092}, {'_account_id': 7799}, {'_account_id': 8214}, {'_account_id': 8310}, {'_account_id': 8311}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 10396}]","[{'number': 1, 'created': '2014-03-12 19:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a62997bb1415d8b4618b7c97afe4d17475ad02e8', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]datastore_options\n   for trove-taskmanger.conf or similar configuration files,\n   which are loaded with --config-file= in command line.\n\n   For an experimental datastore perspective,\n   options may be loaded without touching cfg.py\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 2, 'created': '2014-03-12 19:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a10fe6192bbc3553fb99e5ffbdefbb0584cdcca5', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]datastore_options\n   for trove-taskmanger.conf or similar configuration files,\n   which are loaded with --config-file= in command line.\n\n   For an experimental datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding datastore_options in the conf file itself.\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 3, 'created': '2014-03-12 20:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/fc2b48c185d8d8663281b5bcb3b196c18ed11968', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]datastore_options\n   for trove-taskmanger.conf or similar configuration files,\n   which are loaded with --config-file= in command line.\n\n   For an experimental datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding datastore_options in the conf file itself.\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 4, 'created': '2014-03-14 12:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4a66c02095cdc97af5b02d5635709071529c1654', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]datastore_options\n   for trove-taskmanger.conf or similar configuration files,\n   which are loaded with --config-file= in command line.\n\n   For an experimental datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding datastore_options in the conf file itself.\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 6, 'created': '2014-03-14 19:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d944355e571a1f2b64c1ceb73488cc9bd926ee98', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]datastore_options\n   for trove-taskmanger.conf or similar configuration files,\n   which are loaded with --config-file= in command line.\n\n   For an experimental datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding datastore_options in the conf file itself.\n\nImplements: blueprint refactoring-datastore-options-in-cfg\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 5, 'created': '2014-03-14 19:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/144a8ffd8b594a77dd9a9453f466954042e46670', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]datastore_options\n   for trove-taskmanger.conf or similar configuration files,\n   which are loaded with --config-file= in command line.\n\n   For an experimental datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding datastore_options in the conf file itself.\n\nImplements: blueprint refactoring-datastore-options-in-cfg\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 7, 'created': '2014-04-04 11:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c0ed9fec784819e8f12a976223150a36badbdde0', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]datastore_options\n   for trove-taskmanger.conf or similar configuration files,\n   which are loaded with --config-file= in command line.\n\n   For an experimental datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding datastore_options in the conf file itself.\n\nImplements: blueprint refactoring-datastore-options-in-cfg\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 8, 'created': '2014-04-10 06:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/770015fe10d3907ac7322802f5d85dc75922416a', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]datastore_options\n   for trove-taskmanger.conf or similar configuration files,\n   which are loaded with --config-file= in command line.\n\n   For an experimental datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding datastore_options in the conf file itself.\n\nImplements: blueprint refactoring-datastore-options-in-cfg\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 9, 'created': '2014-04-10 07:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e4e1cbad9df98a38ee055c40c57a634581202b9a', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]datastore_options\n   for trove-taskmanger.conf or similar configuration files,\n   which are loaded with --config-file= in command line.\n\n   For an experimental datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding datastore_options in the conf file itself.\n\nImplements: blueprint refactoring-datastore-options-in-cfg\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 10, 'created': '2014-04-10 08:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f48cf5a3069b7796c39cf1b3eac49748d70db35e', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]custom_datastore_options\n   for trove-taskmanger.conf and trove-api.conf,\n   which are loaded with --config-file= in command line.\n\n   For an experimental/custom datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding custom_datastore_options in the conf file itself.\n\nImplements: blueprint refactoring-datastore-options-in-cfg\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 11, 'created': '2014-04-10 08:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/49341cca0e2b6a80b874e4adbbac871738106168', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]custom_datastore_options\n   for trove-taskmanger.conf and trove.conf,\n   which are loaded with --config-file= in command line.\n\n   For an experimental/custom datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding custom_datastore_options in the conf file itself.\n\nImplements: blueprint refactoring-datastore-options-in-cfg\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 12, 'created': '2014-04-10 08:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0ceebf877452e844c745be9eaa92f666698b810a', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]custom_datastore_options\n   for trove-taskmanger.conf and trove.conf,\n   which are loaded with --config-file= in command line.\n\n   For an experimental/custom datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding custom_datastore_options in the conf file itself.\n\nImplements: blueprint refactoring-datastore-options-in-cfg\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 13, 'created': '2014-04-10 09:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a84a31fc54dca63586970823efcf59fa7e0133b7', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]custom_datastore_options\n   for trove-taskmanger.conf and trove.conf,\n   which are loaded with --config-file= in command line.\n\n   For an experimental/custom datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding custom_datastore_options in the conf file itself.\n\nImplements: blueprint refactoring-datastore-options-in-cfg\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}, {'number': 14, 'created': '2014-04-10 09:33:57.000000000', 'files': ['trove/guestagent/datastore/mongodb/options.py', 'trove/common/cfg.py', 'etc/trove/trove-taskmanager.conf.sample', 'trove/guestagent/datastore/mysql/options.py', 'trove/guestagent/datastore/redis/options.py', 'etc/trove/trove.conf.sample', 'trove/guestagent/datastore/couchbase/options.py', 'trove/guestagent/datastore/cassandra/options.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/0666d97c170365b6f5ae4bfeff70f387079c82c9', 'message': 'datastore opts loaded with module entrypoint\n\noptions related to a datastore may be loaded from\na module entrypoint which gives the following enhancement\n\n1. Keeps the same behaviour with existing code\n\n2. Enables the config variable [DEFAULT]custom_datastore_options\n   for trove-taskmanger.conf and trove.conf,\n   which are loaded with --config-file= in command line.\n\n   For an experimental/custom datastore perspective,\n   options may be loaded without touching cfg.py\n   by adding custom_datastore_options in the conf file itself.\n\nImplements: blueprint refactoring-datastore-options-in-cfg\n\nChange-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a\n'}]",16,80061,0666d97c170365b6f5ae4bfeff70f387079c82c9,65,14,14,8311,,,0,"datastore opts loaded with module entrypoint

options related to a datastore may be loaded from
a module entrypoint which gives the following enhancement

1. Keeps the same behaviour with existing code

2. Enables the config variable [DEFAULT]custom_datastore_options
   for trove-taskmanger.conf and trove.conf,
   which are loaded with --config-file= in command line.

   For an experimental/custom datastore perspective,
   options may be loaded without touching cfg.py
   by adding custom_datastore_options in the conf file itself.

Implements: blueprint refactoring-datastore-options-in-cfg

Change-Id: I97fb0f63b595409d8d4c01f09fdae608c2769d5a
",git fetch https://review.opendev.org/openstack/trove refs/changes/61/80061/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/cfg.py', 'trove/guestagent/datastore/mongodb/options.py', 'trove/guestagent/datastore/mysql/options.py', 'trove/guestagent/datastore/redis/options.py', 'trove/guestagent/datastore/couchbase/options.py', 'trove/guestagent/datastore/cassandra/options.py']",6,a62997bb1415d8b4618b7c97afe4d17475ad02e8,bp/refactoring-datastore-options-in-cfg,"from oslo.config import cfg # Cassandra cassandra_group = cfg.OptGroup( 'cassandra', title='Cassandra options', help=""Oslo option group designed for Cassandra datastore"") cassandra_opts = [ cfg.ListOpt('tcp_ports', default=[""7000"", ""7001"", ""9042"", ""9160""], help='List of TCP ports and/or port ranges to open' ' in the security group (only applicable ' 'if trove_security_groups_support is True)'), cfg.ListOpt('udp_ports', default=[], help='List of UDP ports and/or port ranges to open' ' in the security group (only applicable ' 'if trove_security_groups_support is True)'), cfg.StrOpt('backup_strategy', default=None, help='Default strategy to perform backups.'), cfg.StrOpt('mount_point', default='/var/lib/cassandra', help=""Filesystem path for mounting "" ""volumes if volume support is enabled""), ] CONF = cfg.CONF CONF.register_group(cassandra_group) CONF.register_opts(cassandra_opts, cassandra_group) ",,178,149
openstack%2Fopenstack-manuals~master~I5b17fea3e322483310ec5d07b755d80fc25759ce,openstack/openstack-manuals,master,I5b17fea3e322483310ec5d07b755d80fc25759ce,"Correct the return of ""keystone service-create""",MERGED,2014-07-14 11:13:16.000000000,2014-07-17 08:48:45.000000000,2014-07-17 08:48:44.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 8290}]","[{'number': 1, 'created': '2014-07-14 11:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4e06774515660b62ee06397389cdf63fe4e0bcd9', 'message': 'Correct the return of ""keystone service-create""\n\nIn keystone-service documentation, the return of ""keystone service-create""\nis missing ""enabled"" field, this change fix it.\nAdditionally, this change fix some aligning error of this documentation.\n\nChange-Id: I5b17fea3e322483310ec5d07b755d80fc25759ce\nCloses-Bug: #1341184\n'}, {'number': 2, 'created': '2014-07-15 01:45:23.000000000', 'files': ['doc/install-guide/section_keystone-services.xml', 'doc/common/section_cli_keystone_services.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/445f93e1d7e1798ea6e2f55fed7955b8b2b68dda', 'message': 'Correct the return of ""keystone service-create""\n\nIn keystone-service documentation, the return of ""keystone service-create""\nis missing ""enabled"" field, this change fix it.\nAdditionally, this change fix some aligning error of this\ndocumentation, and redundant return of ""keystone service-delete""\n\nChange-Id: I5b17fea3e322483310ec5d07b755d80fc25759ce\nCloses-Bug: #1341184\n'}]",0,106735,445f93e1d7e1798ea6e2f55fed7955b8b2b68dda,17,5,2,8290,,,0,"Correct the return of ""keystone service-create""

In keystone-service documentation, the return of ""keystone service-create""
is missing ""enabled"" field, this change fix it.
Additionally, this change fix some aligning error of this
documentation, and redundant return of ""keystone service-delete""

Change-Id: I5b17fea3e322483310ec5d07b755d80fc25759ce
Closes-Bug: #1341184
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/35/106735/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_keystone-services.xml'],1,4e06774515660b62ee06397389cdf63fe4e0bcd9,bug/1341184,| enabled | True | | id | 15c11a23667e427e91bc31335b45f4bd | | name | keystone | | type | identity || adminurl | http://controller:35357/v2.0 | | id | 11f9c625a3b94a3f8e66bf4e5de2679f || publicurl | http://controller:5000/v2.0 | | region | regionOne | | service_id | 15c11a23667e427e91bc31335b45f4bd |,| id | 15c11a23667e427e91bc31335b45f4bd | | name | keystone | | type | identity || adminurl | http://controller:35357/v2.0 | | id | 11f9c625a3b94a3f8e66bf4e5de2679f || publicurl | http://controller:5000/v2.0 | | region | regionOne | | service_id | 15c11a23667e427e91bc31335b45f4bd |,9,8
openstack%2Fopenstack-manuals~master~I112b0754ef3de09420a9e06d01868ac683906b73,openstack/openstack-manuals,master,I112b0754ef3de09420a9e06d01868ac683906b73,Imported Translations from Transifex,MERGED,2014-07-17 06:10:11.000000000,2014-07-17 08:48:08.000000000,2014-07-17 08:48:07.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-07-17 06:10:11.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/common/locale/common.pot', 'doc/high-availability-guide/locale/ja.po', 'doc/high-availability-guide/locale/high-availability-guide.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po', 'doc/glossary/locale/glossary.pot'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/be0279df940413b335f147a293d252e01ccc8e3c', 'message': 'Imported Translations from Transifex\n\nChange-Id: I112b0754ef3de09420a9e06d01868ac683906b73\n'}]",0,107567,be0279df940413b335f147a293d252e01ccc8e3c,8,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I112b0754ef3de09420a9e06d01868ac683906b73
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/67/107567/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/common/locale/common.pot', 'doc/high-availability-guide/locale/ja.po', 'doc/high-availability-guide/locale/high-availability-guide.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po', 'doc/glossary/locale/glossary.pot']",11,be0279df940413b335f147a293d252e01ccc8e3c,transifex/translations,"""POT-Creation-Date: 2014-07-17 06:09+0000\n""#: ./doc/glossary/glossary-terms.xml:13(title)#: ./doc/glossary/glossary-terms.xml:16(para)#: ./doc/glossary/glossary-terms.xml:23(link)#: ./doc/glossary/glossary-terms.xml:25(para)#: ./doc/glossary/glossary-terms.xml:37(title)#: ./doc/glossary/glossary-terms.xml:41(primary)#: ./doc/glossary/glossary-terms.xml:40(glossterm)#: ./doc/glossary/glossary-terms.xml:45(para)#: ./doc/glossary/glossary-terms.xml:52(primary)#: ./doc/glossary/glossary-terms.xml:51(glossterm)#: ./doc/glossary/glossary-terms.xml:56(para)#: ./doc/glossary/glossary-terms.xml:67(primary)#: ./doc/glossary/glossary-terms.xml:66(glossterm)#: ./doc/glossary/glossary-terms.xml:71(para)#: ./doc/glossary/glossary-terms.xml:78(primary)#: ./doc/glossary/glossary-terms.xml:77(glossterm)#: ./doc/glossary/glossary-terms.xml:82(para)#: ./doc/glossary/glossary-terms.xml:90(primary)#: ./doc/glossary/glossary-terms.xml:89(glossterm)#: ./doc/glossary/glossary-terms.xml:94(para)#: ./doc/glossary/glossary-terms.xml:102(primary)#: ./doc/glossary/glossary-terms.xml:101(glossterm)#: ./doc/glossary/glossary-terms.xml:106(para)#: ./doc/glossary/glossary-terms.xml:113(primary)#: ./doc/glossary/glossary-terms.xml:112(glossterm)#: ./doc/glossary/glossary-terms.xml:117(para)#: ./doc/glossary/glossary-terms.xml:124(primary)#: ./doc/glossary/glossary-terms.xml:123(glossterm)#: ./doc/glossary/glossary-terms.xml:128(para)#: ./doc/glossary/glossary-terms.xml:135(primary)#: ./doc/glossary/glossary-terms.xml:134(glossterm)#: ./doc/glossary/glossary-terms.xml:139(para)#: ./doc/glossary/glossary-terms.xml:147(primary)#: ./doc/glossary/glossary-terms.xml:146(glossterm)#: ./doc/glossary/glossary-terms.xml:151(para)#: ./doc/glossary/glossary-terms.xml:158(primary)#: ./doc/glossary/glossary-terms.xml:160(see)#: ./doc/glossary/glossary-terms.xml:157(glossterm)#: ./doc/glossary/glossary-terms.xml:164(para)#: ./doc/glossary/glossary-terms.xml:170(primary)#: ./doc/glossary/glossary-terms.xml:169(glossterm)#: ./doc/glossary/glossary-terms.xml:174(para)#: ./doc/glossary/glossary-terms.xml:182(primary)#: ./doc/glossary/glossary-terms.xml:181(glossterm)#: ./doc/glossary/glossary-terms.xml:186(para)#: ./doc/glossary/glossary-terms.xml:193(primary)#: ./doc/glossary/glossary-terms.xml:192(glossterm)#: ./doc/glossary/glossary-terms.xml:197(para)#: ./doc/glossary/glossary-terms.xml:205(primary)#: ./doc/glossary/glossary-terms.xml:204(glossterm)#: ./doc/glossary/glossary-terms.xml:209(para)#: ./doc/glossary/glossary-terms.xml:217(primary) ./doc/glossary/glossary-terms.xml:4268(see)#: ./doc/glossary/glossary-terms.xml:216(glossterm)#: ./doc/glossary/glossary-terms.xml:221(para)#: ./doc/glossary/glossary-terms.xml:230(primary)#: ./doc/glossary/glossary-terms.xml:229(glossterm)#: ./doc/glossary/glossary-terms.xml:234(para)#: ./doc/glossary/glossary-terms.xml:242(primary)#: ./doc/glossary/glossary-terms.xml:240(glossterm)#: ./doc/glossary/glossary-terms.xml:246(para)#: ./doc/glossary/glossary-terms.xml:254(primary)#: ./doc/glossary/glossary-terms.xml:253(glossterm)#: ./doc/glossary/glossary-terms.xml:258(para)#: ./doc/glossary/glossary-terms.xml:265(primary)#: ./doc/glossary/glossary-terms.xml:267(secondary) ./doc/glossary/glossary-terms.xml:757(secondary) ./doc/glossary/glossary-terms.xml:802(secondary) ./doc/glossary/glossary-terms.xml:852(secondary) ./doc/glossary/glossary-terms.xml:1095(secondary) ./doc/glossary/glossary-terms.xml:1177(secondary) ./doc/glossary/glossary-terms.xml:1371(secondary) ./doc/glossary/glossary-terms.xml:1463(secondary) ./doc/glossary/glossary-terms.xml:1537(secondary) ./doc/glossary/glossary-terms.xml:1589(secondary) ./doc/glossary/glossary-terms.xml:1680(secondary) ./doc/glossary/glossary-terms.xml:1878(secondary) ./doc/glossary/glossary-terms.xml:2109(secondary) ./doc/glossary/glossary-terms.xml:2750(secondary) ./doc/glossary/glossary-terms.xml:2858(secondary) ./doc/glossary/glossary-terms.xml:3422(secondary) ./doc/glossary/glossary-terms.xml:3471(secondary) ./doc/glossary/glossary-terms.xml:3569(secondary) ./doc/glossary/glossary-terms.xml:3771(secondary) ./doc/glossary/glossary-terms.xml:3902(secondary) ./doc/glossary/glossary-terms.xml:4302(secondary) ./doc/glossary/glossary-terms.xml:4585(secondary) ./doc/glossary/glossary-terms.xml:4821(secondary) ./doc/glossary/glossary-terms.xml:4915(secondary) ./doc/glossary/glossary-terms.xml:5216(secondary) ./doc/glossary/glossary-terms.xml:5375(secondary) ./doc/glossary/glossary-terms.xml:5458(secondary) ./doc/glossary/glossary-terms.xml:5982(secondary) ./doc/glossary/glossary-terms.xml:6078(secondary) ./doc/glossary/glossary-terms.xml:6119(secondary) ./doc/glossary/glossary-terms.xml:6364(secondary) ./doc/glossary/glossary-terms.xml:6404(secondary)#: ./doc/glossary/glossary-terms.xml:264(glossterm)#: ./doc/glossary/glossary-terms.xml:271(para)#: ./doc/glossary/glossary-terms.xml:280(primary)#: ./doc/glossary/glossary-terms.xml:279(glossterm)#: ./doc/glossary/glossary-terms.xml:284(para)#: ./doc/glossary/glossary-terms.xml:292(primary)#: ./doc/glossary/glossary-terms.xml:291(glossterm)#: ./doc/glossary/glossary-terms.xml:296(para) ./doc/glossary/glossary-terms.xml:307(para) ./doc/glossary/glossary-terms.xml:318(para)#: ./doc/glossary/glossary-terms.xml:303(primary)#: ./doc/glossary/glossary-terms.xml:302(glossterm)#: ./doc/glossary/glossary-terms.xml:314(primary)#: ./doc/glossary/glossary-terms.xml:313(glossterm)#: ./doc/glossary/glossary-terms.xml:325(primary)#: ./doc/glossary/glossary-terms.xml:324(glossterm)#: ./doc/glossary/glossary-terms.xml:329(para)#: ./doc/glossary/glossary-terms.xml:336(primary)#: ./doc/glossary/glossary-terms.xml:335(glossterm)#: ./doc/glossary/glossary-terms.xml:340(para)#: ./doc/glossary/glossary-terms.xml:348(primary)#: ./doc/glossary/glossary-terms.xml:347(glossterm)#: ./doc/glossary/glossary-terms.xml:352(para)#: ./doc/glossary/glossary-terms.xml:359(primary)#: ./doc/glossary/glossary-terms.xml:358(glossterm)#: ./doc/glossary/glossary-terms.xml:363(para)#: ./doc/glossary/glossary-terms.xml:369(glossterm)#: ./doc/glossary/glossary-terms.xml:372(para)#: ./doc/glossary/glossary-terms.xml:378(primary) ./doc/glossary/glossary-terms.xml:2525(primary) ./doc/glossary/glossary-terms.xml:2537(primary) ./doc/glossary/glossary-terms.xml:3111(primary) ./doc/glossary/glossary-terms.xml:7063(primary)#: ./doc/glossary/glossary-terms.xml:380(secondary) ./doc/glossary/glossary-terms.xml:384(secondary)#: ./doc/glossary/glossary-terms.xml:382(primary) ./doc/glossary/glossary-terms.xml:397(primary) ./doc/glossary/glossary-terms.xml:409(primary) ./doc/glossary/glossary-terms.xml:422(primary) ./doc/glossary/glossary-terms.xml:434(primary) ./doc/glossary/glossary-terms.xml:447(primary) ./doc/glossary/glossary-terms.xml:460(primary) ./doc/glossary/glossary-terms.xml:5561(primary)#: ./doc/glossary/glossary-terms.xml:377(glossterm)#: ./doc/glossary/glossary-terms.xml:388(para)#: ./doc/glossary/glossary-terms.xml:399(secondary)#: ./doc/glossary/glossary-terms.xml:396(glossterm)#: ./doc/glossary/glossary-terms.xml:403(para)#: ./doc/glossary/glossary-terms.xml:411(secondary)#: ./doc/glossary/glossary-terms.xml:408(glossterm)#: ./doc/glossary/glossary-terms.xml:415(para)#: ./doc/glossary/glossary-terms.xml:424(secondary)#: ./doc/glossary/glossary-terms.xml:421(glossterm)#: ./doc/glossary/glossary-terms.xml:428(para)#: ./doc/glossary/glossary-terms.xml:436(secondary)#: ./doc/glossary/glossary-terms.xml:433(glossterm)#: ./doc/glossary/glossary-terms.xml:440(para)#: ./doc/glossary/glossary-terms.xml:449(secondary)#: ./doc/glossary/glossary-terms.xml:446(glossterm)#: ./doc/glossary/glossary-terms.xml:453(para)#: ./doc/glossary/glossary-terms.xml:462(secondary)#: ./doc/glossary/glossary-terms.xml:459(glossterm)#: ./doc/glossary/glossary-terms.xml:466(para)#: ./doc/glossary/glossary-terms.xml:473(primary)#: ./doc/glossary/glossary-terms.xml:472(glossterm)#: ./doc/glossary/glossary-terms.xml:477(para)#: ./doc/glossary/glossary-terms.xml:482(glossterm)#: ./doc/glossary/glossary-terms.xml:485(para)#: ./doc/glossary/glossary-terms.xml:493(primary) ./doc/glossary/glossary-terms.xml:5545(primary) ./doc/glossary/glossary-terms.xml:5941(primary) ./doc/glossary/glossary-terms.xml:6362(primary) ./doc/glossary/glossary-terms.xml:6389(primary) ./doc/glossary/glossary-terms.xml:7462(primary)#: ./doc/glossary/glossary-terms.xml:495(secondary)#: ./doc/glossary/glossary-terms.xml:497(primary)#: ./doc/glossary/glossary-terms.xml:492(glossterm)#: ./doc/glossary/glossary-terms.xml:501(para)#: ./doc/glossary/glossary-terms.xml:508(primary)#: ./doc/glossary/glossary-terms.xml:507(glossterm)#: ./doc/glossary/glossary-terms.xml:512(para)#: ./doc/glossary/glossary-terms.xml:520(primary)#: ./doc/glossary/glossary-terms.xml:519(glossterm)#: ./doc/glossary/glossary-terms.xml:524(para)#: ./doc/glossary/glossary-terms.xml:533(primary)#: ./doc/glossary/glossary-terms.xml:532(glossterm)#: ./doc/glossary/glossary-terms.xml:537(para)#: ./doc/glossary/glossary-terms.xml:545(primary)#: ./doc/glossary/glossary-terms.xml:543(glossterm)#: ./doc/glossary/glossary-terms.xml:549(para)#: ./doc/glossary/glossary-terms.xml:557(primary)#: ./doc/glossary/glossary-terms.xml:556(glossterm)#: ./doc/glossary/glossary-terms.xml:561(para)#: ./doc/glossary/glossary-terms.xml:567(primary)#: ./doc/glossary/glossary-terms.xml:566(glossterm)#: ./doc/glossary/glossary-terms.xml:571(para)#: ./doc/glossary/glossary-terms.xml:579(primary)#: ./doc/glossary/glossary-terms.xml:578(glossterm)#: ./doc/glossary/glossary-terms.xml:583(para)#: ./doc/glossary/glossary-terms.xml:590(primary)#: ./doc/glossary/glossary-terms.xml:589(glossterm)#: ./doc/glossary/glossary-terms.xml:594(para)#: ./doc/glossary/glossary-terms.xml:601(primary)#: ./doc/glossary/glossary-terms.xml:600(glossterm)#: ./doc/glossary/glossary-terms.xml:605(para)#: ./doc/glossary/glossary-terms.xml:614(primary)#: ./doc/glossary/glossary-terms.xml:613(glossterm)#: ./doc/glossary/glossary-terms.xml:618(para)#: ./doc/glossary/glossary-terms.xml:626(primary)#: ./doc/glossary/glossary-terms.xml:625(glossterm)#: ./doc/glossary/glossary-terms.xml:630(para)#: ./doc/glossary/glossary-terms.xml:637(primary)#: ./doc/glossary/glossary-terms.xml:636(glossterm)#: ./doc/glossary/glossary-terms.xml:641(para)#: ./doc/glossary/glossary-terms.xml:649(primary)#: ./doc/glossary/glossary-terms.xml:648(glossterm)#: ./doc/glossary/glossary-terms.xml:653(para)#: ./doc/glossary/glossary-terms.xml:661(primary)#: ./doc/glossary/glossary-terms.xml:660(glossterm)#: ./doc/glossary/glossary-terms.xml:665(para)#: ./doc/glossary/glossary-terms.xml:672(primary)#: ./doc/glossary/glossary-terms.xml:671(glossterm)#: ./doc/glossary/glossary-terms.xml:676(para)#: ./doc/glossary/glossary-terms.xml:683(primary)#: ./doc/glossary/glossary-terms.xml:682(glossterm)#: ./doc/glossary/glossary-terms.xml:687(para)#: ./doc/glossary/glossary-terms.xml:694(primary)#: ./doc/glossary/glossary-terms.xml:693(glossterm)#: ./doc/glossary/glossary-terms.xml:698(para)#: ./doc/glossary/glossary-terms.xml:705(primary)#: ./doc/glossary/glossary-terms.xml:704(glossterm)#: ./doc/glossary/glossary-terms.xml:709(para)#: ./doc/glossary/glossary-terms.xml:716(primary)#: ./doc/glossary/glossary-terms.xml:715(glossterm)#: ./doc/glossary/glossary-terms.xml:720(para)#: ./doc/glossary/glossary-terms.xml:727(primary)#: ./doc/glossary/glossary-terms.xml:726(glossterm)#: ./doc/glossary/glossary-terms.xml:731(para)#: ./doc/glossary/glossary-terms.xml:739(primary)#: ./doc/glossary/glossary-terms.xml:738(glossterm)#: ./doc/glossary/glossary-terms.xml:743(para)#: ./doc/glossary/glossary-terms.xml:751(title)#: ./doc/glossary/glossary-terms.xml:755(primary) ./doc/glossary/glossary-terms.xml:769(primary) ./doc/glossary/glossary-terms.xml:784(primary)#: ./doc/glossary/glossary-terms.xml:754(glossterm)#: ./doc/glossary/glossary-terms.xml:761(para)#: ./doc/glossary/glossary-terms.xml:771(secondary) ./doc/glossary/glossary-terms.xml:1141(primary)#: ./doc/glossary/glossary-terms.xml:768(glossterm)#: ./doc/glossary/glossary-terms.xml:775(para)#: ./doc/glossary/glossary-terms.xml:786(secondary)#: ./doc/glossary/glossary-terms.xml:783(glossterm)#: ./doc/glossary/glossary-terms.xml:790(para) msgid ""The persistent data store used to save and retrieve information for a service, such as lists of Object Storage objects, current state of guest VMs, lists of user names, and so on. Also, the method that the Image Service uses to get and store VM images. Options include Object Storage, local file system, S3, and HTTP.""#: ./doc/glossary/glossary-terms.xml:800(primary)#: ./doc/glossary/glossary-terms.xml:799(glossterm)#: ./doc/glossary/glossary-terms.xml:806(para)#: ./doc/glossary/glossary-terms.xml:814(primary)#: ./doc/glossary/glossary-terms.xml:813(glossterm)#: ./doc/glossary/glossary-terms.xml:818(para)#: ./doc/glossary/glossary-terms.xml:825(primary)#: ./doc/glossary/glossary-terms.xml:824(glossterm)#: ./doc/glossary/glossary-terms.xml:829(para)#: ./doc/glossary/glossary-terms.xml:835(primary)#: ./doc/glossary/glossary-terms.xml:834(glossterm)#: ./doc/glossary/glossary-terms.xml:839(para)#: ./doc/glossary/glossary-terms.xml:842(para)#: ./doc/glossary/glossary-terms.xml:850(primary)#: ./doc/glossary/glossary-terms.xml:849(glossterm)#: ./doc/glossary/glossary-terms.xml:856(para)#: ./doc/glossary/glossary-terms.xml:863(primary)#: ./doc/glossary/glossary-terms.xml:862(glossterm)#: ./doc/glossary/glossary-terms.xml:867(para)#: ./doc/glossary/glossary-terms.xml:874(primary)#: ./doc/glossary/glossary-terms.xml:873(glossterm)#: ./doc/glossary/glossary-terms.xml:878(para)#: ./doc/glossary/glossary-terms.xml:885(primary)#: ./doc/glossary/glossary-terms.xml:884(glossterm)#: ./doc/glossary/glossary-terms.xml:889(para)#: ./doc/glossary/glossary-terms.xml:897(primary)#: ./doc/glossary/glossary-terms.xml:896(glossterm)#: ./doc/glossary/glossary-terms.xml:901(para)#: ./doc/glossary/glossary-terms.xml:910(primary)#: ./doc/glossary/glossary-terms.xml:909(glossterm)#: ./doc/glossary/glossary-terms.xml:914(para)#: ./doc/glossary/glossary-terms.xml:922(primary)#: ./doc/glossary/glossary-terms.xml:921(glossterm)#: ./doc/glossary/glossary-terms.xml:926(para)#: ./doc/glossary/glossary-terms.xml:934(primary)#: ./doc/glossary/glossary-terms.xml:933(glossterm)#: ./doc/glossary/glossary-terms.xml:938(para)#: ./doc/glossary/glossary-terms.xml:948(primary)#: ./doc/glossary/glossary-terms.xml:947(glossterm)#: ./doc/glossary/glossary-terms.xml:952(para)#: ./doc/glossary/glossary-terms.xml:959(primary)#: ./doc/glossary/glossary-terms.xml:958(glossterm)#: ./doc/glossary/glossary-terms.xml:963(para)#: ./doc/glossary/glossary-terms.xml:972(primary)#: ./doc/glossary/glossary-terms.xml:971(glossterm)#: ./doc/glossary/glossary-terms.xml:976(para)#: ./doc/glossary/glossary-terms.xml:983(primary)#: ./doc/glossary/glossary-terms.xml:982(glossterm)#: ./doc/glossary/glossary-terms.xml:987(para)#: ./doc/glossary/glossary-terms.xml:995(primary)#: ./doc/glossary/glossary-terms.xml:994(glossterm)#: ./doc/glossary/glossary-terms.xml:999(para)#: ./doc/glossary/glossary-terms.xml:1008(primary)#: ./doc/glossary/glossary-terms.xml:1007(glossterm)#: ./doc/glossary/glossary-terms.xml:1012(para)#: ./doc/glossary/glossary-terms.xml:1021(title)#: ./doc/glossary/glossary-terms.xml:1025(primary)#: ./doc/glossary/glossary-terms.xml:1024(glossterm)#: ./doc/glossary/glossary-terms.xml:1029(para)#: ./doc/glossary/glossary-terms.xml:1044(primary)#: ./doc/glossary/glossary-terms.xml:1043(glossterm)#: ./doc/glossary/glossary-terms.xml:1048(para)#: ./doc/glossary/glossary-terms.xml:1055(primary)#: ./doc/glossary/glossary-terms.xml:1054(glossterm)#: ./doc/glossary/glossary-terms.xml:1059(para)#: ./doc/glossary/glossary-terms.xml:1062(para)#: ./doc/glossary/glossary-terms.xml:1070(glossterm)#: ./doc/glossary/glossary-terms.xml:1072(para)#: ./doc/glossary/glossary-terms.xml:1082(primary)#: ./doc/glossary/glossary-terms.xml:1081(glossterm)#: ./doc/glossary/glossary-terms.xml:1086(para)#: ./doc/glossary/glossary-terms.xml:1093(primary)#: ./doc/glossary/glossary-terms.xml:1092(glossterm)#: ./doc/glossary/glossary-terms.xml:1099(para)#: ./doc/glossary/glossary-terms.xml:1107(primary)#: ./doc/glossary/glossary-terms.xml:1106(glossterm)#: ./doc/glossary/glossary-terms.xml:1111(para)#: ./doc/glossary/glossary-terms.xml:1119(primary)#: ./doc/glossary/glossary-terms.xml:1118(glossterm)#: ./doc/glossary/glossary-terms.xml:1123(para)#: ./doc/glossary/glossary-terms.xml:1130(primary)#: ./doc/glossary/glossary-terms.xml:1129(glossterm)#: ./doc/glossary/glossary-terms.xml:1134(para)#: ./doc/glossary/glossary-terms.xml:1140(glossterm)#: ./doc/glossary/glossary-terms.xml:1145(para)#: ./doc/glossary/glossary-terms.xml:1152(primary)#: ./doc/glossary/glossary-terms.xml:1151(glossterm)#: ./doc/glossary/glossary-terms.xml:1156(para)#: ./doc/glossary/glossary-terms.xml:1163(primary)#: ./doc/glossary/glossary-terms.xml:1162(glossterm)#: ./doc/glossary/glossary-terms.xml:1167(para)#: ./doc/glossary/glossary-terms.xml:1175(primary) ./doc/glossary/glossary-terms.xml:1190(primary) ./doc/glossary/glossary-terms.xml:1204(primary) ./doc/glossary/glossary-terms.xml:1307(primary) ./doc/glossary/glossary-terms.xml:5198(primary)#: ./doc/glossary/glossary-terms.xml:1174(glossterm)#: ./doc/glossary/glossary-terms.xml:1181(para)#: ./doc/glossary/glossary-terms.xml:1192(secondary)#: ./doc/glossary/glossary-terms.xml:1189(glossterm)#: ./doc/glossary/glossary-terms.xml:1196(para)#: ./doc/glossary/glossary-terms.xml:1206(secondary)#: ./doc/glossary/glossary-terms.xml:1203(glossterm)#: ./doc/glossary/glossary-terms.xml:1210(para)#: ./doc/glossary/glossary-terms.xml:1218(primary)#: ./doc/glossary/glossary-terms.xml:1217(glossterm)#: ./doc/glossary/glossary-terms.xml:1222(para) ./doc/glossary/glossary-terms.xml:1989(para) ./doc/glossary/glossary-terms.xml:5152(para) ./doc/glossary/glossary-terms.xml:5901(para) ./doc/glossary/glossary-terms.xml:6848(para)#: ./doc/glossary/glossary-terms.xml:1228(primary)#: ./doc/glossary/glossary-terms.xml:1227(glossterm)#: ./doc/glossary/glossary-terms.xml:1232(para)#: ./doc/glossary/glossary-terms.xml:1240(primary)#: ./doc/glossary/glossary-terms.xml:1239(glossterm)#: ./doc/glossary/glossary-terms.xml:1244(para)#: ./doc/glossary/glossary-terms.xml:1250(primary)#: ./doc/glossary/glossary-terms.xml:1249(glossterm)#: ./doc/glossary/glossary-terms.xml:1254(para)#: ./doc/glossary/glossary-terms.xml:1262(primary)#: ./doc/glossary/glossary-terms.xml:1260(glossterm)#: ./doc/glossary/glossary-terms.xml:1267(para)#: ./doc/glossary/glossary-terms.xml:1273(primary)#: ./doc/glossary/glossary-terms.xml:1272(glossterm)#: ./doc/glossary/glossary-terms.xml:1277(para)#: ./doc/glossary/glossary-terms.xml:1284(primary)#: ./doc/glossary/glossary-terms.xml:1283(glossterm)#: ./doc/glossary/glossary-terms.xml:1288(para)#: ./doc/glossary/glossary-terms.xml:1296(primary)#: ./doc/glossary/glossary-terms.xml:1295(glossterm)#: ./doc/glossary/glossary-terms.xml:1300(para)#: ./doc/glossary/glossary-terms.xml:1309(secondary) ./doc/glossary/glossary-terms.xml:1311(primary)#: ./doc/glossary/glossary-terms.xml:1306(glossterm)#: ./doc/glossary/glossary-terms.xml:1315(para)#: ./doc/glossary/glossary-terms.xml:1325(primary)#: ./doc/glossary/glossary-terms.xml:1324(glossterm)#: ./doc/glossary/glossary-terms.xml:1329(para)#: ./doc/glossary/glossary-terms.xml:1336(primary)#: ./doc/glossary/glossary-terms.xml:1335(glossterm)#: ./doc/glossary/glossary-terms.xml:1340(para)#: ./doc/glossary/glossary-terms.xml:1347(primary)#: ./doc/glossary/glossary-terms.xml:1346(glossterm)#: ./doc/glossary/glossary-terms.xml:1351(para)#: ./doc/glossary/glossary-terms.xml:1358(primary)#: ./doc/glossary/glossary-terms.xml:1357(glossterm)#: ./doc/glossary/glossary-terms.xml:1362(para)#: ./doc/glossary/glossary-terms.xml:1369(primary) ./doc/glossary/glossary-terms.xml:1384(primary) ./doc/glossary/glossary-terms.xml:1399(primary)#: ./doc/glossary/glossary-terms.xml:1368(glossterm)#: ./doc/glossary/glossary-terms.xml:1375(para)#: ./doc/glossary/glossary-terms.xml:1386(secondary)#: ./doc/glossary/glossary-terms.xml:1383(glossterm)#: ./doc/glossary/glossary-terms.xml:1390(para)#: ./doc/glossary/glossary-terms.xml:1401(secondary)#: ./doc/glossary/glossary-terms.xml:1398(glossterm)#: ./doc/glossary/glossary-terms.xml:1405(para)#: ./doc/glossary/glossary-terms.xml:1414(primary)#: ./doc/glossary/glossary-terms.xml:1412(glossterm)#: ./doc/glossary/glossary-terms.xml:1418(para)#: ./doc/glossary/glossary-terms.xml:1426(primary)#: ./doc/glossary/glossary-terms.xml:1424(glossterm)#: ./doc/glossary/glossary-terms.xml:1430(para)#: ./doc/glossary/glossary-terms.xml:1437(primary)#: ./doc/glossary/glossary-terms.xml:1436(glossterm)#: ./doc/glossary/glossary-terms.xml:1441(para)#: ./doc/glossary/glossary-terms.xml:1450(primary)#: ./doc/glossary/glossary-terms.xml:1449(glossterm)#: ./doc/glossary/glossary-terms.xml:1454(para)#: ./doc/glossary/glossary-terms.xml:1461(primary) ./doc/glossary/glossary-terms.xml:1474(primary)#: ./doc/glossary/glossary-terms.xml:1460(glossterm)#: ./doc/glossary/glossary-terms.xml:1467(para)#: ./doc/glossary/glossary-terms.xml:1476(secondary)#: ./doc/glossary/glossary-terms.xml:1473(glossterm)#: ./doc/glossary/glossary-terms.xml:1480(para)#: ./doc/glossary/glossary-terms.xml:1487(primary)#: ./doc/glossary/glossary-terms.xml:1486(glossterm)#: ./doc/glossary/glossary-terms.xml:1491(para)#: ./doc/glossary/glossary-terms.xml:1497(primary)#: ./doc/glossary/glossary-terms.xml:1496(glossterm)#: ./doc/glossary/glossary-terms.xml:1501(para)#: ./doc/glossary/glossary-terms.xml:1508(primary)#: ./doc/glossary/glossary-terms.xml:1507(glossterm)#: ./doc/glossary/glossary-terms.xml:1512(para)#: ./doc/glossary/glossary-terms.xml:1521(primary)#: ./doc/glossary/glossary-terms.xml:1520(glossterm)#: ./doc/glossary/glossary-terms.xml:1525(para)#: ./doc/glossary/glossary-terms.xml:1535(primary) ./doc/glossary/glossary-terms.xml:1548(primary) ./doc/glossary/glossary-terms.xml:1562(primary) ./doc/glossary/glossary-terms.xml:1575(primary) ./doc/glossary/glossary-terms.xml:1602(primary) ./doc/glossary/glossary-terms.xml:1614(primary)#: ./doc/glossary/glossary-terms.xml:1534(glossterm)#: ./doc/glossary/glossary-terms.xml:1541(para)#: ./doc/glossary/glossary-terms.xml:1550(secondary) ./doc/glossary/glossary-terms.xml:4883(secondary)#: ./doc/glossary/glossary-terms.xml:1547(glossterm)#: ./doc/glossary/glossary-terms.xml:1554(para)#: ./doc/glossary/glossary-terms.xml:1564(secondary)#: ./doc/glossary/glossary-terms.xml:1561(glossterm)#: ./doc/glossary/glossary-terms.xml:1568(para)#: ./doc/glossary/glossary-terms.xml:1577(secondary)#: ./doc/glossary/glossary-terms.xml:1574(glossterm)#: ./doc/glossary/glossary-terms.xml:1581(para)#: ./doc/glossary/glossary-terms.xml:1587(primary)#: ./doc/glossary/glossary-terms.xml:1586(glossterm)#: ./doc/glossary/glossary-terms.xml:1593(para)#: ./doc/glossary/glossary-terms.xml:1604(secondary)#: ./doc/glossary/glossary-terms.xml:1601(glossterm)#: ./doc/glossary/glossary-terms.xml:1608(para)#: ./doc/glossary/glossary-terms.xml:1616(secondary)#: ./doc/glossary/glossary-terms.xml:1613(glossterm)#: ./doc/glossary/glossary-terms.xml:1620(para)#: ./doc/glossary/glossary-terms.xml:1629(primary) ./doc/glossary/glossary-terms.xml:4313(primary) ./doc/glossary/glossary-terms.xml:4913(primary) ./doc/glossary/glossary-terms.xml:4926(primary) ./doc/glossary/glossary-terms.xml:4939(primary) ./doc/glossary/glossary-terms.xml:4953(primary) ./doc/glossary/glossary-terms.xml:4965(primary) ./doc/glossary/glossary-terms.xml:4978(primary) ./doc/glossary/glossary-terms.xml:4991(primary) ./doc/glossary/glossary-terms.xml:5042(primary) ./doc/glossary/glossary-terms.xml:6346(primary)#: ./doc/glossary/glossary-terms.xml:1631(secondary) ./doc/glossary/glossary-terms.xml:1633(primary)#: ./doc/glossary/glossary-terms.xml:1628(glossterm)#: ./doc/glossary/glossary-terms.xml:1637(para)#: ./doc/glossary/glossary-terms.xml:1644(primary)#: ./doc/glossary/glossary-terms.xml:1643(glossterm)#: ./doc/glossary/glossary-terms.xml:1648(para)#: ./doc/glossary/glossary-terms.xml:1657(primary)#: ./doc/glossary/glossary-terms.xml:1656(glossterm)#: ./doc/glossary/glossary-terms.xml:1661(para)#: ./doc/glossary/glossary-terms.xml:1668(primary)#: ./doc/glossary/glossary-terms.xml:1667(glossterm)#: ./doc/glossary/glossary-terms.xml:1672(para)#: ./doc/glossary/glossary-terms.xml:1678(primary) ./doc/glossary/glossary-terms.xml:1692(primary) ./doc/glossary/glossary-terms.xml:1706(primary) ./doc/glossary/glossary-terms.xml:1720(primary) ./doc/glossary/glossary-terms.xml:1734(primary) ./doc/glossary/glossary-terms.xml:1746(primary)#: ./doc/glossary/glossary-terms.xml:1677(glossterm)#: ./doc/glossary/glossary-terms.xml:1684(para)#: ./doc/glossary/glossary-terms.xml:1694(secondary)#: ./doc/glossary/glossary-terms.xml:1691(glossterm)#: ./doc/glossary/glossary-terms.xml:1698(para)#: ./doc/glossary/glossary-terms.xml:1708(secondary)#: ./doc/glossary/glossary-terms.xml:1705(glossterm)#: ./doc/glossary/glossary-terms.xml:1712(para)#: ./doc/glossary/glossary-terms.xml:1722(secondary)#: ./doc/glossary/glossary-terms.xml:1719(glossterm)#: ./doc/glossary/glossary-terms.xml:1726(para)#: ./doc/glossary/glossary-terms.xml:1736(secondary)#: ./doc/glossary/glossary-terms.xml:1733(glossterm)#: ./doc/glossary/glossary-terms.xml:1740(para)#: ./doc/glossary/glossary-terms.xml:1748(secondary)#: ./doc/glossary/glossary-terms.xml:1745(glossterm)#: ./doc/glossary/glossary-terms.xml:1752(para)#: ./doc/glossary/glossary-terms.xml:1759(primary)#: ./doc/glossary/glossary-terms.xml:1761(see)#: ./doc/glossary/glossary-terms.xml:1758(glossterm)#: ./doc/glossary/glossary-terms.xml:1765(para)#: ./doc/glossary/glossary-terms.xml:1771(primary)#: ./doc/glossary/glossary-terms.xml:1770(glossterm)#: ./doc/glossary/glossary-terms.xml:1775(para)#: ./doc/glossary/glossary-terms.xml:1783(primary)#: ./doc/glossary/glossary-terms.xml:1782(glossterm)#: ./doc/glossary/glossary-terms.xml:1787(para)#: ./doc/glossary/glossary-terms.xml:1799(primary)#: ./doc/glossary/glossary-terms.xml:1798(glossterm)#: ./doc/glossary/glossary-terms.xml:1803(para)#: ./doc/glossary/glossary-terms.xml:1811(primary)#: ./doc/glossary/glossary-terms.xml:1810(glossterm)#: ./doc/glossary/glossary-terms.xml:1815(para)#: ./doc/glossary/glossary-terms.xml:1824(primary)#: ./doc/glossary/glossary-terms.xml:1823(glossterm)#: ./doc/glossary/glossary-terms.xml:1828(para)#: ./doc/glossary/glossary-terms.xml:1835(primary)#: ./doc/glossary/glossary-terms.xml:1834(glossterm)#: ./doc/glossary/glossary-terms.xml:1839(para)#: ./doc/glossary/glossary-terms.xml:1847(primary)#: ./doc/glossary/glossary-terms.xml:1849(see)#: ./doc/glossary/glossary-terms.xml:1846(glossterm)#: ./doc/glossary/glossary-terms.xml:1853(para)#: ./doc/glossary/glossary-terms.xml:1859(primary)#: ./doc/glossary/glossary-terms.xml:1858(glossterm)#: ./doc/glossary/glossary-terms.xml:1863(para)#: ./doc/glossary/glossary-terms.xml:1872(title)#: ./doc/glossary/glossary-terms.xml:1876(primary)#: ./doc/glossary/glossary-terms.xml:1875(glossterm)#: ./doc/glossary/glossary-terms.xml:1882(para)#: ./doc/glossary/glossary-terms.xml:1890(primary)#: ./doc/glossary/glossary-terms.xml:1889(glossterm)#: ./doc/glossary/glossary-terms.xml:1894(para)#: ./doc/glossary/glossary-terms.xml:1904(primary)#: ./doc/glossary/glossary-terms.xml:1903(glossterm)#: ./doc/glossary/glossary-terms.xml:1908(para)#: ./doc/glossary/glossary-terms.xml:1915(primary)#: ./doc/glossary/glossary-terms.xml:1917(secondary)#: ./doc/glossary/glossary-terms.xml:1914(glossterm)#: ./doc/glossary/glossary-terms.xml:1921(para)#: ./doc/glossary/glossary-terms.xml:1932(primary) ./doc/glossary/glossary-terms.xml:1945(primary)#: ./doc/glossary/glossary-terms.xml:1934(secondary)#: ./doc/glossary/glossary-terms.xml:1931(glossterm)#: ./doc/glossary/glossary-terms.xml:1938(para)#: ./doc/glossary/glossary-terms.xml:1947(secondary)#: ./doc/glossary/glossary-terms.xml:1944(glossterm)#: ./doc/glossary/glossary-terms.xml:1951(para)#: ./doc/glossary/glossary-terms.xml:1958(primary)#: ./doc/glossary/glossary-terms.xml:1957(glossterm)#: ./doc/glossary/glossary-terms.xml:1962(para)#: ./doc/glossary/glossary-terms.xml:1973(primary)#: ./doc/glossary/glossary-terms.xml:1972(glossterm)#: ./doc/glossary/glossary-terms.xml:1977(para)#: ./doc/glossary/glossary-terms.xml:1985(primary)#: ./doc/glossary/glossary-terms.xml:1984(glossterm)#: ./doc/glossary/glossary-terms.xml:1995(primary)#: ./doc/glossary/glossary-terms.xml:1994(glossterm)#: ./doc/glossary/glossary-terms.xml:1999(para)#: ./doc/glossary/glossary-terms.xml:2007(primary)#: ./doc/glossary/glossary-terms.xml:2006(glossterm)#: ./doc/glossary/glossary-terms.xml:2011(para)#: ./doc/glossary/glossary-terms.xml:2018(primary)#: ./doc/glossary/glossary-terms.xml:2017(glossterm)#: ./doc/glossary/glossary-terms.xml:2022(para)#: ./doc/glossary/glossary-terms.xml:2029(primary)#: ./doc/glossary/glossary-terms.xml:2028(glossterm)#: ./doc/glossary/glossary-terms.xml:2033(para)#: ./doc/glossary/glossary-terms.xml:2040(primary)#: ./doc/glossary/glossary-terms.xml:2039(glossterm)#: ./doc/glossary/glossary-terms.xml:2044(para)#: ./doc/glossary/glossary-terms.xml:2051(primary)#: ./doc/glossary/glossary-terms.xml:2050(glossterm)#: ./doc/glossary/glossary-terms.xml:2055(para)#: ./doc/glossary/glossary-terms.xml:2062(primary)#: ./doc/glossary/glossary-terms.xml:2061(glossterm)#: ./doc/glossary/glossary-terms.xml:2066(para)#: ./doc/glossary/glossary-terms.xml:2074(primary)#: ./doc/glossary/glossary-terms.xml:2073(glossterm)#: ./doc/glossary/glossary-terms.xml:2078(para)#: ./doc/glossary/glossary-terms.xml:2085(primary)#: ./doc/glossary/glossary-terms.xml:2084(glossterm)#: ./doc/glossary/glossary-terms.xml:2089(para)#: ./doc/glossary/glossary-terms.xml:2096(primary)#: ./doc/glossary/glossary-terms.xml:2095(glossterm)#: ./doc/glossary/glossary-terms.xml:2100(para)#: ./doc/glossary/glossary-terms.xml:2107(primary)#: ./doc/glossary/glossary-terms.xml:2106(glossterm)#: ./doc/glossary/glossary-terms.xml:2113(para)#: ./doc/glossary/glossary-terms.xml:2120(primary)#: ./doc/glossary/glossary-terms.xml:2122(secondary) ./doc/glossary/glossary-terms.xml:3348(secondary) ./doc/glossary/glossary-terms.xml:3454(secondary) ./doc/glossary/glossary-terms.xml:3530(secondary) ./doc/glossary/glossary-terms.xml:5113(secondary) ./doc/glossary/glossary-terms.xml:5868(secondary)#: ./doc/glossary/glossary-terms.xml:2119(glossterm)#: ./doc/glossary/glossary-terms.xml:2126(para)#: ./doc/glossary/glossary-terms.xml:2137(primary)#: ./doc/glossary/glossary-terms.xml:2136(glossterm)#: ./doc/glossary/glossary-terms.xml:2141(para)#: ./doc/glossary/glossary-terms.xml:2148(primary)#: ./doc/glossary/glossary-terms.xml:2147(glossterm)#: ./doc/glossary/glossary-terms.xml:2152(para)#: ./doc/glossary/glossary-terms.xml:2156(para)#: ./doc/glossary/glossary-terms.xml:2165(primary)#: ./doc/glossary/glossary-terms.xml:2164(glossterm)#: ./doc/glossary/glossary-terms.xml:2169(para)#: ./doc/glossary/glossary-terms.xml:2177(primary)#: ./doc/glossary/glossary-terms.xml:2176(glossterm)#: ./doc/glossary/glossary-terms.xml:2181(para)#: ./doc/glossary/glossary-terms.xml:2189(primary)#: ./doc/glossary/glossary-terms.xml:2188(glossterm)#: ./doc/glossary/glossary-terms.xml:2193(para)#: ./doc/glossary/glossary-terms.xml:2200(primary)#: ./doc/glossary/glossary-terms.xml:2199(glossterm)#: ./doc/glossary/glossary-terms.xml:2204(para)#: ./doc/glossary/glossary-terms.xml:2212(primary)#: ./doc/glossary/glossary-terms.xml:2211(glossterm)#: ./doc/glossary/glossary-terms.xml:2216(para)#: ./doc/glossary/glossary-terms.xml:2223(primary)#: ./doc/glossary/glossary-terms.xml:2222(glossterm)#: ./doc/glossary/glossary-terms.xml:2227(para)#: ./doc/glossary/glossary-terms.xml:2235(primary)#: ./doc/glossary/glossary-terms.xml:2234(glossterm)#: ./doc/glossary/glossary-terms.xml:2239(para)#: ./doc/glossary/glossary-terms.xml:2246(primary)#: ./doc/glossary/glossary-terms.xml:2245(glossterm)#: ./doc/glossary/glossary-terms.xml:2250(para)#: ./doc/glossary/glossary-terms.xml:2257(primary) ./doc/glossary/glossary-terms.xml:2272(primary)#: ./doc/glossary/glossary-terms.xml:2259(secondary)#: ./doc/glossary/glossary-terms.xml:2256(glossterm)#: ./doc/glossary/glossary-terms.xml:2263(para)#: ./doc/glossary/glossary-terms.xml:2274(secondary)#: ./doc/glossary/glossary-terms.xml:2271(glossterm)#: ./doc/glossary/glossary-terms.xml:2278(para)#: ./doc/glossary/glossary-terms.xml:2285(primary)#: ./doc/glossary/glossary-terms.xml:2284(glossterm)#: ./doc/glossary/glossary-terms.xml:2289(para)#: ./doc/glossary/glossary-terms.xml:2296(primary)#: ./doc/glossary/glossary-terms.xml:2295(glossterm)#: ./doc/glossary/glossary-terms.xml:2300(para)#: ./doc/glossary/glossary-terms.xml:2304(para)#: ./doc/glossary/glossary-terms.xml:2310(glossterm)#: ./doc/glossary/glossary-terms.xml:2313(para)#: ./doc/glossary/glossary-terms.xml:2320(glossterm)#: ./doc/glossary/glossary-terms.xml:2323(para)#: ./doc/glossary/glossary-terms.xml:2326(para)#: ./doc/glossary/glossary-terms.xml:2330(para)#: ./doc/glossary/glossary-terms.xml:2341(primary)#: ./doc/glossary/glossary-terms.xml:2340(glossterm)#: ./doc/glossary/glossary-terms.xml:2345(para)#: ./doc/glossary/glossary-terms.xml:2352(primary)#: ./doc/glossary/glossary-terms.xml:2351(glossterm)#: ./doc/glossary/glossary-terms.xml:2356(para)#: ./doc/glossary/glossary-terms.xml:2362(primary)#: ./doc/glossary/glossary-terms.xml:2361(glossterm)#: ./doc/glossary/glossary-terms.xml:2366(para)#: ./doc/glossary/glossary-terms.xml:2373(primary)#: ./doc/glossary/glossary-terms.xml:2372(glossterm)#: ./doc/glossary/glossary-terms.xml:2377(para)#: ./doc/glossary/glossary-terms.xml:2383(glossterm)#: ./doc/glossary/glossary-terms.xml:2386(para)#: ./doc/glossary/glossary-terms.xml:2394(primary)#: ./doc/glossary/glossary-terms.xml:2392(glossterm)#: ./doc/glossary/glossary-terms.xml:2398(para)#: ./doc/glossary/glossary-terms.xml:2408(title)#: ./doc/glossary/glossary-terms.xml:2412(primary)#: ./doc/glossary/glossary-terms.xml:2411(glossterm)#: ./doc/glossary/glossary-terms.xml:2416(para)#: ./doc/glossary/glossary-terms.xml:2423(primary) ./doc/glossary/glossary-terms.xml:2623(primary)#: ./doc/glossary/glossary-terms.xml:2422(glossterm) ./doc/glossary/glossary-terms.xml:2622(glossterm)#: ./doc/glossary/glossary-terms.xml:2427(para)#: ./doc/glossary/glossary-terms.xml:2434(glossterm) ./doc/glossary/glossary-terms.xml:2444(primary) ./doc/glossary/glossary-terms.xml:2457(primary) ./doc/glossary/glossary-terms.xml:2470(primary) ./doc/glossary/glossary-terms.xml:2483(primary)#: ./doc/glossary/glossary-terms.xml:2437(para)#: ./doc/glossary/glossary-terms.xml:2446(secondary)#: ./doc/glossary/glossary-terms.xml:2443(glossterm)#: ./doc/glossary/glossary-terms.xml:2450(para)#: ./doc/glossary/glossary-terms.xml:2459(secondary)#: ./doc/glossary/glossary-terms.xml:2456(glossterm)#: ./doc/glossary/glossary-terms.xml:2463(para)#: ./doc/glossary/glossary-terms.xml:2472(secondary)#: ./doc/glossary/glossary-terms.xml:2469(glossterm)#: ./doc/glossary/glossary-terms.xml:2476(para)#: ./doc/glossary/glossary-terms.xml:2485(secondary)#: ./doc/glossary/glossary-terms.xml:2482(glossterm)#: ./doc/glossary/glossary-terms.xml:2489(para)#: ./doc/glossary/glossary-terms.xml:2496(primary)#: ./doc/glossary/glossary-terms.xml:2495(glossterm)#: ./doc/glossary/glossary-terms.xml:2500(para)#: ./doc/glossary/glossary-terms.xml:2506(primary)#: ./doc/glossary/glossary-terms.xml:2505(glossterm)#: ./doc/glossary/glossary-terms.xml:2510(para)#: ./doc/glossary/glossary-terms.xml:2516(glossterm)#: ./doc/glossary/glossary-terms.xml:2519(para)#: ./doc/glossary/glossary-terms.xml:2527(secondary)#: ./doc/glossary/glossary-terms.xml:2524(glossterm)#: ./doc/glossary/glossary-terms.xml:2531(para)#: ./doc/glossary/glossary-terms.xml:2539(secondary)#: ./doc/glossary/glossary-terms.xml:2536(glossterm)#: ./doc/glossary/glossary-terms.xml:2543(para)#: ./doc/glossary/glossary-terms.xml:2551(primary)#: ./doc/glossary/glossary-terms.xml:2550(glossterm)#: ./doc/glossary/glossary-terms.xml:2555(para)#: ./doc/glossary/glossary-terms.xml:2564(primary)#: ./doc/glossary/glossary-terms.xml:2563(glossterm)#: ./doc/glossary/glossary-terms.xml:2568(para)#: ./doc/glossary/glossary-terms.xml:2576(primary) ./doc/glossary/glossary-terms.xml:4863(see)#: ./doc/glossary/glossary-terms.xml:2575(glossterm)#: ./doc/glossary/glossary-terms.xml:2580(para)#: ./doc/glossary/glossary-terms.xml:2587(primary)#: ./doc/glossary/glossary-terms.xml:2586(glossterm)#: ./doc/glossary/glossary-terms.xml:2591(para)#: ./doc/glossary/glossary-terms.xml:2595(para)#: ./doc/glossary/glossary-terms.xml:2603(primary)#: ./doc/glossary/glossary-terms.xml:2602(glossterm)#: ./doc/glossary/glossary-terms.xml:2607(para) ./doc/glossary/glossary-terms.xml:2617(para) ./doc/glossary/glossary-terms.xml:4084(para) ./doc/glossary/glossary-terms.xml:4196(para) ./doc/glossary/glossary-terms.xml:7288(para) ./doc/glossary/glossary-terms.xml:7501(para) ./doc/glossary/glossary-terms.xml:7714(para) ./doc/glossary/glossary-terms.xml:7794(para) ./doc/glossary/glossary-terms.xml:7819(para)#: ./doc/glossary/glossary-terms.xml:2613(primary)#: ./doc/glossary/glossary-terms.xml:2612(glossterm)#: ./doc/glossary/glossary-terms.xml:2627(para)#: ./doc/glossary/glossary-terms.xml:2636(primary)#: ./doc/glossary/glossary-terms.xml:2635(glossterm)#: ./doc/glossary/glossary-terms.xml:2640(para)#: ./doc/glossary/glossary-terms.xml:2647(primary)#: ./doc/glossary/glossary-terms.xml:2646(glossterm)#: ./doc/glossary/glossary-terms.xml:2651(para)#: ./doc/glossary/glossary-terms.xml:2658(primary)#: ./doc/glossary/glossary-terms.xml:2657(glossterm)#: ./doc/glossary/glossary-terms.xml:2662(para)#: ./doc/glossary/glossary-terms.xml:2668(primary)#: ./doc/glossary/glossary-terms.xml:2667(glossterm)#: ./doc/glossary/glossary-terms.xml:2672(para)#: ./doc/glossary/glossary-terms.xml:2678(primary)#: ./doc/glossary/glossary-terms.xml:2677(glossterm)#: ./doc/glossary/glossary-terms.xml:2682(para)#: ./doc/glossary/glossary-terms.xml:2688(primary)#: ./doc/glossary/glossary-terms.xml:2687(glossterm)#: ./doc/glossary/glossary-terms.xml:2692(para)#: ./doc/glossary/glossary-terms.xml:2700(primary)#: ./doc/glossary/glossary-terms.xml:2699(glossterm)#: ./doc/glossary/glossary-terms.xml:2704(para)#: ./doc/glossary/glossary-terms.xml:2710(primary)#: ./doc/glossary/glossary-terms.xml:2709(glossterm)#: ./doc/glossary/glossary-terms.xml:2714(para)#: ./doc/glossary/glossary-terms.xml:2720(primary) ./doc/glossary/glossary-terms.xml:7196(primary)#: ./doc/glossary/glossary-terms.xml:2722(secondary) ./doc/glossary/glossary-terms.xml:2724(primary)#: ./doc/glossary/glossary-terms.xml:2719(glossterm)#: ./doc/glossary/glossary-terms.xml:2728(para)#: ./doc/glossary/glossary-terms.xml:2735(primary)#: ./doc/glossary/glossary-terms.xml:2734(glossterm)#: ./doc/glossary/glossary-terms.xml:2739(para)#: ./doc/glossary/glossary-terms.xml:2748(primary)#: ./doc/glossary/glossary-terms.xml:2747(glossterm)#: ./doc/glossary/glossary-terms.xml:2754(para)#: ./doc/glossary/glossary-terms.xml:2762(primary)#: ./doc/glossary/glossary-terms.xml:2761(glossterm)#: ./doc/glossary/glossary-terms.xml:2766(para)#: ./doc/glossary/glossary-terms.xml:2773(primary)#: ./doc/glossary/glossary-terms.xml:2772(glossterm)#: ./doc/glossary/glossary-terms.xml:2777(para)#: ./doc/glossary/glossary-terms.xml:2787(title)#: ./doc/glossary/glossary-terms.xml:2791(primary)#: ./doc/glossary/glossary-terms.xml:2790(glossterm)#: ./doc/glossary/glossary-terms.xml:2795(para)#: ./doc/glossary/glossary-terms.xml:2802(primary)#: ./doc/glossary/glossary-terms.xml:2801(glossterm)#: ./doc/glossary/glossary-terms.xml:2806(para)#: ./doc/glossary/glossary-terms.xml:2814(primary)#: ./doc/glossary/glossary-terms.xml:2813(glossterm)#: ./doc/glossary/glossary-terms.xml:2818(para)#: ./doc/glossary/glossary-terms.xml:2824(primary)#: ./doc/glossary/glossary-terms.xml:2823(glossterm)#: ./doc/glossary/glossary-terms.xml:2828(para)#: ./doc/glossary/glossary-terms.xml:2835(primary)#: ./doc/glossary/glossary-terms.xml:2834(glossterm)#: ./doc/glossary/glossary-terms.xml:2839(para)#: ./doc/glossary/glossary-terms.xml:2845(primary)#: ./doc/glossary/glossary-terms.xml:2844(glossterm)#: ./doc/glossary/glossary-terms.xml:2849(para)#: ./doc/glossary/glossary-terms.xml:2856(primary) ./doc/glossary/glossary-terms.xml:3730(primary)#: ./doc/glossary/glossary-terms.xml:2855(glossterm)#: ./doc/glossary/glossary-terms.xml:2862(para)#: ./doc/glossary/glossary-terms.xml:2869(primary)#: ./doc/glossary/glossary-terms.xml:2868(glossterm)#: ./doc/glossary/glossary-terms.xml:2873(para)#: ./doc/glossary/glossary-terms.xml:2881(primary)#: ./doc/glossary/glossary-terms.xml:2880(glossterm)#: ./doc/glossary/glossary-terms.xml:2885(para)#: ./doc/glossary/glossary-terms.xml:2892(primary) ./doc/glossary/glossary-terms.xml:2980(primary) ./doc/glossary/glossary-terms.xml:3900(primary) ./doc/glossary/glossary-terms.xml:5420(primary) ./doc/glossary/glossary-terms.xml:5591(primary) ./doc/glossary/glossary-terms.xml:6510(primary) ./doc/glossary/glossary-terms.xml:6718(primary)#: ./doc/glossary/glossary-terms.xml:2894(secondary)#: ./doc/glossary/glossary-terms.xml:2896(primary)#: ./doc/glossary/glossary-terms.xml:2891(glossterm)#: ./doc/glossary/glossary-terms.xml:2900(para)#: ./doc/glossary/glossary-terms.xml:2909(primary)#: ./doc/glossary/glossary-terms.xml:2908(glossterm)#: ./doc/glossary/glossary-terms.xml:2913(para)#: ./doc/glossary/glossary-terms.xml:2921(primary)#: ./doc/glossary/glossary-terms.xml:2920(glossterm)#: ./doc/glossary/glossary-terms.xml:2925(para)#: ./doc/glossary/glossary-terms.xml:2933(primary)#: ./doc/glossary/glossary-terms.xml:2932(glossterm)#: ./doc/glossary/glossary-terms.xml:2937(para)#: ./doc/glossary/glossary-terms.xml:2948(primary)#: ./doc/glossary/glossary-terms.xml:2947(glossterm)#: ./doc/glossary/glossary-terms.xml:2952(para)#: ./doc/glossary/glossary-terms.xml:2959(primary)#: ./doc/glossary/glossary-terms.xml:2958(glossterm)#: ./doc/glossary/glossary-terms.xml:2963(para)#: ./doc/glossary/glossary-terms.xml:2969(primary)#: ./doc/glossary/glossary-terms.xml:2968(glossterm)#: ./doc/glossary/glossary-terms.xml:2973(para)#: ./doc/glossary/glossary-terms.xml:2982(secondary)#: ./doc/glossary/glossary-terms.xml:2984(primary)#: ./doc/glossary/glossary-terms.xml:2979(glossterm)#: ./doc/glossary/glossary-terms.xml:2988(para)#: ./doc/glossary/glossary-terms.xml:2998(primary)#: ./doc/glossary/glossary-terms.xml:2997(glossterm)#: ./doc/glossary/glossary-terms.xml:3002(para)#: ./doc/glossary/glossary-terms.xml:3007(para)#: ./doc/glossary/glossary-terms.xml:3016(primary)#: ./doc/glossary/glossary-terms.xml:3015(glossterm)#: ./doc/glossary/glossary-terms.xml:3020(para)#: ./doc/glossary/glossary-terms.xml:3027(primary)#: ./doc/glossary/glossary-terms.xml:3026(glossterm)#: ./doc/glossary/glossary-terms.xml:3031(para)#: ./doc/glossary/glossary-terms.xml:3040(title)#: ./doc/glossary/glossary-terms.xml:3044(primary)#: ./doc/glossary/glossary-terms.xml:3043(glossterm)#: ./doc/glossary/glossary-terms.xml:3048(para)#: ./doc/glossary/glossary-terms.xml:3055(primary)#: ./doc/glossary/glossary-terms.xml:3054(glossterm)#: ./doc/glossary/glossary-terms.xml:3058(para)#: ./doc/glossary/glossary-terms.xml:3066(primary)#: ./doc/glossary/glossary-terms.xml:3065(glossterm)#: ./doc/glossary/glossary-terms.xml:3069(para)#: ./doc/glossary/glossary-terms.xml:3076(glossterm) ./doc/glossary/glossary-terms.xml:3085(primary) ./doc/glossary/glossary-terms.xml:3099(primary)#: ./doc/glossary/glossary-terms.xml:3079(para)#: ./doc/glossary/glossary-terms.xml:3087(secondary)#: ./doc/glossary/glossary-terms.xml:3084(glossterm)#: ./doc/glossary/glossary-terms.xml:3091(para)#: ./doc/glossary/glossary-terms.xml:3101(secondary)#: ./doc/glossary/glossary-terms.xml:3098(glossterm)#: ./doc/glossary/glossary-terms.xml:3105(para)#: ./doc/glossary/glossary-terms.xml:3113(secondary) ./doc/glossary/glossary-terms.xml:3115(primary)#: ./doc/glossary/glossary-terms.xml:3110(glossterm)#: ./doc/glossary/glossary-terms.xml:3119(para)#: ./doc/glossary/glossary-terms.xml:3126(primary)#: ./doc/glossary/glossary-terms.xml:3125(glossterm)#: ./doc/glossary/glossary-terms.xml:3130(para)#: ./doc/glossary/glossary-terms.xml:3137(primary)#: ./doc/glossary/glossary-terms.xml:3136(glossterm)#: ./doc/glossary/glossary-terms.xml:3141(para)#: ./doc/glossary/glossary-terms.xml:3149(primary)#: ./doc/glossary/glossary-terms.xml:3148(glossterm)#: ./doc/glossary/glossary-terms.xml:3153(para)#: ./doc/glossary/glossary-terms.xml:3160(primary)#: ./doc/glossary/glossary-terms.xml:3159(glossterm)#: ./doc/glossary/glossary-terms.xml:3164(para)#: ./doc/glossary/glossary-terms.xml:3171(primary)#: ./doc/glossary/glossary-terms.xml:3170(glossterm)#: ./doc/glossary/glossary-terms.xml:3175(para)#: ./doc/glossary/glossary-terms.xml:3183(primary)#: ./doc/glossary/glossary-terms.xml:3182(glossterm)#: ./doc/glossary/glossary-terms.xml:3187(para)#: ./doc/glossary/glossary-terms.xml:3196(primary)#: ./doc/glossary/glossary-terms.xml:3195(glossterm)#: ./doc/glossary/glossary-terms.xml:3200(para)#: ./doc/glossary/glossary-terms.xml:3209(title)#: ./doc/glossary/glossary-terms.xml:3213(primary)#: ./doc/glossary/glossary-terms.xml:3212(glossterm)#: ./doc/glossary/glossary-terms.xml:3217(para)#: ./doc/glossary/glossary-terms.xml:3224(primary)#: ./doc/glossary/glossary-terms.xml:3223(glossterm)#: ./doc/glossary/glossary-terms.xml:3228(para)#: ./doc/glossary/glossary-terms.xml:3235(primary)#: ./doc/glossary/glossary-terms.xml:3234(glossterm)#: ./doc/glossary/glossary-terms.xml:3239(para)#: ./doc/glossary/glossary-terms.xml:3247(primary)#: ./doc/glossary/glossary-terms.xml:3246(glossterm)#: ./doc/glossary/glossary-terms.xml:3251(para)#: ./doc/glossary/glossary-terms.xml:3259(primary)#: ./doc/glossary/glossary-terms.xml:3258(glossterm)#: ./doc/glossary/glossary-terms.xml:3263(para)#: ./doc/glossary/glossary-terms.xml:3270(primary)#: ./doc/glossary/glossary-terms.xml:3269(glossterm)#: ./doc/glossary/glossary-terms.xml:3274(para)#: ./doc/glossary/glossary-terms.xml:3280(primary)#: ./doc/glossary/glossary-terms.xml:3279(glossterm)#: ./doc/glossary/glossary-terms.xml:3284(para)#: ./doc/glossary/glossary-terms.xml:3294(glossterm)#: ./doc/glossary/glossary-terms.xml:3297(para)#: ./doc/glossary/glossary-terms.xml:3304(primary)#: ./doc/glossary/glossary-terms.xml:3303(glossterm)#: ./doc/glossary/glossary-terms.xml:3308(para)#: ./doc/glossary/glossary-terms.xml:3314(primary)#: ./doc/glossary/glossary-terms.xml:3313(glossterm)#: ./doc/glossary/glossary-terms.xml:3318(para)#: ./doc/glossary/glossary-terms.xml:3324(primary)#: ./doc/glossary/glossary-terms.xml:3323(glossterm)#: ./doc/glossary/glossary-terms.xml:3328(para)#: ./doc/glossary/glossary-terms.xml:3335(primary)#: ./doc/glossary/glossary-terms.xml:3334(glossterm)#: ./doc/glossary/glossary-terms.xml:3339(para)#: ./doc/glossary/glossary-terms.xml:3346(primary)#: ./doc/glossary/glossary-terms.xml:3345(glossterm)#: ./doc/glossary/glossary-terms.xml:3352(para)#: ./doc/glossary/glossary-terms.xml:3363(primary)#: ./doc/glossary/glossary-terms.xml:3362(glossterm)#: ./doc/glossary/glossary-terms.xml:3367(para)#: ./doc/glossary/glossary-terms.xml:3379(primary)#: ./doc/glossary/glossary-terms.xml:3378(glossterm)#: ./doc/glossary/glossary-terms.xml:3383(para)#: ./doc/glossary/glossary-terms.xml:3389(primary)#: ./doc/glossary/glossary-terms.xml:3388(glossterm)#: ./doc/glossary/glossary-terms.xml:3393(para)#: ./doc/glossary/glossary-terms.xml:3400(glossterm)#: ./doc/glossary/glossary-terms.xml:3403(para)#: ./doc/glossary/glossary-terms.xml:3409(glossterm)#: ./doc/glossary/glossary-terms.xml:3412(para)#: ./doc/glossary/glossary-terms.xml:3420(primary) ./doc/glossary/glossary-terms.xml:3433(primary)#: ./doc/glossary/glossary-terms.xml:3419(glossterm)#: ./doc/glossary/glossary-terms.xml:3426(para)#: ./doc/glossary/glossary-terms.xml:3435(secondary)#: ./doc/glossary/glossary-terms.xml:3432(glossterm)#: ./doc/glossary/glossary-terms.xml:3439(para)#: ./doc/glossary/glossary-terms.xml:3448(title)#: ./doc/glossary/glossary-terms.xml:3452(primary)#: ./doc/glossary/glossary-terms.xml:3451(glossterm)#: ./doc/glossary/glossary-terms.xml:3458(para)#: ./doc/glossary/glossary-terms.xml:3469(primary)#: ./doc/glossary/glossary-terms.xml:3468(glossterm)#: ./doc/glossary/glossary-terms.xml:3475(para)#: ./doc/glossary/glossary-terms.xml:3483(primary)#: ./doc/glossary/glossary-terms.xml:3482(glossterm)#: ./doc/glossary/glossary-terms.xml:3487(para)#: ./doc/glossary/glossary-terms.xml:3496(primary)#: ./doc/glossary/glossary-terms.xml:3495(glossterm)#: ./doc/glossary/glossary-terms.xml:3500(para)#: ./doc/glossary/glossary-terms.xml:3506(glossterm)#: ./doc/glossary/glossary-terms.xml:3509(para)#: ./doc/glossary/glossary-terms.xml:3515(primary) ./doc/glossary/glossary-terms.xml:3528(primary) ./doc/glossary/glossary-terms.xml:3544(primary) ./doc/glossary/glossary-terms.xml:3610(primary)#: ./doc/glossary/glossary-terms.xml:3517(secondary)#: ./doc/glossary/glossary-terms.xml:3514(glossterm)#: ./doc/glossary/glossary-terms.xml:3521(para)#: ./doc/glossary/glossary-terms.xml:3527(glossterm)#: ./doc/glossary/glossary-terms.xml:3534(para)#: ./doc/glossary/glossary-terms.xml:3546(secondary)#: ./doc/glossary/glossary-terms.xml:3543(glossterm)#: ./doc/glossary/glossary-terms.xml:3550(para)#: ./doc/glossary/glossary-terms.xml:3557(primary)#: ./doc/glossary/glossary-terms.xml:3556(glossterm)#: ./doc/glossary/glossary-terms.xml:3561(para)#: ./doc/glossary/glossary-terms.xml:3567(primary)#: ./doc/glossary/glossary-terms.xml:3566(glossterm)#: ./doc/glossary/glossary-terms.xml:3573(para)#: ./doc/glossary/glossary-terms.xml:3583(primary) ./doc/glossary/glossary-terms.xml:3596(primary) ./doc/glossary/glossary-terms.xml:3623(primary) ./doc/glossary/glossary-terms.xml:3636(primary) ./doc/glossary/glossary-terms.xml:3649(primary) ./doc/glossary/glossary-terms.xml:3661(glossterm) ./doc/glossary/glossary-terms.xml:3680(primary) ./doc/glossary/glossary-terms.xml:3693(primary) ./doc/glossary/glossary-terms.xml:3706(primary) ./doc/glossary/glossary-terms.xml:5576(primary)#: ./doc/glossary/glossary-terms.xml:3585(secondary) ./doc/glossary/glossary-terms.xml:3671(glossterm)#: ./doc/glossary/glossary-terms.xml:3582(glossterm)#: ./doc/glossary/glossary-terms.xml:3589(para)#: ./doc/glossary/glossary-terms.xml:3598(secondary)#: ./doc/glossary/glossary-terms.xml:3595(glossterm)#: ./doc/glossary/glossary-terms.xml:3602(para)#: ./doc/glossary/glossary-terms.xml:3612(secondary)#: ./doc/glossary/glossary-terms.xml:3609(glossterm)#: ./doc/glossary/glossary-terms.xml:3616(para)#: ./doc/glossary/glossary-terms.xml:3625(secondary)#: ./doc/glossary/glossary-terms.xml:3622(glossterm)#: ./doc/glossary/glossary-terms.xml:3629(para) ./doc/glossary/glossary-terms.xml:4367(para)#: ./doc/glossary/glossary-terms.xml:3638(secondary)#: ./doc/glossary/glossary-terms.xml:3635(glossterm)#: ./doc/glossary/glossary-terms.xml:3642(para)#: ./doc/glossary/glossary-terms.xml:3651(secondary)#: ./doc/glossary/glossary-terms.xml:3648(glossterm)#: ./doc/glossary/glossary-terms.xml:3655(para)#: ./doc/glossary/glossary-terms.xml:3664(para)#: ./doc/glossary/glossary-terms.xml:3674(para)#: ./doc/glossary/glossary-terms.xml:3682(secondary)#: ./doc/glossary/glossary-terms.xml:3679(glossterm)#: ./doc/glossary/glossary-terms.xml:3686(para)#: ./doc/glossary/glossary-terms.xml:3695(secondary)#: ./doc/glossary/glossary-terms.xml:3692(glossterm)#: ./doc/glossary/glossary-terms.xml:3699(para)#: ./doc/glossary/glossary-terms.xml:3708(secondary)#: ./doc/glossary/glossary-terms.xml:3705(glossterm)#: ./doc/glossary/glossary-terms.xml:3712(para)#: ./doc/glossary/glossary-terms.xml:3719(primary)#: ./doc/glossary/glossary-terms.xml:3718(glossterm)#: ./doc/glossary/glossary-terms.xml:3723(para)#: ./doc/glossary/glossary-terms.xml:3732(secondary) ./doc/glossary/glossary-terms.xml:3734(primary)#: ./doc/glossary/glossary-terms.xml:3729(glossterm)#: ./doc/glossary/glossary-terms.xml:3738(para)#: ./doc/glossary/glossary-terms.xml:3745(primary)#: ./doc/glossary/glossary-terms.xml:3744(glossterm)#: ./doc/glossary/glossary-terms.xml:3748(para)#: ./doc/glossary/glossary-terms.xml:3758(primary)#: ./doc/glossary/glossary-terms.xml:3757(glossterm)#: ./doc/glossary/glossary-terms.xml:3762(para)#: ./doc/glossary/glossary-terms.xml:3769(primary) ./doc/glossary/glossary-terms.xml:3782(primary) ./doc/glossary/glossary-terms.xml:3794(primary) ./doc/glossary/glossary-terms.xml:3817(primary) ./doc/glossary/glossary-terms.xml:3831(primary) ./doc/glossary/glossary-terms.xml:3843(primary)#: ./doc/glossary/glossary-terms.xml:3768(glossterm)#: ./doc/glossary/glossary-terms.xml:3775(para)#: ./doc/glossary/glossary-terms.xml:3784(secondary)#: ./doc/glossary/glossary-terms.xml:3781(glossterm)#: ./doc/glossary/glossary-terms.xml:3788(para)#: ./doc/glossary/glossary-terms.xml:3796(secondary)#: ./doc/glossary/glossary-terms.xml:3793(glossterm)#: ./doc/glossary/glossary-terms.xml:3800(para)#: ./doc/glossary/glossary-terms.xml:3806(primary)#: ./doc/glossary/glossary-terms.xml:3805(glossterm)#: ./doc/glossary/glossary-terms.xml:3810(para)#: ./doc/glossary/glossary-terms.xml:3819(secondary)#: ./doc/glossary/glossary-terms.xml:3816(glossterm)#: ./doc/glossary/glossary-terms.xml:3823(para)#: ./doc/glossary/glossary-terms.xml:3833(secondary)#: ./doc/glossary/glossary-terms.xml:3830(glossterm)#: ./doc/glossary/glossary-terms.xml:3837(para)#: ./doc/glossary/glossary-terms.xml:3845(secondary)#: ./doc/glossary/glossary-terms.xml:3842(glossterm)#: ./doc/glossary/glossary-terms.xml:3849(para) ./doc/glossary/glossary-terms.xml:6395(para)#: ./doc/glossary/glossary-terms.xml:3856(primary)#: ./doc/glossary/glossary-terms.xml:3855(glossterm)#: ./doc/glossary/glossary-terms.xml:3860(para)#: ./doc/glossary/glossary-terms.xml:3867(primary)#: ./doc/glossary/glossary-terms.xml:3866(glossterm)#: ./doc/glossary/glossary-terms.xml:3871(para)#: ./doc/glossary/glossary-terms.xml:3878(primary)#: ./doc/glossary/glossary-terms.xml:3877(glossterm)#: ./doc/glossary/glossary-terms.xml:3882(para)#: ./doc/glossary/glossary-terms.xml:3889(primary)#: ./doc/glossary/glossary-terms.xml:3888(glossterm)#: ./doc/glossary/glossary-terms.xml:3893(para)#: ./doc/glossary/glossary-terms.xml:3899(glossterm)#: ./doc/glossary/glossary-terms.xml:3906(para)#: ./doc/glossary/glossary-terms.xml:3914(primary)#: ./doc/glossary/glossary-terms.xml:3913(glossterm)#: ./doc/glossary/glossary-terms.xml:3918(para)#: ./doc/glossary/glossary-terms.xml:3926(primary)#: ./doc/glossary/glossary-terms.xml:3925(glossterm)#: ./doc/glossary/glossary-terms.xml:3930(para)#: ./doc/glossary/glossary-terms.xml:3936(primary)#: ./doc/glossary/glossary-terms.xml:3935(glossterm)#: ./doc/glossary/glossary-terms.xml:3940(para)#: ./doc/glossary/glossary-terms.xml:3952(primary)#: ./doc/glossary/glossary-terms.xml:3951(glossterm)#: ./doc/glossary/glossary-terms.xml:3956(para)#: ./doc/glossary/glossary-terms.xml:3965(primary)#: ./doc/glossary/glossary-terms.xml:3964(glossterm)#: ./doc/glossary/glossary-terms.xml:3969(para)#: ./doc/glossary/glossary-terms.xml:3981(primary)#: ./doc/glossary/glossary-terms.xml:3980(glossterm)#: ./doc/glossary/glossary-terms.xml:3985(para)#: ./doc/glossary/glossary-terms.xml:3992(primary)#: ./doc/glossary/glossary-terms.xml:3991(glossterm)#: ./doc/glossary/glossary-terms.xml:3996(para) ./doc/glossary/glossary-terms.xml:5665(para) ./doc/glossary/glossary-terms.xml:7341(para) ./doc/glossary/glossary-terms.xml:7352(para) ./doc/glossary/glossary-terms.xml:7541(para)#: ./doc/glossary/glossary-terms.xml:4003(primary)#: ./doc/glossary/glossary-terms.xml:4002(glossterm)#: ./doc/glossary/glossary-terms.xml:4007(para)#: ./doc/glossary/glossary-terms.xml:4016(title)#: ./doc/glossary/glossary-terms.xml:4020(primary)#: ./doc/glossary/glossary-terms.xml:4019(glossterm)#: ./doc/glossary/glossary-terms.xml:4024(para)#: ./doc/glossary/glossary-terms.xml:4031(primary)#: ./doc/glossary/glossary-terms.xml:4030(glossterm)#: ./doc/glossary/glossary-terms.xml:4035(para)#: ./doc/glossary/glossary-terms.xml:4041(primary)#: ./doc/glossary/glossary-terms.xml:4040(glossterm)#: ./doc/glossary/glossary-terms.xml:4045(para)#: ./doc/glossary/glossary-terms.xml:4051(primary)#: ./doc/glossary/glossary-terms.xml:4050(glossterm)#: ./doc/glossary/glossary-terms.xml:4055(para)#: ./doc/glossary/glossary-terms.xml:4062(primary)#: ./doc/glossary/glossary-terms.xml:4061(glossterm)#: ./doc/glossary/glossary-terms.xml:4066(para)#: ./doc/glossary/glossary-terms.xml:4076(title)#: ./doc/glossary/glossary-terms.xml:4080(primary)#: ./doc/glossary/glossary-terms.xml:4079(glossterm)#: ./doc/glossary/glossary-terms.xml:4090(primary)#: ./doc/glossary/glossary-terms.xml:4089(glossterm)#: ./doc/glossary/glossary-terms.xml:4094(para)#: ./doc/glossary/glossary-terms.xml:4100(primary)#: ./doc/glossary/glossary-terms.xml:4099(glossterm)#: ./doc/glossary/glossary-terms.xml:4104(para)#: ./doc/glossary/glossary-terms.xml:4113(title)#: ./doc/glossary/glossary-terms.xml:4117(primary)#: ./doc/glossary/glossary-terms.xml:4116(glossterm)#: ./doc/glossary/glossary-terms.xml:4121(para)#: ./doc/glossary/glossary-terms.xml:4127(primary)#: ./doc/glossary/glossary-terms.xml:4126(glossterm)#: ./doc/glossary/glossary-terms.xml:4131(para)#: ./doc/glossary/glossary-terms.xml:4137(primary)#: ./doc/glossary/glossary-terms.xml:4136(glossterm)#: ./doc/glossary/glossary-terms.xml:4141(para)#: ./doc/glossary/glossary-terms.xml:4148(primary)#: ./doc/glossary/glossary-terms.xml:4147(glossterm)#: ./doc/glossary/glossary-terms.xml:4152(para)#: ./doc/glossary/glossary-terms.xml:4159(primary)#: ./doc/glossary/glossary-terms.xml:4158(glossterm)#: ./doc/glossary/glossary-terms.xml:4163(para)#: ./doc/glossary/glossary-terms.xml:4169(glossterm)#: ./doc/glossary/glossary-terms.xml:4172(para)#: ./doc/glossary/glossary-terms.xml:4179(primary)#: ./doc/glossary/glossary-terms.xml:4181(secondary) ./doc/glossary/glossary-terms.xml:5090(secondary)#: ./doc/glossary/glossary-terms.xml:4178(glossterm)#: ./doc/glossary/glossary-terms.xml:4185(para)#: ./doc/glossary/glossary-terms.xml:4192(primary)#: ./doc/glossary/glossary-terms.xml:4191(glossterm)#: ./doc/glossary/glossary-terms.xml:4202(primary)#: ./doc/glossary/glossary-terms.xml:4201(glossterm)#: ./doc/glossary/glossary-terms.xml:4206(para)#: ./doc/glossary/glossary-terms.xml:4213(glossterm)#: ./doc/glossary/glossary-terms.xml:4216(para)#: ./doc/glossary/glossary-terms.xml:4225(primary)#: ./doc/glossary/glossary-terms.xml:4224(glossterm)#: ./doc/glossary/glossary-terms.xml:4229(para)#: ./doc/glossary/glossary-terms.xml:4237(primary)#: ./doc/glossary/glossary-terms.xml:4235(glossterm)#: ./doc/glossary/glossary-terms.xml:4241(para)#: ./doc/glossary/glossary-terms.xml:4248(primary)#: ./doc/glossary/glossary-terms.xml:4247(glossterm)#: ./doc/glossary/glossary-terms.xml:4252(para)#: ./doc/glossary/glossary-terms.xml:4262(title)#: ./doc/glossary/glossary-terms.xml:4266(primary)#: ./doc/glossary/glossary-terms.xml:4265(glossterm)#: ./doc/glossary/glossary-terms.xml:4272(para)#: ./doc/glossary/glossary-terms.xml:4278(primary)#: ./doc/glossary/glossary-terms.xml:4277(glossterm)#: ./doc/glossary/glossary-terms.xml:4282(para)#: ./doc/glossary/glossary-terms.xml:4289(primary)#: ./doc/glossary/glossary-terms.xml:4288(glossterm)#: ./doc/glossary/glossary-terms.xml:4293(para)#: ./doc/glossary/glossary-terms.xml:4300(primary) ./doc/glossary/glossary-terms.xml:4317(primary)#: ./doc/glossary/glossary-terms.xml:4299(glossterm)#: ./doc/glossary/glossary-terms.xml:4306(para)#: ./doc/glossary/glossary-terms.xml:4315(secondary) ./doc/glossary/glossary-terms.xml:4319(secondary)#: ./doc/glossary/glossary-terms.xml:4312(glossterm)#: ./doc/glossary/glossary-terms.xml:4323(para)#: ./doc/glossary/glossary-terms.xml:4330(primary)#: ./doc/glossary/glossary-terms.xml:4329(glossterm)#: ./doc/glossary/glossary-terms.xml:4334(para)#: ./doc/glossary/glossary-terms.xml:4341(primary)#: ./doc/glossary/glossary-terms.xml:4340(glossterm)#: ./doc/glossary/glossary-terms.xml:4345(para)#: ./doc/glossary/glossary-terms.xml:4352(primary)#: ./doc/glossary/glossary-terms.xml:4351(glossterm)#: ./doc/glossary/glossary-terms.xml:4356(para)#: ./doc/glossary/glossary-terms.xml:4363(primary)#: ./doc/glossary/glossary-terms.xml:4362(glossterm)#: ./doc/glossary/glossary-terms.xml:4374(primary)#: ./doc/glossary/glossary-terms.xml:4373(glossterm)#: ./doc/glossary/glossary-terms.xml:4378(para)#: ./doc/glossary/glossary-terms.xml:4385(primary)#: ./doc/glossary/glossary-terms.xml:4384(glossterm)#: ./doc/glossary/glossary-terms.xml:4389(para)#: ./doc/glossary/glossary-terms.xml:4398(primary)#: ./doc/glossary/glossary-terms.xml:4397(glossterm)#: ./doc/glossary/glossary-terms.xml:4402(para)#: ./doc/glossary/glossary-terms.xml:4409(primary)#: ./doc/glossary/glossary-terms.xml:4408(glossterm)#: ./doc/glossary/glossary-terms.xml:4413(para)#: ./doc/glossary/glossary-terms.xml:4420(primary)#: ./doc/glossary/glossary-terms.xml:4419(glossterm)#: ./doc/glossary/glossary-terms.xml:4424(para)#: ./doc/glossary/glossary-terms.xml:4431(primary)#: ./doc/glossary/glossary-terms.xml:4430(glossterm)#: ./doc/glossary/glossary-terms.xml:4435(para)#: ./doc/glossary/glossary-terms.xml:4442(primary)#: ./doc/glossary/glossary-terms.xml:4441(glossterm)#: ./doc/glossary/glossary-terms.xml:4446(para)#: ./doc/glossary/glossary-terms.xml:4452(primary)#: ./doc/glossary/glossary-terms.xml:4451(glossterm)#: ./doc/glossary/glossary-terms.xml:4456(para)#: ./doc/glossary/glossary-terms.xml:4463(primary)#: ./doc/glossary/glossary-terms.xml:4462(glossterm)#: ./doc/glossary/glossary-terms.xml:4467(para)#: ./doc/glossary/glossary-terms.xml:4475(glossterm)#: ./doc/glossary/glossary-terms.xml:4478(para)#: ./doc/glossary/glossary-terms.xml:4486(primary)#: ./doc/glossary/glossary-terms.xml:4484(glossterm)#: ./doc/glossary/glossary-terms.xml:4490(para)#: ./doc/glossary/glossary-terms.xml:4497(primary)#: ./doc/glossary/glossary-terms.xml:4496(glossterm)#: ./doc/glossary/glossary-terms.xml:4501(para)#: ./doc/glossary/glossary-terms.xml:4508(primary)#: ./doc/glossary/glossary-terms.xml:4507(glossterm)#: ./doc/glossary/glossary-terms.xml:4512(para)#: ./doc/glossary/glossary-terms.xml:4519(primary)#: ./doc/glossary/glossary-terms.xml:4518(glossterm)#: ./doc/glossary/glossary-terms.xml:4523(para)#: ./doc/glossary/glossary-terms.xml:4531(primary)#: ./doc/glossary/glossary-terms.xml:4530(glossterm)#: ./doc/glossary/glossary-terms.xml:4535(para)#: ./doc/glossary/glossary-terms.xml:4544(title)#: ./doc/glossary/glossary-terms.xml:4548(primary)#: ./doc/glossary/glossary-terms.xml:4547(glossterm)#: ./doc/glossary/glossary-terms.xml:4552(para)#: ./doc/glossary/glossary-terms.xml:4559(primary)#: ./doc/glossary/glossary-terms.xml:4558(glossterm)#: ./doc/glossary/glossary-terms.xml:4563(para)#: ./doc/glossary/glossary-terms.xml:4571(primary)#: ./doc/glossary/glossary-terms.xml:4570(glossterm)#: ./doc/glossary/glossary-terms.xml:4575(para)#: ./doc/glossary/glossary-terms.xml:4583(primary) ./doc/glossary/glossary-terms.xml:4598(primary) ./doc/glossary/glossary-terms.xml:4611(primary) ./doc/glossary/glossary-terms.xml:4625(primary) ./doc/glossary/glossary-terms.xml:4638(primary) ./doc/glossary/glossary-terms.xml:4651(primary) ./doc/glossary/glossary-terms.xml:4664(primary) ./doc/glossary/glossary-terms.xml:4676(primary) ./doc/glossary/glossary-terms.xml:4689(primary) ./doc/glossary/glossary-terms.xml:4702(primary) ./doc/glossary/glossary-terms.xml:4715(primary) ./doc/glossary/glossary-terms.xml:5435(primary) ./doc/glossary/glossary-terms.xml:5616(primary) ./doc/glossary/glossary-terms.xml:7384(primary) ./doc/glossary/glossary-terms.xml:7518(primary)#: ./doc/glossary/glossary-terms.xml:4582(glossterm)#: ./doc/glossary/glossary-terms.xml:4589(para)#: ./doc/glossary/glossary-terms.xml:4600(secondary)#: ./doc/glossary/glossary-terms.xml:4597(glossterm)#: ./doc/glossary/glossary-terms.xml:4604(para)#: ./doc/glossary/glossary-terms.xml:4613(secondary)#: ./doc/glossary/glossary-terms.xml:4610(glossterm)#: ./doc/glossary/glossary-terms.xml:4617(para)#: ./doc/glossary/glossary-terms.xml:4627(secondary)#: ./doc/glossary/glossary-terms.xml:4624(glossterm)#: ./doc/glossary/glossary-terms.xml:4631(para)#: ./doc/glossary/glossary-terms.xml:4640(secondary)#: ./doc/glossary/glossary-terms.xml:4637(glossterm)#: ./doc/glossary/glossary-terms.xml:4644(para)#: ./doc/glossary/glossary-terms.xml:4653(secondary)#: ./doc/glossary/glossary-terms.xml:4650(glossterm)#: ./doc/glossary/glossary-terms.xml:4657(para)#: ./doc/glossary/glossary-terms.xml:4666(secondary)#: ./doc/glossary/glossary-terms.xml:4663(glossterm)#: ./doc/glossary/glossary-terms.xml:4670(para)#: ./doc/glossary/glossary-terms.xml:4678(secondary)#: ./doc/glossary/glossary-terms.xml:4675(glossterm)#: ./doc/glossary/glossary-terms.xml:4682(para)#: ./doc/glossary/glossary-terms.xml:4691(secondary)#: ./doc/glossary/glossary-terms.xml:4688(glossterm)#: ./doc/glossary/glossary-terms.xml:4695(para)#: ./doc/glossary/glossary-terms.xml:4704(secondary)#: ./doc/glossary/glossary-terms.xml:4701(glossterm)#: ./doc/glossary/glossary-terms.xml:4708(para)#: ./doc/glossary/glossary-terms.xml:4717(secondary)#: ./doc/glossary/glossary-terms.xml:4714(glossterm)#: ./doc/glossary/glossary-terms.xml:4721(para)#: ./doc/glossary/glossary-terms.xml:4728(glossterm)#: ./doc/glossary/glossary-terms.xml:4731(para)#: ./doc/glossary/glossary-terms.xml:4739(primary) ./doc/glossary/glossary-terms.xml:4761(secondary)#: ./doc/glossary/glossary-terms.xml:4738(glossterm)#: ./doc/glossary/glossary-terms.xml:4743(para)#: ./doc/glossary/glossary-terms.xml:4749(glossterm) ./doc/glossary/glossary-terms.xml:4759(primary) ./doc/glossary/glossary-terms.xml:4771(primary) ./doc/glossary/glossary-terms.xml:4784(primary)#: ./doc/glossary/glossary-terms.xml:4752(para)#: ./doc/glossary/glossary-terms.xml:4758(glossterm)#: ./doc/glossary/glossary-terms.xml:4765(para)#: ./doc/glossary/glossary-terms.xml:4773(secondary)#: ./doc/glossary/glossary-terms.xml:4770(glossterm)#: ./doc/glossary/glossary-terms.xml:4777(para)#: ./doc/glossary/glossary-terms.xml:4786(secondary)#: ./doc/glossary/glossary-terms.xml:4783(glossterm)#: ./doc/glossary/glossary-terms.xml:4790(para)#: ./doc/glossary/glossary-terms.xml:4798(primary)#: ./doc/glossary/glossary-terms.xml:4797(glossterm)#: ./doc/glossary/glossary-terms.xml:4802(para)#: ./doc/glossary/glossary-terms.xml:4808(primary)#: ./doc/glossary/glossary-terms.xml:4807(glossterm)#: ./doc/glossary/glossary-terms.xml:4812(para)#: ./doc/glossary/glossary-terms.xml:4819(primary) ./doc/glossary/glossary-terms.xml:5531(primary) ./doc/glossary/glossary-terms.xml:6754(primary) ./doc/glossary/glossary-terms.xml:6938(primary)#: ./doc/glossary/glossary-terms.xml:4818(glossterm)#: ./doc/glossary/glossary-terms.xml:4825(para)#: ./doc/glossary/glossary-terms.xml:4831(primary) ./doc/glossary/glossary-terms.xml:4846(primary) ./doc/glossary/glossary-terms.xml:5276(primary) ./doc/glossary/glossary-terms.xml:7181(primary)#: ./doc/glossary/glossary-terms.xml:4833(secondary) ./doc/glossary/glossary-terms.xml:4835(primary) ./doc/glossary/glossary-terms.xml:7162(see)#: ./doc/glossary/glossary-terms.xml:4830(glossterm)#: ./doc/glossary/glossary-terms.xml:4839(para)#: ./doc/glossary/glossary-terms.xml:4848(secondary)#: ./doc/glossary/glossary-terms.xml:4850(primary)#: ./doc/glossary/glossary-terms.xml:4845(glossterm)#: ./doc/glossary/glossary-terms.xml:4854(para)#: ./doc/glossary/glossary-terms.xml:4861(primary)#: ./doc/glossary/glossary-terms.xml:4860(glossterm)#: ./doc/glossary/glossary-terms.xml:4867(para)#: ./doc/glossary/glossary-terms.xml:4872(glossterm) ./doc/glossary/glossary-terms.xml:4881(primary) ./doc/glossary/glossary-terms.xml:4893(primary)#: ./doc/glossary/glossary-terms.xml:4875(para)#: ./doc/glossary/glossary-terms.xml:4880(glossterm)#: ./doc/glossary/glossary-terms.xml:4887(para)#: ./doc/glossary/glossary-terms.xml:4895(secondary)#: ./doc/glossary/glossary-terms.xml:4892(glossterm)#: ./doc/glossary/glossary-terms.xml:4899(para)#: ./doc/glossary/glossary-terms.xml:4909(title)#: ./doc/glossary/glossary-terms.xml:4912(glossterm)#: ./doc/glossary/glossary-terms.xml:4919(para)#: ./doc/glossary/glossary-terms.xml:4928(secondary)#: ./doc/glossary/glossary-terms.xml:4925(glossterm)#: ./doc/glossary/glossary-terms.xml:4932(para)#: ./doc/glossary/glossary-terms.xml:4941(secondary)#: ./doc/glossary/glossary-terms.xml:4938(glossterm)#: ./doc/glossary/glossary-terms.xml:4945(para)#: ./doc/glossary/glossary-terms.xml:4955(secondary)#: ./doc/glossary/glossary-terms.xml:4952(glossterm)#: ./doc/glossary/glossary-terms.xml:4959(para)#: ./doc/glossary/glossary-terms.xml:4967(secondary)#: ./doc/glossary/glossary-terms.xml:4964(glossterm)#: ./doc/glossary/glossary-terms.xml:4971(para)#: ./doc/glossary/glossary-terms.xml:4980(secondary)#: ./doc/glossary/glossary-terms.xml:4977(glossterm)#: ./doc/glossary/glossary-terms.xml:4984(para)#: ./doc/glossary/glossary-terms.xml:4993(secondary)#: ./doc/glossary/glossary-terms.xml:4990(glossterm)#: ./doc/glossary/glossary-terms.xml:4997(para)#: ./doc/glossary/glossary-terms.xml:5003(glossterm) ./doc/glossary/glossary-terms.xml:5018(primary) ./doc/glossary/glossary-terms.xml:5030(primary)#: ./doc/glossary/glossary-terms.xml:5006(para)#: ./doc/glossary/glossary-terms.xml:5014(primary) ./doc/glossary/glossary-terms.xml:6887(glossterm) ./doc/glossary/glossary-terms.xml:6908(primary) ./doc/glossary/glossary-terms.xml:6921(primary) ./doc/glossary/glossary-terms.xml:6942(primary)#: ./doc/glossary/glossary-terms.xml:5016(secondary) ./doc/glossary/glossary-terms.xml:5020(secondary)#: ./doc/glossary/glossary-terms.xml:5013(glossterm)#: ./doc/glossary/glossary-terms.xml:5024(para)#: ./doc/glossary/glossary-terms.xml:5032(secondary)#: ./doc/glossary/glossary-terms.xml:5029(glossterm)#: ./doc/glossary/glossary-terms.xml:5036(para)#: ./doc/glossary/glossary-terms.xml:5044(secondary)#: ./doc/glossary/glossary-terms.xml:5041(glossterm)#: ./doc/glossary/glossary-terms.xml:5048(para)#: ./doc/glossary/glossary-terms.xml:5055(primary)#: ./doc/glossary/glossary-terms.xml:5054(glossterm)#: ./doc/glossary/glossary-terms.xml:5059(para)#: ./doc/glossary/glossary-terms.xml:5067(primary)#: ./doc/glossary/glossary-terms.xml:5065(glossterm)#: ./doc/glossary/glossary-terms.xml:5071(para)#: ./doc/glossary/glossary-terms.xml:5078(primary)#: ./doc/glossary/glossary-terms.xml:5077(glossterm)#: ./doc/glossary/glossary-terms.xml:5082(para)#: ./doc/glossary/glossary-terms.xml:5088(primary)#: ./doc/glossary/glossary-terms.xml:5087(glossterm)#: ./doc/glossary/glossary-terms.xml:5094(para)#: ./doc/glossary/glossary-terms.xml:5100(primary)#: ./doc/glossary/glossary-terms.xml:5099(glossterm)#: ./doc/glossary/glossary-terms.xml:5104(para)#: ./doc/glossary/glossary-terms.xml:5111(primary) ./doc/glossary/glossary-terms.xml:5128(primary)#: ./doc/glossary/glossary-terms.xml:5110(glossterm)#: ./doc/glossary/glossary-terms.xml:5117(para)#: ./doc/glossary/glossary-terms.xml:5129(secondary)#: ./doc/glossary/glossary-terms.xml:5127(glossterm)#: ./doc/glossary/glossary-terms.xml:5133(para)#: ./doc/glossary/glossary-terms.xml:5148(primary)#: ./doc/glossary/glossary-terms.xml:5147(glossterm)#: ./doc/glossary/glossary-terms.xml:5158(primary)#: ./doc/glossary/glossary-terms.xml:5157(glossterm)#: ./doc/glossary/glossary-terms.xml:5162(para)#: ./doc/glossary/glossary-terms.xml:5169(primary)#: ./doc/glossary/glossary-terms.xml:5168(glossterm)#: ./doc/glossary/glossary-terms.xml:5173(para)#: ./doc/glossary/glossary-terms.xml:5181(primary)#: ./doc/glossary/glossary-terms.xml:5180(glossterm)#: ./doc/glossary/glossary-terms.xml:5185(para)#: ./doc/glossary/glossary-terms.xml:5194(title)#: ./doc/glossary/glossary-terms.xml:5200(secondary) ./doc/glossary/glossary-terms.xml:5202(primary)#: ./doc/glossary/glossary-terms.xml:5197(glossterm)#: ./doc/glossary/glossary-terms.xml:5206(para)#: ./doc/glossary/glossary-terms.xml:5214(primary) ./doc/glossary/glossary-terms.xml:5228(primary) ./doc/glossary/glossary-terms.xml:5241(primary)#: ./doc/glossary/glossary-terms.xml:5213(glossterm)#: ./doc/glossary/glossary-terms.xml:5220(para)#: ./doc/glossary/glossary-terms.xml:5230(secondary)#: ./doc/glossary/glossary-terms.xml:5227(glossterm)#: ./doc/glossary/glossary-terms.xml:5234(para)#: ./doc/glossary/glossary-terms.xml:5243(secondary)#: ./doc/glossary/glossary-terms.xml:5240(glossterm)#: ./doc/glossary/glossary-terms.xml:5247(para)#: ./doc/glossary/glossary-terms.xml:5254(primary)#: ./doc/glossary/glossary-terms.xml:5253(glossterm)#: ./doc/glossary/glossary-terms.xml:5258(para)#: ./doc/glossary/glossary-terms.xml:5265(primary)#: ./doc/glossary/glossary-terms.xml:5264(glossterm)#: ./doc/glossary/glossary-terms.xml:5269(para)#: ./doc/glossary/glossary-terms.xml:5278(secondary) ./doc/glossary/glossary-terms.xml:5280(primary)#: ./doc/glossary/glossary-terms.xml:5275(glossterm)#: ./doc/glossary/glossary-terms.xml:5284(para)#: ./doc/glossary/glossary-terms.xml:5291(primary)#: ./doc/glossary/glossary-terms.xml:5290(glossterm)#: ./doc/glossary/glossary-terms.xml:5295(para)#: ./doc/glossary/glossary-terms.xml:5301(primary)#: ./doc/glossary/glossary-terms.xml:5300(glossterm)#: ./doc/glossary/glossary-terms.xml:5305(para)#: ./doc/glossary/glossary-terms.xml:5312(primary)#: ./doc/glossary/glossary-terms.xml:5311(glossterm)#: ./doc/glossary/glossary-terms.xml:5316(para)#: ./doc/glossary/glossary-terms.xml:5326(primary)#: ./doc/glossary/glossary-terms.xml:5325(glossterm)#: ./doc/glossary/glossary-terms.xml:5330(para)#: ./doc/glossary/glossary-terms.xml:5337(primary)#: ./doc/glossary/glossary-terms.xml:5336(glossterm)#: ./doc/glossary/glossary-terms.xml:5341(para)#: ./doc/glossary/glossary-terms.xml:5348(primary)#: ./doc/glossary/glossary-terms.xml:5347(glossterm)#: ./doc/glossary/glossary-terms.xml:5352(para)#: ./doc/glossary/glossary-terms.xml:5362(primary)#: ./doc/glossary/glossary-terms.xml:5361(glossterm)#: ./doc/glossary/glossary-terms.xml:5366(para)#: ./doc/glossary/glossary-terms.xml:5373(primary) ./doc/glossary/glossary-terms.xml:5386(primary) ./doc/glossary/glossary-terms.xml:7435(primary)#: ./doc/glossary/glossary-terms.xml:5372(glossterm)#: ./doc/glossary/glossary-terms.xml:5379(para)#: ./doc/glossary/glossary-terms.xml:5388(secondary)#: ./doc/glossary/glossary-terms.xml:5385(glossterm)#: ./doc/glossary/glossary-terms.xml:5392(para)#: ./doc/glossary/glossary-terms.xml:5398(primary)#: ./doc/glossary/glossary-terms.xml:5397(glossterm)#: ./doc/glossary/glossary-terms.xml:5402(para)#: ./doc/glossary/glossary-terms.xml:5409(primary)#: ./doc/glossary/glossary-terms.xml:5408(glossterm)#: ./doc/glossary/glossary-terms.xml:5413(para)#: ./doc/glossary/glossary-terms.xml:5422(secondary)#: ./doc/glossary/glossary-terms.xml:5424(primary)#: ./doc/glossary/glossary-terms.xml:5419(glossterm)#: ./doc/glossary/glossary-terms.xml:5428(para)#: ./doc/glossary/glossary-terms.xml:5437(secondary) ./doc/glossary/glossary-terms.xml:5439(primary)#: ./doc/glossary/glossary-terms.xml:5434(glossterm)#: ./doc/glossary/glossary-terms.xml:5443(para)#: ./doc/glossary/glossary-terms.xml:5456(primary) ./doc/glossary/glossary-terms.xml:5469(primary) ./doc/glossary/glossary-terms.xml:5482(primary)#: ./doc/glossary/glossary-terms.xml:5455(glossterm)#: ./doc/glossary/glossary-terms.xml:5462(para)#: ./doc/glossary/glossary-terms.xml:5471(secondary)#: ./doc/glossary/glossary-terms.xml:5468(glossterm)#: ./doc/glossary/glossary-terms.xml:5475(para)#: ./doc/glossary/glossary-terms.xml:5484(secondary)#: ./doc/glossary/glossary-terms.xml:5481(glossterm)#: ./doc/glossary/glossary-terms.xml:5488(para)#: ./doc/glossary/glossary-terms.xml:5494(primary)#: ./doc/glossary/glossary-terms.xml:5493(glossterm)#: ./doc/glossary/glossary-terms.xml:5498(para)#: ./doc/glossary/glossary-terms.xml:5506(primary)#: ./doc/glossary/glossary-terms.xml:5505(glossterm)#: ./doc/glossary/glossary-terms.xml:5510(para)#: ./doc/glossary/glossary-terms.xml:5520(primary)#: ./doc/glossary/glossary-terms.xml:5519(glossterm)#: ./doc/glossary/glossary-terms.xml:5524(para)#: ./doc/glossary/glossary-terms.xml:5533(secondary) ./doc/glossary/glossary-terms.xml:5535(primary)#: ./doc/glossary/glossary-terms.xml:5530(glossterm)#: ./doc/glossary/glossary-terms.xml:5539(para)#: ./doc/glossary/glossary-terms.xml:5547(secondary) ./doc/glossary/glossary-terms.xml:5549(primary)#: ./doc/glossary/glossary-terms.xml:5544(glossterm)#: ./doc/glossary/glossary-terms.xml:5553(para)#: ./doc/glossary/glossary-terms.xml:5563(secondary)#: ./doc/glossary/glossary-terms.xml:5565(primary)#: ./doc/glossary/glossary-terms.xml:5560(glossterm)#: ./doc/glossary/glossary-terms.xml:5569(para)#: ./doc/glossary/glossary-terms.xml:5578(secondary)#: ./doc/glossary/glossary-terms.xml:5580(primary)#: ./doc/glossary/glossary-terms.xml:5575(glossterm)#: ./doc/glossary/glossary-terms.xml:5584(para)#: ./doc/glossary/glossary-terms.xml:5593(secondary) ./doc/glossary/glossary-terms.xml:5618(secondary)#: ./doc/glossary/glossary-terms.xml:5595(primary)#: ./doc/glossary/glossary-terms.xml:5590(glossterm)#: ./doc/glossary/glossary-terms.xml:5599(para)#: ./doc/glossary/glossary-terms.xml:5605(primary)#: ./doc/glossary/glossary-terms.xml:5604(glossterm)#: ./doc/glossary/glossary-terms.xml:5609(para)#: ./doc/glossary/glossary-terms.xml:5620(primary)#: ./doc/glossary/glossary-terms.xml:5615(glossterm)#: ./doc/glossary/glossary-terms.xml:5624(para)#: ./doc/glossary/glossary-terms.xml:5634(primary)#: ./doc/glossary/glossary-terms.xml:5633(glossterm)#: ./doc/glossary/glossary-terms.xml:5638(para)#: ./doc/glossary/glossary-terms.xml:5645(primary)#: ./doc/glossary/glossary-terms.xml:5644(glossterm)#: ./doc/glossary/glossary-terms.xml:5649(para)#: ./doc/glossary/glossary-terms.xml:5657(title)#: ./doc/glossary/glossary-terms.xml:5661(primary)#: ./doc/glossary/glossary-terms.xml:5660(glossterm)#: ./doc/glossary/glossary-terms.xml:5672(primary)#: ./doc/glossary/glossary-terms.xml:5671(glossterm)#: ./doc/glossary/glossary-terms.xml:5676(para)#: ./doc/glossary/glossary-terms.xml:5683(primary)#: ./doc/glossary/glossary-terms.xml:5682(glossterm)#: ./doc/glossary/glossary-terms.xml:5687(para)#: ./doc/glossary/glossary-terms.xml:5695(primary)#: ./doc/glossary/glossary-terms.xml:5694(glossterm)#: ./doc/glossary/glossary-terms.xml:5699(para)#: ./doc/glossary/glossary-terms.xml:5702(para)#: ./doc/glossary/glossary-terms.xml:5709(primary)#: ./doc/glossary/glossary-terms.xml:5708(glossterm)#: ./doc/glossary/glossary-terms.xml:5713(para)#: ./doc/glossary/glossary-terms.xml:5722(title)#: ./doc/glossary/glossary-terms.xml:5726(primary)#: ./doc/glossary/glossary-terms.xml:5725(glossterm)#: ./doc/glossary/glossary-terms.xml:5730(para)#: ./doc/glossary/glossary-terms.xml:5736(primary)#: ./doc/glossary/glossary-terms.xml:5735(glossterm)#: ./doc/glossary/glossary-terms.xml:5740(para)#: ./doc/glossary/glossary-terms.xml:5747(primary)#: ./doc/glossary/glossary-terms.xml:5746(glossterm)#: ./doc/glossary/glossary-terms.xml:5751(para)#: ./doc/glossary/glossary-terms.xml:5758(primary)#: ./doc/glossary/glossary-terms.xml:5757(glossterm)#: ./doc/glossary/glossary-terms.xml:5762(para)#: ./doc/glossary/glossary-terms.xml:5770(primary)#: ./doc/glossary/glossary-terms.xml:5769(glossterm)#: ./doc/glossary/glossary-terms.xml:5774(para)#: ./doc/glossary/glossary-terms.xml:5781(primary)#: ./doc/glossary/glossary-terms.xml:5780(glossterm)#: ./doc/glossary/glossary-terms.xml:5785(para)#: ./doc/glossary/glossary-terms.xml:5794(primary)#: ./doc/glossary/glossary-terms.xml:5793(glossterm)#: ./doc/glossary/glossary-terms.xml:5798(para)#: ./doc/glossary/glossary-terms.xml:5805(primary)#: ./doc/glossary/glossary-terms.xml:5804(glossterm)#: ./doc/glossary/glossary-terms.xml:5809(para)#: ./doc/glossary/glossary-terms.xml:5816(primary)#: ./doc/glossary/glossary-terms.xml:5815(glossterm)#: ./doc/glossary/glossary-terms.xml:5820(para)#: ./doc/glossary/glossary-terms.xml:5828(primary) ./doc/glossary/glossary-terms.xml:6619(primary)#: ./doc/glossary/glossary-terms.xml:5830(secondary) ./doc/glossary/glossary-terms.xml:6621(secondary)#: ./doc/glossary/glossary-terms.xml:5827(glossterm)#: ./doc/glossary/glossary-terms.xml:5834(para)#: ./doc/glossary/glossary-terms.xml:5845(primary)#: ./doc/glossary/glossary-terms.xml:5844(glossterm)#: ./doc/glossary/glossary-terms.xml:5849(para)#: ./doc/glossary/glossary-terms.xml:5856(primary)#: ./doc/glossary/glossary-terms.xml:5855(glossterm)#: ./doc/glossary/glossary-terms.xml:5860(para)#: ./doc/glossary/glossary-terms.xml:5866(primary) ./doc/glossary/glossary-terms.xml:5884(primary)#: ./doc/glossary/glossary-terms.xml:5865(glossterm)#: ./doc/glossary/glossary-terms.xml:5872(para)#: ./doc/glossary/glossary-terms.xml:5886(secondary)#: ./doc/glossary/glossary-terms.xml:5883(glossterm)#: ./doc/glossary/glossary-terms.xml:5890(para)#: ./doc/glossary/glossary-terms.xml:5897(primary)#: ./doc/glossary/glossary-terms.xml:5896(glossterm)#: ./doc/glossary/glossary-terms.xml:5907(primary)#: ./doc/glossary/glossary-terms.xml:5906(glossterm)#: ./doc/glossary/glossary-terms.xml:5911(para)#: ./doc/glossary/glossary-terms.xml:5917(primary)#: ./doc/glossary/glossary-terms.xml:5916(glossterm)#: ./doc/glossary/glossary-terms.xml:5921(para)#: ./doc/glossary/glossary-terms.xml:5929(primary)#: ./doc/glossary/glossary-terms.xml:5931(see)#: ./doc/glossary/glossary-terms.xml:5928(glossterm)#: ./doc/glossary/glossary-terms.xml:5935(para)#: ./doc/glossary/glossary-terms.xml:5943(secondary) ./doc/glossary/glossary-terms.xml:5945(primary)#: ./doc/glossary/glossary-terms.xml:5940(glossterm)#: ./doc/glossary/glossary-terms.xml:5949(para)#: ./doc/glossary/glossary-terms.xml:5957(primary)#: ./doc/glossary/glossary-terms.xml:5955(glossterm)#: ./doc/glossary/glossary-terms.xml:5962(para)#: ./doc/glossary/glossary-terms.xml:5969(primary)#: ./doc/glossary/glossary-terms.xml:5968(glossterm)#: ./doc/glossary/glossary-terms.xml:5973(para)#: ./doc/glossary/glossary-terms.xml:5980(primary) ./doc/glossary/glossary-terms.xml:5994(primary) ./doc/glossary/glossary-terms.xml:6006(glossterm) ./doc/glossary/glossary-terms.xml:6016(primary)#: ./doc/glossary/glossary-terms.xml:5979(glossterm)#: ./doc/glossary/glossary-terms.xml:5986(para)#: ./doc/glossary/glossary-terms.xml:5996(secondary)#: ./doc/glossary/glossary-terms.xml:5993(glossterm)#: ./doc/glossary/glossary-terms.xml:6000(para)#: ./doc/glossary/glossary-terms.xml:6009(para)#: ./doc/glossary/glossary-terms.xml:6018(secondary)#: ./doc/glossary/glossary-terms.xml:6015(glossterm)#: ./doc/glossary/glossary-terms.xml:6022(para)#: ./doc/glossary/glossary-terms.xml:6029(primary)#: ./doc/glossary/glossary-terms.xml:6028(glossterm)#: ./doc/glossary/glossary-terms.xml:6033(para)#: ./doc/glossary/glossary-terms.xml:6039(primary)#: ./doc/glossary/glossary-terms.xml:6038(glossterm)#: ./doc/glossary/glossary-terms.xml:6043(para)#: ./doc/glossary/glossary-terms.xml:6051(primary)#: ./doc/glossary/glossary-terms.xml:6050(glossterm)#: ./doc/glossary/glossary-terms.xml:6055(para)#: ./doc/glossary/glossary-terms.xml:6064(primary)#: ./doc/glossary/glossary-terms.xml:6063(glossterm)#: ./doc/glossary/glossary-terms.xml:6068(para)#: ./doc/glossary/glossary-terms.xml:6076(primary) ./doc/glossary/glossary-terms.xml:6090(primary)#: ./doc/glossary/glossary-terms.xml:6075(glossterm)#: ./doc/glossary/glossary-terms.xml:6082(para)#: ./doc/glossary/glossary-terms.xml:6092(secondary)#: ./doc/glossary/glossary-terms.xml:6089(glossterm)#: ./doc/glossary/glossary-terms.xml:6096(para)#: ./doc/glossary/glossary-terms.xml:6104(primary)#: ./doc/glossary/glossary-terms.xml:6103(glossterm)#: ./doc/glossary/glossary-terms.xml:6108(para)#: ./doc/glossary/glossary-terms.xml:6117(primary) ./doc/glossary/glossary-terms.xml:6131(primary)#: ./doc/glossary/glossary-terms.xml:6116(glossterm)#: ./doc/glossary/glossary-terms.xml:6123(para)#: ./doc/glossary/glossary-terms.xml:6133(secondary)#: ./doc/glossary/glossary-terms.xml:6130(glossterm)#: ./doc/glossary/glossary-terms.xml:6137(para)#: ./doc/glossary/glossary-terms.xml:6143(primary)#: ./doc/glossary/glossary-terms.xml:6142(glossterm)#: ./doc/glossary/glossary-terms.xml:6147(para)#: ./doc/glossary/glossary-terms.xml:6154(primary) ./doc/glossary/glossary-terms.xml:6658(primary)#: ./doc/glossary/glossary-terms.xml:6156(secondary)#: ./doc/glossary/glossary-terms.xml:6158(primary)#: ./doc/glossary/glossary-terms.xml:6153(glossterm)#: ./doc/glossary/glossary-terms.xml:6162(para)#: ./doc/glossary/glossary-terms.xml:6169(primary)#: ./doc/glossary/glossary-terms.xml:6168(glossterm)#: ./doc/glossary/glossary-terms.xml:6173(para)#: ./doc/glossary/glossary-terms.xml:6180(primary)#: ./doc/glossary/glossary-terms.xml:6179(glossterm)#: ./doc/glossary/glossary-terms.xml:6184(para)#: ./doc/glossary/glossary-terms.xml:6192(primary)#: ./doc/glossary/glossary-terms.xml:6194(secondary) ./doc/glossary/glossary-terms.xml:6196(primary)#: ./doc/glossary/glossary-terms.xml:6191(glossterm)#: ./doc/glossary/glossary-terms.xml:6200(para)#: ./doc/glossary/glossary-terms.xml:6208(primary)#: ./doc/glossary/glossary-terms.xml:6207(glossterm)#: ./doc/glossary/glossary-terms.xml:6212(para)#: ./doc/glossary/glossary-terms.xml:6218(primary)#: ./doc/glossary/glossary-terms.xml:6217(glossterm)#: ./doc/glossary/glossary-terms.xml:6222(para)#: ./doc/glossary/glossary-terms.xml:6228(glossterm)#: ./doc/glossary/glossary-terms.xml:6231(para)#: ./doc/glossary/glossary-terms.xml:6238(primary)#: ./doc/glossary/glossary-terms.xml:6237(glossterm)#: ./doc/glossary/glossary-terms.xml:6242(para)#: ./doc/glossary/glossary-terms.xml:6251(title)#: ./doc/glossary/glossary-terms.xml:6255(primary)#: ./doc/glossary/glossary-terms.xml:6254(glossterm)#: ./doc/glossary/glossary-terms.xml:6259(para)#: ./doc/glossary/glossary-terms.xml:6267(primary)#: ./doc/glossary/glossary-terms.xml:6266(glossterm)#: ./doc/glossary/glossary-terms.xml:6271(para)#: ./doc/glossary/glossary-terms.xml:6278(primary)#: ./doc/glossary/glossary-terms.xml:6277(glossterm)#: ./doc/glossary/glossary-terms.xml:6282(para)#: ./doc/glossary/glossary-terms.xml:6290(primary)#: ./doc/glossary/glossary-terms.xml:6289(glossterm)#: ./doc/glossary/glossary-terms.xml:6294(para)#: ./doc/glossary/glossary-terms.xml:6301(primary)#: ./doc/glossary/glossary-terms.xml:6300(glossterm)#: ./doc/glossary/glossary-terms.xml:6305(para)#: ./doc/glossary/glossary-terms.xml:6312(primary)#: ./doc/glossary/glossary-terms.xml:6311(glossterm)#: ./doc/glossary/glossary-terms.xml:6316(para)#: ./doc/glossary/glossary-terms.xml:6323(primary)#: ./doc/glossary/glossary-terms.xml:6322(glossterm)#: ./doc/glossary/glossary-terms.xml:6327(para)#: ./doc/glossary/glossary-terms.xml:6335(primary)#: ./doc/glossary/glossary-terms.xml:6334(glossterm)#: ./doc/glossary/glossary-terms.xml:6339(para)#: ./doc/glossary/glossary-terms.xml:6348(secondary) ./doc/glossary/glossary-terms.xml:6350(primary)#: ./doc/glossary/glossary-terms.xml:6345(glossterm)#: ./doc/glossary/glossary-terms.xml:6354(para)#: ./doc/glossary/glossary-terms.xml:6361(glossterm)#: ./doc/glossary/glossary-terms.xml:6368(para)#: ./doc/glossary/glossary-terms.xml:6372(para)#: ./doc/glossary/glossary-terms.xml:6379(primary)#: ./doc/glossary/glossary-terms.xml:6378(glossterm)#: ./doc/glossary/glossary-terms.xml:6383(para)#: ./doc/glossary/glossary-terms.xml:6391(secondary)#: ./doc/glossary/glossary-terms.xml:6388(glossterm)#: ./doc/glossary/glossary-terms.xml:6402(primary)#: ./doc/glossary/glossary-terms.xml:6401(glossterm)#: ./doc/glossary/glossary-terms.xml:6408(para)#: ./doc/glossary/glossary-terms.xml:6416(primary)#: ./doc/glossary/glossary-terms.xml:6415(glossterm)#: ./doc/glossary/glossary-terms.xml:6420(para)#: ./doc/glossary/glossary-terms.xml:6426(primary)#: ./doc/glossary/glossary-terms.xml:6425(glossterm)#: ./doc/glossary/glossary-terms.xml:6430(para)#: ./doc/glossary/glossary-terms.xml:6437(primary)#: ./doc/glossary/glossary-terms.xml:6436(glossterm)#: ./doc/glossary/glossary-terms.xml:6441(para)#: ./doc/glossary/glossary-terms.xml:6448(primary)#: ./doc/glossary/glossary-terms.xml:6447(glossterm)#: ./doc/glossary/glossary-terms.xml:6452(para)#: ./doc/glossary/glossary-terms.xml:6459(primary)#: ./doc/glossary/glossary-terms.xml:6458(glossterm)#: ./doc/glossary/glossary-terms.xml:6463(para)#: ./doc/glossary/glossary-terms.xml:6470(primary) ./doc/glossary/glossary-terms.xml:6483(primary) ./doc/glossary/glossary-terms.xml:6497(primary)#: ./doc/glossary/glossary-terms.xml:6472(secondary)#: ./doc/glossary/glossary-terms.xml:6469(glossterm)#: ./doc/glossary/glossary-terms.xml:6476(para)#: ./doc/glossary/glossary-terms.xml:6485(secondary)#: ./doc/glossary/glossary-terms.xml:6482(glossterm)#: ./doc/glossary/glossary-terms.xml:6489(para)#: ./doc/glossary/glossary-terms.xml:6499(secondary)#: ./doc/glossary/glossary-terms.xml:6496(glossterm)#: ./doc/glossary/glossary-terms.xml:6503(para)#: ./doc/glossary/glossary-terms.xml:6512(secondary)#: ./doc/glossary/glossary-terms.xml:6514(primary)#: ./doc/glossary/glossary-terms.xml:6509(glossterm)#: ./doc/glossary/glossary-terms.xml:6518(para)#: ./doc/glossary/glossary-terms.xml:6532(primary)#: ./doc/glossary/glossary-terms.xml:6531(glossterm)#: ./doc/glossary/glossary-terms.xml:6536(para)#: ./doc/glossary/glossary-terms.xml:6546(primary)#: ./doc/glossary/glossary-terms.xml:6545(glossterm)#: ./doc/glossary/glossary-terms.xml:6550(para)#: ./doc/glossary/glossary-terms.xml:6557(primary)#: ./doc/glossary/glossary-terms.xml:6556(glossterm)#: ./doc/glossary/glossary-terms.xml:6561(para)#: ./doc/glossary/glossary-terms.xml:6569(primary)#: ./doc/glossary/glossary-terms.xml:6567(glossterm)#: ./doc/glossary/glossary-terms.xml:6573(para)#: ./doc/glossary/glossary-terms.xml:6581(primary)#: ./doc/glossary/glossary-terms.xml:6579(glossterm)#: ./doc/glossary/glossary-terms.xml:6585(para)#: ./doc/glossary/glossary-terms.xml:6596(primary)#: ./doc/glossary/glossary-terms.xml:6595(glossterm)#: ./doc/glossary/glossary-terms.xml:6600(para)#: ./doc/glossary/glossary-terms.xml:6607(primary)#: ./doc/glossary/glossary-terms.xml:6606(glossterm)#: ./doc/glossary/glossary-terms.xml:6611(para)#: ./doc/glossary/glossary-terms.xml:6623(primary)#: ./doc/glossary/glossary-terms.xml:6618(glossterm)#: ./doc/glossary/glossary-terms.xml:6627(para)#: ./doc/glossary/glossary-terms.xml:6634(primary)#: ./doc/glossary/glossary-terms.xml:6633(glossterm)#: ./doc/glossary/glossary-terms.xml:6638(para)#: ./doc/glossary/glossary-terms.xml:6645(primary)#: ./doc/glossary/glossary-terms.xml:6644(glossterm)#: ./doc/glossary/glossary-terms.xml:6650(para)#: ./doc/glossary/glossary-terms.xml:6660(secondary)#: ./doc/glossary/glossary-terms.xml:6662(primary)#: ./doc/glossary/glossary-terms.xml:6657(glossterm)#: ./doc/glossary/glossary-terms.xml:6666(para)#: ./doc/glossary/glossary-terms.xml:6673(primary)#: ./doc/glossary/glossary-terms.xml:6672(glossterm)#: ./doc/glossary/glossary-terms.xml:6677(para)#: ./doc/glossary/glossary-terms.xml:6683(primary)#: ./doc/glossary/glossary-terms.xml:6682(glossterm)#: ./doc/glossary/glossary-terms.xml:6687(para)#: ./doc/glossary/glossary-terms.xml:6694(primary)#: ./doc/glossary/glossary-terms.xml:6693(glossterm)#: ./doc/glossary/glossary-terms.xml:6698(para)#: ./doc/glossary/glossary-terms.xml:6707(primary)#: ./doc/glossary/glossary-terms.xml:6706(glossterm)#: ./doc/glossary/glossary-terms.xml:6711(para)#: ./doc/glossary/glossary-terms.xml:6720(secondary)#: ./doc/glossary/glossary-terms.xml:6722(primary)#: ./doc/glossary/glossary-terms.xml:6717(glossterm)#: ./doc/glossary/glossary-terms.xml:6726(para)#: ./doc/glossary/glossary-terms.xml:6732(primary)#: ./doc/glossary/glossary-terms.xml:6731(glossterm)#: ./doc/glossary/glossary-terms.xml:6736(para)#: ./doc/glossary/glossary-terms.xml:6743(primary)#: ./doc/glossary/glossary-terms.xml:6742(glossterm)#: ./doc/glossary/glossary-terms.xml:6747(para)#: ./doc/glossary/glossary-terms.xml:6756(secondary)#: ./doc/glossary/glossary-terms.xml:6758(primary)#: ./doc/glossary/glossary-terms.xml:6753(glossterm)#: ./doc/glossary/glossary-terms.xml:6762(para)#: ./doc/glossary/glossary-terms.xml:6770(primary) ./doc/glossary/glossary-terms.xml:6783(primary) ./doc/glossary/glossary-terms.xml:6796(primary) ./doc/glossary/glossary-terms.xml:6934(primary)#: ./doc/glossary/glossary-terms.xml:6772(secondary)#: ./doc/glossary/glossary-terms.xml:6769(glossterm)#: ./doc/glossary/glossary-terms.xml:6776(para)#: ./doc/glossary/glossary-terms.xml:6785(secondary)#: ./doc/glossary/glossary-terms.xml:6782(glossterm)#: ./doc/glossary/glossary-terms.xml:6789(para)#: ./doc/glossary/glossary-terms.xml:6798(secondary)#: ./doc/glossary/glossary-terms.xml:6795(glossterm)#: ./doc/glossary/glossary-terms.xml:6802(para)#: ./doc/glossary/glossary-terms.xml:6809(primary)#: ./doc/glossary/glossary-terms.xml:6808(glossterm)#: ./doc/glossary/glossary-terms.xml:6813(para)#: ./doc/glossary/glossary-terms.xml:6820(primary)#: ./doc/glossary/glossary-terms.xml:6819(glossterm)#: ./doc/glossary/glossary-terms.xml:6824(para)#: ./doc/glossary/glossary-terms.xml:6833(primary)#: ./doc/glossary/glossary-terms.xml:6832(glossterm)#: ./doc/glossary/glossary-terms.xml:6837(para)#: ./doc/glossary/glossary-terms.xml:6844(primary)#: ./doc/glossary/glossary-terms.xml:6842(glossterm)#: ./doc/glossary/glossary-terms.xml:6854(primary)#: ./doc/glossary/glossary-terms.xml:6853(glossterm)#: ./doc/glossary/glossary-terms.xml:6858(para)#: ./doc/glossary/glossary-terms.xml:6865(primary)#: ./doc/glossary/glossary-terms.xml:6864(glossterm)#: ./doc/glossary/glossary-terms.xml:6869(para)#: ./doc/glossary/glossary-terms.xml:6876(primary)#: ./doc/glossary/glossary-terms.xml:6875(glossterm)#: ./doc/glossary/glossary-terms.xml:6880(para)#: ./doc/glossary/glossary-terms.xml:6890(para)#: ./doc/glossary/glossary-terms.xml:6897(primary)#: ./doc/glossary/glossary-terms.xml:6896(glossterm)#: ./doc/glossary/glossary-terms.xml:6901(para)#: ./doc/glossary/glossary-terms.xml:6910(secondary)#: ./doc/glossary/glossary-terms.xml:6907(glossterm)#: ./doc/glossary/glossary-terms.xml:6914(para)#: ./doc/glossary/glossary-terms.xml:6923(secondary)#: ./doc/glossary/glossary-terms.xml:6920(glossterm)#: ./doc/glossary/glossary-terms.xml:6927(para)#: ./doc/glossary/glossary-terms.xml:6936(secondary) ./doc/glossary/glossary-terms.xml:6940(secondary) ./doc/glossary/glossary-terms.xml:6944(secondary)#: ./doc/glossary/glossary-terms.xml:6933(glossterm)#: ./doc/glossary/glossary-terms.xml:6948(para)#: ./doc/glossary/glossary-terms.xml:6955(primary)#: ./doc/glossary/glossary-terms.xml:6954(glossterm)#: ./doc/glossary/glossary-terms.xml:6959(para)#: ./doc/glossary/glossary-terms.xml:6966(primary)#: ./doc/glossary/glossary-terms.xml:6965(glossterm)#: ./doc/glossary/glossary-terms.xml:6970(para)#: ./doc/glossary/glossary-terms.xml:6978(primary)#: ./doc/glossary/glossary-terms.xml:6977(glossterm)#: ./doc/glossary/glossary-terms.xml:6982(para)#: ./doc/glossary/glossary-terms.xml:6992(title)#: ./doc/glossary/glossary-terms.xml:6996(primary)#: ./doc/glossary/glossary-terms.xml:6995(glossterm)#: ./doc/glossary/glossary-terms.xml:7000(para)#: ./doc/glossary/glossary-terms.xml:7008(primary)#: ./doc/glossary/glossary-terms.xml:7007(glossterm)#: ./doc/glossary/glossary-terms.xml:7012(para)#: ./doc/glossary/glossary-terms.xml:7020(primary)#: ./doc/glossary/glossary-terms.xml:7019(glossterm)#: ./doc/glossary/glossary-terms.xml:7024(para)#: ./doc/glossary/glossary-terms.xml:7031(primary)#: ./doc/glossary/glossary-terms.xml:7030(glossterm)#: ./doc/glossary/glossary-terms.xml:7035(para)#: ./doc/glossary/glossary-terms.xml:7041(glossterm) ./doc/glossary/glossary-terms.xml:7051(primary) ./doc/glossary/glossary-terms.xml:7067(primary) ./doc/glossary/glossary-terms.xml:7080(primary)#: ./doc/glossary/glossary-terms.xml:7044(para)#: ./doc/glossary/glossary-terms.xml:7053(secondary)#: ./doc/glossary/glossary-terms.xml:7050(glossterm)#: ./doc/glossary/glossary-terms.xml:7057(para)#: ./doc/glossary/glossary-terms.xml:7065(secondary) ./doc/glossary/glossary-terms.xml:7069(secondary)#: ./doc/glossary/glossary-terms.xml:7062(glossterm)#: ./doc/glossary/glossary-terms.xml:7073(para)#: ./doc/glossary/glossary-terms.xml:7082(secondary)#: ./doc/glossary/glossary-terms.xml:7079(glossterm)#: ./doc/glossary/glossary-terms.xml:7086(para)#: ./doc/glossary/glossary-terms.xml:7093(primary)#: ./doc/glossary/glossary-terms.xml:7092(glossterm)#: ./doc/glossary/glossary-terms.xml:7097(para)#: ./doc/glossary/glossary-terms.xml:7104(primary)#: ./doc/glossary/glossary-terms.xml:7103(glossterm)#: ./doc/glossary/glossary-terms.xml:7108(para)#: ./doc/glossary/glossary-terms.xml:7114(glossterm)#: ./doc/glossary/glossary-terms.xml:7117(para)#: ./doc/glossary/glossary-terms.xml:7127(primary)#: ./doc/glossary/glossary-terms.xml:7126(glossterm)#: ./doc/glossary/glossary-terms.xml:7131(para)#: ./doc/glossary/glossary-terms.xml:7138(primary)#: ./doc/glossary/glossary-terms.xml:7137(glossterm)#: ./doc/glossary/glossary-terms.xml:7142(para)#: ./doc/glossary/glossary-terms.xml:7149(primary)#: ./doc/glossary/glossary-terms.xml:7148(glossterm)#: ./doc/glossary/glossary-terms.xml:7153(para)#: ./doc/glossary/glossary-terms.xml:7160(primary)#: ./doc/glossary/glossary-terms.xml:7159(glossterm)#: ./doc/glossary/glossary-terms.xml:7166(para)#: ./doc/glossary/glossary-terms.xml:7171(glossterm)#: ./doc/glossary/glossary-terms.xml:7174(para)#: ./doc/glossary/glossary-terms.xml:7183(secondary) ./doc/glossary/glossary-terms.xml:7185(primary)#: ./doc/glossary/glossary-terms.xml:7180(glossterm)#: ./doc/glossary/glossary-terms.xml:7189(para)#: ./doc/glossary/glossary-terms.xml:7198(secondary) ./doc/glossary/glossary-terms.xml:7200(primary)#: ./doc/glossary/glossary-terms.xml:7195(glossterm)#: ./doc/glossary/glossary-terms.xml:7204(para)#: ./doc/glossary/glossary-terms.xml:7210(primary)#: ./doc/glossary/glossary-terms.xml:7209(glossterm)#: ./doc/glossary/glossary-terms.xml:7214(para)#: ./doc/glossary/glossary-terms.xml:7223(title)#: ./doc/glossary/glossary-terms.xml:7227(primary)#: ./doc/glossary/glossary-terms.xml:7226(glossterm)#: ./doc/glossary/glossary-terms.xml:7231(para)#: ./doc/glossary/glossary-terms.xml:7237(primary)#: ./doc/glossary/glossary-terms.xml:7236(glossterm)#: ./doc/glossary/glossary-terms.xml:7241(para)#: ./doc/glossary/glossary-terms.xml:7247(primary)#: ./doc/glossary/glossary-terms.xml:7246(glossterm)#: ./doc/glossary/glossary-terms.xml:7251(para)#: ./doc/glossary/glossary-terms.xml:7258(primary)#: ./doc/glossary/glossary-terms.xml:7257(glossterm)#: ./doc/glossary/glossary-terms.xml:7262(para)#: ./doc/glossary/glossary-terms.xml:7270(primary)#: ./doc/glossary/glossary-terms.xml:7269(glossterm)#: ./doc/glossary/glossary-terms.xml:7274(para)#: ./doc/glossary/glossary-terms.xml:7284(primary)#: ./doc/glossary/glossary-terms.xml:7283(glossterm)#: ./doc/glossary/glossary-terms.xml:7296(title)#: ./doc/glossary/glossary-terms.xml:7300(primary)#: ./doc/glossary/glossary-terms.xml:7299(glossterm)#: ./doc/glossary/glossary-terms.xml:7304(para)#: ./doc/glossary/glossary-terms.xml:7310(primary)#: ./doc/glossary/glossary-terms.xml:7309(glossterm)#: ./doc/glossary/glossary-terms.xml:7314(para)#: ./doc/glossary/glossary-terms.xml:7326(primary)#: ./doc/glossary/glossary-terms.xml:7324(glossterm)#: ./doc/glossary/glossary-terms.xml:7330(para)#: ./doc/glossary/glossary-terms.xml:7337(primary)#: ./doc/glossary/glossary-terms.xml:7336(glossterm)#: ./doc/glossary/glossary-terms.xml:7348(primary)#: ./doc/glossary/glossary-terms.xml:7347(glossterm)#: ./doc/glossary/glossary-terms.xml:7359(primary)#: ./doc/glossary/glossary-terms.xml:7358(glossterm)#: ./doc/glossary/glossary-terms.xml:7363(para)#: ./doc/glossary/glossary-terms.xml:7372(primary)#: ./doc/glossary/glossary-terms.xml:7371(glossterm)#: ./doc/glossary/glossary-terms.xml:7376(para)#: ./doc/glossary/glossary-terms.xml:7386(secondary) ./doc/glossary/glossary-terms.xml:7437(secondary) ./doc/glossary/glossary-terms.xml:7464(secondary)#: ./doc/glossary/glossary-terms.xml:7388(primary)#: ./doc/glossary/glossary-terms.xml:7383(glossterm)#: ./doc/glossary/glossary-terms.xml:7392(para)#: ./doc/glossary/glossary-terms.xml:7398(primary)#: ./doc/glossary/glossary-terms.xml:7397(glossterm)#: ./doc/glossary/glossary-terms.xml:7402(para)#: ./doc/glossary/glossary-terms.xml:7412(primary)#: ./doc/glossary/glossary-terms.xml:7411(glossterm)#: ./doc/glossary/glossary-terms.xml:7416(para)#: ./doc/glossary/glossary-terms.xml:7423(primary)#: ./doc/glossary/glossary-terms.xml:7422(glossterm)#: ./doc/glossary/glossary-terms.xml:7427(para)#: ./doc/glossary/glossary-terms.xml:7439(primary)#: ./doc/glossary/glossary-terms.xml:7434(glossterm)#: ./doc/glossary/glossary-terms.xml:7443(para)#: ./doc/glossary/glossary-terms.xml:7450(primary)#: ./doc/glossary/glossary-terms.xml:7449(glossterm)#: ./doc/glossary/glossary-terms.xml:7454(para)#: ./doc/glossary/glossary-terms.xml:7466(primary)#: ./doc/glossary/glossary-terms.xml:7461(glossterm)#: ./doc/glossary/glossary-terms.xml:7470(para)#: ./doc/glossary/glossary-terms.xml:7476(primary)#: ./doc/glossary/glossary-terms.xml:7475(glossterm)#: ./doc/glossary/glossary-terms.xml:7480(para)#: ./doc/glossary/glossary-terms.xml:7487(primary)#: ./doc/glossary/glossary-terms.xml:7486(glossterm)#: ./doc/glossary/glossary-terms.xml:7491(para)#: ./doc/glossary/glossary-terms.xml:7497(primary)#: ./doc/glossary/glossary-terms.xml:7496(glossterm)#: ./doc/glossary/glossary-terms.xml:7507(primary)#: ./doc/glossary/glossary-terms.xml:7506(glossterm)#: ./doc/glossary/glossary-terms.xml:7511(para)#: ./doc/glossary/glossary-terms.xml:7520(secondary)#: ./doc/glossary/glossary-terms.xml:7522(primary)#: ./doc/glossary/glossary-terms.xml:7517(glossterm)#: ./doc/glossary/glossary-terms.xml:7526(para)#: ./doc/glossary/glossary-terms.xml:7537(primary)#: ./doc/glossary/glossary-terms.xml:7536(glossterm)#: ./doc/glossary/glossary-terms.xml:7548(primary)#: ./doc/glossary/glossary-terms.xml:7547(glossterm)#: ./doc/glossary/glossary-terms.xml:7552(para)#: ./doc/glossary/glossary-terms.xml:7558(primary)#: ./doc/glossary/glossary-terms.xml:7557(glossterm)#: ./doc/glossary/glossary-terms.xml:7562(para)#: ./doc/glossary/glossary-terms.xml:7569(primary)#: ./doc/glossary/glossary-terms.xml:7568(glossterm)#: ./doc/glossary/glossary-terms.xml:7573(para)#: ./doc/glossary/glossary-terms.xml:7578(glossterm)#: ./doc/glossary/glossary-terms.xml:7581(para)#: ./doc/glossary/glossary-terms.xml:7587(primary)#: ./doc/glossary/glossary-terms.xml:7586(glossterm)#: ./doc/glossary/glossary-terms.xml:7591(para)#: ./doc/glossary/glossary-terms.xml:7597(glossterm) ./doc/glossary/glossary-terms.xml:7608(primary) ./doc/glossary/glossary-terms.xml:7620(primary) ./doc/glossary/glossary-terms.xml:7633(primary) ./doc/glossary/glossary-terms.xml:7645(primary) ./doc/glossary/glossary-terms.xml:7658(primary) ./doc/glossary/glossary-terms.xml:7671(primary) ./doc/glossary/glossary-terms.xml:7684(primary)#: ./doc/glossary/glossary-terms.xml:7600(para)#: ./doc/glossary/glossary-terms.xml:7610(secondary)#: ./doc/glossary/glossary-terms.xml:7607(glossterm)#: ./doc/glossary/glossary-terms.xml:7614(para)#: ./doc/glossary/glossary-terms.xml:7622(secondary)#: ./doc/glossary/glossary-terms.xml:7619(glossterm)#: ./doc/glossary/glossary-terms.xml:7626(para)#: ./doc/glossary/glossary-terms.xml:7635(secondary)#: ./doc/glossary/glossary-terms.xml:7632(glossterm)#: ./doc/glossary/glossary-terms.xml:7639(para)#: ./doc/glossary/glossary-terms.xml:7647(secondary)#: ./doc/glossary/glossary-terms.xml:7644(glossterm)#: ./doc/glossary/glossary-terms.xml:7651(para)#: ./doc/glossary/glossary-terms.xml:7660(secondary)#: ./doc/glossary/glossary-terms.xml:7657(glossterm)#: ./doc/glossary/glossary-terms.xml:7664(para)#: ./doc/glossary/glossary-terms.xml:7673(secondary)#: ./doc/glossary/glossary-terms.xml:7670(glossterm)#: ./doc/glossary/glossary-terms.xml:7677(para)#: ./doc/glossary/glossary-terms.xml:7686(secondary)#: ./doc/glossary/glossary-terms.xml:7683(glossterm)#: ./doc/glossary/glossary-terms.xml:7690(para)#: ./doc/glossary/glossary-terms.xml:7697(primary)#: ./doc/glossary/glossary-terms.xml:7696(glossterm)#: ./doc/glossary/glossary-terms.xml:7701(para)#: ./doc/glossary/glossary-terms.xml:7710(primary)#: ./doc/glossary/glossary-terms.xml:7709(glossterm)#: ./doc/glossary/glossary-terms.xml:7722(title)#: ./doc/glossary/glossary-terms.xml:7726(primary)#: ./doc/glossary/glossary-terms.xml:7725(glossterm)#: ./doc/glossary/glossary-terms.xml:7730(para)#: ./doc/glossary/glossary-terms.xml:7738(primary)#: ./doc/glossary/glossary-terms.xml:7737(glossterm)#: ./doc/glossary/glossary-terms.xml:7742(para)#: ./doc/glossary/glossary-terms.xml:7749(primary)#: ./doc/glossary/glossary-terms.xml:7748(glossterm)#: ./doc/glossary/glossary-terms.xml:7753(para)#: ./doc/glossary/glossary-terms.xml:7760(primary)#: ./doc/glossary/glossary-terms.xml:7759(glossterm)#: ./doc/glossary/glossary-terms.xml:7764(para)#: ./doc/glossary/glossary-terms.xml:7775(title)#: ./doc/glossary/glossary-terms.xml:7778(glossterm) ./doc/glossary/glossary-terms.xml:7788(primary) ./doc/glossary/glossary-terms.xml:7800(primary) ./doc/glossary/glossary-terms.xml:7813(primary)#: ./doc/glossary/glossary-terms.xml:7781(para)#: ./doc/glossary/glossary-terms.xml:7790(secondary)#: ./doc/glossary/glossary-terms.xml:7787(glossterm)#: ./doc/glossary/glossary-terms.xml:7802(secondary)#: ./doc/glossary/glossary-terms.xml:7799(glossterm)#: ./doc/glossary/glossary-terms.xml:7806(para)#: ./doc/glossary/glossary-terms.xml:7815(secondary)#: ./doc/glossary/glossary-terms.xml:7812(glossterm)#: ./doc/glossary/glossary-terms.xml:7827(title)#: ./doc/glossary/glossary-terms.xml:7841(title)#: ./doc/glossary/glossary-terms.xml:7845(primary)#: ./doc/glossary/glossary-terms.xml:7844(glossterm)#: ./doc/glossary/glossary-terms.xml:7849(para)#: ./doc/glossary/glossary-terms.xml:7856(primary)#: ./doc/glossary/glossary-terms.xml:7855(glossterm)#: ./doc/glossary/glossary-terms.xml:7860(para)","""POT-Creation-Date: 2014-07-08 06:08+0000\n""#: ./doc/glossary/glossary-terms.xml:10(title)#: ./doc/glossary/glossary-terms.xml:13(para)#: ./doc/glossary/glossary-terms.xml:20(link)#: ./doc/glossary/glossary-terms.xml:22(para)#: ./doc/glossary/glossary-terms.xml:34(title)#: ./doc/glossary/glossary-terms.xml:38(primary)#: ./doc/glossary/glossary-terms.xml:37(glossterm)#: ./doc/glossary/glossary-terms.xml:42(para)#: ./doc/glossary/glossary-terms.xml:49(primary)#: ./doc/glossary/glossary-terms.xml:48(glossterm)#: ./doc/glossary/glossary-terms.xml:53(para)#: ./doc/glossary/glossary-terms.xml:64(primary)#: ./doc/glossary/glossary-terms.xml:63(glossterm)#: ./doc/glossary/glossary-terms.xml:68(para)#: ./doc/glossary/glossary-terms.xml:75(primary)#: ./doc/glossary/glossary-terms.xml:74(glossterm)#: ./doc/glossary/glossary-terms.xml:79(para)#: ./doc/glossary/glossary-terms.xml:87(primary)#: ./doc/glossary/glossary-terms.xml:86(glossterm)#: ./doc/glossary/glossary-terms.xml:91(para)#: ./doc/glossary/glossary-terms.xml:99(primary)#: ./doc/glossary/glossary-terms.xml:98(glossterm)#: ./doc/glossary/glossary-terms.xml:103(para)#: ./doc/glossary/glossary-terms.xml:110(primary)#: ./doc/glossary/glossary-terms.xml:109(glossterm)#: ./doc/glossary/glossary-terms.xml:114(para)#: ./doc/glossary/glossary-terms.xml:121(primary)#: ./doc/glossary/glossary-terms.xml:120(glossterm)#: ./doc/glossary/glossary-terms.xml:125(para)#: ./doc/glossary/glossary-terms.xml:132(primary)#: ./doc/glossary/glossary-terms.xml:131(glossterm)#: ./doc/glossary/glossary-terms.xml:136(para)#: ./doc/glossary/glossary-terms.xml:144(primary)#: ./doc/glossary/glossary-terms.xml:143(glossterm)#: ./doc/glossary/glossary-terms.xml:148(para)#: ./doc/glossary/glossary-terms.xml:155(primary)#: ./doc/glossary/glossary-terms.xml:157(see)#: ./doc/glossary/glossary-terms.xml:154(glossterm)#: ./doc/glossary/glossary-terms.xml:161(para)#: ./doc/glossary/glossary-terms.xml:167(primary)#: ./doc/glossary/glossary-terms.xml:166(glossterm)#: ./doc/glossary/glossary-terms.xml:171(para)#: ./doc/glossary/glossary-terms.xml:179(primary)#: ./doc/glossary/glossary-terms.xml:178(glossterm)#: ./doc/glossary/glossary-terms.xml:183(para)#: ./doc/glossary/glossary-terms.xml:190(primary)#: ./doc/glossary/glossary-terms.xml:189(glossterm)#: ./doc/glossary/glossary-terms.xml:194(para)#: ./doc/glossary/glossary-terms.xml:202(primary)#: ./doc/glossary/glossary-terms.xml:201(glossterm)#: ./doc/glossary/glossary-terms.xml:206(para)#: ./doc/glossary/glossary-terms.xml:214(primary) ./doc/glossary/glossary-terms.xml:4265(see)#: ./doc/glossary/glossary-terms.xml:213(glossterm)#: ./doc/glossary/glossary-terms.xml:218(para)#: ./doc/glossary/glossary-terms.xml:227(primary)#: ./doc/glossary/glossary-terms.xml:226(glossterm)#: ./doc/glossary/glossary-terms.xml:231(para)#: ./doc/glossary/glossary-terms.xml:239(primary)#: ./doc/glossary/glossary-terms.xml:237(glossterm)#: ./doc/glossary/glossary-terms.xml:243(para)#: ./doc/glossary/glossary-terms.xml:251(primary)#: ./doc/glossary/glossary-terms.xml:250(glossterm)#: ./doc/glossary/glossary-terms.xml:255(para)#: ./doc/glossary/glossary-terms.xml:262(primary)#: ./doc/glossary/glossary-terms.xml:264(secondary) ./doc/glossary/glossary-terms.xml:754(secondary) ./doc/glossary/glossary-terms.xml:799(secondary) ./doc/glossary/glossary-terms.xml:849(secondary) ./doc/glossary/glossary-terms.xml:1092(secondary) ./doc/glossary/glossary-terms.xml:1174(secondary) ./doc/glossary/glossary-terms.xml:1368(secondary) ./doc/glossary/glossary-terms.xml:1460(secondary) ./doc/glossary/glossary-terms.xml:1534(secondary) ./doc/glossary/glossary-terms.xml:1586(secondary) ./doc/glossary/glossary-terms.xml:1677(secondary) ./doc/glossary/glossary-terms.xml:1875(secondary) ./doc/glossary/glossary-terms.xml:2106(secondary) ./doc/glossary/glossary-terms.xml:2747(secondary) ./doc/glossary/glossary-terms.xml:2855(secondary) ./doc/glossary/glossary-terms.xml:3419(secondary) ./doc/glossary/glossary-terms.xml:3468(secondary) ./doc/glossary/glossary-terms.xml:3566(secondary) ./doc/glossary/glossary-terms.xml:3768(secondary) ./doc/glossary/glossary-terms.xml:3899(secondary) ./doc/glossary/glossary-terms.xml:4299(secondary) ./doc/glossary/glossary-terms.xml:4582(secondary) ./doc/glossary/glossary-terms.xml:4818(secondary) ./doc/glossary/glossary-terms.xml:4912(secondary) ./doc/glossary/glossary-terms.xml:5213(secondary) ./doc/glossary/glossary-terms.xml:5372(secondary) ./doc/glossary/glossary-terms.xml:5455(secondary) ./doc/glossary/glossary-terms.xml:5979(secondary) ./doc/glossary/glossary-terms.xml:6075(secondary) ./doc/glossary/glossary-terms.xml:6116(secondary) ./doc/glossary/glossary-terms.xml:6361(secondary) ./doc/glossary/glossary-terms.xml:6401(secondary)#: ./doc/glossary/glossary-terms.xml:261(glossterm)#: ./doc/glossary/glossary-terms.xml:268(para)#: ./doc/glossary/glossary-terms.xml:277(primary)#: ./doc/glossary/glossary-terms.xml:276(glossterm)#: ./doc/glossary/glossary-terms.xml:281(para)#: ./doc/glossary/glossary-terms.xml:289(primary)#: ./doc/glossary/glossary-terms.xml:288(glossterm)#: ./doc/glossary/glossary-terms.xml:293(para) ./doc/glossary/glossary-terms.xml:304(para) ./doc/glossary/glossary-terms.xml:315(para)#: ./doc/glossary/glossary-terms.xml:300(primary)#: ./doc/glossary/glossary-terms.xml:299(glossterm)#: ./doc/glossary/glossary-terms.xml:311(primary)#: ./doc/glossary/glossary-terms.xml:310(glossterm)#: ./doc/glossary/glossary-terms.xml:322(primary)#: ./doc/glossary/glossary-terms.xml:321(glossterm)#: ./doc/glossary/glossary-terms.xml:326(para)#: ./doc/glossary/glossary-terms.xml:333(primary)#: ./doc/glossary/glossary-terms.xml:332(glossterm)#: ./doc/glossary/glossary-terms.xml:337(para)#: ./doc/glossary/glossary-terms.xml:345(primary)#: ./doc/glossary/glossary-terms.xml:344(glossterm)#: ./doc/glossary/glossary-terms.xml:349(para)#: ./doc/glossary/glossary-terms.xml:356(primary)#: ./doc/glossary/glossary-terms.xml:355(glossterm)#: ./doc/glossary/glossary-terms.xml:360(para)#: ./doc/glossary/glossary-terms.xml:366(glossterm)#: ./doc/glossary/glossary-terms.xml:369(para)#: ./doc/glossary/glossary-terms.xml:375(primary) ./doc/glossary/glossary-terms.xml:2522(primary) ./doc/glossary/glossary-terms.xml:2534(primary) ./doc/glossary/glossary-terms.xml:3108(primary) ./doc/glossary/glossary-terms.xml:7060(primary)#: ./doc/glossary/glossary-terms.xml:377(secondary) ./doc/glossary/glossary-terms.xml:381(secondary)#: ./doc/glossary/glossary-terms.xml:379(primary) ./doc/glossary/glossary-terms.xml:394(primary) ./doc/glossary/glossary-terms.xml:406(primary) ./doc/glossary/glossary-terms.xml:419(primary) ./doc/glossary/glossary-terms.xml:431(primary) ./doc/glossary/glossary-terms.xml:444(primary) ./doc/glossary/glossary-terms.xml:457(primary) ./doc/glossary/glossary-terms.xml:5558(primary)#: ./doc/glossary/glossary-terms.xml:374(glossterm)#: ./doc/glossary/glossary-terms.xml:385(para)#: ./doc/glossary/glossary-terms.xml:396(secondary)#: ./doc/glossary/glossary-terms.xml:393(glossterm)#: ./doc/glossary/glossary-terms.xml:400(para)#: ./doc/glossary/glossary-terms.xml:408(secondary)#: ./doc/glossary/glossary-terms.xml:405(glossterm)#: ./doc/glossary/glossary-terms.xml:412(para)#: ./doc/glossary/glossary-terms.xml:421(secondary)#: ./doc/glossary/glossary-terms.xml:418(glossterm)#: ./doc/glossary/glossary-terms.xml:425(para)#: ./doc/glossary/glossary-terms.xml:433(secondary)#: ./doc/glossary/glossary-terms.xml:430(glossterm)#: ./doc/glossary/glossary-terms.xml:437(para)#: ./doc/glossary/glossary-terms.xml:446(secondary)#: ./doc/glossary/glossary-terms.xml:443(glossterm)#: ./doc/glossary/glossary-terms.xml:450(para)#: ./doc/glossary/glossary-terms.xml:459(secondary)#: ./doc/glossary/glossary-terms.xml:456(glossterm)#: ./doc/glossary/glossary-terms.xml:463(para)#: ./doc/glossary/glossary-terms.xml:470(primary)#: ./doc/glossary/glossary-terms.xml:469(glossterm)#: ./doc/glossary/glossary-terms.xml:474(para)#: ./doc/glossary/glossary-terms.xml:479(glossterm)#: ./doc/glossary/glossary-terms.xml:482(para)#: ./doc/glossary/glossary-terms.xml:490(primary) ./doc/glossary/glossary-terms.xml:5542(primary) ./doc/glossary/glossary-terms.xml:5938(primary) ./doc/glossary/glossary-terms.xml:6359(primary) ./doc/glossary/glossary-terms.xml:6386(primary) ./doc/glossary/glossary-terms.xml:7459(primary)#: ./doc/glossary/glossary-terms.xml:492(secondary)#: ./doc/glossary/glossary-terms.xml:494(primary)#: ./doc/glossary/glossary-terms.xml:489(glossterm)#: ./doc/glossary/glossary-terms.xml:498(para)#: ./doc/glossary/glossary-terms.xml:505(primary)#: ./doc/glossary/glossary-terms.xml:504(glossterm)#: ./doc/glossary/glossary-terms.xml:509(para)#: ./doc/glossary/glossary-terms.xml:517(primary)#: ./doc/glossary/glossary-terms.xml:516(glossterm)#: ./doc/glossary/glossary-terms.xml:521(para)#: ./doc/glossary/glossary-terms.xml:530(primary)#: ./doc/glossary/glossary-terms.xml:529(glossterm)#: ./doc/glossary/glossary-terms.xml:534(para)#: ./doc/glossary/glossary-terms.xml:542(primary)#: ./doc/glossary/glossary-terms.xml:540(glossterm)#: ./doc/glossary/glossary-terms.xml:546(para)#: ./doc/glossary/glossary-terms.xml:554(primary)#: ./doc/glossary/glossary-terms.xml:553(glossterm)#: ./doc/glossary/glossary-terms.xml:558(para)#: ./doc/glossary/glossary-terms.xml:564(primary)#: ./doc/glossary/glossary-terms.xml:563(glossterm)#: ./doc/glossary/glossary-terms.xml:568(para)#: ./doc/glossary/glossary-terms.xml:576(primary)#: ./doc/glossary/glossary-terms.xml:575(glossterm)#: ./doc/glossary/glossary-terms.xml:580(para)#: ./doc/glossary/glossary-terms.xml:587(primary)#: ./doc/glossary/glossary-terms.xml:586(glossterm)#: ./doc/glossary/glossary-terms.xml:591(para)#: ./doc/glossary/glossary-terms.xml:598(primary)#: ./doc/glossary/glossary-terms.xml:597(glossterm)#: ./doc/glossary/glossary-terms.xml:602(para)#: ./doc/glossary/glossary-terms.xml:611(primary)#: ./doc/glossary/glossary-terms.xml:610(glossterm)#: ./doc/glossary/glossary-terms.xml:615(para)#: ./doc/glossary/glossary-terms.xml:623(primary)#: ./doc/glossary/glossary-terms.xml:622(glossterm)#: ./doc/glossary/glossary-terms.xml:627(para)#: ./doc/glossary/glossary-terms.xml:634(primary)#: ./doc/glossary/glossary-terms.xml:633(glossterm)#: ./doc/glossary/glossary-terms.xml:638(para)#: ./doc/glossary/glossary-terms.xml:646(primary)#: ./doc/glossary/glossary-terms.xml:645(glossterm)#: ./doc/glossary/glossary-terms.xml:650(para)#: ./doc/glossary/glossary-terms.xml:658(primary)#: ./doc/glossary/glossary-terms.xml:657(glossterm)#: ./doc/glossary/glossary-terms.xml:662(para)#: ./doc/glossary/glossary-terms.xml:669(primary)#: ./doc/glossary/glossary-terms.xml:668(glossterm)#: ./doc/glossary/glossary-terms.xml:673(para)#: ./doc/glossary/glossary-terms.xml:680(primary)#: ./doc/glossary/glossary-terms.xml:679(glossterm)#: ./doc/glossary/glossary-terms.xml:684(para)#: ./doc/glossary/glossary-terms.xml:691(primary)#: ./doc/glossary/glossary-terms.xml:690(glossterm)#: ./doc/glossary/glossary-terms.xml:695(para)#: ./doc/glossary/glossary-terms.xml:702(primary)#: ./doc/glossary/glossary-terms.xml:701(glossterm)#: ./doc/glossary/glossary-terms.xml:706(para)#: ./doc/glossary/glossary-terms.xml:713(primary)#: ./doc/glossary/glossary-terms.xml:712(glossterm)#: ./doc/glossary/glossary-terms.xml:717(para)#: ./doc/glossary/glossary-terms.xml:724(primary)#: ./doc/glossary/glossary-terms.xml:723(glossterm)#: ./doc/glossary/glossary-terms.xml:728(para)#: ./doc/glossary/glossary-terms.xml:736(primary)#: ./doc/glossary/glossary-terms.xml:735(glossterm)#: ./doc/glossary/glossary-terms.xml:740(para)#: ./doc/glossary/glossary-terms.xml:748(title)#: ./doc/glossary/glossary-terms.xml:752(primary) ./doc/glossary/glossary-terms.xml:766(primary) ./doc/glossary/glossary-terms.xml:781(primary)#: ./doc/glossary/glossary-terms.xml:751(glossterm)#: ./doc/glossary/glossary-terms.xml:758(para)#: ./doc/glossary/glossary-terms.xml:768(secondary) ./doc/glossary/glossary-terms.xml:1138(primary)#: ./doc/glossary/glossary-terms.xml:765(glossterm)#: ./doc/glossary/glossary-terms.xml:772(para)#: ./doc/glossary/glossary-terms.xml:783(secondary)#: ./doc/glossary/glossary-terms.xml:780(glossterm)#: ./doc/glossary/glossary-terms.xml:787(para) msgid ""The persistent data store used to save and retrieve information for a service, such as lists of Object Storage objects, current state of guest VMs, lists of usernames, and so on. Also, the method that the Image Service uses to get and store VM images. Options include Object Storage, local file system, S3, and HTTP.""#: ./doc/glossary/glossary-terms.xml:797(primary)#: ./doc/glossary/glossary-terms.xml:796(glossterm)#: ./doc/glossary/glossary-terms.xml:803(para)#: ./doc/glossary/glossary-terms.xml:811(primary)#: ./doc/glossary/glossary-terms.xml:810(glossterm)#: ./doc/glossary/glossary-terms.xml:815(para)#: ./doc/glossary/glossary-terms.xml:822(primary)#: ./doc/glossary/glossary-terms.xml:821(glossterm)#: ./doc/glossary/glossary-terms.xml:826(para)#: ./doc/glossary/glossary-terms.xml:832(primary)#: ./doc/glossary/glossary-terms.xml:831(glossterm)#: ./doc/glossary/glossary-terms.xml:836(para)#: ./doc/glossary/glossary-terms.xml:839(para)#: ./doc/glossary/glossary-terms.xml:847(primary)#: ./doc/glossary/glossary-terms.xml:846(glossterm)#: ./doc/glossary/glossary-terms.xml:853(para)#: ./doc/glossary/glossary-terms.xml:860(primary)#: ./doc/glossary/glossary-terms.xml:859(glossterm)#: ./doc/glossary/glossary-terms.xml:864(para)#: ./doc/glossary/glossary-terms.xml:871(primary)#: ./doc/glossary/glossary-terms.xml:870(glossterm)#: ./doc/glossary/glossary-terms.xml:875(para)#: ./doc/glossary/glossary-terms.xml:882(primary)#: ./doc/glossary/glossary-terms.xml:881(glossterm)#: ./doc/glossary/glossary-terms.xml:886(para)#: ./doc/glossary/glossary-terms.xml:894(primary)#: ./doc/glossary/glossary-terms.xml:893(glossterm)#: ./doc/glossary/glossary-terms.xml:898(para)#: ./doc/glossary/glossary-terms.xml:907(primary)#: ./doc/glossary/glossary-terms.xml:906(glossterm)#: ./doc/glossary/glossary-terms.xml:911(para)#: ./doc/glossary/glossary-terms.xml:919(primary)#: ./doc/glossary/glossary-terms.xml:918(glossterm)#: ./doc/glossary/glossary-terms.xml:923(para)#: ./doc/glossary/glossary-terms.xml:931(primary)#: ./doc/glossary/glossary-terms.xml:930(glossterm)#: ./doc/glossary/glossary-terms.xml:935(para)#: ./doc/glossary/glossary-terms.xml:945(primary)#: ./doc/glossary/glossary-terms.xml:944(glossterm)#: ./doc/glossary/glossary-terms.xml:949(para)#: ./doc/glossary/glossary-terms.xml:956(primary)#: ./doc/glossary/glossary-terms.xml:955(glossterm)#: ./doc/glossary/glossary-terms.xml:960(para)#: ./doc/glossary/glossary-terms.xml:969(primary)#: ./doc/glossary/glossary-terms.xml:968(glossterm)#: ./doc/glossary/glossary-terms.xml:973(para)#: ./doc/glossary/glossary-terms.xml:980(primary)#: ./doc/glossary/glossary-terms.xml:979(glossterm)#: ./doc/glossary/glossary-terms.xml:984(para)#: ./doc/glossary/glossary-terms.xml:992(primary)#: ./doc/glossary/glossary-terms.xml:991(glossterm)#: ./doc/glossary/glossary-terms.xml:996(para)#: ./doc/glossary/glossary-terms.xml:1005(primary)#: ./doc/glossary/glossary-terms.xml:1004(glossterm)#: ./doc/glossary/glossary-terms.xml:1009(para)#: ./doc/glossary/glossary-terms.xml:1018(title)#: ./doc/glossary/glossary-terms.xml:1022(primary)#: ./doc/glossary/glossary-terms.xml:1021(glossterm)#: ./doc/glossary/glossary-terms.xml:1026(para)#: ./doc/glossary/glossary-terms.xml:1041(primary)#: ./doc/glossary/glossary-terms.xml:1040(glossterm)#: ./doc/glossary/glossary-terms.xml:1045(para)#: ./doc/glossary/glossary-terms.xml:1052(primary)#: ./doc/glossary/glossary-terms.xml:1051(glossterm)#: ./doc/glossary/glossary-terms.xml:1056(para)#: ./doc/glossary/glossary-terms.xml:1059(para)#: ./doc/glossary/glossary-terms.xml:1067(glossterm)#: ./doc/glossary/glossary-terms.xml:1069(para)#: ./doc/glossary/glossary-terms.xml:1079(primary)#: ./doc/glossary/glossary-terms.xml:1078(glossterm)#: ./doc/glossary/glossary-terms.xml:1083(para)#: ./doc/glossary/glossary-terms.xml:1090(primary)#: ./doc/glossary/glossary-terms.xml:1089(glossterm)#: ./doc/glossary/glossary-terms.xml:1096(para)#: ./doc/glossary/glossary-terms.xml:1104(primary)#: ./doc/glossary/glossary-terms.xml:1103(glossterm)#: ./doc/glossary/glossary-terms.xml:1108(para)#: ./doc/glossary/glossary-terms.xml:1116(primary)#: ./doc/glossary/glossary-terms.xml:1115(glossterm)#: ./doc/glossary/glossary-terms.xml:1120(para)#: ./doc/glossary/glossary-terms.xml:1127(primary)#: ./doc/glossary/glossary-terms.xml:1126(glossterm)#: ./doc/glossary/glossary-terms.xml:1131(para)#: ./doc/glossary/glossary-terms.xml:1137(glossterm)#: ./doc/glossary/glossary-terms.xml:1142(para)#: ./doc/glossary/glossary-terms.xml:1149(primary)#: ./doc/glossary/glossary-terms.xml:1148(glossterm)#: ./doc/glossary/glossary-terms.xml:1153(para)#: ./doc/glossary/glossary-terms.xml:1160(primary)#: ./doc/glossary/glossary-terms.xml:1159(glossterm)#: ./doc/glossary/glossary-terms.xml:1164(para)#: ./doc/glossary/glossary-terms.xml:1172(primary) ./doc/glossary/glossary-terms.xml:1187(primary) ./doc/glossary/glossary-terms.xml:1201(primary) ./doc/glossary/glossary-terms.xml:1304(primary) ./doc/glossary/glossary-terms.xml:5195(primary)#: ./doc/glossary/glossary-terms.xml:1171(glossterm)#: ./doc/glossary/glossary-terms.xml:1178(para)#: ./doc/glossary/glossary-terms.xml:1189(secondary)#: ./doc/glossary/glossary-terms.xml:1186(glossterm)#: ./doc/glossary/glossary-terms.xml:1193(para)#: ./doc/glossary/glossary-terms.xml:1203(secondary)#: ./doc/glossary/glossary-terms.xml:1200(glossterm)#: ./doc/glossary/glossary-terms.xml:1207(para)#: ./doc/glossary/glossary-terms.xml:1215(primary)#: ./doc/glossary/glossary-terms.xml:1214(glossterm)#: ./doc/glossary/glossary-terms.xml:1219(para) ./doc/glossary/glossary-terms.xml:1986(para) ./doc/glossary/glossary-terms.xml:5149(para) ./doc/glossary/glossary-terms.xml:5898(para) ./doc/glossary/glossary-terms.xml:6845(para)#: ./doc/glossary/glossary-terms.xml:1225(primary)#: ./doc/glossary/glossary-terms.xml:1224(glossterm)#: ./doc/glossary/glossary-terms.xml:1229(para)#: ./doc/glossary/glossary-terms.xml:1237(primary)#: ./doc/glossary/glossary-terms.xml:1236(glossterm)#: ./doc/glossary/glossary-terms.xml:1241(para)#: ./doc/glossary/glossary-terms.xml:1247(primary)#: ./doc/glossary/glossary-terms.xml:1246(glossterm)#: ./doc/glossary/glossary-terms.xml:1251(para)#: ./doc/glossary/glossary-terms.xml:1259(primary)#: ./doc/glossary/glossary-terms.xml:1257(glossterm)#: ./doc/glossary/glossary-terms.xml:1264(para)#: ./doc/glossary/glossary-terms.xml:1270(primary)#: ./doc/glossary/glossary-terms.xml:1269(glossterm)#: ./doc/glossary/glossary-terms.xml:1274(para)#: ./doc/glossary/glossary-terms.xml:1281(primary)#: ./doc/glossary/glossary-terms.xml:1280(glossterm)#: ./doc/glossary/glossary-terms.xml:1285(para)#: ./doc/glossary/glossary-terms.xml:1293(primary)#: ./doc/glossary/glossary-terms.xml:1292(glossterm)#: ./doc/glossary/glossary-terms.xml:1297(para)#: ./doc/glossary/glossary-terms.xml:1306(secondary) ./doc/glossary/glossary-terms.xml:1308(primary)#: ./doc/glossary/glossary-terms.xml:1303(glossterm)#: ./doc/glossary/glossary-terms.xml:1312(para)#: ./doc/glossary/glossary-terms.xml:1322(primary)#: ./doc/glossary/glossary-terms.xml:1321(glossterm)#: ./doc/glossary/glossary-terms.xml:1326(para)#: ./doc/glossary/glossary-terms.xml:1333(primary)#: ./doc/glossary/glossary-terms.xml:1332(glossterm)#: ./doc/glossary/glossary-terms.xml:1337(para)#: ./doc/glossary/glossary-terms.xml:1344(primary)#: ./doc/glossary/glossary-terms.xml:1343(glossterm)#: ./doc/glossary/glossary-terms.xml:1348(para)#: ./doc/glossary/glossary-terms.xml:1355(primary)#: ./doc/glossary/glossary-terms.xml:1354(glossterm)#: ./doc/glossary/glossary-terms.xml:1359(para)#: ./doc/glossary/glossary-terms.xml:1366(primary) ./doc/glossary/glossary-terms.xml:1381(primary) ./doc/glossary/glossary-terms.xml:1396(primary)#: ./doc/glossary/glossary-terms.xml:1365(glossterm)#: ./doc/glossary/glossary-terms.xml:1372(para)#: ./doc/glossary/glossary-terms.xml:1383(secondary)#: ./doc/glossary/glossary-terms.xml:1380(glossterm)#: ./doc/glossary/glossary-terms.xml:1387(para)#: ./doc/glossary/glossary-terms.xml:1398(secondary)#: ./doc/glossary/glossary-terms.xml:1395(glossterm)#: ./doc/glossary/glossary-terms.xml:1402(para)#: ./doc/glossary/glossary-terms.xml:1411(primary)#: ./doc/glossary/glossary-terms.xml:1409(glossterm)#: ./doc/glossary/glossary-terms.xml:1415(para)#: ./doc/glossary/glossary-terms.xml:1423(primary)#: ./doc/glossary/glossary-terms.xml:1421(glossterm)#: ./doc/glossary/glossary-terms.xml:1427(para)#: ./doc/glossary/glossary-terms.xml:1434(primary)#: ./doc/glossary/glossary-terms.xml:1433(glossterm)#: ./doc/glossary/glossary-terms.xml:1438(para)#: ./doc/glossary/glossary-terms.xml:1447(primary)#: ./doc/glossary/glossary-terms.xml:1446(glossterm)#: ./doc/glossary/glossary-terms.xml:1451(para)#: ./doc/glossary/glossary-terms.xml:1458(primary) ./doc/glossary/glossary-terms.xml:1471(primary)#: ./doc/glossary/glossary-terms.xml:1457(glossterm)#: ./doc/glossary/glossary-terms.xml:1464(para)#: ./doc/glossary/glossary-terms.xml:1473(secondary)#: ./doc/glossary/glossary-terms.xml:1470(glossterm)#: ./doc/glossary/glossary-terms.xml:1477(para)#: ./doc/glossary/glossary-terms.xml:1484(primary)#: ./doc/glossary/glossary-terms.xml:1483(glossterm)#: ./doc/glossary/glossary-terms.xml:1488(para)#: ./doc/glossary/glossary-terms.xml:1494(primary)#: ./doc/glossary/glossary-terms.xml:1493(glossterm)#: ./doc/glossary/glossary-terms.xml:1498(para)#: ./doc/glossary/glossary-terms.xml:1505(primary)#: ./doc/glossary/glossary-terms.xml:1504(glossterm)#: ./doc/glossary/glossary-terms.xml:1509(para)#: ./doc/glossary/glossary-terms.xml:1518(primary)#: ./doc/glossary/glossary-terms.xml:1517(glossterm)#: ./doc/glossary/glossary-terms.xml:1522(para)#: ./doc/glossary/glossary-terms.xml:1532(primary) ./doc/glossary/glossary-terms.xml:1545(primary) ./doc/glossary/glossary-terms.xml:1559(primary) ./doc/glossary/glossary-terms.xml:1572(primary) ./doc/glossary/glossary-terms.xml:1599(primary) ./doc/glossary/glossary-terms.xml:1611(primary)#: ./doc/glossary/glossary-terms.xml:1531(glossterm)#: ./doc/glossary/glossary-terms.xml:1538(para)#: ./doc/glossary/glossary-terms.xml:1547(secondary) ./doc/glossary/glossary-terms.xml:4880(secondary)#: ./doc/glossary/glossary-terms.xml:1544(glossterm)#: ./doc/glossary/glossary-terms.xml:1551(para)#: ./doc/glossary/glossary-terms.xml:1561(secondary)#: ./doc/glossary/glossary-terms.xml:1558(glossterm)#: ./doc/glossary/glossary-terms.xml:1565(para)#: ./doc/glossary/glossary-terms.xml:1574(secondary)#: ./doc/glossary/glossary-terms.xml:1571(glossterm)#: ./doc/glossary/glossary-terms.xml:1578(para)#: ./doc/glossary/glossary-terms.xml:1584(primary)#: ./doc/glossary/glossary-terms.xml:1583(glossterm)#: ./doc/glossary/glossary-terms.xml:1590(para)#: ./doc/glossary/glossary-terms.xml:1601(secondary)#: ./doc/glossary/glossary-terms.xml:1598(glossterm)#: ./doc/glossary/glossary-terms.xml:1605(para)#: ./doc/glossary/glossary-terms.xml:1613(secondary)#: ./doc/glossary/glossary-terms.xml:1610(glossterm)#: ./doc/glossary/glossary-terms.xml:1617(para)#: ./doc/glossary/glossary-terms.xml:1626(primary) ./doc/glossary/glossary-terms.xml:4310(primary) ./doc/glossary/glossary-terms.xml:4910(primary) ./doc/glossary/glossary-terms.xml:4923(primary) ./doc/glossary/glossary-terms.xml:4936(primary) ./doc/glossary/glossary-terms.xml:4950(primary) ./doc/glossary/glossary-terms.xml:4962(primary) ./doc/glossary/glossary-terms.xml:4975(primary) ./doc/glossary/glossary-terms.xml:4988(primary) ./doc/glossary/glossary-terms.xml:5039(primary) ./doc/glossary/glossary-terms.xml:6343(primary)#: ./doc/glossary/glossary-terms.xml:1628(secondary) ./doc/glossary/glossary-terms.xml:1630(primary)#: ./doc/glossary/glossary-terms.xml:1625(glossterm)#: ./doc/glossary/glossary-terms.xml:1634(para)#: ./doc/glossary/glossary-terms.xml:1641(primary)#: ./doc/glossary/glossary-terms.xml:1640(glossterm)#: ./doc/glossary/glossary-terms.xml:1645(para)#: ./doc/glossary/glossary-terms.xml:1654(primary)#: ./doc/glossary/glossary-terms.xml:1653(glossterm)#: ./doc/glossary/glossary-terms.xml:1658(para)#: ./doc/glossary/glossary-terms.xml:1665(primary)#: ./doc/glossary/glossary-terms.xml:1664(glossterm)#: ./doc/glossary/glossary-terms.xml:1669(para)#: ./doc/glossary/glossary-terms.xml:1675(primary) ./doc/glossary/glossary-terms.xml:1689(primary) ./doc/glossary/glossary-terms.xml:1703(primary) ./doc/glossary/glossary-terms.xml:1717(primary) ./doc/glossary/glossary-terms.xml:1731(primary) ./doc/glossary/glossary-terms.xml:1743(primary)#: ./doc/glossary/glossary-terms.xml:1674(glossterm)#: ./doc/glossary/glossary-terms.xml:1681(para)#: ./doc/glossary/glossary-terms.xml:1691(secondary)#: ./doc/glossary/glossary-terms.xml:1688(glossterm)#: ./doc/glossary/glossary-terms.xml:1695(para)#: ./doc/glossary/glossary-terms.xml:1705(secondary)#: ./doc/glossary/glossary-terms.xml:1702(glossterm)#: ./doc/glossary/glossary-terms.xml:1709(para)#: ./doc/glossary/glossary-terms.xml:1719(secondary)#: ./doc/glossary/glossary-terms.xml:1716(glossterm)#: ./doc/glossary/glossary-terms.xml:1723(para)#: ./doc/glossary/glossary-terms.xml:1733(secondary)#: ./doc/glossary/glossary-terms.xml:1730(glossterm)#: ./doc/glossary/glossary-terms.xml:1737(para)#: ./doc/glossary/glossary-terms.xml:1745(secondary)#: ./doc/glossary/glossary-terms.xml:1742(glossterm)#: ./doc/glossary/glossary-terms.xml:1749(para)#: ./doc/glossary/glossary-terms.xml:1756(primary)#: ./doc/glossary/glossary-terms.xml:1758(see)#: ./doc/glossary/glossary-terms.xml:1755(glossterm)#: ./doc/glossary/glossary-terms.xml:1762(para)#: ./doc/glossary/glossary-terms.xml:1768(primary)#: ./doc/glossary/glossary-terms.xml:1767(glossterm)#: ./doc/glossary/glossary-terms.xml:1772(para)#: ./doc/glossary/glossary-terms.xml:1780(primary)#: ./doc/glossary/glossary-terms.xml:1779(glossterm)#: ./doc/glossary/glossary-terms.xml:1784(para)#: ./doc/glossary/glossary-terms.xml:1796(primary)#: ./doc/glossary/glossary-terms.xml:1795(glossterm)#: ./doc/glossary/glossary-terms.xml:1800(para)#: ./doc/glossary/glossary-terms.xml:1808(primary)#: ./doc/glossary/glossary-terms.xml:1807(glossterm)#: ./doc/glossary/glossary-terms.xml:1812(para)#: ./doc/glossary/glossary-terms.xml:1821(primary)#: ./doc/glossary/glossary-terms.xml:1820(glossterm)#: ./doc/glossary/glossary-terms.xml:1825(para)#: ./doc/glossary/glossary-terms.xml:1832(primary)#: ./doc/glossary/glossary-terms.xml:1831(glossterm)#: ./doc/glossary/glossary-terms.xml:1836(para)#: ./doc/glossary/glossary-terms.xml:1844(primary)#: ./doc/glossary/glossary-terms.xml:1846(see)#: ./doc/glossary/glossary-terms.xml:1843(glossterm)#: ./doc/glossary/glossary-terms.xml:1850(para)#: ./doc/glossary/glossary-terms.xml:1856(primary)#: ./doc/glossary/glossary-terms.xml:1855(glossterm)#: ./doc/glossary/glossary-terms.xml:1860(para)#: ./doc/glossary/glossary-terms.xml:1869(title)#: ./doc/glossary/glossary-terms.xml:1873(primary)#: ./doc/glossary/glossary-terms.xml:1872(glossterm)#: ./doc/glossary/glossary-terms.xml:1879(para)#: ./doc/glossary/glossary-terms.xml:1887(primary)#: ./doc/glossary/glossary-terms.xml:1886(glossterm)#: ./doc/glossary/glossary-terms.xml:1891(para)#: ./doc/glossary/glossary-terms.xml:1901(primary)#: ./doc/glossary/glossary-terms.xml:1900(glossterm)#: ./doc/glossary/glossary-terms.xml:1905(para)#: ./doc/glossary/glossary-terms.xml:1912(primary)#: ./doc/glossary/glossary-terms.xml:1914(secondary)#: ./doc/glossary/glossary-terms.xml:1911(glossterm)#: ./doc/glossary/glossary-terms.xml:1918(para)#: ./doc/glossary/glossary-terms.xml:1929(primary) ./doc/glossary/glossary-terms.xml:1942(primary)#: ./doc/glossary/glossary-terms.xml:1931(secondary)#: ./doc/glossary/glossary-terms.xml:1928(glossterm)#: ./doc/glossary/glossary-terms.xml:1935(para)#: ./doc/glossary/glossary-terms.xml:1944(secondary)#: ./doc/glossary/glossary-terms.xml:1941(glossterm)#: ./doc/glossary/glossary-terms.xml:1948(para)#: ./doc/glossary/glossary-terms.xml:1955(primary)#: ./doc/glossary/glossary-terms.xml:1954(glossterm)#: ./doc/glossary/glossary-terms.xml:1959(para)#: ./doc/glossary/glossary-terms.xml:1970(primary)#: ./doc/glossary/glossary-terms.xml:1969(glossterm)#: ./doc/glossary/glossary-terms.xml:1974(para)#: ./doc/glossary/glossary-terms.xml:1982(primary)#: ./doc/glossary/glossary-terms.xml:1981(glossterm)#: ./doc/glossary/glossary-terms.xml:1992(primary)#: ./doc/glossary/glossary-terms.xml:1991(glossterm)#: ./doc/glossary/glossary-terms.xml:1996(para)#: ./doc/glossary/glossary-terms.xml:2004(primary)#: ./doc/glossary/glossary-terms.xml:2003(glossterm)#: ./doc/glossary/glossary-terms.xml:2008(para)#: ./doc/glossary/glossary-terms.xml:2015(primary)#: ./doc/glossary/glossary-terms.xml:2014(glossterm)#: ./doc/glossary/glossary-terms.xml:2019(para)#: ./doc/glossary/glossary-terms.xml:2026(primary)#: ./doc/glossary/glossary-terms.xml:2025(glossterm)#: ./doc/glossary/glossary-terms.xml:2030(para)#: ./doc/glossary/glossary-terms.xml:2037(primary)#: ./doc/glossary/glossary-terms.xml:2036(glossterm)#: ./doc/glossary/glossary-terms.xml:2041(para)#: ./doc/glossary/glossary-terms.xml:2048(primary)#: ./doc/glossary/glossary-terms.xml:2047(glossterm)#: ./doc/glossary/glossary-terms.xml:2052(para)#: ./doc/glossary/glossary-terms.xml:2059(primary)#: ./doc/glossary/glossary-terms.xml:2058(glossterm)#: ./doc/glossary/glossary-terms.xml:2063(para)#: ./doc/glossary/glossary-terms.xml:2071(primary)#: ./doc/glossary/glossary-terms.xml:2070(glossterm)#: ./doc/glossary/glossary-terms.xml:2075(para)#: ./doc/glossary/glossary-terms.xml:2082(primary)#: ./doc/glossary/glossary-terms.xml:2081(glossterm)#: ./doc/glossary/glossary-terms.xml:2086(para)#: ./doc/glossary/glossary-terms.xml:2093(primary)#: ./doc/glossary/glossary-terms.xml:2092(glossterm)#: ./doc/glossary/glossary-terms.xml:2097(para)#: ./doc/glossary/glossary-terms.xml:2104(primary)#: ./doc/glossary/glossary-terms.xml:2103(glossterm)#: ./doc/glossary/glossary-terms.xml:2110(para)#: ./doc/glossary/glossary-terms.xml:2117(primary)#: ./doc/glossary/glossary-terms.xml:2119(secondary) ./doc/glossary/glossary-terms.xml:3345(secondary) ./doc/glossary/glossary-terms.xml:3451(secondary) ./doc/glossary/glossary-terms.xml:3527(secondary) ./doc/glossary/glossary-terms.xml:5110(secondary) ./doc/glossary/glossary-terms.xml:5865(secondary)#: ./doc/glossary/glossary-terms.xml:2116(glossterm)#: ./doc/glossary/glossary-terms.xml:2123(para)#: ./doc/glossary/glossary-terms.xml:2134(primary)#: ./doc/glossary/glossary-terms.xml:2133(glossterm)#: ./doc/glossary/glossary-terms.xml:2138(para)#: ./doc/glossary/glossary-terms.xml:2145(primary)#: ./doc/glossary/glossary-terms.xml:2144(glossterm)#: ./doc/glossary/glossary-terms.xml:2149(para)#: ./doc/glossary/glossary-terms.xml:2153(para)#: ./doc/glossary/glossary-terms.xml:2162(primary)#: ./doc/glossary/glossary-terms.xml:2161(glossterm)#: ./doc/glossary/glossary-terms.xml:2166(para)#: ./doc/glossary/glossary-terms.xml:2174(primary)#: ./doc/glossary/glossary-terms.xml:2173(glossterm)#: ./doc/glossary/glossary-terms.xml:2178(para)#: ./doc/glossary/glossary-terms.xml:2186(primary)#: ./doc/glossary/glossary-terms.xml:2185(glossterm)#: ./doc/glossary/glossary-terms.xml:2190(para)#: ./doc/glossary/glossary-terms.xml:2197(primary)#: ./doc/glossary/glossary-terms.xml:2196(glossterm)#: ./doc/glossary/glossary-terms.xml:2201(para)#: ./doc/glossary/glossary-terms.xml:2209(primary)#: ./doc/glossary/glossary-terms.xml:2208(glossterm)#: ./doc/glossary/glossary-terms.xml:2213(para)#: ./doc/glossary/glossary-terms.xml:2220(primary)#: ./doc/glossary/glossary-terms.xml:2219(glossterm)#: ./doc/glossary/glossary-terms.xml:2224(para)#: ./doc/glossary/glossary-terms.xml:2232(primary)#: ./doc/glossary/glossary-terms.xml:2231(glossterm)#: ./doc/glossary/glossary-terms.xml:2236(para)#: ./doc/glossary/glossary-terms.xml:2243(primary)#: ./doc/glossary/glossary-terms.xml:2242(glossterm)#: ./doc/glossary/glossary-terms.xml:2247(para)#: ./doc/glossary/glossary-terms.xml:2254(primary) ./doc/glossary/glossary-terms.xml:2269(primary)#: ./doc/glossary/glossary-terms.xml:2256(secondary)#: ./doc/glossary/glossary-terms.xml:2253(glossterm)#: ./doc/glossary/glossary-terms.xml:2260(para)#: ./doc/glossary/glossary-terms.xml:2271(secondary)#: ./doc/glossary/glossary-terms.xml:2268(glossterm)#: ./doc/glossary/glossary-terms.xml:2275(para)#: ./doc/glossary/glossary-terms.xml:2282(primary)#: ./doc/glossary/glossary-terms.xml:2281(glossterm)#: ./doc/glossary/glossary-terms.xml:2286(para)#: ./doc/glossary/glossary-terms.xml:2293(primary)#: ./doc/glossary/glossary-terms.xml:2292(glossterm)#: ./doc/glossary/glossary-terms.xml:2297(para)#: ./doc/glossary/glossary-terms.xml:2301(para)#: ./doc/glossary/glossary-terms.xml:2307(glossterm)#: ./doc/glossary/glossary-terms.xml:2310(para)#: ./doc/glossary/glossary-terms.xml:2317(glossterm)#: ./doc/glossary/glossary-terms.xml:2320(para)#: ./doc/glossary/glossary-terms.xml:2323(para)#: ./doc/glossary/glossary-terms.xml:2327(para)#: ./doc/glossary/glossary-terms.xml:2338(primary)#: ./doc/glossary/glossary-terms.xml:2337(glossterm)#: ./doc/glossary/glossary-terms.xml:2342(para)#: ./doc/glossary/glossary-terms.xml:2349(primary)#: ./doc/glossary/glossary-terms.xml:2348(glossterm)#: ./doc/glossary/glossary-terms.xml:2353(para)#: ./doc/glossary/glossary-terms.xml:2359(primary)#: ./doc/glossary/glossary-terms.xml:2358(glossterm)#: ./doc/glossary/glossary-terms.xml:2363(para)#: ./doc/glossary/glossary-terms.xml:2370(primary)#: ./doc/glossary/glossary-terms.xml:2369(glossterm)#: ./doc/glossary/glossary-terms.xml:2374(para)#: ./doc/glossary/glossary-terms.xml:2380(glossterm)#: ./doc/glossary/glossary-terms.xml:2383(para)#: ./doc/glossary/glossary-terms.xml:2391(primary)#: ./doc/glossary/glossary-terms.xml:2389(glossterm)#: ./doc/glossary/glossary-terms.xml:2395(para)#: ./doc/glossary/glossary-terms.xml:2405(title)#: ./doc/glossary/glossary-terms.xml:2409(primary)#: ./doc/glossary/glossary-terms.xml:2408(glossterm)#: ./doc/glossary/glossary-terms.xml:2413(para)#: ./doc/glossary/glossary-terms.xml:2420(primary) ./doc/glossary/glossary-terms.xml:2620(primary)#: ./doc/glossary/glossary-terms.xml:2419(glossterm) ./doc/glossary/glossary-terms.xml:2619(glossterm)#: ./doc/glossary/glossary-terms.xml:2424(para)#: ./doc/glossary/glossary-terms.xml:2431(glossterm) ./doc/glossary/glossary-terms.xml:2441(primary) ./doc/glossary/glossary-terms.xml:2454(primary) ./doc/glossary/glossary-terms.xml:2467(primary) ./doc/glossary/glossary-terms.xml:2480(primary)#: ./doc/glossary/glossary-terms.xml:2434(para)#: ./doc/glossary/glossary-terms.xml:2443(secondary)#: ./doc/glossary/glossary-terms.xml:2440(glossterm)#: ./doc/glossary/glossary-terms.xml:2447(para)#: ./doc/glossary/glossary-terms.xml:2456(secondary)#: ./doc/glossary/glossary-terms.xml:2453(glossterm)#: ./doc/glossary/glossary-terms.xml:2460(para)#: ./doc/glossary/glossary-terms.xml:2469(secondary)#: ./doc/glossary/glossary-terms.xml:2466(glossterm)#: ./doc/glossary/glossary-terms.xml:2473(para)#: ./doc/glossary/glossary-terms.xml:2482(secondary)#: ./doc/glossary/glossary-terms.xml:2479(glossterm)#: ./doc/glossary/glossary-terms.xml:2486(para)#: ./doc/glossary/glossary-terms.xml:2493(primary)#: ./doc/glossary/glossary-terms.xml:2492(glossterm)#: ./doc/glossary/glossary-terms.xml:2497(para)#: ./doc/glossary/glossary-terms.xml:2503(primary)#: ./doc/glossary/glossary-terms.xml:2502(glossterm)#: ./doc/glossary/glossary-terms.xml:2507(para)#: ./doc/glossary/glossary-terms.xml:2513(glossterm)#: ./doc/glossary/glossary-terms.xml:2516(para)#: ./doc/glossary/glossary-terms.xml:2524(secondary)#: ./doc/glossary/glossary-terms.xml:2521(glossterm)#: ./doc/glossary/glossary-terms.xml:2528(para)#: ./doc/glossary/glossary-terms.xml:2536(secondary)#: ./doc/glossary/glossary-terms.xml:2533(glossterm)#: ./doc/glossary/glossary-terms.xml:2540(para)#: ./doc/glossary/glossary-terms.xml:2548(primary)#: ./doc/glossary/glossary-terms.xml:2547(glossterm)#: ./doc/glossary/glossary-terms.xml:2552(para)#: ./doc/glossary/glossary-terms.xml:2561(primary)#: ./doc/glossary/glossary-terms.xml:2560(glossterm)#: ./doc/glossary/glossary-terms.xml:2565(para)#: ./doc/glossary/glossary-terms.xml:2573(primary) ./doc/glossary/glossary-terms.xml:4860(see)#: ./doc/glossary/glossary-terms.xml:2572(glossterm)#: ./doc/glossary/glossary-terms.xml:2577(para)#: ./doc/glossary/glossary-terms.xml:2584(primary)#: ./doc/glossary/glossary-terms.xml:2583(glossterm)#: ./doc/glossary/glossary-terms.xml:2588(para)#: ./doc/glossary/glossary-terms.xml:2592(para)#: ./doc/glossary/glossary-terms.xml:2600(primary)#: ./doc/glossary/glossary-terms.xml:2599(glossterm)#: ./doc/glossary/glossary-terms.xml:2604(para) ./doc/glossary/glossary-terms.xml:2614(para) ./doc/glossary/glossary-terms.xml:4081(para) ./doc/glossary/glossary-terms.xml:4193(para) ./doc/glossary/glossary-terms.xml:7285(para) ./doc/glossary/glossary-terms.xml:7498(para) ./doc/glossary/glossary-terms.xml:7711(para) ./doc/glossary/glossary-terms.xml:7791(para) ./doc/glossary/glossary-terms.xml:7816(para)#: ./doc/glossary/glossary-terms.xml:2610(primary)#: ./doc/glossary/glossary-terms.xml:2609(glossterm)#: ./doc/glossary/glossary-terms.xml:2624(para)#: ./doc/glossary/glossary-terms.xml:2633(primary)#: ./doc/glossary/glossary-terms.xml:2632(glossterm)#: ./doc/glossary/glossary-terms.xml:2637(para)#: ./doc/glossary/glossary-terms.xml:2644(primary)#: ./doc/glossary/glossary-terms.xml:2643(glossterm)#: ./doc/glossary/glossary-terms.xml:2648(para)#: ./doc/glossary/glossary-terms.xml:2655(primary)#: ./doc/glossary/glossary-terms.xml:2654(glossterm)#: ./doc/glossary/glossary-terms.xml:2659(para)#: ./doc/glossary/glossary-terms.xml:2665(primary)#: ./doc/glossary/glossary-terms.xml:2664(glossterm)#: ./doc/glossary/glossary-terms.xml:2669(para)#: ./doc/glossary/glossary-terms.xml:2675(primary)#: ./doc/glossary/glossary-terms.xml:2674(glossterm)#: ./doc/glossary/glossary-terms.xml:2679(para)#: ./doc/glossary/glossary-terms.xml:2685(primary)#: ./doc/glossary/glossary-terms.xml:2684(glossterm)#: ./doc/glossary/glossary-terms.xml:2689(para)#: ./doc/glossary/glossary-terms.xml:2697(primary)#: ./doc/glossary/glossary-terms.xml:2696(glossterm)#: ./doc/glossary/glossary-terms.xml:2701(para)#: ./doc/glossary/glossary-terms.xml:2707(primary)#: ./doc/glossary/glossary-terms.xml:2706(glossterm)#: ./doc/glossary/glossary-terms.xml:2711(para)#: ./doc/glossary/glossary-terms.xml:2717(primary) ./doc/glossary/glossary-terms.xml:7193(primary)#: ./doc/glossary/glossary-terms.xml:2719(secondary) ./doc/glossary/glossary-terms.xml:2721(primary)#: ./doc/glossary/glossary-terms.xml:2716(glossterm)#: ./doc/glossary/glossary-terms.xml:2725(para)#: ./doc/glossary/glossary-terms.xml:2732(primary)#: ./doc/glossary/glossary-terms.xml:2731(glossterm)#: ./doc/glossary/glossary-terms.xml:2736(para)#: ./doc/glossary/glossary-terms.xml:2745(primary)#: ./doc/glossary/glossary-terms.xml:2744(glossterm)#: ./doc/glossary/glossary-terms.xml:2751(para)#: ./doc/glossary/glossary-terms.xml:2759(primary)#: ./doc/glossary/glossary-terms.xml:2758(glossterm)#: ./doc/glossary/glossary-terms.xml:2763(para)#: ./doc/glossary/glossary-terms.xml:2770(primary)#: ./doc/glossary/glossary-terms.xml:2769(glossterm)#: ./doc/glossary/glossary-terms.xml:2774(para)#: ./doc/glossary/glossary-terms.xml:2784(title)#: ./doc/glossary/glossary-terms.xml:2788(primary)#: ./doc/glossary/glossary-terms.xml:2787(glossterm)#: ./doc/glossary/glossary-terms.xml:2792(para)#: ./doc/glossary/glossary-terms.xml:2799(primary)#: ./doc/glossary/glossary-terms.xml:2798(glossterm)#: ./doc/glossary/glossary-terms.xml:2803(para)#: ./doc/glossary/glossary-terms.xml:2811(primary)#: ./doc/glossary/glossary-terms.xml:2810(glossterm)#: ./doc/glossary/glossary-terms.xml:2815(para)#: ./doc/glossary/glossary-terms.xml:2821(primary)#: ./doc/glossary/glossary-terms.xml:2820(glossterm)#: ./doc/glossary/glossary-terms.xml:2825(para)#: ./doc/glossary/glossary-terms.xml:2832(primary)#: ./doc/glossary/glossary-terms.xml:2831(glossterm)#: ./doc/glossary/glossary-terms.xml:2836(para)#: ./doc/glossary/glossary-terms.xml:2842(primary)#: ./doc/glossary/glossary-terms.xml:2841(glossterm)#: ./doc/glossary/glossary-terms.xml:2846(para)#: ./doc/glossary/glossary-terms.xml:2853(primary) ./doc/glossary/glossary-terms.xml:3727(primary)#: ./doc/glossary/glossary-terms.xml:2852(glossterm)#: ./doc/glossary/glossary-terms.xml:2859(para)#: ./doc/glossary/glossary-terms.xml:2866(primary)#: ./doc/glossary/glossary-terms.xml:2865(glossterm)#: ./doc/glossary/glossary-terms.xml:2870(para)#: ./doc/glossary/glossary-terms.xml:2878(primary)#: ./doc/glossary/glossary-terms.xml:2877(glossterm)#: ./doc/glossary/glossary-terms.xml:2882(para)#: ./doc/glossary/glossary-terms.xml:2889(primary) ./doc/glossary/glossary-terms.xml:2977(primary) ./doc/glossary/glossary-terms.xml:3897(primary) ./doc/glossary/glossary-terms.xml:5417(primary) ./doc/glossary/glossary-terms.xml:5588(primary) ./doc/glossary/glossary-terms.xml:6507(primary) ./doc/glossary/glossary-terms.xml:6715(primary)#: ./doc/glossary/glossary-terms.xml:2891(secondary)#: ./doc/glossary/glossary-terms.xml:2893(primary)#: ./doc/glossary/glossary-terms.xml:2888(glossterm)#: ./doc/glossary/glossary-terms.xml:2897(para)#: ./doc/glossary/glossary-terms.xml:2906(primary)#: ./doc/glossary/glossary-terms.xml:2905(glossterm)#: ./doc/glossary/glossary-terms.xml:2910(para)#: ./doc/glossary/glossary-terms.xml:2918(primary)#: ./doc/glossary/glossary-terms.xml:2917(glossterm)#: ./doc/glossary/glossary-terms.xml:2922(para)#: ./doc/glossary/glossary-terms.xml:2930(primary)#: ./doc/glossary/glossary-terms.xml:2929(glossterm)#: ./doc/glossary/glossary-terms.xml:2934(para)#: ./doc/glossary/glossary-terms.xml:2945(primary)#: ./doc/glossary/glossary-terms.xml:2944(glossterm)#: ./doc/glossary/glossary-terms.xml:2949(para)#: ./doc/glossary/glossary-terms.xml:2956(primary)#: ./doc/glossary/glossary-terms.xml:2955(glossterm)#: ./doc/glossary/glossary-terms.xml:2960(para)#: ./doc/glossary/glossary-terms.xml:2966(primary)#: ./doc/glossary/glossary-terms.xml:2965(glossterm)#: ./doc/glossary/glossary-terms.xml:2970(para)#: ./doc/glossary/glossary-terms.xml:2979(secondary)#: ./doc/glossary/glossary-terms.xml:2981(primary)#: ./doc/glossary/glossary-terms.xml:2976(glossterm)#: ./doc/glossary/glossary-terms.xml:2985(para)#: ./doc/glossary/glossary-terms.xml:2995(primary)#: ./doc/glossary/glossary-terms.xml:2994(glossterm)#: ./doc/glossary/glossary-terms.xml:2999(para)#: ./doc/glossary/glossary-terms.xml:3004(para)#: ./doc/glossary/glossary-terms.xml:3013(primary)#: ./doc/glossary/glossary-terms.xml:3012(glossterm)#: ./doc/glossary/glossary-terms.xml:3017(para)#: ./doc/glossary/glossary-terms.xml:3024(primary)#: ./doc/glossary/glossary-terms.xml:3023(glossterm)#: ./doc/glossary/glossary-terms.xml:3028(para)#: ./doc/glossary/glossary-terms.xml:3037(title)#: ./doc/glossary/glossary-terms.xml:3041(primary)#: ./doc/glossary/glossary-terms.xml:3040(glossterm)#: ./doc/glossary/glossary-terms.xml:3045(para)#: ./doc/glossary/glossary-terms.xml:3052(primary)#: ./doc/glossary/glossary-terms.xml:3051(glossterm)#: ./doc/glossary/glossary-terms.xml:3055(para)#: ./doc/glossary/glossary-terms.xml:3063(primary)#: ./doc/glossary/glossary-terms.xml:3062(glossterm)#: ./doc/glossary/glossary-terms.xml:3066(para)#: ./doc/glossary/glossary-terms.xml:3073(glossterm) ./doc/glossary/glossary-terms.xml:3082(primary) ./doc/glossary/glossary-terms.xml:3096(primary)#: ./doc/glossary/glossary-terms.xml:3076(para)#: ./doc/glossary/glossary-terms.xml:3084(secondary)#: ./doc/glossary/glossary-terms.xml:3081(glossterm)#: ./doc/glossary/glossary-terms.xml:3088(para)#: ./doc/glossary/glossary-terms.xml:3098(secondary)#: ./doc/glossary/glossary-terms.xml:3095(glossterm)#: ./doc/glossary/glossary-terms.xml:3102(para)#: ./doc/glossary/glossary-terms.xml:3110(secondary) ./doc/glossary/glossary-terms.xml:3112(primary)#: ./doc/glossary/glossary-terms.xml:3107(glossterm)#: ./doc/glossary/glossary-terms.xml:3116(para)#: ./doc/glossary/glossary-terms.xml:3123(primary)#: ./doc/glossary/glossary-terms.xml:3122(glossterm)#: ./doc/glossary/glossary-terms.xml:3127(para)#: ./doc/glossary/glossary-terms.xml:3134(primary)#: ./doc/glossary/glossary-terms.xml:3133(glossterm)#: ./doc/glossary/glossary-terms.xml:3138(para)#: ./doc/glossary/glossary-terms.xml:3146(primary)#: ./doc/glossary/glossary-terms.xml:3145(glossterm)#: ./doc/glossary/glossary-terms.xml:3150(para)#: ./doc/glossary/glossary-terms.xml:3157(primary)#: ./doc/glossary/glossary-terms.xml:3156(glossterm)#: ./doc/glossary/glossary-terms.xml:3161(para)#: ./doc/glossary/glossary-terms.xml:3168(primary)#: ./doc/glossary/glossary-terms.xml:3167(glossterm)#: ./doc/glossary/glossary-terms.xml:3172(para)#: ./doc/glossary/glossary-terms.xml:3180(primary)#: ./doc/glossary/glossary-terms.xml:3179(glossterm)#: ./doc/glossary/glossary-terms.xml:3184(para)#: ./doc/glossary/glossary-terms.xml:3193(primary)#: ./doc/glossary/glossary-terms.xml:3192(glossterm)#: ./doc/glossary/glossary-terms.xml:3197(para)#: ./doc/glossary/glossary-terms.xml:3206(title)#: ./doc/glossary/glossary-terms.xml:3210(primary)#: ./doc/glossary/glossary-terms.xml:3209(glossterm)#: ./doc/glossary/glossary-terms.xml:3214(para)#: ./doc/glossary/glossary-terms.xml:3221(primary)#: ./doc/glossary/glossary-terms.xml:3220(glossterm)#: ./doc/glossary/glossary-terms.xml:3225(para)#: ./doc/glossary/glossary-terms.xml:3232(primary)#: ./doc/glossary/glossary-terms.xml:3231(glossterm)#: ./doc/glossary/glossary-terms.xml:3236(para)#: ./doc/glossary/glossary-terms.xml:3244(primary)#: ./doc/glossary/glossary-terms.xml:3243(glossterm)#: ./doc/glossary/glossary-terms.xml:3248(para)#: ./doc/glossary/glossary-terms.xml:3256(primary)#: ./doc/glossary/glossary-terms.xml:3255(glossterm)#: ./doc/glossary/glossary-terms.xml:3260(para)#: ./doc/glossary/glossary-terms.xml:3267(primary)#: ./doc/glossary/glossary-terms.xml:3266(glossterm)#: ./doc/glossary/glossary-terms.xml:3271(para)#: ./doc/glossary/glossary-terms.xml:3277(primary)#: ./doc/glossary/glossary-terms.xml:3276(glossterm)#: ./doc/glossary/glossary-terms.xml:3281(para)#: ./doc/glossary/glossary-terms.xml:3291(glossterm)#: ./doc/glossary/glossary-terms.xml:3294(para)#: ./doc/glossary/glossary-terms.xml:3301(primary)#: ./doc/glossary/glossary-terms.xml:3300(glossterm)#: ./doc/glossary/glossary-terms.xml:3305(para)#: ./doc/glossary/glossary-terms.xml:3311(primary)#: ./doc/glossary/glossary-terms.xml:3310(glossterm)#: ./doc/glossary/glossary-terms.xml:3315(para)#: ./doc/glossary/glossary-terms.xml:3321(primary)#: ./doc/glossary/glossary-terms.xml:3320(glossterm)#: ./doc/glossary/glossary-terms.xml:3325(para)#: ./doc/glossary/glossary-terms.xml:3332(primary)#: ./doc/glossary/glossary-terms.xml:3331(glossterm)#: ./doc/glossary/glossary-terms.xml:3336(para)#: ./doc/glossary/glossary-terms.xml:3343(primary)#: ./doc/glossary/glossary-terms.xml:3342(glossterm)#: ./doc/glossary/glossary-terms.xml:3349(para)#: ./doc/glossary/glossary-terms.xml:3360(primary)#: ./doc/glossary/glossary-terms.xml:3359(glossterm)#: ./doc/glossary/glossary-terms.xml:3364(para)#: ./doc/glossary/glossary-terms.xml:3376(primary)#: ./doc/glossary/glossary-terms.xml:3375(glossterm)#: ./doc/glossary/glossary-terms.xml:3380(para)#: ./doc/glossary/glossary-terms.xml:3386(primary)#: ./doc/glossary/glossary-terms.xml:3385(glossterm)#: ./doc/glossary/glossary-terms.xml:3390(para)#: ./doc/glossary/glossary-terms.xml:3397(glossterm)#: ./doc/glossary/glossary-terms.xml:3400(para)#: ./doc/glossary/glossary-terms.xml:3406(glossterm)#: ./doc/glossary/glossary-terms.xml:3409(para)#: ./doc/glossary/glossary-terms.xml:3417(primary) ./doc/glossary/glossary-terms.xml:3430(primary)#: ./doc/glossary/glossary-terms.xml:3416(glossterm)#: ./doc/glossary/glossary-terms.xml:3423(para)#: ./doc/glossary/glossary-terms.xml:3432(secondary)#: ./doc/glossary/glossary-terms.xml:3429(glossterm)#: ./doc/glossary/glossary-terms.xml:3436(para)#: ./doc/glossary/glossary-terms.xml:3445(title)#: ./doc/glossary/glossary-terms.xml:3449(primary)#: ./doc/glossary/glossary-terms.xml:3448(glossterm)#: ./doc/glossary/glossary-terms.xml:3455(para)#: ./doc/glossary/glossary-terms.xml:3466(primary)#: ./doc/glossary/glossary-terms.xml:3465(glossterm)#: ./doc/glossary/glossary-terms.xml:3472(para)#: ./doc/glossary/glossary-terms.xml:3480(primary)#: ./doc/glossary/glossary-terms.xml:3479(glossterm)#: ./doc/glossary/glossary-terms.xml:3484(para)#: ./doc/glossary/glossary-terms.xml:3493(primary)#: ./doc/glossary/glossary-terms.xml:3492(glossterm)#: ./doc/glossary/glossary-terms.xml:3497(para)#: ./doc/glossary/glossary-terms.xml:3503(glossterm)#: ./doc/glossary/glossary-terms.xml:3506(para)#: ./doc/glossary/glossary-terms.xml:3512(primary) ./doc/glossary/glossary-terms.xml:3525(primary) ./doc/glossary/glossary-terms.xml:3541(primary) ./doc/glossary/glossary-terms.xml:3607(primary)#: ./doc/glossary/glossary-terms.xml:3514(secondary)#: ./doc/glossary/glossary-terms.xml:3511(glossterm)#: ./doc/glossary/glossary-terms.xml:3518(para)#: ./doc/glossary/glossary-terms.xml:3524(glossterm)#: ./doc/glossary/glossary-terms.xml:3531(para)#: ./doc/glossary/glossary-terms.xml:3543(secondary)#: ./doc/glossary/glossary-terms.xml:3540(glossterm)#: ./doc/glossary/glossary-terms.xml:3547(para)#: ./doc/glossary/glossary-terms.xml:3554(primary)#: ./doc/glossary/glossary-terms.xml:3553(glossterm)#: ./doc/glossary/glossary-terms.xml:3558(para)#: ./doc/glossary/glossary-terms.xml:3564(primary)#: ./doc/glossary/glossary-terms.xml:3563(glossterm)#: ./doc/glossary/glossary-terms.xml:3570(para)#: ./doc/glossary/glossary-terms.xml:3580(primary) ./doc/glossary/glossary-terms.xml:3593(primary) ./doc/glossary/glossary-terms.xml:3620(primary) ./doc/glossary/glossary-terms.xml:3633(primary) ./doc/glossary/glossary-terms.xml:3646(primary) ./doc/glossary/glossary-terms.xml:3658(glossterm) ./doc/glossary/glossary-terms.xml:3677(primary) ./doc/glossary/glossary-terms.xml:3690(primary) ./doc/glossary/glossary-terms.xml:3703(primary) ./doc/glossary/glossary-terms.xml:5573(primary)#: ./doc/glossary/glossary-terms.xml:3582(secondary) ./doc/glossary/glossary-terms.xml:3668(glossterm)#: ./doc/glossary/glossary-terms.xml:3579(glossterm)#: ./doc/glossary/glossary-terms.xml:3586(para)#: ./doc/glossary/glossary-terms.xml:3595(secondary)#: ./doc/glossary/glossary-terms.xml:3592(glossterm)#: ./doc/glossary/glossary-terms.xml:3599(para)#: ./doc/glossary/glossary-terms.xml:3609(secondary)#: ./doc/glossary/glossary-terms.xml:3606(glossterm)#: ./doc/glossary/glossary-terms.xml:3613(para)#: ./doc/glossary/glossary-terms.xml:3622(secondary)#: ./doc/glossary/glossary-terms.xml:3619(glossterm)#: ./doc/glossary/glossary-terms.xml:3626(para) ./doc/glossary/glossary-terms.xml:4364(para)#: ./doc/glossary/glossary-terms.xml:3635(secondary)#: ./doc/glossary/glossary-terms.xml:3632(glossterm)#: ./doc/glossary/glossary-terms.xml:3639(para)#: ./doc/glossary/glossary-terms.xml:3648(secondary)#: ./doc/glossary/glossary-terms.xml:3645(glossterm)#: ./doc/glossary/glossary-terms.xml:3652(para)#: ./doc/glossary/glossary-terms.xml:3661(para)#: ./doc/glossary/glossary-terms.xml:3671(para)#: ./doc/glossary/glossary-terms.xml:3679(secondary)#: ./doc/glossary/glossary-terms.xml:3676(glossterm)#: ./doc/glossary/glossary-terms.xml:3683(para)#: ./doc/glossary/glossary-terms.xml:3692(secondary)#: ./doc/glossary/glossary-terms.xml:3689(glossterm)#: ./doc/glossary/glossary-terms.xml:3696(para)#: ./doc/glossary/glossary-terms.xml:3705(secondary)#: ./doc/glossary/glossary-terms.xml:3702(glossterm)#: ./doc/glossary/glossary-terms.xml:3709(para)#: ./doc/glossary/glossary-terms.xml:3716(primary)#: ./doc/glossary/glossary-terms.xml:3715(glossterm)#: ./doc/glossary/glossary-terms.xml:3720(para)#: ./doc/glossary/glossary-terms.xml:3729(secondary) ./doc/glossary/glossary-terms.xml:3731(primary)#: ./doc/glossary/glossary-terms.xml:3726(glossterm)#: ./doc/glossary/glossary-terms.xml:3735(para)#: ./doc/glossary/glossary-terms.xml:3742(primary)#: ./doc/glossary/glossary-terms.xml:3741(glossterm)#: ./doc/glossary/glossary-terms.xml:3745(para)#: ./doc/glossary/glossary-terms.xml:3755(primary)#: ./doc/glossary/glossary-terms.xml:3754(glossterm)#: ./doc/glossary/glossary-terms.xml:3759(para)#: ./doc/glossary/glossary-terms.xml:3766(primary) ./doc/glossary/glossary-terms.xml:3779(primary) ./doc/glossary/glossary-terms.xml:3791(primary) ./doc/glossary/glossary-terms.xml:3814(primary) ./doc/glossary/glossary-terms.xml:3828(primary) ./doc/glossary/glossary-terms.xml:3840(primary)#: ./doc/glossary/glossary-terms.xml:3765(glossterm)#: ./doc/glossary/glossary-terms.xml:3772(para)#: ./doc/glossary/glossary-terms.xml:3781(secondary)#: ./doc/glossary/glossary-terms.xml:3778(glossterm)#: ./doc/glossary/glossary-terms.xml:3785(para)#: ./doc/glossary/glossary-terms.xml:3793(secondary)#: ./doc/glossary/glossary-terms.xml:3790(glossterm)#: ./doc/glossary/glossary-terms.xml:3797(para)#: ./doc/glossary/glossary-terms.xml:3803(primary)#: ./doc/glossary/glossary-terms.xml:3802(glossterm)#: ./doc/glossary/glossary-terms.xml:3807(para)#: ./doc/glossary/glossary-terms.xml:3816(secondary)#: ./doc/glossary/glossary-terms.xml:3813(glossterm)#: ./doc/glossary/glossary-terms.xml:3820(para)#: ./doc/glossary/glossary-terms.xml:3830(secondary)#: ./doc/glossary/glossary-terms.xml:3827(glossterm)#: ./doc/glossary/glossary-terms.xml:3834(para)#: ./doc/glossary/glossary-terms.xml:3842(secondary)#: ./doc/glossary/glossary-terms.xml:3839(glossterm)#: ./doc/glossary/glossary-terms.xml:3846(para) ./doc/glossary/glossary-terms.xml:6392(para)#: ./doc/glossary/glossary-terms.xml:3853(primary)#: ./doc/glossary/glossary-terms.xml:3852(glossterm)#: ./doc/glossary/glossary-terms.xml:3857(para)#: ./doc/glossary/glossary-terms.xml:3864(primary)#: ./doc/glossary/glossary-terms.xml:3863(glossterm)#: ./doc/glossary/glossary-terms.xml:3868(para)#: ./doc/glossary/glossary-terms.xml:3875(primary)#: ./doc/glossary/glossary-terms.xml:3874(glossterm)#: ./doc/glossary/glossary-terms.xml:3879(para)#: ./doc/glossary/glossary-terms.xml:3886(primary)#: ./doc/glossary/glossary-terms.xml:3885(glossterm)#: ./doc/glossary/glossary-terms.xml:3890(para)#: ./doc/glossary/glossary-terms.xml:3896(glossterm)#: ./doc/glossary/glossary-terms.xml:3903(para)#: ./doc/glossary/glossary-terms.xml:3911(primary)#: ./doc/glossary/glossary-terms.xml:3910(glossterm)#: ./doc/glossary/glossary-terms.xml:3915(para)#: ./doc/glossary/glossary-terms.xml:3923(primary)#: ./doc/glossary/glossary-terms.xml:3922(glossterm)#: ./doc/glossary/glossary-terms.xml:3927(para)#: ./doc/glossary/glossary-terms.xml:3933(primary)#: ./doc/glossary/glossary-terms.xml:3932(glossterm)#: ./doc/glossary/glossary-terms.xml:3937(para)#: ./doc/glossary/glossary-terms.xml:3949(primary)#: ./doc/glossary/glossary-terms.xml:3948(glossterm)#: ./doc/glossary/glossary-terms.xml:3953(para)#: ./doc/glossary/glossary-terms.xml:3962(primary)#: ./doc/glossary/glossary-terms.xml:3961(glossterm)#: ./doc/glossary/glossary-terms.xml:3966(para)#: ./doc/glossary/glossary-terms.xml:3978(primary)#: ./doc/glossary/glossary-terms.xml:3977(glossterm)#: ./doc/glossary/glossary-terms.xml:3982(para)#: ./doc/glossary/glossary-terms.xml:3989(primary)#: ./doc/glossary/glossary-terms.xml:3988(glossterm)#: ./doc/glossary/glossary-terms.xml:3993(para) ./doc/glossary/glossary-terms.xml:5662(para) ./doc/glossary/glossary-terms.xml:7338(para) ./doc/glossary/glossary-terms.xml:7349(para) ./doc/glossary/glossary-terms.xml:7538(para)#: ./doc/glossary/glossary-terms.xml:4000(primary)#: ./doc/glossary/glossary-terms.xml:3999(glossterm)#: ./doc/glossary/glossary-terms.xml:4004(para)#: ./doc/glossary/glossary-terms.xml:4013(title)#: ./doc/glossary/glossary-terms.xml:4017(primary)#: ./doc/glossary/glossary-terms.xml:4016(glossterm)#: ./doc/glossary/glossary-terms.xml:4021(para)#: ./doc/glossary/glossary-terms.xml:4028(primary)#: ./doc/glossary/glossary-terms.xml:4027(glossterm)#: ./doc/glossary/glossary-terms.xml:4032(para)#: ./doc/glossary/glossary-terms.xml:4038(primary)#: ./doc/glossary/glossary-terms.xml:4037(glossterm)#: ./doc/glossary/glossary-terms.xml:4042(para)#: ./doc/glossary/glossary-terms.xml:4048(primary)#: ./doc/glossary/glossary-terms.xml:4047(glossterm)#: ./doc/glossary/glossary-terms.xml:4052(para)#: ./doc/glossary/glossary-terms.xml:4059(primary)#: ./doc/glossary/glossary-terms.xml:4058(glossterm)#: ./doc/glossary/glossary-terms.xml:4063(para)#: ./doc/glossary/glossary-terms.xml:4073(title)#: ./doc/glossary/glossary-terms.xml:4077(primary)#: ./doc/glossary/glossary-terms.xml:4076(glossterm)#: ./doc/glossary/glossary-terms.xml:4087(primary)#: ./doc/glossary/glossary-terms.xml:4086(glossterm)#: ./doc/glossary/glossary-terms.xml:4091(para)#: ./doc/glossary/glossary-terms.xml:4097(primary)#: ./doc/glossary/glossary-terms.xml:4096(glossterm)#: ./doc/glossary/glossary-terms.xml:4101(para)#: ./doc/glossary/glossary-terms.xml:4110(title)#: ./doc/glossary/glossary-terms.xml:4114(primary)#: ./doc/glossary/glossary-terms.xml:4113(glossterm)#: ./doc/glossary/glossary-terms.xml:4118(para)#: ./doc/glossary/glossary-terms.xml:4124(primary)#: ./doc/glossary/glossary-terms.xml:4123(glossterm)#: ./doc/glossary/glossary-terms.xml:4128(para)#: ./doc/glossary/glossary-terms.xml:4134(primary)#: ./doc/glossary/glossary-terms.xml:4133(glossterm)#: ./doc/glossary/glossary-terms.xml:4138(para)#: ./doc/glossary/glossary-terms.xml:4145(primary)#: ./doc/glossary/glossary-terms.xml:4144(glossterm)#: ./doc/glossary/glossary-terms.xml:4149(para)#: ./doc/glossary/glossary-terms.xml:4156(primary)#: ./doc/glossary/glossary-terms.xml:4155(glossterm)#: ./doc/glossary/glossary-terms.xml:4160(para)#: ./doc/glossary/glossary-terms.xml:4166(glossterm)#: ./doc/glossary/glossary-terms.xml:4169(para)#: ./doc/glossary/glossary-terms.xml:4176(primary)#: ./doc/glossary/glossary-terms.xml:4178(secondary) ./doc/glossary/glossary-terms.xml:5087(secondary)#: ./doc/glossary/glossary-terms.xml:4175(glossterm)#: ./doc/glossary/glossary-terms.xml:4182(para)#: ./doc/glossary/glossary-terms.xml:4189(primary)#: ./doc/glossary/glossary-terms.xml:4188(glossterm)#: ./doc/glossary/glossary-terms.xml:4199(primary)#: ./doc/glossary/glossary-terms.xml:4198(glossterm)#: ./doc/glossary/glossary-terms.xml:4203(para)#: ./doc/glossary/glossary-terms.xml:4210(glossterm)#: ./doc/glossary/glossary-terms.xml:4213(para)#: ./doc/glossary/glossary-terms.xml:4222(primary)#: ./doc/glossary/glossary-terms.xml:4221(glossterm)#: ./doc/glossary/glossary-terms.xml:4226(para)#: ./doc/glossary/glossary-terms.xml:4234(primary)#: ./doc/glossary/glossary-terms.xml:4232(glossterm)#: ./doc/glossary/glossary-terms.xml:4238(para)#: ./doc/glossary/glossary-terms.xml:4245(primary)#: ./doc/glossary/glossary-terms.xml:4244(glossterm)#: ./doc/glossary/glossary-terms.xml:4249(para)#: ./doc/glossary/glossary-terms.xml:4259(title)#: ./doc/glossary/glossary-terms.xml:4263(primary)#: ./doc/glossary/glossary-terms.xml:4262(glossterm)#: ./doc/glossary/glossary-terms.xml:4269(para)#: ./doc/glossary/glossary-terms.xml:4275(primary)#: ./doc/glossary/glossary-terms.xml:4274(glossterm)#: ./doc/glossary/glossary-terms.xml:4279(para)#: ./doc/glossary/glossary-terms.xml:4286(primary)#: ./doc/glossary/glossary-terms.xml:4285(glossterm)#: ./doc/glossary/glossary-terms.xml:4290(para)#: ./doc/glossary/glossary-terms.xml:4297(primary) ./doc/glossary/glossary-terms.xml:4314(primary)#: ./doc/glossary/glossary-terms.xml:4296(glossterm)#: ./doc/glossary/glossary-terms.xml:4303(para)#: ./doc/glossary/glossary-terms.xml:4312(secondary) ./doc/glossary/glossary-terms.xml:4316(secondary)#: ./doc/glossary/glossary-terms.xml:4309(glossterm)#: ./doc/glossary/glossary-terms.xml:4320(para)#: ./doc/glossary/glossary-terms.xml:4327(primary)#: ./doc/glossary/glossary-terms.xml:4326(glossterm)#: ./doc/glossary/glossary-terms.xml:4331(para)#: ./doc/glossary/glossary-terms.xml:4338(primary)#: ./doc/glossary/glossary-terms.xml:4337(glossterm)#: ./doc/glossary/glossary-terms.xml:4342(para)#: ./doc/glossary/glossary-terms.xml:4349(primary)#: ./doc/glossary/glossary-terms.xml:4348(glossterm)#: ./doc/glossary/glossary-terms.xml:4353(para)#: ./doc/glossary/glossary-terms.xml:4360(primary)#: ./doc/glossary/glossary-terms.xml:4359(glossterm)#: ./doc/glossary/glossary-terms.xml:4371(primary)#: ./doc/glossary/glossary-terms.xml:4370(glossterm)#: ./doc/glossary/glossary-terms.xml:4375(para)#: ./doc/glossary/glossary-terms.xml:4382(primary)#: ./doc/glossary/glossary-terms.xml:4381(glossterm)#: ./doc/glossary/glossary-terms.xml:4386(para)#: ./doc/glossary/glossary-terms.xml:4395(primary)#: ./doc/glossary/glossary-terms.xml:4394(glossterm)#: ./doc/glossary/glossary-terms.xml:4399(para)#: ./doc/glossary/glossary-terms.xml:4406(primary)#: ./doc/glossary/glossary-terms.xml:4405(glossterm)#: ./doc/glossary/glossary-terms.xml:4410(para)#: ./doc/glossary/glossary-terms.xml:4417(primary)#: ./doc/glossary/glossary-terms.xml:4416(glossterm)#: ./doc/glossary/glossary-terms.xml:4421(para)#: ./doc/glossary/glossary-terms.xml:4428(primary)#: ./doc/glossary/glossary-terms.xml:4427(glossterm)#: ./doc/glossary/glossary-terms.xml:4432(para)#: ./doc/glossary/glossary-terms.xml:4439(primary)#: ./doc/glossary/glossary-terms.xml:4438(glossterm)#: ./doc/glossary/glossary-terms.xml:4443(para)#: ./doc/glossary/glossary-terms.xml:4449(primary)#: ./doc/glossary/glossary-terms.xml:4448(glossterm)#: ./doc/glossary/glossary-terms.xml:4453(para)#: ./doc/glossary/glossary-terms.xml:4460(primary)#: ./doc/glossary/glossary-terms.xml:4459(glossterm)#: ./doc/glossary/glossary-terms.xml:4464(para)#: ./doc/glossary/glossary-terms.xml:4472(glossterm)#: ./doc/glossary/glossary-terms.xml:4475(para)#: ./doc/glossary/glossary-terms.xml:4483(primary)#: ./doc/glossary/glossary-terms.xml:4481(glossterm)#: ./doc/glossary/glossary-terms.xml:4487(para)#: ./doc/glossary/glossary-terms.xml:4494(primary)#: ./doc/glossary/glossary-terms.xml:4493(glossterm)#: ./doc/glossary/glossary-terms.xml:4498(para)#: ./doc/glossary/glossary-terms.xml:4505(primary)#: ./doc/glossary/glossary-terms.xml:4504(glossterm)#: ./doc/glossary/glossary-terms.xml:4509(para)#: ./doc/glossary/glossary-terms.xml:4516(primary)#: ./doc/glossary/glossary-terms.xml:4515(glossterm)#: ./doc/glossary/glossary-terms.xml:4520(para)#: ./doc/glossary/glossary-terms.xml:4528(primary)#: ./doc/glossary/glossary-terms.xml:4527(glossterm)#: ./doc/glossary/glossary-terms.xml:4532(para)#: ./doc/glossary/glossary-terms.xml:4541(title)#: ./doc/glossary/glossary-terms.xml:4545(primary)#: ./doc/glossary/glossary-terms.xml:4544(glossterm)#: ./doc/glossary/glossary-terms.xml:4549(para)#: ./doc/glossary/glossary-terms.xml:4556(primary)#: ./doc/glossary/glossary-terms.xml:4555(glossterm)#: ./doc/glossary/glossary-terms.xml:4560(para)#: ./doc/glossary/glossary-terms.xml:4568(primary)#: ./doc/glossary/glossary-terms.xml:4567(glossterm)#: ./doc/glossary/glossary-terms.xml:4572(para)#: ./doc/glossary/glossary-terms.xml:4580(primary) ./doc/glossary/glossary-terms.xml:4595(primary) ./doc/glossary/glossary-terms.xml:4608(primary) ./doc/glossary/glossary-terms.xml:4622(primary) ./doc/glossary/glossary-terms.xml:4635(primary) ./doc/glossary/glossary-terms.xml:4648(primary) ./doc/glossary/glossary-terms.xml:4661(primary) ./doc/glossary/glossary-terms.xml:4673(primary) ./doc/glossary/glossary-terms.xml:4686(primary) ./doc/glossary/glossary-terms.xml:4699(primary) ./doc/glossary/glossary-terms.xml:4712(primary) ./doc/glossary/glossary-terms.xml:5432(primary) ./doc/glossary/glossary-terms.xml:5613(primary) ./doc/glossary/glossary-terms.xml:7381(primary) ./doc/glossary/glossary-terms.xml:7515(primary)#: ./doc/glossary/glossary-terms.xml:4579(glossterm)#: ./doc/glossary/glossary-terms.xml:4586(para)#: ./doc/glossary/glossary-terms.xml:4597(secondary)#: ./doc/glossary/glossary-terms.xml:4594(glossterm)#: ./doc/glossary/glossary-terms.xml:4601(para)#: ./doc/glossary/glossary-terms.xml:4610(secondary)#: ./doc/glossary/glossary-terms.xml:4607(glossterm)#: ./doc/glossary/glossary-terms.xml:4614(para)#: ./doc/glossary/glossary-terms.xml:4624(secondary)#: ./doc/glossary/glossary-terms.xml:4621(glossterm)#: ./doc/glossary/glossary-terms.xml:4628(para)#: ./doc/glossary/glossary-terms.xml:4637(secondary)#: ./doc/glossary/glossary-terms.xml:4634(glossterm)#: ./doc/glossary/glossary-terms.xml:4641(para)#: ./doc/glossary/glossary-terms.xml:4650(secondary)#: ./doc/glossary/glossary-terms.xml:4647(glossterm)#: ./doc/glossary/glossary-terms.xml:4654(para)#: ./doc/glossary/glossary-terms.xml:4663(secondary)#: ./doc/glossary/glossary-terms.xml:4660(glossterm)#: ./doc/glossary/glossary-terms.xml:4667(para)#: ./doc/glossary/glossary-terms.xml:4675(secondary)#: ./doc/glossary/glossary-terms.xml:4672(glossterm)#: ./doc/glossary/glossary-terms.xml:4679(para)#: ./doc/glossary/glossary-terms.xml:4688(secondary)#: ./doc/glossary/glossary-terms.xml:4685(glossterm)#: ./doc/glossary/glossary-terms.xml:4692(para)#: ./doc/glossary/glossary-terms.xml:4701(secondary)#: ./doc/glossary/glossary-terms.xml:4698(glossterm)#: ./doc/glossary/glossary-terms.xml:4705(para)#: ./doc/glossary/glossary-terms.xml:4714(secondary)#: ./doc/glossary/glossary-terms.xml:4711(glossterm)#: ./doc/glossary/glossary-terms.xml:4718(para)#: ./doc/glossary/glossary-terms.xml:4725(glossterm)#: ./doc/glossary/glossary-terms.xml:4728(para)#: ./doc/glossary/glossary-terms.xml:4736(primary) ./doc/glossary/glossary-terms.xml:4758(secondary)#: ./doc/glossary/glossary-terms.xml:4735(glossterm)#: ./doc/glossary/glossary-terms.xml:4740(para)#: ./doc/glossary/glossary-terms.xml:4746(glossterm) ./doc/glossary/glossary-terms.xml:4756(primary) ./doc/glossary/glossary-terms.xml:4768(primary) ./doc/glossary/glossary-terms.xml:4781(primary)#: ./doc/glossary/glossary-terms.xml:4749(para)#: ./doc/glossary/glossary-terms.xml:4755(glossterm)#: ./doc/glossary/glossary-terms.xml:4762(para)#: ./doc/glossary/glossary-terms.xml:4770(secondary)#: ./doc/glossary/glossary-terms.xml:4767(glossterm)#: ./doc/glossary/glossary-terms.xml:4774(para)#: ./doc/glossary/glossary-terms.xml:4783(secondary)#: ./doc/glossary/glossary-terms.xml:4780(glossterm)#: ./doc/glossary/glossary-terms.xml:4787(para)#: ./doc/glossary/glossary-terms.xml:4795(primary)#: ./doc/glossary/glossary-terms.xml:4794(glossterm)#: ./doc/glossary/glossary-terms.xml:4799(para)#: ./doc/glossary/glossary-terms.xml:4805(primary)#: ./doc/glossary/glossary-terms.xml:4804(glossterm)#: ./doc/glossary/glossary-terms.xml:4809(para)#: ./doc/glossary/glossary-terms.xml:4816(primary) ./doc/glossary/glossary-terms.xml:5528(primary) ./doc/glossary/glossary-terms.xml:6751(primary) ./doc/glossary/glossary-terms.xml:6935(primary)#: ./doc/glossary/glossary-terms.xml:4815(glossterm)#: ./doc/glossary/glossary-terms.xml:4822(para)#: ./doc/glossary/glossary-terms.xml:4828(primary) ./doc/glossary/glossary-terms.xml:4843(primary) ./doc/glossary/glossary-terms.xml:5273(primary) ./doc/glossary/glossary-terms.xml:7178(primary)#: ./doc/glossary/glossary-terms.xml:4830(secondary) ./doc/glossary/glossary-terms.xml:4832(primary) ./doc/glossary/glossary-terms.xml:7159(see)#: ./doc/glossary/glossary-terms.xml:4827(glossterm)#: ./doc/glossary/glossary-terms.xml:4836(para)#: ./doc/glossary/glossary-terms.xml:4845(secondary)#: ./doc/glossary/glossary-terms.xml:4847(primary)#: ./doc/glossary/glossary-terms.xml:4842(glossterm)#: ./doc/glossary/glossary-terms.xml:4851(para)#: ./doc/glossary/glossary-terms.xml:4858(primary)#: ./doc/glossary/glossary-terms.xml:4857(glossterm)#: ./doc/glossary/glossary-terms.xml:4864(para)#: ./doc/glossary/glossary-terms.xml:4869(glossterm) ./doc/glossary/glossary-terms.xml:4878(primary) ./doc/glossary/glossary-terms.xml:4890(primary)#: ./doc/glossary/glossary-terms.xml:4872(para)#: ./doc/glossary/glossary-terms.xml:4877(glossterm)#: ./doc/glossary/glossary-terms.xml:4884(para)#: ./doc/glossary/glossary-terms.xml:4892(secondary)#: ./doc/glossary/glossary-terms.xml:4889(glossterm)#: ./doc/glossary/glossary-terms.xml:4896(para)#: ./doc/glossary/glossary-terms.xml:4906(title)#: ./doc/glossary/glossary-terms.xml:4909(glossterm)#: ./doc/glossary/glossary-terms.xml:4916(para)#: ./doc/glossary/glossary-terms.xml:4925(secondary)#: ./doc/glossary/glossary-terms.xml:4922(glossterm)#: ./doc/glossary/glossary-terms.xml:4929(para)#: ./doc/glossary/glossary-terms.xml:4938(secondary)#: ./doc/glossary/glossary-terms.xml:4935(glossterm)#: ./doc/glossary/glossary-terms.xml:4942(para)#: ./doc/glossary/glossary-terms.xml:4952(secondary)#: ./doc/glossary/glossary-terms.xml:4949(glossterm)#: ./doc/glossary/glossary-terms.xml:4956(para)#: ./doc/glossary/glossary-terms.xml:4964(secondary)#: ./doc/glossary/glossary-terms.xml:4961(glossterm)#: ./doc/glossary/glossary-terms.xml:4968(para)#: ./doc/glossary/glossary-terms.xml:4977(secondary)#: ./doc/glossary/glossary-terms.xml:4974(glossterm)#: ./doc/glossary/glossary-terms.xml:4981(para)#: ./doc/glossary/glossary-terms.xml:4990(secondary)#: ./doc/glossary/glossary-terms.xml:4987(glossterm)#: ./doc/glossary/glossary-terms.xml:4994(para)#: ./doc/glossary/glossary-terms.xml:5000(glossterm) ./doc/glossary/glossary-terms.xml:5015(primary) ./doc/glossary/glossary-terms.xml:5027(primary)#: ./doc/glossary/glossary-terms.xml:5003(para)#: ./doc/glossary/glossary-terms.xml:5011(primary) ./doc/glossary/glossary-terms.xml:6884(glossterm) ./doc/glossary/glossary-terms.xml:6905(primary) ./doc/glossary/glossary-terms.xml:6918(primary) ./doc/glossary/glossary-terms.xml:6939(primary)#: ./doc/glossary/glossary-terms.xml:5013(secondary) ./doc/glossary/glossary-terms.xml:5017(secondary)#: ./doc/glossary/glossary-terms.xml:5010(glossterm)#: ./doc/glossary/glossary-terms.xml:5021(para)#: ./doc/glossary/glossary-terms.xml:5029(secondary)#: ./doc/glossary/glossary-terms.xml:5026(glossterm)#: ./doc/glossary/glossary-terms.xml:5033(para)#: ./doc/glossary/glossary-terms.xml:5041(secondary)#: ./doc/glossary/glossary-terms.xml:5038(glossterm)#: ./doc/glossary/glossary-terms.xml:5045(para)#: ./doc/glossary/glossary-terms.xml:5052(primary)#: ./doc/glossary/glossary-terms.xml:5051(glossterm)#: ./doc/glossary/glossary-terms.xml:5056(para)#: ./doc/glossary/glossary-terms.xml:5064(primary)#: ./doc/glossary/glossary-terms.xml:5062(glossterm)#: ./doc/glossary/glossary-terms.xml:5068(para)#: ./doc/glossary/glossary-terms.xml:5075(primary)#: ./doc/glossary/glossary-terms.xml:5074(glossterm)#: ./doc/glossary/glossary-terms.xml:5079(para)#: ./doc/glossary/glossary-terms.xml:5085(primary)#: ./doc/glossary/glossary-terms.xml:5084(glossterm)#: ./doc/glossary/glossary-terms.xml:5091(para)#: ./doc/glossary/glossary-terms.xml:5097(primary)#: ./doc/glossary/glossary-terms.xml:5096(glossterm)#: ./doc/glossary/glossary-terms.xml:5101(para)#: ./doc/glossary/glossary-terms.xml:5108(primary) ./doc/glossary/glossary-terms.xml:5125(primary)#: ./doc/glossary/glossary-terms.xml:5107(glossterm)#: ./doc/glossary/glossary-terms.xml:5114(para)#: ./doc/glossary/glossary-terms.xml:5126(secondary)#: ./doc/glossary/glossary-terms.xml:5124(glossterm)#: ./doc/glossary/glossary-terms.xml:5130(para)#: ./doc/glossary/glossary-terms.xml:5145(primary)#: ./doc/glossary/glossary-terms.xml:5144(glossterm)#: ./doc/glossary/glossary-terms.xml:5155(primary)#: ./doc/glossary/glossary-terms.xml:5154(glossterm)#: ./doc/glossary/glossary-terms.xml:5159(para)#: ./doc/glossary/glossary-terms.xml:5166(primary)#: ./doc/glossary/glossary-terms.xml:5165(glossterm)#: ./doc/glossary/glossary-terms.xml:5170(para)#: ./doc/glossary/glossary-terms.xml:5178(primary)#: ./doc/glossary/glossary-terms.xml:5177(glossterm)#: ./doc/glossary/glossary-terms.xml:5182(para)#: ./doc/glossary/glossary-terms.xml:5191(title)#: ./doc/glossary/glossary-terms.xml:5197(secondary) ./doc/glossary/glossary-terms.xml:5199(primary)#: ./doc/glossary/glossary-terms.xml:5194(glossterm)#: ./doc/glossary/glossary-terms.xml:5203(para)#: ./doc/glossary/glossary-terms.xml:5211(primary) ./doc/glossary/glossary-terms.xml:5225(primary) ./doc/glossary/glossary-terms.xml:5238(primary)#: ./doc/glossary/glossary-terms.xml:5210(glossterm)#: ./doc/glossary/glossary-terms.xml:5217(para)#: ./doc/glossary/glossary-terms.xml:5227(secondary)#: ./doc/glossary/glossary-terms.xml:5224(glossterm)#: ./doc/glossary/glossary-terms.xml:5231(para)#: ./doc/glossary/glossary-terms.xml:5240(secondary)#: ./doc/glossary/glossary-terms.xml:5237(glossterm)#: ./doc/glossary/glossary-terms.xml:5244(para)#: ./doc/glossary/glossary-terms.xml:5251(primary)#: ./doc/glossary/glossary-terms.xml:5250(glossterm)#: ./doc/glossary/glossary-terms.xml:5255(para)#: ./doc/glossary/glossary-terms.xml:5262(primary)#: ./doc/glossary/glossary-terms.xml:5261(glossterm)#: ./doc/glossary/glossary-terms.xml:5266(para)#: ./doc/glossary/glossary-terms.xml:5275(secondary) ./doc/glossary/glossary-terms.xml:5277(primary)#: ./doc/glossary/glossary-terms.xml:5272(glossterm)#: ./doc/glossary/glossary-terms.xml:5281(para)#: ./doc/glossary/glossary-terms.xml:5288(primary)#: ./doc/glossary/glossary-terms.xml:5287(glossterm)#: ./doc/glossary/glossary-terms.xml:5292(para)#: ./doc/glossary/glossary-terms.xml:5298(primary)#: ./doc/glossary/glossary-terms.xml:5297(glossterm)#: ./doc/glossary/glossary-terms.xml:5302(para)#: ./doc/glossary/glossary-terms.xml:5309(primary)#: ./doc/glossary/glossary-terms.xml:5308(glossterm)#: ./doc/glossary/glossary-terms.xml:5313(para)#: ./doc/glossary/glossary-terms.xml:5323(primary)#: ./doc/glossary/glossary-terms.xml:5322(glossterm)#: ./doc/glossary/glossary-terms.xml:5327(para)#: ./doc/glossary/glossary-terms.xml:5334(primary)#: ./doc/glossary/glossary-terms.xml:5333(glossterm)#: ./doc/glossary/glossary-terms.xml:5338(para)#: ./doc/glossary/glossary-terms.xml:5345(primary)#: ./doc/glossary/glossary-terms.xml:5344(glossterm)#: ./doc/glossary/glossary-terms.xml:5349(para)#: ./doc/glossary/glossary-terms.xml:5359(primary)#: ./doc/glossary/glossary-terms.xml:5358(glossterm)#: ./doc/glossary/glossary-terms.xml:5363(para)#: ./doc/glossary/glossary-terms.xml:5370(primary) ./doc/glossary/glossary-terms.xml:5383(primary) ./doc/glossary/glossary-terms.xml:7432(primary)#: ./doc/glossary/glossary-terms.xml:5369(glossterm)#: ./doc/glossary/glossary-terms.xml:5376(para)#: ./doc/glossary/glossary-terms.xml:5385(secondary)#: ./doc/glossary/glossary-terms.xml:5382(glossterm)#: ./doc/glossary/glossary-terms.xml:5389(para)#: ./doc/glossary/glossary-terms.xml:5395(primary)#: ./doc/glossary/glossary-terms.xml:5394(glossterm)#: ./doc/glossary/glossary-terms.xml:5399(para)#: ./doc/glossary/glossary-terms.xml:5406(primary)#: ./doc/glossary/glossary-terms.xml:5405(glossterm)#: ./doc/glossary/glossary-terms.xml:5410(para)#: ./doc/glossary/glossary-terms.xml:5419(secondary)#: ./doc/glossary/glossary-terms.xml:5421(primary)#: ./doc/glossary/glossary-terms.xml:5416(glossterm)#: ./doc/glossary/glossary-terms.xml:5425(para)#: ./doc/glossary/glossary-terms.xml:5434(secondary) ./doc/glossary/glossary-terms.xml:5436(primary)#: ./doc/glossary/glossary-terms.xml:5431(glossterm)#: ./doc/glossary/glossary-terms.xml:5440(para)#: ./doc/glossary/glossary-terms.xml:5453(primary) ./doc/glossary/glossary-terms.xml:5466(primary) ./doc/glossary/glossary-terms.xml:5479(primary)#: ./doc/glossary/glossary-terms.xml:5452(glossterm)#: ./doc/glossary/glossary-terms.xml:5459(para)#: ./doc/glossary/glossary-terms.xml:5468(secondary)#: ./doc/glossary/glossary-terms.xml:5465(glossterm)#: ./doc/glossary/glossary-terms.xml:5472(para)#: ./doc/glossary/glossary-terms.xml:5481(secondary)#: ./doc/glossary/glossary-terms.xml:5478(glossterm)#: ./doc/glossary/glossary-terms.xml:5485(para)#: ./doc/glossary/glossary-terms.xml:5491(primary)#: ./doc/glossary/glossary-terms.xml:5490(glossterm)#: ./doc/glossary/glossary-terms.xml:5495(para)#: ./doc/glossary/glossary-terms.xml:5503(primary)#: ./doc/glossary/glossary-terms.xml:5502(glossterm)#: ./doc/glossary/glossary-terms.xml:5507(para)#: ./doc/glossary/glossary-terms.xml:5517(primary)#: ./doc/glossary/glossary-terms.xml:5516(glossterm)#: ./doc/glossary/glossary-terms.xml:5521(para)#: ./doc/glossary/glossary-terms.xml:5530(secondary) ./doc/glossary/glossary-terms.xml:5532(primary)#: ./doc/glossary/glossary-terms.xml:5527(glossterm)#: ./doc/glossary/glossary-terms.xml:5536(para)#: ./doc/glossary/glossary-terms.xml:5544(secondary) ./doc/glossary/glossary-terms.xml:5546(primary)#: ./doc/glossary/glossary-terms.xml:5541(glossterm)#: ./doc/glossary/glossary-terms.xml:5550(para)#: ./doc/glossary/glossary-terms.xml:5560(secondary)#: ./doc/glossary/glossary-terms.xml:5562(primary)#: ./doc/glossary/glossary-terms.xml:5557(glossterm)#: ./doc/glossary/glossary-terms.xml:5566(para)#: ./doc/glossary/glossary-terms.xml:5575(secondary)#: ./doc/glossary/glossary-terms.xml:5577(primary)#: ./doc/glossary/glossary-terms.xml:5572(glossterm)#: ./doc/glossary/glossary-terms.xml:5581(para)#: ./doc/glossary/glossary-terms.xml:5590(secondary) ./doc/glossary/glossary-terms.xml:5615(secondary)#: ./doc/glossary/glossary-terms.xml:5592(primary)#: ./doc/glossary/glossary-terms.xml:5587(glossterm)#: ./doc/glossary/glossary-terms.xml:5596(para)#: ./doc/glossary/glossary-terms.xml:5602(primary)#: ./doc/glossary/glossary-terms.xml:5601(glossterm)#: ./doc/glossary/glossary-terms.xml:5606(para)#: ./doc/glossary/glossary-terms.xml:5617(primary)#: ./doc/glossary/glossary-terms.xml:5612(glossterm)#: ./doc/glossary/glossary-terms.xml:5621(para)#: ./doc/glossary/glossary-terms.xml:5631(primary)#: ./doc/glossary/glossary-terms.xml:5630(glossterm)#: ./doc/glossary/glossary-terms.xml:5635(para)#: ./doc/glossary/glossary-terms.xml:5642(primary)#: ./doc/glossary/glossary-terms.xml:5641(glossterm)#: ./doc/glossary/glossary-terms.xml:5646(para)#: ./doc/glossary/glossary-terms.xml:5654(title)#: ./doc/glossary/glossary-terms.xml:5658(primary)#: ./doc/glossary/glossary-terms.xml:5657(glossterm)#: ./doc/glossary/glossary-terms.xml:5669(primary)#: ./doc/glossary/glossary-terms.xml:5668(glossterm)#: ./doc/glossary/glossary-terms.xml:5673(para)#: ./doc/glossary/glossary-terms.xml:5680(primary)#: ./doc/glossary/glossary-terms.xml:5679(glossterm)#: ./doc/glossary/glossary-terms.xml:5684(para)#: ./doc/glossary/glossary-terms.xml:5692(primary)#: ./doc/glossary/glossary-terms.xml:5691(glossterm)#: ./doc/glossary/glossary-terms.xml:5696(para)#: ./doc/glossary/glossary-terms.xml:5699(para)#: ./doc/glossary/glossary-terms.xml:5706(primary)#: ./doc/glossary/glossary-terms.xml:5705(glossterm)#: ./doc/glossary/glossary-terms.xml:5710(para)#: ./doc/glossary/glossary-terms.xml:5719(title)#: ./doc/glossary/glossary-terms.xml:5723(primary)#: ./doc/glossary/glossary-terms.xml:5722(glossterm)#: ./doc/glossary/glossary-terms.xml:5727(para)#: ./doc/glossary/glossary-terms.xml:5733(primary)#: ./doc/glossary/glossary-terms.xml:5732(glossterm)#: ./doc/glossary/glossary-terms.xml:5737(para)#: ./doc/glossary/glossary-terms.xml:5744(primary)#: ./doc/glossary/glossary-terms.xml:5743(glossterm)#: ./doc/glossary/glossary-terms.xml:5748(para)#: ./doc/glossary/glossary-terms.xml:5755(primary)#: ./doc/glossary/glossary-terms.xml:5754(glossterm)#: ./doc/glossary/glossary-terms.xml:5759(para)#: ./doc/glossary/glossary-terms.xml:5767(primary)#: ./doc/glossary/glossary-terms.xml:5766(glossterm)#: ./doc/glossary/glossary-terms.xml:5771(para)#: ./doc/glossary/glossary-terms.xml:5778(primary)#: ./doc/glossary/glossary-terms.xml:5777(glossterm)#: ./doc/glossary/glossary-terms.xml:5782(para)#: ./doc/glossary/glossary-terms.xml:5791(primary)#: ./doc/glossary/glossary-terms.xml:5790(glossterm)#: ./doc/glossary/glossary-terms.xml:5795(para)#: ./doc/glossary/glossary-terms.xml:5802(primary)#: ./doc/glossary/glossary-terms.xml:5801(glossterm)#: ./doc/glossary/glossary-terms.xml:5806(para)#: ./doc/glossary/glossary-terms.xml:5813(primary)#: ./doc/glossary/glossary-terms.xml:5812(glossterm)#: ./doc/glossary/glossary-terms.xml:5817(para)#: ./doc/glossary/glossary-terms.xml:5825(primary) ./doc/glossary/glossary-terms.xml:6616(primary)#: ./doc/glossary/glossary-terms.xml:5827(secondary) ./doc/glossary/glossary-terms.xml:6618(secondary)#: ./doc/glossary/glossary-terms.xml:5824(glossterm)#: ./doc/glossary/glossary-terms.xml:5831(para)#: ./doc/glossary/glossary-terms.xml:5842(primary)#: ./doc/glossary/glossary-terms.xml:5841(glossterm)#: ./doc/glossary/glossary-terms.xml:5846(para)#: ./doc/glossary/glossary-terms.xml:5853(primary)#: ./doc/glossary/glossary-terms.xml:5852(glossterm)#: ./doc/glossary/glossary-terms.xml:5857(para)#: ./doc/glossary/glossary-terms.xml:5863(primary) ./doc/glossary/glossary-terms.xml:5881(primary)#: ./doc/glossary/glossary-terms.xml:5862(glossterm)#: ./doc/glossary/glossary-terms.xml:5869(para)#: ./doc/glossary/glossary-terms.xml:5883(secondary)#: ./doc/glossary/glossary-terms.xml:5880(glossterm)#: ./doc/glossary/glossary-terms.xml:5887(para)#: ./doc/glossary/glossary-terms.xml:5894(primary)#: ./doc/glossary/glossary-terms.xml:5893(glossterm)#: ./doc/glossary/glossary-terms.xml:5904(primary)#: ./doc/glossary/glossary-terms.xml:5903(glossterm)#: ./doc/glossary/glossary-terms.xml:5908(para)#: ./doc/glossary/glossary-terms.xml:5914(primary)#: ./doc/glossary/glossary-terms.xml:5913(glossterm)#: ./doc/glossary/glossary-terms.xml:5918(para)#: ./doc/glossary/glossary-terms.xml:5926(primary)#: ./doc/glossary/glossary-terms.xml:5928(see)#: ./doc/glossary/glossary-terms.xml:5925(glossterm)#: ./doc/glossary/glossary-terms.xml:5932(para)#: ./doc/glossary/glossary-terms.xml:5940(secondary) ./doc/glossary/glossary-terms.xml:5942(primary)#: ./doc/glossary/glossary-terms.xml:5937(glossterm)#: ./doc/glossary/glossary-terms.xml:5946(para)#: ./doc/glossary/glossary-terms.xml:5954(primary)#: ./doc/glossary/glossary-terms.xml:5952(glossterm)#: ./doc/glossary/glossary-terms.xml:5959(para)#: ./doc/glossary/glossary-terms.xml:5966(primary)#: ./doc/glossary/glossary-terms.xml:5965(glossterm)#: ./doc/glossary/glossary-terms.xml:5970(para)#: ./doc/glossary/glossary-terms.xml:5977(primary) ./doc/glossary/glossary-terms.xml:5991(primary) ./doc/glossary/glossary-terms.xml:6003(glossterm) ./doc/glossary/glossary-terms.xml:6013(primary)#: ./doc/glossary/glossary-terms.xml:5976(glossterm)#: ./doc/glossary/glossary-terms.xml:5983(para)#: ./doc/glossary/glossary-terms.xml:5993(secondary)#: ./doc/glossary/glossary-terms.xml:5990(glossterm)#: ./doc/glossary/glossary-terms.xml:5997(para)#: ./doc/glossary/glossary-terms.xml:6006(para)#: ./doc/glossary/glossary-terms.xml:6015(secondary)#: ./doc/glossary/glossary-terms.xml:6012(glossterm)#: ./doc/glossary/glossary-terms.xml:6019(para)#: ./doc/glossary/glossary-terms.xml:6026(primary)#: ./doc/glossary/glossary-terms.xml:6025(glossterm)#: ./doc/glossary/glossary-terms.xml:6030(para)#: ./doc/glossary/glossary-terms.xml:6036(primary)#: ./doc/glossary/glossary-terms.xml:6035(glossterm)#: ./doc/glossary/glossary-terms.xml:6040(para)#: ./doc/glossary/glossary-terms.xml:6048(primary)#: ./doc/glossary/glossary-terms.xml:6047(glossterm)#: ./doc/glossary/glossary-terms.xml:6052(para)#: ./doc/glossary/glossary-terms.xml:6061(primary)#: ./doc/glossary/glossary-terms.xml:6060(glossterm)#: ./doc/glossary/glossary-terms.xml:6065(para)#: ./doc/glossary/glossary-terms.xml:6073(primary) ./doc/glossary/glossary-terms.xml:6087(primary)#: ./doc/glossary/glossary-terms.xml:6072(glossterm)#: ./doc/glossary/glossary-terms.xml:6079(para)#: ./doc/glossary/glossary-terms.xml:6089(secondary)#: ./doc/glossary/glossary-terms.xml:6086(glossterm)#: ./doc/glossary/glossary-terms.xml:6093(para)#: ./doc/glossary/glossary-terms.xml:6101(primary)#: ./doc/glossary/glossary-terms.xml:6100(glossterm)#: ./doc/glossary/glossary-terms.xml:6105(para)#: ./doc/glossary/glossary-terms.xml:6114(primary) ./doc/glossary/glossary-terms.xml:6128(primary)#: ./doc/glossary/glossary-terms.xml:6113(glossterm)#: ./doc/glossary/glossary-terms.xml:6120(para)#: ./doc/glossary/glossary-terms.xml:6130(secondary)#: ./doc/glossary/glossary-terms.xml:6127(glossterm)#: ./doc/glossary/glossary-terms.xml:6134(para)#: ./doc/glossary/glossary-terms.xml:6140(primary)#: ./doc/glossary/glossary-terms.xml:6139(glossterm)#: ./doc/glossary/glossary-terms.xml:6144(para)#: ./doc/glossary/glossary-terms.xml:6151(primary) ./doc/glossary/glossary-terms.xml:6655(primary)#: ./doc/glossary/glossary-terms.xml:6153(secondary)#: ./doc/glossary/glossary-terms.xml:6155(primary)#: ./doc/glossary/glossary-terms.xml:6150(glossterm)#: ./doc/glossary/glossary-terms.xml:6159(para)#: ./doc/glossary/glossary-terms.xml:6166(primary)#: ./doc/glossary/glossary-terms.xml:6165(glossterm)#: ./doc/glossary/glossary-terms.xml:6170(para)#: ./doc/glossary/glossary-terms.xml:6177(primary)#: ./doc/glossary/glossary-terms.xml:6176(glossterm)#: ./doc/glossary/glossary-terms.xml:6181(para)#: ./doc/glossary/glossary-terms.xml:6189(primary)#: ./doc/glossary/glossary-terms.xml:6191(secondary) ./doc/glossary/glossary-terms.xml:6193(primary)#: ./doc/glossary/glossary-terms.xml:6188(glossterm)#: ./doc/glossary/glossary-terms.xml:6197(para)#: ./doc/glossary/glossary-terms.xml:6205(primary)#: ./doc/glossary/glossary-terms.xml:6204(glossterm)#: ./doc/glossary/glossary-terms.xml:6209(para)#: ./doc/glossary/glossary-terms.xml:6215(primary)#: ./doc/glossary/glossary-terms.xml:6214(glossterm)#: ./doc/glossary/glossary-terms.xml:6219(para)#: ./doc/glossary/glossary-terms.xml:6225(glossterm)#: ./doc/glossary/glossary-terms.xml:6228(para)#: ./doc/glossary/glossary-terms.xml:6235(primary)#: ./doc/glossary/glossary-terms.xml:6234(glossterm)#: ./doc/glossary/glossary-terms.xml:6239(para)#: ./doc/glossary/glossary-terms.xml:6248(title)#: ./doc/glossary/glossary-terms.xml:6252(primary)#: ./doc/glossary/glossary-terms.xml:6251(glossterm)#: ./doc/glossary/glossary-terms.xml:6256(para)#: ./doc/glossary/glossary-terms.xml:6264(primary)#: ./doc/glossary/glossary-terms.xml:6263(glossterm)#: ./doc/glossary/glossary-terms.xml:6268(para)#: ./doc/glossary/glossary-terms.xml:6275(primary)#: ./doc/glossary/glossary-terms.xml:6274(glossterm)#: ./doc/glossary/glossary-terms.xml:6279(para)#: ./doc/glossary/glossary-terms.xml:6287(primary)#: ./doc/glossary/glossary-terms.xml:6286(glossterm)#: ./doc/glossary/glossary-terms.xml:6291(para)#: ./doc/glossary/glossary-terms.xml:6298(primary)#: ./doc/glossary/glossary-terms.xml:6297(glossterm)#: ./doc/glossary/glossary-terms.xml:6302(para)#: ./doc/glossary/glossary-terms.xml:6309(primary)#: ./doc/glossary/glossary-terms.xml:6308(glossterm)#: ./doc/glossary/glossary-terms.xml:6313(para)#: ./doc/glossary/glossary-terms.xml:6320(primary)#: ./doc/glossary/glossary-terms.xml:6319(glossterm)#: ./doc/glossary/glossary-terms.xml:6324(para)#: ./doc/glossary/glossary-terms.xml:6332(primary)#: ./doc/glossary/glossary-terms.xml:6331(glossterm)#: ./doc/glossary/glossary-terms.xml:6336(para)#: ./doc/glossary/glossary-terms.xml:6345(secondary) ./doc/glossary/glossary-terms.xml:6347(primary)#: ./doc/glossary/glossary-terms.xml:6342(glossterm)#: ./doc/glossary/glossary-terms.xml:6351(para)#: ./doc/glossary/glossary-terms.xml:6358(glossterm)#: ./doc/glossary/glossary-terms.xml:6365(para)#: ./doc/glossary/glossary-terms.xml:6369(para)#: ./doc/glossary/glossary-terms.xml:6376(primary)#: ./doc/glossary/glossary-terms.xml:6375(glossterm)#: ./doc/glossary/glossary-terms.xml:6380(para)#: ./doc/glossary/glossary-terms.xml:6388(secondary)#: ./doc/glossary/glossary-terms.xml:6385(glossterm)#: ./doc/glossary/glossary-terms.xml:6399(primary)#: ./doc/glossary/glossary-terms.xml:6398(glossterm)#: ./doc/glossary/glossary-terms.xml:6405(para)#: ./doc/glossary/glossary-terms.xml:6413(primary)#: ./doc/glossary/glossary-terms.xml:6412(glossterm)#: ./doc/glossary/glossary-terms.xml:6417(para)#: ./doc/glossary/glossary-terms.xml:6423(primary)#: ./doc/glossary/glossary-terms.xml:6422(glossterm)#: ./doc/glossary/glossary-terms.xml:6427(para)#: ./doc/glossary/glossary-terms.xml:6434(primary)#: ./doc/glossary/glossary-terms.xml:6433(glossterm)#: ./doc/glossary/glossary-terms.xml:6438(para)#: ./doc/glossary/glossary-terms.xml:6445(primary)#: ./doc/glossary/glossary-terms.xml:6444(glossterm)#: ./doc/glossary/glossary-terms.xml:6449(para)#: ./doc/glossary/glossary-terms.xml:6456(primary)#: ./doc/glossary/glossary-terms.xml:6455(glossterm)#: ./doc/glossary/glossary-terms.xml:6460(para)#: ./doc/glossary/glossary-terms.xml:6467(primary) ./doc/glossary/glossary-terms.xml:6480(primary) ./doc/glossary/glossary-terms.xml:6494(primary)#: ./doc/glossary/glossary-terms.xml:6469(secondary)#: ./doc/glossary/glossary-terms.xml:6466(glossterm)#: ./doc/glossary/glossary-terms.xml:6473(para)#: ./doc/glossary/glossary-terms.xml:6482(secondary)#: ./doc/glossary/glossary-terms.xml:6479(glossterm)#: ./doc/glossary/glossary-terms.xml:6486(para)#: ./doc/glossary/glossary-terms.xml:6496(secondary)#: ./doc/glossary/glossary-terms.xml:6493(glossterm)#: ./doc/glossary/glossary-terms.xml:6500(para)#: ./doc/glossary/glossary-terms.xml:6509(secondary)#: ./doc/glossary/glossary-terms.xml:6511(primary)#: ./doc/glossary/glossary-terms.xml:6506(glossterm)#: ./doc/glossary/glossary-terms.xml:6515(para)#: ./doc/glossary/glossary-terms.xml:6529(primary)#: ./doc/glossary/glossary-terms.xml:6528(glossterm)#: ./doc/glossary/glossary-terms.xml:6533(para)#: ./doc/glossary/glossary-terms.xml:6543(primary)#: ./doc/glossary/glossary-terms.xml:6542(glossterm)#: ./doc/glossary/glossary-terms.xml:6547(para)#: ./doc/glossary/glossary-terms.xml:6554(primary)#: ./doc/glossary/glossary-terms.xml:6553(glossterm)#: ./doc/glossary/glossary-terms.xml:6558(para)#: ./doc/glossary/glossary-terms.xml:6566(primary)#: ./doc/glossary/glossary-terms.xml:6564(glossterm)#: ./doc/glossary/glossary-terms.xml:6570(para)#: ./doc/glossary/glossary-terms.xml:6578(primary)#: ./doc/glossary/glossary-terms.xml:6576(glossterm)#: ./doc/glossary/glossary-terms.xml:6582(para)#: ./doc/glossary/glossary-terms.xml:6593(primary)#: ./doc/glossary/glossary-terms.xml:6592(glossterm)#: ./doc/glossary/glossary-terms.xml:6597(para)#: ./doc/glossary/glossary-terms.xml:6604(primary)#: ./doc/glossary/glossary-terms.xml:6603(glossterm)#: ./doc/glossary/glossary-terms.xml:6608(para)#: ./doc/glossary/glossary-terms.xml:6620(primary)#: ./doc/glossary/glossary-terms.xml:6615(glossterm)#: ./doc/glossary/glossary-terms.xml:6624(para)#: ./doc/glossary/glossary-terms.xml:6631(primary)#: ./doc/glossary/glossary-terms.xml:6630(glossterm)#: ./doc/glossary/glossary-terms.xml:6635(para)#: ./doc/glossary/glossary-terms.xml:6642(primary)#: ./doc/glossary/glossary-terms.xml:6641(glossterm)#: ./doc/glossary/glossary-terms.xml:6647(para)#: ./doc/glossary/glossary-terms.xml:6657(secondary)#: ./doc/glossary/glossary-terms.xml:6659(primary)#: ./doc/glossary/glossary-terms.xml:6654(glossterm)#: ./doc/glossary/glossary-terms.xml:6663(para)#: ./doc/glossary/glossary-terms.xml:6670(primary)#: ./doc/glossary/glossary-terms.xml:6669(glossterm)#: ./doc/glossary/glossary-terms.xml:6674(para)#: ./doc/glossary/glossary-terms.xml:6680(primary)#: ./doc/glossary/glossary-terms.xml:6679(glossterm)#: ./doc/glossary/glossary-terms.xml:6684(para)#: ./doc/glossary/glossary-terms.xml:6691(primary)#: ./doc/glossary/glossary-terms.xml:6690(glossterm)#: ./doc/glossary/glossary-terms.xml:6695(para)#: ./doc/glossary/glossary-terms.xml:6704(primary)#: ./doc/glossary/glossary-terms.xml:6703(glossterm)#: ./doc/glossary/glossary-terms.xml:6708(para)#: ./doc/glossary/glossary-terms.xml:6717(secondary)#: ./doc/glossary/glossary-terms.xml:6719(primary)#: ./doc/glossary/glossary-terms.xml:6714(glossterm)#: ./doc/glossary/glossary-terms.xml:6723(para)#: ./doc/glossary/glossary-terms.xml:6729(primary)#: ./doc/glossary/glossary-terms.xml:6728(glossterm)#: ./doc/glossary/glossary-terms.xml:6733(para)#: ./doc/glossary/glossary-terms.xml:6740(primary)#: ./doc/glossary/glossary-terms.xml:6739(glossterm)#: ./doc/glossary/glossary-terms.xml:6744(para)#: ./doc/glossary/glossary-terms.xml:6753(secondary)#: ./doc/glossary/glossary-terms.xml:6755(primary)#: ./doc/glossary/glossary-terms.xml:6750(glossterm)#: ./doc/glossary/glossary-terms.xml:6759(para)#: ./doc/glossary/glossary-terms.xml:6767(primary) ./doc/glossary/glossary-terms.xml:6780(primary) ./doc/glossary/glossary-terms.xml:6793(primary) ./doc/glossary/glossary-terms.xml:6931(primary)#: ./doc/glossary/glossary-terms.xml:6769(secondary)#: ./doc/glossary/glossary-terms.xml:6766(glossterm)#: ./doc/glossary/glossary-terms.xml:6773(para)#: ./doc/glossary/glossary-terms.xml:6782(secondary)#: ./doc/glossary/glossary-terms.xml:6779(glossterm)#: ./doc/glossary/glossary-terms.xml:6786(para)#: ./doc/glossary/glossary-terms.xml:6795(secondary)#: ./doc/glossary/glossary-terms.xml:6792(glossterm)#: ./doc/glossary/glossary-terms.xml:6799(para)#: ./doc/glossary/glossary-terms.xml:6806(primary)#: ./doc/glossary/glossary-terms.xml:6805(glossterm)#: ./doc/glossary/glossary-terms.xml:6810(para)#: ./doc/glossary/glossary-terms.xml:6817(primary)#: ./doc/glossary/glossary-terms.xml:6816(glossterm)#: ./doc/glossary/glossary-terms.xml:6821(para)#: ./doc/glossary/glossary-terms.xml:6830(primary)#: ./doc/glossary/glossary-terms.xml:6829(glossterm)#: ./doc/glossary/glossary-terms.xml:6834(para)#: ./doc/glossary/glossary-terms.xml:6841(primary)#: ./doc/glossary/glossary-terms.xml:6839(glossterm)#: ./doc/glossary/glossary-terms.xml:6851(primary)#: ./doc/glossary/glossary-terms.xml:6850(glossterm)#: ./doc/glossary/glossary-terms.xml:6855(para)#: ./doc/glossary/glossary-terms.xml:6862(primary)#: ./doc/glossary/glossary-terms.xml:6861(glossterm)#: ./doc/glossary/glossary-terms.xml:6866(para)#: ./doc/glossary/glossary-terms.xml:6873(primary)#: ./doc/glossary/glossary-terms.xml:6872(glossterm)#: ./doc/glossary/glossary-terms.xml:6877(para)#: ./doc/glossary/glossary-terms.xml:6887(para)#: ./doc/glossary/glossary-terms.xml:6894(primary)#: ./doc/glossary/glossary-terms.xml:6893(glossterm)#: ./doc/glossary/glossary-terms.xml:6898(para)#: ./doc/glossary/glossary-terms.xml:6907(secondary)#: ./doc/glossary/glossary-terms.xml:6904(glossterm)#: ./doc/glossary/glossary-terms.xml:6911(para)#: ./doc/glossary/glossary-terms.xml:6920(secondary)#: ./doc/glossary/glossary-terms.xml:6917(glossterm)#: ./doc/glossary/glossary-terms.xml:6924(para)#: ./doc/glossary/glossary-terms.xml:6933(secondary) ./doc/glossary/glossary-terms.xml:6937(secondary) ./doc/glossary/glossary-terms.xml:6941(secondary)#: ./doc/glossary/glossary-terms.xml:6930(glossterm)#: ./doc/glossary/glossary-terms.xml:6945(para)#: ./doc/glossary/glossary-terms.xml:6952(primary)#: ./doc/glossary/glossary-terms.xml:6951(glossterm)#: ./doc/glossary/glossary-terms.xml:6956(para)#: ./doc/glossary/glossary-terms.xml:6963(primary)#: ./doc/glossary/glossary-terms.xml:6962(glossterm)#: ./doc/glossary/glossary-terms.xml:6967(para)#: ./doc/glossary/glossary-terms.xml:6975(primary)#: ./doc/glossary/glossary-terms.xml:6974(glossterm)#: ./doc/glossary/glossary-terms.xml:6979(para)#: ./doc/glossary/glossary-terms.xml:6989(title)#: ./doc/glossary/glossary-terms.xml:6993(primary)#: ./doc/glossary/glossary-terms.xml:6992(glossterm)#: ./doc/glossary/glossary-terms.xml:6997(para)#: ./doc/glossary/glossary-terms.xml:7005(primary)#: ./doc/glossary/glossary-terms.xml:7004(glossterm)#: ./doc/glossary/glossary-terms.xml:7009(para)#: ./doc/glossary/glossary-terms.xml:7017(primary)#: ./doc/glossary/glossary-terms.xml:7016(glossterm)#: ./doc/glossary/glossary-terms.xml:7021(para)#: ./doc/glossary/glossary-terms.xml:7028(primary)#: ./doc/glossary/glossary-terms.xml:7027(glossterm)#: ./doc/glossary/glossary-terms.xml:7032(para)#: ./doc/glossary/glossary-terms.xml:7038(glossterm) ./doc/glossary/glossary-terms.xml:7048(primary) ./doc/glossary/glossary-terms.xml:7064(primary) ./doc/glossary/glossary-terms.xml:7077(primary)#: ./doc/glossary/glossary-terms.xml:7041(para)#: ./doc/glossary/glossary-terms.xml:7050(secondary)#: ./doc/glossary/glossary-terms.xml:7047(glossterm)#: ./doc/glossary/glossary-terms.xml:7054(para)#: ./doc/glossary/glossary-terms.xml:7062(secondary) ./doc/glossary/glossary-terms.xml:7066(secondary)#: ./doc/glossary/glossary-terms.xml:7059(glossterm)#: ./doc/glossary/glossary-terms.xml:7070(para)#: ./doc/glossary/glossary-terms.xml:7079(secondary)#: ./doc/glossary/glossary-terms.xml:7076(glossterm)#: ./doc/glossary/glossary-terms.xml:7083(para)#: ./doc/glossary/glossary-terms.xml:7090(primary)#: ./doc/glossary/glossary-terms.xml:7089(glossterm)#: ./doc/glossary/glossary-terms.xml:7094(para)#: ./doc/glossary/glossary-terms.xml:7101(primary)#: ./doc/glossary/glossary-terms.xml:7100(glossterm)#: ./doc/glossary/glossary-terms.xml:7105(para)#: ./doc/glossary/glossary-terms.xml:7111(glossterm)#: ./doc/glossary/glossary-terms.xml:7114(para)#: ./doc/glossary/glossary-terms.xml:7124(primary)#: ./doc/glossary/glossary-terms.xml:7123(glossterm)#: ./doc/glossary/glossary-terms.xml:7128(para)#: ./doc/glossary/glossary-terms.xml:7135(primary)#: ./doc/glossary/glossary-terms.xml:7134(glossterm)#: ./doc/glossary/glossary-terms.xml:7139(para)#: ./doc/glossary/glossary-terms.xml:7146(primary)#: ./doc/glossary/glossary-terms.xml:7145(glossterm)#: ./doc/glossary/glossary-terms.xml:7150(para)#: ./doc/glossary/glossary-terms.xml:7157(primary)#: ./doc/glossary/glossary-terms.xml:7156(glossterm)#: ./doc/glossary/glossary-terms.xml:7163(para)#: ./doc/glossary/glossary-terms.xml:7168(glossterm)#: ./doc/glossary/glossary-terms.xml:7171(para)#: ./doc/glossary/glossary-terms.xml:7180(secondary) ./doc/glossary/glossary-terms.xml:7182(primary)#: ./doc/glossary/glossary-terms.xml:7177(glossterm)#: ./doc/glossary/glossary-terms.xml:7186(para)#: ./doc/glossary/glossary-terms.xml:7195(secondary) ./doc/glossary/glossary-terms.xml:7197(primary)#: ./doc/glossary/glossary-terms.xml:7192(glossterm)#: ./doc/glossary/glossary-terms.xml:7201(para)#: ./doc/glossary/glossary-terms.xml:7207(primary)#: ./doc/glossary/glossary-terms.xml:7206(glossterm)#: ./doc/glossary/glossary-terms.xml:7211(para)#: ./doc/glossary/glossary-terms.xml:7220(title)#: ./doc/glossary/glossary-terms.xml:7224(primary)#: ./doc/glossary/glossary-terms.xml:7223(glossterm)#: ./doc/glossary/glossary-terms.xml:7228(para)#: ./doc/glossary/glossary-terms.xml:7234(primary)#: ./doc/glossary/glossary-terms.xml:7233(glossterm)#: ./doc/glossary/glossary-terms.xml:7238(para)#: ./doc/glossary/glossary-terms.xml:7244(primary)#: ./doc/glossary/glossary-terms.xml:7243(glossterm)#: ./doc/glossary/glossary-terms.xml:7248(para)#: ./doc/glossary/glossary-terms.xml:7255(primary)#: ./doc/glossary/glossary-terms.xml:7254(glossterm)#: ./doc/glossary/glossary-terms.xml:7259(para)#: ./doc/glossary/glossary-terms.xml:7267(primary)#: ./doc/glossary/glossary-terms.xml:7266(glossterm)#: ./doc/glossary/glossary-terms.xml:7271(para)#: ./doc/glossary/glossary-terms.xml:7281(primary)#: ./doc/glossary/glossary-terms.xml:7280(glossterm)#: ./doc/glossary/glossary-terms.xml:7293(title)#: ./doc/glossary/glossary-terms.xml:7297(primary)#: ./doc/glossary/glossary-terms.xml:7296(glossterm)#: ./doc/glossary/glossary-terms.xml:7301(para)#: ./doc/glossary/glossary-terms.xml:7307(primary)#: ./doc/glossary/glossary-terms.xml:7306(glossterm)#: ./doc/glossary/glossary-terms.xml:7311(para)#: ./doc/glossary/glossary-terms.xml:7323(primary)#: ./doc/glossary/glossary-terms.xml:7321(glossterm)#: ./doc/glossary/glossary-terms.xml:7327(para)#: ./doc/glossary/glossary-terms.xml:7334(primary)#: ./doc/glossary/glossary-terms.xml:7333(glossterm)#: ./doc/glossary/glossary-terms.xml:7345(primary)#: ./doc/glossary/glossary-terms.xml:7344(glossterm)#: ./doc/glossary/glossary-terms.xml:7356(primary)#: ./doc/glossary/glossary-terms.xml:7355(glossterm)#: ./doc/glossary/glossary-terms.xml:7360(para)#: ./doc/glossary/glossary-terms.xml:7369(primary)#: ./doc/glossary/glossary-terms.xml:7368(glossterm)#: ./doc/glossary/glossary-terms.xml:7373(para)#: ./doc/glossary/glossary-terms.xml:7383(secondary) ./doc/glossary/glossary-terms.xml:7434(secondary) ./doc/glossary/glossary-terms.xml:7461(secondary)#: ./doc/glossary/glossary-terms.xml:7385(primary)#: ./doc/glossary/glossary-terms.xml:7380(glossterm)#: ./doc/glossary/glossary-terms.xml:7389(para)#: ./doc/glossary/glossary-terms.xml:7395(primary)#: ./doc/glossary/glossary-terms.xml:7394(glossterm)#: ./doc/glossary/glossary-terms.xml:7399(para)#: ./doc/glossary/glossary-terms.xml:7409(primary)#: ./doc/glossary/glossary-terms.xml:7408(glossterm)#: ./doc/glossary/glossary-terms.xml:7413(para)#: ./doc/glossary/glossary-terms.xml:7420(primary)#: ./doc/glossary/glossary-terms.xml:7419(glossterm)#: ./doc/glossary/glossary-terms.xml:7424(para)#: ./doc/glossary/glossary-terms.xml:7436(primary)#: ./doc/glossary/glossary-terms.xml:7431(glossterm)#: ./doc/glossary/glossary-terms.xml:7440(para)#: ./doc/glossary/glossary-terms.xml:7447(primary)#: ./doc/glossary/glossary-terms.xml:7446(glossterm)#: ./doc/glossary/glossary-terms.xml:7451(para)#: ./doc/glossary/glossary-terms.xml:7463(primary)#: ./doc/glossary/glossary-terms.xml:7458(glossterm)#: ./doc/glossary/glossary-terms.xml:7467(para)#: ./doc/glossary/glossary-terms.xml:7473(primary)#: ./doc/glossary/glossary-terms.xml:7472(glossterm)#: ./doc/glossary/glossary-terms.xml:7477(para)#: ./doc/glossary/glossary-terms.xml:7484(primary)#: ./doc/glossary/glossary-terms.xml:7483(glossterm)#: ./doc/glossary/glossary-terms.xml:7488(para)#: ./doc/glossary/glossary-terms.xml:7494(primary)#: ./doc/glossary/glossary-terms.xml:7493(glossterm)#: ./doc/glossary/glossary-terms.xml:7504(primary)#: ./doc/glossary/glossary-terms.xml:7503(glossterm)#: ./doc/glossary/glossary-terms.xml:7508(para)#: ./doc/glossary/glossary-terms.xml:7517(secondary)#: ./doc/glossary/glossary-terms.xml:7519(primary)#: ./doc/glossary/glossary-terms.xml:7514(glossterm)#: ./doc/glossary/glossary-terms.xml:7523(para)#: ./doc/glossary/glossary-terms.xml:7534(primary)#: ./doc/glossary/glossary-terms.xml:7533(glossterm)#: ./doc/glossary/glossary-terms.xml:7545(primary)#: ./doc/glossary/glossary-terms.xml:7544(glossterm)#: ./doc/glossary/glossary-terms.xml:7549(para)#: ./doc/glossary/glossary-terms.xml:7555(primary)#: ./doc/glossary/glossary-terms.xml:7554(glossterm)#: ./doc/glossary/glossary-terms.xml:7559(para)#: ./doc/glossary/glossary-terms.xml:7566(primary)#: ./doc/glossary/glossary-terms.xml:7565(glossterm)#: ./doc/glossary/glossary-terms.xml:7570(para)#: ./doc/glossary/glossary-terms.xml:7575(glossterm)#: ./doc/glossary/glossary-terms.xml:7578(para)#: ./doc/glossary/glossary-terms.xml:7584(primary)#: ./doc/glossary/glossary-terms.xml:7583(glossterm)#: ./doc/glossary/glossary-terms.xml:7588(para)#: ./doc/glossary/glossary-terms.xml:7594(glossterm) ./doc/glossary/glossary-terms.xml:7605(primary) ./doc/glossary/glossary-terms.xml:7617(primary) ./doc/glossary/glossary-terms.xml:7630(primary) ./doc/glossary/glossary-terms.xml:7642(primary) ./doc/glossary/glossary-terms.xml:7655(primary) ./doc/glossary/glossary-terms.xml:7668(primary) ./doc/glossary/glossary-terms.xml:7681(primary)#: ./doc/glossary/glossary-terms.xml:7597(para)#: ./doc/glossary/glossary-terms.xml:7607(secondary)#: ./doc/glossary/glossary-terms.xml:7604(glossterm)#: ./doc/glossary/glossary-terms.xml:7611(para)#: ./doc/glossary/glossary-terms.xml:7619(secondary)#: ./doc/glossary/glossary-terms.xml:7616(glossterm)#: ./doc/glossary/glossary-terms.xml:7623(para)#: ./doc/glossary/glossary-terms.xml:7632(secondary)#: ./doc/glossary/glossary-terms.xml:7629(glossterm)#: ./doc/glossary/glossary-terms.xml:7636(para)#: ./doc/glossary/glossary-terms.xml:7644(secondary)#: ./doc/glossary/glossary-terms.xml:7641(glossterm)#: ./doc/glossary/glossary-terms.xml:7648(para)#: ./doc/glossary/glossary-terms.xml:7657(secondary)#: ./doc/glossary/glossary-terms.xml:7654(glossterm)#: ./doc/glossary/glossary-terms.xml:7661(para)#: ./doc/glossary/glossary-terms.xml:7670(secondary)#: ./doc/glossary/glossary-terms.xml:7667(glossterm)#: ./doc/glossary/glossary-terms.xml:7674(para)#: ./doc/glossary/glossary-terms.xml:7683(secondary)#: ./doc/glossary/glossary-terms.xml:7680(glossterm)#: ./doc/glossary/glossary-terms.xml:7687(para)#: ./doc/glossary/glossary-terms.xml:7694(primary)#: ./doc/glossary/glossary-terms.xml:7693(glossterm)#: ./doc/glossary/glossary-terms.xml:7698(para)#: ./doc/glossary/glossary-terms.xml:7707(primary)#: ./doc/glossary/glossary-terms.xml:7706(glossterm)#: ./doc/glossary/glossary-terms.xml:7719(title)#: ./doc/glossary/glossary-terms.xml:7723(primary)#: ./doc/glossary/glossary-terms.xml:7722(glossterm)#: ./doc/glossary/glossary-terms.xml:7727(para)#: ./doc/glossary/glossary-terms.xml:7735(primary)#: ./doc/glossary/glossary-terms.xml:7734(glossterm)#: ./doc/glossary/glossary-terms.xml:7739(para)#: ./doc/glossary/glossary-terms.xml:7746(primary)#: ./doc/glossary/glossary-terms.xml:7745(glossterm)#: ./doc/glossary/glossary-terms.xml:7750(para)#: ./doc/glossary/glossary-terms.xml:7757(primary)#: ./doc/glossary/glossary-terms.xml:7756(glossterm)#: ./doc/glossary/glossary-terms.xml:7761(para)#: ./doc/glossary/glossary-terms.xml:7772(title)#: ./doc/glossary/glossary-terms.xml:7775(glossterm) ./doc/glossary/glossary-terms.xml:7785(primary) ./doc/glossary/glossary-terms.xml:7797(primary) ./doc/glossary/glossary-terms.xml:7810(primary)#: ./doc/glossary/glossary-terms.xml:7778(para)#: ./doc/glossary/glossary-terms.xml:7787(secondary)#: ./doc/glossary/glossary-terms.xml:7784(glossterm)#: ./doc/glossary/glossary-terms.xml:7799(secondary)#: ./doc/glossary/glossary-terms.xml:7796(glossterm)#: ./doc/glossary/glossary-terms.xml:7803(para)#: ./doc/glossary/glossary-terms.xml:7812(secondary)#: ./doc/glossary/glossary-terms.xml:7809(glossterm)#: ./doc/glossary/glossary-terms.xml:7824(title)#: ./doc/glossary/glossary-terms.xml:7838(title)#: ./doc/glossary/glossary-terms.xml:7842(primary)#: ./doc/glossary/glossary-terms.xml:7841(glossterm)#: ./doc/glossary/glossary-terms.xml:7846(para)#: ./doc/glossary/glossary-terms.xml:7853(primary)#: ./doc/glossary/glossary-terms.xml:7852(glossterm)#: ./doc/glossary/glossary-terms.xml:7857(para)",5842,5811
openstack%2Ftempest~master~I70bf5438a8fea9ca4f785313db4975b328f3a749,openstack/tempest,master,I70bf5438a8fea9ca4f785313db4975b328f3a749,cleaning up index.rst file,MERGED,2014-05-29 15:15:25.000000000,2014-07-17 08:45:07.000000000,2014-07-17 08:45:06.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1921}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-29 15:15:25.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7e571e6eea0e0455d8c68d5ff102a8f607de19d4', 'message': 'cleaning up index.rst file\n\nRemoved notes about the generation of the file.\n\nChange-Id: I70bf5438a8fea9ca4f785313db4975b328f3a749\n'}]",0,96490,7e571e6eea0e0455d8c68d5ff102a8f607de19d4,27,8,1,167,,,0,"cleaning up index.rst file

Removed notes about the generation of the file.

Change-Id: I70bf5438a8fea9ca4f785313db4975b328f3a749
",git fetch https://review.opendev.org/openstack/tempest refs/changes/90/96490/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,7e571e6eea0e0455d8c68d5ff102a8f607de19d4,fix_docu_index,,".. Tempest documentation master file, created by sphinx-quickstart on Tue May 21 17:43:32 2013. You can adapt this file completely to your liking, but it should at least contain the root `toctree` directive. ",0,5
openstack%2Fos-loganalyze~master~I1a85a841283ba5f40880356278d5d588139eed7e,openstack/os-loganalyze,master,I1a85a841283ba5f40880356278d5d588139eed7e,Try fetching index.html from swift,MERGED,2014-07-16 09:58:54.000000000,2014-07-17 08:37:30.000000000,2014-07-17 08:37:30.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}]","[{'number': 1, 'created': '2014-07-16 09:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/74ea5e79fec9c4b689167a3f3fc7d094a7447d99', 'message': ""Try fetching index.html from swift\n\nOpenStack returns a directory of log files back to gerrit. Swift\nhas no good way of listing this directory. However we'll upload our\nown index.html along with the files so we need to check for that.\n\nIf we have 404'd (or failed) on fetching from swift we should try\nseeing if an 'index.html' exists.\n\nChange-Id: I1a85a841283ba5f40880356278d5d588139eed7e\n""}, {'number': 2, 'created': '2014-07-17 08:26:51.000000000', 'files': ['os_loganalyze/generator.py'], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/e968f80893b503faac2af7c68239c83d3cf14fc9', 'message': ""Try fetching index.html from swift\n\nOpenStack returns a directory of log files back to gerrit. Swift\nhas no good way of listing this directory. However we'll upload our\nown index.html along with the files so we need to check for that.\n\nIf we have 404'd (or failed) on fetching from swift we should try\nseeing if an 'index.html' exists.\n\nChange-Id: I1a85a841283ba5f40880356278d5d588139eed7e\n""}]",0,107289,e968f80893b503faac2af7c68239c83d3cf14fc9,11,3,2,7069,,,0,"Try fetching index.html from swift

OpenStack returns a directory of log files back to gerrit. Swift
has no good way of listing this directory. However we'll upload our
own index.html along with the files so we need to check for that.

If we have 404'd (or failed) on fetching from swift we should try
seeing if an 'index.html' exists.

Change-Id: I1a85a841283ba5f40880356278d5d588139eed7e
",git fetch https://review.opendev.org/openstack/os-loganalyze refs/changes/89/107289/2 && git format-patch -1 --stdout FETCH_HEAD,['os_loganalyze/generator.py'],1,74ea5e79fec9c4b689167a3f3fc7d094a7447d99,check_for_index," if not flines_generator: logname = os.path.join(logname, 'index.html') flines_generator = get_swift_line_generator(logname, config)",,3,0
openstack%2Fneutron~master~Id420983ccbceece5f4a00546941618318b9562c7,openstack/neutron,master,Id420983ccbceece5f4a00546941618318b9562c7,VPNaaS: separate out validation logic for ref impl,MERGED,2014-06-24 21:13:48.000000000,2014-07-17 08:33:01.000000000,2014-07-17 03:11:48.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-06-24 21:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/871aa4679370573f336ea3719b97d3a8e0ccf6f0', 'message': 'VPNaaS: separate out validation logic for ref impl\n\nModify the persistence logic for VPNaaS to separate out the\nvalidation for the reference implmentation. This allows\nproviders to override/extend the validation, as needed.\nAdditional commits will address the separation for other\nproviders and for other L3 services.\n\nOnly attributes that have multiple validations are considered\nat this time, but this can be extended, as needed.\n\nIn the future, TaskFlow may be used for the L3 services workflow,\nand these changes will provide validation modularization for that\neffort.\n\nChange-Id: Id420983ccbceece5f4a00546941618318b9562c7\nPartially-implements: plueprint l3-svcs-vendor-validation\n'}, {'number': 2, 'created': '2014-06-25 15:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/50b364db88a91bab59afc1e7c44f3216394fabb5', 'message': 'VPNaaS: separate out validation logic for ref impl\n\nModify the persistence logic for VPNaaS to separate out the\nvalidation for the reference implmentation. This allows\nproviders to override/extend the validation, as needed.\nAdditional commits will address the separation for other\nproviders and for other L3 services.\n\nOnly attributes that have multiple validations are considered\nat this time, but this can be extended, as needed.\n\nIn the future, TaskFlow may be used for the L3 services workflow,\nand these changes will provide validation modularization for that\neffort.\n\nChange-Id: Id420983ccbceece5f4a00546941618318b9562c7\nPartially-implements: plueprint l3-svcs-vendor-validation\n'}, {'number': 3, 'created': '2014-06-25 23:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/acbb8f3add171a8069ef0c3bcb8ee08ab7b5d03e', 'message': 'VPNaaS: separate out validation logic for ref impl\n\nModify the persistence logic for VPNaaS to separate out the\nvalidation for the reference implmentation. This allows\nproviders to override/extend the validation, as needed.\nAdditional commits will address the separation for other\nproviders and for other L3 services.\n\nOnly attributes that have multiple validations are considered\nat this time, but this can be extended, as needed.\n\nIn the future, TaskFlow may be used for the L3 services workflow,\nand these changes will provide validation modularization for that\neffort.\n\nChange-Id: Id420983ccbceece5f4a00546941618318b9562c7\nPartially-implements: plueprint l3-svcs-vendor-validation\n'}, {'number': 4, 'created': '2014-06-26 14:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e0140b66e59febd5ecb06c73797b93d1df8043a', 'message': 'VPNaaS: separate out validation logic for ref impl\n\nModify the persistence logic for VPNaaS to separate out the\nvalidation for the reference implmentation. This allows\nproviders to override/extend the validation, as needed.\nAdditional commits will address the separation for other\nproviders and for other L3 services.\n\nOnly attributes that have multiple validations are considered\nat this time, but this can be extended, as needed.\n\nIn the future, TaskFlow may be used for the L3 services workflow,\nand these changes will provide validation modularization for that\neffort.\n\nChange-Id: Id420983ccbceece5f4a00546941618318b9562c7\nPartially-implements: plueprint l3-svcs-vendor-validation\n'}, {'number': 5, 'created': '2014-06-29 19:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a4ca15501c2f5d3126a3c97a7e2ed54cafdaabf5', 'message': 'VPNaaS: separate out validation logic for ref impl\n\nModify the persistence logic for VPNaaS to separate out the\nvalidation for the reference implmentation. This allows\nproviders to override/extend the validation, as needed.\nAdditional commits will address the separation for other\nproviders and for other L3 services.\n\nOnly attributes that have multiple validations are considered\nat this time, but this can be extended, as needed.\n\nIn the future, TaskFlow may be used for the L3 services workflow,\nand these changes will provide validation modularization for that\neffort.\n\nChange-Id: Id420983ccbceece5f4a00546941618318b9562c7\nPartially-implements: blueprint l3-svcs-vendor-validation\n'}, {'number': 6, 'created': '2014-07-11 15:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4f3c46c55ace6c3d362a8c29c4ab1043f776bb5', 'message': 'VPNaaS: separate out validation logic for ref impl\n\nModify the persistence logic for VPNaaS to separate out the\nvalidation for the reference implmentation. This allows\nproviders to override/extend the validation, as needed.\nAdditional commits will address the separation for other\nproviders and for other L3 services.\n\nIn addition, the logic that sets default values for optional\nattributes is also moved into separate methods to allow\nproviders to override the defaults used.\n\nOnly attributes that have multiple validations are considered\nat this time, but this can be extended, as needed.\n\nCurrently, one UT fails due to an oslo.messaging bug that\nhas been fixed, but not yet released for Neutron use.\nAs a workaround, the affected test case has been commented\nout. This test verifies that the right (only, in this case)\ndevice driver is used for validation. Once the issue with\nreleasing oslo.messaging 1.4.0.0a2 or newer is resolved,\nthis can be uncommented.\n\nIn the future, TaskFlow may be used for the L3 services workflow,\nand these changes will provide validation modularization for that\neffort.\n\nChange-Id: Id420983ccbceece5f4a00546941618318b9562c7\nPartially-implements: blueprint l3-svcs-vendor-validation\n'}, {'number': 7, 'created': '2014-07-16 19:05:12.000000000', 'files': ['neutron/tests/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron/db/vpn/vpn_validator.py', 'neutron/services/vpn/plugin.py', 'neutron/db/vpn/vpn_db.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c0ee4dc06a641abc941bcbb9b5467410c888a76', 'message': 'VPNaaS: separate out validation logic for ref impl\n\nModify the persistence logic for VPNaaS to separate out the\nvalidation for the reference implmentation. This allows\nproviders to override/extend the validation, as needed.\nAdditional commits will address the separation for other\nproviders and for other L3 services.\n\nIn addition, the logic that sets default values for optional\nattributes is also moved into separate methods to allow\nproviders to override the defaults used.\n\nOnly attributes that have multiple validations are considered\nat this time, but this can be extended, as needed.\n\nCurrently, one UT fails due to an oslo.messaging bug that\nhas been fixed, but not yet released for Neutron use.\nAs a workaround, the affected test case has been commented\nout. This test verifies that the right (only, in this case)\ndevice driver is used for validation. Once the issue with\nreleasing oslo.messaging 1.4.0.0a2 or newer is resolved,\nthis can be uncommented.\n\nIn the future, TaskFlow may be used for the L3 services workflow,\nand these changes will provide validation modularization for that\neffort.\n\nChange-Id: Id420983ccbceece5f4a00546941618318b9562c7\nPartially-implements: blueprint l3-svcs-vendor-validation\n'}]",26,102351,4c0ee4dc06a641abc941bcbb9b5467410c888a76,130,21,7,6659,,,0,"VPNaaS: separate out validation logic for ref impl

Modify the persistence logic for VPNaaS to separate out the
validation for the reference implmentation. This allows
providers to override/extend the validation, as needed.
Additional commits will address the separation for other
providers and for other L3 services.

In addition, the logic that sets default values for optional
attributes is also moved into separate methods to allow
providers to override the defaults used.

Only attributes that have multiple validations are considered
at this time, but this can be extended, as needed.

Currently, one UT fails due to an oslo.messaging bug that
has been fixed, but not yet released for Neutron use.
As a workaround, the affected test case has been commented
out. This test verifies that the right (only, in this case)
device driver is used for validation. Once the issue with
releasing oslo.messaging 1.4.0.0a2 or newer is resolved,
this can be uncommented.

In the future, TaskFlow may be used for the L3 services workflow,
and these changes will provide validation modularization for that
effort.

Change-Id: Id420983ccbceece5f4a00546941618318b9562c7
Partially-implements: blueprint l3-svcs-vendor-validation
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/102351/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron/db/vpn/vpn_validator.py', 'neutron/services/vpn/plugin.py', 'neutron/db/vpn/vpn_db.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py']",7,871aa4679370573f336ea3719b97d3a8e0ccf6f0,bp/l3-svcs-vendor-validation,"from neutron import context as n_ctx from neutron.db import l3_db from neutron.db.vpn import vpn_validator from neutron.extensions import vpnaasFAKE_SERVICE_ID = _uuid() FAKE_VPN_CONNECTION = { 'vpnservice_id': FAKE_SERVICE_ID } FAKE_ROUTER_ID = _uuid() FAKE_VPN_SERVICE = { 'router_id': FAKE_ROUTER_IDFAKE_ROUTER = {l3_db.EXTERNAL_GW_INFO: FAKE_ROUTER_ID} FAKE_SUBNET_ID = _uuid() IPV4 = 4 IPV6 = 6 class TestIPsecDriverValidation(base.BaseTestCase): def setUp(self): super(TestIPsecDriverValidation, self).setUp() self.l3_plugin = mock.Mock() mock.patch( 'neutron.manager.NeutronManager.get_service_plugins', return_value={constants.L3_ROUTER_NAT: self.l3_plugin}).start() self.core_plugin = mock.Mock() mock.patch('neutron.manager.NeutronManager.get_plugin', return_value=self.core_plugin).start() self.context = n_ctx.Context('some_user', 'some_tenant') self.validator = vpn_validator.VpnReferenceValidator() def test_non_public_router_for_vpn_service(self): """"""Failure test of service validate, when router missing ext. I/F."""""" self.l3_plugin.get_router.return_value = {} # No external gateway vpnservice = {'router_id': 123, 'subnet_id': 456} self.assertRaises(vpnaas.RouterIsNotExternal, self.validator.validate_vpnservice, self.context, vpnservice) def test_subnet_not_connected_for_vpn_service(self): """"""Failure test of service validate, when subnet not on router."""""" self.l3_plugin.get_router.return_value = FAKE_ROUTER self.core_plugin.get_ports.return_value = None vpnservice = {'router_id': FAKE_ROUTER_ID, 'subnet_id': FAKE_SUBNET_ID} self.assertRaises(vpnaas.SubnetIsNotConnectedToRouter, self.validator.validate_vpnservice, self.context, vpnservice) def test_validate_create_using_defaults(self): """"""Check IPSec conn. create validation using defaults. Note: MTU has a default and will always be present on create. However, the DPD settings do not have a default, so the database create method will assign default values for any missing. These defaults are provided to the validate function. """""" ipsec_sitecon = {'mtu': 1500, 'vpnservice_id': FAKE_SERVICE_ID} self.validator.validate_ipsec_site_connection( self.context, ipsec_sitecon, IPV4) expected = { 'mtu': 1500, 'vpnservice_id': FAKE_SERVICE_ID, 'dpd_action': 'hold', 'dpd_timeout': 120, 'dpd_interval': 30 } self.assertEqual(expected, ipsec_sitecon) def test_bad_dpd_settings_on_create(self): """"""Failure tests of DPD settings for IPSec conn during create."""""" ipsec_sitecon = {'mtu': 1500, 'dpd': {'interval': 100, 'timeout': 100}, 'vpnservice_id': FAKE_SERVICE_ID} self.assertRaises(vpnaas.IPsecSiteConnectionDpdIntervalValueError, self.validator.validate_ipsec_site_connection, self.context, ipsec_sitecon, IPV4) ipsec_sitecon = {'mtu': 1500, 'dpd': {'interval': 100, 'timeout': 99}, 'vpnservice_id': FAKE_SERVICE_ID} self.assertRaises(vpnaas.IPsecSiteConnectionDpdIntervalValueError, self.validator.validate_ipsec_site_connection, self.context, ipsec_sitecon, IPV4) def test_bad_dpd_settings_on_update(self): """"""Failure tests of DPD settings for IPSec conn. during update. On an update, the user may specify only some of the DPD settings. The validation will check the values provided, and will use the existing (previous) settings, for any that are not provided. Note: The MTU may not be provided, during validation and will be ignored, if that is the case. """""" previous = {'dpd_action': 'hold', 'dpd_interval': 100, 'dpd_timeout': 120} ipsec_sitecon = {'dpd': {'interval': 120}, 'vpnservice_id': FAKE_SERVICE_ID} self.assertRaises(vpnaas.IPsecSiteConnectionDpdIntervalValueError, self.validator.validate_ipsec_site_connection, self.context, ipsec_sitecon, IPV4, previous) ipsec_sitecon = {'dpd': {'timeout': 99}, 'vpnservice_id': FAKE_SERVICE_ID} self.assertRaises(vpnaas.IPsecSiteConnectionDpdIntervalValueError, self.validator.validate_ipsec_site_connection, self.context, ipsec_sitecon, IPV4, previous) def test_bad_mtu_for_ipsec_connection(self): """"""Failure test of invalid MTU values for IPSec conn create/update."""""" ip_version_limits = vpn_validator.VpnReferenceValidator.IP_MIN_MTU for version, limit in ip_version_limits.items(): ipsec_sitecon = {'mtu': limit - 1, 'vpnservice_id': FAKE_SERVICE_ID} self.assertRaises( vpnaas.IPsecSiteConnectionMtuError, self.validator.validate_ipsec_site_connection, self.context, ipsec_sitecon, version) ctxt = n_ctx.Context('', 'somebody')","from neutron import contextFAKE_VPN_CONNECTION = { 'vpnservice_id': _uuid() } FAKE_VPN_SERVICE = { 'router_id': _uuid() ctxt = context.Context('', 'somebody')",273,189
openstack%2Fhorizon~master~Iafb7a61a3547633b79da2425806b41011da69671,openstack/horizon,master,Iafb7a61a3547633b79da2425806b41011da69671,Imported Translations from Transifex,MERGED,2014-07-17 06:04:23.000000000,2014-07-17 08:31:46.000000000,2014-07-17 08:31:45.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 6610}]","[{'number': 1, 'created': '2014-07-17 06:04:23.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ebaf18b3133cf06e76644e23672237e0060b5715', 'message': 'Imported Translations from Transifex\n\nChange-Id: Iafb7a61a3547633b79da2425806b41011da69671\n'}]",0,107564,ebaf18b3133cf06e76644e23672237e0060b5715,8,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Iafb7a61a3547633b79da2425806b41011da69671
",git fetch https://review.opendev.org/openstack/horizon refs/changes/64/107564/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",17,ebaf18b3133cf06e76644e23672237e0060b5715,transifex/translations,"""POT-Creation-Date: 2014-07-16 09:23-0500\n"" ""PO-Revision-Date: 2014-07-16 14:42+0000\n""#: dashboards/project/loadbalancers/workflows.py:36 #: dashboards/project/loadbalancers/workflows.py:153#: dashboards/project/volumes/volumes/tables.py:276 #: dashboards/project/volumes/volumes/tables.py:305#: dashboards/project/instances/tables.py:815#: dashboards/project/volumes/volumes/tables.py:313#: dashboards/project/loadbalancers/workflows.py:39 #: dashboards/project/loadbalancers/workflows.py:156#: dashboards/project/volumes/volumes/tables.py:279#: dashboards/project/volumes/volumes/tables.py:219#: dashboards/project/instances/templates/instances/_instance_flavor.html:4#: dashboards/project/instances/templates/instances/_instance_flavor.html:5#: dashboards/project/loadbalancers/workflows.py:134 #: dashboards/project/loadbalancers/workflows.py:251 #: dashboards/project/loadbalancers/workflows.py:423 #: dashboards/project/loadbalancers/workflows.py:576#: dashboards/project/loadbalancers/workflows.py:460#: dashboards/project/volumes/volumes/tables.py:308#: dashboards/project/instances/tables.py:834#: dashboards/project/instances/tables.py:798#: dashboards/project/instances/tables.py:800#: dashboards/project/instances/tables.py:810#: dashboards/project/volumes/volumes/tables.py:286#: dashboards/project/volumes/volumes/tables.py:60 #: dashboards/project/volumes/volumes/tables.py:324 #: dashboards/project/volumes/volumes/tables.py:337#: dashboards/project/volumes/volumes/tables.py:362#: dashboards/project/instances/tables.py:802#: dashboards/project/instances/tables.py:805 #: dashboards/project/instances/templates/instances/_instance_flavor.html:6#: dashboards/project/volumes/volumes/tables.py:282#: dashboards/project/instances/tables.py:817#: dashboards/project/instances/tables.py:824#: dashboards/project/instances/tables.py:827#: dashboards/project/loadbalancers/workflows.py:46 #: dashboards/project/loadbalancers/workflows.py:191 #: dashboards/project/loadbalancers/workflows.py:343 #: dashboards/project/loadbalancers/workflows.py:522#: dashboards/project/loadbalancers/workflows.py:43#: dashboards/project/instances/tables.py:695 #: dashboards/project/instances/tables.py:711#: dashboards/project/instances/tables.py:706#: dashboards/project/loadbalancers/workflows.py:299#: dashboards/project/volumes/volumes/tables.py:106#: dashboards/project/loadbalancers/workflows.py:638#: dashboards/project/loadbalancers/workflows.py:700#: dashboards/project/instances/tables.py:807#: dashboards/project/loadbalancers/workflows.py:166#: dashboards/project/volumes/volumes/tables.py:177#: dashboards/project/volumes/volumes/tables.py:61#: dashboards/project/instances/tables.py:687#: dashboards/project/instances/tables.py:721#: dashboards/project/loadbalancers/workflows.py:44 #: dashboards/project/loadbalancers/workflows.py:169#: dashboards/project/loadbalancers/workflows.py:462#: dashboards/project/volumes/volumes/tables.py:89 #: dashboards/project/volumes/volumes/tables.py:108#: dashboards/project/volumes/volumes/tables.py:160#: dashboards/project/instances/tables.py:705#: dashboards/project/instances/tables.py:699 #: dashboards/project/instances/tables.py:763#: dashboards/project/instances/tables.py:698 #: dashboards/project/instances/tables.py:767#: dashboards/project/instances/tables.py:703#: dashboards/project/instances/tables.py:765#: dashboards/project/instances/tables.py:671msgid ""%s GB"" msgstr ""%s GB"" #: dashboards/project/instances/tables.py:696#: dashboards/project/instances/tables.py:697#: dashboards/project/instances/tables.py:700#: dashboards/project/instances/tables.py:701#: dashboards/project/instances/tables.py:702#: dashboards/project/instances/tables.py:704#: dashboards/project/instances/tables.py:707#: dashboards/project/instances/tables.py:708 #: dashboards/project/instances/tables.py:748#: dashboards/project/instances/tables.py:709#: dashboards/project/instances/tables.py:710#: dashboards/project/instances/tables.py:712#: dashboards/project/instances/tables.py:713#: dashboards/project/instances/tables.py:714#: dashboards/project/instances/tables.py:719#: dashboards/project/instances/tables.py:720#: dashboards/project/instances/tables.py:722#: dashboards/project/instances/tables.py:723#: dashboards/project/instances/tables.py:724#: dashboards/project/instances/tables.py:725#: dashboards/project/instances/tables.py:726#: dashboards/project/instances/tables.py:727#: dashboards/project/instances/tables.py:728#: dashboards/project/instances/tables.py:729#: dashboards/project/instances/tables.py:730#: dashboards/project/instances/tables.py:731#: dashboards/project/instances/tables.py:732#: dashboards/project/instances/tables.py:733#: dashboards/project/instances/tables.py:734#: dashboards/project/instances/tables.py:735#: dashboards/project/instances/tables.py:736#: dashboards/project/instances/tables.py:737#: dashboards/project/instances/tables.py:738 #: dashboards/project/instances/tables.py:740#: dashboards/project/instances/tables.py:739#: dashboards/project/instances/tables.py:741#: dashboards/project/instances/tables.py:742#: dashboards/project/instances/tables.py:743#: dashboards/project/instances/tables.py:744#: dashboards/project/instances/tables.py:745#: dashboards/project/instances/tables.py:746#: dashboards/project/instances/tables.py:747#: dashboards/project/instances/tables.py:749#: dashboards/project/instances/tables.py:750#: dashboards/project/instances/tables.py:751#: dashboards/project/instances/tables.py:752#: dashboards/project/instances/tables.py:753#: dashboards/project/instances/tables.py:754#: dashboards/project/instances/tables.py:755#: dashboards/project/instances/tables.py:756#: dashboards/project/instances/tables.py:760#: dashboards/project/instances/tables.py:761#: dashboards/project/instances/tables.py:762#: dashboards/project/instances/tables.py:764#: dashboards/project/instances/tables.py:766#: dashboards/project/instances/tables.py:768#: dashboards/project/instances/tables.py:769#: dashboards/project/volumes/volumes/tables.py:311#: dashboards/project/volumes/volumes/tables.py:59 #: dashboards/project/volumes/volumes/tables.py:336#: dashboards/project/instances/templates/instances/_instance_flavor.html:8#: dashboards/project/loadbalancers/workflows.py:45#: dashboards/project/loadbalancers/workflows.py:171#: dashboards/project/loadbalancers/workflows.py:178#: dashboards/project/loadbalancers/workflows.py:179#: dashboards/project/loadbalancers/workflows.py:187#: dashboards/project/loadbalancers/workflows.py:188#: dashboards/project/loadbalancers/workflows.py:356#: dashboards/project/loadbalancers/workflows.py:219#: dashboards/project/loadbalancers/workflows.py:330#: dashboards/project/loadbalancers/workflows.py:471#: dashboards/project/loadbalancers/workflows.py:472#: dashboards/project/loadbalancers/workflows.py:476#: dashboards/project/loadbalancers/workflows.py:477#: dashboards/project/loadbalancers/workflows.py:481#: dashboards/project/loadbalancers/workflows.py:482#: dashboards/project/loadbalancers/workflows.py:133#: dashboards/project/loadbalancers/workflows.py:250#: dashboards/project/loadbalancers/workflows.py:422#: dashboards/project/loadbalancers/workflows.py:575#: dashboards/project/loadbalancers/workflows.py:593 #: dashboards/project/loadbalancers/workflows.py:655#: dashboards/project/loadbalancers/workflows.py:637#: dashboards/project/loadbalancers/workflows.py:699#: dashboards/project/loadbalancers/workflows.py:42#: dashboards/project/loadbalancers/workflows.py:165 #: dashboards/project/loadbalancers/workflows.py:337#: dashboards/project/loadbalancers/workflows.py:54#: dashboards/project/loadbalancers/workflows.py:59#: dashboards/project/loadbalancers/workflows.py:66 #: dashboards/project/loadbalancers/workflows.py:199#: dashboards/project/loadbalancers/workflows.py:70#: dashboards/project/loadbalancers/workflows.py:84#: dashboards/project/loadbalancers/workflows.py:98#: dashboards/project/loadbalancers/workflows.py:101#: dashboards/project/loadbalancers/workflows.py:103#: dashboards/project/loadbalancers/workflows.py:109#: dashboards/project/loadbalancers/workflows.py:111#: dashboards/project/loadbalancers/workflows.py:135#: dashboards/project/loadbalancers/workflows.py:136#: dashboards/project/loadbalancers/workflows.py:158#: dashboards/project/loadbalancers/workflows.py:196#: dashboards/project/loadbalancers/workflows.py:203#: dashboards/project/loadbalancers/workflows.py:209#: dashboards/project/loadbalancers/workflows.py:224#: dashboards/project/loadbalancers/workflows.py:226#: dashboards/project/loadbalancers/workflows.py:252#: dashboards/project/loadbalancers/workflows.py:253#: dashboards/project/loadbalancers/workflows.py:266#: dashboards/project/loadbalancers/workflows.py:276#: dashboards/project/loadbalancers/workflows.py:301 msgid ""Member Source"" msgstr """" #: dashboards/project/loadbalancers/workflows.py:302 msgid ""Select from active instances"" msgstr """" #: dashboards/project/loadbalancers/workflows.py:303 #: dashboards/project/loadbalancers/workflows.py:320 msgid ""Specify member IP address"" msgstr """" #: dashboards/project/loadbalancers/workflows.py:310 #: dashboards/project/loadbalancers/workflows.py:316#: dashboards/project/loadbalancers/workflows.py:318#: dashboards/project/loadbalancers/workflows.py:319 #: dashboards/project/loadbalancers/workflows.py:325 msgid ""Member address"" msgstr """" #: dashboards/project/loadbalancers/workflows.py:331#: dashboards/project/loadbalancers/workflows.py:338#: dashboards/project/loadbalancers/workflows.py:349#: dashboards/project/loadbalancers/workflows.py:369#: dashboards/project/loadbalancers/workflows.py:373#: dashboards/project/loadbalancers/workflows.py:389 msgid ""At least one member must be specified"" msgstr ""At least one member must be specified"" #: dashboards/project/loadbalancers/workflows.py:393 msgid ""Member IP address must be specified"" msgstr """" #: dashboards/project/loadbalancers/workflows.py:398#: dashboards/project/loadbalancers/workflows.py:400#: dashboards/project/loadbalancers/workflows.py:424#: dashboards/project/loadbalancers/workflows.py:425 msgid ""Unable to add member(s)"" msgstr """" #: dashboards/project/loadbalancers/workflows.py:461#: dashboards/project/loadbalancers/workflows.py:463#: dashboards/project/loadbalancers/workflows.py:464#: dashboards/project/loadbalancers/workflows.py:487#: dashboards/project/loadbalancers/workflows.py:488 #: dashboards/project/loadbalancers/workflows.py:493 #: dashboards/project/loadbalancers/workflows.py:494#: dashboards/project/loadbalancers/workflows.py:489#: dashboards/project/loadbalancers/workflows.py:500 #: dashboards/project/loadbalancers/workflows.py:504 #: dashboards/project/loadbalancers/workflows.py:505#: dashboards/project/loadbalancers/workflows.py:512 #: dashboards/project/loadbalancers/workflows.py:519 #: dashboards/project/loadbalancers/workflows.py:520#: dashboards/project/loadbalancers/workflows.py:513#: dashboards/project/loadbalancers/workflows.py:538#: dashboards/project/loadbalancers/workflows.py:541#: dashboards/project/loadbalancers/workflows.py:544#: dashboards/project/loadbalancers/workflows.py:551#: dashboards/project/loadbalancers/workflows.py:553#: dashboards/project/loadbalancers/workflows.py:577#: dashboards/project/loadbalancers/workflows.py:578#: dashboards/project/loadbalancers/workflows.py:588#: dashboards/project/loadbalancers/workflows.py:599#: dashboards/project/loadbalancers/workflows.py:602 #: dashboards/project/loadbalancers/workflows.py:665#: dashboards/project/loadbalancers/workflows.py:613 #: dashboards/project/loadbalancers/workflows.py:674#: dashboards/project/loadbalancers/workflows.py:619 #: dashboards/project/loadbalancers/workflows.py:680#: dashboards/project/loadbalancers/workflows.py:621#: dashboards/project/loadbalancers/workflows.py:639#: dashboards/project/loadbalancers/workflows.py:640 #: dashboards/project/loadbalancers/workflows.py:650#: dashboards/project/loadbalancers/workflows.py:662#: dashboards/project/loadbalancers/workflows.py:682#: dashboards/project/loadbalancers/workflows.py:701#: dashboards/project/loadbalancers/workflows.py:702 #: dashboards/project/loadbalancers/workflows.py:712#: dashboards/project/volumes/volumes/tables.py:383#: dashboards/project/volumes/volumes/tables.py:120#: dashboards/project/volumes/volumes/tables.py:195#: dashboards/project/volumes/volumes/tables.py:39#: dashboards/project/volumes/volumes/tables.py:76#: dashboards/project/volumes/volumes/tables.py:137#: dashboards/project/volumes/volumes/tables.py:232#: dashboards/project/volumes/volumes/tables.py:250#: dashboards/project/volumes/volumes/tables.py:315#: dashboards/project/volumes/volumes/tables.py:318#: dashboards/project/volumes/volumes/tables.py:334#: dashboards/project/volumes/volumes/tables.py:335#: dashboards/project/volumes/volumes/tables.py:364#: dashboards/project/volumes/volumes/tables.py:373","""POT-Creation-Date: 2014-07-15 07:11-0500\n"" ""PO-Revision-Date: 2014-07-15 11:04+0000\n""#: dashboards/project/loadbalancers/workflows.py:31 #: dashboards/project/loadbalancers/workflows.py:148#: dashboards/project/volumes/volumes/tables.py:266 #: dashboards/project/volumes/volumes/tables.py:295#: dashboards/project/instances/tables.py:808#: dashboards/project/volumes/volumes/tables.py:303#: dashboards/project/loadbalancers/workflows.py:34 #: dashboards/project/loadbalancers/workflows.py:151#: dashboards/project/volumes/volumes/tables.py:269#: dashboards/project/volumes/volumes/tables.py:209#: dashboards/project/loadbalancers/workflows.py:129 #: dashboards/project/loadbalancers/workflows.py:246 #: dashboards/project/loadbalancers/workflows.py:388 #: dashboards/project/loadbalancers/workflows.py:529#: dashboards/project/loadbalancers/workflows.py:413#: dashboards/project/volumes/volumes/tables.py:298#: dashboards/project/instances/tables.py:827#: dashboards/project/instances/tables.py:791#: dashboards/project/instances/tables.py:793#: dashboards/project/instances/tables.py:803#: dashboards/project/volumes/volumes/tables.py:276#: dashboards/project/volumes/volumes/tables.py:59 #: dashboards/project/volumes/volumes/tables.py:314 #: dashboards/project/volumes/volumes/tables.py:327#: dashboards/project/volumes/volumes/tables.py:352#: dashboards/project/instances/tables.py:795#: dashboards/project/instances/tables.py:798#: dashboards/project/volumes/volumes/tables.py:272#: dashboards/project/instances/tables.py:810#: dashboards/project/instances/tables.py:817#: dashboards/project/instances/tables.py:820#: dashboards/project/loadbalancers/workflows.py:41 #: dashboards/project/loadbalancers/workflows.py:186 #: dashboards/project/loadbalancers/workflows.py:317 #: dashboards/project/loadbalancers/workflows.py:475#: dashboards/project/loadbalancers/workflows.py:38#: dashboards/project/instances/tables.py:688 #: dashboards/project/instances/tables.py:704#: dashboards/project/instances/tables.py:699#: dashboards/project/loadbalancers/workflows.py:294#: dashboards/project/volumes/volumes/tables.py:100#: dashboards/project/loadbalancers/workflows.py:591#: dashboards/project/loadbalancers/workflows.py:653#: dashboards/project/instances/tables.py:800#: dashboards/project/loadbalancers/workflows.py:161#: dashboards/project/volumes/volumes/tables.py:167#: dashboards/project/volumes/volumes/tables.py:60#: dashboards/project/instances/tables.py:673#: dashboards/project/instances/tables.py:714#: dashboards/project/loadbalancers/workflows.py:39 #: dashboards/project/loadbalancers/workflows.py:164#: dashboards/project/loadbalancers/workflows.py:415#: dashboards/project/volumes/volumes/tables.py:88 #: dashboards/project/volumes/volumes/tables.py:102#: dashboards/project/volumes/volumes/tables.py:150#: dashboards/project/instances/tables.py:698#: dashboards/project/instances/tables.py:692 #: dashboards/project/instances/tables.py:756#: dashboards/project/instances/tables.py:691 #: dashboards/project/instances/tables.py:760#: dashboards/project/instances/tables.py:696#: dashboards/project/instances/tables.py:758#: dashboards/project/instances/tables.py:666msgid ""%(name)s | %(RAM)s RAM | %(VCPU)s VCPU | %(disk)s Disk"" msgstr ""%(name)s | %(RAM)s RAM | %(VCPU)s VCPU | %(disk)s Disk"" #: dashboards/project/instances/tables.py:689#: dashboards/project/instances/tables.py:690#: dashboards/project/instances/tables.py:693#: dashboards/project/instances/tables.py:694#: dashboards/project/instances/tables.py:695#: dashboards/project/instances/tables.py:697#: dashboards/project/instances/tables.py:700#: dashboards/project/instances/tables.py:701 #: dashboards/project/instances/tables.py:741#: dashboards/project/instances/tables.py:702#: dashboards/project/instances/tables.py:703#: dashboards/project/instances/tables.py:705#: dashboards/project/instances/tables.py:706#: dashboards/project/instances/tables.py:707#: dashboards/project/instances/tables.py:712#: dashboards/project/instances/tables.py:713#: dashboards/project/instances/tables.py:715#: dashboards/project/instances/tables.py:716#: dashboards/project/instances/tables.py:717#: dashboards/project/instances/tables.py:718#: dashboards/project/instances/tables.py:719#: dashboards/project/instances/tables.py:720#: dashboards/project/instances/tables.py:721#: dashboards/project/instances/tables.py:722#: dashboards/project/instances/tables.py:723#: dashboards/project/instances/tables.py:724#: dashboards/project/instances/tables.py:725#: dashboards/project/instances/tables.py:726#: dashboards/project/instances/tables.py:727#: dashboards/project/instances/tables.py:728#: dashboards/project/instances/tables.py:729#: dashboards/project/instances/tables.py:730#: dashboards/project/instances/tables.py:731 #: dashboards/project/instances/tables.py:733#: dashboards/project/instances/tables.py:732#: dashboards/project/instances/tables.py:734#: dashboards/project/instances/tables.py:735#: dashboards/project/instances/tables.py:736#: dashboards/project/instances/tables.py:737#: dashboards/project/instances/tables.py:738#: dashboards/project/instances/tables.py:739#: dashboards/project/instances/tables.py:740#: dashboards/project/instances/tables.py:742#: dashboards/project/instances/tables.py:743#: dashboards/project/instances/tables.py:744#: dashboards/project/instances/tables.py:745#: dashboards/project/instances/tables.py:746#: dashboards/project/instances/tables.py:747#: dashboards/project/instances/tables.py:748#: dashboards/project/instances/tables.py:749#: dashboards/project/instances/tables.py:753#: dashboards/project/instances/tables.py:754#: dashboards/project/instances/tables.py:755#: dashboards/project/instances/tables.py:757#: dashboards/project/instances/tables.py:759#: dashboards/project/instances/tables.py:761#: dashboards/project/instances/tables.py:762#: dashboards/project/volumes/volumes/tables.py:301#: dashboards/project/volumes/volumes/tables.py:58 #: dashboards/project/volumes/volumes/tables.py:326#: dashboards/project/loadbalancers/workflows.py:40#: dashboards/project/loadbalancers/workflows.py:166#: dashboards/project/loadbalancers/workflows.py:173#: dashboards/project/loadbalancers/workflows.py:174#: dashboards/project/loadbalancers/workflows.py:182#: dashboards/project/loadbalancers/workflows.py:183#: dashboards/project/loadbalancers/workflows.py:330#: dashboards/project/loadbalancers/workflows.py:214#: dashboards/project/loadbalancers/workflows.py:304#: dashboards/project/loadbalancers/workflows.py:424#: dashboards/project/loadbalancers/workflows.py:425#: dashboards/project/loadbalancers/workflows.py:429#: dashboards/project/loadbalancers/workflows.py:430#: dashboards/project/loadbalancers/workflows.py:434#: dashboards/project/loadbalancers/workflows.py:435#: dashboards/project/loadbalancers/workflows.py:128#: dashboards/project/loadbalancers/workflows.py:245#: dashboards/project/loadbalancers/workflows.py:387#: dashboards/project/loadbalancers/workflows.py:528#: dashboards/project/loadbalancers/workflows.py:546 #: dashboards/project/loadbalancers/workflows.py:608#: dashboards/project/loadbalancers/workflows.py:590#: dashboards/project/loadbalancers/workflows.py:652#: dashboards/project/loadbalancers/workflows.py:37#: dashboards/project/loadbalancers/workflows.py:160 #: dashboards/project/loadbalancers/workflows.py:311#: dashboards/project/loadbalancers/workflows.py:49#: dashboards/project/loadbalancers/workflows.py:54#: dashboards/project/loadbalancers/workflows.py:61 #: dashboards/project/loadbalancers/workflows.py:194#: dashboards/project/loadbalancers/workflows.py:65#: dashboards/project/loadbalancers/workflows.py:79#: dashboards/project/loadbalancers/workflows.py:93#: dashboards/project/loadbalancers/workflows.py:96#: dashboards/project/loadbalancers/workflows.py:98#: dashboards/project/loadbalancers/workflows.py:104#: dashboards/project/loadbalancers/workflows.py:106#: dashboards/project/loadbalancers/workflows.py:130#: dashboards/project/loadbalancers/workflows.py:131#: dashboards/project/loadbalancers/workflows.py:153#: dashboards/project/loadbalancers/workflows.py:191#: dashboards/project/loadbalancers/workflows.py:198#: dashboards/project/loadbalancers/workflows.py:204#: dashboards/project/loadbalancers/workflows.py:219#: dashboards/project/loadbalancers/workflows.py:221#: dashboards/project/loadbalancers/workflows.py:247#: dashboards/project/loadbalancers/workflows.py:248#: dashboards/project/loadbalancers/workflows.py:261#: dashboards/project/loadbalancers/workflows.py:271#: dashboards/project/loadbalancers/workflows.py:296#: dashboards/project/loadbalancers/workflows.py:301 msgid ""At least one member must be specified"" msgstr ""At least one member must be specified"" #: dashboards/project/loadbalancers/workflows.py:302 #: dashboards/project/loadbalancers/workflows.py:350#: dashboards/project/loadbalancers/workflows.py:305#: dashboards/project/loadbalancers/workflows.py:312#: dashboards/project/loadbalancers/workflows.py:323#: dashboards/project/loadbalancers/workflows.py:343#: dashboards/project/loadbalancers/workflows.py:347#: dashboards/project/loadbalancers/workflows.py:363#: dashboards/project/loadbalancers/workflows.py:365#: dashboards/project/loadbalancers/workflows.py:389#: dashboards/project/loadbalancers/workflows.py:390 msgid ""Unable to add member(s)."" msgstr ""Unable to add member(s)."" #: dashboards/project/loadbalancers/workflows.py:414#: dashboards/project/loadbalancers/workflows.py:416#: dashboards/project/loadbalancers/workflows.py:417#: dashboards/project/loadbalancers/workflows.py:440#: dashboards/project/loadbalancers/workflows.py:441 #: dashboards/project/loadbalancers/workflows.py:446 #: dashboards/project/loadbalancers/workflows.py:447#: dashboards/project/loadbalancers/workflows.py:442#: dashboards/project/loadbalancers/workflows.py:453 #: dashboards/project/loadbalancers/workflows.py:457 #: dashboards/project/loadbalancers/workflows.py:458#: dashboards/project/loadbalancers/workflows.py:465 #: dashboards/project/loadbalancers/workflows.py:472 #: dashboards/project/loadbalancers/workflows.py:473#: dashboards/project/loadbalancers/workflows.py:466#: dashboards/project/loadbalancers/workflows.py:491#: dashboards/project/loadbalancers/workflows.py:494#: dashboards/project/loadbalancers/workflows.py:497#: dashboards/project/loadbalancers/workflows.py:504#: dashboards/project/loadbalancers/workflows.py:506#: dashboards/project/loadbalancers/workflows.py:530#: dashboards/project/loadbalancers/workflows.py:531#: dashboards/project/loadbalancers/workflows.py:541#: dashboards/project/loadbalancers/workflows.py:552#: dashboards/project/loadbalancers/workflows.py:555 #: dashboards/project/loadbalancers/workflows.py:618#: dashboards/project/loadbalancers/workflows.py:566 #: dashboards/project/loadbalancers/workflows.py:627#: dashboards/project/loadbalancers/workflows.py:572 #: dashboards/project/loadbalancers/workflows.py:633#: dashboards/project/loadbalancers/workflows.py:574#: dashboards/project/loadbalancers/workflows.py:592#: dashboards/project/loadbalancers/workflows.py:593 #: dashboards/project/loadbalancers/workflows.py:603#: dashboards/project/loadbalancers/workflows.py:615#: dashboards/project/loadbalancers/workflows.py:635#: dashboards/project/loadbalancers/workflows.py:654#: dashboards/project/loadbalancers/workflows.py:655 #: dashboards/project/loadbalancers/workflows.py:665#: dashboards/project/volumes/volumes/tables.py:373#: dashboards/project/volumes/volumes/tables.py:110#: dashboards/project/volumes/volumes/tables.py:185#: dashboards/project/volumes/volumes/tables.py:38#: dashboards/project/volumes/volumes/tables.py:75#: dashboards/project/volumes/volumes/tables.py:127#: dashboards/project/volumes/volumes/tables.py:222#: dashboards/project/volumes/volumes/tables.py:240#: dashboards/project/volumes/volumes/tables.py:305#: dashboards/project/volumes/volumes/tables.py:308#: dashboards/project/volumes/volumes/tables.py:324#: dashboards/project/volumes/volumes/tables.py:325#: dashboards/project/volumes/volumes/tables.py:354#: dashboards/project/volumes/volumes/tables.py:363",4637,4195
openstack%2Fneutron~master~I52c17ea8e6ecb0beb2511e03ffbd8c36dd7c1d66,openstack/neutron,master,I52c17ea8e6ecb0beb2511e03ffbd8c36dd7c1d66,Shamelessly removing commented print line,MERGED,2014-07-15 16:39:37.000000000,2014-07-17 08:31:43.000000000,2014-07-17 00:39:17.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8279}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-15 16:39:37.000000000', 'files': ['neutron/tests/unit/_test_extension_portbindings.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d21572de8cebd3b2f910487f9b010cc33b053ff1', 'message': 'Shamelessly removing commented print line\n\nThis is not supposed to be there.\n\nChange-Id: I52c17ea8e6ecb0beb2511e03ffbd8c36dd7c1d66\n'}]",0,107103,d21572de8cebd3b2f910487f9b010cc33b053ff1,33,21,1,748,,,0,"Shamelessly removing commented print line

This is not supposed to be there.

Change-Id: I52c17ea8e6ecb0beb2511e03ffbd8c36dd7c1d66
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/107103/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/_test_extension_portbindings.py'],1,d21572de8cebd3b2f910487f9b010cc33b053ff1,one-liner,," # print ""(1) %s"" % port",0,1
openstack%2Fnova~master~I570d91e892a6e1ff4b3cdb8cf81acc483649835e,openstack/nova,master,I570d91e892a6e1ff4b3cdb8cf81acc483649835e,Retry db.api.instance_destroy on deadlock,MERGED,2014-07-15 12:27:12.000000000,2014-07-17 08:31:35.000000000,2014-07-17 08:31:32.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 10614}]","[{'number': 1, 'created': '2014-07-15 12:27:12.000000000', 'files': ['nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/44f8f1e93f21275311d1eab0c93a2834395c2365', 'message': 'Retry db.api.instance_destroy on deadlock\n\nUpdate the instance_destroy method of the sqlalchemy db API to retry if\nit fails because of a deadlock. The decorator that handles this was\nintroduced in I0293c62d2dd5ac036445bc639cabbd05ba016e83.\n\nThis patch does not include a unit test for this bug, as deadlocks are\nvery hard to reproduce.\n\nChange-Id: I570d91e892a6e1ff4b3cdb8cf81acc483649835e\nCloses-Bug: #1342086\n'}]",0,107025,44f8f1e93f21275311d1eab0c93a2834395c2365,16,9,1,1849,,,0,"Retry db.api.instance_destroy on deadlock

Update the instance_destroy method of the sqlalchemy db API to retry if
it fails because of a deadlock. The decorator that handles this was
introduced in I0293c62d2dd5ac036445bc639cabbd05ba016e83.

This patch does not include a unit test for this bug, as deadlocks are
very hard to reproduce.

Change-Id: I570d91e892a6e1ff4b3cdb8cf81acc483649835e
Closes-Bug: #1342086
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/107025/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,44f8f1e93f21275311d1eab0c93a2834395c2365,bug/1342086,@_retry_on_deadlock,,1,0
openstack%2Fsahara~master~Ied0ff893b329b3f1fbe01518f9d77b33d734b9c1,openstack/sahara,master,Ied0ff893b329b3f1fbe01518f9d77b33d734b9c1,Switched Sahara unit tests base class to oslotest,MERGED,2014-07-08 19:28:01.000000000,2014-07-17 08:29:32.000000000,2014-07-17 08:29:32.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-07-08 19:28:01.000000000', 'files': ['sahara/tests/unit/base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/407f6fc302be239db04e78d153531d1760869952', 'message': 'Switched Sahara unit tests base class to oslotest\n\nImplements blueprint: oslotest\n\nChange-Id: Ied0ff893b329b3f1fbe01518f9d77b33d734b9c1\n'}]",1,105564,407f6fc302be239db04e78d153531d1760869952,25,8,1,8411,,,0,"Switched Sahara unit tests base class to oslotest

Implements blueprint: oslotest

Change-Id: Ied0ff893b329b3f1fbe01518f9d77b33d734b9c1
",git fetch https://review.opendev.org/openstack/sahara refs/changes/64/105564/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/unit/base.py'],1,407f6fc302be239db04e78d153531d1760869952,bp/oslotest,from oslotest import baseclass SaharaTestCase(base.BaseTestCase):,import fixturesimport testtoolsclass SaharaTestCase(testtools.TestCase): self.useFixture(fixtures.FakeLogger('sahara')),2,4
openstack%2Fceilometer~master~Ia313c98b7cccf0e8aed4fb933292bd7e6141b801,openstack/ceilometer,master,Ia313c98b7cccf0e8aed4fb933292bd7e6141b801,Use hmac.compare_digest to compare signature,MERGED,2014-06-23 15:21:03.000000000,2014-07-17 08:29:30.000000000,2014-07-17 08:29:29.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 7473}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 8871}, {'_account_id': 9562}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-23 15:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/737e3f73366fb583f15a8fa68ec23cd6f63d18ec', 'message': ""Use hmac.compare_digest to compare signature\n\nhmac.compare_digest must be used to compare sample\nsignature to avoid timing-attack.\n\nWe also provide a best-effort version of hmac.compare_digest\nfor python version that doesn't have the C version.\n\nCloses bug #1332390\n\nChange-Id: Ia313c98b7cccf0e8aed4fb933292bd7e6141b801\n""}, {'number': 2, 'created': '2014-06-23 15:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/581e1087e9b616821ba58ddd9ac96f6dfd28d036', 'message': ""Use hmac.compare_digest to compare signature\n\nhmac.compare_digest must be used to compare sample\nsignature to avoid timing-attack.\n\nWe also provide a best-effort version of hmac.compare_digest\nfor python version that doesn't have the C version.\n\nCloses bug #1332390\n\nChange-Id: Ia313c98b7cccf0e8aed4fb933292bd7e6141b801\n""}, {'number': 3, 'created': '2014-06-24 06:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/633c8a923349eea825c4ccdf524c8b7d8d5b2f62', 'message': ""Use hmac.compare_digest to compare signature\n\nhmac.compare_digest must be used to compare sample\nsignature to avoid timing-attack.\n\nWe also provide a best-effort version of hmac.compare_digest\nfor python version that doesn't have the C version.\n\nCloses bug #1332390\n\nChange-Id: Ia313c98b7cccf0e8aed4fb933292bd7e6141b801\n""}, {'number': 4, 'created': '2014-06-24 07:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5aa3fe2669925e6bbb07f3147b083981797acc6d', 'message': ""Use hmac.compare_digest to compare signature\n\nhmac.compare_digest must be used to compare sample\nsignature to avoid timing-attack.\n\nWe also provide a best-effort version of hmac.compare_digest\nfor python version that doesn't have the C version.\n\nCloses bug #1332390\n\nChange-Id: Ia313c98b7cccf0e8aed4fb933292bd7e6141b801\n""}, {'number': 5, 'created': '2014-07-17 06:13:54.000000000', 'files': ['ceilometer/publisher/utils.py', 'ceilometer/tests/publisher/test_utils.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8b4e4987a5a1ab82f302abd470452d6eb5671320', 'message': ""Use hmac.compare_digest to compare signature\n\nhmac.compare_digest must be used to compare sample\nsignature to avoid timing-attack.\n\nWe also provide a best-effort version of hmac.compare_digest\nfor python version that doesn't have the C version.\n\nCloses bug #1332390\n\nChange-Id: Ia313c98b7cccf0e8aed4fb933292bd7e6141b801\n""}]",0,101934,8b4e4987a5a1ab82f302abd470452d6eb5671320,50,12,5,2813,,,0,"Use hmac.compare_digest to compare signature

hmac.compare_digest must be used to compare sample
signature to avoid timing-attack.

We also provide a best-effort version of hmac.compare_digest
for python version that doesn't have the C version.

Closes bug #1332390

Change-Id: Ia313c98b7cccf0e8aed4fb933292bd7e6141b801
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/34/101934/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/publisher/utils.py', 'ceilometer/tests/publisher/test_utils.py']",2,737e3f73366fb583f15a8fa68ec23cd6f63d18ec,bug/1332390," def test_besteffort_compare_digest(self): hash1 = ""f5ac3fe42b80b80f979825d177191bc5"" hash2 = ""f5ac3fe42b80b80f979825d177191bc5"" hash3 = ""1dece7821bf3fd70fe1309eaa37d52a2"" hash4 = b""f5ac3fe42b80b80f979825d177191bc5"" hash5 = b""f5ac3fe42b80b80f979825d177191bc5"" hash6 = b""1dece7821bf3fd70fe1309eaa37d52a2"" self.assertTrue(utils.besteffort_compare_digest(hash1, hash2)) self.assertFalse(utils.besteffort_compare_digest(hash1, hash3)) self.assertTrue(utils.besteffort_compare_digest(hash4, hash5)) self.assertFalse(utils.besteffort_compare_digest(hash4, hash6))",,47,1
openstack%2Fdevstack-gate~master~Ic5b2b7ba8fe44bdf9a1648f68a9677ad1ab788d9,openstack/devstack-gate,master,Ic5b2b7ba8fe44bdf9a1648f68a9677ad1ab788d9,move setup_localrc to functions.sh,ABANDONED,2014-07-07 14:44:45.000000000,2014-07-17 08:24:15.000000000,,"[{'_account_id': 3}, {'_account_id': 5803}]","[{'number': 1, 'created': '2014-07-07 14:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/9ee1dbc4dbb964595a59b02077ed0a031db6b08a', 'message': ""move setup_localrc to functions.sh\n\n* Have the devstack-vm-gate.sh to be able to call functions\n  from the functions.sh.\n* allow setup_localrc to be called from a different script,\n  without executing the full devstack-vm-gate.sh.\n\nNOTE: setup_localrc will be modified to behave differently on 'primary'\nand 'sub' nodes, in multi-node setup.\n\nChange-Id: Ic5b2b7ba8fe44bdf9a1648f68a9677ad1ab788d9\n""}, {'number': 2, 'created': '2014-07-07 16:55:57.000000000', 'files': ['devstack-vm-gate.sh', 'functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8255e5e3415cbbf60e0b5fbb91e5f22b16f08eec', 'message': ""move setup_localrc to functions.sh\n\n* Have the devstack-vm-gate.sh to be able to call functions\n  from the functions.sh.\n* allow setup_localrc to be called from a different script,\n  without executing the full devstack-vm-gate.sh.\n\nNOTE: setup_localrc will be modified to behave differently on 'primary'\nand 'sub' nodes, in multi-node setup.\n\nChange-Id: Ic5b2b7ba8fe44bdf9a1648f68a9677ad1ab788d9\n""}]",0,105194,8255e5e3415cbbf60e0b5fbb91e5f22b16f08eec,10,2,2,5803,,,0,"move setup_localrc to functions.sh

* Have the devstack-vm-gate.sh to be able to call functions
  from the functions.sh.
* allow setup_localrc to be called from a different script,
  without executing the full devstack-vm-gate.sh.

NOTE: setup_localrc will be modified to behave differently on 'primary'
and 'sub' nodes, in multi-node setup.

Change-Id: Ic5b2b7ba8fe44bdf9a1648f68a9677ad1ab788d9
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/94/105194/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-gate.sh', 'functions.sh']",2,9ee1dbc4dbb964595a59b02077ed0a031db6b08a,move_localrc_func," # NOTE(afazekas): We should switch to localconf after the juno release function setup_localrc() { LOCALRC_OLDNEW=$1; LOCALRC_BRANCH=$2; # Allow calling context to pre-populate the localrc file # with additional values if [[ -z $KEEP_LOCALRC ]] ; then rm -f localrc fi MY_ENABLED_SERVICES=`cd $BASE/new/devstack-gate && ./test-matrix.py -b $LOCALRC_BRANCH -f $DEVSTACK_GATE_FEATURE_MATRIX` # Allow optional injection of ENABLED_SERVICES from the calling context if [[ ! -z $ENABLED_SERVICES ]] ; then MY_ENABLED_SERVICES+=,$ENABLED_SERVICES fi # the exercises we *don't* want to test on for devstack SKIP_EXERCISES=boot_from_volume,bundle,client-env,euca if [[ ""$DEVSTACK_GATE_NEUTRON"" -eq ""1"" ]]; then echo ""Q_USE_DEBUG_COMMAND=True"" >>localrc echo ""NETWORK_GATEWAY=10.1.0.1"" >>localrc fi if [[ ""$LOCALRC_BRANCH"" == ""stable/havana"" ]]; then # we don't want to enable services for grenade that don't have upgrade support # otherwise they can break grenade, especially when they are projects like # ceilometer which inject code in other projects if [[ ""$DEVSTACK_GATE_GRENADE"" -eq ""1"" ]]; then SKIP_EXERCISES=${SKIP_EXERCISES},swift,client-args fi fi cat <<EOF >>localrc DEST=$BASE/$LOCALRC_OLDNEW ACTIVE_TIMEOUT=90 BOOT_TIMEOUT=90 ASSOCIATE_TIMEOUT=60 TERMINATE_TIMEOUT=60 MYSQL_PASSWORD=secret DATABASE_PASSWORD=secret RABBIT_PASSWORD=secret ADMIN_PASSWORD=secret SERVICE_PASSWORD=secret SERVICE_TOKEN=111222333444 SWIFT_HASH=1234123412341234 ROOTSLEEP=0 ERROR_ON_CLONE=True ENABLED_SERVICES=$MY_ENABLED_SERVICES SKIP_EXERCISES=$SKIP_EXERCISES SERVICE_HOST=127.0.0.1 # Screen console logs will capture service logs. SYSLOG=False SCREEN_LOGDIR=$BASE/$LOCALRC_OLDNEW/screen-logs LOGFILE=$BASE/$LOCALRC_OLDNEW/devstacklog.txt VERBOSE=True FIXED_RANGE=10.1.0.0/20 FIXED_NETWORK_SIZE=4096 VIRT_DRIVER=$DEVSTACK_GATE_VIRT_DRIVER SWIFT_REPLICAS=1 LOG_COLOR=False PIP_USE_MIRRORS=False USE_GET_PIP=1 # Don't reset the requirements.txt files after g-r updates UNDO_REQUIREMENTS=False CINDER_PERIODIC_INTERVAL=10 export OS_NO_CACHE=True EOF if [[ ""$DEVSTACK_CINDER_SECURE_DELETE"" -eq ""0"" ]]; then echo ""CINDER_SECURE_DELETE=False"" >>localrc fi if [[ ""$DEVSTACK_GATE_TEMPEST_HEAT_SLOW"" -eq ""1"" ]]; then echo ""HEAT_CREATE_TEST_IMAGE=False"" >>localrc # Use Fedora 20 for heat test image, it has heat-cfntools pre-installed echo ""HEAT_FETCHED_TEST_IMAGE=Fedora-i386-20-20131211.1-sda"" >>localrc fi if [[ ""$DEVSTACK_GATE_VIRT_DRIVER"" == ""openvz"" ]]; then echo ""SKIP_EXERCISES=${SKIP_EXERCISES},volumes"" >>localrc echo ""DEFAULT_INSTANCE_TYPE=m1.small"" >>localrc echo ""DEFAULT_INSTANCE_USER=root"" >>localrc echo ""DEFAULT_INSTANCE_TYPE=m1.small"" >>exerciserc echo ""DEFAULT_INSTANCE_USER=root"" >>exerciserc fi if [[ ""$DEVSTACK_GATE_VIRT_DRIVER"" == ""ironic"" ]]; then echo ""VIRT_DRIVER=ironic"" >>localrc echo ""IRONIC_BAREMETAL_BASIC_OPS=True"" >>localrc echo ""IRONIC_VM_EPHEMERAL_DISK=1"" >>localrc echo ""IRONIC_VM_LOG_DIR=$BASE/$LOCALRC_OLDNEW/ironic-bm-logs"" >>localrc echo ""DEFAULT_INSTANCE_TYPE=baremetal"" >>localrc fi if [[ ""$DEVSTACK_GATE_VIRT_DRIVER"" == ""xenapi"" ]]; then if [ ! $DEVSTACK_GATE_XENAPI_DOM0_IP -o ! $DEVSTACK_GATE_XENAPI_DOMU_IP -o ! $DEVSTACK_GATE_XENAPI_PASSWORD ]; then echo ""XenAPI must have DEVSTACK_GATE_XENAPI_DOM0_IP, DEVSTACK_GATE_XENAPI_DOMU_IP and DEVSTACK_GATE_XENAPI_PASSWORD all set"" exit 1 fi cat >> localrc << EOF SKIP_EXERCISES=${SKIP_EXERCISES},volumes XENAPI_PASSWORD=${DEVSTACK_GATE_XENAPI_PASSWORD} XENAPI_CONNECTION_URL=http://${DEVSTACK_GATE_XENAPI_DOM0_IP} VNCSERVER_PROXYCLIENT_ADDRESS=${DEVSTACK_GATE_XENAPI_DOM0_IP} VIRT_DRIVER=xenserver # A separate xapi network is created with this name-label FLAT_NETWORK_BRIDGE=vmnet # A separate xapi network on eth4 serves the purpose of the public network PUBLIC_INTERFACE=eth4 # The xapi network ""vmnet"" is connected to eth3 in domU # We need to explicitly specify these, as the devstack/xenserver driver # sets GUEST_INTERFACE_DEFAULT VLAN_INTERFACE=eth3 FLAT_INTERFACE=eth3 # Explicitly set HOST_IP, so that it will be passed down to xapi, # thus it will be able to reach glance HOST_IP=${DEVSTACK_GATE_XENAPI_DOMU_IP} SERVICE_HOST=${DEVSTACK_GATE_XENAPI_DOMU_IP} # Disable firewall XEN_FIREWALL_DRIVER=nova.virt.firewall.NoopFirewallDriver # Disable agent EXTRA_OPTS=(""xenapi_disable_agent=True"") # Add a separate device for volumes VOLUME_BACKING_DEVICE=/dev/xvdb # Set multi-host config MULTI_HOST=1 EOF fi if [[ ""$DEVSTACK_GATE_TEMPEST"" -eq ""1"" ]]; then # We need to disable ratelimiting when running # Tempest tests since so many requests are executed echo ""API_RATE_LIMIT=False"" >> localrc # Volume tests in Tempest require a number of volumes # to be created, each of 1G size. Devstack's default # volume backing file size is 10G. # # The 24G setting is expected to be enough even # in parallel run. echo ""VOLUME_BACKING_FILE_SIZE=24G"" >> localrc # in order to ensure glance http tests don't time out, we # specify the TEMPEST_HTTP_IMAGE address to be horrizon's # front page. Kind of hacky, but it works. echo ""TEMPEST_HTTP_IMAGE=http://127.0.0.1/"" >> localrc fi if [[ ""$DEVSTACK_GATE_TEMPEST_DISABLE_TENANT_ISOLATION"" -eq ""1"" ]]; then echo ""TEMPEST_ALLOW_TENANT_ISOLATION=False"" >>localrc fi if [[ ""$DEVSTACK_GATE_GRENADE"" -eq ""1"" ]]; then echo ""DATA_DIR=/opt/stack/data"" >> localrc echo ""SWIFT_DATA_DIR=/opt/stack/data/swift"" >> localrc if [[ ""$LOCALRC_OLDNEW"" == ""old"" ]]; then echo ""GRENADE_PHASE=base"" >> localrc else echo ""GRENADE_PHASE=target"" >> localrc fi else # Grenade needs screen, so only turn this off if we aren't # running grenade. echo ""USE_SCREEN=False"" >>localrc fi if [[ ""$DEVSTACK_GATE_TEMPEST_LARGE_OPS"" -eq ""1"" ]]; then # NOTE(danms): Temporary transition to =NUM_RESOURCES echo ""VIRT_DRIVER=fake"" >> localrc echo ""TEMPEST_LARGE_OPS_NUMBER=50"" >>localrc elif [[ ""$DEVSTACK_GATE_TEMPEST_LARGE_OPS"" -gt ""1"" ]]; then # use fake virt driver and 10 copies of nova-compute echo ""VIRT_DRIVER=fake"" >> localrc # To make debugging easier, disabled until bug 1218575 is fixed. # echo ""NUMBER_FAKE_NOVA_COMPUTE=10"" >>localrc echo ""TEMPEST_LARGE_OPS_NUMBER=$DEVSTACK_GATE_TEMPEST_LARGE_OPS"" >>localrc fi if [[ ""$DEVSTACK_GATE_CONFIGDRIVE"" -eq ""1"" ]]; then echo ""FORCE_CONFIG_DRIVE=always"" >>localrc else echo ""FORCE_CONFIG_DRIVE=False"" >>localrc fi if [[ ""$DEVSTACK_GATE_KEYSTONE_V3"" -eq ""1"" ]]; then # Run gate using only keystone v3 # For now this is only injected in tempest configuration echo ""TEMPEST_AUTH_VERSION=v3"" >>localrc fi if [[ ""$DEVSTACK_GATE_USE_APACHE"" -eq ""0"" ]]; then # Disable running services that can run under alternatives from Apache # (e.g. Keystone under eventlet) from being configured to run under # Apache. This will affect all services that run under HTTPD (mod_wsgi) # by default. echo ""APACHE_ENABLED_SERVICES="" >> localrc fi if [[ ""$DEVSTACK_GATE_TEMPEST_NOVA_V3_API"" -eq ""1"" ]]; then echo ""TEMPEST_NOVA_API_V3=True"" >> localrc fi }",,212,210
openstack%2Ftripleo-image-elements~master~Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f,openstack/tripleo-image-elements,master,Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f,Adds passthrough config for nova rootwrap,ABANDONED,2014-05-30 15:54:44.000000000,2014-07-17 08:22:46.000000000,,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 6488}, {'_account_id': 8153}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-05-30 15:54:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6ab8e88090ce103245126874abd162dbd0588ffa', 'message': 'Adds passthrough config for nova rootwrap\n\nPreviously the nova rootwrap.conf and rootwrap.d was copied from the nova\nsource tree. This patch copies the rootwrap.d directory from the source tree\nbut adds the rootwrap.conf via o-a-c so that it can be templated. The supplied\ntemplate also includes support for passthrough config.\n\nThis is useful for folks who want to add custom logging or other conf\nto their rootwrap.\n\nChange-Id: Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f\n'}, {'number': 2, 'created': '2014-05-30 20:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/96b6fb4968745520e6f97ccefd5508355f544e32', 'message': 'Adds passthrough config for nova rootwrap\n\nPreviously the nova rootwrap.conf and rootwrap.d was copied from the\nnova source tree. This patch copies the rootwrap.d directory from the\nsource tree but adds the rootwrap.conf via o-a-c so that it can be\ntemplated. The supplied template also includes support for\npassthrough config.\n\nThis is useful for folks who want to add custom logging or other conf\nto their rootwrap.\n\nExtra config looks like this:\n{\n  ""nova"": {\n    ""rootwrap"": [\n      {\n        ""section"": ""default"",\n        ""values"": [\n          {\n            ""value"": ""bar"",\n            ""option"": ""foo""\n          }\n        ],\n      }\n    ]\n  }\n}\n\nChange-Id: Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f\n'}, {'number': 3, 'created': '2014-05-30 20:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/23471173f977b8308ce2552d71953e204d72d768', 'message': 'Adds passthrough config for nova rootwrap\n\nPreviously the nova rootwrap.conf and rootwrap.d was copied from the\nnova source tree. This patch copies the rootwrap.d directory from the\nsource tree but adds the rootwrap.conf via o-a-c so that it can be\ntemplated. The supplied template also includes support for\npassthrough config.\n\nThis is useful for folks who want to add custom logging or other conf\nto their rootwrap.\n\nExtra config looks like this:\n{\n  ""nova"": {\n    ""rootwrap"": [\n      {\n        ""section"": ""default"",\n        ""values"": [\n          {\n            ""value"": ""bar"",\n            ""option"": ""foo""\n          }\n        ]\n      }\n    ]\n  }\n}\n\nChange-Id: Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f\n'}, {'number': 4, 'created': '2014-05-30 22:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a2ce2be99f34d842e8339121cc4852cb6fe4e76e', 'message': 'Adds passthrough config for nova rootwrap\n\nPreviously the nova rootwrap.conf and rootwrap.d was copied from the\nnova source tree. This patch copies the rootwrap.d directory from the\nsource tree but adds the rootwrap.conf via o-a-c so that it can be\ntemplated. The supplied template also includes support for\npassthrough config.\n\nThis is useful for folks who want to add custom logging or other conf\nto their rootwrap.\n\nExtra config looks like this:\n{\n  ""nova_rootwrap"": {\n    ""config"": [\n      {\n        ""section"": ""default"",\n        ""values"": [\n          {\n            ""value"": ""bar"",\n            ""option"": ""foo""\n          }\n        ]\n      }\n    ]\n  }\n}\n\nChange-Id: Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f\n'}, {'number': 5, 'created': '2014-06-23 15:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e6a091f641cccc88d6f3d60f8bdd851845f8a15f', 'message': 'Adds passthrough config for nova rootwrap\n\nPreviously the nova rootwrap.conf and rootwrap.d was copied from the\nnova source tree. This patch copies the rootwrap.d directory from the\nsource tree but adds the rootwrap.conf via o-a-c so that it can be\ntemplated. The supplied template also includes support for\npassthrough config.\n\nThis is useful for folks who want to add custom logging or other conf\nto their rootwrap.\n\nExtra config looks like this:\n{\n  ""nova_rootwrap"": {\n    ""config"": [\n      {\n        ""section"": ""default"",\n        ""values"": [\n          {\n            ""value"": ""bar"",\n            ""option"": ""foo""\n          }\n        ]\n      }\n    ]\n  }\n}\n\nChange-Id: Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f\n'}, {'number': 6, 'created': '2014-06-25 10:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b5f035c6cefc3adb344dcebf3ec0d37e61380222', 'message': 'Adds passthrough config for nova rootwrap\n\nPreviously the nova rootwrap.conf and rootwrap.d was copied from the\nnova source tree. This patch copies the rootwrap.d directory from the\nsource tree but adds the rootwrap.conf via o-a-c so that it can be\ntemplated. The supplied template also includes support for\npassthrough config.\n\nThis is useful for folks who want to add custom logging or other conf\nto their rootwrap.\n\nExtra config looks like this:\n{\n  ""nova_rootwrap"": {\n    ""config"": [\n      {\n        ""section"": ""SECTIONNAME"",\n        ""values"": [\n          {\n            ""option"": ""OPTIONNAME""\n            ""value"": ""VALUENAME"",\n          }\n        ]\n      }\n    ]\n  }\n}\n\nChange-Id: Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f\nblueprint: passthrough-config\n'}, {'number': 7, 'created': '2014-07-02 17:05:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/558694357dd0e50582c67e07d04a62ab950a4bbb', 'message': 'Adds passthrough config for nova rootwrap\n\nPreviously the nova rootwrap.conf and rootwrap.d was copied from the\nnova source tree. This patch copies the rootwrap.d directory from the\nsource tree but adds the rootwrap.conf via o-a-c so that it can be\ntemplated. The supplied template also includes support for\npassthrough config.\n\nThis is useful for folks who want to add custom logging or other conf\nto their rootwrap.\n\nExtra config looks like this:\n{\n  ""nova"": {\n    ""rootwrap_config"": [\n      {\n        ""section"": ""SECTIONNAME"",\n        ""values"": [\n          {\n            ""option"": ""OPTIONNAME"",\n            ""value"": ""VALUENAME""\n          }\n        ]\n      }\n    ]\n  }\n}\n\nChange-Id: Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f\nblueprint: passthrough-config\n'}, {'number': 8, 'created': '2014-07-10 16:56:04.000000000', 'files': ['elements/nova/README.md', 'elements/nova/os-apply-config/etc/nova/rootwrap.d/passthrough.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/c6df582d098076a9fe73c722d0df2a606c70c719', 'message': 'Adds passthrough config for nova rootwrap\n\nThis patch adds a passthrough.conf to the nova rootwrap.d directory\nwhich supports passthrough config.\n\nThis is useful for folks who want to add custom logging or other conf\nto their rootwrap.\n\nExtra config looks like this:\n{\n  ""nova"": {\n    ""rootwrap_config"": [\n      {\n        ""section"": ""SECTIONNAME"",\n        ""values"": [\n          {\n            ""option"": ""OPTIONNAME"",\n            ""value"": ""VALUENAME""\n          }\n        ]\n      }\n    ]\n  }\n}\n\nChange-Id: Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f\nblueprint: passthrough-config\n'}]",4,96811,c6df582d098076a9fe73c722d0df2a606c70c719,52,5,8,8153,,,0,"Adds passthrough config for nova rootwrap

This patch adds a passthrough.conf to the nova rootwrap.d directory
which supports passthrough config.

This is useful for folks who want to add custom logging or other conf
to their rootwrap.

Extra config looks like this:
{
  ""nova"": {
    ""rootwrap_config"": [
      {
        ""section"": ""SECTIONNAME"",
        ""values"": [
          {
            ""option"": ""OPTIONNAME"",
            ""value"": ""VALUENAME""
          }
        ]
      }
    ]
  }
}

Change-Id: Iff3f107dfdd71af214aac3f19c05bc7ba7745d9f
blueprint: passthrough-config
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/11/96811/6 && git format-patch -1 --stdout FETCH_HEAD,"['elements/nova/install.d/nova-source-install/74-nova', 'elements/nova/os-apply-config/etc/nova/rootwrap.conf']",2,6ab8e88090ce103245126874abd162dbd0588ffa,novarootwrap,"# Configuration for nova-rootwrap # This file should be owned by (and only-writeable by) the root user [DEFAULT] # List of directories to load filter definitions from (separated by ','). # These directories MUST all be only writeable by root ! filters_path=/etc/nova/rootwrap.d,/usr/share/nova/rootwrap # List of directories to search executables in, in case filters do not # explicitely specify a full path (separated by ',') # If not specified, defaults to system PATH environment variable. # These directories MUST all be only writeable by root ! exec_dirs=/sbin,/usr/sbin,/bin,/usr/bin # Enable logging to syslog # Default value is False use_syslog=False # Which syslog facility to use. # Valid values include auth, authpriv, syslog, local0, local1... # Default value is 'syslog' syslog_log_facility=syslog # Which messages to log. # INFO means log all usage # ERROR means only log unsuccessful attempts syslog_log_level=ERROR {{#nova_rootwrap}} {{#config}} [{{{section}}}] {{#values}} {{#comment}} {{/comment}} {{#option}} {{{option}}}={{{value}}} {{/option}} {{/values}} {{/config}} {{/nova_rootwrap}} ",,44,1
openstack%2Ftripleo-incubator~master~I0a3765c56352a4bca3d260b45774ce6ee098d806,openstack/tripleo-incubator,master,I0a3765c56352a4bca3d260b45774ce6ee098d806,Makes devtest_seed.sh respect local.json,ABANDONED,2014-07-10 16:35:25.000000000,2014-07-17 08:12:55.000000000,,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1865}, {'_account_id': 8153}, {'_account_id': 8688}]","[{'number': 1, 'created': '2014-07-10 16:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/b9de7b5df098137d28a8d3c89346ea482cd99d9d', 'message': 'Makes devtest_seed.sh respect local.json\n\nThe seed-stack-config element allows you to use a local.json to\noverride config.json for configuring openstack services in the\nseed. However devtest_seed.sh will rudely ignore then overwrite\nlocal.json with a modified config.josn.\n\nThis patch makes devtest_seed.sh check for a local.json and use\nthat in preference to config.json. It will print a deprecation\nwarning similar to the seed-stack-config element.\n\nChange-Id: I0a3765c56352a4bca3d260b45774ce6ee098d806\n'}, {'number': 2, 'created': '2014-07-10 17:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/480b956fbe4528dbb3ba7e093e739457921e40ce', 'message': 'Makes devtest_seed.sh respect local.json\n\nThe seed-stack-config element allows you to use a local.json to\noverride config.json for configuring openstack services in the\nseed. However devtest_seed.sh will rudely ignore then overwrite\nlocal.json with a modified config.josn.\n\nThis patch makes devtest_seed.sh check for a local.json and use\nthat in preference to config.json.\n\nChange-Id: I0a3765c56352a4bca3d260b45774ce6ee098d806\n'}, {'number': 3, 'created': '2014-07-10 17:13:02.000000000', 'files': ['scripts/devtest_seed.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/33068dfb79f2f05e1f9c612f10f2aa9f7ee6a246', 'message': 'Makes devtest_seed.sh respect local.json\n\nThe seed-stack-config element expects you to copy config.json\nto local.json and add your seed settings. Devtest does this for\nyou but it ignores an existing local.json, which you may have\ntweaked.\n\nUpdate devtest_seed.sh so it will use local.json in preference\nto config.json if it exists.\n\nChange-Id: I0a3765c56352a4bca3d260b45774ce6ee098d806\n'}]",2,106099,33068dfb79f2f05e1f9c612f10f2aa9f7ee6a246,21,5,3,8153,,,0,"Makes devtest_seed.sh respect local.json

The seed-stack-config element expects you to copy config.json
to local.json and add your seed settings. Devtest does this for
you but it ignores an existing local.json, which you may have
tweaked.

Update devtest_seed.sh so it will use local.json in preference
to config.json if it exists.

Change-Id: I0a3765c56352a4bca3d260b45774ce6ee098d806
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/99/106099/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_seed.sh'],1,b9de7b5df098137d28a8d3c89346ea482cd99d9d,localjson,"## #. Config is read from local.json (and fall back to config.json for now). ## Check out the individual elements to see what config is supported. ## :: if [ -e ""local.json"" ]; then CONFIG_FILE=""local.json"" else echo ""Deprecated: Using config.json rather than local.json"" >&2 CONFIG_FILE=""config.json"" fi jq -s '.[1] as $config |(.[0].nova.baremetal |= (.virtual_power.user=$config[""ssh-user""]|.virtual_power.ssh_host=$config[""host-ip""]|.virtual_power.ssh_key=$config[""ssh-key""]|.arch=$config.arch|.power_manager=$config.power_manager))|.[0].ironic=""""| .[0]' $CONFIG_FILE $TE_DATAFILE > tmp_local.json jq -s '.[1] as $config |(.[0].ironic |= (.virtual_power_ssh_key=$config[""ssh-key""]))|.[0].nova.compute_driver=""ironic.nova.virt.ironic.driver.IronicDriver""|.[0].nova.compute_manager=""ironic.nova.compute.manager.ClusteredComputeManager""|.[0].nova.baremetal={}| .[0]' $CONFIG_FILE $TE_DATAFILE > tmp_local.json"," jq -s '.[1] as $config |(.[0].nova.baremetal |= (.virtual_power.user=$config[""ssh-user""]|.virtual_power.ssh_host=$config[""host-ip""]|.virtual_power.ssh_key=$config[""ssh-key""]|.arch=$config.arch|.power_manager=$config.power_manager))|.[0].ironic=""""| .[0]' config.json $TE_DATAFILE > tmp_local.json jq -s '.[1] as $config |(.[0].ironic |= (.virtual_power_ssh_key=$config[""ssh-key""]))|.[0].nova.compute_driver=""ironic.nova.virt.ironic.driver.IronicDriver""|.[0].nova.compute_manager=""ironic.nova.compute.manager.ClusteredComputeManager""|.[0].nova.baremetal={}| .[0]' config.json $TE_DATAFILE > tmp_local.json",13,2
openstack%2Fdevstack-gate~master~I4a782c47d1ba1ead0354dba613017e12ecea02e6,openstack/devstack-gate,master,I4a782c47d1ba1ead0354dba613017e12ecea02e6,Deterministic uid/gid usage,ABANDONED,2014-07-07 12:41:18.000000000,2014-07-17 08:10:20.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-07 12:41:18.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/27a989bdfcf7660ba9c75591133d75b3ddc48ef5', 'message': 'Deterministic uid/gid usage\n\nAllow to specify UID on devstack gate,\nin-order to ensure the same UID/GID can be used in multi-node setups.\n\nChange-Id: I4a782c47d1ba1ead0354dba613017e12ecea02e6\n'}]",0,105150,27a989bdfcf7660ba9c75591133d75b3ddc48ef5,4,1,1,5803,,,0,"Deterministic uid/gid usage

Allow to specify UID on devstack gate,
in-order to ensure the same UID/GID can be used in multi-node setups.

Change-Id: I4a782c47d1ba1ead0354dba613017e12ecea02e6
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/50/105150/1 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,27a989bdfcf7660ba9c75591133d75b3ddc48ef5,stack-uid-const, DEVSTACK_STACK_UID=${DEVSTACK_STACK_UID:-2222} DEVSTACK_TEMPEST_UID=${DEVSTACK_TEMPEST_UID:-3333} sudo groupadd -fg $DEVSTACK_STACK_UID stack sudo useradd -g stack -u $DEVSTACK_STACK_UID -s /bin/bash -d $BASE/new -m stack sudo groupadd -fg $DEVSTACK_TEMPEST_UID tempest sudo useradd -g tempest -u $DEVSTACK_TEMPEST_UID -s /bin/bash -m tempest, sudo useradd -U -s /bin/bash -d $BASE/new -m stack sudo useradd -U -s /bin/bash -m tempest,6,2
openstack%2Fdevstack~master~I93b8ef32832269d730c76a6dc24ddb4f20c6d9df,openstack/devstack,master,I93b8ef32832269d730c76a6dc24ddb4f20c6d9df,Support multiple Cinder backend types,MERGED,2014-06-16 14:58:24.000000000,2014-07-17 08:05:07.000000000,2014-07-15 19:33:02.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4523}, {'_account_id': 6984}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-16 14:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9421e623785e1a87da6135f80604decbfb061a4e', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 2, 'created': '2014-06-23 20:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/939a7763c4a818f0bc95b6db0e4d5c4374a952a6', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 3, 'created': '2014-06-23 22:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/bf8043092b70bdcbc9d7da6b6a5c43a598aee9bd', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 4, 'created': '2014-07-01 14:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e4bb51ec3ea9c677cc279ad21eb80084ae1c497f', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time using CINDER_ENABLED_BACKENDS.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 5, 'created': '2014-07-01 16:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a271f50b7e4e7c2e99e162065a3aa4a1a2daf27c', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time using CINDER_ENABLED_BACKENDS.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nAdd wait for c-api to start-trying to figure out why cinder type-create fails...\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 6, 'created': '2014-07-01 16:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5ab639b86951ca4345490fa109071457e07d154d', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time using CINDER_ENABLED_BACKENDS.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nAdd wait for c-api to start-trying to figure out why cinder type-create fails...\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 7, 'created': '2014-07-01 21:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a360b13a4467ea948021c6d4d19cc5bed0f43a0f', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time using CINDER_ENABLED_BACKENDS.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nAdd wait for c-api to start-trying to figure out why cinder type-create fails...\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 8, 'created': '2014-07-02 14:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/fe0ed856e6a3cccabbfd0e27f0d8180eae1a18b0', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time using CINDER_ENABLED_BACKENDS.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nAdd wait for c-api to start-trying to figure out why cinder type-create fails...\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 9, 'created': '2014-07-03 15:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/16576219c4abf047e99f60d874ff05f8ac75c35f', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time using CINDER_ENABLED_BACKENDS.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nAdd wait for c-api to ensure it is started before continuing.\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 10, 'created': '2014-07-03 19:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/97b60f2bcc1e8186136b537471f734dbc319844e', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time using CINDER_ENABLED_BACKENDS.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nAdd wait for c-api to ensure it is started before continuing.\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 11, 'created': '2014-07-03 23:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/21ff84c9cf94e21e59b19f4ba3a93c05f1df6754', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time using CINDER_ENABLED_BACKENDS.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nAdd wait for c-api to ensure it is started before continuing.\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}, {'number': 12, 'created': '2014-07-15 16:56:53.000000000', 'files': ['lib/cinder_backends/lvm', 'lib/cinder', 'lib/cinder_backends/nfs', 'stackrc', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/097183356e60f6375061914e89816c8faafb3a6f', 'message': 'Support multiple Cinder backend types\n\nThis is the first step in supporting multiple Cinder backend types at\nonce.  It initially converts the existing hard-coded multi-lvm support\nto a new cinder_backends driver form.  Eventually the cinder_plugins\nwill be converted to this form so they can be enabled more than just\none at a time using CINDER_ENABLED_BACKENDS.\n\nThe default configuration should be identical to the previous defaults,\nincluding for both True and False values of CINDER_MULTI_LVM_BACKEND.\n\nThe existing cinder_plugins are expected to be removed when this is\ncomplete. They should continue to work until they have been converted.\n\nAdd wait for c-api to ensure it is started before continuing.\n\nChange-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df\n'}]",7,100271,097183356e60f6375061914e89816c8faafb3a6f,104,10,12,970,,,0,"Support multiple Cinder backend types

This is the first step in supporting multiple Cinder backend types at
once.  It initially converts the existing hard-coded multi-lvm support
to a new cinder_backends driver form.  Eventually the cinder_plugins
will be converted to this form so they can be enabled more than just
one at a time using CINDER_ENABLED_BACKENDS.

The default configuration should be identical to the previous defaults,
including for both True and False values of CINDER_MULTI_LVM_BACKEND.

The existing cinder_plugins are expected to be removed when this is
complete. They should continue to work until they have been converted.

Add wait for c-api to ensure it is started before continuing.

Change-Id: I93b8ef32832269d730c76a6dc24ddb4f20c6d9df
",git fetch https://review.opendev.org/openstack/devstack refs/changes/71/100271/12 && git format-patch -1 --stdout FETCH_HEAD,"['lib/cinder_backends/lvm', 'lib/cinder', 'lib/cinder_backends/nfs', 'lib/cinder_plugins/nfs']",4,9421e623785e1a87da6135f80604decbfb061a4e,bp/implement-ceph-backend,,"# lib/cinder_plugins/nfs # Configure the nfs driver # Enable with: # # CINDER_DRIVER=nfs # Dependencies: # # - ``functions`` file # - ``cinder`` configurations # configure_cinder_driver - make configuration changes, including those to other services # Save trace setting MY_XTRACE=$(set +o | grep xtrace) set +o xtrace # Defaults # -------- # Set up default directories # Entry Points # ------------ # configure_cinder_driver - Set config files, create data dirs, etc function configure_cinder_driver { iniset $CINDER_CONF DEFAULT volume_driver ""cinder.volume.drivers.nfs.NfsDriver"" iniset $CINDER_CONF DEFAULT nfs_shares_config ""$CINDER_CONF_DIR/nfs_shares.conf"" echo ""$CINDER_NFS_SERVERPATH"" | tee ""$CINDER_CONF_DIR/nfs_shares.conf"" } # Restore xtrace $MY_XTRACE # Local variables: # mode: shell-script # End: ",274,180
openstack%2Fopenstack-manuals~stable%2Ficehouse~I1caac81c8b4e019e56c9f1cbf8ad75d938aa3ebb,openstack/openstack-manuals,stable/icehouse,I1caac81c8b4e019e56c9f1cbf8ad75d938aa3ebb,Additional configuration steps for HEAT on RHEL,MERGED,2014-07-12 10:50:22.000000000,2014-07-17 07:58:38.000000000,2014-07-17 07:58:37.000000000,"[{'_account_id': 3}, {'_account_id': 6772}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-07-12 10:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0015b86a754439cdbfe1feb828733913fe36ace5', 'message': 'Additional configuration steps for HEAT on RHEL\n\nAdded steps on configuring HEAT service to use\nQPID as the messaging broker.\n\nUpdated the editing steps to add keystone_authoken\nand ec2authtoken to use openstack-config to modify\nthe heat.conf file as the other configuration\nediting in this section uses openstack-config.\n\nChange-Id: I1caac81c8b4e019e56c9f1cbf8ad75d938aa3ebb\nCloses-Bug: 1331050\n'}, {'number': 2, 'created': '2014-07-15 09:34:32.000000000', 'files': ['doc/install-guide/section_heat-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1686a9dbdb6ca276eba036657ee28bee0c7e97f5', 'message': 'Additional configuration steps for HEAT on RHEL\n\nAdded steps on configuring HEAT service to use\nQpid as the messaging broker.\n\nUpdated the editing steps to add keystone_authoken\nand ec2authtoken to use openstack-config to modify\nthe heat.conf file as the other configuration\nediting in this section uses openstack-config.\n\nCloses-Bug: 1331050\n\nChange-Id: I1caac81c8b4e019e56c9f1cbf8ad75d938aa3ebb\n'}]",4,106556,1686a9dbdb6ca276eba036657ee28bee0c7e97f5,14,3,2,7071,,,0,"Additional configuration steps for HEAT on RHEL

Added steps on configuring HEAT service to use
Qpid as the messaging broker.

Updated the editing steps to add keystone_authoken
and ec2authtoken to use openstack-config to modify
the heat.conf file as the other configuration
editing in this section uses openstack-config.

Closes-Bug: 1331050

Change-Id: I1caac81c8b4e019e56c9f1cbf8ad75d938aa3ebb
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/56/106556/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_heat-install.xml'],1,0015b86a754439cdbfe1feb828733913fe36ace5,bug/1331050," <step os=""rhel;centos;fedora""> <para>Configure the Orchestration Service to use the QPID message broker.</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/heat/heat.conf DEFAULT qpid_hostname <replaceable>controller</replaceable></userinput></screen> </step> <step os=""opensuse;sles;ubuntu""> <step os=""rhel;centos;fedora""> <para>Run the following commands to configure the Orchestration service to authenticate with the Identity service:</para> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/heat/heat.conf keystone_authtoken \ auth_uri http://<replaceable>controller</replaceable>:5000</userinput></screen> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/heat/heat.conf keystone_authtoken \ auth_port 35357 </userinput></screen> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/heat/heat.conf keystone_authtoken \ auth_protocol http </userinput></screen> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/heat/heat.conf keystone_authtoken \ admin_tenant_name service</userinput></screen> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/heat/heat.conf keystone_authtoken \ admin_user heat</userinput></screen> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/heat/heat.conf keystone_authtoken \ admin_password <replaceable>HEAT_PASS</replaceable></userinput></screen> <screen><prompt>#</prompt> <userinput>openstack-config --set /etc/heat/heat.conf ec2authtoken \ auth_uri http://<replaceable>controller</replaceable>:5000</userinput></screen> </step>"," <step os=""rhel;centos;fedora;opensuse;sles;ubuntu"">",23,1
openstack%2Fpython-keystoneclient~master~Ic14d54f0f1d8cca2c3a5a6a6da7465c703773aa0,openstack/python-keystoneclient,master,Ic14d54f0f1d8cca2c3a5a6a6da7465c703773aa0,Test that tenant list function can use auth_url,MERGED,2014-07-04 06:35:36.000000000,2014-07-17 07:38:57.000000000,2014-07-17 07:38:57.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 8871}, {'_account_id': 11333}, {'_account_id': 11387}, {'_account_id': 11589}]","[{'number': 1, 'created': '2014-07-04 06:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f786b25d3ed9d5046377cff9bcbcd5d73b12fcc7', 'message': 'Test that tenant list function can use auth_url\n\nListing tenants can be done on the auth URL because it is often needed\nto be performed with an unscoped token. The behaviour is not tested\nthough so add a test to cover it.\n\nChange-Id: Ic14d54f0f1d8cca2c3a5a6a6da7465c703773aa0\n'}, {'number': 2, 'created': '2014-07-04 06:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/63f247331aba7136273f857dd7af34dceac2d227', 'message': 'Test that tenant list function can use auth_url\n\nListing tenants can be done on the auth URL because it is often needed\nto be performed with an unscoped token. The behaviour is not tested\nthough so add a test to cover it.\n\nChange-Id: Ic14d54f0f1d8cca2c3a5a6a6da7465c703773aa0\n'}, {'number': 3, 'created': '2014-07-14 00:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/a9621ccd76c6fa410076468d8796823cb42838c3', 'message': 'Test that tenant list function can use auth_url\n\nListing tenants can be done on the auth URL because it is often needed\nto be performed with an unscoped token. The behaviour is not tested\nthough so add a test to cover it.\n\nChange-Id: Ic14d54f0f1d8cca2c3a5a6a6da7465c703773aa0\n'}, {'number': 4, 'created': '2014-07-14 18:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/55de44f07559bd2b15fc08756d665294f9ad46e9', 'message': 'Test that tenant list function can use auth_url\n\nListing tenants can be done on the auth URL because it is often needed\nto be performed with an unscoped token. The behaviour is not tested\nthough so add a test to cover it.\n\nChange-Id: Ic14d54f0f1d8cca2c3a5a6a6da7465c703773aa0\n'}, {'number': 5, 'created': '2014-07-14 23:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/298c20217cf981cf63faffa5134c6c5bfff11f83', 'message': 'Test that tenant list function can use auth_url\n\nListing tenants can be done on the auth URL because it is often needed\nto be performed with an unscoped token. The behaviour is not tested\nthough so add a test to cover it.\n\nChange-Id: Ic14d54f0f1d8cca2c3a5a6a6da7465c703773aa0\n'}, {'number': 6, 'created': '2014-07-15 03:31:28.000000000', 'files': ['keystoneclient/tests/v2_0/test_tenants.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/5011d51f31fa83263e939d21aaa5f47702a88ee6', 'message': 'Test that tenant list function can use auth_url\n\nListing tenants can be done on the auth URL because it is often needed\nto be performed with an unscoped token. The behaviour is not tested\nthough so add a test to cover it.\n\nChange-Id: Ic14d54f0f1d8cca2c3a5a6a6da7465c703773aa0\n'}]",2,104770,5011d51f31fa83263e939d21aaa5f47702a88ee6,35,9,6,7191,,,0,"Test that tenant list function can use auth_url

Listing tenants can be done on the auth URL because it is often needed
to be performed with an unscoped token. The behaviour is not tested
though so add a test to cover it.

Change-Id: Ic14d54f0f1d8cca2c3a5a6a6da7465c703773aa0
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/70/104770/2 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/tests/v2_0/test_tenants.py'],1,f786b25d3ed9d5046377cff9bcbcd5d73b12fcc7,adapter,"from keystoneclient import fixturefrom keystoneclient.v2_0 import client @httpretty.activate def test_list_tenants_use_admin_url(self): self.stub_url(httpretty.GET, ['tenants'], json=self.TEST_TENANTS) self.assertEqual(self.TEST_URL, self.client.management_url) tenant_list = self.client.tenants.list() [self.assertIsInstance(t, tenants.Tenant) for t in tenant_list] self.assertEqual(len(self.TEST_TENANTS['tenants']['values']), len(tenant_list)) @httpretty.activate def test_list_tenants_fallback_to_auth_url(self): new_auth_url = 'http://keystone.test:5000/v2.0' token = fixture.V2Token(token_id=self.TEST_TOKEN, user_name=self.TEST_USER, user_id=self.TEST_USER_ID) self.stub_auth(base_url=new_auth_url, json=token) self.stub_url(httpretty.GET, ['tenants'], base_url=new_auth_url, json=self.TEST_TENANTS) c = client.Client(username=self.TEST_USER, auth_url=new_auth_url, password=uuid.uuid4().hex) self.assertIsNone(c.management_url) tenant_list = c.tenants.list() [self.assertIsInstance(t, tenants.Tenant) for t in tenant_list] self.assertEqual(len(self.TEST_TENANTS['tenants']['values']), len(tenant_list))",,37,0
openstack%2Fneutron~master~I1d71c8a2cf8c2f71f0dbcfb54c9b347e24c03562,openstack/neutron,master,I1d71c8a2cf8c2f71f0dbcfb54c9b347e24c03562,"ofagent: Handle device name prefixes other than ""tap""",MERGED,2014-07-14 07:41:34.000000000,2014-07-17 07:16:18.000000000,2014-07-16 22:05:00.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-14 07:41:34.000000000', 'files': ['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/plugins/ofagent/agent/ports.py', 'neutron/tests/unit/ofagent/test_ofa_ports.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f676d9215958b1af1105d4ff4671ce6cefd83eb7', 'message': 'ofagent: Handle device name prefixes other than ""tap""\n\nThis fixes regressions in commit 9d13ea884bff749b3975acb5eb5630e5aca4a665.\n\nHandle device name prefixes other than ""tap"".\nFor example, nova hybrid interface driver uses ""qvo"" prefix.\n\nAlso, ignore non neutron ports correctly.  For example, veth pairs\nused to connect physical bridges.\n\nCloses-Bug: #1341465\nChange-Id: I1d71c8a2cf8c2f71f0dbcfb54c9b347e24c03562\n'}]",0,106701,f676d9215958b1af1105d4ff4671ce6cefd83eb7,23,16,1,6854,,,0,"ofagent: Handle device name prefixes other than ""tap""

This fixes regressions in commit 9d13ea884bff749b3975acb5eb5630e5aca4a665.

Handle device name prefixes other than ""tap"".
For example, nova hybrid interface driver uses ""qvo"" prefix.

Also, ignore non neutron ports correctly.  For example, veth pairs
used to connect physical bridges.

Closes-Bug: #1341465
Change-Id: I1d71c8a2cf8c2f71f0dbcfb54c9b347e24c03562
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/106701/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/plugins/ofagent/agent/ports.py', 'neutron/tests/unit/ofagent/test_ofa_ports.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py']",4,f676d9215958b1af1105d4ff4671ce6cefd83eb7,bug/1341465,"def _mock_port(is_neutron=True, normalized_name=None): p = mock.Mock() p.is_neutron_port.return_value = is_neutron if normalized_name: p.normalized_port_name.return_value = normalized_name return p return_value=[_mock_port(True, 'xxx')])): def _mock_treat_devices_added_updated(self, details, port, all_ports, func_name): :param port: port name to process :param all_ports: the port that _get_ports return return_value=all_ports), self.assertFalse(self.agent.treat_devices_added_or_updated([port])) port_name = 'hoge' p1 = _mock_port(True, port_name) p1.ofport = -1 mock.MagicMock(), port_name, [p1], 'port_dead')) port_name = 'hoge' p1 = _mock_port(True, port_name) p1.ofport = 1 mock.MagicMock(), port_name, [p1], 'port_dead')) port_name = 'tapd3315981-0b' p1 = _mock_port(False) p2 = _mock_port(True, port_name) ports = [p1, p2] details, port_name, ports, 'treat_vif_port')) return_value=[_mock_port(True, 'xxx')]), ) as (get_dev_fn, _get_ports, upd_dev_up, _get_ports.assert_called_once_with(self.agent.int_br) ps = [_mock_port(True, x) for x in names]"," return_value=[mock.Mock(port_name='xxx')])): def _mock_treat_devices_added_updated(self, details, port, func_name): :param port: the port that get_vif_port_by_id should return return_value=[port]), self.assertFalse(self.agent.treat_devices_added_or_updated( [port.port_name])) port = mock.Mock() port.ofport = -1 mock.MagicMock(), port, 'port_dead')) port = mock.Mock() port.ofport = 1 mock.MagicMock(), port, 'port_dead')) details, mock.Mock(), 'treat_vif_port')) return_value=[mock.Mock(port_name='xxx')]), ) as (get_dev_fn, get_vif_func, upd_dev_up, ps = [mock.Mock(port_name=x, ofport=names.index(x)) for x in names]",120,37
openstack%2Fneutron~master~I7227fbe2718eba6665a5afb5dcaaaa77b341091f,openstack/neutron,master,I7227fbe2718eba6665a5afb5dcaaaa77b341091f,Add L3 Extension for Distributed Routers,MERGED,2014-04-28 20:01:23.000000000,2014-07-17 06:55:33.000000000,2014-07-16 21:08:58.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1038}, {'_account_id': 1131}, {'_account_id': 1935}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 4149}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6659}, {'_account_id': 6695}, {'_account_id': 6854}, {'_account_id': 6876}, {'_account_id': 7016}, {'_account_id': 7141}, {'_account_id': 7183}, {'_account_id': 7249}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8253}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9077}, {'_account_id': 9093}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9705}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9885}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10971}]","[{'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb34883222da45d6ea1ca64b47567871720db59e', 'message': 'Add L3 Extension for Distributed Routers\n\nThis patch is a part of Neutron OVS Distributed\nRouter Blueprint neutron-ovs-dvr.\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/62188ef44f959cd53fbb501230b5ce7f192120fd', 'message': 'Add L3 Extension for Distributed Routers\n\nThis patch is a part of Neutron OVS Distributed\nRouter Blueprint.\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n'}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/307df28751ca7a127d3cd82be00cdd72edc6b581', 'message': 'Add L3 Extension for Distributed Routers\n\nThis patch is a part of Neutron OVS Distributed\nRouter Blueprint neutron-ovs-dvr.\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n'}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e999e148213c0d0a1104061e0e40e586d4c7e6d5', 'message': 'Add L3 Extension for Distributed Routers\n\nThis patch is a part of Neutron OVS Distributed\nRouter Blueprint neutron-ovs-dvr.\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n'}, {'number': 5, 'created': '2014-04-29 00:09:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a59a493ed60095bcbac27b5148a8e4d97fc1351', 'message': 'Add L3 Extension for Distributed Routers\n\nThis patch is a part of Neutron OVS Distributed\nRouter Blueprint neutron-ovs-dvr.\n\nDocImpact: implements neutron-ovs-dvr\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n'}, {'number': 6, 'created': '2014-04-29 00:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e233a72bf3c03b6d62ad78a2010701b89c4ab001', 'message': 'Add L3 Extension for Distributed Routers\n\nThis patch is a part of Neutron OVS Distributed\nRouter Blueprint neutron-ovs-dvr.\n\nDocImpact: implements neutron-ovs-dvr\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n'}, {'number': 7, 'created': '2014-04-29 03:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c1b03f972f9010fbe4a18ea4f7e09a14b4d3242', 'message': 'Add L3 Extension for Distributed Routers\n\nThis patch is a part of Neutron OVS Distributed\nRouter Blueprint neutron-ovs-dvr.\n\nDocImpact: implements neutron-ovs-dvr\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n'}, {'number': 8, 'created': '2014-05-14 15:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf9399a70f8c1fdc11bd877d0e62e390f1ba8fad', 'message': 'Add L3 Extension for Distributed Routers\n\nThis patch is a part of Neutron OVS Distributed\nRouter Blueprint neutron-ovs-dvr.\n\nDocImpact: implements neutron-ovs-dvr\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n'}, {'number': 9, 'created': '2014-05-29 08:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f83db583eaf5a9e093c2f92c78b8e915e9e1995', 'message': 'Add L3 Extension for Distributed Routers\n\nThis patch is a part of Neutron OVS Distributed\nRouter Blueprint neutron-ovs-dvr.\n\nDocImpact: implements neutron-ovs-dvr\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n'}, {'number': 10, 'created': '2014-05-29 08:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb5b0b73bbb69719cb5322ee365ce6d65fd27178', 'message': 'Add L3 Extension for Distributed Routers\n\nThis patch is a part of Neutron OVS Distributed\nRouter Blueprint neutron-ovs-dvr.\n\nDocImpact: implements neutron-ovs-dvr\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n'}, {'number': 11, 'created': '2014-05-29 23:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/05365fabcf2033d67afe8d9fbf4046e6792cbba2', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n""}, {'number': 12, 'created': '2014-05-29 23:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/98ae3b72882fc2627bb354599090328234816f5c', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\n""}, {'number': 13, 'created': '2014-06-02 15:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f818d97d9987a5ba24bbe59eb1b81b37d2e35b94', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 14, 'created': '2014-06-02 16:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f90504e776bedee36a2492bc0805a2a55d82df2b', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 15, 'created': '2014-06-02 16:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/51591032fcefa5d98a9f81230687ecb4c81941f3', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 16, 'created': '2014-06-02 21:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/96f473289630df236951d0e55444028117d418f0', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 17, 'created': '2014-06-03 11:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5a08ab021b2dd93cef61e7e4ef123e45bc2e7fe0', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 18, 'created': '2014-06-03 11:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/775327969b8444f4178d00eaf1d94082b08d71ea', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 19, 'created': '2014-06-03 11:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d7589ffb6bc55f22252784a75d27581d3c0975f8', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 20, 'created': '2014-06-04 20:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/955795afc0b0664d3e55ab0055f7c1b3d0087179', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for blueprint neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 21, 'created': '2014-06-04 20:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/910ba551388c8f9b3e5f3dbff6a0bc06a2f65d75', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for BLU3PR1|\\|7 neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 22, 'created': '2014-06-04 23:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/463e15abb91790156e46ce65ed08685dfb89dbc8', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for BLU3PR1|\\|7 neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 23, 'created': '2014-06-05 09:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6e1acd3885c5dd7ad6606caffad773c10a633cf', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for BLU3PR1|\\|7 neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 24, 'created': '2014-06-05 20:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/03a1531d6bcb9eafed6dee831d8f953984c9c9a3', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for BLU3PR1|\\|7 neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 25, 'created': '2014-06-11 12:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/028db1b394e58a0186371efb5b9080c404f995f8', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for BLU3PR1|\\|7 neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 26, 'created': '2014-06-17 20:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d2e95e868681302b431d95c128dacef835476a3', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for BLU3PR1|\\|7 neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 27, 'created': '2014-06-19 08:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/051f1466ea004f5d9d7a06af325a3131b0ecb309', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 28, 'created': '2014-06-20 12:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a5a3d44d495fbacb57baddd069c07d23c9073b51', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 29, 'created': '2014-06-24 00:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d042ca633bdfa187ce00346e7f8d806e8471b40', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 30, 'created': '2014-06-24 01:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a1d544d793ac4e8b565496ef8dfb896a6971fb1f', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 31, 'created': '2014-06-25 18:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/81c5682e75ab562c5800f411e203c0d4d3be54c7', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 32, 'created': '2014-06-25 20:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/93fa682b8aa56aeb17e37cb5926f3107963c6e19', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 33, 'created': '2014-06-26 01:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/433d3a7082e55867ff26d2e0aba1714b4556406c', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 34, 'created': '2014-06-26 11:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e1f770c07baa306d29f748c9dc5ac524f83453ba', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 35, 'created': '2014-06-27 00:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/979b24f960cbf0012e392e5f4e0e91e69d4e9c0c', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 36, 'created': '2014-06-28 01:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a1766c62b3ef981764c1595596555706d41fce5a', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 37, 'created': '2014-06-28 02:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ee38deacb15c4017071f3b2e76c3d4b3ed8ae15', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 38, 'created': '2014-06-30 12:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e05816382e7b058c63e6b04b61b5c02b11af4ec', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 39, 'created': '2014-06-30 20:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/666a5d95ecd86db295b8770fc86e5b4117a54f8a', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 40, 'created': '2014-06-30 21:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13fb7c2b5bca188598f0cd2f0d9bb0fc8590ee1b', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 41, 'created': '2014-06-30 23:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9ecca913bc00b369bdf3e76dbfe9eb3df08936b', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 42, 'created': '2014-06-30 23:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f52723ee676d3b2b6a2551a6012fd392b9384595', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 43, 'created': '2014-07-01 14:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b62a29ad3bcb6a31ce4adaa2b62145d8db12180f', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 44, 'created': '2014-07-01 15:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d3308da6ebe1948a47567709eff738e149fbd0b', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 45, 'created': '2014-07-01 20:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6faec9d1d5426219b77d3e87382ae924914b4405', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 46, 'created': '2014-07-01 21:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9fb38a87ab8cec6b218304d81017404a3121ac89', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 47, 'created': '2014-07-01 21:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ee7e4ee75581070cea531b05d77e33946378883', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 48, 'created': '2014-07-02 23:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/32c38290c4f335d93446e32834d8fda4fed91185', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 49, 'created': '2014-07-03 22:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a83cc4404461e210765699e23e54861c9e2efef4', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 50, 'created': '2014-07-03 22:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b968748ea37174e23f8da6d587054b5bb91c5109', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension framework for\nimplementing distributed virtual routing on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a 'centralized' or\nlegacy-mode) attribute is added to the API router resource. It is\npossible to convert an existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by the API, may not\nbe honored by the underlying plugin implementation and an appropriate\nerror will be reported.\n\nWhen creating a router (regardless of the user role), Neutron will\nrely on a system wide configuration, whose default currently allows to\ncreate 'centralized' routers.\n\nTests are added for basic unit coverage; when the first building\nblocks for neutron-testing-refactor are complete, functional testing\nwill be added.  This is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 51, 'created': '2014-07-07 14:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b47a0362aae15fb158e36473bc9119146b3e63e', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 52, 'created': '2014-07-08 01:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6cdf8d208077fefae3b2dff958435b6ad6aa9562', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 53, 'created': '2014-07-09 00:11:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ebc227476b6806f4d248fe15362b77bcf881ab42', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 54, 'created': '2014-07-09 07:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b3e37683d5ada432282914e4f3f30ec451bb382', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 55, 'created': '2014-07-09 07:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cff4c83a35acef27c9292304d2de5f1201753e03', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 56, 'created': '2014-07-09 21:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/98ef4df349b15063db320e3750e4a1d25de78007', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 57, 'created': '2014-07-09 21:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bbfa94a40faa428b0c12e8fbaae36f396f5a7277', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 58, 'created': '2014-07-09 23:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f3ac30b5a4a16a22c153c52ad11468e083b9bf25', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 59, 'created': '2014-07-10 01:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6adf2178cd0f7795e7a2910a4f8612abe483ef2b', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 60, 'created': '2014-07-10 16:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c59aa134079b49d43855c49b360fb79cd3da8e97', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 61, 'created': '2014-07-10 22:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/182bde540525f38a168003aab013a28161923f8a', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 62, 'created': '2014-07-11 01:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/31a362beed7666e510f30b8a2ed3ee9917efcdab', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 63, 'created': '2014-07-11 17:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7929bef5e2b145e763fb9e779ccea4ca8f542554', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 64, 'created': '2014-07-14 19:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a571835e9ed3fbfd8c38bab465d41db49b5f6fe3', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 65, 'created': '2014-07-15 21:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/26bf85000f4572f177f93d299cc7ed7536ad3afa', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}, {'number': 66, 'created': '2014-07-16 15:02:02.000000000', 'files': ['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/db/migration/models/head.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/db/l3_dvr_db.py', 'etc/neutron.conf', 'neutron/tests/unit/vmware/test_nsx_plugin.py', 'neutron/db/l3_db.py', 'neutron/db/l3_attrs_db.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/common/constants.py', 'neutron/db/migration/alembic_migrations/versions/3927f7f7c456_l3_extension_distributed_mode.py', 'neutron/api/v2/attributes.py', 'neutron/db/l3_rpc_base.py', 'neutron/extensions/dvr.py', 'neutron/services/l3_router/l3_router_plugin.py', 'etc/policy.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1caa51ea68ba9844ed6e48b3714b742c9096c0af', 'message': ""Add L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nChange-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n""}]",661,84223,1caa51ea68ba9844ed6e48b3714b742c9096c0af,1156,52,66,7016,,,0,"Add L3 Extension for Distributed Routers

This patch introduces the model and extension
framework for implementing distributed virtual
routing on top of Open vSwitch.

A new admin-only 'distributed' (as opposed to a
'centralized' or legacy-mode) attribute is added
to the API router resource. It is possible to convert
an existing (centralized) router to a distributed
one; the opposite conversion, even though allowed by
the API, may not be honored by the underlying
plugin implementation and an appropriate error will
be reported.

When creating a router (regardless of the user role),
Neutron will rely on a system wide configuration, whose
default currently allows to create 'centralized' routers.

Tests are added for basic unit coverage; when the first
building blocks for neutron-testing-refactor
are complete, functional testing will be added.
This is because we should be moving away from how
extension tests have been done up until now.

Partially-implements: blueprint neutron-ovs-dvr

DocImpact

Change-Id: I7227fbe2718eba6665a5afb5dcaaaa77b341091f
Authored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>
Co-Authored-By: Armando Migliaccio <armamig@gmail.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/23/84223/37 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/constants.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/db/migration/alembic_migrations/versions/3927f7f7c456_l3_extension_distributed_mode.py', 'etc/neutron.conf', 'neutron/db/l3_distributed_db.py', 'neutron/extensions/l3_distributed.py', 'neutron/services/l3_router/l3_router_plugin.py', 'neutron/db/l3_db.py', 'neutron/tests/unit/test_extension_l3_distributed.py']",9,fb34883222da45d6ea1ca64b47567871720db59e,bp/neutron-ovs-dvr,"# # (c) Copyright 2014 Hewlett-Packard Development Company, L.P. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # @author: Swaminathan Vasudevan, Hewlett-Packard. import contextlib import mock from oslo.config import cfg from neutron.api.v2 import attributes from neutron.common import constants as l3_constants from neutron.common import exceptions as n_exc from neutron.common.test_lib import test_config from neutron import context from neutron.db import api as qdbapi from neutron.db import db_base_plugin_v2 from neutron.db import l3_agentschedulers_db from neutron.db import l3_distributed_db from neutron.db import model_base from neutron.extensions import l3 from neutron.extensions import l3_distributed from neutron import manager from neutron.openstack.common import uuidutils from neutron.openstack.common.notifier import api as notifier_api from neutron.openstack.common.notifier import test_notifier from neutron.plugins.common import constants as service_constants from neutron.tests.unit import test_l3_plugin _uuid = uuidutils.generate_uuid class L3DistributedTestExtensionManager(object): def get_resources(self): attr_map = attributes.RESOURCE_ATTRIBUTE_MAP attr_map.update(l3.RESOURCE_ATTRIBUTE_MAP) extended_attrs = l3_distributed.EXTENDED_ATTRIBUTES_2_0 for resource, resource_attrs in extended_attrs.iteritems(): if attr_map.get(resource, None): attr_map[resource].update(resource_attrs) else: attr_map[resource] = resource_attrs return l3.L3.get_resources() def get_actions(self): return [] def get_request_extensions(self): return [] class TestL3DistributedIntPlugin( test_l3_plugin.TestL3NatBasePlugin, l3_distributed_db.L3_DVR_db_mixin, l3_agentschedulers_db.L3AgentSchedulerDbMixin): supported_extension_aliases = [""external-net"", ""router"", ""l3-dvr"", ""l3_agent_scheduler""] class TestL3DistributedServicePlugin( test_l3_plugin.TestL3NatServicePlugin, l3_distributed_db.L3_DVR_db_mixin, l3_agentschedulers_db.L3AgentSchedulerDbMixin): supported_extension_aliases = [""router"", ""l3-dvr"", ""l3_agent_scheduler""] class L3DistributedTestCaseBase(test_l3_plugin.L3NatTestCaseMixin): def _create_drouter( self, fmt, tenant_id, name=None, admin_state_up=None, set_context=False, arg_list=None, **kwargs ): data = {'router': {'tenant_id': tenant_id}} if name: data['router']['name'] = name if admin_state_up: data['router']['admin_state_up'] = admin_state_up #if ((distributed is True) or (distributed is False)): #data['router']['distributed'] = distributed for arg in (('admin_state_up', 'tenant_id') + (arg_list or ())): if arg in kwargs and kwargs[arg]: data['router'][arg] = kwargs[arg] router_req = self.new_create_request('routers', data, fmt) if set_context and tenant_id: router_req.environ['neutron.context'] = context.Context( '', tenant_id) elif 'context' in kwargs: router_req.environ['neutron.context'] = kwargs['context'] return router_req.get_response(self.ext_api) def _make_drouter(self, fmt, tenant_id, name, admin_state_up, distributed, external_gateway_info, set_context, arg_list=None, **kwargs): if external_gateway_info: arg_list = ('external_gateway_info',) + (arg_list or ()) if distributed is not None: arg_list = ('distributed',) + (arg_list or ()) res = self._create_drouter( fmt, tenant_id, name, admin_state_up, set_context, arg_list=arg_list, distributed=distributed, external_gateway_info=external_gateway_info, **kwargs) return self.deserialize(fmt, res) @contextlib.contextmanager def drouter(self, name='router1', admin_state_up=True, distributed=None, external_gateway_info=None, fmt=None, tenant_id=_uuid(), set_context=False, **kwargs): drouter = self._make_drouter(fmt or self.fmt, tenant_id, name, admin_state_up, distributed, external_gateway_info, set_context, **kwargs) try: yield drouter finally: if 'router' in drouter: self._delete('routers', drouter['router']['id']) def test_dvr_router_create_default(self): name = 'router1' tenant_id = _uuid() expected_value = [('name', name), ('tenant_id', tenant_id), ('admin_state_up', True), ('status', 'ACTIVE'), ('external_gateway_info', None)] with self.drouter(name=name, admin_state_up=True, tenant_id=tenant_id) as r: for k, v in expected_value: self.assertEqual(r['router'][k], v) router_dict = self._show('routers', r['router']['id']) l_distributed = router_dict['router']['name'] self.assertIsNotNone(l_distributed) def test_dvr_router_create_with_global_distributed_enabled(self): cfg.CONF.set_override('router_distributed', True) name = 'router1' t_distributed = True tenant_id = _uuid() expected_value = [('name', name), ('tenant_id', tenant_id), ('admin_state_up', True), ('status', 'ACTIVE'), ('external_gateway_info', None)] with self.drouter(name=name, admin_state_up=True, tenant_id=tenant_id) as r: for k, v in expected_value: self.assertEqual(r['router'][k], v) router_dict = self._show('routers', r['router']['id']) l_distributed = router_dict['router']['distributed'] #self.assertEqual(l_distributed, t_distributed) self.assertTrue(l_distributed) def test_dvr_router_create_with_global_distributed_disabled(self): cfg.CONF.set_override('router_distributed', False) name = 'router1' t_distributed = False tenant_id = _uuid() expected_value = [('name', name), ('tenant_id', tenant_id), ('admin_state_up', True), ('status', 'ACTIVE'), ('external_gateway_info', None)] with self.drouter(name=name, admin_state_up=True, tenant_id=tenant_id) as r: for k, v in expected_value: self.assertEqual(r['router'][k], v) router_dict = self._show('routers', r['router']['id']) l_distributed = router_dict['router']['distributed'] self.assertEqual(l_distributed, t_distributed) def test_dvr_router_create_with_distributed_admin_context_false(self): name = 'router1' t_distributed = False tenant_id = _uuid() ctx = context.get_admin_context() expected_value = [('name', name), ('tenant_id', tenant_id), ('admin_state_up', True), ('status', 'ACTIVE'), ('external_gateway_info', None)] with self.drouter(name=name, admin_state_up=True, set_context=False, distributed=t_distributed, tenant_id=tenant_id, context=ctx) as r: for k, v in expected_value: self.assertEqual(r['router'][k], v) router_dict = self._show('routers', r['router']['id']) l_distributed = router_dict['router']['distributed'] self.assertEqual(l_distributed, t_distributed) def test_dvr_router_create_with_distributed_admin_context_true(self): name = 'router1' t_distributed = True tenant_id = _uuid() ctx = context.get_admin_context() expected_value = [('name', name), ('tenant_id', tenant_id), ('admin_state_up', True), ('status', 'ACTIVE'), ('external_gateway_info', None)] with self.drouter(name=name, admin_state_up=True, set_context=False, distributed=t_distributed, tenant_id=tenant_id, context=ctx) as r: for k, v in expected_value: self.assertEqual(r['router'][k], v) router_dict = self._show('routers', r['router']['id']) l_distributed = router_dict['router']['distributed'] self.assertEqual(l_distributed, t_distributed) def test_dvr_router_update(self): name = 'router1' tenant_id = _uuid() expected_value = [('name', name), ('tenant_id', tenant_id), ('admin_state_up', True), ('status', 'ACTIVE'), ('external_gateway_info', None)] with self.router(name=name, admin_state_up=True, tenant_id=tenant_id) as r: for k, v in expected_value: self.assertEqual(r['router'][k], v) router_dict = self._show('routers', r['router']['id']) l_distributed = router_dict['router']['name'] self.assertIsNotNone(l_distributed) def test_dvr_router_update_centralized_to_distributed(self): name = 'router1' tenant_id = _uuid() expected_value = [('name', name), ('tenant_id', tenant_id), ('admin_state_up', True), ('status', 'ACTIVE'), ('external_gateway_info', None)] with self.router(name=name, admin_state_up=True, tenant_id=tenant_id) as r: for k, v in expected_value: self.assertEqual(r['router'][k], v) router_dict = self._show('routers', r['router']['id']) l_distributed = router_dict['router']['name'] self.assertIsNotNone(l_distributed) class L3DistributedBaseForIntTests(test_l3_plugin.L3BaseForIntTests): def setUp(self, plugin=None): cfg.CONF.set_default('allow_overlapping_ips', True) cfg.CONF.set_default('router_distributed', False) plugin = ('neutron.tests.unit.test_extension_l3_distributed.' 'TestL3DistributedIntPlugin') ext_mgr = L3DistributedTestExtensionManager() super(L3DistributedBaseForIntTests, self).setUp(plugin=plugin, ext_mgr=ext_mgr) notifier_api._drivers = None cfg.CONF.set_override(""notification_driver"", [test_notifier.__name__]) def tearDown(self): super(L3DistributedBaseForIntTests, self).tearDown() class L3DistributedIntTestCase(L3DistributedBaseForIntTests, L3DistributedTestCaseBase): """"""Unit tests for core plugin with L3 routing integrates."""""" pass class L3DistributedIntTestCaseXML(L3DistributedBaseForIntTests, L3DistributedTestCaseBase): fmt = 'xml' class L3DistributedBaseForSepTests(test_l3_plugin.L3BaseForSepTests): def setUp(self): cfg.CONF.set_default('allow_overlapping_ips', True) cfg.CONF.set_default('router_distributed', False) plugin = 'neutron.tests.unit.test_l3_plugin.TestNoL3NatPlugin' ext_mgr = L3DistributedTestExtensionManager() l3_plugin = ('neutron.tests.unit.test_extension_l3_distributed.' 'TestL3DistributedServicePlugin') service_plugins = {'l3_plugin_name': l3_plugin} super(L3DistributedBaseForSepTests, self).setUp( plugin=plugin, ext_mgr=ext_mgr, service_plugins=service_plugins) notifier_api._drivers = None cfg.CONF.set_override(""notification_driver"", [test_notifier.__name__]) def tearDown(self): super(L3DistributedBaseForSepTests, self).tearDown() class L3DistributedSepTestCase(L3DistributedBaseForSepTests, L3DistributedTestCaseBase): """"""Unit tests for separate plugin with L3 routing service plugin."""""" pass class L3DistributedSepTestCaseXML(L3DistributedBaseForSepTests, L3DistributedTestCaseBase): fmt = 'xml' ",,944,42
openstack%2Fnova~master~I0e90c3af9bf908b733ed895ad7c204b0a95ef786,openstack/nova,master,I0e90c3af9bf908b733ed895ad7c204b0a95ef786,change the firewall debugging for clarity,MERGED,2014-07-03 12:05:45.000000000,2014-07-17 06:51:03.000000000,2014-07-17 06:51:00.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-03 12:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f909e0e8f03bf833c24a31340d38544a7f976542', 'message': ""change the firewall debugging for clarity\n\nWhen we are building rules ensure we log the instance['id'] so\nwe can actually correlate the iptables output to UUID for the\ninstance.\n\nAlso bundle up the security group to iptables translation to a\nfinal view of the world instead of the piecemeal rule at a time\nview.\n\nRelated-Bug: #1298472\n\nChange-Id: I0e90c3af9bf908b733ed895ad7c204b0a95ef786\n""}, {'number': 2, 'created': '2014-07-03 13:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a400748a054614412cdec00374d996f675b9081', 'message': ""change the firewall debugging for clarity\n\nWhen we are building rules ensure we log the instance['id'] so\nwe can actually correlate the iptables output to UUID for the\ninstance.\n\nAlso bundle up the security group to iptables translation to a\nfinal view of the world instead of the piecemeal rule at a time\nview.\n\nDisplay what rules are being skipped in the add process, as the\nskips seem to happen a lot. If this is completely normal we should\nprobably delete the bit entirely at some later point.\n\nRelated-Bug: #1298472\n\nChange-Id: I0e90c3af9bf908b733ed895ad7c204b0a95ef786\n""}, {'number': 3, 'created': '2014-07-07 19:17:38.000000000', 'files': ['nova/network/linux_net.py', 'nova/virt/firewall.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d7ce7cccbcd98aa17515d9fd449c88807cb6f0bd', 'message': ""change the firewall debugging for clarity\n\nWhen we are building rules ensure we log the instance['id'] so\nwe can actually correlate the iptables output to UUID for the\ninstance.\n\nAlso bundle up the security group to iptables translation to a\nfinal view of the world instead of the piecemeal rule at a time\nview.\n\nDisplay what rules are being skipped in the add process, as the\nskips seem to happen a lot. If this is completely normal we should\nprobably delete the bit entirely at some later point.\n\nRelated-Bug: #1298472\n\nChange-Id: I0e90c3af9bf908b733ed895ad7c204b0a95ef786\n""}]",4,104530,d7ce7cccbcd98aa17515d9fd449c88807cb6f0bd,54,13,3,2750,,,0,"change the firewall debugging for clarity

When we are building rules ensure we log the instance['id'] so
we can actually correlate the iptables output to UUID for the
instance.

Also bundle up the security group to iptables translation to a
final view of the world instead of the piecemeal rule at a time
view.

Display what rules are being skipped in the add process, as the
skips seem to happen a lot. If this is completely normal we should
probably delete the bit entirely at some later point.

Related-Bug: #1298472

Change-Id: I0e90c3af9bf908b733ed895ad7c204b0a95ef786
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/104530/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/firewall.py'],1,f909e0e8f03bf833c24a31340d38544a7f976542,netdebug," LOG.debug('Filters added to instance: %s' % instance['id'], instance=instance) LOG.debug('Provider Firewall Rules refreshed: %s' % instance['id'], instance=instance) LOG.debug('Security Groups %s translated to ipv4: %r, ipv6: %r' % ( security_groups, ipv4_rules, ipv6_rules), instance=instance)"," LOG.debug('Filters added to instance', instance=instance) LOG.debug('Provider Firewall Rules refreshed', instance=instance) LOG.debug('Adding security group rule: %r', rule, instance=instance) LOG.debug('Using cidr %r', rule['cidr'], instance=instance) LOG.debug('Using fw_rules: %r', fw_rules, instance=instance) ",6,9
openstack%2Fnova~master~I1199b5f9428f3fad196bd10331b268f9a3eddcf9,openstack/nova,master,I1199b5f9428f3fad196bd10331b268f9a3eddcf9,VMware: remove duplicate key from test_instance dict,MERGED,2014-07-01 13:36:54.000000000,2014-07-17 06:50:48.000000000,2014-07-17 06:50:45.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6167}, {'_account_id': 7239}, {'_account_id': 7400}, {'_account_id': 8027}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-01 13:36:54.000000000', 'files': ['nova/tests/virt/vmwareapi/test_configdrive.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8e2d1eb71570b0940f1abaece5eb08a95328c84f', 'message': ""VMware: remove duplicate key from test_instance dict\n\nRemove the duplicate 'node' key from test_instance dict\n\nChange-Id: I1199b5f9428f3fad196bd10331b268f9a3eddcf9\n""}]",0,103890,8e2d1eb71570b0940f1abaece5eb08a95328c84f,26,13,1,9172,,,0,"VMware: remove duplicate key from test_instance dict

Remove the duplicate 'node' key from test_instance dict

Change-Id: I1199b5f9428f3fad196bd10331b268f9a3eddcf9
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/103890/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/vmwareapi/test_configdrive.py'],1,8e2d1eb71570b0940f1abaece5eb08a95328c84f,rm-dup-key," self.test_instance = {'vm_state': 'building',"," self.test_instance = {'node': 'test_url', 'vm_state': 'building',",1,2
openstack%2Fnova~master~I2d1f975633c8b2cb9e2e744c5f769b8f753b5968,openstack/nova,master,I2d1f975633c8b2cb9e2e744c5f769b8f753b5968,Add 'anon' kwarg to FakeDbBlockDeviceDict class,MERGED,2014-06-07 20:03:58.000000000,2014-07-17 06:46:25.000000000,2014-07-17 06:46:23.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-06-07 20:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/50c5cf2775b7267e00ef438680f546e62fb5ba8d', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 2, 'created': '2014-06-09 13:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d55425fcb1af1c3082666dfe763147c047a1b0e2', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 3, 'created': '2014-06-11 16:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db4c7468f8ade99508dca396c63b021094a7ee20', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 4, 'created': '2014-06-12 07:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e836db4871e267c4275864ac8987989afdcd1e2', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 5, 'created': '2014-06-13 07:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db9ae27edc9e8d34c9c5f7fd6440f72a358a2311', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 6, 'created': '2014-06-13 15:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19f6ce53b41f594f245235c3e8e3e67f89be005e', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 7, 'created': '2014-06-16 10:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f258aca27cfd93d0fcf98520d0517a631d2a01cc', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 8, 'created': '2014-06-17 10:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7e35facd5d6e5280cca298dd170451fa6305325', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 9, 'created': '2014-06-17 11:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a53d94aa88b65e7485980fcdf8d6c5fa33ed3db5', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 10, 'created': '2014-07-02 13:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71f886eb072ff068796ddbcf89fb3a2e9c131c18', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 11, 'created': '2014-07-03 07:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14bc4f3d8bce2898b9d7430fa644a082b4e720e1', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}, {'number': 12, 'created': '2014-07-04 16:18:10.000000000', 'files': ['nova/tests/fake_block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f38a27c211158738dec02e4a933bf9a68cedfb14', 'message': ""Add 'anon' kwarg to FakeDbBlockDeviceDict class\n\nThis will allow us to create fake block devices without the database id\nfield, so we can pass them to BDM objects in our test  which can then\ncall create(). create() would normally error out if there is a DB id set\non the object.\n\nChange-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968\n""}]",0,98606,f38a27c211158738dec02e4a933bf9a68cedfb14,147,13,12,5511,,,0,"Add 'anon' kwarg to FakeDbBlockDeviceDict class

This will allow us to create fake block devices without the database id
field, so we can pass them to BDM objects in our test  which can then
call create(). create() would normally error out if there is a DB id set
on the object.

Change-Id: I2d1f975633c8b2cb9e2e744c5f769b8f753b5968
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/98606/12 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/fake_block_device.py'],1,50c5cf2775b7267e00ef438680f546e62fb5ba8d,bp/compute-manager-objects-juno," def __init__(self, bdm_dict=None, anon=False, **kwargs): fake_db_fields = {'instance_uuid': instance_uuid, if not anon: fake_db_fields['id'] = db_id fake_db_fields['created_at'] = timeutils.utcnow() fake_db_fields['updated_at'] = timeutils.utcnow() def AnonFakeDbBlockDeviceDict(bdm_dict, **kwargs): return FakeDbBlockDeviceDict(bdm_dict=bdm_dict, anon=True, **kwargs)"," def __init__(self, bdm_dict=None, **kwargs): fake_db_fields = {'id': db_id, 'instance_uuid': instance_uuid, 'created_at': timeutils.utcnow(), 'updated_at': timeutils.utcnow(),",10,4
openstack%2Fsahara~master~Ibc42553bf3730e02a4c98bdfad1509f16d16cb61,openstack/sahara,master,Ibc42553bf3730e02a4c98bdfad1509f16d16cb61,Update oslo-incubator db.sqlalchemy module,MERGED,2014-07-11 03:37:46.000000000,2014-07-17 06:38:51.000000000,2014-07-17 06:38:50.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7491}, {'_account_id': 7555}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-11 03:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ef83b597a4a49862337b8df4ca9eb4f324d3ae60', 'message': 'Update oslo-incubator db.sqlalchemy module\n\nChanges -\n * pep8: fixed multiple violations\n * Prevent races in opportunistic db test cases\n * Fix Sphinx directive name\n\nChange-Id: Ibc42553bf3730e02a4c98bdfad1509f16d16cb61\n'}, {'number': 2, 'created': '2014-07-11 05:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a3d3720b59e7c6eabb2c335a51d7b0f0eadd17fe', 'message': 'Update oslo-incubator db.sqlalchemy module\n\nChanges -\n * pep8: fixed multiple violations\n * Prevent races in opportunistic db test cases\n * Fix Sphinx directive name\n\nChange-Id: Ibc42553bf3730e02a4c98bdfad1509f16d16cb61\n'}, {'number': 3, 'created': '2014-07-11 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f210a20ace2ec11951fd0b34da6c0ca7d362bbe7', 'message': 'Update oslo-incubator db.sqlalchemy module\n\nChanges -\n * pep8: fixed multiple violations\n * Prevent races in opportunistic db test cases\n * Fix Sphinx directive name\n\nChange-Id: Ibc42553bf3730e02a4c98bdfad1509f16d16cb61\n'}, {'number': 4, 'created': '2014-07-14 14:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/77af255ecb318816c4581f4a412c2a4e3ba03910', 'message': 'Update oslo-incubator db.sqlalchemy module\n\nChanges -\n * pep8: fixed multiple violations\n * Prevent races in opportunistic db test cases\n * Fix Sphinx directive name\n\nChange-Id: Ibc42553bf3730e02a4c98bdfad1509f16d16cb61\n'}, {'number': 5, 'created': '2014-07-16 18:05:57.000000000', 'files': ['sahara/openstack/common/db/sqlalchemy/test_migrations.py', 'sahara/openstack/common/db/sqlalchemy/session.py', 'sahara/openstack/common/db/sqlalchemy/test_base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9600e7eb60fcb4699a367d959d7463e52d3d74c3', 'message': 'Update oslo-incubator db.sqlalchemy module\n\nChanges -\n * pep8: fixed multiple violations\n * Prevent races in opportunistic db test cases\n * Fix Sphinx directive name\n\nChange-Id: Ibc42553bf3730e02a4c98bdfad1509f16d16cb61\n'}]",0,106267,9600e7eb60fcb4699a367d959d7463e52d3d74c3,54,11,5,7555,,,0,"Update oslo-incubator db.sqlalchemy module

Changes -
 * pep8: fixed multiple violations
 * Prevent races in opportunistic db test cases
 * Fix Sphinx directive name

Change-Id: Ibc42553bf3730e02a4c98bdfad1509f16d16cb61
",git fetch https://review.opendev.org/openstack/sahara refs/changes/67/106267/5 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/openstack/common/db/sqlalchemy/test_migrations.py', 'sahara/openstack/common/db/sqlalchemy/session.py', 'sahara/openstack/common/db/sqlalchemy/test_base.py']",3,ef83b597a4a49862337b8df4ca9eb4f324d3ae60,oslo-sync," DBNAME = '' # connect to MySQL server, but not to the openstack_citest db DBNAME = 'postgres' # PostgreSQL requires the db name here,use service one",,18,14
openstack%2Fsahara~master~I75260a6401c86a1cbf54cd48ce6dbfe58baea784,openstack/sahara,master,I75260a6401c86a1cbf54cd48ce6dbfe58baea784,Update oslo-incubator threadgroup modules,MERGED,2014-07-11 03:37:46.000000000,2014-07-17 06:38:44.000000000,2014-07-17 06:38:43.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-11 03:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/6e7405c0c2e25d2fc6479738bb780ae9acb7bad4', 'message': 'Update oslo-incubator threadgroup modules\n\nChanges -\n * Make stop_timers() method public\n *  Add graceful stop function to ThreadGroup.stop\n\nChange-Id: I75260a6401c86a1cbf54cd48ce6dbfe58baea784\n'}, {'number': 2, 'created': '2014-07-11 05:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ebfb597432574094b4028a2d6e2fde9c0961ce8d', 'message': 'Update oslo-incubator threadgroup modules\n\nChanges -\n * Make stop_timers() method public\n *  Add graceful stop function to ThreadGroup.stop\n\nChange-Id: I75260a6401c86a1cbf54cd48ce6dbfe58baea784\n'}, {'number': 3, 'created': '2014-07-11 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/42a68955616c6e877aa15a5c5d5b45806b86b5d9', 'message': 'Update oslo-incubator threadgroup modules\n\nChanges -\n * Make stop_timers() method public\n *  Add graceful stop function to ThreadGroup.stop\n\nChange-Id: I75260a6401c86a1cbf54cd48ce6dbfe58baea784\n'}, {'number': 4, 'created': '2014-07-14 14:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a703ffd8aed1812ee7144f9864192b0c04bb45fa', 'message': 'Update oslo-incubator threadgroup modules\n\nChanges -\n * Make stop_timers() method public\n *  Add graceful stop function to ThreadGroup.stop\n\nChange-Id: I75260a6401c86a1cbf54cd48ce6dbfe58baea784\n'}, {'number': 5, 'created': '2014-07-16 18:05:57.000000000', 'files': ['sahara/openstack/common/threadgroup.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/5d06e35a524bedbfaea59beb653482b90f6cb4ed', 'message': 'Update oslo-incubator threadgroup modules\n\nChanges -\n * Make stop_timers() method public\n *  Add graceful stop function to ThreadGroup.stop\n\nChange-Id: I75260a6401c86a1cbf54cd48ce6dbfe58baea784\n'}]",0,106266,5d06e35a524bedbfaea59beb653482b90f6cb4ed,49,10,5,7555,,,0,"Update oslo-incubator threadgroup modules

Changes -
 * Make stop_timers() method public
 *  Add graceful stop function to ThreadGroup.stop

Change-Id: I75260a6401c86a1cbf54cd48ce6dbfe58baea784
",git fetch https://review.opendev.org/openstack/sahara refs/changes/66/106266/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/threadgroup.py'],1,6e7405c0c2e25d2fc6479738bb780ae9acb7bad4,oslo-sync," def _stop_threads(self): def stop_timers(self): def stop(self, graceful=False): """"""stop function has the option of graceful=True/False. * In case of graceful=True, wait for all threads to be finished. Never kill threads. * In case of graceful=False, kill threads immediately. """""" self.stop_timers() if graceful: # In case of graceful=True, wait for all threads to be # finished, never kill threads self.wait() else: # In case of graceful=False(Default), kill threads # immediately self._stop_threads() ", def stop(self):,19,1
openstack%2Fpython-keystoneclient~master~I8cfbea37964e3d96cc444ad6f62542786429e44b,openstack/python-keystoneclient,master,I8cfbea37964e3d96cc444ad6f62542786429e44b,Add v2 Token manager authenticate tests,MERGED,2014-07-04 06:35:36.000000000,2014-07-17 06:38:41.000000000,2014-07-17 06:38:40.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 11333}, {'_account_id': 11589}]","[{'number': 1, 'created': '2014-07-04 06:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e1119425c5f72f381c89c4e099044cb3eaf94b63', 'message': 'Add v2 Token manager authenticate tests\n\nThis function is currently completely untested. Create tests to\nreinforce behaviour.\n\nChange-Id: I8cfbea37964e3d96cc444ad6f62542786429e44b\n'}, {'number': 2, 'created': '2014-07-04 06:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/918be2f96e0a921d21fe6e8247105bf13bc4195f', 'message': 'Add v2 Token manager authenticate tests\n\nThis function is currently completely untested. Create tests to\nreinforce behaviour.\n\nChange-Id: I8cfbea37964e3d96cc444ad6f62542786429e44b\n'}, {'number': 3, 'created': '2014-07-14 00:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f8013322ace12031d60936fd3f1d7f2eb77e1407', 'message': 'Add v2 Token manager authenticate tests\n\nThis function is currently completely untested. Create tests to\nreinforce behaviour.\n\nChange-Id: I8cfbea37964e3d96cc444ad6f62542786429e44b\n'}, {'number': 4, 'created': '2014-07-14 18:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/8e4756cfeacf34334ddc6e03266aa43a93f2d099', 'message': 'Add v2 Token manager authenticate tests\n\nThis function is currently completely untested. Create tests to\nreinforce behaviour.\n\nChange-Id: I8cfbea37964e3d96cc444ad6f62542786429e44b\n'}, {'number': 5, 'created': '2014-07-14 23:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/723c4630e541f38ba74d92600d62351f8f7196ba', 'message': 'Add v2 Token manager authenticate tests\n\nThis function is currently completely untested. Create tests to\nreinforce behaviour.\n\nChange-Id: I8cfbea37964e3d96cc444ad6f62542786429e44b\n'}, {'number': 6, 'created': '2014-07-15 03:31:28.000000000', 'files': ['keystoneclient/tests/v2_0/test_tokens.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/976b126c1e18c260008909509a9c551fb6c55ab7', 'message': 'Add v2 Token manager authenticate tests\n\nThis function is currently completely untested. Create tests to\nreinforce behaviour.\n\nChange-Id: I8cfbea37964e3d96cc444ad6f62542786429e44b\n'}]",2,104769,976b126c1e18c260008909509a9c551fb6c55ab7,33,8,6,7191,,,0,"Add v2 Token manager authenticate tests

This function is currently completely untested. Create tests to
reinforce behaviour.

Change-Id: I8cfbea37964e3d96cc444ad6f62542786429e44b
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/69/104769/6 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/tests/v2_0/test_tokens.py'],1,e1119425c5f72f381c89c4e099044cb3eaf94b63,adapter,"from keystoneclient import fixturefrom keystoneclient.v2_0 import client from keystoneclient.v2_0 import tokens @httpretty.activate def test_user_password(self): token_fixture = fixture.V2Token(user_name=self.TEST_USER) self.stub_auth(json=token_fixture) password = uuid.uuid4().hex token_ref = self.client.tokens.authenticate(username=self.TEST_USER, password=password) self.assertIsInstance(token_ref, tokens.Token) self.assertEqual(token_fixture.token_id, token_ref.id) self.assertEqual(token_fixture.expires_str, token_ref.expires) req_body = { 'auth': { 'passwordCredentials': { 'username': self.TEST_USER, 'password': password, } } } self.assertRequestBodyIs(json=req_body) @httpretty.activate def test_with_token_id(self): token_fixture = fixture.V2Token() self.stub_auth(json=token_fixture) token_id = uuid.uuid4().hex token_ref = self.client.tokens.authenticate(token=token_id) self.assertIsInstance(token_ref, tokens.Token) self.assertEqual(token_fixture.token_id, token_ref.id) self.assertEqual(token_fixture.expires_str, token_ref.expires) req_body = { 'auth': { 'token': { 'id': token_id, } } } self.assertRequestBodyIs(json=req_body) def test_without_auth_params(self): self.assertRaises(ValueError, self.client.tokens.authenticate) self.assertRaises(ValueError, self.client.tokens.authenticate, tenant_id=uuid.uuid4().hex) @httpretty.activate def test_with_tenant_id(self): token_fixture = fixture.V2Token() token_fixture.set_scope() self.stub_auth(json=token_fixture) token_id = uuid.uuid4().hex tenant_id = uuid.uuid4().hex token_ref = self.client.tokens.authenticate(token=token_id, tenant_id=tenant_id) self.assertIsInstance(token_ref, tokens.Token) self.assertEqual(token_fixture.token_id, token_ref.id) self.assertEqual(token_fixture.expires_str, token_ref.expires) tenant_data = {'id': token_fixture.tenant_id, 'name': token_fixture.tenant_name} self.assertEqual(tenant_data, token_ref.tenant) req_body = { 'auth': { 'token': { 'id': token_id, }, 'tenantId': tenant_id } } self.assertRequestBodyIs(json=req_body) @httpretty.activate def test_with_tenant_name(self): token_fixture = fixture.V2Token() token_fixture.set_scope() self.stub_auth(json=token_fixture) token_id = uuid.uuid4().hex tenant_name = uuid.uuid4().hex token_ref = self.client.tokens.authenticate(token=token_id, tenant_name=tenant_name) self.assertIsInstance(token_ref, tokens.Token) self.assertEqual(token_fixture.token_id, token_ref.id) self.assertEqual(token_fixture.expires_str, token_ref.expires) tenant_data = {'id': token_fixture.tenant_id, 'name': token_fixture.tenant_name} self.assertEqual(tenant_data, token_ref.tenant) req_body = { 'auth': { 'token': { 'id': token_id, }, 'tenantName': tenant_name } } self.assertRequestBodyIs(json=req_body) @httpretty.activate def test_authenticate_use_admin_url(self): token_fixture = fixture.V2Token() token_fixture.set_scope() self.stub_auth(json=token_fixture) self.assertEqual(self.TEST_URL, self.client.management_url) token_ref = self.client.tokens.authenticate(token=uuid.uuid4().hex) self.assertIsInstance(token_ref, tokens.Token) self.assertEqual(token_fixture.token_id, token_ref.id) self.assertEqual(token_fixture.expires_str, token_ref.expires) @httpretty.activate def test_authenticate_fallback_to_auth_url(self): new_auth_url = 'http://keystone.test:5000/v2.0' token_fixture = fixture.V2Token() self.stub_auth(base_url=new_auth_url, json=token_fixture) c = client.Client(username=self.TEST_USER, auth_url=new_auth_url, password=uuid.uuid4().hex) self.assertIsNone(c.management_url) token_ref = c.tokens.authenticate(token=uuid.uuid4().hex) self.assertIsInstance(token_ref, tokens.Token) self.assertEqual(token_fixture.token_id, token_ref.id) self.assertEqual(token_fixture.expires_str, token_ref.expires)",,146,0
openstack%2Fsahara~master~Ic4b65ffc35ecea3580c984e5417e1ecdcf9c95ca,openstack/sahara,master,Ic4b65ffc35ecea3580c984e5417e1ecdcf9c95ca,Update oslo-incubator processutils module,MERGED,2014-07-11 03:37:46.000000000,2014-07-17 06:38:39.000000000,2014-07-17 06:38:38.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-11 03:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2c5f20a8e7d25a3e94a2e3c0f93725d1202c96d6', 'message': 'Update oslo-incubator processutils module\n\nChanges -\n * Fix exception message in openstack.common.processutils.execute\n * Remove `processutils` dependency on `log`\n * Fix broken formatting of processutils.execute log statement\n * Move nova.utils.cpu_count() to processutils module\n\nChange-Id: Ic4b65ffc35ecea3580c984e5417e1ecdcf9c95ca\n'}, {'number': 2, 'created': '2014-07-11 05:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/46d362e3bbae95e5b403d092f22f1568424d41e7', 'message': 'Update oslo-incubator processutils module\n\nChanges -\n * Fix exception message in openstack.common.processutils.execute\n * Remove `processutils` dependency on `log`\n * Fix broken formatting of processutils.execute log statement\n * Move nova.utils.cpu_count() to processutils module\n\nChange-Id: Ic4b65ffc35ecea3580c984e5417e1ecdcf9c95ca\n'}, {'number': 3, 'created': '2014-07-11 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d5f4ad805180ac2712f0d26e7c68cf06cf416d04', 'message': 'Update oslo-incubator processutils module\n\nChanges -\n * Fix exception message in openstack.common.processutils.execute\n * Remove `processutils` dependency on `log`\n * Fix broken formatting of processutils.execute log statement\n * Move nova.utils.cpu_count() to processutils module\n\nChange-Id: Ic4b65ffc35ecea3580c984e5417e1ecdcf9c95ca\n'}, {'number': 4, 'created': '2014-07-14 14:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/02b91b81c850ec00638eb16e826ec24f184b65d7', 'message': 'Update oslo-incubator processutils module\n\nChanges -\n * Fix exception message in openstack.common.processutils.execute\n * Remove `processutils` dependency on `log`\n * Fix broken formatting of processutils.execute log statement\n * Move nova.utils.cpu_count() to processutils module\n\nChange-Id: Ic4b65ffc35ecea3580c984e5417e1ecdcf9c95ca\n'}, {'number': 5, 'created': '2014-07-16 18:05:57.000000000', 'files': ['sahara/openstack/common/processutils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/84b826a7a12ead1d37b0dc95685f8ce4797f1050', 'message': 'Update oslo-incubator processutils module\n\nChanges -\n * Fix exception message in openstack.common.processutils.execute\n * Remove `processutils` dependency on `log`\n * Fix broken formatting of processutils.execute log statement\n * Move nova.utils.cpu_count() to processutils module\n\nChange-Id: Ic4b65ffc35ecea3580c984e5417e1ecdcf9c95ca\n'}]",0,106265,84b826a7a12ead1d37b0dc95685f8ce4797f1050,43,10,5,7555,,,0,"Update oslo-incubator processutils module

Changes -
 * Fix exception message in openstack.common.processutils.execute
 * Remove `processutils` dependency on `log`
 * Fix broken formatting of processutils.execute log statement
 * Move nova.utils.cpu_count() to processutils module

Change-Id: Ic4b65ffc35ecea3580c984e5417e1ecdcf9c95ca
",git fetch https://review.opendev.org/openstack/sahara refs/changes/65/106265/3 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/processutils.py'],1,2c5f20a8e7d25a3e94a2e3c0f93725d1202c96d6,oslo-sync,"import logging import multiprocessingfrom sahara.openstack.common import strutils :param env_variables: Environment variables and their values that will be set for the process. :type env_variables: dict :type loglevel: int. (Should be logging.DEBUG or logging.INFO) env_variables = kwargs.pop('env_variables', None) loglevel = kwargs.pop('loglevel', logging.DEBUG) raise UnknownArgumentError(_('Got unknown keyword args: %r') % kwargs) strutils.mask_password(' '.join(cmd))) shell=shell, env=env_variables) out, err = '', six.text_type(exn) def get_worker_count(): """"""Utility to get the default worker count. @return: The number of CPUs if that can be determined, else a default worker count of 1 is returned. """""" try: return multiprocessing.cpu_count() except NotImplementedError: return 1","import logging as stdlib_loggingfrom sahara.openstack.common import log as logging :type loglevel: int. (Should be stdlib_logging.DEBUG or stdlib_logging.INFO) loglevel = kwargs.pop('loglevel', stdlib_logging.DEBUG) raise UnknownArgumentError(_('Got unknown keyword args ' 'to utils.execute: %r') % kwargs) ' '.join(cmd)) shell=shell) out, err = '', str(exn)",26,10
openstack%2Fsahara~master~Iab11103942ebe9b2e94c68f97f885a0877e206bb,openstack/sahara,master,Iab11103942ebe9b2e94c68f97f885a0877e206bb,Update oslo-incubator periodic_task module,MERGED,2014-07-11 03:37:45.000000000,2014-07-17 06:38:37.000000000,2014-07-17 06:38:37.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-11 03:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/58b2d909d05b38e126a46a0c00ca02e57c044bfe', 'message': 'Update oslo-incubator periodic_task module\n\nChanges -\n * Make periodic tasks run on regular spacing interval\n * Fix parenthesis typo misunderstanding in periodic_task\n\nChange-Id: Iab11103942ebe9b2e94c68f97f885a0877e206bb\n'}, {'number': 2, 'created': '2014-07-11 05:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7d3888c82019a6606d82c562c0b6fdb87030ceab', 'message': 'Update oslo-incubator periodic_task module\n\nChanges -\n * Make periodic tasks run on regular spacing interval\n * Fix parenthesis typo misunderstanding in periodic_task\n\nChange-Id: Iab11103942ebe9b2e94c68f97f885a0877e206bb\n'}, {'number': 3, 'created': '2014-07-11 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/fc0d059c6e6216524fbb49048849cb5b3ae58ea7', 'message': 'Update oslo-incubator periodic_task module\n\nChanges -\n * Make periodic tasks run on regular spacing interval\n * Fix parenthesis typo misunderstanding in periodic_task\n\nChange-Id: Iab11103942ebe9b2e94c68f97f885a0877e206bb\n'}, {'number': 4, 'created': '2014-07-14 14:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d270dcf970a9f6f2c325eec8d96db6976db94971', 'message': 'Update oslo-incubator periodic_task module\n\nChanges -\n * Make periodic tasks run on regular spacing interval\n * Fix parenthesis typo misunderstanding in periodic_task\n\nChange-Id: Iab11103942ebe9b2e94c68f97f885a0877e206bb\n'}, {'number': 5, 'created': '2014-07-16 18:05:57.000000000', 'files': ['sahara/openstack/common/periodic_task.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/5b8cc7dd70e11c1b05121ad13308e8018dc9ac0b', 'message': 'Update oslo-incubator periodic_task module\n\nChanges -\n * Make periodic tasks run on regular spacing interval\n * Fix parenthesis typo misunderstanding in periodic_task\n\nChange-Id: Iab11103942ebe9b2e94c68f97f885a0877e206bb\n'}]",0,106264,5b8cc7dd70e11c1b05121ad13308e8018dc9ac0b,43,10,5,7555,,,0,"Update oslo-incubator periodic_task module

Changes -
 * Make periodic tasks run on regular spacing interval
 * Fix parenthesis typo misunderstanding in periodic_task

Change-Id: Iab11103942ebe9b2e94c68f97f885a0877e206bb
",git fetch https://review.opendev.org/openstack/sahara refs/changes/64/106264/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/periodic_task.py'],1,58b2d909d05b38e126a46a0c00ca02e57c044bfe,oslo-sync,"import random help='Some periodic tasks can be run in a separate process. ' 'Should we run them here?'), 1. Without arguments '@periodic_task', this will be run on the default interval of 60 seconds. # and without parenthesis. # In the 'with-parenthesis' case (with kwargs present), this function needs # to return a decorator function since the interpreter will invoke it like: # In the 'without-parenthesis' case, the original function will be passed # be run on the default interval to avoid running too # frequently. if task._periodic_spacing == 0: task._periodic_spacing = DEFAULT_INTERVALdef _nearest_boundary(last_run, spacing): """"""Find nearest boundary which is in the past, which is a multiple of the spacing with the last run as an offset. Eg if last run was 10 and spacing was 7, the new last run could be: 17, 24, 31, 38... 0% to 5% of the spacing value will be added to this value to ensure tasks do not synchronize. This jitter is rounded to the nearest second, this means that spacings smaller than 20 seconds will not have jitter. """""" current_time = time.time() if last_run is None: return current_time delta = current_time - last_run offset = delta % spacing # Add up to 5% jitter jitter = int(spacing * (random.random() / 20)) return current_time - offset + jitter # Check if due, if not skip idle_for = min(idle_for, spacing) if last_run is not None: delta = last_run + spacing - time.time() if delta > 0: idle_for = min(idle_for, delta) continue self._periodic_last_run[task_name] = _nearest_boundary( last_run, spacing)"," help=('Some periodic tasks can be run in a separate process. ' 'Should we run them here?')), 1. Without arguments '@periodic_task', this will be run on every cycle of the periodic scheduler. # and without parents. # In the 'with-parents' case (with kwargs present), this function needs to # return a decorator function since the interpreter will invoke it like: # In the 'without-parents' case, the original function will be passed # be run every pass if task._periodic_spacing == 0: task._periodic_spacing = None # If a periodic task is _nearly_ due, then we'll run it early if spacing is not None: idle_for = min(idle_for, spacing) if last_run is not None: delta = last_run + spacing - time.time() if delta > 0.2: idle_for = min(idle_for, delta) continue self._periodic_last_run[task_name] = time.time()",42,19
openstack%2Fsahara~master~I98bc7190b3ff63ac37b0993ccffffadd1163a89c,openstack/sahara,master,I98bc7190b3ff63ac37b0993ccffffadd1163a89c,Update oslo-incubator network_utils module,MERGED,2014-07-11 03:37:45.000000000,2014-07-17 06:38:30.000000000,2014-07-17 06:38:29.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-11 03:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/05aa4715fe323ada80b0c6999fb52e467544404f', 'message': ""Update oslo-incubator network_utils module\n\nChanges -\n * Use the standard python logging in network_utils\n * Set pbr 'warnerrors' option for doc build\n * Avoid raising index error when no host\n\nChange-Id: I98bc7190b3ff63ac37b0993ccffffadd1163a89c\n""}, {'number': 2, 'created': '2014-07-11 05:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/cd014449ca1d99f585e72ce59f024a4fa6f05e47', 'message': ""Update oslo-incubator network_utils module\n\nChanges -\n * Use the standard python logging in network_utils\n * Set pbr 'warnerrors' option for doc build\n * Avoid raising index error when no host\n\nChange-Id: I98bc7190b3ff63ac37b0993ccffffadd1163a89c\n""}, {'number': 3, 'created': '2014-07-11 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/42e7d646fbdc71ef80b49d9cb97e4b5838a7e26a', 'message': ""Update oslo-incubator network_utils module\n\nChanges -\n * Use the standard python logging in network_utils\n * Set pbr 'warnerrors' option for doc build\n * Avoid raising index error when no host\n\nChange-Id: I98bc7190b3ff63ac37b0993ccffffadd1163a89c\n""}, {'number': 4, 'created': '2014-07-14 14:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/949798750992b3082d6db0a57d0d5f96a6f3e9da', 'message': ""Update oslo-incubator network_utils module\n\nChanges -\n * Use the standard python logging in network_utils\n * Set pbr 'warnerrors' option for doc build\n * Avoid raising index error when no host\n\nChange-Id: I98bc7190b3ff63ac37b0993ccffffadd1163a89c\n""}, {'number': 5, 'created': '2014-07-16 18:05:57.000000000', 'files': ['sahara/openstack/common/network_utils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/8371dfa0cbe2959b3fd492ba58fca3cc2c5e3549', 'message': ""Update oslo-incubator network_utils module\n\nChanges -\n * Use the standard python logging in network_utils\n * Set pbr 'warnerrors' option for doc build\n * Avoid raising index error when no host\n\nChange-Id: I98bc7190b3ff63ac37b0993ccffffadd1163a89c\n""}]",0,106263,8371dfa0cbe2959b3fd492ba58fca3cc2c5e3549,51,10,5,7555,,,0,"Update oslo-incubator network_utils module

Changes -
 * Use the standard python logging in network_utils
 * Set pbr 'warnerrors' option for doc build
 * Avoid raising index error when no host

Change-Id: I98bc7190b3ff63ac37b0993ccffffadd1163a89c
",git fetch https://review.opendev.org/openstack/sahara refs/changes/63/106263/4 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/network_utils.py'],1,05aa4715fe323ada80b0c6999fb52e467544404f,oslo-sync,"import logging import socket from six.moves.urllib import parse from sahara.openstack.common.gettextutils import _LW LOG = logging.getLogger(__name__) >>> parse_host_port(None) (None, None) if not address: return (None, None) class ModifiedSplitResult(parse.SplitResult): """"""Split results class for urlsplit."""""" # NOTE(dims): The functions below are needed for Python 2.6.x. # We can remove these when we drop support for 2.6.x. @property def hostname(self): netloc = self.netloc.split('@', 1)[-1] host, port = parse_host_port(netloc) return host @property def port(self): netloc = self.netloc.split('@', 1)[-1] host, port = parse_host_port(netloc) return port scheme, netloc, path, query, fragment = parse.urlsplit( return ModifiedSplitResult(scheme, netloc, path, query, fragment) def set_tcp_keepalive(sock, tcp_keepalive=True, tcp_keepidle=None, tcp_keepalive_interval=None, tcp_keepalive_count=None): """"""Set values for tcp keepalive parameters This function configures tcp keepalive parameters if users wish to do so. :param tcp_keepalive: Boolean, turn on or off tcp_keepalive. If users are not sure, this should be True, and default values will be used. :param tcp_keepidle: time to wait before starting to send keepalive probes :param tcp_keepalive_interval: time between successive probes, once the initial wait time is over :param tcp_keepalive_count: number of probes to send before the connection is killed """""" # NOTE(praneshp): Despite keepalive being a tcp concept, the level is # still SOL_SOCKET. This is a quirk. if isinstance(tcp_keepalive, bool): sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, tcp_keepalive) else: raise TypeError(""tcp_keepalive must be a boolean"") if not tcp_keepalive: return # These options aren't available in the OS X version of eventlet, # Idle + Count * Interval effectively gives you the total timeout. if tcp_keepidle is not None: if hasattr(socket, 'TCP_KEEPIDLE'): sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPIDLE, tcp_keepidle) else: LOG.warning(_LW('tcp_keepidle not available on your system')) if tcp_keepalive_interval is not None: if hasattr(socket, 'TCP_KEEPINTVL'): sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPINTVL, tcp_keepalive_interval) else: LOG.warning(_LW('tcp_keepintvl not available on your system')) if tcp_keepalive_count is not None: if hasattr(socket, 'TCP_KEEPCNT'): sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPCNT, tcp_keepalive_count) else: LOG.warning(_LW('tcp_keepknt not available on your system'))","# vim: tabstop=4 shiftwidth=4 softtabstop=4 import urlparse scheme, netloc, path, query, fragment = urlparse.urlsplit( return urlparse.SplitResult(scheme, netloc, path, query, fragment)",88,6
openstack%2Fkeystone~master~I4711e8670bf9619b9bccc09bd6a843728230b25f,openstack/keystone,master,I4711e8670bf9619b9bccc09bd6a843728230b25f,Migrate default extensions,MERGED,2014-05-29 01:30:42.000000000,2014-07-17 06:38:00.000000000,2014-07-17 06:37:59.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 9751}, {'_account_id': 11045}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-05-29 01:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/83914e30c64ea52fc88fcb6f15f2ee2c5a3ca6d0', 'message': 'Migrate default extensions\n\nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f\n'}, {'number': 2, 'created': '2014-05-29 02:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c3ecc3ea6c3cc4823eeaf8e0c60c20e8ad8d8b84', 'message': 'Migrate default extensions\n\nBug: 1324260\n\nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f\n'}, {'number': 3, 'created': '2014-05-29 02:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c228b698e99918cb1986d87e0f54e489df8ee546', 'message': 'Migrate default extensions\n\nCloses-Bug: 1324260 \nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f'}, {'number': 4, 'created': '2014-06-27 20:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/af69c8cf31386524c9f6f8a2ba33b964e0c4dec4', 'message': 'Migrate default extensions\n\nWhen running \n\nkeystone-manage db_sync \nwith no parameters, the following extensions will also be migrated\n\nendpoint_filter, federation, oauth1, revoke\n\nThese are already in the default pipeline, but are not migrated by the\nmajority of the install tools.\n\n\nCloses-Bug: 1324260 \nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f'}, {'number': 5, 'created': '2014-07-11 14:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3c466036cb993a6f8d5f0c92de66970b09871b4b', 'message': 'Migrate default extensions\n\nWhen running `keystone-manage db_sync` with no parameters, none of the extensions are migrated. \n\nThis patch will now, by default, migrate the following extensions:\n  endpoint_filter, federation, oauth1, revoke\n\nCloses-Bug: 1324260\nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f\n'}, {'number': 6, 'created': '2014-07-11 15:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/87664a980a5ae66a6ec7e0c8af5131eec5bedc22', 'message': 'Migrate default extensions\n\nWhen running `keystone-manage db_sync` with no parameters, none of\nthe extensions are migrated.\n\nThis patch will now, by default, migrate the following extensions:\n  endpoint_filter, federation, oauth1, revoke\n\nCloses-Bug: 1324260\nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f\n'}, {'number': 7, 'created': '2014-07-11 15:36:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b21f39fe7df0a8a5d3a85cfeaf532a12e6dcb5fb', 'message': 'Migrate default extensions\n\nWhen running `keystone-manage db_sync` with no parameters, none of\nthe extensions are migrated.\n\nThis patch will now, by default, migrate the following extensions:\n  endpoint_filter, federation, oauth1, revoke\n\nDocImpact\nCloses-Bug: 1324260\nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f\n'}, {'number': 8, 'created': '2014-07-11 17:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/73393bacc9f345541e194fe7247b2e3fd669b58f', 'message': 'Migrate default extensions\n\nWhen running `keystone-manage db_sync` with no parameters, none of\nthe extensions are migrated.\n\nThis patch will now, by default, migrate the following extensions:\n  endpoint_filter, federation, oauth1, revoke\n\nDocImpact\nCo-Authored-By: Steve Martinelli <stevemar@ca.ibm.com>\nCloses-Bug: 1324260\nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f\n'}, {'number': 9, 'created': '2014-07-11 18:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/36735c45a96e35305bf3a2c98ed678a1cadcd744', 'message': 'Migrate default extensions\n\nWhen running `keystone-manage db_sync` with no parameters, none of\nthe extensions are migrated.\n\nThis patch will now, by default, migrate the following extensions:\n  endpoint_filter, federation, oauth1, revoke\n\nDocImpact\nCo-Authored-By: Steve Martinelli <stevemar@ca.ibm.com>\nCloses-Bug: 1324260\nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f\n'}, {'number': 10, 'created': '2014-07-11 18:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f0f07a494d96864780652839f6e507d89e02cd85', 'message': 'Migrate default extensions\n\nWhen running `keystone-manage db_sync` with no parameters, none of\nthe extensions are migrated.\n\nThis patch will now, by default, migrate the following extensions:\n  endpoint_filter, federation, oauth1, revoke\n\nDocImpact\nCo-Authored-By: Steve Martinelli <stevemar@ca.ibm.com>\nCloses-Bug: 1324260\nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f\n'}, {'number': 11, 'created': '2014-07-11 19:15:13.000000000', 'files': ['keystone/common/sql/migration_helpers.py', 'keystone/tests/test_sql_upgrade.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/48bb31d3be1afd0f96023041e529758c3056fae8', 'message': 'Migrate default extensions\n\nWhen running `keystone-manage db_sync` with no parameters, none of\nthe extensions are migrated.\n\nThis patch will now, by default, migrate the following extensions:\n  revoke\n\nDocImpact\nCo-Authored-By: Steve Martinelli <stevemar@ca.ibm.com>\nCloses-Bug: 1324260\nChange-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f\n'}]",7,96326,48bb31d3be1afd0f96023041e529758c3056fae8,58,15,11,2218,,,0,"Migrate default extensions

When running `keystone-manage db_sync` with no parameters, none of
the extensions are migrated.

This patch will now, by default, migrate the following extensions:
  revoke

DocImpact
Co-Authored-By: Steve Martinelli <stevemar@ca.ibm.com>
Closes-Bug: 1324260
Change-Id: I4711e8670bf9619b9bccc09bd6a843728230b25f
",git fetch https://review.opendev.org/openstack/keystone refs/changes/26/96326/8 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/sql/migration_helpers.py'],1,83914e30c64ea52fc88fcb6f15f2ee2c5a3ca6d0,bug/1324260,"DEFAULT_EXTENSIONS = ['endpoint_filter', 'federation', 'oauth1', 'revoke']def _sync_common_repo(version): abs_path = find_migrate_repo() init_version = migrate_repo.DB_INIT_VERSIONdef _sync_extension_repo(extension, version): init_version = 0 try: package_name = '.'.join((contrib.__name__, extension)) package = importutils.import_module(package_name) except ImportError: raise ImportError(_(""%s extension does not exist."") % package_name) try: abs_path = find_migrate_repo(package) try: migration.db_version_control(sql.get_engine(), abs_path) # Register the repo with the version control API # If it already knows about the repo, it will throw # an exception that we can safely ignore except exceptions.DatabaseAlreadyControlledError: pass except exception.MigrationNotProvided as e: print(e) sys.exit(1) migration.db_sync(sql.get_engine(), abs_path, version=version, init_version=init_version) def sync_database_to_version(extension=None, version=None): if not extension: _sync_common_repo(version) # If an explicit version > 0 is passed, it is for the common # repository only, and only that will be synchronized. # Syncing to version 0 means erase the database, # so downgrade all default extensions as well. if version is None or version is 0: for default_extension in DEFAULT_EXTENSIONS: _sync_extension_repo(default_extension, version) else: _sync_extension_repo(extension, version) ","def sync_database_to_version(extension=None, version=None): if not extension: abs_path = find_migrate_repo() init_version = migrate_repo.DB_INIT_VERSION else: init_version = 0 try: package_name = '.'.join((contrib.__name__, extension)) package = importutils.import_module(package_name) except ImportError: raise ImportError(_(""%s extension does not exist."") % package_name) try: abs_path = find_migrate_repo(package) try: migration.db_version_control(sql.get_engine(), abs_path) # Register the repo with the version control API # If it already knows about the repo, it will throw # an exception that we can safely ignore except exceptions.DatabaseAlreadyControlledError: pass except exception.MigrationNotProvided as e: print(e) sys.exit(1)",43,24
openstack%2Fnova~master~Ie4f800e05dae9aafd6f0f11ef0f2cd9ecf0d3215,openstack/nova,master,Ie4f800e05dae9aafd6f0f11ef0f2cd9ecf0d3215,move the cloudpipe_update API v2 extension to use objects,MERGED,2014-06-17 21:58:23.000000000,2014-07-17 06:37:48.000000000,2014-07-17 06:37:46.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-17 21:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62b03fde689a514aed3d902ff7a64af507e07963', 'message': 'move the cloudpipe_update API v2 extension to use objects\n\nThis change converts the cloudpipe_update extension to use the Network\nobject instead of direct database access.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ie4f800e05dae9aafd6f0f11ef0f2cd9ecf0d3215\n'}, {'number': 2, 'created': '2014-06-23 17:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64cb1dc332ff932f1c700834d471b0c72da13365', 'message': 'move the cloudpipe_update API v2 extension to use objects\n\nThis change converts the cloudpipe_update extension to use the Network\nobject instead of direct database access.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ie4f800e05dae9aafd6f0f11ef0f2cd9ecf0d3215\n'}, {'number': 3, 'created': '2014-07-16 20:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ec2e9e1a9e8599933790d9f0767b9e7e406941d', 'message': 'move the cloudpipe_update API v2 extension to use objects\n\nThis change converts the cloudpipe_update extension to use the Network\nobject instead of direct database access.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ie4f800e05dae9aafd6f0f11ef0f2cd9ecf0d3215\n'}, {'number': 4, 'created': '2014-07-16 21:06:15.000000000', 'files': ['nova/api/openstack/compute/contrib/cloudpipe_update.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e116bbaebd68a451f41cd86fc8ce4c098bc91952', 'message': 'move the cloudpipe_update API v2 extension to use objects\n\nThis change converts the cloudpipe_update extension to use the Network\nobject instead of direct database access.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ie4f800e05dae9aafd6f0f11ef0f2cd9ecf0d3215\n'}]",5,100705,e116bbaebd68a451f41cd86fc8ce4c098bc91952,55,10,4,4690,,,0,"move the cloudpipe_update API v2 extension to use objects

This change converts the cloudpipe_update extension to use the Network
object instead of direct database access.

Related to blueprint compute-manager-objects-juno

Change-Id: Ie4f800e05dae9aafd6f0f11ef0f2cd9ecf0d3215
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/100705/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/contrib/cloudpipe_update.py'],1,62b03fde689a514aed3d902ff7a64af507e07963,bp/compute-manager-objects-juno,"from nova import objects networks = objects.NetworkList.get_by_project(context, project_id) for network in networks: network.vpn_public_address = vpn_ip network.vpn_public_port = int(vpn_port) network.save()","from nova import db networks = db.project_get_networks(context, project_id) for network in networks: db.network_update(context, network['id'], {'vpn_public_address': vpn_ip, 'vpn_public_port': int(vpn_port)})",5,5
openstack%2Fsolum~master~Ia2de63e72b03d48e6dc541bc982b728684531bb6,openstack/solum,master,Ia2de63e72b03d48e6dc541bc982b728684531bb6,Custom language pack for Go,MERGED,2014-07-16 14:56:31.000000000,2014-07-17 06:25:36.000000000,2014-07-17 06:25:35.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 8443}]","[{'number': 1, 'created': '2014-07-16 14:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/075637626caf7774633b6956b74d713aa02b8924', 'message': 'Custom language pack for Go\n\nChange-Id: Ia2de63e72b03d48e6dc541bc982b728684531bb6\n'}, {'number': 2, 'created': '2014-07-16 14:58:05.000000000', 'files': ['examples/language-packs/go/Dockerfile', 'examples/language-packs/go/testgo.sh', 'examples/language-packs/go/hello.go'], 'web_link': 'https://opendev.org/openstack/solum/commit/a8a7c355f550900fc3abd434c817f87d6d8083af', 'message': 'Custom language pack for Go\n\nChange-Id: Ia2de63e72b03d48e6dc541bc982b728684531bb6\n'}]",0,107415,a8a7c355f550900fc3abd434c817f87d6d8083af,12,5,2,2506,,,0,"Custom language pack for Go

Change-Id: Ia2de63e72b03d48e6dc541bc982b728684531bb6
",git fetch https://review.opendev.org/openstack/solum refs/changes/15/107415/2 && git format-patch -1 --stdout FETCH_HEAD,"['examples/language-packs/go/Dockerfile', 'examples/language-packs/go/testgo.sh', 'examples/language-packs/go/hello.go']",3,075637626caf7774633b6956b74d713aa02b8924,go-language-pack,"package main import ""fmt"" func main() { fmt.Printf(""hello world\n"") }",,33,0
openstack%2Fpython-keystoneclient~master~I7c07bd915fd84cc77cae0004220d8bb8d79bb082,openstack/python-keystoneclient,master,I7c07bd915fd84cc77cae0004220d8bb8d79bb082,Fix mistakes in token fixtures,MERGED,2014-07-16 04:23:30.000000000,2014-07-17 05:52:02.000000000,2014-07-17 05:52:01.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-07-16 04:23:30.000000000', 'files': ['keystoneclient/tests/test_fixtures.py', 'keystoneclient/fixture/v2.py', 'keystoneclient/fixture/v3.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/0ed2eec57f14b7f50e472405d7a78130f124e5af', 'message': 'Fix mistakes in token fixtures\n\nThere are two small mistakes i discovered in the token fixtures. Fix\nthese and add a bunch of new tests that would have caught them earlier.\n\nCloses-Bug: #1342513\nCloses-Bug: #1342515\nChange-Id: I7c07bd915fd84cc77cae0004220d8bb8d79bb082\n'}]",2,107228,0ed2eec57f14b7f50e472405d7a78130f124e5af,8,3,1,7191,,,0,"Fix mistakes in token fixtures

There are two small mistakes i discovered in the token fixtures. Fix
these and add a bunch of new tests that would have caught them earlier.

Closes-Bug: #1342513
Closes-Bug: #1342515
Change-Id: I7c07bd915fd84cc77cae0004220d8bb8d79bb082
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/28/107228/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/tests/test_fixtures.py', 'keystoneclient/fixture/v2.py', 'keystoneclient/fixture/v3.py']",3,0ed2eec57f14b7f50e472405d7a78130f124e5af,fixture-fix," return self.root.get('project', {}).get('domain', {}).get('name')"," return self.root.get('project', {}).get('project', {}).get('name')",239,2
openstack%2Fdevstack~master~I26cbe42ace75554bae993a6d849c3b4ac649c78e,openstack/devstack,master,I26cbe42ace75554bae993a6d849c3b4ac649c78e,add python-mock to testonly package list,MERGED,2014-07-15 08:07:51.000000000,2014-07-17 05:50:12.000000000,2014-07-15 11:06:28.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 866}, {'_account_id': 2750}, {'_account_id': 8052}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-15 08:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1e9eccf3e76ac4f9dece8cd1cdac6122b709d01c', 'message': 'add python-mock to testonly package list\n\nPython-mock is needed by most of OpenStack for testability. Add\nthis is a testonly package. This should fix current issues with\nfunctional tests in OpenStack that use devstack, but not tox to\nrun their tests.\n\nChange-Id: I26cbe42ace75554bae993a6d849c3b4ac649c78e\nCloses-Bug: #1341507\n'}, {'number': 2, 'created': '2014-07-15 08:37:54.000000000', 'files': ['files/apts/general'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0ae54daa4a34502f16cc1751d6ddf8f5f9525171', 'message': 'add python-mock to testonly package list\n\nPython-mock is needed by most of OpenStack for testability. Add\nthis is a testonly package. This should fix current issues with\nfunctional tests in OpenStack that use devstack, but not tox to\nrun their tests.\n\nCloses-Bug: #1341507\n\nChange-Id: I26cbe42ace75554bae993a6d849c3b4ac649c78e\n'}]",0,106956,0ae54daa4a34502f16cc1751d6ddf8f5f9525171,14,7,2,2750,,,0,"add python-mock to testonly package list

Python-mock is needed by most of OpenStack for testability. Add
this is a testonly package. This should fix current issues with
functional tests in OpenStack that use devstack, but not tox to
run their tests.

Closes-Bug: #1341507

Change-Id: I26cbe42ace75554bae993a6d849c3b4ac649c78e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/56/106956/2 && git format-patch -1 --stdout FETCH_HEAD,['files/apts/general'],1,1e9eccf3e76ac4f9dece8cd1cdac6122b709d01c,mock_pkg,python-mock # testonly,,1,0
openstack%2Fpython-keystoneclient~master~Iabc6b7f11dce80a2009cc6a3e4bc6150f582f3da,openstack/python-keystoneclient,master,Iabc6b7f11dce80a2009cc6a3e4bc6150f582f3da,Make Token Data fixtures positional,ABANDONED,2014-06-06 05:00:26.000000000,2014-07-17 05:42:58.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 11045}]","[{'number': 1, 'created': '2014-06-06 05:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/9afd81f0a966fb82dbd15bc22bae46e36cec6b89', 'message': 'Make Token Data fixtures positional\n\nAll this information should be passed as keyword arguments.\n\nChange-Id: Iabc6b7f11dce80a2009cc6a3e4bc6150f582f3da\n'}, {'number': 2, 'created': '2014-06-29 23:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/6b5dc51b99961819efe71b099f29216f832c6ebd', 'message': 'Make Token Data fixtures positional\n\nAll this information should be passed as keyword arguments.\n\nChange-Id: Iabc6b7f11dce80a2009cc6a3e4bc6150f582f3da\n'}, {'number': 3, 'created': '2014-07-09 06:09:18.000000000', 'files': ['keystoneclient/fixture/v2.py', 'keystoneclient/fixture/v3.py', 'keystoneclient/tests/v2_0/client_fixtures.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/69a2347bcfd62c5831083804f6fa98a4ad66ab83', 'message': 'Make Token Data fixtures positional\n\nAll arguments to Token Data fixtures should be passed as keyword\narguments not positional arguments.\n\nChange-Id: Iabc6b7f11dce80a2009cc6a3e4bc6150f582f3da\n'}]",6,98299,69a2347bcfd62c5831083804f6fa98a4ad66ab83,30,7,3,7191,,,0,"Make Token Data fixtures positional

All arguments to Token Data fixtures should be passed as keyword
arguments not positional arguments.

Change-Id: Iabc6b7f11dce80a2009cc6a3e4bc6150f582f3da
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/99/98299/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/fixture/v2.py', 'keystoneclient/fixture/v3.py', 'keystoneclient/tests/v2_0/client_fixtures.py', 'keystoneclient/tests/utils.py']",4,9afd81f0a966fb82dbd15bc22bae46e36cec6b89,positional," class FixturedTestCase(TestCase): client_fixture_class = None data_fixture_class = None def setUp(self): super(FixturedTestCase, self).setUp() httpretty.reset() self.data_fixture = None self.client_fixture = None self.cs = None if self.client_fixture_class: self.client_fixture = self.useFixture(self.client_fixture_class()) self.cs = self.client_fixture.client if self.data_fixture_class: self.data_fixture = self.useFixture(self.data_fixture_class()) def assert_called(self, method, path, body=None): self.assertEqual(httpretty.last_request().method, method) self.assertEqual(httpretty.last_request().path, path) if body: req_data = httpretty.last_request().body if isinstance(req_data, six.binary_type): req_data = req_data.decode('utf-8') if not isinstance(body, six.string_types): # json load if the input body to match against is not a string req_data = jsonutils.loads(req_data) self.assertEqual(req_data, body)",,57,9
openstack-attic%2Fidentity-api~master~Ibc89432b2ef5caebc45c708ab8412d0ff6c1c81d,openstack-attic/identity-api,master,Ibc89432b2ef5caebc45c708ab8412d0ff6c1c81d,Fix typo,MERGED,2014-07-15 18:16:16.000000000,2014-07-17 05:40:25.000000000,2014-07-17 05:40:24.000000000,"[{'_account_id': 3}, {'_account_id': 220}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-07-15 18:16:16.000000000', 'files': ['v2.0/src/ch_identity-general-api-info.xml'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/11dd6310c0fde386caa6b160fa7242af25c9673a', 'message': 'Fix typo\n\nmy -> may\n\nChange-Id: Ibc89432b2ef5caebc45c708ab8412d0ff6c1c81d\nCloses-Bug: #1342064\n'}]",0,107138,11dd6310c0fde386caa6b160fa7242af25c9673a,14,5,1,6547,,,0,"Fix typo

my -> may

Change-Id: Ibc89432b2ef5caebc45c708ab8412d0ff6c1c81d
Closes-Bug: #1342064
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/38/107138/1 && git format-patch -1 --stdout FETCH_HEAD,['v2.0/src/ch_identity-general-api-info.xml'],1,11dd6310c0fde386caa6b160fa7242af25c9673a,bug/1342064, <para>Request and response body data may be encoded with gzip, <para>Request and response body data my be encoded with gzip,1,1
openstack%2Fsecurity-doc~master~I29ebbf94bcaa65b66fdba64b8c8c5221d5c4904b,openstack/security-doc,master,I29ebbf94bcaa65b66fdba64b8c8c5221d5c4904b,Clarify novncproxy encryption support statement,MERGED,2014-07-16 20:38:17.000000000,2014-07-17 05:37:27.000000000,2014-07-17 05:37:27.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2807}, {'_account_id': 7063}]","[{'number': 1, 'created': '2014-07-16 20:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/24862c840f6aa88116939c92800a82376f460c54', 'message': 'Clarify novncproxy encryption support statement\n\nChange-Id: I29ebbf94bcaa65b66fdba64b8c8c5221d5c4904b\nCloses-Bug: #1284473\n'}, {'number': 2, 'created': '2014-07-16 20:39:31.000000000', 'files': ['security-guide/ch_compute.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/7d150b0177e91502d94efe6029baf51b4c68a6f7', 'message': 'Clarify novncproxy encryption support statement\n\nChange-Id: I29ebbf94bcaa65b66fdba64b8c8c5221d5c4904b\nCloses-Bug: #1284473\n'}]",0,107492,7d150b0177e91502d94efe6029baf51b4c68a6f7,12,4,2,7128,,,0,"Clarify novncproxy encryption support statement

Change-Id: I29ebbf94bcaa65b66fdba64b8c8c5221d5c4904b
Closes-Bug: #1284473
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/92/107492/2 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_compute.xml'],1,24862c840f6aa88116939c92800a82376f460c54,bug-1284473," <para>By default, the remote desktop traffic is not encrypted. SSL can be enabled to encrypt the VNC traffic.</para> <para><link xlink:href=""http://www.iamlinux.com/2014/06/using-ssl-encryption-with-openstack-nova-novncproxy/"">Using SSL encryption with nova novncproxy</link></para> "," <!-- TODO - check if havana had this feature --> <para>By default, the remote desktop traffic is not encrypted. Havana is expected to have VNC connections secured by Kerberos.</para>",3,2
openstack%2Fdevstack~master~I52fdfc5c865e864939df49fecb71b8e615a28cbf,openstack/devstack,master,I52fdfc5c865e864939df49fecb71b8e615a28cbf,FAQ: Clarification - Devstack is a gating project,MERGED,2014-07-15 04:31:22.000000000,2014-07-17 05:30:08.000000000,2014-07-16 02:55:37.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 5241}, {'_account_id': 6525}, {'_account_id': 7462}, {'_account_id': 9009}, {'_account_id': 10385}, {'_account_id': 11166}, {'_account_id': 11491}]","[{'number': 1, 'created': '2014-07-15 04:31:22.000000000', 'files': ['docs/source/faq.html'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a216254a13933cfc37764be2605394b9bf078133', 'message': 'FAQ: Clarification - Devstack is a gating project\n\nChange-Id: I52fdfc5c865e864939df49fecb71b8e615a28cbf\n'}]",0,106929,a216254a13933cfc37764be2605394b9bf078133,16,9,1,6525,,,0,"FAQ: Clarification - Devstack is a gating project

Change-Id: I52fdfc5c865e864939df49fecb71b8e615a28cbf
",git fetch https://review.opendev.org/openstack/devstack refs/changes/29/106929/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/source/faq.html'],1,a216254a13933cfc37764be2605394b9bf078133,faq/howto-help+gating-project," <dd>A: That isn't a question, but please do! The source for DevStack is <a href=""http://github.com/openstack-dev/devstack"">github</a> and bug reports go to <a href=""http://bugs.launchpad.net/devstack/"">LaunchPad</a>. Contributions follow the usual process as described in the <a href=""http://wiki.openstack.org/HowToContribute"">OpenStack wiki</a>. DevStack is not a core project but a gating project and therefore an official OpenStack project. This site is housed in the CloudBuilder's <a href=""http://github.com/cloudbuilders/devstack"">github</a> in the gh-pages branch.</dd> "," <dd>A: That isn't a question, but please do! The source for DevStack is <a href=""http://github.com/openstack-dev/devstack"">github</a> and bug reports go to <a href=""http://bugs.launchpad.net/devstack/"">LaunchPad</a>. Contributions follow the usual process as described in the <a href=""http://wiki.openstack.org/HowToContribute"">OpenStack wiki</a> even though DevStack is not an official OpenStack project. This site is housed in the CloudBuilder's <a href=""http://github.com/cloudbuilders/devstack"">github</a> in the gh-pages branch.</dd> ",8,8
openstack%2Fpython-keystoneclient~master~I48832c36e1a8b5a0029598dc74aaeaa3b3d2a66f,openstack/python-keystoneclient,master,I48832c36e1a8b5a0029598dc74aaeaa3b3d2a66f,remove useless part of error message,MERGED,2014-07-15 17:43:42.000000000,2014-07-17 05:22:00.000000000,2014-07-17 05:22:00.000000000,"[{'_account_id': 3}, {'_account_id': 220}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 11333}, {'_account_id': 11717}]","[{'number': 1, 'created': '2014-07-15 17:43:42.000000000', 'files': ['keystoneclient/exceptions.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/a15c8bcb49614f306362b5c9b90924db43d72082', 'message': 'remove useless part of error message\n\nalso did a bit of code cleanup for consistency\n\nChange-Id: I48832c36e1a8b5a0029598dc74aaeaa3b3d2a66f\n'}]",0,107122,a15c8bcb49614f306362b5c9b90924db43d72082,13,6,1,4,,,0,"remove useless part of error message

also did a bit of code cleanup for consistency

Change-Id: I48832c36e1a8b5a0029598dc74aaeaa3b3d2a66f
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/22/107122/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/exceptions.py'],1,a15c8bcb49614f306362b5c9b90924db43d72082,, msg = 'Unable to load certificate.' msg = 'Unable to sign or verify data.'," msg = (""Unable to load certificate. "" ""Ensure your system is configured properly."") msg = (""Unable to sign or verify data."")",2,3
openstack%2Fneutron~master~I1aadbe24db63eb2507b088cd53886d7f2e192cab,openstack/neutron,master,I1aadbe24db63eb2507b088cd53886d7f2e192cab,Use auth_token from keystonemiddleware,MERGED,2014-06-24 21:53:21.000000000,2014-07-17 05:17:07.000000000,2014-07-15 22:11:02.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6486}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-06-24 21:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6f760732e93a414a6f58d57ba3c8a6361870efc', 'message': 'Use auth_token from keystonemiddleware\n\nauth_token middleware in python-keystoneclient is deprecated and has\nbeen moved to the keystonemiddleware repo.\n\nChange-Id: I1aadbe24db63eb2507b088cd53886d7f2e192cab\n'}, {'number': 2, 'created': '2014-07-15 18:37:04.000000000', 'files': ['etc/api-paste.ini', 'requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/af00ac7906b55831c971710d55d9add6b5cc3825', 'message': 'Use auth_token from keystonemiddleware\n\nauth_token middleware in python-keystoneclient is deprecated and has\nbeen moved to the keystonemiddleware repo.\n\nCloses-Bug: #1342274\n\nChange-Id: I1aadbe24db63eb2507b088cd53886d7f2e192cab\n'}]",0,102361,af00ac7906b55831c971710d55d9add6b5cc3825,41,18,2,6486,,,0,"Use auth_token from keystonemiddleware

auth_token middleware in python-keystoneclient is deprecated and has
been moved to the keystonemiddleware repo.

Closes-Bug: #1342274

Change-Id: I1aadbe24db63eb2507b088cd53886d7f2e192cab
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/102361/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/api-paste.ini', 'requirements.txt']",2,e6f760732e93a414a6f58d57ba3c8a6361870efc,keystonemiddleware,keystonemiddleware,,2,1
openstack%2Fsecurity-doc~master~I31656052a094166fda7ce25da02d501351beacab,openstack/security-doc,master,I31656052a094166fda7ce25da02d501351beacab,Backend fixes,MERGED,2014-07-16 18:52:26.000000000,2014-07-17 05:11:13.000000000,2014-07-17 05:11:13.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7063}]","[{'number': 1, 'created': '2014-07-16 18:52:26.000000000', 'files': ['security-guide/ch_database-access-control.xml', 'security-guide/ch_dashboard.xml', 'security-guide/ch_identity.xml', 'security-guide/ch_management-interfaces.xml', 'security-guide/ch_object-storage.xml', 'security-guide/ch_data-encryption.xml', 'security-guide/ch_data-privacy-concerns.xml', 'security-guide/ch_database-transport-security.xml', 'security-guide/ch_database-backend-considerations.xml', 'security-guide/ch_introduction-to-openstack.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/bbbcd424dda2aa4f82ab9b2445fbefc7feb19643', 'message': 'Backend fixes\n\nUse proper spelling: back-end (adjective), back end (noun)\n\nChange-Id: I31656052a094166fda7ce25da02d501351beacab\nCloses-Bug: #1342894\n'}]",0,107471,bbbcd424dda2aa4f82ab9b2445fbefc7feb19643,9,5,1,6547,,,0,"Backend fixes

Use proper spelling: back-end (adjective), back end (noun)

Change-Id: I31656052a094166fda7ce25da02d501351beacab
Closes-Bug: #1342894
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/71/107471/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/ch_database-access-control.xml', 'security-guide/ch_dashboard.xml', 'security-guide/ch_identity.xml', 'security-guide/ch_management-interfaces.xml', 'security-guide/ch_object-storage.xml', 'security-guide/ch_data-encryption.xml', 'security-guide/ch_data-privacy-concerns.xml', 'security-guide/ch_database-transport-security.xml', 'security-guide/ch_database-backend-considerations.xml', 'security-guide/ch_introduction-to-openstack.xml']",10,bbbcd424dda2aa4f82ab9b2445fbefc7feb19643,bug/1342894, are transferred to the more secure private cloud back end that pluggable components. Today the implementation back end could be, are transferred to the more secure private cloud backend that pluggable components. Today the implementation backend could be,37,21
openstack%2Fkeystone~master~I88802efe5e44a4c4eb823eae42066561038c0f9c,openstack/keystone,master,I88802efe5e44a4c4eb823eae42066561038c0f9c,Pass token expiry to the .create_token() method,ABANDONED,2014-02-15 03:21:54.000000000,2014-07-17 05:08:52.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 9751}, {'_account_id': 11589}]","[{'number': 1, 'created': '2014-02-15 03:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/84a0e70346efda4e1426a8dbf128d5f9ad8eed44', 'message': 'Pass token expiry to the .create_token() method\n\nPass the token expiry directly to the .create_token() method as\nan argument instead as part of the token_data blob. This is a\nprerequisite of collapsing the token_ref data to not need\nto store token data twice (which is a prerequisite of moving to\nephemeral tokens).\n\nChange-Id: I88802efe5e44a4c4eb823eae42066561038c0f9c\nbp: ephemeral-pki-tokens\n'}, {'number': 2, 'created': '2014-06-27 18:50:47.000000000', 'files': ['keystone/token/backends/kvs.py', 'keystone/token/providers/common.py', 'keystone/token/core.py', 'keystone/contrib/user_crud/core.py', 'keystone/token/backends/sql.py', 'keystone/tests/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/897c713ff34f097c8a60feaa780d87ffb366ebba', 'message': 'Pass token expiry to the .create_token() method\n\nPass the token expiry directly to the .create_token() method as\nan argument instead as part of the token_data blob. This is a\nprerequisite of collapsing the token_ref data to not need\nto store token data twice (which is a prerequisite of moving to\nephemeral tokens).\n\nChange-Id: I88802efe5e44a4c4eb823eae42066561038c0f9c\nbp: non-persistent-tokens\n'}]",2,73769,897c713ff34f097c8a60feaa780d87ffb366ebba,15,5,2,2903,,,0,"Pass token expiry to the .create_token() method

Pass the token expiry directly to the .create_token() method as
an argument instead as part of the token_data blob. This is a
prerequisite of collapsing the token_ref data to not need
to store token data twice (which is a prerequisite of moving to
ephemeral tokens).

Change-Id: I88802efe5e44a4c4eb823eae42066561038c0f9c
bp: non-persistent-tokens
",git fetch https://review.opendev.org/openstack/keystone refs/changes/69/73769/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/backends/kvs.py', 'keystone/token/providers/common.py', 'keystone/contrib/user_crud/core.py', 'keystone/token/core.py', 'keystone/token/backends/sql.py', 'keystone/tests/test_backend_memcache.py', 'keystone/token/backends/memcache.py', 'keystone/tests/test_backend.py']",8,84a0e70346efda4e1426a8dbf128d5f9ad8eed44,bp/non-persistent-tokens," new_token = self.token_api.create_token(token_id, data, expiry=expires) expires = timeutils.utcnow() - datetime.timedelta(minutes=1) data_ref = self.token_api.create_token(token_id, data, expiry=expires) self.assertEqual(data_ref.pop('expires'), expires) data = {'id': token_id, 'id_hash': token_id, 'a': 'b', expires = timeutils.utcnow() - datetime.timedelta(minutes=1) data_ref = self.token_api.create_token(token_id, data, expiry=expires) self.assertEqual(data_ref.pop('expires'), expires) expires = timeutils.utcnow() + datetime.timedelta(minutes=1) data_ref = self.token_api.create_token(token_id, data, expiry=expires) self.assertEqual(data_ref.pop('expires'), expires) self.token_api.create_token(token_id, token_data, expiry=expire_time) self.token_api.create_token(token2_id, token2_data, expiry=expire_time)"," if expires is not None: data['expires'] = expires new_token = self.token_api.create_token(token_id, data) expire_time = timeutils.utcnow() - datetime.timedelta(minutes=1) 'expires': expire_time, data_ref = self.token_api.create_token(token_id, data) data = {'id': token_id, 'id_hash': token_id, 'a': 'b', 'expires': None, expire_time = timeutils.utcnow() - datetime.timedelta(minutes=1) 'expires': expire_time, data_ref = self.token_api.create_token(token_id, data) expire_time = timeutils.utcnow() + datetime.timedelta(minutes=1) 'expires': expire_time, data_ref = self.token_api.create_token(token_id, data) 'expires': expire_time, 'expires': expire_time, self.token_api.create_token(token_id, token_data) self.token_api.create_token(token2_id, token2_data)",36,43
openstack%2Fdevstack~master~I91bbf8f9bbaf28cd411dfd13dfe9659ca322487b,openstack/devstack,master,I91bbf8f9bbaf28cd411dfd13dfe9659ca322487b,By default enable memcache for Keystone,ABANDONED,2014-06-18 01:06:23.000000000,2014-07-17 05:08:26.000000000,,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-18 01:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/69eb9a1d2d48414163195103930abf5062140d4e', 'message': 'By default enable memcache for Keystone\n\nEnable cache for Keystone (memcached) by default. This will utilize\nthe dogpile.cache based caching layer.\n\nChange-Id: I91bbf8f9bbaf28cd411dfd13dfe9659ca322487b\n'}, {'number': 2, 'created': '2014-06-18 02:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2b91f7923621f161c03a9585fc58ef060224ae9a', 'message': 'By default enable memcache for Keystone\n\nEnable cache for Keystone (memcached) by default. This will utilize\nthe dogpile.cache based caching layer.\n\nChange-Id: I91bbf8f9bbaf28cd411dfd13dfe9659ca322487b\n'}, {'number': 3, 'created': '2014-06-18 05:19:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3d25ab0ea74592fa47a4375d6217ee4bb8fffe36', 'message': 'By default enable memcache for Keystone\n\nEnable cache for Keystone (memcached) by default. This will utilize\nthe dogpile.cache based caching layer.\n\nChange-Id: I91bbf8f9bbaf28cd411dfd13dfe9659ca322487b\n'}, {'number': 4, 'created': '2014-07-13 01:28:36.000000000', 'files': ['lib/keystone'], 'web_link': 'https://opendev.org/openstack/devstack/commit/fc272f9cd332aa878566f38e094f45ff24428602', 'message': 'By default enable memcache for Keystone\n\nEnable cache for Keystone (memcached) by default. This will utilize\nthe dogpile.cache based caching layer.\n\nChange-Id: I91bbf8f9bbaf28cd411dfd13dfe9659ca322487b\n'}]",0,100738,fc272f9cd332aa878566f38e094f45ff24428602,28,7,4,2903,,,0,"By default enable memcache for Keystone

Enable cache for Keystone (memcached) by default. This will utilize
the dogpile.cache based caching layer.

Change-Id: I91bbf8f9bbaf28cd411dfd13dfe9659ca322487b
",git fetch https://review.opendev.org/openstack/devstack refs/changes/38/100738/4 && git format-patch -1 --stdout FETCH_HEAD,['lib/keystone'],1,69eb9a1d2d48414163195103930abf5062140d4e,caching,"# Enable Memoization Caching # Use basic memcached based caching for the dogpile cache layer KEYSTONE_ENABLE_CACHE_LAYER={$KEYSTONE_ENABLE_CACHE_LAYER:-True} if [[ ""$KEYSTONE_ENABLE_CACHE_LAYER"" == ""True"" ]]; then iniset $KEYSTONE_CONF cache enable ""True"" iniset $KEYSTONE_CONF cache backend ""dogpile.cache.memcached"" iniset_multiline $KEYSTONE_CONF cache backend_argument ""distributed_lock:True"" ""url:127.0.0.1:11211"" fi if [[ ""$KEYSTONE_ENABLE_CACHE_LAYER"" == ""True"" || ""$KEYSTONE_TOKEN_BACKEND"" == ""memcache"" ]]; then if [[ ""$KEYSTONE_ENABLE_CACHE_LAYER"" == ""True"" || ""$KEYSTONE_TOKEN_BACKEND"" == ""memcache"" ]]; then # (re)start memcached to make sure we have a clean memcache. restart_service memcached fi "," if [[ ""$KEYSTONE_TOKEN_BACKEND"" = ""memcache"" ]]; then",16,1
openstack%2Fsahara-specs~master~I935df7e14946d9e69f2b55ffebe61e05d2493785,openstack/sahara-specs,master,I935df7e14946d9e69f2b55ffebe61e05d2493785,Append to a remote existing file,MERGED,2014-07-15 14:01:49.000000000,2014-07-17 03:58:39.000000000,2014-07-17 03:58:39.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 8932}]","[{'number': 1, 'created': '2014-07-15 14:01:49.000000000', 'files': ['specs/juno/append-to-remote-file.rst'], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/02e398e6aa0996aad9cb9d1834ae2c12257838d9', 'message': ""Append to a remote existing file\n\nSahara utils remote can only create a new file and write to it or\nreplace a line for a new one, but it can't append to an existing file.\nThis bp aims to implement this feature.\n\nChange-Id: I935df7e14946d9e69f2b55ffebe61e05d2493785\nImplements: blueprint append-to-remote-file\n""}]",0,107062,02e398e6aa0996aad9cb9d1834ae2c12257838d9,14,6,1,8932,,,0,"Append to a remote existing file

Sahara utils remote can only create a new file and write to it or
replace a line for a new one, but it can't append to an existing file.
This bp aims to implement this feature.

Change-Id: I935df7e14946d9e69f2b55ffebe61e05d2493785
Implements: blueprint append-to-remote-file
",git fetch https://review.opendev.org/openstack/sahara-specs refs/changes/62/107062/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/append-to-remote-file.rst'],1,02e398e6aa0996aad9cb9d1834ae2c12257838d9,bp/aims,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================ Append to a remote existing file ================================ https://blueprints.launchpad.net/sahara/+spec/append-to-remote-file Sahara utils remote can only create a new file and write to it or replace a line for a new one, but it can't append to an existing file. This bp aims to implement this feature. Problem description =================== When managing remote files, sahara can only create new files and replace lines from existing one. The feature to append to an existing file doesn't exist and it is necessary. Proposed change =============== Implement this feature following the idea of the write_to_file method The code is basically the same, the change will be the method of opening the file. Write uses 'w' we need to use 'a'. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Other end user impact --------------------- None Deployer impact --------------- None Developer impact ---------------- None Sahara-image-elements impact ---------------------------- None Sahara-dashboard / Horizon impact --------------------------------- None Implementation ============== Assignee(s) ----------- Primary assignee: * tellesmvn Work Items ---------- The implementation is very basic, the idea is similar to the write_file, the necessary change is to open the remote file in append mode. Dependencies ============ None Testing ======= None for now. Documentation Impact ==================== None References ========== None ",,107,0
openstack%2Fneutron~master~Ie49088a74bc5a87466f46989ce14d935e27567d1,openstack/neutron,master,Ie49088a74bc5a87466f46989ce14d935e27567d1,Database healing migration,MERGED,2014-05-29 12:24:20.000000000,2014-07-17 03:46:06.000000000,2014-07-15 21:35:48.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6849}, {'_account_id': 7249}, {'_account_id': 8655}, {'_account_id': 9008}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-05-29 12:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/42e064d4f5afcdd9349345f1b8116ab57b6c7da6', 'message': 'WIP: Script\n\nSome tests of alembic functions.\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 2, 'created': '2014-06-02 12:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4eeb95ef95425e7db8d90d8c58d1ccae1805983c', 'message': 'WIP: Script\n\nSome tests of alembic functions.\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 3, 'created': '2014-06-09 10:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/21d3e9705f368118624551edf9a9ddbcf76c0a82', 'message': 'WIP: Script\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 4, 'created': '2014-06-09 11:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3517bbb101f333fe8c964c234d359ffc5a67853a', 'message': 'WIP: Script\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 5, 'created': '2014-06-09 12:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b32d7869a4d51d8f854bff154ac9771e4a6b7e20', 'message': 'WIP: Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 6, 'created': '2014-06-10 07:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e14d63a7cb5c848caaff32e11649f4db4b715aaa', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 7, 'created': '2014-06-10 09:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a78afa50e8038b3166e7c6556c41bd17ac780065', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 8, 'created': '2014-06-10 10:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/14fa2651505f4868e54c621e6e6426d8da8a670e', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 9, 'created': '2014-06-19 10:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/144ede78c768850a77d95ca68ab7dece7201f14d', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 10, 'created': '2014-06-19 13:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea173aec8b3f265e56f65df2bcbe44ea74061a89', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 11, 'created': '2014-06-20 14:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5e52b6b98d0fccfe861a10502333c0a646141c06', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 12, 'created': '2014-06-30 07:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/630736074490313529703f43caf7149969a72a13', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 13, 'created': '2014-06-30 08:22:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9dd20183c2d58435d59f2b026999d96d4a305e75', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 14, 'created': '2014-06-30 14:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/25e1a9e38d43b5d53367920085120700dd42fa3f', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 15, 'created': '2014-06-30 15:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5daba13852aed1f1f2cb83abc742a59b3594dc90', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 16, 'created': '2014-06-30 15:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b3f25dead1a294c2a08d91391932929a70af5b0', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 17, 'created': '2014-07-01 12:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e8dc506045e25932f94be5fa2e2da9123b3339b8', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 18, 'created': '2014-07-02 14:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1bc9758745c6ff219aa133558c752f210a47810b', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\nWait for https://review.openstack.org/101918.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 19, 'created': '2014-07-02 14:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7361a3e41d9b82ca27d9a270f99a028d28d6fc61', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\nWait for https://review.openstack.org/101918.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 20, 'created': '2014-07-02 15:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cdd1f5be660c0fcab5ac96e348e5f476ed0ed67a', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\nWait for https://review.openstack.org/101918.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 21, 'created': '2014-07-03 14:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c842ec0cb79df1c3b654956549e6914af6114f6f', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 22, 'created': '2014-07-03 14:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f1a6f57f01d915ebd55cbcbe28b25977d2cb670', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 23, 'created': '2014-07-04 08:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/16c986dac8f2a8a88dfa2af81057351b4d4698ba', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 24, 'created': '2014-07-07 12:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ead46a689b89013436a6d22ae44f298fb405d8fc', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 25, 'created': '2014-07-07 12:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c72a71a45097f1859e4667b3ef4f00af81dd1957', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 26, 'created': '2014-07-08 07:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/623424c297d0f4aa78d80efb66ff6295b952a9f1', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 27, 'created': '2014-07-08 07:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f80b01901f7ecba695473670d80722b8519c2201', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 28, 'created': '2014-07-08 08:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/21f1ca1436cca7e15428daf258eb1fb223f1b3ef', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 29, 'created': '2014-07-08 14:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01908a463e139c21c8f848e2e38989522084a9de', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 30, 'created': '2014-07-09 13:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a9a8307000677cc03d72a2db8038d147210bff5', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 31, 'created': '2014-07-11 11:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd82abb5aa5443126902741b384b646abcea1931', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 32, 'created': '2014-07-11 12:30:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e8f85250cbca91341402873df827191577b7a3ef', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 33, 'created': '2014-07-11 14:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69e3048d6a7fdf9112d241d8d573d6330550a077', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 34, 'created': '2014-07-11 22:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f291f98dc95bad11ac0bda24736626abdf0d933', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nCloses-bug: #1277379\nCloses-bug: #1304741\nCloses-bug: #1298456\nCloses-bug: #1298461\nCloses-bug: #1239974\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 35, 'created': '2014-07-12 16:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/27cc4eedf42a30f91119270512c9314a4b2a035b', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nCloses-bug: #1277379\nCloses-bug: #1304741\nCloses-bug: #1298456\nCloses-bug: #1298461\nCloses-bug: #1239974\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 36, 'created': '2014-07-12 20:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff1e88d90bb5d3bca4acd27c5f81a225e9e28da0', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nCloses-bug: #1277379\nCloses-bug: #1304741\nCloses-bug: #1298456\nCloses-bug: #1298461\nCloses-bug: #1239974\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 37, 'created': '2014-07-14 11:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f7bb48b5df5b5e34793d77a39853f80db1fe0380', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nCloses-bug: #1277379\nCloses-bug: #1304741\nCloses-bug: #1298456\nCloses-bug: #1298461\nCloses-bug: #1239974\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 38, 'created': '2014-07-14 12:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99396294f5c885e38a13d59af511941a6e6ab51a', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nCloses-bug: #1277379\nCloses-bug: #1304741\nCloses-bug: #1298456\nCloses-bug: #1298461\nCloses-bug: #1239974\nCloses-bug: #1336177\nCloses-bug: #1337185\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 39, 'created': '2014-07-14 15:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/65f42a4504e6c7ababd927c9bc9094305e9d7748', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nCloses-bug: #1277379\nCloses-bug: #1304741\nCloses-bug: #1298456\nCloses-bug: #1298461\nCloses-bug: #1239974\nCloses-bug: #1336177\nCloses-bug: #1337185\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 40, 'created': '2014-07-15 10:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b47ccc8fe2a01dfd73cd8e9710a24eda33384ce2', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nCloses-bug: #1277379\nCloses-bug: #1304741\nCloses-bug: #1298456\nCloses-bug: #1298461\nCloses-bug: #1239974\nCloses-bug: #1336177\nCloses-bug: #1337185\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}, {'number': 41, 'created': '2014-07-15 11:22:09.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/db/migration/alembic_migrations/versions/1d6ee1ae5da5_db_healing.py', 'neutron/db/migration/models/frozen.py', 'neutron/db/migration/alembic_migrations/heal_script.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c3293f9f65912d904df56d9a3c449150af7fcdb', 'message': 'Database healing migration\n\nAdd script that will add all tables for all plugins and make db schema\nunconditional.\n\npartially implement bp: db-migration-refactor\n\nCloses-bug: #1277379\nCloses-bug: #1304741\nCloses-bug: #1298456\nCloses-bug: #1298461\nCloses-bug: #1239974\nCloses-bug: #1336177\nCloses-bug: #1337185\n\nChange-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1\n'}]",80,96438,5c3293f9f65912d904df56d9a3c449150af7fcdb,624,27,41,7249,,,0,"Database healing migration

Add script that will add all tables for all plugins and make db schema
unconditional.

partially implement bp: db-migration-refactor

Closes-bug: #1277379
Closes-bug: #1304741
Closes-bug: #1298456
Closes-bug: #1298461
Closes-bug: #1239974
Closes-bug: #1336177
Closes-bug: #1337185

Change-Id: Ie49088a74bc5a87466f46989ce14d935e27567d1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/38/96438/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/db/migration/alembic_migrations/versions/1d6ee1ae5da5_healing_migration.py']",2,42e064d4f5afcdd9349345f1b8116ab57b6c7da6,bp/db-migration-refactor,"# Copyright 2014 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # """"""healing_migration Revision ID: 1d6ee1ae5da5 Revises: 10cd28e692e9 Create Date: 2014-05-29 10:52:43.898980 """""" # revision identifiers, used by Alembic. revision = '1d6ee1ae5da5' down_revision = '10cd28e692e9' import importlib from alembic import autogenerate as autogen from alembic import context from alembic import op from neutron.db import model_base import pprint def upgrade(active_plugins=None, options=None): import_tables() models_metadata = model_base.BASEV2.metadata # Compare metadata from models and metadata from migrations diff = autogen.compare_metadata(context.get_context(), models_metadata) pprint.pprint(diff, indent=2, width=20) # For each difference run command for el in diff: parse_command(el) # produce a list of operations that should be applied to the database # schema to make it match the metadata obtained from models definitions # autogen._produce_migration_diffs(context.get_context(), ops, []) # # # # compile those actions into python code and execute # actions = '\n'.join(s.strip() for s in ops['upgrades']. # splitlines()[1:-1]) # code = compile(actions, '<string>', 'exec') # exec code in {'context': context, 'op': op, 'sa': sa} def downgrade(active_plugins=None, options=None): pass def parse_command(command): if isinstance(command, tuple): globals()[command[0]](*command[1:]) else: parse_modify_command(command) def parse_modify_command(command): for modifed, _, table, column, existing, new, old in command: args = [table, column] if modifed.endswith('type'): modifed = '_type' elif modifed.endswith('nullable'): modifed = 'nullable' elif modifed.endswith('default'): modifed = 'server_default' dict_agrs = {modifed: new} dict_agrs.update(existing) op.alter_column(*args, **dict_agrs) def add_table(table): op.create_table(table.name, *([c.copy() for c in table.columns] + list(table.constraints))) def add_index(index): op.create_index(index.name, index.table.name, [getattr(col, ""name"", None) for col in index.columns]) # TODO(akamyshnikova) dropping tables should be organized more careful. def remove_table(table): op.drop_table(table.name) def remove_index(index): op.drop_index(index.name, index.table.name) def remove_column(column): op.drop_column(column.table.name, column.name) def add_column(column): op.add_column(column.table.name, column.copy()) def add_unique_constraint(constraint): op.create_unique_constraint(constraint.name, constraint.table.name, constraint.columns) def remove_unique_constraint(constraint): op.drop_constraint(constraint.name, constraint.table.name) def import_tables(): # List of all models models_modules = [ 'neutron.plugins.ml2.models', 'neutron.plugins.ml2.drivers.brocade.db.models', 'neutron.plugins.ml2.drivers.cisco.nexus.nexus_models_v2', 'neutron.plugins.ml2.drivers.mech_arista.db', 'neutron.plugins.ml2.drivers.type_flat', 'neutron.plugins.ml2.drivers.type_gre', 'neutron.plugins.ml2.drivers.type_vlan', 'neutron.plugins.ml2.drivers.type_vxlan', 'neutron.db.agents_db', 'neutron.db.agentschedulers_db', 'neutron.db.l3_db', 'neutron.db.allowedaddresspairs_db', 'neutron.db.external_net_db', 'neutron.db.extraroute_db', 'neutron.db.l3_agentschedulers_db', 'neutron.db.portsecurity_db', 'neutron.db.routedserviceinsertion_db', 'neutron.db.routerservicetype_db', 'neutron.db.securitygroups_db', 'neutron.db.servicetype_db', 'neutron.plugins.cisco.db.n1kv_models_v2', 'neutron.plugins.cisco.db.network_models_v2', 'neutron.plugins.cisco.db.nexus_models_v2', 'neutron.plugins.bigswitch.routerrule_db', 'neutron.plugins.bigswitch.db.consistency_db', 'neutron.plugins.linuxbridge.db.l2network_models_v2' ] for module in models_modules: importlib.import_module(module) ",,152,1
openstack%2Fneutron-specs~master~I68c6db2eb6c874ee36eb84387cdc3b67f80f02dd,openstack/neutron-specs,master,I68c6db2eb6c874ee36eb84387cdc3b67f80f02dd,specification for securitygroup extension support for nuage plugin,MERGED,2014-06-17 00:16:38.000000000,2014-07-17 03:45:59.000000000,2014-07-17 03:45:59.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 2592}, {'_account_id': 7962}, {'_account_id': 8279}]","[{'number': 1, 'created': '2014-06-17 00:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/edc927057ec5a8e26b2d414ceda774717940ad06', 'message': 'specification for securitygroup extension support for nuage plugin\n\nChange-Id: I68c6db2eb6c874ee36eb84387cdc3b67f80f02dd\n'}, {'number': 2, 'created': '2014-06-17 00:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f6ae7bc946e9b77fd133419b395dd26b2038e762', 'message': 'specification for securitygroup extension support for nuage plugin\n\nChange-Id: I68c6db2eb6c874ee36eb84387cdc3b67f80f02dd\n'}, {'number': 3, 'created': '2014-06-17 00:19:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d09799fd942f66b999394bd76148d1b03b31b4c1', 'message': 'specification for securitygroup extension support for nuage plugin\n\nChange-Id: I68c6db2eb6c874ee36eb84387cdc3b67f80f02dd\n'}, {'number': 4, 'created': '2014-07-08 19:13:33.000000000', 'files': ['specs/juno/securitygroup-ext-for-nuage-plugin.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0df017e8fad59204a2687b0ed7258bb9b6f312e0', 'message': 'specification for securitygroup extension support for nuage plugin\n\nChange-Id: I68c6db2eb6c874ee36eb84387cdc3b67f80f02dd\n'}]",2,100389,0df017e8fad59204a2687b0ed7258bb9b6f312e0,25,6,4,7962,,,0,"specification for securitygroup extension support for nuage plugin

Change-Id: I68c6db2eb6c874ee36eb84387cdc3b67f80f02dd
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/89/100389/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/securitygroup-ext-for-nuage-plugin.rst'],1,edc927057ec5a8e26b2d414ceda774717940ad06,sg-extension," ================================================= SecurityGroup Extension support for Nuage Plugin ================================================= https://blueprints.launchpad.net/neutron/+spec/securitygroup-ext-for-nuage-plugin Adding securitygroup extension support to existing nuage networks' Plugin Problem description =================== Current Nuage Plugin does not support Neutron's securitygroup extension. Nuage's VSP supports this feature and the support for extension needs to be added in the plugin code. Proposed change =============== Adding extension support code in Nuage plugin. Alternatives ------------ None Data model impact ----------------- Existing securitygroup tables in neutron will be supported. On top of that, there will be 2 nuage specific tables which will be added: Schema could look like:: class RouterACLMapping(model_base.BASEV2): __tablename__ = ""router_acl_mapping"" router_id = Column(String(36), ForeignKey('routers.id', ondelete=""CASCADE""), primary_key=True) nuage_iacl_id = Column(String(36)) nuage_oacl_id = Column(String(36)) class SubnetACLMapping(model_base.BASEV2): __tablename__ = ""subnet_acl_mapping"" subnet_id = Column(String(36), ForeignKey('subnets.id', ondelete=""CASCADE""), primary_key=True) nuage_iacl_id = Column(String(36)) nuage_oacl_id = Column(String(36)) class VPortVportTagMapping(model_base.BASEV2, models_v2.HasId): __tablename__ = 'vport_vporttag_mapping' nuage_vport_id = Column(String(36)) nuage_vporttag_id = Column(String(36)) class SecGroupVPortTagMapping(model_base.BASEV2): __tablename__ = 'secgroup_vporttag_mapping' secgroup_id = Column(String(36), ForeignKey('securitygroups.id', ondelete=""CASCADE""), primary_key=True) nuage_vporttag_id = Column(String(36)) port_counter = Column(Integer) class SecGroupRuleACLMapping(model_base.BASEV2): __tablename__ = 'secgrouprule_acl_mapping' sgrule_id = Column(String(36), ForeignKey('securitygrouprules.id', ondelete=""CASCADE""), primary_key=True) nuage_acl_id = Column(String(36)) REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== VSP's securitygroup equivalent object's scope is either per router or per subnet. Where Neutron's is per tenant. Because of this, the mapping between neutron and VSP resource always happens at the port create or update time; such that port's router/subnet is known and thus sg attachment point in VSP is known. Following workflow can be imagined: 1) neutron security-group-create sg1 No-op from VSP point of view 2) neutron security-group-rule-create --direction ingress --protocol tcp --port_range_min 80 --port_range_max 80 <sg-id> No-op from VSP point of view 3a) neutron port-create 9d0b9f4a-1a72-4c17-a538-06ee7501d185 --name sub1 --security-group 8eb7ee8e-6d15-4a0d-b13a-0affeba438ae 3b) neutron port-update 71083f7d-1450-4bee-9c40-728b7ffd2876 --security-group c6c08246-bad7-4d82-a0ad-4a42327c9516 If this is the first port getting attached to that security-group, this is where corresponding vport-tag (for sg) and rules (for sg-rules) are created on VSP. Subsequent port-create/update for this sg will simply increment counter and add value to vport to vporttag mapping. Similarly, when the last port attached to this group is deleted, the vport-tag(sg) and the rules(vptag rules) will be deleted. CRUD operation on securitygroup will be supported in normal fashion. Assignee(s) ----------- Ronak Shah Primary assignee: ronak-malav-shah Other contributors: divya.hc Work Items ---------- Extension code in Nuage plugin Nuage Unit tests addition Nuage CI coverage addition Dependencies ============ None Testing ======= Unit Test coverage for security-group extension within Nuage unit test Nuage CI will be modified to start supporting this extension tests Documentation Impact ==================== None References ========== None ",,155,0
openstack%2Fnova~master~I996faa02ec38ec6113105fdf26a6b20ca1f7a039,openstack/nova,master,I996faa02ec38ec6113105fdf26a6b20ca1f7a039,Add support to virtio without vhost for qemu userspace driver,ABANDONED,2014-07-14 21:04:45.000000000,2014-07-17 03:21:47.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 8175}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-14 21:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4289dd826e66cbec00877dc95169bf122d87c63a', 'message': ""Add support to virtio without vhost for qemu userspace driver\n\nWhile virtio uses vhost (kernel space driver), virtio-net uses qemu\nuser space driver. This patch enables virtio without vhost on qemu\nby passing model type='virtio-net'.\n\nChange-Id: I996faa02ec38ec6113105fdf26a6b20ca1f7a039\n""}, {'number': 2, 'created': '2014-07-14 22:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a27183437c11baa71e9fa8e9b227805553f9123', 'message': ""Add support to virtio without vhost for qemu userspace driver\n\nWhile virtio uses vhost (kernel space driver), virtio-net uses qemu\nuser space driver. This patch enables virtio without vhost on qemu\nby passing model type='virtio-net'.\n\nChange-Id: I996faa02ec38ec6113105fdf26a6b20ca1f7a039\n""}, {'number': 3, 'created': '2014-07-15 12:54:56.000000000', 'files': ['nova/virt/libvirt/vif.py', 'nova/tests/virt/libvirt/test_vif.py', 'nova/network/model.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1f46880ed3fdc23f03849b220ad4d094094391c9', 'message': ""Add support to virtio without vhost for qemu userspace driver\n\nWhile virtio uses vhost (kernel space driver), virtio-net uses qemu\nuser space driver. This patch enables virtio without vhost on qemu\nby passing model type='virtio-net'.\n\nChange-Id: I996faa02ec38ec6113105fdf26a6b20ca1f7a039\n""}]",0,106868,1f46880ed3fdc23f03849b220ad4d094094391c9,27,7,3,8175,,,0,"Add support to virtio without vhost for qemu userspace driver

While virtio uses vhost (kernel space driver), virtio-net uses qemu
user space driver. This patch enables virtio without vhost on qemu
by passing model type='virtio-net'.

Change-Id: I996faa02ec38ec6113105fdf26a6b20ca1f7a039
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/106868/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_vif.py', 'nova/virt/libvirt/vif.py', 'nova/network/model.py']",3,4289dd826e66cbec00877dc95169bf122d87c63a,master,VIF_MODEL_VIRTIO_NOVHOST = 'virtio-net',,14,0
openstack%2Ftempest~master~Icafb0470402e59e9df3c81407f57c57b9e719fcb,openstack/tempest,master,Icafb0470402e59e9df3c81407f57c57b9e719fcb,Validate server detail list attribute of Nova APIs,MERGED,2014-06-13 04:00:01.000000000,2014-07-17 03:21:32.000000000,2014-07-17 03:21:31.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5292}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-13 04:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8af0aeca27018f411783ebf63b382e0bb44e0966', 'message': 'Validate server detail list attribute of Nova APIs\n\nThis patch adds the JSON schema for Nova V2 & V3 server detail list\nAPIs response and validate the response with added JSON schema\nto block the backward incompatibility change in the future.\n\n{\n    ""servers"": [\n        {\n            ""accessIPv4"": """",\n            ""accessIPv6"": """",\n            ""addresses"": {\n                ""private"": [\n                    {\n                        ""addr"": ""%(ip)s"",\n                        ""version"": 4\n                    }\n                ]\n            },\n            ""created"": ""%(timestamp)s"",\n            ""flavor"": {\n                ""id"": ""1"",\n                ""links"": [\n                    {\n                        ""href"": ""%(host)s/openstack/flavors/1"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""hostId"": ""%(hostid)s"",\n            ""id"": ""%(id)s"",\n            ""image"": {\n                ""id"": ""%(uuid)s"",\n                ""links"": [\n                    {\n                        ""href"": ""%(host)s/openstack/images/%(uuid)s"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""links"": [\n                {\n                    ""href"": ""%(host)s/v2/openstack/servers/%(id)s"",\n                    ""rel"": ""self""\n                },\n                {\n                    ""href"": ""%(host)s/openstack/servers/%(id)s"",\n                    ""rel"": ""bookmark""\n                }\n            ],\n            ""metadata"": {\n                ""My Server Name"": ""Apache1""\n            },\n            ""name"": ""new-server-test"",\n            ""progress"": 0,\n            ""status"": ""ACTIVE"",\n            ""tenant_id"": ""openstack"",\n            ""updated"": ""%(timestamp)s"",\n            ""user_id"": ""fake""\n        }\n    ]\n}\n\nThe response body of server detail list V3 APIs is below:\n\n{\n    ""servers"": [\n        {\n            ""addresses"": {\n                ""private"": [\n                    {\n                        ""addr"": ""%(ip)s"",\n                        ""mac_addr"": ""aa:bb:cc:dd:ee:ff"",\n                        ""type"": ""fixed"",\n                        ""version"": 4\n                    }\n                ]\n            },\n            ""created"": ""%(timestamp)s"",\n            ""flavor"": {\n                ""id"": ""1"",\n                ""links"": [\n                    {\n                        ""href"": ""%(host)s/flavors/1"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""host_id"": ""%(hostid)s"",\n            ""id"": ""%(id)s"",\n            ""image"": {\n                ""id"": ""%(uuid)s"",\n                ""links"": [\n                    {\n                        ""href"": ""%(glance_host)s/images/%(uuid)s"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""key_name"": null,\n            ""links"": [\n                {\n                    ""href"": ""%(host)s/v3/servers/%(uuid)s"",\n                    ""rel"": ""self""\n                },\n                {\n                    ""href"": ""%(host)s/servers/%(id)s"",\n                    ""rel"": ""bookmark""\n                }\n            ],\n            ""metadata"": {\n                ""My Server Name"": ""Apache1""\n            },\n            ""name"": ""new-server-test"",\n            ""progress"": 0,\n            ""status"": ""ACTIVE"",\n            ""tenant_id"": ""openstack"",\n            ""updated"": ""%(timestamp)s"",\n            ""user_id"": ""fake""\n        }\n    ]\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: Icafb0470402e59e9df3c81407f57c57b9e719fcb\n'}, {'number': 2, 'created': '2014-06-13 04:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/187d8d29f79031704af49d9d2b95127fe2a19e30', 'message': 'Validate server detail list attribute of Nova APIs\n\nThis patch adds the JSON schema for Nova V2 & V3 server detail list\nAPIs response and validate the response with added JSON schema\nto block the backward incompatibility change in the future.\n\nThe response body of server detail list V2 APIs is below:\n\n{\n    ""servers"": [\n        {\n            ""accessIPv4"": """",\n            ""accessIPv6"": """",\n            ""addresses"": {\n                ""private"": [\n                    {\n                        ""addr"": ""%(ip)s"",\n                        ""version"": 4\n                    }\n                ]\n            },\n            ""created"": ""%(timestamp)s"",\n            ""flavor"": {\n                ""id"": ""1"",\n                ""links"": [\n                    {\n                        ""href"": ""%(host)s/openstack/flavors/1"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""hostId"": ""%(hostid)s"",\n            ""id"": ""%(id)s"",\n            ""image"": {\n                ""id"": ""%(uuid)s"",\n                ""links"": [\n                    {\n                        ""href"": ""%(host)s/openstack/images/%(uuid)s"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""links"": [\n                {\n                    ""href"": ""%(host)s/v2/openstack/servers/%(id)s"",\n                    ""rel"": ""self""\n                },\n                {\n                    ""href"": ""%(host)s/openstack/servers/%(id)s"",\n                    ""rel"": ""bookmark""\n                }\n            ],\n            ""metadata"": {\n                ""My Server Name"": ""Apache1""\n            },\n            ""name"": ""new-server-test"",\n            ""progress"": 0,\n            ""status"": ""ACTIVE"",\n            ""tenant_id"": ""openstack"",\n            ""updated"": ""%(timestamp)s"",\n            ""user_id"": ""fake""\n        }\n    ]\n}\n\nThe response body of server detail list V3 APIs is below:\n\n{\n    ""servers"": [\n        {\n            ""addresses"": {\n                ""private"": [\n                    {\n                        ""addr"": ""%(ip)s"",\n                        ""mac_addr"": ""aa:bb:cc:dd:ee:ff"",\n                        ""type"": ""fixed"",\n                        ""version"": 4\n                    }\n                ]\n            },\n            ""created"": ""%(timestamp)s"",\n            ""flavor"": {\n                ""id"": ""1"",\n                ""links"": [\n                    {\n                        ""href"": ""%(host)s/flavors/1"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""host_id"": ""%(hostid)s"",\n            ""id"": ""%(id)s"",\n            ""image"": {\n                ""id"": ""%(uuid)s"",\n                ""links"": [\n                    {\n                        ""href"": ""%(glance_host)s/images/%(uuid)s"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""key_name"": null,\n            ""links"": [\n                {\n                    ""href"": ""%(host)s/v3/servers/%(uuid)s"",\n                    ""rel"": ""self""\n                },\n                {\n                    ""href"": ""%(host)s/servers/%(id)s"",\n                    ""rel"": ""bookmark""\n                }\n            ],\n            ""metadata"": {\n                ""My Server Name"": ""Apache1""\n            },\n            ""name"": ""new-server-test"",\n            ""progress"": 0,\n            ""status"": ""ACTIVE"",\n            ""tenant_id"": ""openstack"",\n            ""updated"": ""%(timestamp)s"",\n            ""user_id"": ""fake""\n        }\n    ]\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: Icafb0470402e59e9df3c81407f57c57b9e719fcb\n'}, {'number': 3, 'created': '2014-07-04 05:37:34.000000000', 'files': ['tempest/api_schema/compute/v3/servers.py', 'tempest/services/compute/json/servers_client.py', 'tempest/api_schema/compute/v2/servers.py', 'tempest/services/compute/v3/json/servers_client.py', 'tempest/api_schema/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/51744863b5bc66c1d0f10f25338d7102ce868230', 'message': 'Validate server detail list attribute of Nova APIs\n\nThis patch adds the JSON schema for Nova V2 & V3 server detail list\nAPIs response and validate the response with added JSON schema\nto block the backward incompatibility change in the future.\n\nThe response body of server detail list V2 APIs is below:\n\n{\n    ""servers"": [\n        {\n            ""accessIPv4"": """",\n            ""accessIPv6"": """",\n            ""addresses"": {\n                ""private"": [\n                    {\n                        ""addr"": ""%(ip)s"",\n                        ""version"": 4\n                    }\n                ]\n            },\n            ""created"": ""%(timestamp)s"",\n            ""flavor"": {\n                ""id"": ""1"",\n                ""links"": [\n                    {\n                        ""href"": ""%(host)s/openstack/flavors/1"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""hostId"": ""%(hostid)s"",\n            ""id"": ""%(id)s"",\n            ""image"": {\n                ""id"": ""%(uuid)s"",\n                ""links"": [\n                    {\n                        ""href"": ""%(host)s/openstack/images/%(uuid)s"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""links"": [\n                {\n                    ""href"": ""%(host)s/v2/openstack/servers/%(id)s"",\n                    ""rel"": ""self""\n                },\n                {\n                    ""href"": ""%(host)s/openstack/servers/%(id)s"",\n                    ""rel"": ""bookmark""\n                }\n            ],\n            ""metadata"": {\n                ""My Server Name"": ""Apache1""\n            },\n            ""name"": ""new-server-test"",\n            ""progress"": 0,\n            ""status"": ""ACTIVE"",\n            ""tenant_id"": ""openstack"",\n            ""updated"": ""%(timestamp)s"",\n            ""user_id"": ""fake""\n        }\n    ]\n}\n\nThe response body of server detail list V3 APIs is below:\n\n{\n    ""servers"": [\n        {\n            ""addresses"": {\n                ""private"": [\n                    {\n                        ""addr"": ""%(ip)s"",\n                        ""mac_addr"": ""aa:bb:cc:dd:ee:ff"",\n                        ""type"": ""fixed"",\n                        ""version"": 4\n                    }\n                ]\n            },\n            ""created"": ""%(timestamp)s"",\n            ""flavor"": {\n                ""id"": ""1"",\n                ""links"": [\n                    {\n                        ""href"": ""%(host)s/flavors/1"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""host_id"": ""%(hostid)s"",\n            ""id"": ""%(id)s"",\n            ""image"": {\n                ""id"": ""%(uuid)s"",\n                ""links"": [\n                    {\n                        ""href"": ""%(glance_host)s/images/%(uuid)s"",\n                        ""rel"": ""bookmark""\n                    }\n                ]\n            },\n            ""key_name"": null,\n            ""links"": [\n                {\n                    ""href"": ""%(host)s/v3/servers/%(uuid)s"",\n                    ""rel"": ""self""\n                },\n                {\n                    ""href"": ""%(host)s/servers/%(id)s"",\n                    ""rel"": ""bookmark""\n                }\n            ],\n            ""metadata"": {\n                ""My Server Name"": ""Apache1""\n            },\n            ""name"": ""new-server-test"",\n            ""progress"": 0,\n            ""status"": ""ACTIVE"",\n            ""tenant_id"": ""openstack"",\n            ""updated"": ""%(timestamp)s"",\n            ""user_id"": ""fake""\n        }\n    ]\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: Icafb0470402e59e9df3c81407f57c57b9e719fcb\n'}]",0,99836,51744863b5bc66c1d0f10f25338d7102ce868230,90,9,3,8556,,,0,"Validate server detail list attribute of Nova APIs

This patch adds the JSON schema for Nova V2 & V3 server detail list
APIs response and validate the response with added JSON schema
to block the backward incompatibility change in the future.

The response body of server detail list V2 APIs is below:

{
    ""servers"": [
        {
            ""accessIPv4"": """",
            ""accessIPv6"": """",
            ""addresses"": {
                ""private"": [
                    {
                        ""addr"": ""%(ip)s"",
                        ""version"": 4
                    }
                ]
            },
            ""created"": ""%(timestamp)s"",
            ""flavor"": {
                ""id"": ""1"",
                ""links"": [
                    {
                        ""href"": ""%(host)s/openstack/flavors/1"",
                        ""rel"": ""bookmark""
                    }
                ]
            },
            ""hostId"": ""%(hostid)s"",
            ""id"": ""%(id)s"",
            ""image"": {
                ""id"": ""%(uuid)s"",
                ""links"": [
                    {
                        ""href"": ""%(host)s/openstack/images/%(uuid)s"",
                        ""rel"": ""bookmark""
                    }
                ]
            },
            ""links"": [
                {
                    ""href"": ""%(host)s/v2/openstack/servers/%(id)s"",
                    ""rel"": ""self""
                },
                {
                    ""href"": ""%(host)s/openstack/servers/%(id)s"",
                    ""rel"": ""bookmark""
                }
            ],
            ""metadata"": {
                ""My Server Name"": ""Apache1""
            },
            ""name"": ""new-server-test"",
            ""progress"": 0,
            ""status"": ""ACTIVE"",
            ""tenant_id"": ""openstack"",
            ""updated"": ""%(timestamp)s"",
            ""user_id"": ""fake""
        }
    ]
}

The response body of server detail list V3 APIs is below:

{
    ""servers"": [
        {
            ""addresses"": {
                ""private"": [
                    {
                        ""addr"": ""%(ip)s"",
                        ""mac_addr"": ""aa:bb:cc:dd:ee:ff"",
                        ""type"": ""fixed"",
                        ""version"": 4
                    }
                ]
            },
            ""created"": ""%(timestamp)s"",
            ""flavor"": {
                ""id"": ""1"",
                ""links"": [
                    {
                        ""href"": ""%(host)s/flavors/1"",
                        ""rel"": ""bookmark""
                    }
                ]
            },
            ""host_id"": ""%(hostid)s"",
            ""id"": ""%(id)s"",
            ""image"": {
                ""id"": ""%(uuid)s"",
                ""links"": [
                    {
                        ""href"": ""%(glance_host)s/images/%(uuid)s"",
                        ""rel"": ""bookmark""
                    }
                ]
            },
            ""key_name"": null,
            ""links"": [
                {
                    ""href"": ""%(host)s/v3/servers/%(uuid)s"",
                    ""rel"": ""self""
                },
                {
                    ""href"": ""%(host)s/servers/%(id)s"",
                    ""rel"": ""bookmark""
                }
            ],
            ""metadata"": {
                ""My Server Name"": ""Apache1""
            },
            ""name"": ""new-server-test"",
            ""progress"": 0,
            ""status"": ""ACTIVE"",
            ""tenant_id"": ""openstack"",
            ""updated"": ""%(timestamp)s"",
            ""user_id"": ""fake""
        }
    ]
}

Partially implements blueprint nova-api-attribute-test

Change-Id: Icafb0470402e59e9df3c81407f57c57b9e719fcb
",git fetch https://review.opendev.org/openstack/tempest refs/changes/36/99836/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api_schema/compute/v3/servers.py', 'tempest/services/compute/json/servers_client.py', 'tempest/api_schema/compute/v2/servers.py', 'tempest/services/compute/v3/json/servers_client.py', 'tempest/api_schema/compute/servers.py']",5,8af0aeca27018f411783ebf63b382e0bb44e0966,bp/nova-api-attribute-test,"common_show_server = { 'type': 'object', 'properties': { 'id': {'type': ['integer', 'string']}, 'name': {'type': 'string'}, 'status': {'type': 'string'}, 'image': { 'type': 'object', 'properties': { 'id': {'type': ['integer', 'string']}, 'links': parameter_types.links }, 'required': ['id', 'links'] }, 'flavor': { 'type': 'object', 'properties': { 'id': {'type': ['integer', 'string']}, 'links': parameter_types.links }, 'required': ['id', 'links'] }, 'user_id': {'type': 'string'}, 'tenant_id': {'type': 'string'}, 'created': {'type': 'string'}, 'updated': {'type': 'string'}, 'progress': {'type': 'integer'}, 'metadata': {'type': 'object'}, 'links': parameter_types.links, 'addresses': parameter_types.addresses, }, # NOTE(GMann): 'progress' attribute is present in the response # only when server's status is one of the progress statuses # (""ACTIVE"",""BUILD"", ""REBUILD"", ""RESIZE"",""VERIFY_RESIZE"") # So it is not defined as 'required'. 'required': ['id', 'name', 'status', 'image', 'flavor', 'user_id', 'tenant_id', 'created', 'updated', 'metadata', 'links', 'addresses'] } 'server': common_show_server base_list_servers_detail = { 'status_code': [200], 'response_body': { 'type': 'object', 'properties': { 'servers': { 'type': 'array', 'items': common_show_server } }, 'required': ['servers'] } }"," 'server': { 'type': 'object', 'properties': { 'id': {'type': ['integer', 'string']}, 'name': {'type': 'string'}, 'status': {'type': 'string'}, 'image': { 'type': 'object', 'properties': { 'id': {'type': ['integer', 'string']}, 'links': parameter_types.links }, 'required': ['id', 'links'] }, 'flavor': { 'type': 'object', 'properties': { 'id': {'type': ['integer', 'string']}, 'links': parameter_types.links }, 'required': ['id', 'links'] }, 'user_id': {'type': 'string'}, 'tenant_id': {'type': 'string'}, 'created': {'type': 'string'}, 'updated': {'type': 'string'}, 'progress': {'type': 'integer'}, 'metadata': {'type': 'object'}, 'links': parameter_types.links, 'addresses': parameter_types.addresses, }, # NOTE(GMann): 'progress' attribute is present in the response # only when server's status is one of the progress statuses # (""ACTIVE"",""BUILD"", ""REBUILD"", ""RESIZE"",""VERIFY_RESIZE"") # So it is not defined as 'required'. 'required': ['id', 'name', 'status', 'image', 'flavor', 'user_id', 'tenant_id', 'created', 'updated', 'metadata', 'links', 'addresses'] }",85,39
openstack%2Fnova~master~I31e2a18d94bb4d8a88d99669b31181a1dea7ad05,openstack/nova,master,I31e2a18d94bb4d8a88d99669b31181a1dea7ad05,Translations: add LC to all LOG.critical messages,MERGED,2014-06-19 10:22:28.000000000,2014-07-17 03:21:10.000000000,2014-07-16 07:59:52.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 6849}, {'_account_id': 8276}, {'_account_id': 8412}, {'_account_id': 8574}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-19 10:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fb82e8eac4d382ac064de439288abcd32ba8079', 'message': 'Translations: add LC to all LOG.critical messages\n\nUpdate all instance of this in the code.\n\nChange-Id: I31e2a18d94bb4d8a88d99669b31181a1dea7ad05\n'}, {'number': 2, 'created': '2014-07-07 18:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f1aca513d69337323681c90c6cb95689cd2907f', 'message': 'Translations: add LC to all LOG.critical messages\n\nUpdate all instance of this in the code.\n\nChange-Id: I31e2a18d94bb4d8a88d99669b31181a1dea7ad05\n'}, {'number': 3, 'created': '2014-07-15 09:49:45.000000000', 'files': ['nova/virt/vmwareapi/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c3ebc5f729ad59cb366e462abc43747e60887cc5', 'message': 'Translations: add LC to all LOG.critical messages\n\nUpdate all instance of this in the code.\n\nPatch https://review.openstack.org/#/c/105675/ deals with the\nother case.\n\nTrivialFix\n\nChange-Id: I31e2a18d94bb4d8a88d99669b31181a1dea7ad05\n'}]",4,101165,c3ebc5f729ad59cb366e462abc43747e60887cc5,72,16,3,1653,,,0,"Translations: add LC to all LOG.critical messages

Update all instance of this in the code.

Patch https://review.openstack.org/#/c/105675/ deals with the
other case.

TrivialFix

Change-Id: I31e2a18d94bb4d8a88d99669b31181a1dea7ad05
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/101165/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/__init__.py', 'nova/virt/vmwareapi/driver.py']",2,8fb82e8eac4d382ac064de439288abcd32ba8079,use-LC,"from nova.openstack.common.gettextutils import _LC LOG.critical(_LC(""Unable to connect to server at %(server)s, "" ""sleeping for %(seconds)s seconds""), {'server': self._host_ip, 'seconds': delay}, exc_info=True) LOG.critical(_LC(""In vmwareapi: _call_method (session=%s)""),"," LOG.critical(_(""Unable to connect to server at %(server)s, "" ""sleeping for %(seconds)s seconds""), {'server': self._host_ip, 'seconds': delay}, exc_info=True) LOG.critical(_(""In vmwareapi: _call_method (session=%s)""),",8,6
openstack%2Fnova~master~Ieb90521cf231acae8b5a9920acf6c77f2e34ef67,openstack/nova,master,Ieb90521cf231acae8b5a9920acf6c77f2e34ef67,Handle over quota exception from Neutron,MERGED,2013-12-17 08:55:14.000000000,2014-07-17 03:20:47.000000000,2014-07-16 02:28:22.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4395}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5652}, {'_account_id': 5754}, {'_account_id': 5930}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7002}, {'_account_id': 7040}, {'_account_id': 7461}, {'_account_id': 7653}, {'_account_id': 8163}, {'_account_id': 8290}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9645}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2013-12-17 08:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/34f1ab0f1269509591e35ce798a58491dc3cdfd8', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to to user, and not consistent with nova-networking\nReutrn FloatingIPExceedLimit exception when quota exceed\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 2, 'created': '2013-12-18 06:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c7edaceff0b4722c2372490aed8c8d6390db387', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReutrn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 3, 'created': '2013-12-18 07:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/810c05a2fddecb2892d008524d45c6743981bceb', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 4, 'created': '2013-12-18 07:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7088cbfe3d6ce9b03155fc5228f2acd95236b86', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 5, 'created': '2013-12-18 07:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b29ced41d2cce79b84ffc84120680773a513922', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 6, 'created': '2013-12-18 15:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1812256923602724da0de0b9bf7bcbe14d012d9', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 7, 'created': '2014-01-10 07:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69ee5d62b2f3202374bc3c832445e5c96f333279', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 8, 'created': '2014-01-20 13:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/52e32331b33f701cb2dc6a3b987cc4496b32c399', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 9, 'created': '2014-03-07 11:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96ccf6b158b0183a851e84c0c79f20a7bd2db256', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 10, 'created': '2014-03-31 02:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4f2711dd1cd5a3a4ad42237dd67a884240caa6f', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 11, 'created': '2014-03-31 02:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7a0444631ba18078b72fbed457e9bea3a18a733', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 12, 'created': '2014-03-31 03:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e6a315ee94c934ce4c52c41a072a364d78906fa', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 13, 'created': '2014-04-01 07:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/855141ea59aa4537f1e746f93fc7f775cc50d8db', 'message': 'Fix over quota errors originating from Neutron result\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\n'}, {'number': 14, 'created': '2014-06-16 09:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d7314ec719cd8a9dfe3d16704f08a5156be0f1b', 'message': 'Handle over quota exception from Neutron\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded.\n\nChange I8788993578ac872da9f676fe3e2fb8f98414289d at neutronclient\nadd OverQuotaClient exception and it is used in this patch\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\nCloses-Bug: #1301117\n'}, {'number': 15, 'created': '2014-06-24 03:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53a137d59f0748cdce70ea97e7cf483b8b9ff35f', 'message': 'Handle over quota exception from Neutron\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded.\n\nChange I8788993578ac872da9f676fe3e2fb8f98414289d at neutronclient\nadd OverQuotaClient exception and it is used in this patch\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\nCloses-Bug: #1301117\n'}, {'number': 16, 'created': '2014-07-10 05:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/846c00b497d250f402f91adf6a93689d2feece29', 'message': 'Handle over quota exception from Neutron\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded.\n\nChange I8788993578ac872da9f676fe3e2fb8f98414289d at neutronclient\nadd OverQuotaClient exception and it is used in this patch\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\nCloses-Bug: #1301117\n'}, {'number': 17, 'created': '2014-07-10 15:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d4c781f48d0cde2ea0efce7e3235341209c8367', 'message': 'Handle over quota exception from Neutron\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded.\n\nChange I8788993578ac872da9f676fe3e2fb8f98414289d at neutronclient\nadd OverQuotaClient exception and it is used in this patch\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\nCloses-Bug: #1301117\n'}, {'number': 18, 'created': '2014-07-14 07:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19d89b26186e5afccfb36886049e5f8def010589', 'message': 'Handle over quota exception from Neutron\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded.\n\nChange I8788993578ac872da9f676fe3e2fb8f98414289d at neutronclient\nadd OverQuotaClient exception and it is used in this patch\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\nCloses-Bug: #1301117\n'}, {'number': 19, 'created': '2014-07-15 08:05:53.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/tests/api/openstack/compute/contrib/test_floating_ips.py', 'nova/api/openstack/compute/contrib/floating_ips.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9f06c76645a56d66cce5f33a5fd5a3b96a7eb421', 'message': 'Handle over quota exception from Neutron\n\nWhen using the floating IP in Nova with Neutron, and\na quota limit is exceeded in Neutron, the exception from\nthe Neutron client results in Nova generating a 500 error.\nThis is unhelpful to user, and not consistent with nova-networking\nReturn FloatingIPExceedLimit exception when quota exceeded.\n\nChange I8788993578ac872da9f676fe3e2fb8f98414289d at neutronclient\nadd OverQuotaClient exception and it is used in this patch\n\nChange-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67\nCloses-Bug: #1210598\nCloses-Bug: #1301117\n'}]",44,62581,9f06c76645a56d66cce5f33a5fd5a3b96a7eb421,234,28,19,6062,,,0,"Handle over quota exception from Neutron

When using the floating IP in Nova with Neutron, and
a quota limit is exceeded in Neutron, the exception from
the Neutron client results in Nova generating a 500 error.
This is unhelpful to user, and not consistent with nova-networking
Return FloatingIPExceedLimit exception when quota exceeded.

Change I8788993578ac872da9f676fe3e2fb8f98414289d at neutronclient
add OverQuotaClient exception and it is used in this patch

Change-Id: Ieb90521cf231acae8b5a9920acf6c77f2e34ef67
Closes-Bug: #1210598
Closes-Bug: #1301117
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/62581/18 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py']",2,34f1ab0f1269509591e35ce798a58491dc3cdfd8,bug/1210598, try: fip = client.create_floatingip(param) except neutron_client_exc.NeutronClientException as e: LOG.exception(_('Neutron error creating floating on pool %s') % pool) # NOTE(mriedem): OverQuota in neutron is a 409 if e.status_code == 409: raise exception.FloatingIpLimitExceeded() raise, # TODO(amotoki): handle exception during create_floatingip() # At this timing it is ensured that a network for pool exists. # quota error may be returned. fip = client.create_floatingip(param),33,4
openstack%2Fnova~master~Id4994551c135c3c1a4982153f0c6cacba6176b95,openstack/nova,master,Id4994551c135c3c1a4982153f0c6cacba6176b95,Fix and gate on H305 and H307,MERGED,2014-07-10 02:27:22.000000000,2014-07-17 03:19:59.000000000,2014-07-15 05:00:31.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6167}, {'_account_id': 7166}, {'_account_id': 8430}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 11069}]","[{'number': 1, 'created': '2014-07-10 02:27:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed3381c59ffff4b03313890bf0a6b72ad6563203', 'message': 'Fix and gate on H305 and H307\n\nBoth H305 and H307 are part of the OpenStack style guide.\n\nEnsure that there are 3 groups of imports, stdlib,\nthird-party and project specific. Within each category\nensure that imports are in alphabetical order.\n\nChange-Id: Id4994551c135c3c1a4982153f0c6cacba6176b95\n'}, {'number': 2, 'created': '2014-07-13 22:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ff9acc31ba5eea7eb32b8fd197baef98c449401', 'message': 'Fix and gate on H305 and H307\n\nBoth H305 and H307 are part of the OpenStack style guide.\n\nEnsure that there are 3 groups of imports, stdlib,\nthird-party and project specific. Within each category\nensure that imports are in alphabetical order.\n\nChange-Id: Id4994551c135c3c1a4982153f0c6cacba6176b95\n'}, {'number': 3, 'created': '2014-07-15 01:13:27.000000000', 'files': ['nova/tests/virt/vmwareapi/test_ds_util.py', 'nova/tests/api/openstack/compute/contrib/test_shelve.py', 'nova/tests/api/test_auth.py', 'nova/compute/monitors/__init__.py', 'nova/tests/api/openstack/test_wsgi.py', 'nova/virt/configdrive.py', 'nova/tests/api/openstack/compute/contrib/test_availability_zone.py', 'nova/tests/objects/test_instance_action.py', 'plugins/xenserver/xenapi/etc/xapi.d/plugins/pluginlib_nova.py', 'nova/virt/xenapi/image/vdi_through_dev.py', 'nova/tests/virt/hyperv/test_vmutils.py', 'nova/virt/xenapi/image/bittorrent.py', 'nova/tests/network/security_group/test_neutron_driver.py', 'nova/virt/xenapi/fake.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors.py', 'nova/virt/storage_users.py', 'nova/tests/virt/hyperv/test_vhdutilsv2.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/tests/api/openstack/compute/plugins/v3/test_security_groups.py', 'nova/tests/compute/test_compute_api.py', 'nova/cmd/__init__.py', 'nova/tests/virt/hyperv/test_networkutilsv2.py', 'nova/virt/vmwareapi/error_util.py', 'nova/api/openstack/compute/contrib/console_output.py', 'nova/tests/image/test_glance.py', 'nova/tests/api/openstack/test_common.py', 'nova/tests/virt/vmwareapi/test_configdrive.py', 'nova/pci/pci_request.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/tests/compute/test_compute.py', 'nova/tests/api/openstack/compute/contrib/test_services.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py', 'nova/virt/libvirt/imagebackend.py', 'nova/tests/api/test_sizelimit.py', 'nova/tests/api/openstack/compute/contrib/test_console_auth_tokens.py', 'nova/objects/fields.py', 'nova/tests/virt/baremetal/test_tilera.py', 'nova/tests/virt/xenapi/test_volume_utils.py', 'nova/objects/network.py', 'nova/tests/scheduler/test_filter_scheduler.py', 'nova/scheduler/filters/json_filter.py', 'nova/tests/virt/test_virt_drivers.py', 'nova/tests/virt/hyperv/test_vhdutils.py', 'nova/tests/virt/vmwareapi/test_volumeops.py', 'nova/tests/test_service.py', 'nova/tests/api/openstack/compute/plugins/v3/test_availability_zone.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/tests/conductor/test_conductor.py', 'nova/cmd/baremetal_deploy_helper.py', 'nova/tests/test_metadata.py', 'nova/tests/virt/libvirt/test_vif.py', 'nova/api/openstack/xmlutil.py', 'nova/virt/hyperv/pathutils.py', 'nova/tests/virt/test_virt_disk_vfs_localfs.py', 'nova/tests/virt/vmwareapi/test_vim_util.py', 'nova/tests/integrated/test_multiprocess_api.py', 'nova/tests/objects/test_fields.py', 'nova/cmd/manage.py', 'nova/tests/virt/baremetal/test_pxe.py', 'nova/tests/db/test_sqlite.py', 'nova/tests/test_configdrive2.py', 'nova/tests/api/openstack/compute/contrib/test_floating_ip_dns.py', 'nova/tests/virt/xenapi/image/test_bittorrent.py', 'nova/tests/virt/test_virt_disk_vfs_guestfs.py', 'nova/tests/api/openstack/test_xmlutil.py', 'nova/tests/virt/hyperv/test_vmutilsv2.py', 'nova/tests/image/test_s3.py', 'nova/tests/virt/hyperv/test_rdpconsoleutils.py', 'nova/tests/network/test_manager.py', 'nova/tests/virt/vmwareapi/test_vm_util.py', 'tox.ini', 'nova/api/ec2/apirequest.py', 'nova/tests/test_objectstore.py', 'nova/tests/test_nova_manage.py', 'nova/tests/api/openstack/compute/contrib/test_console_output.py', 'nova/tests/consoleauth/test_consoleauth.py', 'nova/tests/virt/xenapi/image/test_vdi_through_dev.py', 'nova/tests/compute/test_vmmode.py', 'nova/tests/virt/vmwareapi/test_imagecache.py', 'nova/tests/virt/hyperv/test_rdpconsoleutilsv2.py', 'nova/tests/db/test_db_api.py', 'nova/api/openstack/compute/contrib/security_groups.py', 'nova/virt/hyperv/vhdutilsv2.py', 'nova/tests/test_cinder.py', 'plugins/xenserver/xenapi/etc/xapi.d/plugins/xenstore.py', 'nova/vnc/xvp_proxy.py', 'nova/virt/hyperv/vhdutils.py', 'nova/tests/api/openstack/compute/plugins/v3/test_services.py', 'nova/tests/matchers.py', 'nova/wsgi.py', 'nova/tests/test_wsgi.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/api/openstack/urlmap.py', 'nova/tests/objects/test_flavor.py', 'nova/tests/api/openstack/compute/plugins/v3/test_shelve.py', 'nova/tests/virt/libvirt/test_volume.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f3dc6eefe78463047f63c138cff62c664c21a971', 'message': 'Fix and gate on H305 and H307\n\nBoth H305 and H307 are part of the OpenStack style guide.\n\nEnsure that there are 3 groups of imports, stdlib,\nthird-party and project specific. Within each category\nensure that imports are in alphabetical order.\n\nChange-Id: Id4994551c135c3c1a4982153f0c6cacba6176b95\n'}]",0,105950,f3dc6eefe78463047f63c138cff62c664c21a971,45,15,3,5638,,,0,"Fix and gate on H305 and H307

Both H305 and H307 are part of the OpenStack style guide.

Ensure that there are 3 groups of imports, stdlib,
third-party and project specific. Within each category
ensure that imports are in alphabetical order.

Change-Id: Id4994551c135c3c1a4982153f0c6cacba6176b95
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/105950/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/vmwareapi/test_ds_util.py', 'nova/tests/api/openstack/compute/contrib/test_shelve.py', 'nova/tests/api/test_auth.py', 'nova/compute/monitors/__init__.py', 'nova/tests/api/openstack/test_wsgi.py', 'nova/virt/configdrive.py', 'nova/tests/api/openstack/compute/contrib/test_availability_zone.py', 'nova/tests/objects/test_instance_action.py', 'plugins/xenserver/xenapi/etc/xapi.d/plugins/pluginlib_nova.py', 'nova/virt/xenapi/image/vdi_through_dev.py', 'nova/tests/virt/hyperv/test_vmutils.py', 'nova/virt/xenapi/image/bittorrent.py', 'nova/tests/network/security_group/test_neutron_driver.py', 'nova/virt/xenapi/fake.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors.py', 'nova/virt/storage_users.py', 'nova/tests/virt/hyperv/test_vhdutilsv2.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/tests/volume/test_cinder.py', 'nova/tests/api/openstack/compute/plugins/v3/test_security_groups.py', 'nova/tests/compute/test_compute_api.py', 'nova/cmd/__init__.py', 'nova/tests/virt/hyperv/test_networkutilsv2.py', 'nova/virt/vmwareapi/error_util.py', 'nova/api/openstack/compute/contrib/console_output.py', 'nova/tests/image/test_glance.py', 'nova/tests/api/openstack/test_common.py', 'nova/tests/virt/vmwareapi/test_configdrive.py', 'nova/pci/pci_request.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/tests/compute/test_compute.py', 'nova/tests/api/openstack/compute/contrib/test_services.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py', 'nova/virt/libvirt/imagebackend.py', 'nova/tests/api/test_sizelimit.py', 'nova/tests/api/openstack/compute/contrib/test_console_auth_tokens.py', 'nova/objects/fields.py', 'nova/tests/virt/baremetal/test_tilera.py', 'nova/tests/virt/xenapi/test_volume_utils.py', 'nova/objects/network.py', 'nova/tests/scheduler/test_filter_scheduler.py', 'nova/scheduler/filters/json_filter.py', 'nova/tests/virt/test_virt_drivers.py', 'nova/tests/virt/hyperv/test_vhdutils.py', 'nova/tests/virt/vmwareapi/test_volumeops.py', 'nova/tests/test_service.py', 'nova/tests/api/openstack/compute/plugins/v3/test_availability_zone.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/tests/conductor/test_conductor.py', 'nova/cmd/baremetal_deploy_helper.py', 'nova/tests/test_metadata.py', 'nova/tests/virt/libvirt/test_vif.py', 'nova/api/openstack/xmlutil.py', 'nova/virt/hyperv/pathutils.py', 'nova/tests/virt/test_virt_disk_vfs_localfs.py', 'nova/tests/virt/vmwareapi/test_vim_util.py', 'nova/tests/integrated/test_multiprocess_api.py', 'nova/tests/objects/test_fields.py', 'nova/cmd/manage.py', 'nova/tests/virt/baremetal/test_pxe.py', 'nova/tests/db/test_sqlite.py', 'nova/tests/test_configdrive2.py', 'nova/tests/api/openstack/compute/contrib/test_floating_ip_dns.py', 'nova/tests/virt/xenapi/image/test_bittorrent.py', 'nova/tests/virt/test_virt_disk_vfs_guestfs.py', 'nova/tests/api/openstack/test_xmlutil.py', 'nova/tests/virt/hyperv/test_vmutilsv2.py', 'nova/tests/image/test_s3.py', 'nova/tests/virt/hyperv/test_rdpconsoleutils.py', 'nova/tests/network/test_manager.py', 'nova/tests/virt/vmwareapi/test_vm_util.py', 'tox.ini', 'nova/api/ec2/apirequest.py', 'nova/tests/test_objectstore.py', 'nova/tests/test_nova_manage.py', 'nova/tests/api/openstack/compute/contrib/test_console_output.py', 'nova/tests/consoleauth/test_consoleauth.py', 'nova/tests/virt/xenapi/image/test_vdi_through_dev.py', 'nova/tests/compute/test_vmmode.py', 'nova/tests/virt/vmwareapi/test_imagecache.py', 'nova/tests/virt/hyperv/test_rdpconsoleutilsv2.py', 'nova/tests/db/test_db_api.py', 'nova/api/openstack/compute/contrib/security_groups.py', 'nova/virt/hyperv/vhdutilsv2.py', 'nova/tests/test_cinder.py', 'plugins/xenserver/xenapi/etc/xapi.d/plugins/xenstore.py', 'nova/vnc/xvp_proxy.py', 'nova/virt/hyperv/vhdutils.py', 'nova/tests/api/openstack/compute/plugins/v3/test_services.py', 'nova/tests/matchers.py', 'nova/wsgi.py', 'nova/tests/test_wsgi.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/api/openstack/urlmap.py', 'nova/tests/objects/test_flavor.py', 'nova/tests/api/openstack/compute/plugins/v3/test_shelve.py', 'nova/tests/virt/libvirt/test_volume.py']",98,ed3381c59ffff4b03313890bf0a6b72ad6563203,(detached,import fixtures,import fixtures,123,117
openstack%2Fnova~master~I4ba30a9c0639803d19d5e8355f5bc8dd3f543671,openstack/nova,master,I4ba30a9c0639803d19d5e8355f5bc8dd3f543671,Remove unused instance variables from HostState,MERGED,2014-07-09 20:42:07.000000000,2014-07-17 03:18:12.000000000,2014-07-15 14:08:12.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1247}, {'_account_id': 2835}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8430}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 10614}]","[{'number': 1, 'created': '2014-07-09 20:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/954f1ab6ce896f81c0d06ff4e198119db44663d4', 'message': ""Remove num_instances_by_project from HostState\n\nThe request was to fix num_instances_by_project in HostState to\ncorrectly report state even when last VM was deleted.\n\nHowever in investigation I discovered this instance variable isn't\nused in openstack code.  Following policy, we should be removing\nthis code.\n\nChange-Id: I4ba30a9c0639803d19d5e8355f5bc8dd3f543671\nCloses-Bug: 1201379\n""}, {'number': 2, 'created': '2014-07-11 20:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7161fc0e0099ae2bd66e556796c0e5e2f807c25c', 'message': ""Remove unused instance variables from HostState\n\nThe request was to fix num_instances_by_project in HostState to\ncorrectly report state even when last VM was deleted.\n\nHowever in investigation I discovered this instance variable isn't\nused in openstack code.  Following policy, we should be removing this\ncode.  Also removed vm_states, task_states and\nnum_instances_by_os_type.\n\nChange-Id: I4ba30a9c0639803d19d5e8355f5bc8dd3f543671\nCloses-Bug: 1201379\n""}, {'number': 3, 'created': '2014-07-14 14:04:46.000000000', 'files': ['nova/tests/scheduler/test_host_manager.py', 'nova/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d3891b48e75d69a0f618db7c4d0e1b2ce638b980', 'message': ""Remove unused instance variables from HostState\n\nThe request was to fix num_instances_by_project in HostState to\ncorrectly report state even when last VM was deleted.\n\nHowever in investigation I discovered this instance variable isn't\nused in openstack code.  Following policy, we should be removing this\ncode.  Also removed vm_states, task_states and\nnum_instances_by_os_type.\n\nChange-Id: I4ba30a9c0639803d19d5e8355f5bc8dd3f543671\nCloses-Bug: 1201379\n""}]",2,105871,d3891b48e75d69a0f618db7c4d0e1b2ce638b980,62,15,3,8430,,,0,"Remove unused instance variables from HostState

The request was to fix num_instances_by_project in HostState to
correctly report state even when last VM was deleted.

However in investigation I discovered this instance variable isn't
used in openstack code.  Following policy, we should be removing this
code.  Also removed vm_states, task_states and
num_instances_by_os_type.

Change-Id: I4ba30a9c0639803d19d5e8355f5bc8dd3f543671
Closes-Bug: 1201379
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/105871/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_host_manager.py', 'nova/scheduler/host_manager.py']",2,954f1ab6ce896f81c0d06ff4e198119db44663d4,bug/1201379,," self.num_instances_by_project = {} # Track number of instances by project_id project_id_keys = [k for k in self.stats.keys() if k.startswith(""num_proj_"")] for key in project_id_keys: project_id = key[9:] self.num_instances_by_project[project_id] = int(self.stats[key]) # Track number of instances by project_id project_id = instance.get('project_id') if project_id not in self.num_instances_by_project: self.num_instances_by_project[project_id] = 0 self.num_instances_by_project[project_id] += 1 ",0,19
openstack%2Fnova~master~Ib3a85d0875c06c4e54e4211bc2fb8ce3fe16161d,openstack/nova,master,Ib3a85d0875c06c4e54e4211bc2fb8ce3fe16161d,Standardization of nova.image.API.download,MERGED,2014-06-08 23:17:24.000000000,2014-07-17 03:16:51.000000000,2014-07-16 04:07:04.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9275}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-08 23:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e3c941a79be81275be6ef8e816e18a48d8d6947', 'message': 'Standardization of nova.image.API.download\n\nBrings the wacky download method into the new nova.image.API object and\nremoves calls to nova.image.glance throughout the virt drivers that were\nusing various call signatures of glance.ImageService.download.\n\nThe final patch in this series will refactor the remaining direct use of\nthe nova.image.glance module, which are calls to\nglance.generate_image_url() and glance.generate_glance_url().\n\nChange-Id: Ib3a85d0875c06c4e54e4211bc2fb8ce3fe16161d\nPartially-implements: standardize-nova-image\n'}, {'number': 2, 'created': '2014-06-18 19:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e34f95ab31f586d292a5fd54ead562e833e72ac3', 'message': 'Standardization of nova.image.API.download\n\nBrings the wacky download method into the new nova.image.API object and\nremoves calls to nova.image.glance throughout the virt drivers that were\nusing various call signatures of glance.ImageService.download.\n\nThe final patch in this series will refactor the remaining direct use of\nthe nova.image.glance module, which are calls to\nglance.generate_image_url() and glance.generate_glance_url().\n\nChange-Id: Ib3a85d0875c06c4e54e4211bc2fb8ce3fe16161d\nPartially-implements blueprint: standardize-nova-image\n'}, {'number': 3, 'created': '2014-06-20 13:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ab56668045fbd8eb034c3846debd2985757a065', 'message': 'Standardization of nova.image.API.download\n\nBrings the wacky download method into the new nova.image.API object and\nremoves calls to nova.image.glance throughout the virt drivers that were\nusing various call signatures of glance.ImageService.download.\n\nThe final patch in this series will refactor the remaining direct use of\nthe nova.image.glance module, which are calls to\nglance.generate_image_url() and glance.generate_glance_url().\n\nChange-Id: Ib3a85d0875c06c4e54e4211bc2fb8ce3fe16161d\nPartially-implements blueprint: standardize-nova-image\n'}, {'number': 4, 'created': '2014-06-24 00:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/97256c7543a48475c9966ffefbabacb0a870a868', 'message': 'Standardization of nova.image.API.download\n\nBrings the wacky download method into the new nova.image.API object and\nremoves calls to nova.image.glance throughout the virt drivers that were\nusing various call signatures of glance.ImageService.download.\n\nThe final patch in this series will refactor the remaining direct use of\nthe nova.image.glance module, which are calls to\nglance.generate_image_url() and glance.generate_glance_url().\n\nChange-Id: Ib3a85d0875c06c4e54e4211bc2fb8ce3fe16161d\nPartially-implements blueprint: standardize-nova-image\n'}, {'number': 5, 'created': '2014-07-01 15:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/934b0dbc3a6f6472035643f7a481ace1034d3dec', 'message': 'Standardization of nova.image.API.download\n\nBrings the wacky download method into the new nova.image.API object and\nremoves calls to nova.image.glance throughout the virt drivers that were\nusing various call signatures of glance.ImageService.download.\n\nThe final patch in this series will refactor the remaining direct use of\nthe nova.image.glance module, which are calls to\nglance.generate_image_url() and glance.generate_glance_url().\n\nChange-Id: Ib3a85d0875c06c4e54e4211bc2fb8ce3fe16161d\nPartially-implements blueprint: standardize-nova-image\n'}, {'number': 6, 'created': '2014-07-14 08:31:40.000000000', 'files': ['nova/tests/virt/xenapi/image/test_utils.py', 'nova/virt/xenapi/image/utils.py', 'nova/tests/virt/vmwareapi/test_io_util.py', 'nova/tests/virt/vmwareapi/test_vmware_images.py', 'nova/virt/vmwareapi/io_util.py', 'nova/virt/vmwareapi/vmware_images.py', 'nova/image/api.py', 'nova/virt/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/44d312fb8107f9bc1d917023b8d0ee24f2defe62', 'message': 'Standardization of nova.image.API.download\n\nBrings the wacky download method into the new nova.image.API object and\nremoves calls to nova.image.glance throughout the virt drivers that were\nusing various call signatures of glance.ImageService.download. Since\nsome of the wrapper objects that fetched image bits from Glance were\nusing the get and update methods of the former\nnova.image.glance.GlanceImageService object, those calls were updated to\ninstead call the new, standardized nova.image.API methods of the same\nname and call signature.\n\nThe final patch in this series will refactor the remaining direct use of\nthe nova.image.glance module, which are calls to\nglance.generate_image_url() and glance.generate_glance_url().\n\nChange-Id: Ib3a85d0875c06c4e54e4211bc2fb8ce3fe16161d\nPartially-implements blueprint: standardize-nova-image\n'}]",10,98672,44d312fb8107f9bc1d917023b8d0ee24f2defe62,110,15,6,7,,,0,"Standardization of nova.image.API.download

Brings the wacky download method into the new nova.image.API object and
removes calls to nova.image.glance throughout the virt drivers that were
using various call signatures of glance.ImageService.download. Since
some of the wrapper objects that fetched image bits from Glance were
using the get and update methods of the former
nova.image.glance.GlanceImageService object, those calls were updated to
instead call the new, standardized nova.image.API methods of the same
name and call signature.

The final patch in this series will refactor the remaining direct use of
the nova.image.glance module, which are calls to
glance.generate_image_url() and glance.generate_glance_url().

Change-Id: Ib3a85d0875c06c4e54e4211bc2fb8ce3fe16161d
Partially-implements blueprint: standardize-nova-image
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/98672/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/xenapi/image/test_utils.py', 'nova/virt/xenapi/image/utils.py', 'nova/tests/virt/vmwareapi/test_io_util.py', 'nova/tests/virt/vmwareapi/test_vmware_images.py', 'nova/virt/vmwareapi/io_util.py', 'nova/virt/vmwareapi/vmware_images.py', 'nova/image/api.py', 'nova/virt/images.py']",8,3e3c941a79be81275be6ef8e816e18a48d8d6947,bp/standardize-nova-image,"from nova import imageIMAGE_API = image.API() with fileutils.remove_path_on_error(path): IMAGE_API.download(context, image_href, path)","from nova.image import glance # TODO(vish): Improve context handling and add owner and auth data # when it is added to glance. Right now there is no # auth checking in glance, so we assume that access was # checked before we got here. (image_service, image_id) = glance.get_remote_image_service(context, image_href) with fileutils.remove_path_on_error(path): image_service.download(context, image_id, dst_path=path)",105,123
openstack%2Fnova~master~I4ef0c4a6008acea7e9769e93de79451cfbc0a0fa,openstack/nova,master,I4ef0c4a6008acea7e9769e93de79451cfbc0a0fa,Catch InvalidAggregateAction when deleting an aggregate,MERGED,2014-04-07 06:01:42.000000000,2014-07-17 03:16:29.000000000,2014-07-16 02:51:47.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6348}, {'_account_id': 7461}, {'_account_id': 8163}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9545}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-07 06:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7ab714df5b4a65925f3dae924e3157da9c11e91', 'message': ""Catch InvalidAggregateAction when deleting an aggregate\n\nWhen an aggregate with 'host' attribute not empty is deleted,\nInvalidAggregateAction exception will be raised, but this exception\nis not handled.\nThis bug only exists in V3.\n\nCloses-Bug: #1303591\nChange-Id: I4ef0c4a6008acea7e9769e93de79451cfbc0a0fa\n""}, {'number': 2, 'created': '2014-04-07 06:23:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1d87c66019f515f624dcd386910139caa249996', 'message': ""Catch InvalidAggregateAction when deleting an aggregate\n\nWhen an aggregate with 'host' attribute not empty is deleted,\nInvalidAggregateAction exception will be raised, but this exception\nis not handled.\n\nCloses-Bug: #1303591\nChange-Id: I4ef0c4a6008acea7e9769e93de79451cfbc0a0fa\n""}, {'number': 3, 'created': '2014-07-10 08:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d3b779c1958c9213e6ac9bd41c82ed7918a7ab1', 'message': ""Catch InvalidAggregateAction when deleting an aggregate\n\nWhen an aggregate with 'host' attribute not empty is deleted,\nInvalidAggregateAction exception will be raised, but this exception\nis not handled.\n\nCloses-Bug: #1303591\nChange-Id: I4ef0c4a6008acea7e9769e93de79451cfbc0a0fa\n""}, {'number': 4, 'created': '2014-07-14 02:45:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e34e9855ec356f4585e0986f754f99d111788015', 'message': ""Catch InvalidAggregateAction when deleting an aggregate\n\nWhen an aggregate with 'host' attribute not empty is deleted,\nInvalidAggregateAction exception will be raised, but this exception\nis not handled.\n\nCloses-Bug: #1303591\nChange-Id: I4ef0c4a6008acea7e9769e93de79451cfbc0a0fa\n""}, {'number': 5, 'created': '2014-07-14 07:24:03.000000000', 'files': ['nova/api/openstack/compute/contrib/aggregates.py', 'nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/tests/api/openstack/compute/contrib/test_aggregates.py', 'nova/tests/api/openstack/compute/plugins/v3/test_aggregates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/86d1007c2078a0ad80e49088b37660466b1a5cb3', 'message': ""Catch InvalidAggregateAction when deleting an aggregate\n\nWhen an aggregate with 'host' attribute not empty is deleted,\nInvalidAggregateAction exception will be raised, but this exception\nis not handled.\n\nCloses-Bug: #1303591\nChange-Id: I4ef0c4a6008acea7e9769e93de79451cfbc0a0fa\n""}]",10,85643,86d1007c2078a0ad80e49088b37660466b1a5cb3,68,16,5,6348,,,0,"Catch InvalidAggregateAction when deleting an aggregate

When an aggregate with 'host' attribute not empty is deleted,
InvalidAggregateAction exception will be raised, but this exception
is not handled.

Closes-Bug: #1303591
Change-Id: I4ef0c4a6008acea7e9769e93de79451cfbc0a0fa
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/85643/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/tests/api/openstack/compute/plugins/v3/test_aggregates.py']",2,e7ab714df5b4a65925f3dae924e3157da9c11e91,aggregate_delete," def test_delete_aggregate_with_host(self): def stub_delete_aggregate(context, aggregate): raise exception.InvalidAggregateAction(action=""delete"", aggregate_id=""agg1"", reason=""not empty"") self.stubs.Set(self.controller.api, ""delete_aggregate"", stub_delete_aggregate) self.assertRaises(exc.HTTPBadRequest, self.controller.delete, self.req, ""agg1"")",,14,1
openstack%2Fnova~master~If1035deaf8b31f2712d88f0112fdd2e9e9dc7cb0,openstack/nova,master,If1035deaf8b31f2712d88f0112fdd2e9e9dc7cb0,Nova-api service throws error when SIGHUP is sent,MERGED,2014-07-04 13:02:22.000000000,2014-07-17 03:15:42.000000000,2014-07-15 03:02:23.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 679}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 10795}]","[{'number': 1, 'created': '2014-07-04 13:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f038f0820502f6378e2a35b030b2e93c135adf4', 'message': ""Nova-api service throws error when SIGHUP is sent\n\nAdded reset method in WSGIService class.\n\nAfter adding reset method when SIGHUP signal is sent to\nwsgi service parent process,then it sends SIGHUP signal\nto all of its child processes. Each child process handles\nSIGHUP signal by first stopping the service and then calls\nservice start method again. When it stops the service, it\nkills the eventlet thread, which internally closes the wsgi\nserver socket object. This server socket object is now not\nusable again and it throws following error, while restarting\nthe service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nWhen the wsgi service is stopped, it sets the green pool\nsize to 0, so resizing the green pool to default value,\non service restart.\n\nCloses-Bug: #1334651\n\nChange-Id: If1035deaf8b31f2712d88f0112fdd2e9e9dc7cb0\n""}, {'number': 2, 'created': '2014-07-09 07:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5cb5a0dfe91690f10c7e43650f970d1681816719', 'message': ""Nova-api service throws error when SIGHUP is sent\n\nAdded reset method in WSGIService class.\n\nAfter adding reset method when SIGHUP signal is sent to\nwsgi service parent process,then it sends SIGHUP signal\nto all of its child processes. Each child process handles\nSIGHUP signal by first stopping the service and then calls\nservice start method again. When it stops the service, it\nkills the eventlet thread, which internally closes the wsgi\nserver socket object. This server socket object is now not\nusable again and it throws following error, while restarting\nthe service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nWhen the wsgi service is stopped, it sets the green pool\nsize to 0, so resizing the green pool to default value,\non service restart.\n\nCloses-Bug: #1334651\n\nChange-Id: If1035deaf8b31f2712d88f0112fdd2e9e9dc7cb0\n""}, {'number': 3, 'created': '2014-07-14 06:04:51.000000000', 'files': ['nova/tests/test_service.py', 'nova/service.py', 'nova/tests/integrated/test_multiprocess_api.py', 'nova/wsgi.py', 'nova/tests/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2f3d774eb51eac9a370813362047a2cb3d124d86', 'message': ""Nova-api service throws error when SIGHUP is sent\n\nAdded reset method in WSGIService class.\n\nAfter adding reset method when SIGHUP signal is sent to\nwsgi service parent process,then it sends SIGHUP signal\nto all of its child processes. Each child process handles\nSIGHUP signal by first stopping the service and then calls\nservice start method again. When it stops the service, it\nkills the eventlet thread, which internally closes the wsgi\nserver socket object. This server socket object is now not\nusable again and it throws following error, while restarting\nthe service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nWhen the wsgi service is stopped, it sets the green pool\nsize to 0, so resizing the green pool to default value,\non service restart.\n\nCloses-Bug: #1334651\n\nChange-Id: If1035deaf8b31f2712d88f0112fdd2e9e9dc7cb0\n""}]",8,104887,2f3d774eb51eac9a370813362047a2cb3d124d86,51,12,3,10795,,,0,"Nova-api service throws error when SIGHUP is sent

Added reset method in WSGIService class.

After adding reset method when SIGHUP signal is sent to
wsgi service parent process,then it sends SIGHUP signal
to all of its child processes. Each child process handles
SIGHUP signal by first stopping the service and then calls
service start method again. When it stops the service, it
kills the eventlet thread, which internally closes the wsgi
server socket object. This server socket object is now not
usable again and it throws following error, while restarting
the service:

error: [Errno 9] Bad file descriptor

To resolve 'Bad file descriptor' error, creating duplicate
socket object, every time service starts.

When the wsgi service is stopped, it sets the green pool
size to 0, so resizing the green pool to default value,
on service restart.

Closes-Bug: #1334651

Change-Id: If1035deaf8b31f2712d88f0112fdd2e9e9dc7cb0
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/104887/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/service.py', 'nova/tests/test_service.py', 'nova/tests/integrated/test_multiprocess_api.py', 'nova/wsgi.py', 'nova/tests/test_wsgi.py']",5,9f038f0820502f6378e2a35b030b2e93c135adf4,rm/15650_dup," def test_reset_pool_size_to_default(self): server = nova.wsgi.Server(""test_resize"", None, host=""127.0.0.1"", max_url_len=16384) server.start() # Stopping the server, which in turn sets pool size to 0 server.stop() self.assertEqual(server._pool.size, 0) # Resetting pool size to default server.reset() server.start() self.assertEqual(server._pool.size, CONF.wsgi_default_pool_size) ",,65,2
openstack%2Fnova~master~I5d420a2bf9be77583f8afb97feb761406972f67a,openstack/nova,master,I5d420a2bf9be77583f8afb97feb761406972f67a,Enable terminate for EC2 InstanceInitiatedShutdownBehavior,ABANDONED,2014-07-14 04:15:52.000000000,2014-07-17 03:15:19.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-14 04:15:52.000000000', 'files': ['nova/tests/compute/test_compute_mgr.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py', 'nova/compute/manager.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7549f029645b7aa265ce7333dbfb21bac362e3da', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_instance_power_state now invokes compute_api.delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nCloses-bug #1131395\nChange-Id: I5d420a2bf9be77583f8afb97feb761406972f67a\n""}]",0,106680,7549f029645b7aa265ce7333dbfb21bac362e3da,7,5,1,6661,,,0,"Enable terminate for EC2 InstanceInitiatedShutdownBehavior

The EC2 API supports an instance attribute called
InstanceInitiatedShutdownBehavior (IISB) which can be set to
'stop' or 'terminate' (default: 'stop').  When the instance
initiates its own shutdown, this determines whether or not
the instance hangs around in the Shutoff state or is
terminated by the system.

In nova, this is handled by the shutdown_terminate boolean.
IISB = stop      => shutdown_terminate = False
IISB = terminate => shutdown_terminate = True

sync_instance_power_state now invokes compute_api.delete if
shutdown_terminate = True and we detect the instance power state
has gone from Running to Shutdown.

Closes-bug #1131395
Change-Id: I5d420a2bf9be77583f8afb97feb761406972f67a
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/106680/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_mgr.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py', 'nova/compute/manager.py', 'nova/compute/api.py']",5,7549f029645b7aa265ce7333dbfb21bac362e3da,bug/1131395," block_device_mapping, shutdown_terminate): num_instances, i, shutdown_terminate) legacy_bdm=True, shutdown_terminate=False): block_device_mapping, shutdown_terminate) def _populate_instance_shutdown_terminate(self, instance, shutdown_terminate=False): instance.shutdown_terminate = shutdown_terminate index, shutdown_terminate=False): self._populate_instance_shutdown_terminate(instance, shutdown_terminate) auto_disk_config=None, scheduler_hints=None, legacy_bdm=True, shutdown_terminate=False): legacy_bdm=legacy_bdm, shutdown_terminate=shutdown_terminate)"," block_device_mapping): num_instances, i) legacy_bdm=True): block_device_mapping) def _populate_instance_shutdown_terminate(self, instance, image, block_device_mapping): image_properties = image.get('properties', {}) if (block_device_mapping or image_properties.get('mappings') or image_properties.get('block_device_mapping')): instance.shutdown_terminate = False index): self._populate_instance_shutdown_terminate(instance, image, block_device_mapping) auto_disk_config=None, scheduler_hints=None, legacy_bdm=True): legacy_bdm=legacy_bdm)",44,24
openstack%2Fnova~master~I42eea6a2984f70527d4fc37f48ad973a2248721c,openstack/nova,master,I42eea6a2984f70527d4fc37f48ad973a2248721c,Remove cell api overrides for lock and unlock,MERGED,2014-04-22 06:39:11.000000000,2014-07-17 03:15:05.000000000,2014-07-14 15:59:26.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 3031}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-22 06:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c2362e17560da3740bb6a6450147d48a2216fca', 'message': ""Remove cell api overrides for lock and unlock\n\nThis isn't actually needed as these methods handle objects and is\ntriggered when the instance object is saved.\nIt actually caused a race condition with unlock as it triggers 2\ninstance updates from a compute cell.\n\nChange-Id: I42eea6a2984f70527d4fc37f48ad973a2248721c\nCloses-Bug: #1257168\n""}, {'number': 2, 'created': '2014-07-14 03:49:59.000000000', 'files': ['nova/compute/cells_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fb9b60fb5d3084d4cab29936fd1f534e5599f231', 'message': ""Remove cell api overrides for lock and unlock\n\nThis isn't actually needed as these methods handle objects and is\ntriggered when the instance object is saved.\nIt actually caused a race condition with unlock as it triggers 2\ninstance updates from a compute cell.\n\nChange-Id: I42eea6a2984f70527d4fc37f48ad973a2248721c\nCloses-Bug: #1257168\n""}]",0,89487,fb9b60fb5d3084d4cab29936fd1f534e5599f231,30,12,2,3031,,,0,"Remove cell api overrides for lock and unlock

This isn't actually needed as these methods handle objects and is
triggered when the instance object is saved.
It actually caused a race condition with unlock as it triggers 2
instance updates from a compute cell.

Change-Id: I42eea6a2984f70527d4fc37f48ad973a2248721c
Closes-Bug: #1257168
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/89487/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/cells_api.py'],1,1c2362e17560da3740bb6a6450147d48a2216fca,bugs/1257168,," def lock(self, context, instance): """"""Lock the given instance."""""" super(ComputeCellsAPI, self).lock(context, instance) self._cast_to_cells(context, instance, 'lock') def unlock(self, context, instance): """"""Unlock the given instance."""""" super(ComputeCellsAPI, self).lock(context, instance) self._cast_to_cells(context, instance, 'unlock') ",0,10
openstack%2Fnova~master~I8ec317481dc7da299225ac605f90b146e7a6d98b,openstack/nova,master,I8ec317481dc7da299225ac605f90b146e7a6d98b,Move injected_network_template config to where it's used,MERGED,2014-07-16 20:48:23.000000000,2014-07-17 03:11:56.000000000,2014-07-17 03:11:54.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-16 20:48:23.000000000', 'files': ['nova/virt/netutils.py', 'nova/virt/disk/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4ae968ef505b84032d0ab4ab9b64fbe46d3f83ee', 'message': ""Move injected_network_template config to where it's used\n\nThe config is used by netutils, so netutils should be the place where it's\ndefined.\n\nChange-Id: I8ec317481dc7da299225ac605f90b146e7a6d98b\n""}]",0,107494,4ae968ef505b84032d0ab4ab9b64fbe46d3f83ee,11,6,1,475,,,0,"Move injected_network_template config to where it's used

The config is used by netutils, so netutils should be the place where it's
defined.

Change-Id: I8ec317481dc7da299225ac605f90b146e7a6d98b
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/107494/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/netutils.py', 'nova/virt/disk/api.py']",2,4ae968ef505b84032d0ab4ab9b64fbe46d3f83ee,move-injected-network-template,,"from nova import paths cfg.StrOpt('injected_network_template', default=paths.basedir_def('nova/virt/interfaces.template'), help='Template file for injected network'), ",9,6
openstack%2Fpython-keystoneclient~master~Ia13a24dc0632d3fb0a5b127538117872a7dc660d,openstack/python-keystoneclient,master,Ia13a24dc0632d3fb0a5b127538117872a7dc660d,Add V2 tenant user manager tests,MERGED,2014-07-04 06:35:36.000000000,2014-07-17 02:52:10.000000000,2014-07-11 17:11:17.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 7191}, {'_account_id': 11589}]","[{'number': 1, 'created': '2014-07-04 06:35:36.000000000', 'files': ['keystoneclient/tests/v2_0/test_tenants.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ee52726351d3dcaac72f149e6ce50b07af12edd7', 'message': 'Add V2 tenant user manager tests\n\nThe cross over between the tenant manager and the user manager is not\ntested. As this will be changed soon re-enforce the current behaviour.\n\nChange-Id: Ia13a24dc0632d3fb0a5b127538117872a7dc660d\n'}]",1,104767,ee52726351d3dcaac72f149e6ce50b07af12edd7,16,6,1,7191,,,0,"Add V2 tenant user manager tests

The cross over between the tenant manager and the user manager is not
tested. As this will be changed soon re-enforce the current behaviour.

Change-Id: Ia13a24dc0632d3fb0a5b127538117872a7dc660d
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/67/104767/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/tests/v2_0/test_tenants.py'],1,ee52726351d3dcaac72f149e6ce50b07af12edd7,client-adapter,"from keystoneclient.v2_0 import users @httpretty.activate def test_tenant_list_users(self): tenant_id = uuid.uuid4().hex user_id1 = uuid.uuid4().hex user_id2 = uuid.uuid4().hex tenant_resp = { 'tenant': { 'name': uuid.uuid4().hex, 'enabled': True, 'id': tenant_id, 'description': 'test tenant', } } users_resp = { 'users': { 'values': [ { 'email': uuid.uuid4().hex, 'enabled': True, 'id': user_id1, 'name': uuid.uuid4().hex, }, { 'email': uuid.uuid4().hex, 'enabled': True, 'id': user_id2, 'name': uuid.uuid4().hex, }, ] } } self.stub_url(httpretty.GET, ['tenants', tenant_id], json=tenant_resp) self.stub_url(httpretty.GET, ['tenants', tenant_id, 'users'], json=users_resp) tenant = self.client.tenants.get(tenant_id) user_objs = tenant.list_users() for u in user_objs: self.assertIsInstance(u, users.User) self.assertEqual(set([user_id1, user_id2]), set([u.id for u in user_objs]))",,49,0
openstack%2Fpython-keystoneclient~master~Ie238dda046ec8bbdaca749a691df3da63f5a9a63,openstack/python-keystoneclient,master,Ie238dda046ec8bbdaca749a691df3da63f5a9a63,Pass user and roles manager to tenant manager,MERGED,2014-07-04 06:35:36.000000000,2014-07-17 02:51:00.000000000,2014-07-11 18:21:47.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 11589}]","[{'number': 1, 'created': '2014-07-04 06:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/d529e1e6a9ef27b62d4b3baa02bf103651d4c402', 'message': 'Pass user and roles manager to tenant manager\n\nThis is part of breaking a cyclical dependency where the client has a\nreference to the manager but the manager has a reference to the client.\n\nTo be able to pass in an adapter to the managers we need to remove the\nclient specific usages of manager, including referring to other managers\nvia the client.\n\nChange-Id: Ie238dda046ec8bbdaca749a691df3da63f5a9a63\n'}, {'number': 2, 'created': '2014-07-04 06:42:07.000000000', 'files': ['keystoneclient/v2_0/client.py', 'keystoneclient/v2_0/tenants.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/3a60390fd2b77460eab6eadf2c1eefb3f30caac4', 'message': 'Pass user and roles manager to tenant manager\n\nThis is part of breaking a cyclical dependency where the client has a\nreference to the manager but the manager has a reference to the client.\n\nTo be able to pass in an adapter to the managers we need to remove the\nclient specific usages of manager, including referring to other managers\nvia the client.\n\nChange-Id: Ie238dda046ec8bbdaca749a691df3da63f5a9a63\n'}]",0,104768,3a60390fd2b77460eab6eadf2c1eefb3f30caac4,15,5,2,7191,,,0,"Pass user and roles manager to tenant manager

This is part of breaking a cyclical dependency where the client has a
reference to the manager but the manager has a reference to the client.

To be able to pass in an adapter to the managers we need to remove the
client specific usages of manager, including referring to other managers
via the client.

Change-Id: Ie238dda046ec8bbdaca749a691df3da63f5a9a63
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/68/104768/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/v2_0/client.py', 'keystoneclient/v2_0/tenants.py']",2,d529e1e6a9ef27b62d4b3baa02bf103651d4c402,client-adapter," def __init__(self, client, role_manager, user_manager): super(TenantManager, self).__init__(client) self.role_manager = role_manager self.user_manager = user_manager return self.user_manager.list(base.getid(tenant)) return self.role_manager.add_user_role(base.getid(user), base.getid(role), base.getid(tenant)) return self.role_manager.remove_user_role(base.getid(user), base.getid(role), base.getid(tenant))"," return self.api.users.list(base.getid(tenant)) return self.api.roles.add_user_role(base.getid(user), base.getid(role), base.getid(tenant)) return self.api.roles.remove_user_role(base.getid(user), base.getid(role), base.getid(tenant))",14,8
openstack%2Fpython-keystoneclient~master~Icae9ef0a95fc39cc898564ba49c23f848faeb888,openstack/python-keystoneclient,master,Icae9ef0a95fc39cc898564ba49c23f848faeb888,Add V3 parameters to V2 Password plugin,ABANDONED,2014-06-20 15:04:23.000000000,2014-07-17 02:47:32.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 6482}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-06-20 15:04:23.000000000', 'files': ['keystoneclient/auth/identity/v2.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/c37eb18154de498d4991d099bc910ad77fcdb965', 'message': 'Add V3 parameters to V2 Password plugin\n\nChange-Id: Icae9ef0a95fc39cc898564ba49c23f848faeb888\nCloses-Bug: 1332553\n'}]",3,101574,c37eb18154de498d4991d099bc910ad77fcdb965,11,5,1,2218,,,0,"Add V3 parameters to V2 Password plugin

Change-Id: Icae9ef0a95fc39cc898564ba49c23f848faeb888
Closes-Bug: 1332553
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/74/101574/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/auth/identity/v2.py'],1,c37eb18154de498d4991d099bc910ad77fcdb965,bug/1332553," def __init__(self, auth_url, username, password, #the following three parameters are for parity with the #V3 Plugin only. They will be ignored if passed in. user_id=None, user_domain_id=None, user_domain_name=None, **kwargs): :param string user_id: Ignored. :param string user_domain_id: Ignored. :param string user_domain_name: Ignored."," def __init__(self, auth_url, username, password, **kwargs):",10,1
openstack%2Fkeystone~master~I658ac8dc61d6a8cdacb243a10d853cf9f6aa9409,openstack/keystone,master,I658ac8dc61d6a8cdacb243a10d853cf9f6aa9409,Update the configuration docs for the revocation extension,MERGED,2014-07-11 15:53:16.000000000,2014-07-17 02:00:50.000000000,2014-07-17 02:00:49.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 11333}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-07-11 15:53:16.000000000', 'files': ['doc/source/extensions/revoke.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2d3daeade8278ed4b29608bc63c6f4eca2c55cf6', 'message': 'Update the configuration docs for the revocation extension\n\nThere was a formatting error in how step 1 appeared, and I also\nchanged the title to the more formal name instead of OS-REVOKE,\nas the other extensions did not use their OS-* name.\n\nChange-Id: I658ac8dc61d6a8cdacb243a10d853cf9f6aa9409\n'}]",0,106416,2d3daeade8278ed4b29608bc63c6f4eca2c55cf6,13,8,1,6482,,,0,"Update the configuration docs for the revocation extension

There was a formatting error in how step 1 appeared, and I also
changed the title to the more formal name instead of OS-REVOKE,
as the other extensions did not use their OS-* name.

Change-Id: I658ac8dc61d6a8cdacb243a10d853cf9f6aa9409
",git fetch https://review.opendev.org/openstack/keystone refs/changes/16/106416/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/extensions/revoke.rst'],1,2d3daeade8278ed4b29608bc63c6f4eca2c55cf6,update_revocation_docs,================================= Enabling the Revocation Extension ================================= For the SQL driver::,================================ Enabling the OS-REVOKE Extension ================================For the SQL driver::,4,4
openstack%2Fsecurity-doc~master~I78a961c06987a8c415d248469868dd571c1484a2,openstack/security-doc,master,I78a961c06987a8c415d248469868dd571c1484a2,Basic cleanup and edits for ch15,MERGED,2014-07-15 22:05:43.000000000,2014-07-17 01:56:58.000000000,2014-07-17 01:56:57.000000000,"[{'_account_id': 3}, {'_account_id': 2807}, {'_account_id': 6547}, {'_account_id': 7063}]","[{'number': 1, 'created': '2014-07-15 22:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/5cfa34db5a2628eccda8c3629aa3fb775da69c72', 'message': 'Basic cleanup and edits for ch15\n\nCleaned up wording and use of sections. Provided some more clarity around\nthe introduction and some of the cipher options.\n\nChange-Id: I78a961c06987a8c415d248469868dd571c1484a2\n'}, {'number': 2, 'created': '2014-07-16 18:16:40.000000000', 'files': ['security-guide/ch_ssl-proxies-and-http-services.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/45b671e101fefaee8b4dede3832538f3ba524109', 'message': 'Basic cleanup and edits for ch15\n\nCleaned up wording and use of sections. Provided some more clarity around\nthe introduction and some of the cipher options.\n\nChange-Id: I78a961c06987a8c415d248469868dd571c1484a2\n'}]",4,107189,45b671e101fefaee8b4dede3832538f3ba524109,15,4,2,2807,,,0,"Basic cleanup and edits for ch15

Cleaned up wording and use of sections. Provided some more clarity around
the introduction and some of the cipher options.

Change-Id: I78a961c06987a8c415d248469868dd571c1484a2
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/89/107189/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_ssl-proxies-and-http-services.xml'],1,5cfa34db5a2628eccda8c3629aa3fb775da69c72,ch15_cleanup," <para>OpenStack endpoints are HTTP services providing APIs to both end-users on public networks and to other OpenStack services on the management network. It is highly recommended that all of these requests, both internal and external, operate over SSL. To achieve this goal, API services must be deployed behind a SSL proxy that can establish and terminate SSL sessions. The following table offers a non-exhaustive list of open source software that can be used for this purpose:</para> <para>In cases where software termination offers insufficient performance, hardware accelerators may be worth exploring as an alternative option. It is important to be mindful of the size of requests that will be processed by any chosen SSL proxy.</para> <para>Below we provide sample recommended configuration settings for enabling SSL in some of the more popular web servers/SSL terminators. Note that we have SSL v3 enabled in some of these examples as this will be required in many deployments for client compatibility.</para> <para>Disallows clear text.</para> <para>Disallows export encryption algorithms, which by design tend to be weak, typically using 40 and 56 bit keys.</para> <para>Disallows low (56 or 64 bit long keys) and medium (128 bit long keys) ciphers because of their vulnerability to brute force attacks (example 2-DES). This rule still permits Triple Data Encryption Standard (Triple DES) also known as Triple Data Encryption Algorithm (TDEA) and the Advanced Encryption Standard (AES), each of which has keys greater than equal to 128 bits and thus more secure.</para> <title>Pound</title> <para>This Pound example enables <literal>AES-NI</literal> acceleration, which helps to improve performance on systems with processors that support this feature.</para> <para>This stud example enables SSL v3 for client compatibility. The <emphasis role=""italic"" >ciphers</emphasis> line can be tweaked based on your needs, however this is a reasonable starting place.</para> <para>This nginx example requires TLS v1.1 or v1.2 for maximum security. The <emphasis role=""italic"">ssl_ciphers</emphasis> line can be tweaked based on your needs, however this is a reasonable starting place.</para> </section> <para>We recommend that all production deployments use HTTP strict transport security (HSTS). This header prevents browsers from making insecure connections after they have made a single secure one. If you have deployed your HTTP services on a public or an untrusted domain, HSTS is especially important. To enable HSTS, configure your web server to send a header like this with all requests:</para> <para>Start with a short timeout of 1 day during testing, and raise it to one year after testing has shown that you have not introduced problems for users. Note that once this header is set to a large timeout, it is (by design) very difficult to disable.</para>"," <para>OpenStack endpoints are HTTP services providing APIs to both end-users on public networks and to other OpenStack services within the same deployment operating over the management network. It is highly recommended these requests, both those internal and external, operate over SSL.</para> <para>In order for API requests to be encrypted by SSL it's necessary to position the API services behind a proxy that will establish and terminate SSL sessions. The following table offers a non-exhaustive list of software services that can proxy SSL traffic for API requests:</para><listitem> <para>Hardware appliance SSL acceleration proxies</para> </listitem> <para>It is important to be mindful of the size of requests that will be processed by any chosen SSL proxy.</para> <para>Below we provide some sample recommended configuration settings for enabling SSL in some of the more popular web servers/SSL terminators. Note that we have SSL v3 enabled in some of these examples as this will be required in many deployments for client compatibility.</para> <para>Disallows clear text</para> <para>Disallows export encryption algorithms, which by design tend to were weak, typically using 40 and 56 bit keys.</para> <para>Disallows low (keys 56 or 64 bits long) and medium (128 bit long keys) ciphers because of their vulnerability to brute force attacks (example 2-DES). This constraint leaves acceptable Triple Data Encryption Standard (Triple DES) also known as Triple Data Encryption Algorithm (TDEA) and the Advanced Encryption Standard (AES), each of which has keys greater than equal to 128 bits and thus more secure.</para> <title>Pound - with AES-NI acceleration</title> <para>This stud example enables SSL v3 for client compatibility. The ciphers line can be tweaked based on your needs, however this is a reasonable starting place.</para> </section> <para>This nginx example requires TLS v1.1 or v1.2 for maximum security. The ssl_ciphers line can be tweaked based on your needs, however this is a reasonable starting place.</para> <para>We recommend that all production deployments use HSTS. This header prevents browsers from making insecure connections after they have made a single secure one. If you have deployed your HTTP services on a public or an untrusted domain, HSTS is especially important. To enable HSTS, configure your web server to send a header like this with all requests:</para> <para>Start with a short timeout of 1 day during testing, and raise it to one year after testing has shown that you haven't introduced problems for users. Note that once this header is set to a large timeout, it is (by design) very difficult to disable.</para>",38,16
openstack%2Fkeystone~master~I853469f1fb5f5274ef52caaeb2d12b3164433697,openstack/keystone,master,I853469f1fb5f5274ef52caaeb2d12b3164433697,Sync with oslo-incubator,MERGED,2014-07-16 00:59:04.000000000,2014-07-17 01:40:40.000000000,2014-07-17 01:40:39.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6486}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-07-16 00:59:04.000000000', 'files': ['keystone/openstack/common/log.py', 'keystone/openstack/common/strutils.py', 'keystone/openstack/common/jsonutils.py', 'keystone/openstack/common/gettextutils.py', 'keystone/openstack/common/versionutils.py', 'keystone/openstack/common/lockutils.py', 'keystone/openstack/common/loopingcall.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1070afe2cb8707ad28d43c4ea76116a941cf2131', 'message': 'Sync with oslo-incubator\n\nThis syncs keystone with oslo-incubator commit hash\n5fa2dae429a9e37dfd1a527eb3957cea57a3e8c4\n\nCommits since last sync (e9bb0b59):\n-----------------------------------\n0506d17 cfgfilter has graduated, remove it\ne5c78bb log: make set_defaults() tests clean up properly\n05ae498 Add JUNO as a target to versionutils module\n569979a Fix tests.unit.reports.test_base_report with python3.4\ne184dd3 Fix exception message in openstack.common.processutils.execute\n3d90045 Backport code for i18n to check lazy at runtime\n43b0df3 Updated from global requirements\nef37e03 Added missing jsonutils.dump() function\n5fd77eb Ability to customize default_log_levels for each project\n4d9328c Python 3: enable tests/unit/test_log.py\nb8db732 Delete \'deprecated\' directory\na44ad7b Allow test_lockutils to run in isolation\n8b5bc62 Allow test_service to run in isolation\n80284aa Mark gettextutils obsolete\nd6b55fb Remove `processutils` dependency on `log`\ncb5a804 Move `mask_password` to strutils\n9502a21 Use the standard python logging in network_utils\n3310d8d update new requests logger to default WARN\ne377393 Changes calcuation of variable delay\nab5d5f1 Use timestamp in loopingcall\n5c68515 Updated from global requirements\n011fc27 Python 3: replace ""im_self"" by ""__self__""\n5c11c4d Don\'t import fcntl on Windows\n33afb20 Fix broken formatting of processutils.execute log statement\n6751b30 Remove extra whitespace\n\nChange-Id: I853469f1fb5f5274ef52caaeb2d12b3164433697\nRelated-BP: non-persistent-tokens\n'}]",3,107217,1070afe2cb8707ad28d43c4ea76116a941cf2131,12,5,1,2903,,,0,"Sync with oslo-incubator

This syncs keystone with oslo-incubator commit hash
5fa2dae429a9e37dfd1a527eb3957cea57a3e8c4

Commits since last sync (e9bb0b59):
-----------------------------------
0506d17 cfgfilter has graduated, remove it
e5c78bb log: make set_defaults() tests clean up properly
05ae498 Add JUNO as a target to versionutils module
569979a Fix tests.unit.reports.test_base_report with python3.4
e184dd3 Fix exception message in openstack.common.processutils.execute
3d90045 Backport code for i18n to check lazy at runtime
43b0df3 Updated from global requirements
ef37e03 Added missing jsonutils.dump() function
5fd77eb Ability to customize default_log_levels for each project
4d9328c Python 3: enable tests/unit/test_log.py
b8db732 Delete 'deprecated' directory
a44ad7b Allow test_lockutils to run in isolation
8b5bc62 Allow test_service to run in isolation
80284aa Mark gettextutils obsolete
d6b55fb Remove `processutils` dependency on `log`
cb5a804 Move `mask_password` to strutils
9502a21 Use the standard python logging in network_utils
3310d8d update new requests logger to default WARN
e377393 Changes calcuation of variable delay
ab5d5f1 Use timestamp in loopingcall
5c68515 Updated from global requirements
011fc27 Python 3: replace ""im_self"" by ""__self__""
5c11c4d Don't import fcntl on Windows
33afb20 Fix broken formatting of processutils.execute log statement
6751b30 Remove extra whitespace

Change-Id: I853469f1fb5f5274ef52caaeb2d12b3164433697
Related-BP: non-persistent-tokens
",git fetch https://review.opendev.org/openstack/keystone refs/changes/17/107217/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/openstack/common/log.py', 'keystone/openstack/common/strutils.py', 'keystone/openstack/common/jsonutils.py', 'keystone/openstack/common/gettextutils.py', 'keystone/openstack/common/versionutils.py', 'keystone/openstack/common/lockutils.py', 'keystone/openstack/common/loopingcall.py']",7,1070afe2cb8707ad28d43c4ea76116a941cf2131,bp/non-persistent-tokens,"import time# NOTE(zyluo): This lambda function was declared to avoid mocking collisions # with time.time() called in the standard logging module # during unittests. _ts = lambda: time.time() start = _ts() end = _ts() delay = end - start - interval if delay > 0: 'interval by %(delay).2f sec'), {'func_name': repr(self.f), 'delay': delay}) greenthread.sleep(-delay if delay < 0 else 0)","from keystone.openstack.common import timeutils start = timeutils.utcnow() end = timeutils.utcnow() delay = interval - timeutils.delta_seconds(start, end) if delay <= 0: 'interval by %(delay)s sec'), {'func_name': repr(self.f), 'delay': -delay}) greenthread.sleep(delay if delay > 0 else 0)",133,121
openstack%2Fpython-keystoneclient~master~Iab82a33639ffebb291d48b6c840f6756f2351032,openstack/python-keystoneclient,master,Iab82a33639ffebb291d48b6c840f6756f2351032,Isolate the identity get_endpoint function,ABANDONED,2014-07-15 09:50:04.000000000,2014-07-17 01:35:51.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-15 09:50:04.000000000', 'files': ['keystoneclient/auth/identity/base.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/622619922eb8c36eb3510620addaf80fa1214cc2', 'message': ""Isolate the identity get_endpoint function\n\nThis logic is going to be needed in at least the auth_token middleware\nfor an identity plugin that can't be re-authenticated.\n\nIsolate it into it's own function for re-use.\n\nChange-Id: Iab82a33639ffebb291d48b6c840f6756f2351032\n""}]",0,106976,622619922eb8c36eb3510620addaf80fa1214cc2,4,1,1,7191,,,0,"Isolate the identity get_endpoint function

This logic is going to be needed in at least the auth_token middleware
for an identity plugin that can't be re-authenticated.

Isolate it into it's own function for re-use.

Change-Id: Iab82a33639ffebb291d48b6c840f6756f2351032
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/76/106976/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/auth/identity/base.py'],1,622619922eb8c36eb3510620addaf80fa1214cc2,isolate-get-endpoint,"from keystoneclient import utils@utils.positional(2) def get_endpoint_from_catalog(session, catalog, service_type=None, interface=None, region_name=None, service_name=None, version=None, endpoint_cache=None, log=LOG, **kwargs): """"""Lookup and do discovery of a URL from a service catalog. Query the service catalog based on the parameters provided to a get_endpoint call and then do discovery on the URL to find the URL for a specific version. """""" if not service_type: log.warn('Plugin cannot return an endpoint without knowing the ' 'service type that is required. Add service_type to ' 'endpoint filtering data.') return None if not interface: interface = 'public' sc_url = catalog.url_for(service_type=service_type, endpoint_type=interface, region_name=region_name, service_name=service_name) if not version: # NOTE(jamielennox): This may not be the best thing to default to # but is here for backwards compatibility. It may be worth # defaulting to the most recent version. return sc_url disc = None # NOTE(jamielennox): we want to cache endpoints on the session as well # so that they maintain sharing between auth plugins. Create a cache on # the session if it doesn't exist already. try: session_endpoint_cache = session._identity_endpoint_cache except AttributeError: session_endpoint_cache = session._identity_endpoint_cache = {} # NOTE(jamielennox): in the event that no other cache is passed then just # have a disposable cache rather than a new set of logic. if endpoint_cache is None: endpoint_cache = {} # NOTE(jamielennox): There is a cache located on both the session # object and the auth plugin object so that they can be shared and the # cache is still usable for cache in (endpoint_cache, session_endpoint_cache): disc = cache.get(sc_url) if disc: break else: try: disc = _discover.Discover(session, sc_url) except (exceptions.HTTPError, exceptions.ConnectionError): log.warn('Failed to contact the endpoint at %s for discovery. ' 'Fallback to using that endpoint as the ' 'base url.', sc_url) return sc_url else: endpoint_cache[sc_url] = disc session_endpoint_cache[sc_url] = disc return disc.url_for(version) def get_endpoint(self, session, **kwargs): catalog = self.get_access(session).service_catalog return get_endpoint_from_catalog(session, catalog, log=LOG, endpoint_cache=self._endpoint_cache, **kwargs)"," def get_endpoint(self, session, service_type=None, interface=None, region_name=None, service_name=None, version=None, **kwargs): if not service_type: LOG.warn('Plugin cannot return an endpoint without knowing the ' 'service type that is required. Add service_type to ' 'endpoint filtering data.') return None if not interface: interface = 'public' service_catalog = self.get_access(session).service_catalog sc_url = service_catalog.url_for(service_type=service_type, endpoint_type=interface, region_name=region_name, service_name=service_name) if not version: # NOTE(jamielennox): This may not be the best thing to default to # but is here for backwards compatibility. It may be worth # defaulting to the most recent version. return sc_url disc = None # NOTE(jamielennox): we want to cache endpoints on the session as well # so that they maintain sharing between auth plugins. Create a cache on # the session if it doesn't exist already. try: session_endpoint_cache = session._identity_endpoint_cache except AttributeError: session_endpoint_cache = session._identity_endpoint_cache = {} # NOTE(jamielennox): There is a cache located on both the session # object and the auth plugin object so that they can be shared and the # cache is still usable for cache in (self._endpoint_cache, session_endpoint_cache): disc = cache.get(sc_url) if disc: break else: try: disc = _discover.Discover(session, sc_url) except (exceptions.HTTPError, exceptions.ConnectionError): LOG.warn('Failed to contact the endpoint at %s for discovery. ' 'Fallback to using that endpoint as the ' 'base url.', sc_url) return sc_url else: self._endpoint_cache[sc_url] = disc session_endpoint_cache[sc_url] = disc return disc.url_for(version)",79,56
openstack%2Fneutron~master~I812f4531de1f9a34d6e365b90efaeca3f79ce29b,openstack/neutron,master,I812f4531de1f9a34d6e365b90efaeca3f79ce29b,Modify Bad LOG format,ABANDONED,2014-07-14 07:37:04.000000000,2014-07-17 01:31:41.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-14 07:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/10b8ce7afe3aa5719eb252599db1be38e56f2e0e', 'message': 'Modify Bad LOG format\n\nWe have some bad log format in code, I go through the code and\nmodify them.\n\nChange-Id: I812f4531de1f9a34d6e365b90efaeca3f79ce29b\nCloses-Bug: #1341458\n'}, {'number': 2, 'created': '2014-07-14 09:39:34.000000000', 'files': ['neutron/tests/unit/database_stubs.py', 'neutron/tests/unit/vmware/apiclient/fake.py', 'neutron/db/agentschedulers_db.py', 'neutron/tests/unit/services/vpn/device_drivers/cisco_csr_mock.py', 'neutron/plugins/ml2/drivers/mechanism_fslsdn.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b21ba557bebe9ef40979849dd0b68659fbb805ac', 'message': 'Modify Bad LOG format\n\nWe have some bad log format in code, I go through the code and\nmodify them.\n\nChange-Id: I812f4531de1f9a34d6e365b90efaeca3f79ce29b\nCloses-Bug: #1341458\n'}]",0,106700,b21ba557bebe9ef40979849dd0b68659fbb805ac,43,21,2,9820,,,0,"Modify Bad LOG format

We have some bad log format in code, I go through the code and
modify them.

Change-Id: I812f4531de1f9a34d6e365b90efaeca3f79ce29b
Closes-Bug: #1341458
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/106700/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/database_stubs.py', 'neutron/tests/unit/vmware/apiclient/fake.py', 'neutron/db/agentschedulers_db.py', 'neutron/tests/unit/services/vpn/device_drivers/cisco_csr_mock.py', 'neutron/plugins/ml2/drivers/mechanism_fslsdn.py']",5,10b8ce7afe3aa5719eb252599db1be38e56f2e0e,bug1341458," LOG.debug(_(""create_network update sent to CRD Server: %s""), body) LOG.debug(_(""update_network update sent to CRD Server: %s""), body) _(""delete_network update sent to CRD Server: %s""), LOG.debug(_(""More than one fixed IP exists - using first one."")) LOG.debug(_(""Handling fixed IP {subnet_id:%(subnet)s, "" ""ip_address:%(ip)s}""), LOG.debug(_(""No fixed IPs found."")) LOG.debug(_(""create_port update sent to CRD Server: %s""), body) LOG.debug(_(""delete_port update sent to CRD Server: %s""), port['id']) LOG.debug(_(""create_subnet update sent to CRD Server: %s""), body) LOG.debug(_(""update_subnet update sent to CRD Server: %s""), body) LOG.debug(_(""delete_subnet update sent to CRD Server: %s""), subnet['id']) LOG.debug(_(""Attempting to bind port %(port)s on "" ""network %(network)s""), LOG.debug(_(""Bound using segment: %s""), segment) LOG.debug(_(""Refusing to bind port for segment ID %(id)s, "" ""network type %(nettype)s""),"," LOG.debug(""create_network update sent to CRD Server: %s"", body) LOG.debug(""update_network update sent to CRD Server: %s"", body) ""delete_network update sent to CRD Server: %s"", LOG.debug(""More than one fixed IP exists - using first one."") LOG.debug(""Handling fixed IP {subnet_id:%(subnet)s, "" ""ip_address:%(ip)s}"", LOG.debug(""No fixed IPs found."") LOG.debug(""create_port update sent to CRD Server: %s"", body) LOG.debug(""delete_port update sent to CRD Server: %s"", port['id']) LOG.debug(""create_subnet update sent to CRD Server: %s"", body) LOG.debug(""update_subnet update sent to CRD Server: %s"", body) LOG.debug(""delete_subnet update sent to CRD Server: %s"", subnet['id']) LOG.debug(""Attempting to bind port %(port)s on "" ""network %(network)s"", LOG.debug(""Bound using segment: %s"", segment) LOG.debug(""Refusing to bind port for segment ID %(id)s, "" ""network type %(nettype)s"",",61,60
openstack%2Fkeystone~master~I4cec4fe5de4530d8da79e3be10e2d8fe431ed1f1,openstack/keystone,master,I4cec4fe5de4530d8da79e3be10e2d8fe431ed1f1,Avoid loading a ref from SQL to delete the ref,MERGED,2014-07-10 19:13:32.000000000,2014-07-17 01:31:40.000000000,2014-07-17 01:31:39.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6486}, {'_account_id': 8871}, {'_account_id': 9954}, {'_account_id': 10917}, {'_account_id': 11045}]","[{'number': 1, 'created': '2014-07-10 19:13:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0db4c364a20dd57424ee09bc69575ebbccacf1d5', 'message': 'Avoid loading a ref to delete the ref\n\nIn the mapping_backend there is no need to load the ref just to\nissue a delete, it can be handled as a single SQL query.\n\nChange-Id: I4cec4fe5de4530d8da79e3be10e2d8fe431ed1f1\n'}, {'number': 2, 'created': '2014-07-10 19:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/38ecdabf74fd361e8a3d3c3822b29261c96cc96e', 'message': 'Avoid loading a ref from SQL to delete the ref\n\nIn the mapping_backend there is no need to load the ref just to\nissue a delete, it can be handled as a single SQL query.\n\nChange-Id: I4cec4fe5de4530d8da79e3be10e2d8fe431ed1f1\n'}, {'number': 3, 'created': '2014-07-11 19:43:36.000000000', 'files': ['keystone/identity/mapping_backends/sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/baa6c5134ccdb3b703567424fb48a688570d74ed', 'message': 'Avoid loading a ref from SQL to delete the ref\n\nIn the mapping_backend there is no need to load the ref just to\nissue a delete, it can be handled as a single SQL query.\n\nChange-Id: I4cec4fe5de4530d8da79e3be10e2d8fe431ed1f1\n'}]",1,106140,baa6c5134ccdb3b703567424fb48a688570d74ed,19,7,3,2903,,,0,"Avoid loading a ref from SQL to delete the ref

In the mapping_backend there is no need to load the ref just to
issue a delete, it can be handled as a single SQL query.

Change-Id: I4cec4fe5de4530d8da79e3be10e2d8fe431ed1f1
",git fetch https://review.opendev.org/openstack/keystone refs/changes/40/106140/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/identity/mapping_backends/sql.py'],1,0db4c364a20dd57424ee09bc69575ebbccacf1d5,sql_cleanup, try: session.query(IDMapping).filter( IDMapping.public_id == public_id).delete() except sql.NotFound: # NOTE(morganfainberg): There is nothing to delete and nothing # to do. pass, ref = session.query(IDMapping).get(public_id) if ref: session.delete(ref),7,3
openstack%2Fmanila~master~I4b943ff57be26c7ca0e7161114c2ef56a6a12df8,openstack/manila,master,I4b943ff57be26c7ca0e7161114c2ef56a6a12df8,Enable hacking check H236,MERGED,2014-07-16 17:11:57.000000000,2014-07-17 01:03:23.000000000,2014-07-17 01:03:23.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7173}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-07-16 17:11:57.000000000', 'files': ['manila/network/linux/interface.py', 'manila/manager.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/manila/commit/8c1a574de3e2e1b0da5f8ffa509284c84ca03264', 'message': 'Enable hacking check H236\n\n* [H236] Use six.add_metaclass instead of __metaclass__\n\nChange-Id: I4b943ff57be26c7ca0e7161114c2ef56a6a12df8\n'}]",0,107442,8c1a574de3e2e1b0da5f8ffa509284c84ca03264,9,4,1,167,,,0,"Enable hacking check H236

* [H236] Use six.add_metaclass instead of __metaclass__

Change-Id: I4b943ff57be26c7ca0e7161114c2ef56a6a12df8
",git fetch https://review.opendev.org/openstack/manila refs/changes/42/107442/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/network/linux/interface.py', 'manila/manager.py', 'tox.ini']",3,8c1a574de3e2e1b0da5f8ffa509284c84ca03264,enable_h236,"ignore = E12,E711,E712,H237,H302,H303,H304,H305,H307,H402,H404,H405,H501,H904,F","# H236: Python 3.x incompatible __metaclass__, use six.add_metaclass()ignore = E12,E711,E712,H236,H237,H302,H303,H304,H305,H307,H402,H404,H405,H501,H904,F",5,4
openstack%2Fswift~master~I6d3428b0dafef776bdb3ebac7639b3126fa5e60d,openstack/swift,master,I6d3428b0dafef776bdb3ebac7639b3126fa5e60d,Disable case-changing behavior in Eventlet,MERGED,2014-05-15 18:43:16.000000000,2014-07-17 01:02:32.000000000,2014-07-17 01:02:31.000000000,"[{'_account_id': 3}, {'_account_id': 124}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 4608}, {'_account_id': 5600}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-15 18:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/62ff9da66594bc10c9e4b956fcb5f35f41430e20', 'message': ""Normalize response headers as S3 clients expect\n\nRFC 2616 says that HTTP header fields are case-insensitive.  However, there are\nsome clients who don't accept headers normalized by Swift.  For example, AWS\nJava SDK expects that a etag header is 'ETag', not 'Etag'.\n\nThis patch normalizes Swift response headers as those clients expect.  Note\nthat this change requires a fix for Eventlet, which will be included in the\nnext Eventlet release (v0.15).\n\nChange-Id: I6d3428b0dafef776bdb3ebac7639b3126fa5e60d\n""}, {'number': 2, 'created': '2014-05-16 02:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/72dbf57972f3dbdcc559ac9d3eacd99404f5cf57', 'message': ""Disable case-changing behavior in Eventlet\n\nRFC 2616 says that HTTP header fields are case-insensitive.  However, there are\nsome S3 clients who don't accept normalized header by Swift and Eventlet.  For\nexample, AWS Java SDK expects that an etag header is 'ETag', not 'Etag'.\n\nThis patch disables Eventlet's header capitalization so that the swift3\nmiddleware can normalize the response headers as those clients expect.\n\nNote that this change requires a fix for Eventlet, which will be included in\nthe next Eventlet release (v0.15).\n\nChange-Id: I6d3428b0dafef776bdb3ebac7639b3126fa5e60d\n""}, {'number': 3, 'created': '2014-05-30 10:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a64c5b19d76c81d67a3803625dab58f5b17001b3', 'message': ""Disable case-changing behavior in Eventlet\n\nRFC 2616 says that HTTP header fields are case-insensitive.  However, there are\nsome S3 clients who don't accept normalized header by Swift and Eventlet.  For\nexample, AWS Java SDK expects that an etag header is 'ETag', not 'Etag'.\n\nThis patch disables Eventlet's header capitalization so that the swift3\nmiddleware can normalize the response headers as those clients expect.\n\nNote that this change requires a fix for Eventlet, which will be included in\nthe next Eventlet release (v0.15).\n\nChange-Id: I6d3428b0dafef776bdb3ebac7639b3126fa5e60d\n""}, {'number': 4, 'created': '2014-06-20 03:06:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5f397e9d058f70d7efa2c2614579adf035330369', 'message': ""Disable case-changing behavior in Eventlet\n\nRFC 2616 says that HTTP header fields are case-insensitive.  However, there are\nsome S3 clients who don't accept normalized header by Swift and Eventlet.  For\nexample, AWS Java SDK expects that an etag header is 'ETag', not 'Etag'.\n\nThis patch disables Eventlet's header capitalization so that the swift3\nmiddleware can normalize the response headers as those clients expect.\n\nNote that this change requires a fix for Eventlet, which will be included in\nthe next Eventlet release (v0.15).\n\nChange-Id: I6d3428b0dafef776bdb3ebac7639b3126fa5e60d\n""}, {'number': 5, 'created': '2014-06-25 03:31:23.000000000', 'files': ['swift/common/middleware/proxy_logging.py', 'swift/common/wsgi.py', 'test/unit/common/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f2774a4d11bb005c0d54928477ad7b82afbf0cf3', 'message': ""Disable case-changing behavior in Eventlet\n\nRFC 2616 says that HTTP header fields are case-insensitive.  However, there are\nsome S3 clients who don't accept normalized header by Swift and Eventlet.  For\nexample, AWS Java SDK expects that an etag header is 'ETag', not 'Etag'.\n\nThis patch disables Eventlet's header capitalization so that the swift3\nmiddleware can normalize the response headers as those clients expect.\n\nNote that this change requires a fix for Eventlet, which will be included in\nthe next Eventlet release (v0.15).\n\nChange-Id: I6d3428b0dafef776bdb3ebac7639b3126fa5e60d\n""}]",0,93780,f2774a4d11bb005c0d54928477ad7b82afbf0cf3,56,10,5,124,,,0,"Disable case-changing behavior in Eventlet

RFC 2616 says that HTTP header fields are case-insensitive.  However, there are
some S3 clients who don't accept normalized header by Swift and Eventlet.  For
example, AWS Java SDK expects that an etag header is 'ETag', not 'Etag'.

This patch disables Eventlet's header capitalization so that the swift3
middleware can normalize the response headers as those clients expect.

Note that this change requires a fix for Eventlet, which will be included in
the next Eventlet release (v0.15).

Change-Id: I6d3428b0dafef776bdb3ebac7639b3126fa5e60d
",git fetch https://review.opendev.org/openstack/swift refs/changes/80/93780/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/swob.py', 'swift/common/wsgi.py', 'test/unit/common/test_wsgi.py']",3,62ff9da66594bc10c9e4b956fcb5f35f41430e20,capitalization," with mock.patch('swift.common.wsgi.inspect'): conf = wsgi.appconfig(conf_file) logger = logging.getLogger('test') sock = listen(('localhost', 0)) wsgi.run_server(conf, logger, sock) with mock.patch('swift.common.wsgi.inspect'): conf = wsgi.appconfig(conf_dir) logger = logging.getLogger('test') sock = listen(('localhost', 0)) wsgi.run_server(conf, logger, sock) self.assert_(os.environ['TZ'] is not '')"," conf = wsgi.appconfig(conf_file) logger = logging.getLogger('test') sock = listen(('localhost', 0)) wsgi.run_server(conf, logger, sock) conf = wsgi.appconfig(conf_dir) logger = logging.getLogger('test') sock = listen(('localhost', 0)) wsgi.run_server(conf, logger, sock) self.assert_(os.environ['TZ'] is not '')",39,20
openstack%2Fkeystone-specs~master~I03c975e6ec0b0e169f039fb71686a4fcc9d81c48,openstack/keystone-specs,master,I03c975e6ec0b0e169f039fb71686a4fcc9d81c48,Updated from global requirements,MERGED,2014-07-11 02:16:03.000000000,2014-07-17 00:43:13.000000000,2014-07-17 00:43:12.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-07-11 02:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/15f6974c794afd0ce9f573790f8af8fb8c95e623', 'message': 'Updated from global requirements\n\nChange-Id: I03c975e6ec0b0e169f039fb71686a4fcc9d81c48\n'}, {'number': 2, 'created': '2014-07-16 00:07:14.000000000', 'files': ['requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e6cda7c3b6fa099ed77c653c323346f67111feed', 'message': 'Updated from global requirements\n\nChange-Id: I03c975e6ec0b0e169f039fb71686a4fcc9d81c48\n'}]",0,106233,e6cda7c3b6fa099ed77c653c323346f67111feed,14,4,2,11131,,,0,"Updated from global requirements

Change-Id: I03c975e6ec0b0e169f039fb71686a4fcc9d81c48
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/33/106233/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'setup.py']",2,15f6974c794afd0ce9f573790f8af8fb8c95e623,openstack/requirements,"# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass ",,9,1
openstack%2Fpython-neutronclient~master~I9f71b731e5de07712daf0bb9db5aa6c663663c8c,openstack/python-neutronclient,master,I9f71b731e5de07712daf0bb9db5aa6c663663c8c,Change help string related to router's distributed attribute,ABANDONED,2014-07-17 00:36:59.000000000,2014-07-17 00:38:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-17 00:36:59.000000000', 'files': ['neutronclient/neutron/v2_0/router.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/09b888d2ac31be2edb67bf85d09c86ab857e981b', 'message': ""Change help string related to router's distributed attribute\n\nThis is currently supported by the NSX plugin and the ML2 one\n(only on OVS/VxLAN). Since the compat matrix is inevitably\nsubject to change, we are better off dropping the list of\nsupported plugins in the help string and rely on external\ndocumentation where we specify which technologies do support\nthe ability to distribute routers.\n\nDocImpact\n\nChange-Id: I9f71b731e5de07712daf0bb9db5aa6c663663c8c\nSupports-blueprint: neutron-ovs-dvr\n""}]",0,107541,09b888d2ac31be2edb67bf85d09c86ab857e981b,3,1,1,748,,,0,"Change help string related to router's distributed attribute

This is currently supported by the NSX plugin and the ML2 one
(only on OVS/VxLAN). Since the compat matrix is inevitably
subject to change, we are better off dropping the list of
supported plugins in the help string and rely on external
documentation where we specify which technologies do support
the ability to distribute routers.

DocImpact

Change-Id: I9f71b731e5de07712daf0bb9db5aa6c663663c8c
Supports-blueprint: neutron-ovs-dvr
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/41/107541/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/router.py'],1,09b888d2ac31be2edb67bf85d09c86ab857e981b,bp/neutron-ovs-dvr, help=_('Create a distributed router.')), help=_('Create a distributed router (VMware NSX plugin only).')),1,1
openstack%2Fneutron~master~I438147c7961b1ecad47f6146cc7fc9396aee7bc5,openstack/neutron,master,I438147c7961b1ecad47f6146cc7fc9396aee7bc5,Freeze models for healing migration,MERGED,2014-06-26 14:57:36.000000000,2014-07-17 00:18:27.000000000,2014-07-15 16:55:56.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6849}, {'_account_id': 7249}, {'_account_id': 8655}, {'_account_id': 9423}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-06-26 14:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b072ec906bc1606d793acc1a68b389bf22a9717c', 'message': 'WIP: Add module providing icehouse models\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 2, 'created': '2014-06-27 11:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad5f334706c55149ebbacd293151411e4db6a6fb', 'message': 'WIP: Add module providing icehouse models\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 3, 'created': '2014-06-27 12:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/38f73da3f4f1cf56fefe3ab43ab03f12b1d90bed', 'message': 'Add module providing icehouse models\n\nIn this module are all models from Icehouse release in order to have\nmetadata to compare with current db schema. Based on this comparison\nhealing migration will change schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 4, 'created': '2014-07-01 12:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ad1ff9b8c36a1c2a7e77e304939010e00c686d4', 'message': 'Add module providing icehouse models\n\nIn this module are all models from Icehouse release in order to have\nmetadata to compare with current db schema. Based on this comparison\nhealing migration will change schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 5, 'created': '2014-07-02 14:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad8f22b4be07e67b8c358694a4d2138d0924f761', 'message': 'WIP: Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 6, 'created': '2014-07-03 14:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58557e03309cd6c08817f99ba68f90e67301ca5f', 'message': 'WIP: Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 7, 'created': '2014-07-03 14:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2b12ea2c22fced00facf56d4bf699348336fa57', 'message': 'WIP: Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 8, 'created': '2014-07-03 16:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/be5dec02472715c020efd6c8832ba5ebba78da4d', 'message': 'WIP: Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 9, 'created': '2014-07-03 16:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f47b7f3774d78dad87153d537456b04571546dd7', 'message': 'WIP: Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 10, 'created': '2014-07-03 16:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fec539a1475b842cee4da041fe0125f448ea673b', 'message': 'WIP: Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 11, 'created': '2014-07-08 12:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/612612b9f1c5fc3c9a6de26ceedc76a5adff1a38', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 12, 'created': '2014-07-08 12:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d9ce7911a8bee2da0ed627d0c05a843a7306411e', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 13, 'created': '2014-07-09 13:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66dc03202214a50d9e783f515cd774145d3eaa95', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 14, 'created': '2014-07-11 13:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6770d2ef669f1b49edcde5ab36df3a4b468f0801', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 15, 'created': '2014-07-11 15:18:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dcedb6faa7ba97e55ed66b1cef5560a9358cc8c4', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 16, 'created': '2014-07-12 16:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/56657dc1bc5cd8cf851771701831152b505fb542', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 17, 'created': '2014-07-12 18:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e7709fa6cfdf08d8d8c8c2dd79b5c117e7995cbc', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 18, 'created': '2014-07-14 14:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1f8c0d60f90b42cbac0ebb6a4fff92b34481e3b', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 19, 'created': '2014-07-14 14:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/518fe88c9cf3e450e1fc5fa9d754e5663b7d15a6', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 20, 'created': '2014-07-14 14:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01aeb1d97690d446d4c05cdd21a65e2e50f9aa35', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 21, 'created': '2014-07-14 15:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8bac107f0ceef8ecafdda6ce78ca8ca835cac65', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 22, 'created': '2014-07-14 15:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc12bdf55ab6117c6b07a3e5e5e4aa78dcfbeb83', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}, {'number': 23, 'created': '2014-07-14 16:36:17.000000000', 'files': ['neutron/db/migration/models/head.py', 'neutron/tests/functional/db/__init__.py', 'neutron/db/migration/models/frozen.py', 'neutron/db/migration/models/__init__.py', 'neutron/tests/functional/db/test_models.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0befdbcba31dcd0fb43f93e1d48ac186a8f3e0b6', 'message': 'Freeze models for healing migration\n\nTake a snapshot of all models from the code base at the time when the\nhealing migration merges. The healing migration needs this frozen view\nof the models to be available (even as the models change in the future)\nto compare with the current DB schema. The healing migration will use\nthis comparison to heal the schema.\n\npartially implement bp: db-migration-refactor\n\nChange-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5\n'}]",45,102857,0befdbcba31dcd0fb43f93e1d48ac186a8f3e0b6,333,27,23,8655,,,0,"Freeze models for healing migration

Take a snapshot of all models from the code base at the time when the
healing migration merges. The healing migration needs this frozen view
of the models to be available (even as the models change in the future)
to compare with the current DB schema. The healing migration will use
this comparison to heal the schema.

partially implement bp: db-migration-refactor

Change-Id: I438147c7961b1ecad47f6146cc7fc9396aee7bc5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/57/102857/22 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/models/icehouse.py'],1,b072ec906bc1606d793acc1a68b389bf22a9717c,bp/db-migration-refactor," import sqlalchemy as sa from sqlalchemy.ext.orderinglist import ordering_list from sqlalchemy import orm from sqlalchemy.orm import validates from neutron.openstack.common import uuidutils UUID_LEN = 36 STR_LEN = 255 CISCO_CONSTANTS_NETWORK_TYPE_VLAN = 'vlan' CISCO_CONSTANTS_NETWORK_TYPE_OVERLAY = 'overlay' CISCO_CONSTANTS_NETWORK_TYPE_TRUNK = 'trunk' CISCO_CONSTANTS_NETWORK_TYPE_MULTI_SEGMENT = 'multi-segment' CISCO_CONSTANTS_NETWORK = 'network' CISCO_CONSTANTS_POLICY = 'policy' CISCO_CONSTANTS_TENANT_ID_NOT_SET = 'TENANT_ID_NOT_SET' BINDING_PROFILE_LEN = 4095 VNIC_NORMAL = 'normal' #neutron/db/models_v2.py class HasTenant(object): """"""Tenant mixin, add to subclasses that have a tenant."""""" # NOTE(jkoelker) tenant_id is just a free form string ;( tenant_id = sa.Column(sa.String(255)) class HasId(object): """"""id mixin, add to subclasses that have an id."""""" id = sa.Column(sa.String(36), primary_key=True, default=uuidutils.generate_uuid) class HasStatusDescription(object): """"""Status with description mixin."""""" status = sa.Column(sa.String(16), nullable=False) status_description = sa.Column(sa.String(255)) class IPAvailabilityRange(model_base.BASEV2): """"""Internal representation of available IPs for Neutron subnets. Allocation - first entry from the range will be allocated. If the first entry is equal to the last entry then this row will be deleted. Recycling ips involves reading the IPAllocationPool and IPAllocation tables and inserting ranges representing available ips. This happens after the final allocation is pulled from this table and a new ip allocation is requested. Any contiguous ranges of available ips will be inserted as a single range. """""" allocation_pool_id = sa.Column(sa.String(36), sa.ForeignKey('ipallocationpools.id', ondelete=""CASCADE""), nullable=False, primary_key=True) first_ip = sa.Column(sa.String(64), nullable=False, primary_key=True) last_ip = sa.Column(sa.String(64), nullable=False, primary_key=True) def __repr__(self): return ""%s - %s"" % (self.first_ip, self.last_ip) class IPAllocationPool(model_base.BASEV2, HasId): """"""Representation of an allocation pool in a Neutron subnet."""""" subnet_id = sa.Column(sa.String(36), sa.ForeignKey('subnets.id', ondelete=""CASCADE""), nullable=True) first_ip = sa.Column(sa.String(64), nullable=False) last_ip = sa.Column(sa.String(64), nullable=False) available_ranges = orm.relationship(IPAvailabilityRange, backref='ipallocationpool', lazy=""joined"", cascade='delete') def __repr__(self): return ""%s - %s"" % (self.first_ip, self.last_ip) class IPAllocation(model_base.BASEV2): """"""Internal representation of allocated IP addresses in a Neutron subnet. """""" port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), nullable=True) ip_address = sa.Column(sa.String(64), nullable=False, primary_key=True) subnet_id = sa.Column(sa.String(36), sa.ForeignKey('subnets.id', ondelete=""CASCADE""), nullable=False, primary_key=True) network_id = sa.Column(sa.String(36), sa.ForeignKey(""networks.id"", ondelete=""CASCADE""), nullable=False, primary_key=True) class Route(object): """"""mixin of a route."""""" destination = sa.Column(sa.String(64), nullable=False, primary_key=True) nexthop = sa.Column(sa.String(64), nullable=False, primary_key=True) class SubnetRoute(model_base.BASEV2, Route): subnet_id = sa.Column(sa.String(36), sa.ForeignKey('subnets.id', ondelete=""CASCADE""), primary_key=True) class Port(model_base.BASEV2, HasId, HasTenant): """"""Represents a port on a Neutron v2 network."""""" name = sa.Column(sa.String(255)) network_id = sa.Column(sa.String(36), sa.ForeignKey(""networks.id""), nullable=False) fixed_ips = orm.relationship(IPAllocation, backref='ports', lazy='joined') mac_address = sa.Column(sa.String(32), nullable=False) admin_state_up = sa.Column(sa.Boolean(), nullable=False) status = sa.Column(sa.String(16), nullable=False) device_id = sa.Column(sa.String(255), nullable=False) device_owner = sa.Column(sa.String(255), nullable=False) def __init__(self, id=None, tenant_id=None, name=None, network_id=None, mac_address=None, admin_state_up=None, status=None, device_id=None, device_owner=None, fixed_ips=None): self.id = id self.tenant_id = tenant_id self.name = name self.network_id = network_id self.mac_address = mac_address self.admin_state_up = admin_state_up self.device_owner = device_owner self.device_id = device_id # Since this is a relationship only set it if one is passed in. if fixed_ips: self.fixed_ips = fixed_ips # NOTE(arosen): status must be set last as an event is triggered on! self.status = status class DNSNameServer(model_base.BASEV2): """"""Internal representation of a DNS nameserver."""""" address = sa.Column(sa.String(128), nullable=False, primary_key=True) subnet_id = sa.Column(sa.String(36), sa.ForeignKey('subnets.id', ondelete=""CASCADE""), primary_key=True) class Subnet(model_base.BASEV2, HasId, HasTenant): """"""Represents a neutron subnet. When a subnet is created the first and last entries will be created. These are used for the IP allocation. """""" name = sa.Column(sa.String(255)) network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id')) ip_version = sa.Column(sa.Integer, nullable=False) cidr = sa.Column(sa.String(64), nullable=False) gateway_ip = sa.Column(sa.String(64)) allocation_pools = orm.relationship(IPAllocationPool, backref='subnet', lazy=""joined"", cascade='delete') enable_dhcp = sa.Column(sa.Boolean()) dns_nameservers = orm.relationship(DNSNameServer, backref='subnet', cascade='all, delete, delete-orphan') routes = orm.relationship(SubnetRoute, backref='subnet', cascade='all, delete, delete-orphan') shared = sa.Column(sa.Boolean) ipv6_ra_mode = sa.Column(sa.Enum(constants.IPV6_SLAAC, constants.DHCPV6_STATEFUL, constants.DHCPV6_STATELESS, name='ipv6_modes'), nullable=True) ipv6_address_mode = sa.Column(sa.Enum(constants.IPV6_SLAAC, constants.DHCPV6_STATEFUL, constants.DHCPV6_STATELESS, name='ipv6_modes'), nullable=True) class Network(model_base.BASEV2, HasId, HasTenant): """"""Represents a v2 neutron network."""""" name = sa.Column(sa.String(255)) ports = orm.relationship(Port, backref='networks') subnets = orm.relationship(Subnet, backref='networks', lazy=""joined"") status = sa.Column(sa.String(16)) admin_state_up = sa.Column(sa.Boolean) shared = sa.Column(sa.Boolean) # ------------------------------ class Router(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a v2 neutron router."""""" name = sa.Column(sa.String(255)) status = sa.Column(sa.String(16)) admin_state_up = sa.Column(sa.Boolean) gw_port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id')) gw_port = orm.relationship(models_v2.Port, lazy='joined') class FloatingIP(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a floating IP address. This IP address may or may not be allocated to a tenant, and may or may not be associated with an internal port/ip address/router. """""" floating_ip_address = sa.Column(sa.String(64), nullable=False) floating_network_id = sa.Column(sa.String(36), nullable=False) floating_port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id'), nullable=False) fixed_port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id')) fixed_ip_address = sa.Column(sa.String(64)) router_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id')) # Additional attribute for keeping track of the router where the floating # ip was associated in order to be able to ensure consistency even if an # aysnchronous backend is unavailable when the floating IP is disassociated last_known_router_id = sa.Column(sa.String(36)) status = sa.Column(sa.String(16)) class AllowedAddressPair(model_base.BASEV2): port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) mac_address = sa.Column(sa.String(32), nullable=False, primary_key=True) ip_address = sa.Column(sa.String(64), nullable=False, primary_key=True) port = orm.relationship( models_v2.Port, backref=orm.backref(""allowed_address_pairs"", lazy=""joined"", cascade=""delete"")) class Agent(model_base.BASEV2, models_v2.HasId): """"""Represents agents running in neutron deployments."""""" __table_args__ = ( sa.UniqueConstraint('agent_type', 'host', name='uniq_agents0agent_type0host'), ) # L3 agent, DHCP agent, OVS agent, LinuxBridge agent_type = sa.Column(sa.String(255), nullable=False) binary = sa.Column(sa.String(255), nullable=False) # TOPIC is a fanout exchange topic topic = sa.Column(sa.String(255), nullable=False) # TOPIC.host is a target topic host = sa.Column(sa.String(255), nullable=False) admin_state_up = sa.Column(sa.Boolean, default=True, nullable=False) # the time when first report came from agents created_at = sa.Column(sa.DateTime, nullable=False) # the time when first report came after agents start started_at = sa.Column(sa.DateTime, nullable=False) # updated when agents report heartbeat_timestamp = sa.Column(sa.DateTime, nullable=False) # description is note for admin user description = sa.Column(sa.String(255)) # configurations: a json dict string, I think 4095 is enough configurations = sa.Column(sa.String(4095), nullable=False) class IPsecPeerCidr(model_base.BASEV2): """"""Internal representation of a IPsec Peer Cidrs."""""" cidr = sa.Column(sa.String(32), nullable=False, primary_key=True) ipsec_site_connection_id = sa.Column( sa.String(36), sa.ForeignKey('ipsec_site_connections.id', ondelete=""CASCADE""), primary_key=True) class IPsecPolicy(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a v2 IPsecPolicy Object."""""" __tablename__ = 'ipsecpolicies' name = sa.Column(sa.String(255)) description = sa.Column(sa.String(255)) transform_protocol = sa.Column(sa.Enum(""esp"", ""ah"", ""ah-esp"", name=""ipsec_transform_protocols""), nullable=False) auth_algorithm = sa.Column(sa.Enum(""sha1"", name=""vpn_auth_algorithms""), nullable=False) encryption_algorithm = sa.Column(sa.Enum(""3des"", ""aes-128"", ""aes-256"", ""aes-192"", name=""vpn_encrypt_algorithms""), nullable=False) encapsulation_mode = sa.Column(sa.Enum(""tunnel"", ""transport"", name=""ipsec_encapsulations""), nullable=False) lifetime_units = sa.Column(sa.Enum(""seconds"", ""kilobytes"", name=""vpn_lifetime_units""), nullable=False) lifetime_value = sa.Column(sa.Integer, nullable=False) pfs = sa.Column(sa.Enum(""group2"", ""group5"", ""group14"", name=""vpn_pfs""), nullable=False) class IKEPolicy(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a v2 IKEPolicy Object."""""" __tablename__ = 'ikepolicies' name = sa.Column(sa.String(255)) description = sa.Column(sa.String(255)) auth_algorithm = sa.Column(sa.Enum(""sha1"", name=""vpn_auth_algorithms""), nullable=False) encryption_algorithm = sa.Column(sa.Enum(""3des"", ""aes-128"", ""aes-256"", ""aes-192"", name=""vpn_encrypt_algorithms""), nullable=False) phase1_negotiation_mode = sa.Column(sa.Enum(""main"", name=""ike_phase1_mode""), nullable=False) lifetime_units = sa.Column(sa.Enum(""seconds"", ""kilobytes"", name=""vpn_lifetime_units""), nullable=False) lifetime_value = sa.Column(sa.Integer, nullable=False) ike_version = sa.Column(sa.Enum(""v1"", ""v2"", name=""ike_versions""), nullable=False) pfs = sa.Column(sa.Enum(""group2"", ""group5"", ""group14"", name=""vpn_pfs""), nullable=False) class IPsecSiteConnection(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a IPsecSiteConnection Object."""""" __tablename__ = 'ipsec_site_connections' name = sa.Column(sa.String(255)) description = sa.Column(sa.String(255)) peer_address = sa.Column(sa.String(255), nullable=False) peer_id = sa.Column(sa.String(255), nullable=False) route_mode = sa.Column(sa.String(8), nullable=False) mtu = sa.Column(sa.Integer, nullable=False) initiator = sa.Column(sa.Enum(""bi-directional"", ""response-only"", name=""vpn_initiators""), nullable=False) auth_mode = sa.Column(sa.String(16), nullable=False) psk = sa.Column(sa.String(255), nullable=False) dpd_action = sa.Column(sa.Enum(""hold"", ""clear"", ""restart"", ""disabled"", ""restart-by-peer"", name=""vpn_dpd_actions""), nullable=False) dpd_interval = sa.Column(sa.Integer, nullable=False) dpd_timeout = sa.Column(sa.Integer, nullable=False) status = sa.Column(sa.String(16), nullable=False) admin_state_up = sa.Column(sa.Boolean(), nullable=False) vpnservice_id = sa.Column(sa.String(36), sa.ForeignKey('vpnservices.id'), nullable=False) ipsecpolicy_id = sa.Column(sa.String(36), sa.ForeignKey('ipsecpolicies.id'), nullable=False) ikepolicy_id = sa.Column(sa.String(36), sa.ForeignKey('ikepolicies.id'), nullable=False) ipsecpolicy = orm.relationship( IPsecPolicy, backref='ipsec_site_connection') ikepolicy = orm.relationship(IKEPolicy, backref='ipsec_site_connection') peer_cidrs = orm.relationship(IPsecPeerCidr, backref='ipsec_site_connection', lazy='joined', cascade='all, delete, delete-orphan') class VPNService(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a v2 VPNService Object."""""" name = sa.Column(sa.String(255)) description = sa.Column(sa.String(255)) status = sa.Column(sa.String(16), nullable=False) admin_state_up = sa.Column(sa.Boolean(), nullable=False) subnet_id = sa.Column(sa.String(36), sa.ForeignKey('subnets.id'), nullable=False) router_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id'), nullable=False) subnet = orm.relationship(models_v2.Subnet) router = orm.relationship(Router) ipsec_site_connections = orm.relationship( IPsecSiteConnection, backref='vpnservice', cascade=""all, delete-orphan"") class Quota(model_base.BASEV2, models_v2.HasId): """"""Represent a single quota override for a tenant. If there is no row for a given tenant id and resource, then the default for the quota class is used. """""" tenant_id = sa.Column(sa.String(255), index=True) resource = sa.Column(sa.String(255)) limit = sa.Column(sa.Integer) class SegmentationIdAllocation(model_base.BASEV2): """"""Represents allocation state of segmentation_id on physical network."""""" __tablename__ = 'segmentation_id_allocation' physical_network = sa.Column(sa.String(64), nullable=False, primary_key=True) segmentation_id = sa.Column(sa.Integer, nullable=False, primary_key=True, autoincrement=False) allocated = sa.Column(sa.Boolean, nullable=False, default=False) def __init__(self, physical_network, segmentation_id): self.physical_network = physical_network self.segmentation_id = segmentation_id self.allocated = False def __repr__(self): return ""<SegmentationIdAllocation(%s,%d,%s)>"" % (self.physical_network, self.segmentation_id, self.allocated) class NetworkBinding(model_base.BASEV2): """"""Represents binding of virtual network. Binds network to physical_network and segmentation_id """""" __tablename__ = 'mlnx_network_bindings' network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) network_type = sa.Column(sa.String(32), nullable=False) physical_network = sa.Column(sa.String(64)) segmentation_id = sa.Column(sa.Integer, nullable=False) def __init__(self, network_id, network_type, physical_network, vlan_id): self.network_id = network_id self.network_type = network_type self.physical_network = physical_network self.segmentation_id = vlan_id def __repr__(self): return ""<NetworkBinding(%s,%s,%s,%d)>"" % (self.network_id, self.network_type, self.physical_network, self.segmentation_id) class PortProfileBinding(model_base.BASEV2): """"""Represents port profile binding to the port on virtual network."""""" __tablename__ = 'port_profile' port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) vnic_type = sa.Column(sa.String(32), nullable=False) def __init__(self, port_id, vnic_type): self.port_id = port_id self.vnic_type = vnic_type def __repr__(self): return ""<PortProfileBinding(%s,%s,%s,%d)>"" % (self.port_id, self.vnic_type) class VlanAllocation(model_base.BASEV2): """"""Represent allocation state of a vlan_id on a physical network. If allocated is False, the vlan_id on the physical_network is available for allocation to a tenant network. If allocated is True, the vlan_id on the physical_network is in use, either as a tenant or provider network. When an allocation is released, if the vlan_id for the physical_network is inside the pool described by VlanTypeDriver.network_vlan_ranges, then allocated is set to False. If it is outside the pool, the record is deleted. """""" __tablename__ = 'ml2_vlan_allocations' physical_network = sa.Column(sa.String(64), nullable=False, primary_key=True) vlan_id = sa.Column(sa.Integer, nullable=False, primary_key=True, autoincrement=False) allocated = sa.Column(sa.Boolean, nullable=False) class VlanAllocation(model_base.BASEV2): """"""Represents allocation state of vlan_id on physical network."""""" __tablename__ = 'ovs_vlan_allocations' physical_network = sa.Column(sa.String(64), nullable=False, primary_key=True) vlan_id = sa.Column(sa.Integer, nullable=False, primary_key=True, autoincrement=False) allocated = sa.Column(sa.Boolean, nullable=False) def __init__(self, physical_network, vlan_id): self.physical_network = physical_network self.vlan_id = vlan_id self.allocated = False def __repr__(self): return ""<VlanAllocation(%s,%d,%s)>"" % (self.physical_network, self.vlan_id, self.allocated) class TunnelAllocation(model_base.BASEV2): """"""Represents allocation state of tunnel_id."""""" __tablename__ = 'ovs_tunnel_allocations' tunnel_id = sa.Column(sa.Integer, nullable=False, primary_key=True, autoincrement=False) allocated = sa.Column(sa.Boolean, nullable=False) def __init__(self, tunnel_id): self.tunnel_id = tunnel_id self.allocated = False def __repr__(self): return ""<TunnelAllocation(%d,%s)>"" % (self.tunnel_id, self.allocated) class NetworkBinding(model_base.BASEV2): """"""Represents binding of virtual network to physical realization."""""" __tablename__ = 'ovs_network_bindings' network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) # 'gre', 'vlan', 'flat', 'local' network_type = sa.Column(sa.String(32), nullable=False) physical_network = sa.Column(sa.String(64)) segmentation_id = sa.Column(sa.Integer) # tunnel_id or vlan_id network = orm.relationship( models_v2.Network, backref=orm.backref(""binding"", lazy='joined', uselist=False, cascade='delete')) def __init__(self, network_id, network_type, physical_network, segmentation_id): self.network_id = network_id self.network_type = network_type self.physical_network = physical_network self.segmentation_id = segmentation_id def __repr__(self): return ""<NetworkBinding(%s,%s,%s,%d)>"" % (self.network_id, self.network_type, self.physical_network, self.segmentation_id) class TunnelEndpoint(model_base.BASEV2): """"""Represents tunnel endpoint in RPC mode."""""" __tablename__ = 'ovs_tunnel_endpoints' __table_args__ = ( sa.UniqueConstraint('id', name='uniq_ovs_tunnel_endpoints0id'), model_base.BASEV2.__table_args__, ) ip_address = sa.Column(sa.String(64), primary_key=True) id = sa.Column(sa.Integer, nullable=False) def __init__(self, ip_address, id): self.ip_address = ip_address self.id = id def __repr__(self): return ""<TunnelEndpoint(%s,%s)>"" % (self.ip_address, self.id) class N1kvVlanAllocation(model_base.BASEV2): """"""Represents allocation state of vlan_id on physical network."""""" __tablename__ = 'cisco_n1kv_vlan_allocations' physical_network = sa.Column(sa.String(64), nullable=False, primary_key=True) vlan_id = sa.Column(sa.Integer, nullable=False, primary_key=True, autoincrement=False) allocated = sa.Column(sa.Boolean, nullable=False, default=False) network_profile_id = sa.Column(sa.String(36), sa.ForeignKey('cisco_network_profiles.id', ondelete=""CASCADE""), nullable=False) class N1kvVxlanAllocation(model_base.BASEV2): """"""Represents allocation state of vxlan_id."""""" __tablename__ = 'cisco_n1kv_vxlan_allocations' vxlan_id = sa.Column(sa.Integer, nullable=False, primary_key=True, autoincrement=False) allocated = sa.Column(sa.Boolean, nullable=False, default=False) network_profile_id = sa.Column(sa.String(36), sa.ForeignKey('cisco_network_profiles.id', ondelete=""CASCADE""), nullable=False) class N1kvPortBinding(model_base.BASEV2): """"""Represents binding of ports to policy profile."""""" __tablename__ = 'cisco_n1kv_port_bindings' port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) profile_id = sa.Column(sa.String(36), sa.ForeignKey('cisco_policy_profiles.id')) class N1kvNetworkBinding(model_base.BASEV2): """"""Represents binding of virtual network to physical realization."""""" __tablename__ = 'cisco_n1kv_network_bindings' network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) network_type = sa.Column(sa.String(32), nullable=False) physical_network = sa.Column(sa.String(64)) segmentation_id = sa.Column(sa.Integer) multicast_ip = sa.Column(sa.String(32)) profile_id = sa.Column(sa.String(36), sa.ForeignKey('cisco_network_profiles.id')) class N1kVmNetwork(model_base.BASEV2): """"""Represents VM Network information."""""" __tablename__ = 'cisco_n1kv_vmnetworks' name = sa.Column(sa.String(80), primary_key=True) profile_id = sa.Column(sa.String(36), sa.ForeignKey('cisco_policy_profiles.id')) network_id = sa.Column(sa.String(36)) port_count = sa.Column(sa.Integer) class NetworkProfile(model_base.BASEV2, models_v2.HasId): """""" Nexus1000V Network Profiles segment_type - VLAN, OVERLAY, TRUNK, MULTI_SEGMENT sub_type - TRUNK_VLAN, TRUNK_VXLAN, native_vxlan, enhanced_vxlan segment_range - '<integer>-<integer>' multicast_ip_index - <integer> multicast_ip_range - '<ip>-<ip>' physical_network - Name for the physical network """""" __tablename__ = 'cisco_network_profiles' name = sa.Column(sa.String(255)) segment_type = sa.Column(sa.Enum(CISCO_CONSTANTS_NETWORK_TYPE_VLAN, CISCO_CONSTANTS_NETWORK_TYPE_OVERLAY, CISCO_CONSTANTS_NETWORK_TYPE_TRUNK, CISCO_CONSTANTS_NETWORK_TYPE_MULTI_SEGMENT, name='segment_type'), nullable=False) sub_type = sa.Column(sa.String(255)) segment_range = sa.Column(sa.String(255)) multicast_ip_index = sa.Column(sa.Integer, default=0) multicast_ip_range = sa.Column(sa.String(255)) physical_network = sa.Column(sa.String(255)) class PolicyProfile(model_base.BASEV2): """""" Nexus1000V Network Profiles Both 'id' and 'name' are coming from Nexus1000V switch """""" __tablename__ = 'cisco_policy_profiles' id = sa.Column(sa.String(36), primary_key=True) name = sa.Column(sa.String(255)) class ProfileBinding(model_base.BASEV2): """""" Represents a binding of Network Profile or Policy Profile to tenant_id """""" __tablename__ = 'cisco_n1kv_profile_bindings' profile_type = sa.Column(sa.Enum(CISCO_CONSTANTS_NETWORK, CISCO_CONSTANTS_POLICY, name='profile_type')) tenant_id = sa.Column(sa.String(36), primary_key=True, default=CISCO_CONSTANTS_TENANT_ID_NOT_SET) profile_id = sa.Column(sa.String(36), primary_key=True) class N1kvTrunkSegmentBinding(model_base.BASEV2): """"""Represents binding of segments in trunk networks."""""" __tablename__ = 'cisco_n1kv_trunk_segments' trunk_segment_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) segment_id = sa.Column(sa.String(36), nullable=False, primary_key=True) dot1qtag = sa.Column(sa.String(36), nullable=False, primary_key=True) class N1kvMultiSegmentNetworkBinding(model_base.BASEV2): """"""Represents binding of segments in multi-segment networks."""""" __tablename__ = 'cisco_n1kv_multi_segments' multi_segment_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) segment1_id = sa.Column(sa.String(36), nullable=False, primary_key=True) segment2_id = sa.Column(sa.String(36), nullable=False, primary_key=True) encap_profile_name = sa.Column(sa.String(36)) class NetworkSegment(model_base.BASEV2, models_v2.HasId): """"""Represent persistent state of a network segment. A network segment is a portion of a neutron network with a specific physical realization. A neutron network can consist of one or more segments. """""" __tablename__ = 'ml2_network_segments' network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), nullable=False) network_type = sa.Column(sa.String(32), nullable=False) physical_network = sa.Column(sa.String(64)) segmentation_id = sa.Column(sa.Integer) class PortBinding(model_base.BASEV2): """"""Represent binding-related state of a port. A port binding stores the port attributes required for the portbindings extension, as well as internal ml2 state such as which MechanismDriver and which segment are used by the port binding. """""" __tablename__ = 'ml2_port_bindings' port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) host = sa.Column(sa.String(255), nullable=False, default='') vnic_type = sa.Column(sa.String(64), nullable=False, default=VNIC_NORMAL) profile = sa.Column(sa.String(BINDING_PROFILE_LEN), nullable=False, default='') vif_type = sa.Column(sa.String(64), nullable=False) vif_details = sa.Column(sa.String(4095), nullable=False, default='') driver = sa.Column(sa.String(64)) segment = sa.Column(sa.String(36), sa.ForeignKey('ml2_network_segments.id', ondelete=""SET NULL"")) # Add a relationship to the Port model in order to instruct SQLAlchemy to # eagerly load port bindings port = orm.relationship( models_v2.Port, backref=orm.backref(""port_binding"", lazy='joined', uselist=False, cascade='delete')) class PoolPort(model_base.BASEV2): """"""Represents the connection between pools and ports."""""" __tablename__ = 'embrane_pool_port' pool_id = sa.Column(sa.String(36), sa.ForeignKey('pools.id'), primary_key=True) port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id'), nullable=False) class RouterProvider(models_v2.model_base.BASEV2): """"""Represents a binding of router_id to provider."""""" provider = sa.Column(sa.String(255)) router_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id', ondelete=""CASCADE""), primary_key=True) router = orm.relationship(Router, uselist=False, backref=orm.backref('provider', uselist=False, lazy='joined', cascade='delete')) class Credential(model_base.BASEV2): """"""Represents credentials for a tenant to control Cisco switches."""""" __tablename__ = 'cisco_ml2_credentials' credential_id = sa.Column(sa.String(255)) tenant_id = sa.Column(sa.String(255), primary_key=True) credential_name = sa.Column(sa.String(255), primary_key=True) user_name = sa.Column(sa.String(255)) password = sa.Column(sa.String(255)) class RouterL3AgentBinding(model_base.BASEV2, models_v2.HasId): """"""Represents binding between neutron routers and L3 agents."""""" router_id = sa.Column(sa.String(36), sa.ForeignKey(""routers.id"", ondelete='CASCADE')) l3_agent = orm.relation(Agent) l3_agent_id = sa.Column(sa.String(36), sa.ForeignKey(""agents.id"", ondelete='CASCADE')) class TunnelKeyLast(model_base.BASEV2): """"""Last allocated Tunnel key. The next key allocation will be started from this value + 1 """""" last_key = sa.Column(sa.Integer, primary_key=True) def __repr__(self): return ""<TunnelKeyLast(%x)>"" % self.last_key class TunnelKey(model_base.BASEV2): """"""Netowrk ID <-> tunnel key mapping."""""" network_id = sa.Column(sa.String(36), sa.ForeignKey(""networks.id""), nullable=False) tunnel_key = sa.Column(sa.Integer, primary_key=True, nullable=False, autoincrement=False) def __repr__(self): return ""<TunnelKey(%s,%x)>"" % (self.network_id, self.tunnel_key) class PacketFilter(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a packet filter."""""" name = sa.Column(sa.String(255)) network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), nullable=False) priority = sa.Column(sa.Integer, nullable=False) action = sa.Column(sa.String(16), nullable=False) # condition in_port = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), nullable=True) src_mac = sa.Column(sa.String(32), nullable=False) dst_mac = sa.Column(sa.String(32), nullable=False) eth_type = sa.Column(sa.Integer, nullable=False) src_cidr = sa.Column(sa.String(64), nullable=False) dst_cidr = sa.Column(sa.String(64), nullable=False) protocol = sa.Column(sa.String(16), nullable=False) src_port = sa.Column(sa.Integer, nullable=False) dst_port = sa.Column(sa.Integer, nullable=False) # status admin_state_up = sa.Column(sa.Boolean(), nullable=False) status = sa.Column(sa.String(16), nullable=False) network = orm.relationship( models_v2.Network, backref=orm.backref('packetfilters', lazy='joined', cascade='delete'), uselist=False) in_port_ref = orm.relationship( models_v2.Port, backref=orm.backref('packetfilters', lazy='joined', cascade='delete'), primaryjoin=""Port.id==PacketFilter.in_port"", uselist=False) class PortBindingPort(model_base.BASEV2): port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) host = sa.Column(sa.String(255), nullable=False) port = orm.relationship( models_v2.Port, backref=orm.backref(""portbinding"", lazy='joined', uselist=False, cascade='delete')) class NetworkState(model_base.BASEV2): """"""Represents state of vlan_id on physical network."""""" __tablename__ = 'network_states' physical_network = sa.Column(sa.String(64), nullable=False, primary_key=True) vlan_id = sa.Column(sa.Integer, nullable=False, primary_key=True, autoincrement=False) allocated = sa.Column(sa.Boolean, nullable=False) def __init__(self, physical_network, vlan_id): self.physical_network = physical_network self.vlan_id = vlan_id self.allocated = False def __repr__(self): return ""<NetworkState(%s,%d,%s)>"" % (self.physical_network, self.vlan_id, self.allocated) class NetworkBinding(model_base.BASEV2): """"""Represents binding of virtual network to physical network and vlan."""""" __tablename__ = 'network_bindings' network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) physical_network = sa.Column(sa.String(64)) vlan_id = sa.Column(sa.Integer, nullable=False) def __init__(self, network_id, physical_network, vlan_id): self.network_id = network_id self.physical_network = physical_network self.vlan_id = vlan_id def __repr__(self): return ""<NetworkBinding(%s,%s,%d)>"" % (self.network_id, self.physical_network, self.vlan_id) class RouterRoute(model_base.BASEV2, models_v2.Route): router_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id', ondelete=""CASCADE""), primary_key=True) router = orm.relationship(Router, backref=orm.backref(""route_list"", lazy='joined', cascade='delete')) class ExtraDhcpOpt(model_base.BASEV2, models_v2.HasId): """"""Represent a generic concept of extra options associated to a port. Each port may have none to many dhcp opts associated to it that can define specifically different or extra options to DHCP clients. These will be written to the <network_id>/opts files, and each option's tag will be referenced in the <network_id>/host file. """""" port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), nullable=False) opt_name = sa.Column(sa.String(64), nullable=False) opt_value = sa.Column(sa.String(255), nullable=False) __table_args__ = (sa.UniqueConstraint('port_id', 'opt_name', name='uidx_portid_optname'), model_base.BASEV2.__table_args__,) # Add a relationship to the Port model in order to instruct SQLAlchemy to # eagerly load extra_dhcp_opts bindings ports = orm.relationship( models_v2.Port, backref=orm.backref(""dhcp_opts"", lazy='joined', cascade='delete')) class VxlanAllocation(model_base.BASEV2): __tablename__ = 'ml2_vxlan_allocations' vxlan_vni = sa.Column(sa.Integer, nullable=False, primary_key=True, autoincrement=False) allocated = sa.Column(sa.Boolean, nullable=False, default=False) class VxlanEndpoints(model_base.BASEV2): """"""Represents tunnel endpoint in RPC mode."""""" __tablename__ = 'ml2_vxlan_endpoints' ip_address = sa.Column(sa.String(64), primary_key=True) udp_port = sa.Column(sa.Integer, primary_key=True, nullable=False, autoincrement=False) def __repr__(self): return ""<VxlanTunnelEndpoint(%s)>"" % self.ip_address class LsnPort(models_v2.model_base.BASEV2): __tablename__ = 'lsn_port' lsn_port_id = sa.Column(sa.String(36), primary_key=True) lsn_id = sa.Column(sa.String(36), sa.ForeignKey('lsn.lsn_id', ondelete=""CASCADE"")) sub_id = sa.Column(sa.String(36), nullable=False, unique=True) mac_addr = sa.Column(sa.String(32), nullable=False, unique=True) def __init__(self, lsn_port_id, subnet_id, mac_address, lsn_id): self.lsn_port_id = lsn_port_id self.lsn_id = lsn_id self.sub_id = subnet_id self.mac_addr = mac_address class Lsn(models_v2.model_base.BASEV2): __tablename__ = 'lsn' lsn_id = sa.Column(sa.String(36), primary_key=True) net_id = sa.Column(sa.String(36), nullable=False) def __init__(self, net_id, lsn_id): self.net_id = net_id self.lsn_id = lsn_id class NexusPortBinding(model_base.BASEV2): """"""Represents a binding of VM's to nexus ports."""""" __tablename__ = ""cisco_nexusport_bindings"" id = sa.Column(sa.Integer, primary_key=True, autoincrement=True) port_id = sa.Column(sa.String(255)) vlan_id = sa.Column(sa.Integer, nullable=False) switch_ip = sa.Column(sa.String(255)) instance_id = sa.Column(sa.String(255)) def __repr__(self): """"""Just the binding, without the id key."""""" return (""<NexusPortBinding(%s,%s,%s,%s)>"" % (self.port_id, self.vlan_id, self.switch_ip, self.instance_id)) def __eq__(self, other): """"""Compare only the binding, without the id key."""""" return ( self.port_id == other.port_id and self.vlan_id == other.vlan_id and self.switch_ip == other.switch_ip and self.instance_id == other.instance_id ) class RouterRule(model_base.BASEV2): id = sa.Column(sa.Integer, primary_key=True) source = sa.Column(sa.String(64), nullable=False) destination = sa.Column(sa.String(64), nullable=False) nexthops = orm.relationship('NextHop', cascade='all,delete') action = sa.Column(sa.String(10), nullable=False) router_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id', ondelete=""CASCADE"")) class NextHop(model_base.BASEV2): rule_id = sa.Column(sa.Integer, sa.ForeignKey('routerrules.id', ondelete=""CASCADE""), primary_key=True) nexthop = sa.Column(sa.String(64), nullable=False, primary_key=True) class FirewallRule(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a Firewall rule."""""" __tablename__ = 'firewall_rules' name = sa.Column(sa.String(255)) description = sa.Column(sa.String(1024)) firewall_policy_id = sa.Column(sa.String(36), sa.ForeignKey('firewall_policies.id'), nullable=True) shared = sa.Column(sa.Boolean) protocol = sa.Column(sa.String(40)) ip_version = sa.Column(sa.Integer, nullable=False) source_ip_address = sa.Column(sa.String(46)) destination_ip_address = sa.Column(sa.String(46)) source_port_range_min = sa.Column(sa.Integer) source_port_range_max = sa.Column(sa.Integer) destination_port_range_min = sa.Column(sa.Integer) destination_port_range_max = sa.Column(sa.Integer) action = sa.Column(sa.Enum('allow', 'deny', name='firewallrules_action')) enabled = sa.Column(sa.Boolean) position = sa.Column(sa.Integer) class Firewall(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a Firewall resource."""""" __tablename__ = 'firewalls' name = sa.Column(sa.String(255)) description = sa.Column(sa.String(1024)) shared = sa.Column(sa.Boolean) admin_state_up = sa.Column(sa.Boolean) status = sa.Column(sa.String(16)) firewall_policy_id = sa.Column(sa.String(36), sa.ForeignKey('firewall_policies.id'), nullable=True) class FirewallPolicy(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a Firewall Policy resource."""""" __tablename__ = 'firewall_policies' name = sa.Column(sa.String(255)) description = sa.Column(sa.String(1024)) shared = sa.Column(sa.Boolean) firewall_rules = orm.relationship( FirewallRule, backref=orm.backref('firewall_policies', cascade='all, delete'), order_by='FirewallRule.position', collection_class=ordering_list('position', count_from=1)) audited = sa.Column(sa.Boolean) firewalls = orm.relationship(Firewall, backref='firewall_policies') class PortSecurityBinding(model_base.BASEV2): port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) port_security_enabled = sa.Column(sa.Boolean(), nullable=False) # Add a relationship to the Port model in order to be to able to # instruct SQLAlchemy to eagerly load port security binding port = orm.relationship( models_v2.Port, backref=orm.backref(""port_security"", uselist=False, cascade='delete', lazy='joined')) class NetworkSecurityBinding(model_base.BASEV2): network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) port_security_enabled = sa.Column(sa.Boolean(), nullable=False) # Add a relationship to the Port model in order to be able to instruct # SQLAlchemy to eagerly load default port security setting for ports # on this network network = orm.relationship( models_v2.Network, backref=orm.backref(""port_security"", uselist=False, cascade='delete', lazy='joined')) class GreAllocation(model_base.BASEV2): __tablename__ = 'ml2_gre_allocations' gre_id = sa.Column(sa.Integer, nullable=False, primary_key=True, autoincrement=False) allocated = sa.Column(sa.Boolean, nullable=False, default=False) class GreEndpoints(model_base.BASEV2): """"""Represents tunnel endpoint in RPC mode."""""" __tablename__ = 'ml2_gre_endpoints' ip_address = sa.Column(sa.String(64), primary_key=True) def __repr__(self): return ""<GreTunnelEndpoint(%s)>"" % self.ip_address class MacLearningState(model_base.BASEV2): port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) mac_learning_enabled = sa.Column(sa.Boolean(), nullable=False) # Add a relationship to the Port model using the backref attribute. # This will instruct SQLAlchemy to eagerly load this association. port = orm.relationship( models_v2.Port, backref=orm.backref(""mac_learning_state"", lazy='joined', uselist=False, cascade='delete')) class MeteringLabelRule(model_base.BASEV2, models_v2.HasId): direction = sa.Column(sa.Enum('ingress', 'egress', name='meteringlabels_direction')) remote_ip_prefix = sa.Column(sa.String(64)) metering_label_id = sa.Column(sa.String(36), sa.ForeignKey(""meteringlabels.id"", ondelete=""CASCADE""), nullable=False) excluded = sa.Column(sa.Boolean, default=False) class MeteringLabel(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): name = sa.Column(sa.String(255)) description = sa.Column(sa.String(1024)) rules = orm.relationship(MeteringLabelRule, backref=""label"", cascade=""delete"", lazy=""joined"") routers = orm.relationship( Router, primaryjoin=""MeteringLabel.tenant_id==Router.tenant_id"", foreign_keys='MeteringLabel.tenant_id', uselist=True) #neutron/db/servicetype_db.py class ProviderResourceAssociation(model_base.BASEV2): provider_name = sa.Column(sa.String(255), nullable=False, primary_key=True) # should be manualy deleted on resource deletion resource_id = sa.Column(sa.String(36), nullable=False, primary_key=True, unique=True) #neutron/db/loadbalancer/loadbalancer_db.py class SessionPersistence(model_base.BASEV2): vip_id = sa.Column(sa.String(36), sa.ForeignKey(""vips.id""), primary_key=True) type = sa.Column(sa.Enum(""SOURCE_IP"", ""HTTP_COOKIE"", ""APP_COOKIE"", name=""sesssionpersistences_type""), nullable=False) cookie_name = sa.Column(sa.String(1024)) class PoolStatistics(model_base.BASEV2): """"""Represents pool statistics."""""" pool_id = sa.Column(sa.String(36), sa.ForeignKey(""pools.id""), primary_key=True) bytes_in = sa.Column(sa.BigInteger, nullable=False) bytes_out = sa.Column(sa.BigInteger, nullable=False) active_connections = sa.Column(sa.BigInteger, nullable=False) total_connections = sa.Column(sa.BigInteger, nullable=False) @validates('bytes_in', 'bytes_out', 'active_connections', 'total_connections') def validate_non_negative_int(self, key, value): if value < 0: data = {'key': key, 'value': value} raise ValueError(_('The %(key)s field can not have ' 'negative value. ' 'Current value is %(value)d.') % data) return value class Vip(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant, models_v2.HasStatusDescription): """"""Represents a v2 neutron loadbalancer vip."""""" name = sa.Column(sa.String(255)) description = sa.Column(sa.String(255)) port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id')) protocol_port = sa.Column(sa.Integer, nullable=False) protocol = sa.Column(sa.Enum(""HTTP"", ""HTTPS"", ""TCP"", name=""lb_protocols""), nullable=False) pool_id = sa.Column(sa.String(36), nullable=False, unique=True) session_persistence = orm.relationship(SessionPersistence, uselist=False, backref=""vips"", cascade=""all, delete-orphan"") admin_state_up = sa.Column(sa.Boolean(), nullable=False) connection_limit = sa.Column(sa.Integer) port = orm.relationship(models_v2.Port) class Member(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant, models_v2.HasStatusDescription): """"""Represents a v2 neutron loadbalancer member."""""" __table_args__ = ( sa.schema.UniqueConstraint('pool_id', 'address', 'protocol_port', name='uniq_member0pool_id0address0port'), ) pool_id = sa.Column(sa.String(36), sa.ForeignKey(""pools.id""), nullable=False) address = sa.Column(sa.String(64), nullable=False) protocol_port = sa.Column(sa.Integer, nullable=False) weight = sa.Column(sa.Integer, nullable=False) admin_state_up = sa.Column(sa.Boolean(), nullable=False) class Pool(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant, models_v2.HasStatusDescription): """"""Represents a v2 neutron loadbalancer pool."""""" vip_id = sa.Column(sa.String(36), sa.ForeignKey(""vips.id"")) name = sa.Column(sa.String(255)) description = sa.Column(sa.String(255)) subnet_id = sa.Column(sa.String(36), nullable=False) protocol = sa.Column(sa.Enum(""HTTP"", ""HTTPS"", ""TCP"", name=""lb_protocols""), nullable=False) lb_method = sa.Column(sa.Enum(""ROUND_ROBIN"", ""LEAST_CONNECTIONS"", ""SOURCE_IP"", name=""pools_lb_method""), nullable=False) admin_state_up = sa.Column(sa.Boolean(), nullable=False) stats = orm.relationship(PoolStatistics, uselist=False, backref=""pools"", cascade=""all, delete-orphan"") members = orm.relationship(Member, backref=""pools"", cascade=""all, delete-orphan"") monitors = orm.relationship(""PoolMonitorAssociation"", backref=""pools"", cascade=""all, delete-orphan"") vip = orm.relationship(Vip, backref='pool') provider = orm.relationship( ProviderResourceAssociation, uselist=False, lazy=""joined"", primaryjoin=""Pool.id==ProviderResourceAssociation.resource_id"", foreign_keys=[ProviderResourceAssociation.resource_id] ) class HealthMonitor(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a v2 neutron loadbalancer healthmonitor."""""" type = sa.Column(sa.Enum(""PING"", ""TCP"", ""HTTP"", ""HTTPS"", name=""healthmontiors_type""), nullable=False) delay = sa.Column(sa.Integer, nullable=False) timeout = sa.Column(sa.Integer, nullable=False) max_retries = sa.Column(sa.Integer, nullable=False) http_method = sa.Column(sa.String(16)) url_path = sa.Column(sa.String(255)) expected_codes = sa.Column(sa.String(64)) admin_state_up = sa.Column(sa.Boolean(), nullable=False) pools = orm.relationship( ""PoolMonitorAssociation"", backref=""healthmonitor"", cascade=""all"", lazy=""joined"" ) class PoolMonitorAssociation(model_base.BASEV2, models_v2.HasStatusDescription): """"""Many-to-many association between pool and healthMonitor classes."""""" pool_id = sa.Column(sa.String(36), sa.ForeignKey(""pools.id""), primary_key=True) monitor_id = sa.Column(sa.String(36), sa.ForeignKey(""healthmonitors.id""), primary_key=True) #neutron/services/loadbalancer/agent_scheduler.py class PoolLoadbalancerAgentBinding(model_base.BASEV2): """"""Represents binding between neutron loadbalancer pools and agents."""""" pool_id = sa.Column(sa.String(36), sa.ForeignKey(""pools.id"", ondelete='CASCADE'), primary_key=True) agent = orm.relation(Agent) agent_id = sa.Column(sa.String(36), sa.ForeignKey(""agents.id"", ondelete='CASCADE')) #neutron/plugins/vmware/dbexts/models.py class TzNetworkBinding(model_base.BASEV2): """"""Represents a binding of a virtual network with a transport zone. This model class associates a Neutron network with a transport zone; optionally a vlan ID might be used if the binding type is 'bridge' """""" __tablename__ = 'tz_network_bindings' # TODO(arosen) - it might be worth while refactoring the how this data # is stored later so every column does not need to be a primary key. network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) # 'flat', 'vlan', stt' or 'gre' binding_type = sa.Column(sa.Enum('flat', 'vlan', 'stt', 'gre', 'l3_ext', name='tz_network_bindings_binding_type'), nullable=False, primary_key=True) phy_uuid = sa.Column(sa.String(36), primary_key=True, nullable=True) vlan_id = sa.Column(sa.Integer, primary_key=True, nullable=True, autoincrement=False) def __init__(self, network_id, binding_type, phy_uuid, vlan_id): self.network_id = network_id self.binding_type = binding_type self.phy_uuid = phy_uuid self.vlan_id = vlan_id def __repr__(self): return ""<NetworkBinding(%s,%s,%s,%s)>"" % (self.network_id, self.binding_type, self.phy_uuid, self.vlan_id) class NeutronNsxNetworkMapping(model_base.BASEV2): """"""Maps neutron network identifiers to NSX identifiers. Because of chained logical switches more than one mapping might exist for a single Neutron network. """""" __tablename__ = 'neutron_nsx_network_mappings' neutron_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete='CASCADE'), primary_key=True) nsx_id = sa.Column(sa.String(36), primary_key=True) class NeutronNsxSecurityGroupMapping(model_base.BASEV2): """"""Backend mappings for Neutron Security Group identifiers. This class maps a neutron security group identifier to the corresponding NSX security profile identifier. """""" __tablename__ = 'neutron_nsx_security_group_mappings' neutron_id = sa.Column(sa.String(36), sa.ForeignKey('securitygroups.id', ondelete=""CASCADE""), primary_key=True) nsx_id = sa.Column(sa.String(36), primary_key=True) class NeutronNsxPortMapping(model_base.BASEV2): """"""Represents the mapping between neutron and nsx port uuids."""""" __tablename__ = 'neutron_nsx_port_mappings' neutron_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) nsx_switch_id = sa.Column(sa.String(36)) nsx_port_id = sa.Column(sa.String(36)) def __init__(self, neutron_id, nsx_switch_id, nsx_port_id): self.neutron_id = neutron_id self.nsx_switch_id = nsx_switch_id self.nsx_port_id = nsx_port_id class NeutronNsxRouterMapping(model_base.BASEV2): """"""Maps neutron router identifiers to NSX identifiers."""""" __tablename__ = 'neutron_nsx_router_mappings' neutron_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id', ondelete='CASCADE'), primary_key=True) nsx_id = sa.Column(sa.String(36)) class MultiProviderNetworks(model_base.BASEV2): """"""Networks provisioned through multiprovider extension."""""" __tablename__ = 'multi_provider_networks' network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) def __init__(self, network_id): self.network_id = network_id class NSXRouterExtAttributes(model_base.BASEV2): """"""Router attributes managed by NSX plugin extensions."""""" router_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id', ondelete=""CASCADE""), primary_key=True) distributed = sa.Column(sa.Boolean, default=False, nullable=False) service_router = sa.Column(sa.Boolean, default=False, nullable=False) # Add a relationship to the Router model in order to instruct # SQLAlchemy to eagerly load this association router = orm.relationship( Router, backref=orm.backref(""nsx_attributes"", lazy='joined', uselist=False, cascade='delete')) #neutron/plugins/ml2/drivers/type_flat.py class FlatAllocation(model_base.BASEV2): """"""Represent persistent allocation state of a physical network. If a record exists for a physical network, then that physical network has been allocated as a flat network. """""" __tablename__ = 'ml2_flat_allocations' physical_network = sa.Column(sa.String(64), nullable=False, primary_key=True) #neutron/plugins/vmware/dbexts/networkgw_db.py class NetworkConnection(model_base.BASEV2, models_v2.HasTenant): """"""Defines a connection between a network gateway and a network."""""" # We use port_id as the primary key as one can connect a gateway # to a network in multiple ways (and we cannot use the same port form # more than a single gateway) network_gateway_id = sa.Column(sa.String(36), sa.ForeignKey('networkgateways.id', ondelete='CASCADE')) network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete='CASCADE')) segmentation_type = sa.Column( sa.Enum('flat', 'vlan', name='networkconnections_segmentation_type')) segmentation_id = sa.Column(sa.Integer) __table_args__ = (sa.UniqueConstraint(network_gateway_id, segmentation_type, segmentation_id),) # Also, storing port id comes back useful when disconnecting a network # from a gateway port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete='CASCADE'), primary_key=True) class NetworkGatewayDeviceReference(model_base.BASEV2): id = sa.Column(sa.String(36), primary_key=True) network_gateway_id = sa.Column(sa.String(36), sa.ForeignKey('networkgateways.id', ondelete='CASCADE'), primary_key=True) interface_name = sa.Column(sa.String(64), primary_key=True) class NetworkGatewayDevice(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): nsx_id = sa.Column(sa.String(36)) # Optional name for the gateway device name = sa.Column(sa.String(255)) # Transport connector type. Not using enum as range of # connector types might vary with backend version connector_type = sa.Column(sa.String(10)) # Transport connector IP Address connector_ip = sa.Column(sa.String(64)) # operational status status = sa.Column(sa.String(16)) class NetworkGateway(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Defines the data model for a network gateway."""""" name = sa.Column(sa.String(255)) # Tenant id is nullable for this resource tenant_id = sa.Column(sa.String(36)) default = sa.Column(sa.Boolean()) devices = orm.relationship(NetworkGatewayDeviceReference, backref='networkgateways', cascade='all,delete') network_connections = orm.relationship(NetworkConnection, lazy='joined') #neutron/plugins/ml2/drivers/brocade/db/models.py class ML2_BrocadeNetwork(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Schema for brocade network."""""" vlan = sa.Column(sa.String(10)) segment_id = sa.Column(sa.String(36)) network_type = sa.Column(sa.String(10)) class ML2_BrocadePort(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Schema for brocade port."""""" network_id = sa.Column(sa.String(36), sa.ForeignKey(""ml2_brocadenetworks.id""), nullable=False) admin_state_up = sa.Column(sa.Boolean, nullable=False) physical_interface = sa.Column(sa.String(36)) vlan_id = sa.Column(sa.String(36)) #neutron/plugins/hyperv/model.py class VlanAllocation(model_base.BASEV2): """"""Represents allocation state of vlan_id on physical network."""""" __tablename__ = 'hyperv_vlan_allocations' physical_network = sa.Column(sa.String(64), nullable=False, primary_key=True) vlan_id = sa.Column(sa.Integer, nullable=False, primary_key=True, autoincrement=False) allocated = sa.Column(sa.Boolean, nullable=False) def __init__(self, physical_network, vlan_id): self.physical_network = physical_network self.vlan_id = vlan_id self.allocated = False class NetworkBinding(model_base.BASEV2): """"""Represents binding of virtual network to physical realization."""""" __tablename__ = 'hyperv_network_bindings' network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) network_type = sa.Column(sa.String(32), nullable=False) physical_network = sa.Column(sa.String(64)) segmentation_id = sa.Column(sa.Integer) def __init__(self, network_id, network_type, physical_network, segmentation_id): self.network_id = network_id self.network_type = network_type self.physical_network = physical_network self.segmentation_id = segmentation_id #neutron/plugins/brocade/db/models.py class BrocadeNetwork(model_base.BASEV2, models_v2.HasId): """"""Schema for brocade network."""""" vlan = sa.Column(sa.String(10)) class BrocadePort(model_base.BASEV2): """"""Schema for brocade port."""""" port_id = sa.Column(sa.String(36), primary_key=True, default="""") network_id = sa.Column(sa.String(36), sa.ForeignKey(""brocadenetworks.id""), nullable=False) admin_state_up = sa.Column(sa.Boolean, nullable=False) physical_interface = sa.Column(sa.String(36)) vlan_id = sa.Column(sa.String(36)) tenant_id = sa.Column(sa.String(36)) #neutron/db/agentschedulers_db.py class NetworkDhcpAgentBinding(model_base.BASEV2): """"""Represents binding between neutron networks and DHCP agents."""""" network_id = sa.Column(sa.String(36), sa.ForeignKey(""networks.id"", ondelete='CASCADE'), primary_key=True) dhcp_agent = orm.relation(Agent) dhcp_agent_id = sa.Column(sa.String(36), sa.ForeignKey(""agents.id"", ondelete='CASCADE'), primary_key=True) #neutron/plugins/cisco/db/network_models_v2.py class QoS(model_base.BASEV2): """"""Represents QoS policies for a tenant."""""" __tablename__ = 'cisco_qos_policies' qos_id = sa.Column(sa.String(255)) tenant_id = sa.Column(sa.String(255), primary_key=True) qos_name = sa.Column(sa.String(255), primary_key=True) qos_desc = sa.Column(sa.String(255)) class Credential(model_base.BASEV2): """"""Represents credentials for a tenant to control Cisco switches."""""" __tablename__ = 'cisco_credentials' credential_id = sa.Column(sa.String(255)) credential_name = sa.Column(sa.String(255), primary_key=True) user_name = sa.Column(sa.String(255)) password = sa.Column(sa.String(255)) type = sa.Column(sa.String(255)) class ProviderNetwork(model_base.BASEV2): """"""Represents networks that were created as provider networks."""""" __tablename__ = 'cisco_provider_networks' network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) network_type = sa.Column(sa.String(255), nullable=False) segmentation_id = sa.Column(sa.Integer, nullable=False) #neutron/plugins/nuage/nuage_models.py class NetPartition(model_base.BASEV2, models_v2.HasId): __tablename__ = 'net_partitions' name = sa.Column(sa.String(64)) l3dom_tmplt_id = sa.Column(sa.String(36)) l2dom_tmplt_id = sa.Column(sa.String(36)) class NetPartitionRouter(model_base.BASEV2): __tablename__ = ""net_partition_router_mapping"" net_partition_id = sa.Column(sa.String(36), sa.ForeignKey('net_partitions.id', ondelete=""CASCADE""), primary_key=True) router_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id', ondelete=""CASCADE""), primary_key=True) nuage_router_id = sa.Column(sa.String(36)) class RouterZone(model_base.BASEV2): __tablename__ = ""router_zone_mapping"" router_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id', ondelete=""CASCADE""), primary_key=True) nuage_zone_id = sa.Column(sa.String(36)) nuage_user_id = sa.Column(sa.String(36)) nuage_group_id = sa.Column(sa.String(36)) class SubnetL2Domain(model_base.BASEV2): __tablename__ = 'subnet_l2dom_mapping' subnet_id = sa.Column(sa.String(36), sa.ForeignKey('subnets.id', ondelete=""CASCADE""), primary_key=True) net_partition_id = sa.Column(sa.String(36), sa.ForeignKey('net_partitions.id', ondelete=""CASCADE"")) nuage_subnet_id = sa.Column(sa.String(36)) nuage_l2dom_tmplt_id = sa.Column(sa.String(36)) nuage_user_id = sa.Column(sa.String(36)) nuage_group_id = sa.Column(sa.String(36)) class PortVPortMapping(model_base.BASEV2): __tablename__ = 'port_mapping' port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) nuage_vport_id = sa.Column(sa.String(36)) nuage_vif_id = sa.Column(sa.String(36)) static_ip = sa.Column(sa.Boolean()) #neutron/plugins/ml2/drivers/cisco/nexus/nexus_models_v2.py class NexusPortBinding(model_base.BASEV2): """"""Represents a binding of VM's to nexus ports."""""" __tablename__ = ""cisco_ml2_nexusport_bindings"" binding_id = sa.Column(sa.Integer, primary_key=True, autoincrement=True) port_id = sa.Column(sa.String(255)) vlan_id = sa.Column(sa.Integer, nullable=False) switch_ip = sa.Column(sa.String(255)) instance_id = sa.Column(sa.String(255)) def __repr__(self): """"""Just the binding, without the id key."""""" return (""<NexusPortBinding(%s,%s,%s,%s)>"" % (self.port_id, self.vlan_id, self.switch_ip, self.instance_id)) def __eq__(self, other): """"""Compare only the binding, without the id key."""""" return ( self.port_id == other.port_id and self.vlan_id == other.vlan_id and self.switch_ip == other.switch_ip and self.instance_id == other.instance_id ) #neutron/plugins/vmware/dbexts/vcns_models.py class VcnsRouterBinding(model_base.BASEV2, models_v2.HasStatusDescription): """"""Represents the mapping between neutron router and vShield Edge."""""" __tablename__ = 'vcns_router_bindings' # no ForeignKey to routers.id because for now, a router can be removed # from routers when delete_router is executed, but the binding is only # removed after the Edge is deleted router_id = sa.Column(sa.String(36), primary_key=True) edge_id = sa.Column(sa.String(16), nullable=True) lswitch_id = sa.Column(sa.String(36), nullable=False) # # VCNS Edge FW mapping tables # class VcnsEdgeFirewallRuleBinding(model_base.BASEV2): """"""1:1 mapping between firewall rule and edge firewall rule_id."""""" __tablename__ = 'vcns_firewall_rule_bindings' rule_id = sa.Column(sa.String(36), sa.ForeignKey(""firewall_rules.id""), primary_key=True) edge_id = sa.Column(sa.String(36), primary_key=True) rule_vseid = sa.Column(sa.String(36)) class VcnsEdgePoolBinding(model_base.BASEV2): """"""Represents the mapping between neutron pool and Edge pool."""""" __tablename__ = 'vcns_edge_pool_bindings' pool_id = sa.Column(sa.String(36), sa.ForeignKey(""pools.id"", ondelete=""CASCADE""), primary_key=True) edge_id = sa.Column(sa.String(36), primary_key=True) pool_vseid = sa.Column(sa.String(36)) class VcnsEdgeVipBinding(model_base.BASEV2): """"""Represents the mapping between neutron vip and Edge vip."""""" __tablename__ = 'vcns_edge_vip_bindings' vip_id = sa.Column(sa.String(36), sa.ForeignKey(""vips.id"", ondelete=""CASCADE""), primary_key=True) edge_id = sa.Column(sa.String(36)) vip_vseid = sa.Column(sa.String(36)) app_profileid = sa.Column(sa.String(36)) class VcnsEdgeMonitorBinding(model_base.BASEV2): """"""Represents the mapping between neutron monitor and Edge monitor."""""" __tablename__ = 'vcns_edge_monitor_bindings' monitor_id = sa.Column(sa.String(36), sa.ForeignKey(""healthmonitors.id"", ondelete=""CASCADE""), primary_key=True) edge_id = sa.Column(sa.String(36), primary_key=True) monitor_vseid = sa.Column(sa.String(36)) ",,1844,0
openstack%2Fheat-templates~master~I74acfdd553eb6a4c7ac771b6c0ec6543e1e63ea9,openstack/heat-templates,master,I74acfdd553eb6a4c7ac771b6c0ec6543e1e63ea9,Add HA templates to deploy OpenShift on CentOS,MERGED,2014-07-10 20:16:30.000000000,2014-07-17 00:07:05.000000000,2014-07-17 00:07:05.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4715}]","[{'number': 1, 'created': '2014-07-10 20:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/8d8163ce36808ff8963be329cb4cd2f4c4fe2c6f', 'message': 'Add HA templates to deploy OpenShift on CentOS\n\nThese templates are heavily based on the existing OpenShift enterprise\ntemplates for use with RHEL. The OpenShift installer utilized in these\ntemplates has been slightly modified to support CentOS as well as make\nthe install completely automated (aside from creating districts if so\ndesired.)\n\nChange-Id: I74acfdd553eb6a4c7ac771b6c0ec6543e1e63ea9\n'}, {'number': 2, 'created': '2014-07-16 05:05:37.000000000', 'files': ['openshift-origin/centos65/highly-available/oso_node_env.yaml', 'openshift-origin/centos65/highly-available/README.md', 'openshift-origin/centos65/highly-available/oso_ha_env.yaml', 'openshift-origin/centos65/highly-available/oso_ha_stack.yaml', 'openshift-origin/centos65/highly-available/oso_node_stack.yaml', 'openshift-origin/centos65/README.rst'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/d357422cf63e1a71a23ab9259ab030895c201f91', 'message': 'Add HA templates to deploy OpenShift on CentOS\n\nThese templates are heavily based on the existing OpenShift enterprise\ntemplates for use with RHEL. The OpenShift installer utilized in these\ntemplates has been slightly modified to support CentOS as well as make\nthe install completely automated (aside from creating districts if so\ndesired.)\n\nChange-Id: I74acfdd553eb6a4c7ac771b6c0ec6543e1e63ea9\n'}]",2,106159,d357422cf63e1a71a23ab9259ab030895c201f91,15,4,2,3098,,,0,"Add HA templates to deploy OpenShift on CentOS

These templates are heavily based on the existing OpenShift enterprise
templates for use with RHEL. The OpenShift installer utilized in these
templates has been slightly modified to support CentOS as well as make
the install completely automated (aside from creating districts if so
desired.)

Change-Id: I74acfdd553eb6a4c7ac771b6c0ec6543e1e63ea9
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/59/106159/2 && git format-patch -1 --stdout FETCH_HEAD,"['openshift-origin/centos65/highly-available/oso_node_env.yaml', 'openshift-origin/centos65/highly-available/README.md', 'openshift-origin/centos65/highly-available/oso_ha_env.yaml', 'openshift-origin/centos65/highly-available/oso_ha_stack.yaml', 'openshift-origin/centos65/highly-available/oso_node_stack.yaml', 'openshift-origin/centos65/README.rst']",6,8d8163ce36808ff8963be329cb4cd2f4c4fe2c6f,oso-ha, And the following directory: * `highly-available` - deploys OpenShift Origin in a highly available setup as further described in its README.md,,1155,0
openstack%2Fnova~master~Ie8a1ce6d0d7b90fb73555981fa974e9029344d3b,openstack/nova,master,Ie8a1ce6d0d7b90fb73555981fa974e9029344d3b,Add API schema for v2.1/v3 create_backup API,MERGED,2014-01-14 06:45:35.000000000,2014-07-17 00:06:01.000000000,2014-07-17 00:05:58.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9533}, {'_account_id': 9560}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-01-14 06:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dacd1e985fab3bb2be0c8af6632dd6c1c5119376', 'message': 'Add API schema for v3 create_backup API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: Ie8a1ce6d0d7b90fb73555981fa974e9029344d3b\n'}, {'number': 2, 'created': '2014-01-14 23:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ebdd0e382017a9b81ecb59ce93a4501e130fb18', 'message': 'Add API schema for v3 create_backup API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: Ie8a1ce6d0d7b90fb73555981fa974e9029344d3b\n'}, {'number': 3, 'created': '2014-01-20 08:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ef4a22f5cffa02271769eadab9b32e7e3584c91', 'message': 'Add API schema for v3 create_backup API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: Ie8a1ce6d0d7b90fb73555981fa974e9029344d3b\n'}, {'number': 4, 'created': '2014-06-18 02:56:15.000000000', 'files': ['nova/api/openstack/compute/schemas/v3/create_backup.py', 'nova/tests/api/openstack/compute/plugins/v3/test_create_backup.py', 'nova/api/openstack/compute/plugins/v3/create_backup.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/62fa2bcd226350d95ba947e5f9d3ca13d57d6581', 'message': 'Add API schema for v2.1/v3 create_backup API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: Ie8a1ce6d0d7b90fb73555981fa974e9029344d3b\n'}]",3,66502,62fa2bcd226350d95ba947e5f9d3ca13d57d6581,83,13,4,6167,,,0,"Add API schema for v2.1/v3 create_backup API

By defining the API schema, it is possible to separate the validation
code from the API method. The API method can be more simple.
In addition, a response of API validation error can be consistent for
the whole Nova API.

Partially implements blueprint v3-api-schema

Change-Id: Ie8a1ce6d0d7b90fb73555981fa974e9029344d3b
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/66502/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/schemas/v3/create_backup.py', 'nova/api/openstack/compute/plugins/v3/create_backup.py', 'nova/tests/api/openstack/compute/plugins/v3/test_create_backup.py']",3,dacd1e985fab3bb2be0c8af6632dd6c1c5119376,bp/v3-api-schema," def test_create_backup_negative_rotation_with_string_number(self): body = { 'create_backup': { 'name': 'Backup 1', 'backup_type': 'daily', 'rotation': '-1', }, } res = self._make_request(self._make_url('fake'), body) self.assertEqual(400, res.status_int) def test_create_backup_non_dict_metadata(self): body = { 'create_backup': { 'name': 'Backup 1', 'backup_type': 'daily', 'rotation': 1, 'metadata': 'non_dict', }, } res = self._make_request(self._make_url('fake'), body) self.assertEqual(400, res.status_int) def test_create_backup_rotation_is_string_number(self): body = { 'create_backup': { 'name': 'Backup 1', 'backup_type': 'daily', 'rotation': '1', }, } image = dict(id='fake-image-id', status='ACTIVE', name='Backup 1', properties={}) common.check_img_metadata_properties_quota(self.context, {}) instance = self._stub_instance_get() self.compute_api.backup(self.context, instance, 'Backup 1', 'daily', 1, extra_properties={}).AndReturn(image) self.mox.ReplayAll() res = self._make_request(self._make_url(instance['uuid']), body) self.assertEqual(202, res.status_int) self.assertIn('fake-image-id', res.headers['Location']) ",,97,27
openstack%2Fnova~master~I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260,openstack/nova,master,I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260,Add API schema for v2.1/v3 migrate_server API,MERGED,2014-01-14 07:32:55.000000000,2014-07-17 00:04:35.000000000,2014-07-17 00:04:32.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9533}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-01-14 07:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7aa8c4883b1a60e33c25868e019c8e3b6f8b648b', 'message': 'Add API schema for v3 migrate_server API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260\n'}, {'number': 2, 'created': '2014-01-14 23:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d319fe40a36124d5dd5a3693216ca32e29d48db', 'message': 'Add API schema for v3 migrate_server API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260\n'}, {'number': 3, 'created': '2014-01-20 08:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf683612534fd032217301ed00ba95230a43e9a1', 'message': 'Add API schema for v3 migrate_server API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260\n'}, {'number': 4, 'created': '2014-02-03 01:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7a1d99f73641497f801877a25987326344c7e8a', 'message': 'Add API schema for v3 migrate_server API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260\n'}, {'number': 5, 'created': '2014-02-12 08:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/704d8ad6ab5307037ca1ab187b6f60154650f237', 'message': 'Add API schema for v3 migrate_server API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260\n'}, {'number': 6, 'created': '2014-02-17 03:25:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a47ad81802c4b1386e3273568a47abf94ad552eb', 'message': 'Add API schema for v3 migrate_server API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260\n'}, {'number': 7, 'created': '2014-02-25 01:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d9d0991e77f7b405937b7531dec9771993bf1dc', 'message': 'Add API schema for v3 migrate_server API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260\n'}, {'number': 8, 'created': '2014-05-30 06:22:53.000000000', 'files': ['nova/api/openstack/compute/schemas/v3/migrate_server.py', 'nova/api/openstack/compute/plugins/v3/migrate_server.py', 'nova/tests/api/openstack/compute/plugins/v3/test_migrate_server.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/21f9409b2b116b44d206337b770ac0b783347101', 'message': 'Add API schema for v2.1/v3 migrate_server API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260\n'}]",2,66509,21f9409b2b116b44d206337b770ac0b783347101,99,13,8,6167,,,0,"Add API schema for v2.1/v3 migrate_server API

By defining the API schema, it is possible to separate the validation
code from the API method. The API method can be more simple.
In addition, a response of API validation error can be consistent for
the whole Nova API.

Partially implements blueprint v3-api-schema

Change-Id: I9f1eea8471af0f86dcf472ed8a4fdb634dfdb260
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/66509/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/schemas/v3/migrate_server.py', 'nova/api/openstack/compute/plugins/v3/migrate_server.py', 'nova/tests/api/openstack/compute/plugins/v3/test_migrate_server.py']",3,7aa8c4883b1a60e33c25868e019c8e3b6f8b648b,bp/v3-api-schema," def test_migrate_live_without_host(self): def test_migrate_live_without_block_migration(self): res = self._make_request('/servers/FAKE/action', {'migrate_live': {'host': 'hostname', 'dummy': False, 'disk_over_commit': False}}) self.assertEqual(400, res.status_int) def test_migrate_live_without_disk_over_commit(self): res = self._make_request('/servers/FAKE/action', {'migrate_live': {'host': 'hostname', 'block_migration': False, 'dummy': False}}) ", def test_migrate_live_missing_dict_param(self):,69,16
openstack%2Fnova~master~I0c4066c34f6da0934946aa9eda907b911dbede16,openstack/nova,master,I0c4066c34f6da0934946aa9eda907b911dbede16,Add API schema for v2.1/v3 attach_interfaces API,MERGED,2014-01-31 14:29:16.000000000,2014-07-17 00:04:20.000000000,2014-07-17 00:04:18.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 6167}, {'_account_id': 7882}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9533}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-01-31 14:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea01720ce4541fd92c823bda7477a67cdaf821b8', 'message': 'Add API schema for v3 attach_interfaces API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I0c4066c34f6da0934946aa9eda907b911dbede16\n'}, {'number': 2, 'created': '2014-02-03 02:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9d73f75a5ee17a4dd49953f2e6a01c6e4a4998b', 'message': 'Add API schema for v3 attach_interfaces API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I0c4066c34f6da0934946aa9eda907b911dbede16\n'}, {'number': 3, 'created': '2014-02-12 05:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cf713644ddc71f1839f5c9af97b41f81c20f8a1', 'message': 'Add API schema for v3 attach_interfaces API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I0c4066c34f6da0934946aa9eda907b911dbede16\n'}, {'number': 4, 'created': '2014-04-08 08:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8eac67ec88833c098cff14597b8d8dae2946a631', 'message': 'Add API schema for v3 attach_interfaces API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I0c4066c34f6da0934946aa9eda907b911dbede16\n'}, {'number': 5, 'created': '2014-05-30 06:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d6d795b61db8ca14682a0d4cfc6e3818cfdedb5', 'message': 'Add API schema for v2.1/v3 attach_interfaces API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I0c4066c34f6da0934946aa9eda907b911dbede16\n'}, {'number': 6, 'created': '2014-05-30 07:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84442248111992f12a019843d6da849ea426aea6', 'message': 'Add API schema for v2.1/v3 attach_interfaces API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I0c4066c34f6da0934946aa9eda907b911dbede16\n'}, {'number': 7, 'created': '2014-06-18 04:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51280162b49895a21a8586a6fc8dcd20a150d233', 'message': 'Add API schema for v2.1/v3 attach_interfaces API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I0c4066c34f6da0934946aa9eda907b911dbede16\n'}, {'number': 8, 'created': '2014-06-25 04:43:48.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_attach_interfaces.py', 'nova/api/openstack/compute/schemas/v3/attach_interfaces.py', 'nova/api/openstack/compute/plugins/v3/attach_interfaces.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f85eede2eed8bc0a06d3711d3857eea14baf1dfa', 'message': 'Add API schema for v2.1/v3 attach_interfaces API\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I0c4066c34f6da0934946aa9eda907b911dbede16\n'}]",0,70353,f85eede2eed8bc0a06d3711d3857eea14baf1dfa,132,12,8,6167,,,0,"Add API schema for v2.1/v3 attach_interfaces API

By defining the API schema, it is possible to separate the validation
code from the API method. The API method can be more simple.
In addition, a response of API validation error can be consistent for
the whole Nova API.

Partially implements blueprint v3-api-schema

Change-Id: I0c4066c34f6da0934946aa9eda907b911dbede16
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/70353/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_attach_interfaces.py', 'nova/api/openstack/compute/schemas/v3/attach_interfaces.py', 'nova/api/openstack/compute/plugins/v3/attach_interfaces.py']",3,ea01720ce4541fd92c823bda7477a67cdaf821b8,bp/v3-api-schema,from nova.api.openstack.compute.schemas.v3 import attach_interfacesfrom nova.api import validation @validation.schema(attach_interfaces.create),,61,4
openstack%2Fironic~master~Ic7f6b54e9b4b94b4cb3108dd7d4ea808a99fa382,openstack/ironic,master,Ic7f6b54e9b4b94b4cb3108dd7d4ea808a99fa382,Import a few more fixes from the Nova driver,MERGED,2014-07-16 00:35:58.000000000,2014-07-16 23:55:57.000000000,2014-07-16 21:41:26.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-07-16 00:35:58.000000000', 'files': ['ironic/nova/virt/ironic/driver.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a696fe7c6bb0752308d13a60bbea31da685a14f4', 'message': 'Import a few more fixes from the Nova driver\n\nImport a few fixes based on comments on rev 4 of\nhttps://review.openstack.org/#/c/103167/\n\nChange-Id: Ic7f6b54e9b4b94b4cb3108dd7d4ea808a99fa382\n'}]",0,107214,a696fe7c6bb0752308d13a60bbea31da685a14f4,20,6,1,2889,,,0,"Import a few more fixes from the Nova driver

Import a few fixes based on comments on rev 4 of
https://review.openstack.org/#/c/103167/

Change-Id: Ic7f6b54e9b4b94b4cb3108dd7d4ea808a99fa382
",git fetch https://review.opendev.org/openstack/ironic refs/changes/14/107214/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/nova/virt/ironic/driver.py'],1,a696fe7c6bb0752308d13a60bbea31da685a14f4,more-nova-fixes, # validate we are ready to do the deploy # something is wrong. undo what we have done,"def _get_required_value(key, value): """"""Return the requested value."""""" if '/' in value: # we need to split the value split_value = value.split('/') eval_string = 'key' for value in split_value: eval_string = ""%s['%s']"" % (eval_string, value) return eval(eval_string) else: return key[value] #validate we ready to do the deploy # something is wrong. undo we we have done def get_console_output(self, context, instance): """"""Get console log for an instance. Not Implemented Yet. :param context: The security context. :param instance: The instance object. """""" raise NotImplementedError() ",2,26
openstack%2Fmonasca-notification~master~I75175f23aa86fec443ab04bae54584b4fa65f4dd,openstack/monasca-notification,master,I75175f23aa86fec443ab04bae54584b4fa65f4dd,Get initial build to work.,ABANDONED,2014-07-15 21:05:06.000000000,2014-07-16 23:34:54.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-15 21:05:06.000000000', 'files': ['.gitreview', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/7f3e6898da14fb6fda5ff4579729990523a483aa', 'message': 'Get initial build to work.\n\nAdd .gitreview, tox.ini\n\nChange-Id: I75175f23aa86fec443ab04bae54584b4fa65f4dd\n'}]",0,107175,7f3e6898da14fb6fda5ff4579729990523a483aa,4,1,1,11809,,,0,"Get initial build to work.

Add .gitreview, tox.ini

Change-Id: I75175f23aa86fec443ab04bae54584b4fa65f4dd
",git fetch https://review.opendev.org/openstack/monasca-notification refs/changes/75/107175/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'tox.ini']",2,7f3e6898da14fb6fda5ff4579729990523a483aa,check_build,"[tox] envlist = py27,pypy,pep8 minversion = 1.6 skipsdist = True [testenv] setenv = VIRTUAL_ENV={envdir} usedevelop = True install_command = pip install -U {opts} {packages} deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = python setup.py testr --slowest --testr-args='{posargs}' [testenv:pep8] commands = flake8 {toxinidir}/tools/requirements_style_check.sh requirements.txt test-requirements.txt [testenv:venv] commands = {posargs} [testenv:cover] commands = python setup.py testr --coverage --testr-args='{posargs}' [tox:jenkins] downloadcache = ~/cache/pip [flake8] show-source = True # H302: Do not import objects, only modules ignore = H302,H803 builtins = _ exclude=.venv,.git,.tox,dist,*openstack/common*,*lib/python*,*egg,build ",,37,0
openstack%2Fsahara~master~I7265c4ca325fbecd6141b8dbe555a2d7f786e1ba,openstack/sahara,master,I7265c4ca325fbecd6141b8dbe555a2d7f786e1ba,Create v2 API structure,ABANDONED,2014-02-02 20:29:14.000000000,2014-07-16 23:22:26.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7604}, {'_account_id': 7737}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-02-02 20:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/65edeaa3fb75f3c3b20493ef41fae8db961accb3', 'message': 'Create v2 API structure\n\nThis is the proposed structure for the v2 API. It is not necessarily\ncomplete and has no implementation. It serves as the foundation of the\nv2 API.\n\nChange-Id: I7265c4ca325fbecd6141b8dbe555a2d7f786e1ba\nImplements: blueprint v2-api\n'}, {'number': 2, 'created': '2014-02-15 13:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b06e40e57264dcadacd05edfeadfc11a33d0f799', 'message': 'Create v2 API structure\n\nThis is the proposed structure for the v2 API. It is not necessarily\ncomplete and has no implementation. It serves as the foundation of the\nv2 API.\n\nChange-Id: I7265c4ca325fbecd6141b8dbe555a2d7f786e1ba\nImplements: blueprint v2-api\n'}, {'number': 3, 'created': '2014-02-15 14:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d7b8f6a2d611240d37d1ddfd665d278d783a8d54', 'message': 'Create v2 API structure\n\nThis is the proposed structure for the v2 API. It is not necessarily\ncomplete and has no implementation. It serves as the foundation of the\nv2 API.\n\nChange-Id: I7265c4ca325fbecd6141b8dbe555a2d7f786e1ba\nImplements: blueprint v2-api\n'}, {'number': 4, 'created': '2014-02-18 14:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/36aa21eed0190f857ee6d24d760a1b519400f019', 'message': 'Create v2 API structure\n\nThis is the proposed structure for the v2 API. It is not necessarily\ncomplete and has no implementation. It serves as the foundation of the\nv2 API.\n\nChange-Id: I7265c4ca325fbecd6141b8dbe555a2d7f786e1ba\nImplements: blueprint v2-api\n'}, {'number': 5, 'created': '2014-02-19 17:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/313def23c9465a0f890cf2d3c98f3f2d42d9dea3', 'message': 'Create v2 API structure\n\nThis is the proposed structure for the v2 API. It is not necessarily\ncomplete and has no implementation. It serves as the foundation of the\nv2 API.\n\nChange-Id: I7265c4ca325fbecd6141b8dbe555a2d7f786e1ba\nImplements: blueprint v2-api\n'}, {'number': 6, 'created': '2014-02-19 18:40:52.000000000', 'files': ['savanna/api/v2.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/af39e4f39cdb2b962c9a853a45ba673ffd72db05', 'message': 'Create v2 API structure\n\nThis is the proposed structure for the v2 API. It is not necessarily\ncomplete and has no implementation. It serves as the foundation of the\nv2 API.\n\nImplements: blueprint v2-api\nChange-Id: I7265c4ca325fbecd6141b8dbe555a2d7f786e1ba\n'}]",20,70627,af39e4f39cdb2b962c9a853a45ba673ffd72db05,118,11,6,7555,,,0,"Create v2 API structure

This is the proposed structure for the v2 API. It is not necessarily
complete and has no implementation. It serves as the foundation of the
v2 API.

Implements: blueprint v2-api
Change-Id: I7265c4ca325fbecd6141b8dbe555a2d7f786e1ba
",git fetch https://review.opendev.org/openstack/sahara refs/changes/27/70627/4 && git format-patch -1 --stdout FETCH_HEAD,['savanna/api/v2.py'],1,65edeaa3fb75f3c3b20493ef41fae8db961accb3,bp/v2-api,"# Copyright 2013 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import savanna.utils.api rest = savanna.utils.api.Rest('v2', __name__) ## ## plugins ## # list plugins, from config @rest.get('/plugins') def plugins_list(): pass # get details for a plugin @rest.get('/plugins/<name>') def plugins_get(name): pass # get details for a specific plugin version @rest.get('/plugins/<name>/<version>') def plugins_get_version(name, version): pass ## ## images ## # list registered images @rest.get('/images') def images_list(): pass # register or update an image (change username / tags) # note - <id> must be a glance image id @rest.put('/images/<id>') def images_update(id, data): pass # get details of a registered image @rest.get('/images/<id>') def images_get(id): pass # unregister an image @rest.delete('/images/<id>') def images_delete(id): pass ## ## node group templates ## # list node group templates @rest.get('/node-group-templates') def node_group_templates_list(): pass # create a node group template @rest.post('/node-group-templates') def node_group_templates_create(data): pass # get details of a node group template @rest.get('/node-group-templates/<id>') def node_group_templates_get(id): pass # modify a node group template @rest.put('/node-group-templates/<id>') def node_group_templates_update(id, data): pass # delete a node group template @rest.delete('/node-group-templates/<id>') def node_group_templates_delete(id): pass ## ## cluster templates ## # list cluster templates @rest.get('/cluster-templates') def cluster_templates_list(): pass # create a cluster template @rest.post('/cluster-templates') def cluster_templates_create(data): pass # get details of a cluster template @rest.get('/cluster-templates/<id>') def cluster_templates_get(id): pass # modify a cluster template @rest.put('/cluster-templates/<id>') def cluster_templates_update(id, data): pass # delete a cluster template @rest.delete('/cluster-templates/<id>') def cluster_templates_delete(id): pass ## ## clusters ## # list clusters @rest.get('/clusters') def clusters_list(): pass # create a cluster @rest.post('/clusters') def clusters_create(data): pass # get details of a cluster @rest.get('/clusters/<id>') def clusters_get(id): pass # scale a cluster @rest.put('/clusters/<id>') def clusters_update(id, data): pass # delete a cluster @rest.delete('/clusters/<id>') def clusters_delete(id): pass ## ## data sources ## # list data sources @rest.get('/data-sources') def data_sources_list(): pass # create a data source @rest.post('/data-sources') def data_sources_create(data): pass # get details of a data source @rest.get('/data-sources/<id>') def data_sources_get(id): pass # delete a data source @rest.delete('/data-sources/<id>') def data_sources_delete(id): pass ## ## job binaries ## # list job binaries @rest.get('/job-binaries') def job_binaries_list(): pass # create a job binary @rest.post('/job-binaries') def job_binaries_create(data): pass # get details of a job binary @rest.get('/job-binaries/<id>') def job_binaries_get(id): pass # download the job binary data, proxied by savanna api service @rest.get('/job-binaries/<id>/data') def job_binaries_download(id): pass # delete a job binary @rest.delete('/job-binaries/<id>') def job_binaries_delete(id): pass ## ## job binary data, private savanna db storage, use swift instead ## # list stored job binary data @rest.get('/job-binary-data') def job_binary_data_list(): pass # store new job binary data @rest.post_file('/job-binary-data') def job_binary_data_create(data): pass # delete stored job binary data @rest.delete('/job-binary-data/<id>') def job_binary_data_delete(id): pass ## ## job templates ## # list job templates @rest.get('/job-templates') def job_templates_list(): pass # create a job template @rest.post('/job-templates') def job_templates_create(data): pass # get details of a job template @rest.get('/job-templates/<id>') def job_templates_get(id): pass # delete a job template @rest.delete('/job-templates/<id>') def job_templates_delete(id): pass ## ## jobs ## # list jobs @rest.get('/jobs') def jobs_list(): pass # create a new job @rest.post('/jobs') def jobs_create(data): pass # get details of a job @rest.get('/jobs/<id>') def jobs_get(id): pass # delete a job @rest.delete('/jobs/<id>') def jobs_delete(id): pass ",,312,0
openstack%2Fsolum~master~I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e,openstack/solum,master,I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e,Create an empty stack when creating the pipeline,MERGED,2014-07-02 06:09:38.000000000,2014-07-16 23:17:52.000000000,2014-07-16 23:17:51.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-07-02 06:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6410c2a4766d9e05bc890a546bcab4ced1b71b9e', 'message': 'Create an empty stack when creating the pipeline\n\nChange-Id: I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e\n'}, {'number': 2, 'created': '2014-07-07 18:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4f44ee70912ef2c6124f927d1a3fbe7ec571708e', 'message': 'Create an empty stack when creating the pipeline\n\nChange-Id: I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e\n'}, {'number': 3, 'created': '2014-07-08 22:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/e5e3d63e791b6577398eceb542319b9e97c5660d', 'message': 'Create an empty stack when creating the pipeline\n\nChange-Id: I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e\n'}, {'number': 4, 'created': '2014-07-09 18:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/2844247a5f4f9fd25a213833703514627f80b329', 'message': 'Create an empty stack when creating the pipeline\n\nChange-Id: I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e\n'}, {'number': 5, 'created': '2014-07-09 20:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/819280e3dcdd7e99784f5ae589a6a51395589ba7', 'message': ""Create an empty stack when creating the pipeline\n\nHeat stack create needs to create a trust, at the moment\nthis can't be done in the context of a mistral task as\na trust token is passed into the task and creating a trust\nfrom a trust token is not currently allowed.\n\nChange-Id: I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e\n""}, {'number': 6, 'created': '2014-07-14 10:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6896ceba410db08f1ef1daf5593106a12ecef39c', 'message': 'Create an empty stack when creating the pipeline\n\nWhen Heat creates a stack it needs to create a trust,\nat the moment this can\'t be done in the context of a mistral task as\na trust token is passed into the task and creating a trust\nfrom a trust token is not currently allowed.\n\nThis patch is a workaround to create the Heat stack with\na ""normal"" user token. Then the mistral task will only\ndo a stack update, which can be done with a trust token.\n\nhttps://blueprints.launchpad.net/solum/+spec/pipeline\nChange-Id: I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e\n'}, {'number': 7, 'created': '2014-07-15 21:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/06f855d420409ca5aa269a87153c4b0d7db046e5', 'message': 'Create an empty stack when creating the pipeline\n\nWhen Heat creates a stack it needs to create a trust,\nat the moment this can\'t be done in the context of a mistral task as\na trust token is passed into the task and creating a trust\nfrom a trust token is not currently allowed.\n\nThis patch is a workaround to create the Heat stack with\na ""normal"" user token. Then the mistral task will only\ndo a stack update, which can be done with a trust token.\n\nhttps://blueprints.launchpad.net/solum/+spec/pipeline\nChange-Id: I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e\n'}, {'number': 8, 'created': '2014-07-16 10:52:16.000000000', 'files': ['solum/tests/api/handlers/test_pipeline.py', 'etc/solum/templates/empty.yaml', 'solum/api/handlers/pipeline_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/a7a018222c713c1ece348be6cb1cab45f26c10de', 'message': 'Create an empty stack when creating the pipeline\n\nWhen Heat creates a stack it needs to create a trust,\nat the moment this can\'t be done in the context of a mistral task as\na trust token is passed into the task and creating a trust\nfrom a trust token is not currently allowed.\n\nThis patch is a workaround to create the Heat stack with\na ""normal"" user token. Then the mistral task will only\ndo a stack update, which can be done with a trust token.\n\nhttps://blueprints.launchpad.net/solum/+spec/pipeline\nChange-Id: I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e\n'}]",6,104077,a7a018222c713c1ece348be6cb1cab45f26c10de,45,8,8,4715,,,0,"Create an empty stack when creating the pipeline

When Heat creates a stack it needs to create a trust,
at the moment this can't be done in the context of a mistral task as
a trust token is passed into the task and creating a trust
from a trust token is not currently allowed.

This patch is a workaround to create the Heat stack with
a ""normal"" user token. Then the mistral task will only
do a stack update, which can be done with a trust token.

https://blueprints.launchpad.net/solum/+spec/pipeline
Change-Id: I23ce79761e3ebcd46cfbef810330ff6b7c9bde4e
",git fetch https://review.opendev.org/openstack/solum refs/changes/77/104077/8 && git format-patch -1 --stdout FETCH_HEAD,"['solum/tests/api/handlers/test_pipeline.py', 'etc/solum/templates/empty.yaml', 'solum/api/handlers/pipeline_handler.py']",3,6410c2a4766d9e05bc890a546bcab4ced1b71b9e,new-api," ctx['stack_id'] = self._create_empty_stack(pipeline) def _create_empty_stack(self, pipeline): osc = clients.OpenStackClients(self.context) template = catalog.get('templates', 'empty') created_stack = osc.heat().stacks.create(stack_name=pipeline.name, template=template) return created_stack['stack']['id'] ",,12,0
openstack%2Fsolum~master~If4fb4258779c128df96826cd855ba09f63ad35bb,openstack/solum,master,If4fb4258779c128df96826cd855ba09f63ad35bb,Prevent excessive keystone client connections,MERGED,2014-07-14 10:41:05.000000000,2014-07-16 23:06:13.000000000,2014-07-16 23:06:13.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 6662}, {'_account_id': 8334}]","[{'number': 1, 'created': '2014-07-14 10:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b507486499dc5ee8bee21f306336fa272dc8394b', 'message': 'Prevent excessive keystone client connections\n\nTry and reuse the keystone client object by creating it in the\npipeline handler constructor.\n\nChange-Id: If4fb4258779c128df96826cd855ba09f63ad35bb\n'}, {'number': 2, 'created': '2014-07-16 10:52:16.000000000', 'files': ['solum/api/handlers/pipeline_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/b86e96cc8f8b8796f27a3a44c1da90566abbae8a', 'message': 'Prevent excessive keystone client connections\n\nTry and reuse the keystone client object by creating it in the\npipeline handler constructor.\n\nChange-Id: If4fb4258779c128df96826cd855ba09f63ad35bb\n'}]",2,106729,b86e96cc8f8b8796f27a3a44c1da90566abbae8a,18,6,2,4715,,,0,"Prevent excessive keystone client connections

Try and reuse the keystone client object by creating it in the
pipeline handler constructor.

Change-Id: If4fb4258779c128df96826cd855ba09f63ad35bb
",git fetch https://review.opendev.org/openstack/solum refs/changes/29/106729/2 && git format-patch -1 --stdout FETCH_HEAD,['solum/api/handlers/pipeline_handler.py'],1,b507486499dc5ee8bee21f306336fa272dc8394b,new-api," def __init__(self, context): super(PipelineHandler, self).__init__(context) self._clients = None if context is not None: self._clients = clients.OpenStackClients(self.context) self._clients = clients.OpenStackClients(cntx) return self._clients.keystone().context kc = self._clients.keystone() osc = self._clients self._clients.keystone().delete_trust(db_obj.trust_id) trust_context = self._clients.keystone().create_trust_context()",from solum.common import solum_keystoneclient kc = solum_keystoneclient.KeystoneClientV3(cntx) return kc.context kc = solum_keystoneclient.KeystoneClientV3(self.context) osc = clients.OpenStackClients(self.context) ksc = solum_keystoneclient.KeystoneClientV3(self.context) ksc.delete_trust(db_obj.trust_id) ksc = solum_keystoneclient.KeystoneClientV3(self.context) trust_context = ksc.create_trust_context(),12,9
openstack%2Fneutron-specs~master~I1aa1e147012f853d3c192de80505e6ce0d50b5c4,openstack/neutron-specs,master,I1aa1e147012f853d3c192de80505e6ce0d50b5c4,Add spec for retargetable functional testing,MERGED,2014-07-11 07:16:13.000000000,2014-07-16 23:01:53.000000000,2014-07-16 20:41:38.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2035}, {'_account_id': 6524}, {'_account_id': 7448}]","[{'number': 1, 'created': '2014-07-11 07:16:13.000000000', 'files': ['specs/juno/retargetable-functional-testing.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6c0ed15998e40b70a01e14804416893e04e1908d', 'message': 'Add spec for retargetable functional testing\n\nThis spec proposes the addition of support for retargetable\nfunctional testing.  Retargetable tests are intended to be written\nto an abstract client interface that can have multiple backends,\nallowing an API test to be written that can be run against the\nplugin API and a Neutron service with minimal extra effort.\n\nbp retargetable-functional-testing\n\nChange-Id: I1aa1e147012f853d3c192de80505e6ce0d50b5c4\n'}]",4,106290,6c0ed15998e40b70a01e14804416893e04e1908d,12,5,1,2035,,,0,"Add spec for retargetable functional testing

This spec proposes the addition of support for retargetable
functional testing.  Retargetable tests are intended to be written
to an abstract client interface that can have multiple backends,
allowing an API test to be written that can be run against the
plugin API and a Neutron service with minimal extra effort.

bp retargetable-functional-testing

Change-Id: I1aa1e147012f853d3c192de80505e6ce0d50b5c4
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/90/106290/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/retargetable-functional-testing.rst'],1,6c0ed15998e40b70a01e14804416893e04e1908d,bp/retargetable-functional-testing,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================================== Add support for retargetable functional testing =============================================== Launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/retargetable-functional-testing This blueprint describes the rational for adding support for retargetable functional testing to the Neutron test suite. Problem description =================== The current Neutron unit test suite contains a large number of tests that are actually functional. Such tests exercise almost the full application stack through the Neutron REST API regardless of whether that is the appropriate level of abstraction to be writing to. Writing to the incorrect level of abstraction in this manner can result in excessive test implementation, maintenance, and execution costs. There is also considerable duplication between the API-targeting tests in the Neutron tree and the Neutron API tests managed by the Tempest project. This results in a rough doubling of the cost of testing a given API with no increase in effectiveness. The fact that formal API testing is left to Tempest has the added cost of delaying some test additions until after a feature has been merged. Proposed change =============== The goal is to introduce the concept of a 'retargetable' functional api test. Such a test will target an abstract client class, and by varying the implementation of the client, the test can target multiple backends. One backend will be the programmatic plugin API, and another will be the Tempest REST client for the Neutron API, so that tests could be written and run directly against the plugin API (taking less time than the previous REST-targeting tests) , and then be configured to run against a live deployment with minimal effort. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Developers and reviewers will have to be educated as to this new strategy for implementing API tests. It will no longer be acceptable to accept API changes without corresponding test additions, and there will need to be a procedure to copy API tests into Tempest once a given API has stabilized or tests have been modified in a backwards-compatible way. Implementation ============== Assignee(s) ----------- Primary assignee: maru Work Items ---------- 1. Implement a framework for retargetable testing that proves the concept of writing tests to an abstraction that can support targeting both the plugin api and the tempest rest client. 2. Define a procedure for transfering responsibility for stablized API tests to Tempest. Dependencies ============ The testscenarios library, already listed in the openstack/requirements repo, will become a test dependency of Neutron as a result of this spec being implemented: https://pypi.python.org/pypi/testscenarios/ Testing ======= None Documentation Impact ==================== None References ========== Etherpad for summit session arguing for project-maintained API tests: https://etherpad.openstack.org/p/juno-qa-functional-api ",,159,0
openstack%2Fnova~master~I98c5b5bb5a8710d32fadafe9781736a963616fec,openstack/nova,master,I98c5b5bb5a8710d32fadafe9781736a963616fec,Remove redundant code in Libvirt driver,MERGED,2014-07-15 08:07:01.000000000,2014-07-16 22:59:39.000000000,2014-07-16 22:59:36.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 11650}]","[{'number': 1, 'created': '2014-07-15 08:07:01.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/907dfee882cc5d9e9d26ac430eaae9831dc80f58', 'message': 'Remove redundant code in Libvirt driver\n\nChange-Id: I98c5b5bb5a8710d32fadafe9781736a963616fec\nCo-Authored-By: Thomas Kaergel <kaergel@b1-systems.de>\n'}]",0,106955,907dfee882cc5d9e9d26ac430eaae9831dc80f58,21,10,1,167,,,0,"Remove redundant code in Libvirt driver

Change-Id: I98c5b5bb5a8710d32fadafe9781736a963616fec
Co-Authored-By: Thomas Kaergel <kaergel@b1-systems.de>
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/106955/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,907dfee882cc5d9e9d26ac430eaae9831dc80f58,remove_redundant_code_in_libvirt_driver," consolepty.type = ""pty"" guest.add_device(consolepty)"," consolepty.type = ""pty"" guest.add_device(consolepty) consolepty.type = ""pty"" guest.add_device(consolepty)",3,4
openstack%2Fpuppet-neutron~stable%2Fhavana~I2a6b79a48f011c84a8b73467c9bf813741f6e898,openstack/puppet-neutron,stable/havana,I2a6b79a48f011c84a8b73467c9bf813741f6e898,Introduce neutron:config to manage neutron configuration,MERGED,2014-06-02 16:07:26.000000000,2014-07-16 22:58:32.000000000,2014-07-16 22:58:31.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 2265}, {'_account_id': 7156}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-06-02 16:07:26.000000000', 'files': ['manifests/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/f33cef4f074daaaf37f7494e45a2017ab6e1a4c3', 'message': 'Introduce neutron:config to manage neutron configuration\n\nThis neutron::config is aim to use all types of neutron\nconfig resources to manage custom configurations in all\nneutron config files.\nThis will make end user easy to add their own custom options\nin Hiera data.\n\nFully implements blueprint neutron-custom-config\n\n(cherry-picked from e420021699f5fd0b5b13cbf8b070070ba8e03b9b)\nChange-Id: I2a6b79a48f011c84a8b73467c9bf813741f6e898\n'}]",0,97281,f33cef4f074daaaf37f7494e45a2017ab6e1a4c3,17,5,1,4128,,,0,"Introduce neutron:config to manage neutron configuration

This neutron::config is aim to use all types of neutron
config resources to manage custom configurations in all
neutron config files.
This will make end user easy to add their own custom options
in Hiera data.

Fully implements blueprint neutron-custom-config

(cherry-picked from e420021699f5fd0b5b13cbf8b070070ba8e03b9b)
Change-Id: I2a6b79a48f011c84a8b73467c9bf813741f6e898
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/81/97281/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/config.pp'],1,f33cef4f074daaaf37f7494e45a2017ab6e1a4c3,bp/neutron-custom-config,"# == Class: neutron::config # # This class is used to manage arbitrary Neutron configurations. # # === Parameters # # [*xxx_config*] # (optional) Allow configuration of arbitrary Neutron xxx specific configurations. # The value is an hash of neutron_config resources. Example: # server_config => # { 'DEFAULT/foo' => { value => 'fooValue'}, # 'DEFAULT/bar' => { value => 'barValue'} # } # # NOTE: { 'DEFAULT/foo': value => 'fooValue'; 'DEFAULT/bar': value => 'barValue'} is invalid. # # In yaml format, Example: # server_config: # DEFAULT/foo: # value: fooValue # DEFAULT/bar: # value: barValue # # [**server_config**] # (optional) Manage configuration of neutron.conf # # [**api_config**] # (optional) Manage configuration of api-paste.ini # # [**l3_agent_config**] # (optional) Manage configuration of l3_agent.ini # # [**dhcp_agent_config**] # (optional) Manage configuration of dhcp_agent.ini # # [**lbaas_agent_config**] # (optional) Manage configuration of lbaas_agent.ini # # [**metadata_agent_config**] # (optional) Manage configuration of metadata_agent.ini # # [**metering_agent_config**] # (optional) Manage configuration of metering_agent.ini # # [**vpnaas_agent_config**] # (optional) Manage configuration of vpn_agent.ini # # [**plugin_linuxbridge_config**] # (optional) Manage configuration of linuxbridge_conf.ini # # [**plugin_cisco_db_conn_config**] # (optional) Manage configuration of plugins/cisco/db_conn.ini # # [**plugin_cisco_config**] # (optional) Manage configuration of cisco_plugins.ini # # [**plugin_ml2_config**] # (optional) Manage configuration of ml2_conf.ini # # [**plugin_ovs_config**] # (optional) Manage configuration of ovs_neutron_plugin.ini # # NOTE: The configuration MUST NOT be already handled by this module # or Puppet catalog compilation will fail with duplicate resources. # class neutron::config ( $server_config = {}, $api_config = {}, $l3_agent_config = {}, $dhcp_agent_config = {}, $lbaas_agent_config = {}, $metadata_agent_config = {}, $metering_agent_config = {}, $vpnaas_agent_config = {}, $plugin_linuxbridge_config = {}, $plugin_cisco_db_conn_config = {}, $plugin_cisco_l2network_config = {}, $plugin_cisco_config = {}, $plugin_ml2_config = {}, $plugin_ovs_config = {}, ) { validate_hash($server_config) validate_hash($api_config) validate_hash($l3_agent_config) validate_hash($dhcp_agent_config) validate_hash($lbaas_agent_config) validate_hash($metadata_agent_config) validate_hash($metering_agent_config) validate_hash($vpnaas_agent_config) validate_hash($plugin_linuxbridge_config) validate_hash($plugin_cisco_db_conn_config) validate_hash($plugin_cisco_l2network_config) validate_hash($plugin_cisco_config) validate_hash($plugin_ml2_config) validate_hash($plugin_ovs_config) create_resources('neutron_config', $server_config) create_resources('neutron_api_config', $api_config) create_resources('neutron_l3_agent_config', $l3_agent_config) create_resources('neutron_dhcp_agent_config', $dhcp_agent_config) create_resources('neutron_metadata_agent_config', $metadata_agent_config) create_resources('neutron_metering_agent_config', $metering_agent_config) create_resources('neutron_vpnaas_agent_config', $vpnaas_agent_config) create_resources('neutron_plugin_linuxbridge', $plugin_linuxbridge_config) create_resources('neutron_plugin_cisco_db_conn', $plugin_cisco_db_conn_config) create_resources('neutron_plugin_cisco_l2network', $plugin_cisco_l2network_config) create_resources('neutron_plugin_cisco', $plugin_cisco_config) create_resources('neutron_plugin_ml2', $plugin_ml2_config) create_resources('neutron_plugin_ovs', $plugin_ovs_config) } ",,111,0
openstack%2Fneutron-specs~master~I7a05799a2f8e51438852267cd62d1030ae74ceab,openstack/neutron-specs,master,I7a05799a2f8e51438852267cd62d1030ae74ceab,Service group and service object for FWaaS blueprint fwaas-customized-service,MERGED,2014-05-19 05:46:17.000000000,2014-07-16 22:49:46.000000000,2014-07-16 22:49:45.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 2031}, {'_account_id': 6659}, {'_account_id': 6995}, {'_account_id': 7576}, {'_account_id': 7752}, {'_account_id': 8124}, {'_account_id': 9375}, {'_account_id': 10041}, {'_account_id': 11753}]","[{'number': 1, 'created': '2014-05-19 05:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2dde005ec2ada0d9a97c1472c57d263402cedf7c', 'message': 'Service group blueprint\nblueprint fwaas-customized-service\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 2, 'created': '2014-05-19 05:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/1beec6d11a57b414208601f8142d7cdd78b5eebd', 'message': 'Service group blueprint\nblueprint fwaas-customized-service\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 3, 'created': '2014-05-20 06:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/91b0646bd9aa104ff9a7b7931d26f555c62beb8b', 'message': 'Service group blueprint\nblueprint fwaas-customized-service\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 4, 'created': '2014-05-23 16:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6cb2723155a4e0a3420dfd5f63ee8fd7eeb24148', 'message': 'Service group blueprint\nblueprint fwaas-customized-service\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 5, 'created': '2014-05-23 17:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b2095e5e15c9a9120164996a80c03823b79be919', 'message': 'Service group blueprint\nblueprint fwaas-customized-service\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 6, 'created': '2014-06-01 05:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2a0d477710525d332c51acc07d8d1f03ef104586', 'message': 'Service group blueprint\nblueprint fwaas-customized-service\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 7, 'created': '2014-06-01 05:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b1bf3edeb2828fa03e6d31d81144e82161a441bc', 'message': 'Service group blueprint\nblueprint fwaas-customized-service\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 8, 'created': '2014-06-21 06:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d50a021bd11c8083665117d8d95e8f6a24eea51f', 'message': 'Service group blueprint\nblueprint fwaas-customized-service\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 9, 'created': '2014-07-02 21:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f746057d778cc1460a4c03ac3031cd6d8f6ebebf', 'message': 'Service group blueprint\nblueprint fwaas-customized-service\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 10, 'created': '2014-07-14 01:28:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ca0dcd93c90c192a795ba70dc8f1fc2fa7e800f9', 'message': 'Service group and service object for FWaaS\nblueprint fwaas-customized-service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 11, 'created': '2014-07-14 05:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/449bfe6e03bafe427e270e3b16bbe59d22f234b8', 'message': 'Service group and service object for FWaaS\nblueprint fwaas-customized-service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 12, 'created': '2014-07-14 06:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a0cc9d9a76967264ccd0a3f4b564832388c4638c', 'message': 'Service group and service object for FWaaS\nblueprint fwaas-customized-service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 13, 'created': '2014-07-14 22:07:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0d2a50dad6579a2bb827cdb1e45cbf4a72401fc0', 'message': 'Service group and service object for FWaaS\nblueprint fwaas-customized-service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}, {'number': 14, 'created': '2014-07-15 22:56:41.000000000', 'files': ['specs/juno/service-group.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/93b4356da54261d4a192956d0732388e6b02875d', 'message': 'Service group and service object for FWaaS\nblueprint fwaas-customized-service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\n\nChange-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab\n'}]",139,94133,93b4356da54261d4a192956d0732388e6b02875d,111,15,14,10041,,,0,"Service group and service object for FWaaS
blueprint fwaas-customized-service

In the traditional firewall design a service is used to define type of traffic
in firewall. This blueprint creates an extension that allows the firewall
administrators to create customized service objects. The customized service
objects can be grouped together to form a service group object. The policy
rule of FWaaS can reference more than one type of traffic by referencing to
service group objects.

Change-Id: I7a05799a2f8e51438852267cd62d1030ae74ceab
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/33/94133/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/service-group.rst'],1,2dde005ec2ada0d9a97c1472c57d263402cedf7c,bp/fwaas-customized-service,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================== Service group and Service Object support ======================================== Launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/fwaas-customized-service In the traditional firewall design a service is used to define type of traffic in firewall, This blueprint creates an extension that allows the firewall administrators to create customized service objects. The customized service objects can be grouped together to form a service group object. Problem description ======================= In FWaaS, admin can configure firewall rules with port range and protocol tuple. But we don't have a flexible way to allow user to specify more than one port and protocol tuples in the same rule. This makes the process of define rules unscalable. We are also missing the support to configure rule with icmp code and types. Proposed change ================== We propose to add a new extension with two resources. One is called service group and one is called service object. User can create a service group with a group of service objects that can be referenced from firewall rule. The service groups are allowed to be reused among different firewall rules in the same tenant. The service objects are allowed to be reused among service groups in the same tenant. Since the same objects can be useful for other features like security group or group policy. The service object and service group will be global resources. Alternatives ------------ None Data model impact ----------------- Service group: +-------------------+------------+-----------------+-----------+------+-------------------------+ | Attribute name | Type | Default Value | Required | CRUD | Description | +-------------------+------------+-----------------+-----------+------+-------------------------+ | id | uuid | generated | Y | R | | +-------------------+------------+-----------------+-----------+------+-------------------------+ | name | String | empty | N | CRU |Name of service group | +-------------------+------------+-----------------+-----------+------+-------------------------+ | description | String | empty | N | CRU | | +-------------------+------------+-----------------+-----------+------+-------------------------+ | tenant id | uuid | empty | Y | R |Id of tenant that creates| | | | | | |service group | +-------------------+------------+-----------------+-----------+------+-------------------------+ | service objects | list | empty list | N | CRU |List of service objects | +-------------------+------------+-----------------+-----------+------+-------------------------+ Service object: +-------------------+------------------------------------------+------+--------------------------+ | Attribute name | Type | Default Value | Required | CRUD |Description | +-------------------+------------+-----------------+-----------+------+--------------------------+ | id | uuid | generated | Y | R | | +-------------------+------------+-----------------+-----------+------+--------------------------+ | name | String | empty | N | CRU |Name of the service object| +-------------------+------------+-----------------+-----------+------+--------------------------+ | service group id | uuid | empty | N | CRU |Foregin key to service grp| +-------------------+------------+-----------------+-----------+------+--------------------------+ | protocol | string | empty | Y | CRU |'tcp','udp','icmp','any' | | | | | | | or protocol id (0-255) | +-------------------+------------+-----------------+-----------+------+--------------------------+ | source_port_min | short | empty | N | CRU | | +-------------------+------------+-----------------+-----------+------+--------------------------+ | source_port_max | short | empty | N | CRU | | +-------------------+------------+-----------------+-----------+------+--------------------------+ | dest_port_min | short | empty | N | CRU | | +-------------------+------------+-----------------+-----------+------+--------------------------+ | dest_port_max | short | empty | N | CRU | | +-------------------+------------+-----------------+-----------+------+--------------------------+ | icmp_code | char | empty | N | CRU | | +-------------------+------------+-----------------+-----------+------+--------------------------+ | icmp_type | char | empty | N | CRU | | +-------------------+------------+-----------------+-----------+------+--------------------------+ | timeout | short | empty | N | CRU | | +-------------------+------------+-----------------+-----------+------+--------------------------+ | tenant_id | uuid | empty | Y | R | | +-------------------+------------+-----------------+-----------+------+--------------------------+ New CLIs: service-group-create service-group-delete service-group-list service-group-show service-group-update service-object-create service-object-delete service-object-list service-object-show REST API impact --------------- The new resources: .. code-block:: python RESOURCE_ATTRIBUTE_MAP = { 'service_groups': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': '', 'validate': {'type:name_not_default': None}}, 'description': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'required_by_policy': True, 'is_visible': True}, 'service_objects': {'allow_post': False, 'allow_put': False, 'convert_to': attr.convert_none_to_empty_list, 'is_visible': True}, } 'service_objects': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': '', 'validate': {'type:name_not_default': None}}, 'service_group_id': {'allow_post': True, 'allow_put': False, 'is_visible': True, 'required_by_policy': True}, 'protocol': {'allow_post': True, 'allow_put': False, 'is_visible': True, 'default': None, 'convert_to': _convert_protocol}, 'source_port': {'allow_post': True, 'allow_put': False, 'validate': {'type:service_port_range': None}, 'convert_to': _convert_port_to_string, 'default': None, 'is_visible': True}, 'destination_port': {'allow_post': True, 'allow_put': False, 'validate': {'type:service_port_range': None}, 'convert_to': _convert_port_to_string, 'default': None, 'is_visible': True}, 'icmp_code': {'allow_post': True, 'allow_put': False, 'validate': {'type:icmp_code': None}, 'convert_to': _convert_icmp_code, 'default': None, 'is_visible': True}, 'icmp_type': {'allow_post': True, 'allow_put': False, 'validate': {'type:icmp_type': None}, 'convert_to': _convert_icmp_type, 'default': None, 'is_visible': True}, 'timeout': {'allow_post': True, 'allow_put': False, 'validate': {'type:range': [0, 65535]}, 'convert_to': attr.convert_to_int, 'default': 0, 'is_visible': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'required_by_policy': True, 'is_visible': True}, } } +---------------+----------------------------+----------------------+ |Object |URI |Type | +---------------+----------------------------+----------------------+ |service group |/service-groups |GET | +---------------+----------------------------+----------------------+ |service group |/service-groups |POST | +---------------+----------------------------+----------------------+ |service group |/service-groups/{id} |GET | +---------------+----------------------------+----------------------+ |service group |/service-groups/{id} |PUT | +---------------+----------------------------+----------------------+ |service group |/service-group/s{id} |DELETE | +---------------+----------------------------+----------------------+ |service object |/service-objects |GET | +---------------+----------------------------+----------------------+ |service object |/service-objects |POST | +---------------+----------------------------+----------------------+ |service object |/service-objects/{id} |GET | +---------------+----------------------------+----------------------+ |service object |/service-objects/{id} |PUT | +---------------+----------------------------+----------------------+ |service object |/service-objects/{id} |DELETE | +---------------+----------------------------+----------------------+ Security impact --------------- * Does this change touch sensitive data such as tokens, keys, or user data? No * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? No * Does this change involve cryptography or hashing? No * Does this change require the use of sudo or any elevated privileges? No * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. Yes * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Yi Sun beyounn@gmail.com Work Items ------------ * API and database * python-neutronclient Dependencies ============ None Testing ======= Both unit test and tempest test will be required Documentation Impact ==================== Documentation for both administrators and end users will have to be contemplated. Administrators will need to know how to configure the service group by using the service group API and python-neutronclient. References ========== None ",,286,0
openstack%2Fneutron-specs~master~Ifbf839d442d658ad74c14fdfde3dd685f9bc9775,openstack/neutron-specs,master,Ifbf839d442d658ad74c14fdfde3dd685f9bc9775,Add spec for removal of autodeletion in tests,MERGED,2014-07-11 05:55:15.000000000,2014-07-16 22:34:38.000000000,2014-07-16 22:34:38.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 7448}, {'_account_id': 7787}]","[{'number': 1, 'created': '2014-07-11 05:55:15.000000000', 'files': ['specs/juno/remove-unit-test-autodeletion.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d1066ef07e2fc66bd9a2c244cd7c466f689ee6ac', 'message': 'Add spec for removal of autodeletion in tests\n\nThis spec proposes the removal of autodeletion of Neutron resources\nin the unit test suite.\n\nbp remove-unit-test-autodeletion\n\nChange-Id: Ifbf839d442d658ad74c14fdfde3dd685f9bc9775\n'}]",4,106277,d1066ef07e2fc66bd9a2c244cd7c466f689ee6ac,12,7,1,2035,,,0,"Add spec for removal of autodeletion in tests

This spec proposes the removal of autodeletion of Neutron resources
in the unit test suite.

bp remove-unit-test-autodeletion

Change-Id: Ifbf839d442d658ad74c14fdfde3dd685f9bc9775
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/77/106277/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/remove-unit-test-autodeletion.rst'],1,d1066ef07e2fc66bd9a2c244cd7c466f689ee6ac,bp/remove-unit-test-autodeletion,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================================================== Remove the use of resource autodeletion in unit tests ===================================================== Launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/remove-unit-test-autodeletion This blueprint describes the rational for removing resource autodeletion in the unit tests. Problem description =================== The Neutron unit tests currently decorate resource creation methods with contextlib.contextmanager to allow resources to be automatically deleted when they are no longer needed. This strategy is a legacy of a time when this explicit cleanup was required to ensure isolation between tests, but is now unnecessary since db state is automatically thrown away after each test. The strategy has the following negative impacts on much of Neutron's unit test suite: - an execution penalty, since deletion of every created resource is always done and is performed through the wsgi layer - a debugging penalty, since contextmanagers are generators with the consequent loss of stack context - a readability penalty, since the test code is riddled with unnecessary 'with' blocks around resource creation - a coverage penalty, since implicit deletion testing is likely to hide gaps in testing of resource deletion Proposed change =============== Resource creation methods should be modified to not perform autodeletion, as follows: - remove the contextlib.contextmanager decorator - change 'yield' statements to 'return' - remove the do_delete or no_delete parameter - remove the conditional block that deletes the resource(s) In addition, all clients of the resource creation methods should be updated to no longer pass a do_delete/no_delete parameter and perform a regular call (e.g. create_resource()) rather than creating a with block (e.g. with create_resource():). It also may make sense to update the names of resource creation methods, since they are often of the form 'resourcename' rather than 'create_resourcename'. Care will have to be taken to ensure that explicit tests for deletion are added if they do not already exist for a given resource type. Autodeletion ensured that any resource whose creation was tested also had its deletion validated to some extent, but this validation will have to be explicit from now on. This is arguably desirable, since relying on the 'magic' of autodeletion to provide test coverage can potentially lull developers into a false sense of security. There may also be tests that create multiple resources in a way that depended on autodeltion to prevent uniqueness constraint violation. It will be necessary to perform explicit deletion in those cases where removal of autodeletion provokes test failures. Alternatives ------------ The alternative to not removing autodeletion is continuing to live with the penalties it imposes. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Removal of autodeletion should have a positive impact on the execution time of the unit test suite. Other deployer impact --------------------- None Developer impact ---------------- Developers and reviewers familiar with the current contextmanager-based model of resource creation in unit tests will have to be educated as to the move to simpler creation methods and the need for explicit testing of deletion. Once concern voiced at the removal of the contextmanager decorator was that it would disallow the convenience of managing the lifecycle of multiple resources via contextlib.nested. If necessary, this capability can be replicated by creating a helper method that accepts a list of creation functions and ensures that the resources created are cleaned up. Implementation ============== Assignee(s) ----------- Primary assignee: kevinbenton Other contributors: marun Work Items ---------- 1. Add explicit tests for deletion for resource types that have previously relied on autodeletion to perform implicit testing of deletion. 2. Disable autodeletion in each resource creation method (e.g. NeutronDbPluginV2TestCase.network) in the unit test suite and fix any test failures that result. 3. Remove support for autodeletion (parameters, deletion calls) from the resource creation methods and update their callers. 4. Remove the contextmanager decorator from resource creation methods, rename the creation methods (e.g. network -> create_network), and update their clients. Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== None ",,189,0
openstack%2Fpython-cinderclient~master~Ib4a44334001b7b9e3b896c2e44607c414e75e952,openstack/python-cinderclient,master,Ib4a44334001b7b9e3b896c2e44607c414e75e952,Add set-bootable command,MERGED,2014-03-28 08:49:39.000000000,2014-07-16 22:30:29.000000000,2014-07-16 22:30:28.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 7121}]","[{'number': 1, 'created': '2014-03-28 08:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/0cd05a75033016eea9b46fc80751fc5d71929cdc', 'message': 'Add bootable option to cinder create command for users who create a bootable volume manually.\n\nblueprint add-bootable-option\n\nChange-Id: Ib4a44334001b7b9e3b896c2e44607c414e75e952\n'}, {'number': 2, 'created': '2014-03-31 05:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/2adea52f06b0ab32916c0cdde2c528b6af9b0d60', 'message': 'Add set-bootable command for users who create a bootable volume manually.\n\nblueprint add-bootable-option\n\nthis commit is related to https://blueprints.launchpad.net/cinder/+spec/add-bootable-option\n\nChange-Id: Ib4a44334001b7b9e3b896c2e44607c414e75e952\n'}, {'number': 3, 'created': '2014-03-31 07:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/098d67c5f3c40ddb5bd1186767bf74a07bc9f04b', 'message': 'Add set-bootable command.\n\nblueprint add-bootable-option\n\nthis commit is related to https://review.openstack.org/#/c/84057/\n\nChange-Id: Ib4a44334001b7b9e3b896c2e44607c414e75e952\n'}, {'number': 4, 'created': '2014-04-01 05:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/0ae437f79a781b9c022292e834aeda0e110c77b5', 'message': 'Add set-bootable command\n\nBootable Status is set to ""True"" automatically when user create a volume from a image.\n\nBut user have to set bootable status manually when creating a bootable volume manually.\n\nblueprint add-bootable-option\n\nthis commit is related to https://review.openstack.org/#/c/84057/\n\nChange-Id: Ib4a44334001b7b9e3b896c2e44607c414e75e952\n'}, {'number': 5, 'created': '2014-04-02 00:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/689775a33e4353b95565c6c5cee0c7761d49fb96', 'message': 'Add set-bootable command\n\nBootable Status is set to ""True"" automatically when user create a volume from image.\n\nBut user have to set bootable status manually when creating a bootable volume manually.\n\nblueprint add-bootable-option\n\nthis commit is related to https://review.openstack.org/#/c/84057/\n\nChange-Id: Ib4a44334001b7b9e3b896c2e44607c414e75e952\n'}, {'number': 6, 'created': '2014-04-02 00:51:29.000000000', 'files': ['cinderclient/tests/v2/test_volumes.py', 'cinderclient/tests/v2/fakes.py', 'cinderclient/tests/v1/test_volumes.py', 'cinderclient/v2/volumes.py', 'cinderclient/v1/shell.py', 'cinderclient/v1/volumes.py', 'cinderclient/tests/v1/fakes.py', 'cinderclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/c364372477f7b9f6ddc53c9c13d08f8e459ff74e', 'message': 'Add set-bootable command\n\nBootable Status is set to ""True"" automatically when user\ncreate a volume from a image. But user have to set bootable\nstatus manually when creating a bootable volume manually.\n\nblueprint add-bootable-option\n\nthis commit is related to https://review.openstack.org/#/c/84057/\n\nChange-Id: Ib4a44334001b7b9e3b896c2e44607c414e75e952\n'}]",1,83691,c364372477f7b9f6ddc53c9c13d08f8e459ff74e,43,4,6,7121,,,0,"Add set-bootable command

Bootable Status is set to ""True"" automatically when user
create a volume from a image. But user have to set bootable
status manually when creating a bootable volume manually.

blueprint add-bootable-option

this commit is related to https://review.openstack.org/#/c/84057/

Change-Id: Ib4a44334001b7b9e3b896c2e44607c414e75e952
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/91/83691/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/v1/shell.py', 'cinderclient/v1/volumes.py', 'cinderclient/v2/volumes.py', 'cinderclient/v2/shell.py']",4,0cd05a75033016eea9b46fc80751fc5d71929cdc,bp/add-bootable-option,"@utils.arg('--bootable', metavar='<True|true|False|false>', choices=['True', 'true', 'False', 'false'], help='Optional flag to indicate whether ' 'to create a bootable volume' '(Default=False)') args.bootable,",,27,2
openstack%2Fcinder~master~I3eebb245e9e41b92c9ec82ebbd2dd6b417704819,openstack/cinder,master,I3eebb245e9e41b92c9ec82ebbd2dd6b417704819,Remove definition of Python Source Code Encodings,MERGED,2014-07-09 08:06:47.000000000,2014-07-16 22:29:57.000000000,2014-07-16 22:29:56.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2243}, {'_account_id': 7219}, {'_account_id': 9533}, {'_account_id': 10628}, {'_account_id': 12017}]","[{'number': 1, 'created': '2014-07-09 08:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/abb29f8a7d4c506ce2731b6b695aead5766faace', 'message': 'Remove definition of Python Source Code Encodings\n\nThe definition of Python Source Code Encodings is no longer needed.\nThis patch remove those.\n\nChange-Id: I3eebb245e9e41b92c9ec82ebbd2dd6b417704819\n'}, {'number': 2, 'created': '2014-07-10 08:36:04.000000000', 'files': ['doc/source/conf.py', 'doc/ext/cinder_todo.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/11c268bd692e654a968281cb162b953dcd300da5', 'message': 'Remove definition of Python Source Code Encodings\n\nThe definition of Python Source Code Encodings is no longer needed.\nThis patch remove those.\n\nChange-Id: I3eebb245e9e41b92c9ec82ebbd2dd6b417704819\n'}]",0,105668,11c268bd692e654a968281cb162b953dcd300da5,19,7,2,9533,,,0,"Remove definition of Python Source Code Encodings

The definition of Python Source Code Encodings is no longer needed.
This patch remove those.

Change-Id: I3eebb245e9e41b92c9ec82ebbd2dd6b417704819
",git fetch https://review.opendev.org/openstack/cinder refs/changes/68/105668/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'doc/ext/cinder_todo.py', 'cinder/openstack/common/db/sqlalchemy/migration.py']",3,abb29f8a7d4c506ce2731b6b695aead5766faace,RemoveCodingUTF-8,,# coding: utf-8 #,0,5
openstack%2Fneutron~master~I39afe86c66f864d71adf865d7bd1c9db35511505,openstack/neutron,master,I39afe86c66f864d71adf865d7bd1c9db35511505,L3 agent prefers RPC messages over full sync,MERGED,2014-03-07 00:09:50.000000000,2014-07-16 22:18:21.000000000,2014-07-15 21:03:20.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 1038}, {'_account_id': 1131}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5209}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8655}, {'_account_id': 8873}, {'_account_id': 8950}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-03-07 00:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3cee457570e8f9fcfef300b51ea8858c317a23a', 'message': ""L3 agent gives preference to processing RPC messages over full sync (WIP)\n\nPlease provide feedback on this approach to solving the bug before I\ncommit too much more work on it.\n\nThis is a preview.  It is far from complete.  Here, I propose\ncombining the work from _rpc_loop and _sync_routers_task in to a\nsingle loop that I call _process_routers_loop.  This loop has worker\nthreads that pull from a priority queue.  The queue ensures that RPC\nmessages are handled before maintenance tasks.\n\nWith multiple worker threads, I needed to handled the case where an\nRPC message came in while a thread was working on a router.  We don't\nwant another thread to handle the same router.  Instead, I add a\nmechanism to single to the working thread that an update came in for\nthe router it is working on.\n\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 2, 'created': '2014-03-18 00:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/253193dc5f0dca9e427f2e931afa0e92f9d00980', 'message': ""L3 agent gives preference to processing RPC messages over full sync (WIP)\n\nThis is a checkpoint that I want to get up for feedback.  There is\nmore work to do.\n\nHere, I propose combining the work from _rpc_loop and\n_sync_routers_task in to a single loop that I call\n_process_routers_loop.  This loop has worker threads that pull from a\npriority queue.  The queue ensures that RPC messages are handled\nbefore maintenance tasks.\n\nWith multiple worker threads, I needed to handled the case where an\nRPC message came in while a thread was working on a router.  We don't\nwant another thread to handle the same router.  I add a mechanism to\nsingle to the working thread that an update came in for the router it\nis working on.\n\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 5, 'created': '2014-03-23 05:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3cd74b989055e0082196d2c591eea266bd78332', 'message': ""L3 agent prefers RPC messages over full sync\n\nCombine the work from _rpc_loop and _sync_routers_task in to a single loop\ncalled _process_routers_loop.  This loop spawns threads that pull from a\npriority queue.  The queue ensures that RPC messages are handled before\n_process_routers_loop.  The latter is generally maintenance tasks\ntriggered by the agent rather than user triggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of then need for synchronization between loops\nis probably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 4, 'created': '2014-03-23 05:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2617db8738dd560a5a60f476c4ca522dfbe40e41', 'message': ""L3 agent prefers RPC messages over full sync\n\nCombine the work from _rpc_loop and _sync_routers_task in to a single loop\ncalled _process_routers_loop.  This loop spawns threads that pull from a\npriority queue.  The queue ensures that RPC messages are handled before\n_process_routers_loop.  The latter is generally maintenance tasks\ntriggered by the agent rather than user triggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of then need for synchronization between loops\nis probably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 3, 'created': '2014-03-23 05:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb5d68933f0d8df215a87e1cca3e3b9a0a2e7a6b', 'message': ""L3 agent prefers RPC messages over full sync\n\nCombine the work from _rpc_loop and _sync_routers_task in to a single loop\ncalled _process_routers_loop.  This loop spawns threads that pull from a\npriority queue.  The queue ensures that RPC messages are handled before\n_process_routers_loop.  The latter is generally maintenance tasks\ntriggered by the agent rather than user triggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of then need for synchronization between loops\nis probably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 6, 'created': '2014-04-08 18:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6fb83ebc434535db087818ffe255502ee0dc6644', 'message': ""L3 agent prefers RPC messages over full sync\n\nCombine the work from _rpc_loop and _sync_routers_task in to a single loop\ncalled _process_routers_loop.  This loop spawns threads that pull from a\npriority queue.  The queue ensures that RPC messages are handled before\n_process_routers_loop.  The latter is generally maintenance tasks\ntriggered by the agent rather than user triggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of then need for synchronization between loops\nis probably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 7, 'created': '2014-04-15 18:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd581ad5222f2b56273ff410a8e4c9c52afc7273', 'message': ""L3 agent prefers RPC messages over full sync\n\nCombine the work from _rpc_loop and _sync_routers_task in to a single loop\ncalled _process_routers_loop.  This loop spawns threads that pull from a\npriority queue.  The queue ensures that RPC messages are handled before\n_process_routers_loop.  The latter is generally maintenance tasks\ntriggered by the agent rather than user triggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of then need for synchronization between loops\nis probably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 8, 'created': '2014-04-15 18:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc445786b363df5b9f2672cfd105d7e1308fea26', 'message': ""L3 agent prefers RPC messages over full sync\n\nCombine the work from _rpc_loop and _sync_routers_task in to a single loop\ncalled _process_routers_loop.  This loop spawns threads that pull from a\npriority queue.  The queue ensures that RPC messages are handled before\n_process_routers_loop.  The latter is generally maintenance tasks\ntriggered by the agent rather than user triggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of then need for synchronization between loops\nis probably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 9, 'created': '2014-04-25 18:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c74cb3a5b5c92d06d4d9c2b882c86c65c7f86cd', 'message': ""L3 agent prefers RPC messages over full sync\n\nWhen the L3 agent starts up and runs the sync task it doesn't process\nany incoming RPC events until the sync task is complete.\n\nThis change combines the work from _rpc_loop and _sync_routers_task in\nto a single loop called _process_routers_loop.  This loop spawns\nthreads that pull from a priority queue.  The queue ensures that RPC\nmessages are handled before _process_routers_loop.  The latter is\ngenerally maintenance tasks triggered by the agent rather than user\ntriggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of the need for synchronization between loops is\nprobably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 10, 'created': '2014-04-29 16:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d9f7c7f5e477a27db086425f2fe34f9baf27a2ed', 'message': ""L3 agent prefers RPC messages over full sync\n\nWhen the L3 agent starts up and runs the sync task it doesn't process\nany incoming RPC events until the sync task is complete.\n\nThis change combines the work from _rpc_loop and _sync_routers_task in\nto a single loop called _process_routers_loop.  This loop spawns\nthreads that pull from a priority queue.  The queue ensures that RPC\nmessages are handled before _process_routers_loop.  The latter is\ngenerally maintenance tasks triggered by the agent rather than user\ntriggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of the need for synchronization between loops is\nprobably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 11, 'created': '2014-05-23 21:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d0e4fdc54764a6147de690bf2789186e23cbaa5', 'message': ""L3 agent prefers RPC messages over full sync\n\nWhen the L3 agent starts up and runs the sync task it doesn't process\nany incoming RPC events until the sync task is complete.\n\nThis change combines the work from _rpc_loop and _sync_routers_task in\nto a single loop called _process_routers_loop.  This loop spawns\nthreads that pull from a priority queue.  The queue ensures that RPC\nmessages are handled before _process_routers_loop.  The latter is\ngenerally maintenance tasks triggered by the agent rather than user\ntriggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of the need for synchronization between loops is\nprobably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nblueprint l3-agent-responsiveness\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 12, 'created': '2014-05-23 21:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48c4e7f19e0728811b3a7a9667d6101c1fc273c8', 'message': ""L3 agent prefers RPC messages over full sync\n\nWhen the L3 agent starts up and runs the sync task it doesn't process\nany incoming RPC events until the sync task is complete.\n\nThis change combines the work from _rpc_loop and _sync_routers_task in\nto a single loop called _process_routers_loop.  This loop spawns\nthreads that pull from a priority queue.  The queue ensures that RPC\nmessages are handled before _process_routers_loop.  The latter is\ngenerally maintenance tasks triggered by the agent rather than user\ntriggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of the need for synchronization between loops is\nprobably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nblueprint l3-agent-responsiveness\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 13, 'created': '2014-05-24 18:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8b7e0d683d4784699af7673c2bb7cda9384c243a', 'message': ""L3 agent prefers RPC messages over full sync\n\nWhen the L3 agent starts up and runs the sync task it doesn't process\nany incoming RPC events until the sync task is complete.\n\nThis change combines the work from _rpc_loop and _sync_routers_task in\nto a single loop called _process_routers_loop.  This loop spawns\nthreads that pull from a priority queue.  The queue ensures that RPC\nmessages are handled before _process_routers_loop.  The latter is\ngenerally maintenance tasks triggered by the agent rather than user\ntriggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of the need for synchronization between loops is\nprobably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nblueprint l3-agent-responsiveness\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 14, 'created': '2014-07-14 17:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/df453e4b14ae12f1b6a9cfd364279243b8b0115f', 'message': ""L3 agent prefers RPC messages over full sync\n\nWhen the L3 agent starts up and runs the sync task it doesn't process\nany incoming RPC events until the sync task is complete.\n\nThis change combines the work from _rpc_loop and _sync_routers_task in\nto a single loop called _process_routers_loop.  This loop spawns\nthreads that pull from a priority queue.  The queue ensures that RPC\nmessages are handled before _process_routers_loop.  The latter is\ngenerally maintenance tasks triggered by the agent rather than user\ntriggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of the need for synchronization between loops is\nprobably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nblueprint l3-agent-responsiveness\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 15, 'created': '2014-07-14 19:33:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a5017bb64b29b70db73c41e2fb724a0009f47fc', 'message': ""L3 agent prefers RPC messages over full sync\n\nWhen the L3 agent starts up and runs the sync task it doesn't process\nany incoming RPC events until the sync task is complete.\n\nThis change combines the work from _rpc_loop and _sync_routers_task in\nto a single loop called _process_routers_loop.  This loop spawns\nthreads that pull from a priority queue.  The queue ensures that RPC\nmessages are handled before _process_routers_loop.  The latter is\ngenerally maintenance tasks triggered by the agent rather than user\ntriggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of the need for synchronization between loops is\nprobably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nblueprint l3-agent-responsiveness\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}, {'number': 16, 'created': '2014-07-15 15:38:35.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fe2ca9a75878a445a54ecfe4a97c79b696abf503', 'message': ""L3 agent prefers RPC messages over full sync\n\nWhen the L3 agent starts up and runs the sync task it doesn't process\nany incoming RPC events until the sync task is complete.\n\nThis change combines the work from _rpc_loop and _sync_routers_task in\nto a single loop called _process_routers_loop.  This loop spawns\nthreads that pull from a priority queue.  The queue ensures that RPC\nmessages are handled before _process_routers_loop.  The latter is\ngenerally maintenance tasks triggered by the agent rather than user\ntriggered tasks.\n\nSynchronization between RPC and sync routers loops is no longer\nnecessary since they both feed in to a single queue.  There were\nplaces where it was necessary to reorder some things to allow for the\nlack of synchronization.  For example, it is necessary to list\nnamespaces before fetching the full list of routers to ensure that it\ndoesn't delete a new namespace that gets created after listing\nnamespaces.  The lack of the need for synchronization between loops is\nprobably the main strength of this patch.\n\nWith multiple worker threads, need to handle the case where an RPC\nmessage came in while a thread was working on a router.  Another\nthread should not handle the same router that is already in progress.\nAdds a mechanism to signal to the working thread that an update came\nin for the router it is working on.  The original thread will repeat\nprocessing the router when it is finished to get the update.\nMultiple rapid updates to the same router will be consolidated.\nEssentially, there is still synchronization of work for a given router\nbut not between routers.  Much better than before.\n\nblueprint l3-agent-responsiveness\nCloses-Bug: #1289066\nChange-Id: I39afe86c66f864d71adf865d7bd1c9db35511505\n""}]",35,78819,fe2ca9a75878a445a54ecfe4a97c79b696abf503,288,31,16,7448,,,0,"L3 agent prefers RPC messages over full sync

When the L3 agent starts up and runs the sync task it doesn't process
any incoming RPC events until the sync task is complete.

This change combines the work from _rpc_loop and _sync_routers_task in
to a single loop called _process_routers_loop.  This loop spawns
threads that pull from a priority queue.  The queue ensures that RPC
messages are handled before _process_routers_loop.  The latter is
generally maintenance tasks triggered by the agent rather than user
triggered tasks.

Synchronization between RPC and sync routers loops is no longer
necessary since they both feed in to a single queue.  There were
places where it was necessary to reorder some things to allow for the
lack of synchronization.  For example, it is necessary to list
namespaces before fetching the full list of routers to ensure that it
doesn't delete a new namespace that gets created after listing
namespaces.  The lack of the need for synchronization between loops is
probably the main strength of this patch.

With multiple worker threads, need to handle the case where an RPC
message came in while a thread was working on a router.  Another
thread should not handle the same router that is already in progress.
Adds a mechanism to signal to the working thread that an update came
in for the router it is working on.  The original thread will repeat
processing the router when it is finished to get the update.
Multiple rapid updates to the same router will be consolidated.
Essentially, there is still synchronization of work for a given router
but not between routers.  Much better than before.

blueprint l3-agent-responsiveness
Closes-Bug: #1289066
Change-Id: I39afe86c66f864d71adf865d7bd1c9db35511505
",git fetch https://review.opendev.org/openstack/neutron refs/changes/19/78819/16 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/openstack/common/timeutils.py']",3,b3cee457570e8f9fcfef300b51ea8858c317a23a,l3-prioritize-process-routers,DATETIME_MIN = datetime.datetime.min,,93,0
openstack%2Ftripleo-image-elements~master~I368d273089c8aa3b2647e79b821c124b11342fba,openstack/tripleo-image-elements,master,I368d273089c8aa3b2647e79b821c124b11342fba,"Revert ""Move libvirt's qemu configuration dir to state fs""",MERGED,2014-07-16 00:19:06.000000000,2014-07-16 22:12:48.000000000,2014-07-16 14:38:59.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1420}, {'_account_id': 6928}, {'_account_id': 9369}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-07-16 00:19:06.000000000', 'files': ['elements/nova-kvm/install.d/81-nova-kvm'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/042e96b5d889607a2d24b68376a4e147881f72be', 'message': 'Revert ""Move libvirt\'s qemu configuration dir to state fs""\n\nThis reverts commit 455e35e8fc845449cf8fd9b03afd804651612173.\n\nIt breaks with \n+ register-state-path --leave-symlink /etc/libvirt/qemu\n/tmp/in_target.d/install.d/81-nova-kvm: line 10: register-state-path: command not found\n\nChange-Id: I368d273089c8aa3b2647e79b821c124b11342fba\n'}]",0,107209,042e96b5d889607a2d24b68376a4e147881f72be,15,6,1,4190,,,0,"Revert ""Move libvirt's qemu configuration dir to state fs""

This reverts commit 455e35e8fc845449cf8fd9b03afd804651612173.

It breaks with 
+ register-state-path --leave-symlink /etc/libvirt/qemu
/tmp/in_target.d/install.d/81-nova-kvm: line 10: register-state-path: command not found

Change-Id: I368d273089c8aa3b2647e79b821c124b11342fba
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/09/107209/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/nova-kvm/install.d/81-nova-kvm'],1,042e96b5d889607a2d24b68376a4e147881f72be,libvirt_stateful,,register-state-path --leave-symlink /etc/libvirt/qemu ,0,2
openstack%2Fmonasca-notification~master~I1f2fc4d0ad6375f4c39446f9627247945066e4ad,openstack/monasca-notification,master,I1f2fc4d0ad6375f4c39446f9627247945066e4ad,"Rename to monasca, setup for tox, removed legacy bits",MERGED,2014-07-16 20:54:03.000000000,2014-07-16 22:09:43.000000000,2014-07-16 22:09:43.000000000,"[{'_account_id': 3}, {'_account_id': 2419}]","[{'number': 1, 'created': '2014-07-16 20:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/06051457f177d1c6878ac49b2d83e63d526c7701', 'message': 'Rename to monasca, setup for tox, removed legacy bits\n\nRemoved manual tests which are no longer valid with a modern mini-mon\nRemoved debian creation bits all distribution is with pypi now\n\nChange-Id: I1f2fc4d0ad6375f4c39446f9627247945066e4ad\n'}, {'number': 2, 'created': '2014-07-16 20:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/41caccc81ca1af3e82f9d30c2ad79c9262933886', 'message': 'Rename to monasca, setup for tox, removed legacy bits\n\nRemoved manual tests which are no longer valid with a modern mini-mon\nRemoved debian creation bits all distribution is with pypi now\n\nChange-Id: I1f2fc4d0ad6375f4c39446f9627247945066e4ad\n'}, {'number': 3, 'created': '2014-07-16 21:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/d0befecfb5743b714a983996157e95d2f80c4582', 'message': 'Rename to monasca, setup for tox, removed legacy bits\n\nRemoved manual tests which are no longer valid with a modern mini-mon\nRemoved debian creation bits all distribution is with pypi now\n\nChange-Id: I1f2fc4d0ad6375f4c39446f9627247945066e4ad\n'}, {'number': 4, 'created': '2014-07-16 21:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/7b36a30b06a733b5afa5061143522837d71a37f9', 'message': 'Rename to monasca, setup for tox, removed legacy bits\n\nRemoved manual tests which are no longer valid with a modern mini-mon\nRemoved debian creation bits all distribution is with pypi now\n\nChange-Id: I1f2fc4d0ad6375f4c39446f9627247945066e4ad\n'}, {'number': 5, 'created': '2014-07-16 21:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/87656e0b9746507bf8c7c52f3b272b201f6f7d44', 'message': 'Rename to monasca, setup for tox, removed legacy bits\n\nRemoved manual tests which are no longer valid with a modern mini-mon\nRemoved debian creation bits all distribution is with pypi now\n\nChange-Id: I1f2fc4d0ad6375f4c39446f9627247945066e4ad\n'}, {'number': 6, 'created': '2014-07-16 21:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/a8ed899f35712ad144e342191a2b545481bf197b', 'message': 'Rename to monasca, setup for tox, removed legacy bits\n\nRemoved manual tests which are no longer valid with a modern mini-mon\nRemoved debian creation bits all distribution is with pypi now\nMinor pep8 fixes\n\nChange-Id: I1f2fc4d0ad6375f4c39446f9627247945066e4ad\n'}, {'number': 7, 'created': '2014-07-16 21:59:03.000000000', 'files': ['monasca_notification/processors/notification_processor.py', 'tests/manual/README.md', '.gitignore', 'monasca_notification/processors/__init__.py', '.gitreview', 'debian/changelog', 'monasca_notification/__init__.py', 'monasca_notification/notification_exceptions.py', 'monasca_notification/state_tracker.py', 'test-requirements.txt', 'tests/test_alarm_processor.py', 'tests/manual/invalid.json', 'setup.py', 'tools/monasca_notification_offsets.py', 'notification.yaml', 'tests/test_notification_processor.py', 'monasca_notification/processors/sent_notification_processor.py', 'tests/manual/sample_notifications.sql', 'monasca_notification/processors/alarm_processor.py', 'tests/test_state_tracker.py', 'debian/rules', 'tests/manual/no-op.json', 'monasca_notification/processors/base.py', 'debian/copyright', 'debian/control', 'README.md', 'monasca_notification/main.py', 'debian/compat', 'tests/manual/notify.json', 'monasca_notification/processors/kafka_consumer.py', 'tests/test_notification.py', 'tox.ini', 'HACKING.rst', 'monasca_notification/notification.py'], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/e6e54c6576dda1578e074d99126bc8327df6e2a0', 'message': 'Rename to monasca, setup for tox, removed legacy bits\n\nRemoved manual tests which are no longer valid with a modern mini-mon\nRemoved debian creation bits all distribution is with pypi now\nMinor pep8 fixes\n\nChange-Id: I1f2fc4d0ad6375f4c39446f9627247945066e4ad\n'}]",0,107496,e6e54c6576dda1578e074d99126bc8327df6e2a0,25,2,7,11094,,,0,"Rename to monasca, setup for tox, removed legacy bits

Removed manual tests which are no longer valid with a modern mini-mon
Removed debian creation bits all distribution is with pypi now
Minor pep8 fixes

Change-Id: I1f2fc4d0ad6375f4c39446f9627247945066e4ad
",git fetch https://review.opendev.org/openstack/monasca-notification refs/changes/96/107496/7 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_notification/processors/notification_processor.py', 'tests/manual/README.md', '.gitignore', 'monasca_notification/processors/__init__.py', '.gitreview', 'debian/changelog', 'monasca_notification/__init__.py', 'monasca_notification/notification_exceptions.py', 'monasca_notification/state_tracker.py', 'test-requirements.txt', 'tests/test_alarm_processor.py', 'tests/manual/invalid.json', 'setup.py', 'tools/monasca_notification_offsets.py', 'notification.yaml', 'tests/test_notification_processor.py', 'monasca_notification/processors/sent_notification_processor.py', 'tests/manual/sample_notifications.sql', 'monasca_notification/processors/alarm_processor.py', 'tests/test_state_tracker.py', 'debian/rules', 'tests/manual/no-op.json', 'monasca_notification/processors/base.py', 'debian/copyright', 'debian/control', 'README.md', 'monasca_notification/main.py', 'debian/compat', 'tests/manual/notify.json', 'monasca_notification/processors/kafka_consumer.py', 'tests/test_notification.py', 'tox.ini', 'HACKING.rst', 'monasca_notification/notification.py']",34,06051457f177d1c6878ac49b2d83e63d526c7701,,,,55,107
openstack%2Fhorizon~master~I02779d0b7c279d37a81666115e4a340b3a705a89,openstack/horizon,master,I02779d0b7c279d37a81666115e4a340b3a705a89,Angularize admin flavors table,ABANDONED,2014-07-16 21:57:15.000000000,2014-07-16 22:09:32.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-16 21:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9cad8782cab10b1f8fc5c8efccc5719b053591c9', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to clientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I02779d0b7c279d37a81666115e4a340b3a705a89\nImplements: blueprint table-client-rendering\n'}, {'number': 2, 'created': '2014-07-16 21:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2cd1a5cdf4b19c08ee14e2790eab63e379a2b92d', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to clientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I02779d0b7c279d37a81666115e4a340b3a705a89\nImplements: blueprint table-client-rendering\n'}, {'number': 3, 'created': '2014-07-16 21:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7d8f4b0513e1b6e23f37df8d24dac9057c76400f', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to \nclientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I02779d0b7c279d37a81666115e4a340b3a705a89\nImplements: blueprint table-client-rendering\n'}, {'number': 4, 'created': '2014-07-16 22:06:52.000000000', 'files': ['horizon/templates/horizon/_conf.html', 'horizon/templates/horizon/angular/_table.html', 'openstack_dashboard/dashboards/project/instances/templates/instances/_instances_table.html', 'horizon/static/horizon/js/angular/directives/hz.table.directives.js', 'openstack_dashboard/utils/json_encoder.py', 'horizon/static/horizon/js/angular/horizon.js', 'horizon/tables/__init__.py', 'horizon/tables/base.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/instances/tables.py', 'horizon/templates/horizon/angular/_table_actions.html', 'openstack_dashboard/dashboards/admin/flavors/tables.py', 'horizon/test/tests/tables.py', 'horizon/static/horizon/js/angular/hz.table.js', 'horizon/static/horizon/js/angular/filters/hz.table.filters.js', 'openstack_dashboard/dashboards/admin/flavors/views.py', 'horizon/tables/views.py', 'openstack_dashboard/api/base.py', 'openstack_dashboard/dashboards/admin/flavors/templates/flavors/table.html', 'horizon/static/horizon/js/horizon.tables.js', 'horizon/templates/horizon/angular/_table_row_actions.html', 'openstack_dashboard/dashboards/project/instances/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ab9265b222565f763050fee6de2d2ad09c42293c', 'message': 'Angularize admin flavors table\n\nThis patch is part of the larger initiative to move rendering logic to clientside. As demonstrated here, it can be achieve in 3 easy steps:\n\n1. Inherit JSONTableMixin in your view and specify an encoder class.\n2. Define a data-binding template (can even include scripts).\n3. Reference this template in your table by overriding template.\n\nChange-Id: I02779d0b7c279d37a81666115e4a340b3a705a89\nImplements: blueprint table-client-rendering\n'}]",0,107513,ab9265b222565f763050fee6de2d2ad09c42293c,10,1,4,9576,,,0,"Angularize admin flavors table

This patch is part of the larger initiative to move rendering logic to clientside. As demonstrated here, it can be achieve in 3 easy steps:

1. Inherit JSONTableMixin in your view and specify an encoder class.
2. Define a data-binding template (can even include scripts).
3. Reference this template in your table by overriding template.

Change-Id: I02779d0b7c279d37a81666115e4a340b3a705a89
Implements: blueprint table-client-rendering
",git fetch https://review.opendev.org/openstack/horizon refs/changes/13/107513/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/horizon/_conf.html', 'horizon/templates/horizon/angular/_table.html', 'openstack_dashboard/dashboards/project/instances/templates/instances/_instances_table.html', 'horizon/static/horizon/js/angular/directives/hz.table.directives.js', 'openstack_dashboard/utils/json_encoder.py', 'horizon/static/horizon/js/angular/horizon.js', 'horizon/tables/__init__.py', 'horizon/tables/base.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/instances/tables.py', 'horizon/templates/horizon/angular/_table_actions.html', 'openstack_dashboard/dashboards/admin/flavors/tables.py', 'horizon/test/tests/tables.py', 'horizon/static/horizon/js/angular/hz.table.js', 'horizon/static/horizon/js/angular/filters/hz.table.filters.js', 'openstack_dashboard/dashboards/admin/flavors/views.py', 'horizon/tables/views.py', 'openstack_dashboard/api/base.py', 'openstack_dashboard/dashboards/admin/flavors/templates/flavors/table.html', 'horizon/static/horizon/js/horizon.tables.js', 'horizon/templates/horizon/angular/_table_row_actions.html', 'openstack_dashboard/dashboards/project/instances/views.py']",22,9cad8782cab10b1f8fc5c8efccc5719b053591c9,bp/table-client-rendering,"from openstack_dashboard.utils import json_encoder class IndexView(tables.JSONTableMixin, tables.DataTableView): encoder_class = json_encoder.OSAPIJSONEncoder", class IndexView(tables.DataTableView):,1028,76
openstack%2Fglance~master~Ic8ba2d2f470ec052ba13c3b63b26d5e2270f7412,openstack/glance,master,Ic8ba2d2f470ec052ba13c3b63b26d5e2270f7412,Use auth_token from keystonemiddleware,MERGED,2014-06-24 21:22:08.000000000,2014-07-16 22:05:17.000000000,2014-07-16 22:05:16.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2537}, {'_account_id': 4395}, {'_account_id': 5202}, {'_account_id': 6486}, {'_account_id': 6549}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-24 21:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f673cdb2263cc412f6f0b673eb4e3df2273e4426', 'message': 'Use auth_token from keystonemiddleware\n\nThe auth_token middleware in python-keystoneclient is now\ndeprecated and has been moved to keystonemiddleware.\n\nChange-Id: Ic8ba2d2f470ec052ba13c3b63b26d5e2270f7412\n'}, {'number': 2, 'created': '2014-07-03 17:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/19a3362c1717720f096197835f5621e247dbe712', 'message': 'Use auth_token from keystonemiddleware\n\nThe auth_token middleware in python-keystoneclient is now\ndeprecated and has been moved to keystonemiddleware.\n\nChange-Id: Ic8ba2d2f470ec052ba13c3b63b26d5e2270f7412\n'}, {'number': 3, 'created': '2014-07-11 16:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e9cc83967656954e557ac88b214281fc5dc01b96', 'message': 'Use auth_token from keystonemiddleware\n\nThe auth_token middleware in python-keystoneclient is now\ndeprecated and has been moved to keystonemiddleware.\n\nChange-Id: Ic8ba2d2f470ec052ba13c3b63b26d5e2270f7412\n'}, {'number': 4, 'created': '2014-07-11 16:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5601295b92819c1e85b3231e279bee5cc3b4815f', 'message': 'Use auth_token from keystonemiddleware\n\nThe auth_token middleware in python-keystoneclient is now\ndeprecated and has been moved to keystonemiddleware.\n\nChange-Id: Ic8ba2d2f470ec052ba13c3b63b26d5e2270f7412\n'}, {'number': 5, 'created': '2014-07-15 18:36:14.000000000', 'files': ['etc/glance-registry-paste.ini', 'requirements.txt', 'doc/source/authentication.rst', 'glance/registry/client/v1/api.py', 'etc/glance-api-paste.ini'], 'web_link': 'https://opendev.org/openstack/glance/commit/adeca091242eed0b691b88f6bcaac8c8044120f6', 'message': 'Use auth_token from keystonemiddleware\n\nThe auth_token middleware in python-keystoneclient is now\ndeprecated and has been moved to keystonemiddleware.\n\nCloses-Bug: #1342274\n\nChange-Id: Ic8ba2d2f470ec052ba13c3b63b26d5e2270f7412\n'}]",4,102352,adeca091242eed0b691b88f6bcaac8c8044120f6,49,10,5,6486,,,0,"Use auth_token from keystonemiddleware

The auth_token middleware in python-keystoneclient is now
deprecated and has been moved to keystonemiddleware.

Closes-Bug: #1342274

Change-Id: Ic8ba2d2f470ec052ba13c3b63b26d5e2270f7412
",git fetch https://review.opendev.org/openstack/glance refs/changes/52/102352/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'etc/glance-api-paste.ini']",2,f673cdb2263cc412f6f0b673eb4e3df2273e4426,keystonemiddleware,paste.filter_factory = keystonemiddleware.auth_token:filter_factory,paste.filter_factory = keystoneclient.middleware.auth_token:filter_factory,2,1
openstack%2Fcinder~stable%2Fhavana~I35711876b2c088ad28f32abd39248dc9a467d00d,openstack/cinder,stable/havana,I35711876b2c088ad28f32abd39248dc9a467d00d,Change RBD delete failure log level to warn,MERGED,2014-03-19 06:24:47.000000000,2014-07-16 22:05:10.000000000,2014-07-16 22:05:09.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5538}, {'_account_id': 7198}, {'_account_id': 9533}]","[{'number': 1, 'created': '2014-03-19 06:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7936993ef3af5a8086865385d4a9b1008b4fc426', 'message': ""Change RBD delete failure log level to warn\n\nThis is a recoverable issue in the backend, so we don't have to provide\nthe message on the error level.\n\nChange-Id: I35711876b2c088ad28f32abd39248dc9a467d00d\nCloses-Bug: #1256259\n""}, {'number': 2, 'created': '2014-03-19 22:54:47.000000000', 'files': ['cinder/volume/drivers/rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0b2041fb68cc845f0adb270304352045de6c3754', 'message': ""Change RBD delete failure log level to warn\n\nThis is a recoverable issue in the backend, so we don't have to provide\nthe message on the error level.\n\nChange-Id: I35711876b2c088ad28f32abd39248dc9a467d00d\nCloses-Bug: #1256259\n(cherry picked from commit a2f2a0e0d2f9516d86ef5988e083f70804c3977c)\n""}]",0,81451,0b2041fb68cc845f0adb270304352045de6c3754,32,7,2,170,,,0,"Change RBD delete failure log level to warn

This is a recoverable issue in the backend, so we don't have to provide
the message on the error level.

Change-Id: I35711876b2c088ad28f32abd39248dc9a467d00d
Closes-Bug: #1256259
(cherry picked from commit a2f2a0e0d2f9516d86ef5988e083f70804c3977c)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/51/81451/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rbd.py'],1,7936993ef3af5a8086865385d4a9b1008b4fc426,, LOG.warn(msg), LOG.error(msg),1,1
openstack%2Fnova~master~Ifc26e112b9c2974e0fb7a91ba39d5b2d887bd549,openstack/nova,master,Ifc26e112b9c2974e0fb7a91ba39d5b2d887bd549,Fixed wrong assertion in test_vmops.py,MERGED,2014-06-30 14:16:22.000000000,2014-07-16 21:56:09.000000000,2014-07-16 21:56:07.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 8247}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 11650}]","[{'number': 1, 'created': '2014-06-30 14:16:22.000000000', 'files': ['nova/tests/virt/vmwareapi/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aaa9d6a8a28335b8dac4e1d4045571aa565e3196', 'message': ""Fixed wrong assertion in test_vmops.py\n\nThere is wrong assert method in\nnova.tests.virt.vmwareapi.vmwareapi.test_vmops.py:640\nwhile checking a number of calls mocked method 'mkdir'.\n\nWe should use assertEqual(3, len(mock_mkdir.mock_calls))\ninstead of self.assertTrue(3, len(mock_mkdir.mock_calls))\n\nBut number of calling method 'mkdir' not always is 3.\nIf dict block_device_info contains key 'block_device_mapping'\nwith any information, method 'mkdir' wouldn't be called in method\nself._vmops.spawn(). That is why corresponding check been added.\n\nChange-Id: Ifc26e112b9c2974e0fb7a91ba39d5b2d887bd549\nCloses-Bug: #1335859\n""}]",0,103550,aaa9d6a8a28335b8dac4e1d4045571aa565e3196,22,11,1,9569,,,0,"Fixed wrong assertion in test_vmops.py

There is wrong assert method in
nova.tests.virt.vmwareapi.vmwareapi.test_vmops.py:640
while checking a number of calls mocked method 'mkdir'.

We should use assertEqual(3, len(mock_mkdir.mock_calls))
instead of self.assertTrue(3, len(mock_mkdir.mock_calls))

But number of calling method 'mkdir' not always is 3.
If dict block_device_info contains key 'block_device_mapping'
with any information, method 'mkdir' wouldn't be called in method
self._vmops.spawn(). That is why corresponding check been added.

Change-Id: Ifc26e112b9c2974e0fb7a91ba39d5b2d887bd549
Closes-Bug: #1335859
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/103550/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/vmwareapi/test_vmops.py'],1,aaa9d6a8a28335b8dac4e1d4045571aa565e3196,bug/1335859," expected_mkdir_calls = 3 if block_device_info and len(block_device_info.get( 'block_device_mapping', [])) > 0: # if block_device_info contains key 'block_device_mapping' # with any information, method mkdir wouldn't be called in # method self._vmops.spawn() expected_mkdir_calls = 0 self.assertEqual(expected_mkdir_calls, len(mock_mkdir.mock_calls)) "," self.assertTrue(3, len(mock_mkdir.mock_calls))",11,1
openstack%2Fneutron~master~Id9ca10855e6527d4bec689f8f9bcd6f681221954,openstack/neutron,master,Id9ca10855e6527d4bec689f8f9bcd6f681221954,Add -s option for neutron metering rules,MERGED,2014-05-26 13:55:39.000000000,2014-07-16 21:53:49.000000000,2014-07-14 21:25:23.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 2031}, {'_account_id': 2284}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 7141}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10068}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 11279}, {'_account_id': 11515}, {'_account_id': 11614}, {'_account_id': 11825}]","[{'number': 1, 'created': '2014-05-26 13:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f4220320185bbb604e90c57afc23956d71a829e', 'message': 'added -s option for meter-labels\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 2, 'created': '2014-05-26 14:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/984e548e3da9a4852831a9066b603e0bfa0b2e29', 'message': 'added -s option for meter-labels\n\nCloses-dug:1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 3, 'created': '2014-05-27 05:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/81296308a3b7d9ea8bd1fe307b2eaea1f8480bde', 'message': 'added -s option for meter-labels\n\nCloses-bug:1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 4, 'created': '2014-05-28 12:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78f7e7e6452ff16a367387f7fd96d55470da317c', 'message': 'While adding iptables rule, adding cidr as destination\nfor both ingress and egress directions.\nadded -s for egress and -d for ingress.\n\nCloses-bug:1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 5, 'created': '2014-05-29 06:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/520e422486dfce9695abc4d04ba2a3611b4fc682', 'message': 'While adding iptables rule, we add cidr as\n\ndestination for both ingress and egress\ndirections.Modified code to add -s for egress\nand -d for ingress.\n\nCloses-bug:1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 6, 'created': '2014-06-03 09:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9c3c87c5fe6c0ab7292bfaab9bcdc80e8da320b', 'message': 'While adding iptables rule, we add cidr as\n\ndestination for both ingress and egress\ndirections.Modified code to add -s for egress\nand -d for ingress.\n\nCloses-bug:1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 7, 'created': '2014-06-10 10:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ea9d754efc9153ebc4c245443d15a143616425a', 'message': 'While adding iptables rule, we add cidr as\n\ndestination for both ingress and egress\ndirections.Modified code to add -s for egress\nand -d for ingress.\n\nCloses-bug:1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 8, 'created': '2014-06-10 14:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3720c20ae6f01ae5c8d54076024652bfc6da913b', 'message': 'Add -s option for neutron metering rules\n\nWhile adding iptables rule, cidr is added\nas destination for both ingress and egress\ndirections. Modified code to add -s for\negress and -d for ingress.\n\nCloses-bug:1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 9, 'created': '2014-06-12 16:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/523f6c984452d27e59ab4efc8d35b86894e65c1b', 'message': 'Add -s option for neutron metering rules\n\nWhile adding iptables rule, cidr is added\nas destination for both ingress and egress\ndirections. Modified code to add -s for\negress and -d for ingress.\n\nCloses-bug:1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 10, 'created': '2014-06-13 07:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/984d2097c2375068b2e20b8800298fc218cf2937', 'message': 'Add -s option for neutron metering rules\n\nWhile adding iptables rule, cidr is added\nas destination for both ingress and egress\ndirections. Modified code to add -s for\negress and -d for ingress.\n\nCloses-bug:1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 11, 'created': '2014-06-16 07:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d83534dfd8c595c39304f67d7c8be640e8f7450a', 'message': 'Add -s option for neutron metering rules\n\nWhile adding iptables rule, cidr is added\nas destination for both ingress and egress\ndirections. Modified code to add -s for\negress and -d for ingress.\n\nCloses-bug: 1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 12, 'created': '2014-06-25 10:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66049b5c3ee9c6f18cffde7ab6bd67b5ba9fafa0', 'message': 'Add -s option for neutron metering rules\n\nWhile adding iptables rule, cidr is added as destination for both ingress\nand egress directions. Modified code to add -s for egress and -d for ingress.\n\nCloses-bug: 1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 13, 'created': '2014-06-25 10:32:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/da22760aacc79740f75663ea28d425d6c55a223e', 'message': 'Add -s option for neutron metering rules\n\nWhile adding iptables rule, cidr is added as destination for both ingress\nand egress directions. Modified code to add -s for egress and -d for ingress.\n\nCloses-bug: 1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 14, 'created': '2014-07-10 10:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4022c7b5827335403eb5f43accba1c258c6d5eb', 'message': 'Add -s option for neutron metering rules\n\nWhile adding iptables rule, cidr is added as destination for both ingress\nand egress directions. Modified code to add -s for egress and -d for ingress.\n\nCloses-bug: 1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}, {'number': 15, 'created': '2014-07-14 07:13:06.000000000', 'files': ['neutron/tests/unit/services/metering/drivers/test_iptables_driver.py', 'neutron/services/metering/drivers/iptables/iptables_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/72e8b5dc5a5e36722327efca4c399f0321e9bbbb', 'message': 'Add -s option for neutron metering rules\n\nWhile adding iptables rule, cidr is added as destination for both ingress\nand egress directions. Modified code to add -s for egress and -d for ingress.\n\nCloses-bug: 1310589\n\nChange-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954\n'}]",54,95526,72e8b5dc5a5e36722327efca4c399f0321e9bbbb,253,33,15,11614,,,0,"Add -s option for neutron metering rules

While adding iptables rule, cidr is added as destination for both ingress
and egress directions. Modified code to add -s for egress and -d for ingress.

Closes-bug: 1310589

Change-Id: Id9ca10855e6527d4bec689f8f9bcd6f681221954
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/95526/13 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/metering/drivers/iptables/iptables_driver.py'],1,1f4220320185bbb604e90c57afc23956d71a829e,bug/1310589, if rule['direction'] == 'egress': ipt_rule = dir + ' -s ' + remote_ip + ' -j ' + label_chain else: ipt_rule = dir + ' -d ' + remote_ip + ' -j ' + label_chain, ipt_rule = dir + ' -d ' + remote_ip + ' -j ' + label_chain,4,1
openstack%2Fheat~master~Ie79b04bc1ae2d4784318c19661584d02b7bee088,openstack/heat,master,Ie79b04bc1ae2d4784318c19661584d02b7bee088,Fix H201 violations and re-enable gating,MERGED,2014-06-26 09:25:54.000000000,2014-07-16 21:47:30.000000000,2014-07-16 21:47:29.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 6577}, {'_account_id': 6899}, {'_account_id': 7193}, {'_account_id': 7404}, {'_account_id': 8290}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-06-26 09:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c8df11dc87b63ffa3845c3421ea4b0bed7787ec1', 'message': 'Fix E201 violations and re-enable gating\n\nE201 got stricter in hacking 0.9, so fix new violations and\nre-enable gating.\n\nChange-Id: Ie79b04bc1ae2d4784318c19661584d02b7bee088\n'}, {'number': 2, 'created': '2014-07-02 04:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/065cfd2a75ca9253c0f20e43f01eeef333293a91', 'message': 'Fix H201 violations and re-enable gating\n\nH201 got stricter in hacking 0.9, so fix new violations and\nre-enable gating.\n\nChange-Id: Ie79b04bc1ae2d4784318c19661584d02b7bee088\nImplements: blueprint reduce-flake8-ignore-rules\n'}, {'number': 3, 'created': '2014-07-03 08:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bfe4302ccbf9071a552c591159d636963ece89c7', 'message': 'Fix H201 violations and re-enable gating\n\nH201 got stricter in hacking 0.9, so fix new violations and\nre-enable gating.\n\nChange-Id: Ie79b04bc1ae2d4784318c19661584d02b7bee088\nImplements: blueprint reduce-flake8-ignored-rules\n'}, {'number': 4, 'created': '2014-07-03 09:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/84a19cea3788e73bfbfb414b37c12c323fe5641e', 'message': 'Fix H201 violations and re-enable gating\n\nH201 got stricter in hacking 0.9, so fix new violations and\nre-enable gating.\n\nChange-Id: Ie79b04bc1ae2d4784318c19661584d02b7bee088\nImplements: blueprint reduce-flake8-ignore-rules\n'}, {'number': 5, 'created': '2014-07-10 03:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8eaedb310765e5ec2ba3088b2034ef4b15de7768', 'message': 'Fix H201 violations and re-enable gating\n\nH201 got stricter in hacking 0.9, so fix new violations and\nre-enable gating.\n\nChange-Id: Ie79b04bc1ae2d4784318c19661584d02b7bee088\nImplements: blueprint reduce-flake8-ignore-rules\n'}, {'number': 6, 'created': '2014-07-10 04:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a34be5d3429d79420a67985b3d43e33ec0ad5dd0', 'message': 'Fix H201 violations and re-enable gating\n\nH201 got stricter in hacking 0.9, so fix new violations and\nre-enable gating.\n\nChange-Id: Ie79b04bc1ae2d4784318c19661584d02b7bee088\nImplements: blueprint reduce-flake8-ignore-rules\n'}, {'number': 7, 'created': '2014-07-11 02:19:05.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py', 'heat/engine/resources/nova_utils.py', 'heat/tests/test_stack_lock.py', 'heat/db/sqlalchemy/migrate_repo/versions/029_event_id_to_uuid.py', 'heat/tests/test_nova_servergroup.py', 'heat/engine/scheduler.py', 'heat/engine/stack_lock.py', 'tox.ini', 'heat/engine/resource.py', 'heat/db/sqlalchemy/migrate_repo/versions/015_grizzly.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4876f70b02bbd1780533e4500bf3322352efc4b3', 'message': 'Fix H201 violations and re-enable gating\n\nH201 got stricter in hacking 0.9, so fix new violations and\nre-enable gating.\n\nChange-Id: Ie79b04bc1ae2d4784318c19661584d02b7bee088\nImplements: blueprint reduce-flake8-ignore-rules\n'}]",18,102778,4876f70b02bbd1780533e4500bf3322352efc4b3,57,9,7,8290,,,0,"Fix H201 violations and re-enable gating

H201 got stricter in hacking 0.9, so fix new violations and
re-enable gating.

Change-Id: Ie79b04bc1ae2d4784318c19661584d02b7bee088
Implements: blueprint reduce-flake8-ignore-rules
",git fetch https://review.opendev.org/openstack/heat refs/changes/78/102778/6 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py', 'heat/engine/resources/nova_utils.py', 'heat/tests/test_stack_lock.py', 'heat/db/sqlalchemy/migrate_repo/versions/029_event_id_to_uuid.py', 'heat/engine/scheduler.py', 'heat/engine/stack_lock.py', 'tox.ini', 'heat/engine/resource.py', 'heat/db/sqlalchemy/migrate_repo/versions/015_grizzly.py']",10,c8df11dc87b63ffa3845c3421ea4b0bed7787ec1,bp/reduce-flake8-ignore-rules, except Exception:, except:,17,18
openstack%2Ffuel-web~master~I008c558b64dd954df92d74ef357230b6765962ee,openstack/fuel-web,master,I008c558b64dd954df92d74ef357230b6765962ee,"Revert ""Set default repos/puppets for releases""",MERGED,2014-07-16 21:12:09.000000000,2014-07-16 21:39:27.000000000,2014-07-16 21:26:03.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9582}]","[{'number': 1, 'created': '2014-07-16 21:12:09.000000000', 'files': ['nailgun/nailgun/settings.yaml', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/87408ee7fb915591bd463261744973586b1b8ced', 'message': 'Revert ""Set default repos/puppets for releases""\n\nThis reverts commit 428e630ca998fa0b5f5e3a9918a01f2ed1dc5472.\n\nChange-Id: I008c558b64dd954df92d74ef357230b6765962ee\nCloses-Bug: #1342951\n'}]",0,107501,87408ee7fb915591bd463261744973586b1b8ced,12,5,1,406,,,0,"Revert ""Set default repos/puppets for releases""

This reverts commit 428e630ca998fa0b5f5e3a9918a01f2ed1dc5472.

Change-Id: I008c558b64dd954df92d74ef357230b6765962ee
Closes-Bug: #1342951
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/01/107501/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/settings.yaml', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py']",3,87408ee7fb915591bd463261744973586b1b8ced,bug/1342168, def test_repo_and_puppet_data(self):," def test_repo_and_puppet_data_w_orch_data(self): def test_repo_and_puppet_data_wo_orch_data(self): release_id = self.env.create_release().id cluster_id = self.env.create( cluster_kwargs={ 'release_id': release_id }, nodes_kwargs=[ {'roles': ['controller'], 'pending_addition': True} ] )[""id""] cluster = self.db.query(Cluster).get(cluster_id) objects.NodeCollection.prepare_for_deployment(cluster.nodes) facts = self.serializer.serialize(cluster, cluster.nodes) self.assertEqual(1, len(facts)) fact = facts[0] self.assertEqual( fact['repo_metadata'], { 'nailgun': 'http://127.0.0.1:8080/centos/fuelweb/x86_64' } ) self.assertEqual( fact['puppet_modules_source'], 'rsync://127.0.0.1:/puppet/modules/' ) self.assertEqual( fact['puppet_manifests_source'], 'rsync://127.0.0.1:/puppet/manifests/' ) ",2,59
openstack%2Fsahara~master~I2357f72762a3a73adb42208fe64a835cffa5716b,openstack/sahara,master,I2357f72762a3a73adb42208fe64a835cffa5716b,Fixed configuring instances for Vanilla 2.0,MERGED,2014-07-08 16:52:27.000000000,2014-07-16 21:28:24.000000000,2014-07-16 21:28:24.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-07-08 16:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d8acbcb6075d363070028d6787a2072fd1feae31', 'message': ' Fixed configuring instances for Vanilla 2.0\n\nFixed configuring instances and starting services using threaded\nSSH command for Vanilla Hadoop 2.0.\n\nChange-Id: I2357f72762a3a73adb42208fe64a835cffa5716b\n'}, {'number': 2, 'created': '2014-07-08 16:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/776ee703eab53d4fab162344a90ccf08c8b03b9f', 'message': ' Fixed configuring instances for Vanilla 2.0\n\nFixed configuring instances and starting services using threaded\nSSH command for Vanilla Hadoop 2.0.\n\nChange-Id: I2357f72762a3a73adb42208fe64a835cffa5716b\nCloses-bug: #1324289\n'}, {'number': 3, 'created': '2014-07-09 14:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4074130ec91a229703af502420bdf9d77c07dfca', 'message': 'Fixed configuring instances for Vanilla 2.0\n\nFixed configuring instances and starting services using threaded\nSSH command for Vanilla Hadoop 2.0.\n\nChange-Id: I2357f72762a3a73adb42208fe64a835cffa5716b\nCloses-bug: #1324289\n'}, {'number': 4, 'created': '2014-07-10 11:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b6c1989e753be3b1a970ed75959ec8a8aa91dd7c', 'message': 'Fixed configuring instances for Vanilla 2.0\n\nFixed configuring instances and starting services using threaded\nSSH command for Vanilla Hadoop 2.0.\n\nChange-Id: I2357f72762a3a73adb42208fe64a835cffa5716b\nCloses-bug: #1324289\n'}, {'number': 5, 'created': '2014-07-10 11:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/bcc50934b32d0db0b482df2a02f8a43ced41235b', 'message': 'Fixed configuring instances for Vanilla 2.0\n\nFixed configuring instances and starting services using threaded\nSSH command for Vanilla Hadoop 2.0.\n\nChange-Id: I2357f72762a3a73adb42208fe64a835cffa5716b\nCloses-bug: #1324289\n'}, {'number': 6, 'created': '2014-07-11 09:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/045930a3eb6ca8d940a4c353a0f67abfa8e80a68', 'message': 'Fixed configuring instances for Vanilla 2.0\n\nFixed configuring instances and starting services using threaded\nSSH command for Vanilla Hadoop 2.0.\n\nChange-Id: I2357f72762a3a73adb42208fe64a835cffa5716b\nCloses-bug: #1324289\n'}, {'number': 7, 'created': '2014-07-11 11:43:00.000000000', 'files': ['sahara/plugins/vanilla/hadoop2/run_scripts.py', 'sahara/plugins/vanilla/hadoop2/scaling.py', 'sahara/plugins/vanilla/v2_3_0/versionhandler.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/45af90b1452f980632d4ca7ba577458d4ae542bc', 'message': 'Fixed configuring instances for Vanilla 2.0\n\nFixed configuring instances and starting services using threaded\nSSH command for Vanilla Hadoop 2.0.\n\nChange-Id: I2357f72762a3a73adb42208fe64a835cffa5716b\nCloses-bug: #1324289\n'}]",6,105525,45af90b1452f980632d4ca7ba577458d4ae542bc,64,11,7,12038,,,0,"Fixed configuring instances for Vanilla 2.0

Fixed configuring instances and starting services using threaded
SSH command for Vanilla Hadoop 2.0.

Change-Id: I2357f72762a3a73adb42208fe64a835cffa5716b
Closes-bug: #1324289
",git fetch https://review.opendev.org/openstack/sahara refs/changes/25/105525/3 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/vanilla/hadoop2/run_scripts.py', 'sahara/plugins/vanilla/hadoop2/scaling.py', 'sahara/plugins/vanilla/v2_3_0/versionhandler.py']",3,d8acbcb6075d363070028d6787a2072fd1feae31,fix_starting,"from sahara.plugins.general import utils def _start_dn_nm(self, instance, dn_nm_procs): with instance.remote() as r: run.start_processes_nm_dn(r, *dn_nm_procs) def _start_dn_nm_process(self, instances): dn_nm_names = ['datanode', 'nodemanager'] with context.ThreadGroup() as tg: for i in instances: processes = set(i.node_group.node_processes) dn_nm_procs = processes.intersection(dn_nm_names) if dn_nm_procs: tg.spawn('vanilla-start-dn-nm-%s' % i.instance_name, self._start_dn_nm, i, list(dn_nm_procs)) self._start_dn_nm_process(utils.get_instances(cluster))"," for dn in vu.get_datanodes(cluster): run.start_hadoop_process(dn, 'datanode') for nm in vu.get_nodemanagers(cluster): run.start_yarn_process(nm, 'nodemanager') ",53,7
openstack%2Fneutron~master~I4627481813f714819efe85831e2a55975ea71ed4,openstack/neutron,master,I4627481813f714819efe85831e2a55975ea71ed4,Change all occurences of no_delete to do_delete,MERGED,2014-05-04 15:37:27.000000000,2014-07-16 21:27:56.000000000,2014-07-16 03:44:11.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 1923}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7141}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8655}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 11710}]","[{'number': 1, 'created': '2014-05-04 15:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/be57e500cc08574fb11d5f4587d3f218361345b2', 'message': 'Testing: Change all occurences of do_delete to no_delete\n\nPreviously, ports, networks and subnets had a do_delete=True\nparameter. By default, these resources were deleted at the\nend of the context manager scope. All other resources used\na different semantic: no_delete=False.\n\nThis caused confusing situations such as:\nwith self.subnet(network, do_delete=False) as subnet:\n    with self.security_group(no_delete=True) as sg:\n        pass\n\nNow all resources use the same no_delete semantic.\n\nChange-Id: I4627481813f714819efe85831e2a55975ea71ed4\n'}, {'number': 2, 'created': '2014-05-05 07:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f6a1ef6fa35129ec545d57fe060cc47c1d19208', 'message': 'Testing: Change all occurences of do_delete to no_delete\n\nPreviously, ports, networks and subnets had a do_delete=True\nparameter. By default, these resources were deleted at the\nend of the context manager scope. All other resources used\na different semantic: no_delete=False.\n\nThis caused confusing situations such as:\nwith self.subnet(network, do_delete=False) as subnet:\n    with self.security_group(no_delete=True) as sg:\n        pass\n\nNow all resources use the same no_delete semantic.\n\nChange-Id: I4627481813f714819efe85831e2a55975ea71ed4\n'}, {'number': 3, 'created': '2014-06-30 11:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e1f921e6ee8d6f934939cf11d94bf258f64e1f8f', 'message': 'Change all occurences of no_delete to do_delete\n\nPreviously, ports, networks and subnets had a do_delete=True\nparameter. By default, these resources were deleted at the\nend of the context manager scope. All other resources used\na different semantic: no_delete=False.\n\nThis caused confusing situations such as:\nwith self.subnet(network, do_delete=False) as subnet:\n    with self.security_group(no_delete=True) as sg:\n        pass\n\nNow all resources use the same do_delete semantic.\n\nChange-Id: I4627481813f714819efe85831e2a55975ea71ed4\n'}, {'number': 4, 'created': '2014-06-30 14:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/33b65f2d66547352b5e32a33391c64dd7aea6066', 'message': 'Change all occurences of no_delete to do_delete\n\nPreviously, ports, networks and subnets had a do_delete=True\nparameter. By default, these resources were deleted at the\nend of the context manager scope. All other resources used\na different semantic: no_delete=False.\n\nThis caused confusing situations such as:\nwith self.subnet(network, do_delete=False) as subnet:\n    with self.security_group(no_delete=True) as sg:\n        pass\n\nNow all resources use the same do_delete semantic.\n\nChange-Id: I4627481813f714819efe85831e2a55975ea71ed4\n'}, {'number': 5, 'created': '2014-07-01 08:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fdfc589bddbcc6b90e4d073d978baf3cb8c5dce5', 'message': 'Change all occurences of no_delete to do_delete\n\nPreviously, ports, networks and subnets had a do_delete=True\nparameter. By default, these resources were deleted at the\nend of the context manager scope. All other resources used\na different semantic: no_delete=False.\n\nThis caused confusing situations such as:\nwith self.subnet(network, do_delete=False) as subnet:\n    with self.security_group(no_delete=True) as sg:\n        pass\n\nNow all resources use the same do_delete semantic.\n\nCloses-Bug: #1336196\nChange-Id: I4627481813f714819efe85831e2a55975ea71ed4\n'}, {'number': 6, 'created': '2014-07-09 08:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea534ca0e8111f2db368b30152d98d2255599bc3', 'message': 'Change all occurences of no_delete to do_delete\n\nPreviously, ports, networks and subnets had a do_delete=True\nparameter. By default, these resources were deleted at the\nend of the context manager scope. All other resources used\na different semantic: no_delete=False.\n\nThis caused confusing situations such as:\nwith self.subnet(network, do_delete=False) as subnet:\n    with self.security_group(no_delete=True) as sg:\n        pass\n\nNow all resources use the same do_delete semantic.\n\nCloses-Bug: #1336196\nChange-Id: I4627481813f714819efe85831e2a55975ea71ed4\n'}, {'number': 7, 'created': '2014-07-13 08:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4917be12e5f072f27f38e83926881966f205335e', 'message': 'Change all occurences of no_delete to do_delete\n\nPreviously, ports, networks and subnets had a do_delete=True\nparameter. By default, these resources were deleted at the\nend of the context manager scope. All other resources used\na different semantic: no_delete=False.\n\nThis caused confusing situations such as:\nwith self.subnet(network, do_delete=False) as subnet:\n    with self.security_group(no_delete=True) as sg:\n        pass\n\nNow all resources use the same do_delete semantic.\n\nCloses-Bug: #1336196\nChange-Id: I4627481813f714819efe85831e2a55975ea71ed4\n'}, {'number': 8, 'created': '2014-07-13 11:08:01.000000000', 'files': ['neutron/tests/unit/nec/test_nec_plugin.py', 'neutron/tests/unit/vmware/test_nsx_plugin.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py', 'neutron/tests/unit/vmware/vshield/test_firewall_driver.py', 'neutron/tests/unit/vmware/vshield/test_loadbalancer_driver.py', 'neutron/tests/unit/bigswitch/test_router_db.py', 'neutron/tests/unit/nec/test_packet_filter.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/tests/unit/db/firewall/test_db_firewall.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py', 'neutron/tests/unit/test_extension_security_group.py', 'neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py', 'neutron/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/tests/unit/db/metering/test_db_metering.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py', 'neutron/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron/tests/unit/services/metering/test_metering_plugin.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/test_plugin_driver.py', 'neutron/tests/unit/nuage/test_nuage_plugin.py', 'neutron/tests/unit/vmware/extensions/test_qosqueues.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/69dfbd9468282f9ce16cc5b0cb1bcb121632a0d8', 'message': 'Change all occurences of no_delete to do_delete\n\nPreviously, ports, networks and subnets had a do_delete=True\nparameter. By default, these resources were deleted at the\nend of the context manager scope. All other resources used\na different semantic: no_delete=False.\n\nThis caused confusing situations such as:\nwith self.subnet(network, do_delete=False) as subnet:\n    with self.security_group(no_delete=True) as sg:\n        pass\n\nNow all resources use the same do_delete semantic.\n\nCloses-Bug: #1336196\nChange-Id: I4627481813f714819efe85831e2a55975ea71ed4\n'}]",33,92013,69dfbd9468282f9ce16cc5b0cb1bcb121632a0d8,169,37,8,8873,,,0,"Change all occurences of no_delete to do_delete

Previously, ports, networks and subnets had a do_delete=True
parameter. By default, these resources were deleted at the
end of the context manager scope. All other resources used
a different semantic: no_delete=False.

This caused confusing situations such as:
with self.subnet(network, do_delete=False) as subnet:
    with self.security_group(no_delete=True) as sg:
        pass

Now all resources use the same do_delete semantic.

Closes-Bug: #1336196
Change-Id: I4627481813f714819efe85831e2a55975ea71ed4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/92013/8 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_l3_plugin.py', 'neutron/tests/unit/nec/test_nec_plugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py', 'neutron/tests/unit/test_extension_ext_net.py', 'neutron/tests/unit/nuage/test_netpartition.py', 'neutron/tests/unit/nec/test_packet_filter.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/tests/unit/cisco/test_network_plugin.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/tests/unit/vmware/extensions/test_qosqueues.py', 'neutron/tests/unit/test_extension_portsecurity.py']",12,be57e500cc08574fb11d5f4587d3f218361345b2,bug/1336196," with self.network(shared=True, no_delete=True) as net: with self.subnet(network=net, no_delete=True):"," with self.network(shared=True, do_delete=False) as net: with self.subnet(network=net, do_delete=False):",43,43
openstack%2Ffuel-web~master~Id0917d1044824879d348cf1ff2f8fa1588d716fb,openstack/fuel-web,master,Id0917d1044824879d348cf1ff2f8fa1588d716fb,Set default repos/puppets for releases,MERGED,2014-07-15 21:48:43.000000000,2014-07-16 21:12:09.000000000,2014-07-16 10:01:37.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-07-15 21:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6ae16e759960a9f3997827d00b391b9d2f6bf035', 'message': 'Set default repos/puppets for releases\n\nSince Fuel 5.1 repos/puppets paths are sent by Nailgun to Astute.\nSo we need to set defaults here, and remove them from Astute in\norder to make our code more clear and centralized.\n\nCloses-Bug: #1342168\nChange-Id: Id0917d1044824879d348cf1ff2f8fa1588d716fb\n'}, {'number': 2, 'created': '2014-07-16 07:44:09.000000000', 'files': ['nailgun/nailgun/settings.yaml', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/428e630ca998fa0b5f5e3a9918a01f2ed1dc5472', 'message': 'Set default repos/puppets for releases\n\nSince Fuel 5.1 repos/puppets paths are sent by Nailgun to Astute.\nSo we need to set defaults here, and remove them from Astute in\norder to make our code more clear and centralized.\n\nCloses-Bug: #1342168\nChange-Id: Id0917d1044824879d348cf1ff2f8fa1588d716fb\n'}]",0,107184,428e630ca998fa0b5f5e3a9918a01f2ed1dc5472,24,6,2,10391,,,0,"Set default repos/puppets for releases

Since Fuel 5.1 repos/puppets paths are sent by Nailgun to Astute.
So we need to set defaults here, and remove them from Astute in
order to make our code more clear and centralized.

Closes-Bug: #1342168
Change-Id: Id0917d1044824879d348cf1ff2f8fa1588d716fb
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/84/107184/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/settings.yaml', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py']",3,6ae16e759960a9f3997827d00b391b9d2f6bf035,bug/1342168," def test_repo_and_puppet_data_w_orch_data(self): def test_repo_and_puppet_data_wo_orch_data(self): release_id = self.env.create_release().id cluster_id = self.env.create( cluster_kwargs={ 'release_id': release_id }, nodes_kwargs=[ {'roles': ['controller'], 'pending_addition': True} ] )[""id""] cluster = self.db.query(Cluster).get(cluster_id) objects.NodeCollection.prepare_for_deployment(cluster.nodes) facts = self.serializer.serialize(cluster, cluster.nodes) self.assertEqual(1, len(facts)) fact = facts[0] self.assertEqual( fact['repo_metadata'], { 'nailgun': 'http://127.0.0.1:8080/centos/fuelweb/x86_64' } ) self.assertEqual( fact['puppet_modules_source'], 'rsync://127.0.0.1:/puppet/modules/' ) self.assertEqual( fact['puppet_manifests_source'], 'rsync://127.0.0.1:/puppet/manifests/' ) ", def test_repo_and_puppet_data(self):,59,2
openstack%2Fswift~master~I914fc189514207df2535731eda10cb4b3d30cc6c,openstack/swift,master,I914fc189514207df2535731eda10cb4b3d30cc6c,Object services user-agent string uses full name,MERGED,2014-06-25 00:47:48.000000000,2014-07-16 21:09:04.000000000,2014-07-16 21:09:03.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 9129}]","[{'number': 1, 'created': '2014-06-25 00:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c829115f647c251e75eefc7d66be557de5e27c31', 'message': 'Modify the object services to report their full service name.\n\nNowhere, aside from the user-agent string, does obj-server, obj-updater, or\nobj-replicator (or obj-anything*) appear anywhere in the swift code.\nFurthermore, the container and proxy services always report their full name in\nthe user agent string. For consistency, update the object server to use object-\nprefix rather than obj- in its user agent string.\n\n* obj-etag does appear in a unit test, but not part of the regular code.\n\nChange-Id: I914fc189514207df2535731eda10cb4b3d30cc6c\n'}, {'number': 2, 'created': '2014-06-25 01:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/13a2fa4650ca77f2acd020391de9d5da0d30c17e', 'message': 'Modify the object services to report their full service name.\n\nNowhere, aside from the user-agent string, does obj-server,\nobj-updater, or obj-replicator (or obj-anything*) appear anywhere in\nthe swift code. Furthermore, the container and proxy services always\nreport their full name in the user agent string, and the process name\nmakes more sense to report witht he process PID. For consistency,\nupdate the object server to use object- prefix rather than obj- in its\nuser agent string.\n\n* obj-etag does appear in a unit test, but not part of the regular\ncode.\n\nChange-Id: I914fc189514207df2535731eda10cb4b3d30cc6c\n'}, {'number': 3, 'created': '2014-06-25 01:20:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6cc1d8b5b29cf940e7846c23b09f08034a4cfdb0', 'message': 'Modify the object services to report their full service name.\n\nNowhere, aside from the user-agent string, does obj-server,\nobj-updater, or obj-replicator (or obj-anything*) appear anywhere in\nthe swift code. Furthermore, the container and proxy services always\nreport their full name in the user agent string, and the process name\nmakes more sense to report witht he process PID. For consistency,\nupdate the object server to use object- prefix rather than obj- in its\nuser agent string.\n\n* obj-etag does appear in a unit test, but not part of the regular\ncode.\n\nChange-Id: I914fc189514207df2535731eda10cb4b3d30cc6c\n'}, {'number': 4, 'created': '2014-07-03 01:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5ccdf6f8b8bdf5e0ab1a73bd6c93425344022e7c', 'message': 'Object services user-agent string uses full name\n\nIt does not appear that, aside from the user-agent string, the strings\n""obj-server"", ""obj-updater"", or ""obj-replicator"" (or ""obj-<anything>""*)\nappear in the swift code base, aside from the directory containing the\nobject services code being named ""obj"".\n\nFurthermore, the container, account, and proxy services construct their\nuser-agent string, as reported in the logs, using their full name. In\naddition, this full name also shows up as the name of the process via\n""ps"" or ""top"", etc., which can make it easier for admins to match log\nentries with other tools.\n\nFor consistency, we update the object services to use an ""object-""\nprefix rather than ""obj-"" in its user agent string.\n\n* obj-etag does appear in a unit test, but not part of the regular\ncode.\n\nChange-Id: I914fc189514207df2535731eda10cb4b3d30cc6c\n'}, {'number': 5, 'created': '2014-07-03 01:36:00.000000000', 'files': ['swift/obj/replicator.py', 'swift/obj/updater.py', 'swift/obj/server.py', 'swift/obj/mem_server.py', 'test/unit/obj/test_server.py', 'test/unit/obj/test_replicator.py', 'doc/source/logs.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/7573fbd4985fb090cc315b5af9e7531dc900b7b8', 'message': 'Object services user-agent string uses full name\n\nIt does not appear that, aside from the user-agent string, the strings\n""obj-server"", ""obj-updater"", or ""obj-replicator"" (or ""obj-<anything>""*)\nappear in the swift code base, aside from the directory containing the\nobject services code being named ""obj"".\n\nFurthermore, the container, account, and proxy services construct their\nuser-agent string, as reported in the logs, using their full name. In\naddition, this full name also shows up as the name of the process via\n""ps"" or ""top"", etc., which can make it easier for admins to match log\nentries with other tools.\n\nFor consistency, we update the object services to use an ""object-""\nprefix rather than ""obj-"" in its user agent string.\n\n* obj-etag does appear in a unit test, but not part of the regular\ncode.\n\nChange-Id: I914fc189514207df2535731eda10cb4b3d30cc6c\n'}]",4,102401,7573fbd4985fb090cc315b5af9e7531dc900b7b8,38,8,5,9129,,,0,"Object services user-agent string uses full name

It does not appear that, aside from the user-agent string, the strings
""obj-server"", ""obj-updater"", or ""obj-replicator"" (or ""obj-<anything>""*)
appear in the swift code base, aside from the directory containing the
object services code being named ""obj"".

Furthermore, the container, account, and proxy services construct their
user-agent string, as reported in the logs, using their full name. In
addition, this full name also shows up as the name of the process via
""ps"" or ""top"", etc., which can make it easier for admins to match log
entries with other tools.

For consistency, we update the object services to use an ""object-""
prefix rather than ""obj-"" in its user agent string.

* obj-etag does appear in a unit test, but not part of the regular
code.

Change-Id: I914fc189514207df2535731eda10cb4b3d30cc6c
",git fetch https://review.opendev.org/openstack/swift refs/changes/01/102401/4 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/replicator.py', 'swift/obj/updater.py', 'swift/obj/server.py', 'swift/obj/mem_server.py', 'test/unit/obj/test_server.py', 'test/unit/obj/test_replicator.py']",6,c829115f647c251e75eefc7d66be557de5e27c31,object-server-user-agent, 'user-agent': 'object-replicator %s' % os.getpid()}, 'user-agent': 'obj-replicator %s' % os.getpid()},15,15
openstack%2Fdjango_openstack_auth~master~I6bb638b5b79a916b6bdfe21410b72de939806b94,openstack/django_openstack_auth,master,I6bb638b5b79a916b6bdfe21410b72de939806b94,Imported Translations from Transifex,MERGED,2014-07-15 06:06:38.000000000,2014-07-16 21:04:11.000000000,2014-07-16 21:04:11.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1941}, {'_account_id': 6914}, {'_account_id': 8871}, {'_account_id': 9659}]","[{'number': 1, 'created': '2014-07-15 06:06:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/65ed557d0316b8e5877621c375547e2c3b00092c', 'message': 'Imported Translations from Transifex\n\nChange-Id: I6bb638b5b79a916b6bdfe21410b72de939806b94\n'}, {'number': 2, 'created': '2014-07-16 06:06:38.000000000', 'files': ['openstack_auth/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_auth/locale/uk/LC_MESSAGES/django.po', 'openstack_auth/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_auth/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_auth/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_auth/locale/fr/LC_MESSAGES/django.po', 'openstack_auth/locale/ru/LC_MESSAGES/django.po', 'openstack_auth/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_auth/locale/sl_SI/LC_MESSAGES/django.po', 'openstack_auth/locale/it/LC_MESSAGES/django.po', 'openstack_auth/locale/en_GB/LC_MESSAGES/django.po', 'openstack_auth/locale/es/LC_MESSAGES/django.po', 'openstack_auth/locale/cs/LC_MESSAGES/django.po', 'openstack_auth/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_auth/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_auth/locale/es_MX/LC_MESSAGES/django.po', 'openstack_auth/locale/en_AU/LC_MESSAGES/django.po', 'openstack_auth/locale/ja/LC_MESSAGES/django.po', 'openstack_auth/locale/ca/LC_MESSAGES/django.po', 'openstack_auth/locale/pa_IN/LC_MESSAGES/django.po', 'openstack_auth/locale/hi/LC_MESSAGES/django.po', 'openstack_auth/locale/ar/LC_MESSAGES/django.po', 'openstack_auth/locale/sr/LC_MESSAGES/django.po', 'openstack_auth/locale/pt/LC_MESSAGES/django.po', 'openstack_auth/locale/de/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/1f2bb06a15e0f09156b3de79dcf58d9c85cb639f', 'message': 'Imported Translations from Transifex\n\nChange-Id: I6bb638b5b79a916b6bdfe21410b72de939806b94\n'}]",0,106943,1f2bb06a15e0f09156b3de79dcf58d9c85cb639f,18,6,2,11131,,,0,"Imported Translations from Transifex

Change-Id: I6bb638b5b79a916b6bdfe21410b72de939806b94
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/43/106943/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_auth/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_auth/locale/uk/LC_MESSAGES/django.po', 'openstack_auth/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_auth/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_auth/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_auth/locale/fr/LC_MESSAGES/django.po', 'openstack_auth/locale/ru/LC_MESSAGES/django.po', 'openstack_auth/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_auth/locale/sl_SI/LC_MESSAGES/django.po', 'openstack_auth/locale/it/LC_MESSAGES/django.po', 'openstack_auth/locale/en_GB/LC_MESSAGES/django.po', 'openstack_auth/locale/es/LC_MESSAGES/django.po', 'openstack_auth/locale/cs/LC_MESSAGES/django.po', 'openstack_auth/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_auth/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_auth/locale/es_MX/LC_MESSAGES/django.po', 'openstack_auth/locale/en_AU/LC_MESSAGES/django.po', 'openstack_auth/locale/ja/LC_MESSAGES/django.po', 'openstack_auth/locale/ca/LC_MESSAGES/django.po', 'openstack_auth/locale/pa_IN/LC_MESSAGES/django.po', 'openstack_auth/locale/hi/LC_MESSAGES/django.po', 'openstack_auth/locale/ar/LC_MESSAGES/django.po', 'openstack_auth/locale/sr/LC_MESSAGES/django.po', 'openstack_auth/locale/pt/LC_MESSAGES/django.po', 'openstack_auth/locale/de/LC_MESSAGES/django.po']",25,65ed557d0316b8e5877621c375547e2c3b00092c,transifex/translations,"# German translations for django_openstack_auth. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the # django_openstack_auth project.""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-07-15 06:06+0000\n""","# SOME DESCRIPTIVE TITLE. # Copyright (C) 2014 THE PACKAGE'S COPYRIGHT HOLDER # This file is distributed under the same license as the PACKAGE package.""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2014-07-13 06:01+0000\n""",167,142
openstack%2Ftraining-guides~master~Id7edd03ee930cd7f3b1d2971997638743d25b50f,openstack/training-guides,master,Id7edd03ee930cd7f3b1d2971997638743d25b50f,clean up of bk000-preface xml file,MERGED,2014-07-10 18:23:20.000000000,2014-07-16 20:52:13.000000000,2014-07-16 20:52:13.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7007}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-07-10 18:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/7b0150114ae07f1ee90670991062c047b74db28e', 'message': 'clean up of bk000-preface xml file\n\nremoved references to trello\nremoved references to cards change to bugs\n\nChange-Id: Id7edd03ee930cd7f3b1d2971997638743d25b50f\n'}, {'number': 2, 'created': '2014-07-15 13:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/e299e77f67a42ad85d66ac71258c608450d4e9b7', 'message': 'clean up of bk000-preface xml file\n\nremoved references to trello\nremoved references to cards change to bugs\n\nChange-Id: Id7edd03ee930cd7f3b1d2971997638743d25b50f\n'}, {'number': 3, 'created': '2014-07-15 14:07:11.000000000', 'files': ['doc/training-guides/bk000-preface.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/93126b16cc0b484f307c1c0cec091efbd39c81e5', 'message': 'clean up of bk000-preface xml file\n\nremoved references to trello\nremoved references to cards change to bugs\n\nChange-Id: Id7edd03ee930cd7f3b1d2971997638743d25b50f\n'}]",2,106132,93126b16cc0b484f307c1c0cec091efbd39c81e5,19,4,3,9382,,,0,"clean up of bk000-preface xml file

removed references to trello
removed references to cards change to bugs

Change-Id: Id7edd03ee930cd7f3b1d2971997638743d25b50f
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/32/106132/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/bk000-preface.xml'],1,7b0150114ae07f1ee90670991062c047b74db28e,install_scripts," <para><emphasis role=""bold"">Pick a Bug:</emphasis> Once you have your tools ready xlink:https://bugs.launchpad.net/openstack-training-guides"" >Bugs</link> and assign a bug from the list to yourself.</para> <para><emphasis role=""bold"">Create the Content:</emphasis> Each bug from the list will be a separate chunk of content that you will xlink:href=""https://launchpad.net/openstack-training-guides"" >Training Bugs</link>(we develop high level action items"," <para><emphasis role=""bold"">Pick a Card:</emphasis> Once you have your tools ready xlink:href=""https://trello.com/board/openstack-training/51d6e5fee37248fd5b003de9"" >Training Trello/KanBan storyboard</link> and assign a card / user story from the Sprint Backlog to yourself. If you do not have a Trello account, no problem, just create one. Email seanrob@yahoo-inc.com and you will have access.</para> <para><emphasis role=""bold"">Create the Content:</emphasis> Each card / user story from the KanBan story board will be a separate chunk of content that you will xlink:href=""https://trello.com/board/openstack-training/51d6e5fee37248fd5b003de9"" >Training Trello/KanBan storyboard</link>(we develop high level project action items",7,9
openstack%2Ffuel-main~stable%2F5.0~I31470af079bc88ae4303dc511bfe2b1c1c9c2fed,openstack/fuel-main,stable/5.0,I31470af079bc88ae4303dc511bfe2b1c1c9c2fed,Use direct mount for puppet docker container,MERGED,2014-07-16 10:52:24.000000000,2014-07-16 20:50:55.000000000,2014-07-16 20:50:54.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8749}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-16 10:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0629616be14860b3a888836d15619150dfd00533', 'message': 'Use direct mount for puppet docker container\n\nRemoving workaround for mount of /etc/puppet\nto /puppet, then ln -s /puppet/{files} into\n/etc/puppet, because it breaks upgrade schema\nwhere /etc/puppet/$VER is added.\n\nChange-Id: I31470af079bc88ae4303dc511bfe2b1c1c9c2fed\nPartial-Bug: #1339688\n(cherry picked from commit 8b658b11be66afea92acbe362064aa5ee41de22a)\n'}, {'number': 2, 'created': '2014-07-16 10:53:10.000000000', 'files': ['docker/storage-puppet/Dockerfile'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/dc70b8e5099c9ecc9ff32512662cc268573ffc8c', 'message': 'Use direct mount for puppet docker container\n\nRelies on https://review.openstack.org/#/c/107314/\n\nRemoving workaround for mount of /etc/puppet\nto /puppet, then ln -s /puppet/{files} into\n/etc/puppet, because it breaks upgrade schema\nwhere /etc/puppet/$VER is added.\n\nChange-Id: I31470af079bc88ae4303dc511bfe2b1c1c9c2fed\nPartial-Bug: #1339688\n(cherry picked from commit 8b658b11be66afea92acbe362064aa5ee41de22a)\n'}]",0,107313,dc70b8e5099c9ecc9ff32512662cc268573ffc8c,15,7,2,7195,,,0,"Use direct mount for puppet docker container

Relies on https://review.openstack.org/#/c/107314/

Removing workaround for mount of /etc/puppet
to /puppet, then ln -s /puppet/{files} into
/etc/puppet, because it breaks upgrade schema
where /etc/puppet/$VER is added.

Change-Id: I31470af079bc88ae4303dc511bfe2b1c1c9c2fed
Partial-Bug: #1339688
(cherry picked from commit 8b658b11be66afea92acbe362064aa5ee41de22a)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/13/107313/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/storage-puppet/Dockerfile'],1,0629616be14860b3a888836d15619150dfd00533,,#run with -v /etc/puppet:/etc/puppetCMD /bin/echo storage/puppet I am a data-only container for Fuel,#run with -v /etc/puppet:/puppetRUN mkdir -p /etc/puppet/ /puppet CMD /bin/echo storage/puppet I am a data-only container for Fuel && ln -s /puppet/puppet.conf /puppet/modules /puppet/manifests /etc/puppet/,2,3
openstack%2Ffuel-library~stable%2F5.0~I6c75d6027f617abe96122569686c9fb04497ca89,openstack/fuel-library,stable/5.0,I6c75d6027f617abe96122569686c9fb04497ca89,Direct mount of puppet directory for puppet container,MERGED,2014-07-16 10:52:33.000000000,2014-07-16 20:50:21.000000000,2014-07-16 20:50:21.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8749}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-16 10:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b0a295d2072036fd2c5857280109690f5f1f5d63', 'message': 'Direct mount of puppet directory for puppet container\n\nRelies on https://review.openstack.org/105739\n\nChange-Id: I6c75d6027f617abe96122569686c9fb04497ca89\nCloses-Bug: #1339688\n(cherry picked from commit 064cd6983dd6826a73d805d99b31e31d395db1e2)\n'}, {'number': 2, 'created': '2014-07-16 10:52:52.000000000', 'files': ['deployment/puppet/docker/templates/dockerctl_config.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e8c2bb726be6b78c3a34f75c84337a3a5662bb35', 'message': 'Direct mount of puppet directory for puppet container\n\nRelies on https://review.openstack.org/#/c/107313/\n\nChange-Id: I6c75d6027f617abe96122569686c9fb04497ca89\nCloses-Bug: #1339688\n(cherry picked from commit 064cd6983dd6826a73d805d99b31e31d395db1e2)\n'}]",0,107314,e8c2bb726be6b78c3a34f75c84337a3a5662bb35,19,7,2,7195,,,0,"Direct mount of puppet directory for puppet container

Relies on https://review.openstack.org/#/c/107313/

Change-Id: I6c75d6027f617abe96122569686c9fb04497ca89
Closes-Bug: #1339688
(cherry picked from commit 064cd6983dd6826a73d805d99b31e31d395db1e2)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/14/107314/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/docker/templates/dockerctl_config.erb'],1,b0a295d2072036fd2c5857280109690f5f1f5d63,,"HOST_VOL['puppet']=""-v /etc/puppet:/etc/puppet:ro""","HOST_VOL['puppet']=""-v /etc/puppet:/puppet:ro""",1,1
openstack%2Fcinder-specs~master~Ia0c6488c7867bf1dbb92d0ba76b2a99da186619c,openstack/cinder-specs,master,Ia0c6488c7867bf1dbb92d0ba76b2a99da186619c,Add blueprint for vHost connector support,MERGED,2014-06-27 08:07:54.000000000,2014-07-16 20:42:13.000000000,2014-07-16 20:42:13.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 8874}]","[{'number': 1, 'created': '2014-06-27 08:07:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/32f002a2e5ab8b532b652b3533afc9947e6a2abb', 'message': 'Add blueprint for vHost connector support\n\nChange-Id: Ia0c6488c7867bf1dbb92d0ba76b2a99da186619c\n'}, {'number': 2, 'created': '2014-07-16 04:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/f529503d705a885403cb3280367582c31d83db74', 'message': 'Add blueprint for vHost connector support\n\nChange-Id: Ia0c6488c7867bf1dbb92d0ba76b2a99da186619c\n'}, {'number': 3, 'created': '2014-07-16 08:43:04.000000000', 'files': ['specs/juno/vhost-support.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/f7ccfbfed0cf3ffa01736414408d801a65c2d0c2', 'message': 'Add blueprint for vHost connector support\n\nChange-Id: Ia0c6488c7867bf1dbb92d0ba76b2a99da186619c\n'}]",9,103048,f7ccfbfed0cf3ffa01736414408d801a65c2d0c2,25,7,3,170,,,0,"Add blueprint for vHost connector support

Change-Id: Ia0c6488c7867bf1dbb92d0ba76b2a99da186619c
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/48/103048/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/vhost-support.rst'],1,32f002a2e5ab8b532b652b3533afc9947e6a2abb,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== vHost Support ========================================== https://blueprints.launchpad.net/cinder/+spec/vhost-support The vHost driver was added in the 3.6 Linux kernel. The Linux-IO Target vHost fabric module implements I/O prcoessing based on the Linux virtio mechanism. It provides virtually bare-metal local storage performance for KVM guests. Currently Linux guest VMs are supported. Problem description =================== The vHost driver is not a self-contained virtio device, as it depends on userspace to handle the control plane while the data plane is done in kernel. This means the data plane does not go through emulations, which can slow down I/O performance. Cinder today does not provide an option for taking advantage Linux vHost driver. Proposed change =============== Add an additional target helper vhost in brick, which will use rtstool. rtstool will have the appropriate commands available to use the already existing rtslib interface for managing targets in vHost. Alternatives ------------ n/a Data model impact ----------------- n/a REST API impact --------------- n/a Security impact --------------- n/a Notifications impact -------------------- n/a Other end user impact --------------------- n/a Performance Impact ------------------ Cinder itself being the control plane will not experience any different performance. The data plane should experience a greater deal of performance [1]. Other deployer impact --------------------- The deployer will need to set in the cinder.conf the iscsi_helper to `lio_vhost`. The target would need to be configured to use the Linux-IO vHost fabric module. Developer impact ---------------- n/a Implementation ============== Assignee(s) ----------- Primary assignee: thingee Work Items ---------- * Add vHost management to rtstool. * Add LiovHost object to brick. * Add unit tests for LiovHost. Dependencies ============ Nothing. vHost Linux driver has been in mainline kernel since 3.6. rtslib interface for vHost management already exists as well. Testing ======= There will be appropriate unit tests available making sure target creation, deletion, adding initators via the brick vhost connector object. Documentation Impact ==================== Documentation for setting up the vHost connector in Cinder will be provided. References ========== [1] - http://linux-iscsi.org/wiki/VHost#Linux_performance ",,121,0
openstack%2Fswift~master~I2dcf20b6feb27e346111466a565695eba4b4b1da,openstack/swift,master,I2dcf20b6feb27e346111466a565695eba4b4b1da,Container PUT requests and max container per account,MERGED,2014-04-24 07:00:31.000000000,2014-07-16 20:38:35.000000000,2014-07-16 20:38:34.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8542}, {'_account_id': 8871}, {'_account_id': 9205}]","[{'number': 1, 'created': '2014-04-24 07:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3fd9341be1e331c7182afbcc6581c5d222062ab0', 'message': 'Container PUT requests and max container per account\n\nIf container counter per account is equal or greater than\nmax_container_per_account, then all PUT requests are failed and\n403 is returned.\nThis is correct behaviour if the request is to create a new\ncontainer, however if container already exists PUT should be\nallowed, even the max_container_per_account condition has met.\n\nThis patch allows to process PUT requests for existing containers,\neven if max_container_per_account > = container count.\n\nIt indirectly resolve the bug 1306711, since swift-client\nuses internally PUT requests for container, prior it upload an\nobject there.\n\nChange-Id: I2dcf20b6feb27e346111466a565695eba4b4b1da\n'}, {'number': 2, 'created': '2014-07-10 05:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dbb027d0e016c3cb69505a69e38e55801fa0ad69', 'message': 'Container PUT requests and max container per account\n\nIf container counter per account is equal or greater than\nmax_container_per_account, then all PUT requests are failed and\n403 is returned.\nThis is correct behaviour if the request is to create a new\ncontainer, however if container already exists PUT should be\nallowed, even the max_container_per_account condition has met.\n\nThis patch allows to process PUT requests for existing containers,\neven if max_container_per_account > = container count.\n\nIt indirectly resolve the bug 1306711, since swift-client\nuses internally PUT requests for container, prior it upload an\nobject there.\n\nChange-Id: I2dcf20b6feb27e346111466a565695eba4b4b1da\n'}, {'number': 3, 'created': '2014-07-11 08:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e009761cad032bdc92d6db2dfc91e6ef23ade00d', 'message': 'Container PUT requests and max container per account\n\nIf container counter per account is equal or greater than\nmax_container_per_account, then all PUT requests are failed and\n403 is returned.\nThis is correct behaviour if the request is to create a new\ncontainer, however if container already exists PUT should be\nallowed, even the max_container_per_account condition has met.\n\nThis patch allows to process PUT requests for existing containers,\neven if max_container_per_account > = container count.\n\nIt indirectly resolve the bug 1306711, since swift-client\nuses internally PUT requests for container, prior it upload an\nobject there.\n\nChange-Id: I2dcf20b6feb27e346111466a565695eba4b4b1da\n'}, {'number': 4, 'created': '2014-07-11 09:56:37.000000000', 'files': ['test/unit/proxy/test_server.py', 'swift/proxy/controllers/container.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e5d76e9f055805e1b44e4ee2f1898a5b9a0a354c', 'message': 'Container PUT requests and max container per account\n\nIf container counter per account is equal or greater than\nmax_container_per_account, then all PUT requests are failed and\n403 is returned.\nThis is correct behaviour if the request is to create a new\ncontainer, however if container already exists PUT should be\nallowed, even the max_container_per_account condition has met.\n\nThis patch allows to process PUT requests for existing containers,\neven if max_container_per_account > = container count.\n\nIt indirectly resolve the bug 1306711, since swift-client\nuses internally PUT requests for container, prior it upload an\nobject there.\n\nChange-Id: I2dcf20b6feb27e346111466a565695eba4b4b1da\n'}]",5,90016,e5d76e9f055805e1b44e4ee2f1898a5b9a0a354c,59,9,4,9205,,,0,"Container PUT requests and max container per account

If container counter per account is equal or greater than
max_container_per_account, then all PUT requests are failed and
403 is returned.
This is correct behaviour if the request is to create a new
container, however if container already exists PUT should be
allowed, even the max_container_per_account condition has met.

This patch allows to process PUT requests for existing containers,
even if max_container_per_account > = container count.

It indirectly resolve the bug 1306711, since swift-client
uses internally PUT requests for container, prior it upload an
object there.

Change-Id: I2dcf20b6feb27e346111466a565695eba4b4b1da
",git fetch https://review.opendev.org/openstack/swift refs/changes/16/90016/3 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/proxy/test_server.py', 'swift/proxy/controllers/container.py']",2,3fd9341be1e331c7182afbcc6581c5d222062ab0,bug/1306711," container_info = \ self.container_info(self.account_name, self.container_name, req) if container_info.get('status') < 200 or \ container_info.get('status') > 299: resp = HTTPForbidden(request=req) resp.body = 'Reached container limit of %s' % \ self.app.max_containers_per_account return resp", resp = HTTPForbidden(request=req) resp.body = 'Reached container limit of %s' % \ self.app.max_containers_per_account return resp,20,5
openstack%2Fnova~master~I44d77525ed7acdf34e8f67d0df2b5f1f0076aa20,openstack/nova,master,I44d77525ed7acdf34e8f67d0df2b5f1f0076aa20,libvirt: Add configdrive support to LXC,ABANDONED,2014-07-11 16:39:08.000000000,2014-07-16 20:25:15.000000000,,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5387}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-11 16:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72dac2c72764450d64db054c0d155b73d60bb418', 'message': ""libvirt: Add configdrive support to LXC\n\nAdds a new configdrive type called 'fs' which allows us to support\nconfigdrive within an LXC guest.\n\nMoves that configdrive directory into the guests rootfs on spawn, avoiding the\nneed for a bind-mount.\n\nCloses-Bug: 1340834\n\nChange-Id: I44d77525ed7acdf34e8f67d0df2b5f1f0076aa20\n""}, {'number': 2, 'created': '2014-07-11 18:28:55.000000000', 'files': ['nova/virt/libvirt/blockinfo.py', 'nova/virt/libvirt/driver.py', 'etc/nova/rootwrap.d/compute.filters', 'nova/virt/configdrive.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/241909059957903ad846f6f32e492866541d786d', 'message': ""libvirt: Add configdrive support to LXC\n\nAdds a new configdrive type called 'fs' which allows us to support\nconfigdrive within an LXC guest.\n\nMoves that configdrive directory into the guests rootfs on spawn, avoiding the\nneed for a bind-mount.\n\nCloses-Bug: 1340834\n\nChange-Id: I44d77525ed7acdf34e8f67d0df2b5f1f0076aa20\n""}]",5,106430,241909059957903ad846f6f32e492866541d786d,20,10,2,475,,,0,"libvirt: Add configdrive support to LXC

Adds a new configdrive type called 'fs' which allows us to support
configdrive within an LXC guest.

Moves that configdrive directory into the guests rootfs on spawn, avoiding the
need for a bind-mount.

Closes-Bug: 1340834

Change-Id: I44d77525ed7acdf34e8f67d0df2b5f1f0076aa20
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/106430/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/blockinfo.py', 'nova/virt/libvirt/driver.py', 'etc/nova/rootwrap.d/compute.filters', 'nova/tests/virt/libvirt/test_driver.py', 'nova/virt/configdrive.py']",5,72dac2c72764450d64db054c0d155b73d60bb418,bug/1340834," def _make_fs(self, path, tmpdir): shutil.copytree(tmpdir, path) os.chmod(path, 0o755) elif CONF.config_drive_format == 'fs': self._make_fs(path, tmpdir)",,65,1
openstack%2Fcinder-specs~master~If60fdb2a7d5c783ab12a2b1f9a2d64decf8e428b,openstack/cinder-specs,master,If60fdb2a7d5c783ab12a2b1f9a2d64decf8e428b,Proposal for incremental backup functionality,MERGED,2014-06-13 19:17:46.000000000,2014-07-16 20:20:34.000000000,2014-07-16 20:20:34.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 6491}, {'_account_id': 10068}, {'_account_id': 11923}]","[{'number': 1, 'created': '2014-06-13 19:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/7749105e3f7df118b143287ca1ea79b50ef70c6a', 'message': 'Proposal for incremental backup functionality\n\nChange-Id: If60fdb2a7d5c783ab12a2b1f9a2d64decf8e428b\n'}, {'number': 2, 'created': '2014-07-16 14:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/4cad3ca279f88a8199f1c26fcefc818e2e562833', 'message': 'Proposal for incremental backup functionality\n\nChange-Id: If60fdb2a7d5c783ab12a2b1f9a2d64decf8e428b\n'}, {'number': 3, 'created': '2014-07-16 14:35:20.000000000', 'files': ['specs/juno/incremental-backup.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/6b10ca66282eb2ee090e2fe70b6a125b7941d408', 'message': 'Proposal for incremental backup functionality\n\nChange-Id: If60fdb2a7d5c783ab12a2b1f9a2d64decf8e428b\n'}]",12,99995,6b10ca66282eb2ee090e2fe70b6a125b7941d408,22,5,3,11923,,,0,"Proposal for incremental backup functionality

Change-Id: If60fdb2a7d5c783ab12a2b1f9a2d64decf8e428b
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/95/99995/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/incremental-backup.rst'],1,7749105e3f7df118b143287ca1ea79b50ef70c6a,incremental-backup,"Proposal to implement incremental backup feature in Cinder This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================== Support for incremental backup in Cinder ======================================== Launchpad Blueprint: https://blueprints.launchpad.net/cinder/+spec/incremental-backup Problem description: ==================== The current implementation of Cinder Backup functionality only supports full backup and restore of a given volume. There is no provision to backup changes only that happened since last backup. As the volumes grow bigger and over all changes to volume between backups stay relatively small, copying entire volumes during backups will be resource intensive and do not scale well for larger deployments. This specification discusses implementation of incremental backup feature in detail. Proposed change: ================ Cinder backup API, by default uses swift as its backend. When a volume is backed up to Swift, swift creates a manifest file that describes the contents of the backup volume. The manifest file contains header (metadata) and array of pointers to the volume backup files. Since Swift has an upper limit on the object size, cinder backup api splits the volume data into individual chunks of swift object size and uploads these individual chunks to swift. Cinder volume backup manifest file includes these list of object, their corresponding size, the logical offset of each object within the volume and a message digest of each chunk to detect any unwarranted changes to objects. During restore operation, cinder reconstructs the volume based on the manifest and individual chunks referenced in the manifest. To support incremental backup functionality, we introduce another object called shafile to the list of backup files. This new object holds SHA256s of the volume. The backup manifest file will have a reference to this object. During a full backup operation, Cinder divides up the volume into fixed blocks of user configurable block size. It calculates SHA256 of each block and compiles a list of SHAs and uploads the shafile to the backup container. To keep the incremental backup implementation simple, an incremental operation is only performed with respect to a full backup. During incremental backup, cinder reads the shafile of the full backup. It creates a new shafile from the current volume data and compares the new shafile with full backup shafile to calculate the blocks that are changed since last full backup. We will use existing manifest mechanism to capture the delta. Since full backups do not contain any holes, offset+lengths of each chunk of the volume describe the full length of the volume logical address. However with incremental backups, this model is chanllenged and the offset/chunk of individual files become sparse. The absence of offset/length in a manifest represents the data is not modified since last backup. One potential drawback of this approach is if changes to volume are fragmented, incremental backups may result in too many objects in the swift. However object stores like swift are built to handle many small objects effectively. The new shafile is uploaded as part of the incremental backup. The manifest header identifies this backup as incremental backup and hence contains a reference to full backup container. Following changes are made to the manifest header of the backup metadata['version'] = self.DRIVER_VERSION metadata['backup_id'] = backup['id'] metadata['volume_id'] = volume_id metadata['backup_name'] = backup['display_name'] metadata['backup_description'] = backup['display_description'] metadata['created_at'] = str(backup['created_at']) # Changes to metadata section of manifest metadata['shafile'] = <shafilename> # Path to shafile name. Or # can be hardcoded to ""shafile"" # in the container metadata['backup_type'] = ""incrementa/full"" # backup type metadata['full_container'] = <object path> # path of full backup Restore API is not expected to change, however restore implementation will be changed to handle incremental backups. To keep the restore from incremental backups simple and easy to test, the restore operation first performs restore of the full volume from the full backup copy and then apply incremental changes at offset and length as described in the incremental backup manifest. Snapshot based backups ====================== Since existing backup implementation copies the data directly from the volume, it requires the volume to be detached from the instance. For most cloud workloads this may be sufficient but other workloads that cannot tolerate prolonged downtimes, a snapshot based backup solution can be a viable alternative. Snapshot based backup will perform a point in time copy of the volume and backup the data from point in time copy. This approach does not require volume to be detached from the instance. Rest of the backup and restore functionality remain the same. Alternatives ============ Incremental backups offer two important benefits: 1. Use less storage when storing backup images 2. Use less network bandwidth and improve overall efficiency of backup process in terms of CPU and time utilization The first benefit can be achieved as a post processing of the backup images to remove duplication or by using dedupe enabled backup storage. However the second benefit cannot be achieved unless cinder backup supports incremental backups. Snapshot based backups can be implemented by extending existing backup functionality to snapshot volumes. This approach can be lot more simpler than backup api taking snapshot of the volume and then managing the snapshots. Data model impact ================= No percieved data model changes REST API impact =============== No new apis are proposed. Instead existing backup api will be enhanced to accept additional option called ""--incr"" with <path to full backup container>"" as its argument. cinder backup-create <volumeid> —incr <full backup container> Performs incremental backup cinder backup-create <volumeid> —snapshot Optionally backup-create will backup a snapshot of the volume. cinder backup-create <volumeid> —snapshot —incr <full backup container> Optionally backup-create will perform incremental backup from volume snapshot No anticipated changes to restore api Security impact =============== None Notifications impact ==================== None Other end user impact ===================== python-cinderclient will be modified to accept ""--incr"" option. It may include some validation code to validate if the full backup container path is valid Currenly backup functionality is not integrated with openstack dashboard. When it happens, the dashboard will provide an option for user to choose increment backups Performance Impact ================== Except for calculating SHAs during full backup operation, there is no other performance impact on existing API. The performance penalty can be easily offset by the efficiency gained by incremental backups. Also new hardware support CPU instructions to calculate SHAs which alleviates some stress on the CPU cycles. Other deployer impact ===================== None Developer impact ================ None Implementation ============== Assignee(s) Primary assignee: Murali Balcha (murali.balcha@triliodata.com) Other contributors: Giri Basava (giri.basava@triliodata.com) Work Items ========== 1. python-cinderclient That accepts ""--incr"" option and some validation code 2. cinder/api Which parses the ""--incr"" option 3. cinder/backup/api.py backup api signature is modified 4. cinder/backup/manager.py 5. cinder/backup/driver/swift.py Heavy lifted is done here. Both backup and restore apis will be modified. Dependencies ============ None Testing ======= Testing will primarily focus on the following: 1. SHA file generation 2. Creating various changes to the original volume. These include 1. Changes to first block 2. Changes to last block 3. Changes to odd number of successive blocks 4. Changes to even number of successive blocks 5. Changes spread across multiple regions of the volume 3. Perform 1 incremental 4. Peform multiple incremental backups 5. Restore series of incremental backups and compare the contents 6. Perform full backup, then incremental, then full and then incremenal Restore the volume from various backups. Documentation Impact ==================== Need to document new option ",,224,0
openstack%2Fsolum~master~Ia9a6aa70fd28ee1b7af700480ac71021fd806f49,openstack/solum,master,Ia9a6aa70fd28ee1b7af700480ac71021fd806f49,Fix mistral's service_type,MERGED,2014-07-14 10:41:05.000000000,2014-07-16 19:59:32.000000000,2014-07-16 19:59:32.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}]","[{'number': 1, 'created': '2014-07-14 10:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5bf31531d73b3893d68c21cad5d653ac5f2b78af', 'message': 'Fix mistral\'s service_type\n\nMistral\'s service type has been changed to ""workflow""\n(from ""workflow_service"") to be more consistent with the\nother OpenStack service types.\n\nChange-Id: Ia9a6aa70fd28ee1b7af700480ac71021fd806f49\n'}, {'number': 2, 'created': '2014-07-16 10:52:16.000000000', 'files': ['solum/tests/common/test_clients.py', 'solum/common/clients.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/3d5c26518c2e19f4604435863f8cdc1e39fb1c2b', 'message': 'Fix mistral\'s service_type\n\nMistral\'s service type has been changed to ""workflow""\n(from ""workflow_service"") to be more consistent with the\nother OpenStack service types.\n\nChange-Id: Ia9a6aa70fd28ee1b7af700480ac71021fd806f49\n'}]",0,106728,3d5c26518c2e19f4604435863f8cdc1e39fb1c2b,22,5,2,4715,,,0,"Fix mistral's service_type

Mistral's service type has been changed to ""workflow""
(from ""workflow_service"") to be more consistent with the
other OpenStack service types.

Change-Id: Ia9a6aa70fd28ee1b7af700480ac71021fd806f49
",git fetch https://review.opendev.org/openstack/solum refs/changes/28/106728/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/tests/common/test_clients.py', 'solum/common/clients.py']",2,5bf31531d73b3893d68c21cad5d653ac5f2b78af,new-api," endpoint = self.url_for(service_type='workflow',"," endpoint = self.url_for(service_type='workflow_service',",2,2
openstack%2Fsecurity-doc~master~I415c57c560778553299ef57e66f591a26cd15bb5,openstack/security-doc,master,I415c57c560778553299ef57e66f591a26cd15bb5,Fix grammatical errors,MERGED,2014-07-16 19:36:48.000000000,2014-07-16 19:58:15.000000000,2014-07-16 19:58:15.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7063}]","[{'number': 1, 'created': '2014-07-16 19:36:48.000000000', 'files': ['security-guide/ch_security-boundaries-and-threats.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/4076a42a4d4ad0e45b585c19e4d3174f81b3d591', 'message': 'Fix grammatical errors\n\nChange-Id: I415c57c560778553299ef57e66f591a26cd15bb5\nCloses-Bug: #1342867\n'}]",0,107480,4076a42a4d4ad0e45b585c19e4d3174f81b3d591,8,3,1,7128,,,0,"Fix grammatical errors

Change-Id: I415c57c560778553299ef57e66f591a26cd15bb5
Closes-Bug: #1342867
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/80/107480/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_security-boundaries-and-threats.xml'],1,4076a42a4d4ad0e45b585c19e4d3174f81b3d591,bug-1342867," is one of the primary barriers for the adoption of public cloud infrastructures, as many of the previously mentioned controls do not exist.</para>"," is one of the primary barriers to adoption for the public cloud, as many of these controls do not exist.</para>",2,2
openstack%2Fpython-designateclient~master~Ic02858615833b516fd2c68a859146c8e018ae8e1,openstack/python-designateclient,master,Ic02858615833b516fd2c68a859146c8e018ae8e1,Enable hacking check H104,MERGED,2014-07-16 17:24:57.000000000,2014-07-16 19:57:40.000000000,2014-07-16 19:57:40.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}]","[{'number': 1, 'created': '2014-07-16 17:24:57.000000000', 'files': ['designateclient/tests/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/e9adf2a88f32e8df13556b39e8789448afa5f2b9', 'message': 'Enable hacking check H104\n\n* [H104] Files with no code shouldn’t contain any license\n         header nor comments, and must be left completely empty.\n\nChange-Id: Ic02858615833b516fd2c68a859146c8e018ae8e1\n'}]",0,107445,e9adf2a88f32e8df13556b39e8789448afa5f2b9,11,3,1,167,,,0,"Enable hacking check H104

* [H104] Files with no code shouldn’t contain any license
         header nor comments, and must be left completely empty.

Change-Id: Ic02858615833b516fd2c68a859146c8e018ae8e1
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/45/107445/1 && git format-patch -1 --stdout FETCH_HEAD,"['designateclient/tests/__init__.py', 'tox.ini']",2,e9adf2a88f32e8df13556b39e8789448afa5f2b9,enable_h104,"ignore = H302,H402,H404,H405,H904","# H104 file contains nothing more than commentsignore = H104,H302,H402,H404,H405,H904",1,15
openstack%2Ffuel-library~master~I47eabb0e5272bb8fdeac5fcd8d8173d9ce106202,openstack/fuel-library,master,I47eabb0e5272bb8fdeac5fcd8d8173d9ce106202,Make all nodes appear in mysql-wss config,MERGED,2014-07-15 14:47:54.000000000,2014-07-16 19:48:22.000000000,2014-07-16 14:06:42.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-07-15 14:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7b54544a88636bd439c423c12476897d1e62652f', 'message': 'Make all nodes appear in mysql-wss config\n\n* New Galera requires all nodes in the config\n* Remove unused galera_final_config class\n\nCloses-Bug: 1342128\n\nChange-Id: I47eabb0e5272bb8fdeac5fcd8d8173d9ce106202\n'}, {'number': 2, 'created': '2014-07-15 18:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/137fa71fd6350293534b4dc81a94b125b45cbf40', 'message': 'Make all nodes appear in mysql-wss config\n\n* New Galera requires all nodes in the config\n* Remove unused galera_final_config class\n\nCloses-Bug: 1342128\n\nChange-Id: I47eabb0e5272bb8fdeac5fcd8d8173d9ce106202\n'}, {'number': 3, 'created': '2014-07-15 19:43:04.000000000', 'files': ['deployment/puppet/galera/templates/wsrep.cnf.erb', 'deployment/puppet/galera/manifests/init.pp', 'deployment/puppet/galera/manifests/galera_master_final_config.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d6636dd02bde07993dcd875afd8c66e61e9ea31a', 'message': 'Make all nodes appear in mysql-wss config\n\n* New Galera requires all nodes in the config\n* Remove unused galera_final_config class\n\nCloses-Bug: 1342128\n\nChange-Id: I47eabb0e5272bb8fdeac5fcd8d8173d9ce106202\n'}]",0,107072,d6636dd02bde07993dcd875afd8c66e61e9ea31a,28,8,3,9037,,,0,"Make all nodes appear in mysql-wss config

* New Galera requires all nodes in the config
* Remove unused galera_final_config class

Closes-Bug: 1342128

Change-Id: I47eabb0e5272bb8fdeac5fcd8d8173d9ce106202
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/72/107072/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/galera/templates/wsrep.cnf.erb', 'deployment/puppet/galera/manifests/init.pp', 'deployment/puppet/galera/manifests/galera_master_final_config.pp']",3,7b54544a88636bd439c423c12476897d1e62652f,bug/1342128,,"# Copyright 2013 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # # == Define: galera_master_final_config # # Class for final configuring of galera master node. # # === Parameters # # [*primary_controller*] # Set to true if the node is primary controller/master of galera cluster. # [*node_addresses*] # Array of galera cluster node members IPs/hostnames. # # [*node_address*] # Name of the node used in galera cluster config. Can be IP/hostname. # class galera::galera_master_final_config ($primary_controller, $node_addresses, $node_address) { if $primary_controller { $galera_gcomm_string = inline_template(""<%= @node_addresses.reject{|ip| ip == @hostname || ip == @node_address || ip == @l3_fqdn_hostname }.collect {|ip| ip + ':' + 4567.to_s }.join ',' %>"" ) $check_galera = ""show status like 'wsrep_cluster_size';"" $mysql_user = $::galera::params::mysql_user $mysql_password = $::galera::params::mysql_password exec { ""first-galera-node-final-config"": path => ""/usr/bin:/usr/sbin:/bin:/sbin"", command => ""sed -i 's/wsrep_cluster_address=\""gcomm:\\/\\/\""\$/wsrep_cluster_address=\""gcomm:\\/\\/${galera_gcomm_string}\""/' /etc/mysql/conf.d/wsrep.cnf; sleep 15"", onlyif => ""sleep 15; mysql -u${mysql_user} -p${mysql_password} -e \""${check_galera}\"" && (mysql -u${mysql_user} -p${mysql_password} -e \""${check_galera}\"" | awk '\$1 == \""wsrep_cluster_size\"" {print \$2}' | awk '{if (\$0 > 1) exit 0; else exit 1}')"", logoutput => true, } } } ",3,57
openstack%2Foslo.db~master~Ib518e77b26cf61cac4acb6a7e9b851aafffcd855,openstack/oslo.db,master,Ib518e77b26cf61cac4acb6a7e9b851aafffcd855,Use explicit loops instead of list comprehensions,MERGED,2014-07-14 13:00:55.000000000,2014-07-16 19:46:50.000000000,2014-07-16 19:46:50.000000000,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 8871}, {'_account_id': 9656}, {'_account_id': 10068}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-07-14 13:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/7b1fb4638d299b93c0bbe2634da927727e6aa3fe', 'message': 'Use explicit loops instead of list comprehensions\n\nChanges only where list comprehensions were used instead of loops and their return values were not used\n\nChange-Id: Ib518e77b26cf61cac4acb6a7e9b851aafffcd855\n'}, {'number': 2, 'created': '2014-07-14 13:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/6950123291f75fef157f01ea94d1efefc321275f', 'message': 'Use explicit loops instead of list comprehensions\n\nChanges only where list comprehensions were used instead of loops and their\nreturn values were not used\n\nChange-Id: Ib518e77b26cf61cac4acb6a7e9b851aafffcd855\n'}, {'number': 3, 'created': '2014-07-14 13:27:48.000000000', 'files': ['oslo/db/sqlalchemy/utils.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/e68a53b7993e4cfe1ff037df8aef0b763b633b67', 'message': 'Use explicit loops instead of list comprehensions\n\nChanges only the places where list comprehensions were used instead of loops\nand their return values were not used\n\nChange-Id: Ib518e77b26cf61cac4acb6a7e9b851aafffcd855\n'}]",2,106760,e68a53b7993e4cfe1ff037df8aef0b763b633b67,27,7,3,12356,,,0,"Use explicit loops instead of list comprehensions

Changes only the places where list comprehensions were used instead of loops
and their return values were not used

Change-Id: Ib518e77b26cf61cac4acb6a7e9b851aafffcd855
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/60/106760/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/db/sqlalchemy/utils.py'],1,7b1fb4638d299b93c0bbe2634da927727e6aa3fe,rm-comprehensions, for index in indexes: index.create(migrate_engine) for index in indexes: index.create(migrate_engine), [index.create(migrate_engine) for index in indexes] [index.create(migrate_engine) for index in indexes],4,2
openstack%2Fneutron-specs~master~I014a472082d7efb03c103fd2e324a1e2361c3867,openstack/neutron-specs,master,I014a472082d7efb03c103fd2e324a1e2361c3867,Specification for Firewall Services on Cisco CSR1kv,MERGED,2014-07-08 06:47:24.000000000,2014-07-16 19:42:42.000000000,2014-07-16 19:42:41.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 333}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 6659}, {'_account_id': 6995}, {'_account_id': 7021}, {'_account_id': 7576}, {'_account_id': 7752}, {'_account_id': 8279}, {'_account_id': 10041}, {'_account_id': 10182}, {'_account_id': 10359}]","[{'number': 1, 'created': '2014-07-08 06:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3e20af4e93f5ce049545df0152d735a53eb454c3', 'message': 'Specification for Firewall Services on Cisco CSR1kv\n\nSpecification addresses the Cisco CSR1kv Service Plugin and\nassociated Agent design.\n\nfwaas-cisco\n\nChange-Id: I014a472082d7efb03c103fd2e324a1e2361c3867\n'}, {'number': 2, 'created': '2014-07-08 08:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ca3676d97294c629813311eb3565f6eb393a5fea', 'message': 'Specification for Firewall Services on Cisco CSR1kv\n\nSpecification addresses the Cisco CSR1kv Service Plugin and\nassociated Agent design.\n\nfwaas-cisco\n\nChange-Id: I014a472082d7efb03c103fd2e324a1e2361c3867\n'}, {'number': 3, 'created': '2014-07-09 05:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8b13260346196d8879fe08d84ec583629eebdaad', 'message': 'Specification for Firewall Services on Cisco CSR1kv\n\nSpecification addresses the Cisco CSR1kv Service Plugin and\nassociated Agent design.\n\nfwaas-cisco\n\nChange-Id: I014a472082d7efb03c103fd2e324a1e2361c3867\n'}, {'number': 4, 'created': '2014-07-10 22:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/671b52d34be71794d6a89796bf584af6b673ab08', 'message': 'Specification for Firewall Services on Cisco CSR1kv\n\nSpecification addresses the Cisco CSR1kv Service Plugin and\nassociated Agent design.\n\nfwaas-cisco\n\nChange-Id: I014a472082d7efb03c103fd2e324a1e2361c3867\n'}, {'number': 5, 'created': '2014-07-11 01:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d905d7405b54118a6c626931faf8dc0c53fa703f', 'message': 'Specification for Firewall Services on Cisco CSR1kv\n\nSpecification addresses the Cisco CSR1kv Service Plugin and\nassociated Agent design.\n\nImplements: blueprint fwaas-cisco\n\nChange-Id: I014a472082d7efb03c103fd2e324a1e2361c3867\n'}, {'number': 6, 'created': '2014-07-14 05:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9c04d215f77baaf36f0e5a138e65afa903e7966a', 'message': 'Specification for Firewall Services on Cisco CSR1kv\n\nSpecification addresses the Cisco CSR1kv Service Plugin and\nassociated Agent design.\n\nImplements: blueprint fwaas-cisco\n\nChange-Id: I014a472082d7efb03c103fd2e324a1e2361c3867\n'}, {'number': 7, 'created': '2014-07-14 05:43:57.000000000', 'files': ['specs/juno/fwaas-cisco.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d684e13c09b9fbdce6f622d33d83bcc678f47352', 'message': 'Specification for Firewall Services on Cisco CSR1kv\n\nSpecification addresses the Cisco CSR1kv Service Plugin and\nassociated Agent design.\n\nImplements: blueprint fwaas-cisco\n\nChange-Id: I014a472082d7efb03c103fd2e324a1e2361c3867\n'}]",22,105373,d684e13c09b9fbdce6f622d33d83bcc678f47352,41,15,7,6995,,,0,"Specification for Firewall Services on Cisco CSR1kv

Specification addresses the Cisco CSR1kv Service Plugin and
associated Agent design.

Implements: blueprint fwaas-cisco

Change-Id: I014a472082d7efb03c103fd2e324a1e2361c3867
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/73/105373/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/fwaas-cisco.rst'],1,3e20af4e93f5ce049545df0152d735a53eb454c3,bp/fwaas-cisco,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================= FWaaS Implementation for Cisco Virtual Router ============================================= https://blueprints.launchpad.net/neutron/+spec/fwaas-cisco Problem description =================== The Cisco Virtual Router implementation (CSR1kv) also supports services such as Firewall and VPN in addition to Routing. This blueprint targets support of CSR1kv as a vendor backend for neutron FWaaS. The CSR1kv, as a backend will allow implementing the Firewall functionality on any of its interfaces on traffic either ingressing or egressing the specified interface as specified. Proposed change =============== Implementation targetted as a Service Plugin and will be refactored to align with the Flavor Framework post Juno. Also given that the Service Insertion BP[3] is in discussion, the initial implementation will be done using Vendor extension attributes to capture the insertion points of the service in as simple a form as possible. This will be refactored to align with the community post Juno. Supporting the CSR1kv requires: - Additional vendor attributes to specify firewall insertion points (neutron port corresponding to router interface and associated direction). Supported as vendor extension attributes as a simple model that will be refactored to adopt the Service Insertion BP when available. The ""extraroute"" approach will be taken to add the neeeded attributes of port and direction without any changes to the client. - Introduce new table to track insertion points of a firewall resource in the vendor plugin. - Interaction with the CSR1kv Routing Service Plugin[1] which is limited to querying for the hosting VM and some validation for the attached interface. - Add validators for the attribute extensions to conform to vendor implementation constraints. - Agent support for Firewall built on Cisco Config Agent[2] as a service agent to handle messaging with the plugin along with the messaging interfaces (firewall dict, plugin API and agent API) mostly along the lines of the reference implementation. - Agent to backend communication using existing vendor REST communication library. Alternatives ------------ The ideal approach is to base it on the flavor framework and service insertion BP's. But given that these are WIP, this is being proposed as a Service Plugin which will be refactored to align with the community model when available. Data model impact ----------------- There are no changes planned to existing Firewall resources (FirewallRule, FirewallPolicy and Firewalls). The insertion point attributes are tracked by introducing a new table CiscoFirewallAssociation: * fw - uuid of logical firewall resource * portid - uuid of neutron port corresponding to router interface * direction - direction of traffic on the portid to apply firewall on can be: - ingress - egress - bidirectional REST API impact --------------- No new REST API is introduced. Security impact --------------- None. Notifications impact -------------------- None to existing. New topic for messaging between the plugin and agent. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- Deployer will have to enable the CSR1kv Routing Service Plugin, the Cisco Config Agent in addition the CSR1kv Firewall Service Plugin being proposed here. There is no impact to the community implementation when this is not enabled. Developer impact ---------------- None. Implementation ============== Neutron Server +---+---------------------+--------+ +-----------+ | +---------------------+ | |Cisco Cfg | | | CSR1kv Routing | | | Agent | | | Service Plugin | | | | | | | | | | | | | | | | | +---------------------+ | +----+------+ | ^ | |CSR1|kv Firewall | | | |Agen|t* | | +------------------------>| |<---+ | v | | +----+ | Cisco | +------------------v--+ | | Device specific | | CSR1kv Firewall | | v REST i/f | | Service Plugin* | | +------+ | | | | |CSR1kv| | | | | | VM | | +---------------------+ | | | | | | | | | +------+ | | | | +----------------------------------+ The above figure is a representation of the CSR1kv components and interactions. The CSR1kv Routing Service Plugin [1] and the Cisco Config Agent[2] are being addressed in separate BP's. The work being targetted here are the two items suffixed with a '*' and their interfaces to the existing components. Assignee(s) ----------- Primary assignee: skandasw Other contributors: yanping Work Items ---------- Service Plugin with vendor extension attributes for the Firewall Resource. API & DB changes for the vendor specific extensions. Cisco CSR1kv FWaaS service agent addition to the Cisco config Agent[2]. Dependencies ============ https://blueprints.launchpad.net/neutron/+spec/cisco-routing-service-vm https://blueprints.launchpad.net/neutron/+spec/cisco-config-agent Testing ======= Unit tests, Tempest API tests and support for Vendor CI framework will be addressed. Scenario tests will be attempted based on the tests available for the reference implementation. Documentation Impact ==================== Will require new documentation in Cisco sections. References ========== [1]https://blueprints.launchpad.net/neutron/+spec/cisco-routing-service-vm [2]https://blueprints.launchpad.net/neutron/+spec/cisco-config-agent [3]https://blueprints.launchpad.net/neutron/+spec/\ service-base-class-and-insertion ",,166,0
openstack%2Fneutron~master~I73bbb264dfbe32cacbd65c12863e4bf2501dcbe6,openstack/neutron,master,I73bbb264dfbe32cacbd65c12863e4bf2501dcbe6,Use auth_token from keystonemiddleware,ABANDONED,2014-07-15 18:34:03.000000000,2014-07-16 19:36:04.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-15 18:34:03.000000000', 'files': ['etc/api-paste.ini', 'requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/373caaf2b3584a09828c3e6d4f0ba2d9de7faec9', 'message': 'Use auth_token from keystonemiddleware\n\nauth_token middleware in python-keystoneclient is deprecated and has\nbeen moved to the keystonemiddleware repo.\n\nChange-Id: I73bbb264dfbe32cacbd65c12863e4bf2501dcbe6\n'}]",0,107146,373caaf2b3584a09828c3e6d4f0ba2d9de7faec9,14,12,1,4395,,,0,"Use auth_token from keystonemiddleware

auth_token middleware in python-keystoneclient is deprecated and has
been moved to the keystonemiddleware repo.

Change-Id: I73bbb264dfbe32cacbd65c12863e4bf2501dcbe6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/107146/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/api-paste.ini', 'requirements.txt']",2,373caaf2b3584a09828c3e6d4f0ba2d9de7faec9,,keystonemiddleware,,2,1
openstack%2Fdesignate~master~Ib2250a4f43a1f9fa4e0d01ba7c9195907afc9c31,openstack/designate,master,Ib2250a4f43a1f9fa4e0d01ba7c9195907afc9c31,Add validate_log_translations flake8 check,MERGED,2014-07-16 12:15:04.000000000,2014-07-16 19:35:57.000000000,2014-07-16 19:35:56.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-07-16 12:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c3afbe13bc925740b219da488571940590e5fa2d', 'message': 'Add validate_log_translations flake8 check\n\nThis check ensures all logging calls outside of the tests are\ntranslated. Regex copied from nova/hacking/checks.py.\n\nChange-Id: Ib2250a4f43a1f9fa4e0d01ba7c9195907afc9c31\n'}, {'number': 2, 'created': '2014-07-16 12:16:47.000000000', 'files': ['designate/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/1b7e68c3bdfc2f43f754cc39e1f2f80bfa5bee80', 'message': 'Add validate_log_translations flake8 check\n\nThis check ensures all logging calls outside of the tests are\ntranslated. Regex copied from nova/hacking/checks.py.\n\nChange-Id: Ib2250a4f43a1f9fa4e0d01ba7c9195907afc9c31\n'}]",0,107340,1b7e68c3bdfc2f43f754cc39e1f2f80bfa5bee80,18,4,2,741,,,0,"Add validate_log_translations flake8 check

This check ensures all logging calls outside of the tests are
translated. Regex copied from nova/hacking/checks.py.

Change-Id: Ib2250a4f43a1f9fa4e0d01ba7c9195907afc9c31
",git fetch https://review.opendev.org/openstack/designate refs/changes/40/107340/2 && git format-patch -1 --stdout FETCH_HEAD,['designate/hacking/checks.py'],1,c3afbe13bc925740b219da488571940590e5fa2d,,"import pep8 log_translation = re.compile( r""(.)*LOG\.(audit|error|info|warn|warning|critical|exception)\(\s*('|\"")"") if pep8.noqa(logical_line): return def validate_log_translations(logical_line, physical_line, filename): # Translations are not required in the test directory if ""designate/tests"" in filename: return if pep8.noqa(physical_line): return msg = ""D702: Log messages require translation"" if log_translation.match(logical_line): yield (0, msg) register(validate_log_translations)",,20,0
openstack%2Fsahara-image-elements~master~I0368eb12a6c06c8fc900c0f9cca94758437de1df,openstack/sahara-image-elements,master,I0368eb12a6c06c8fc900c0f9cca94758437de1df,Building Cloudera hadoop images with Cloudera Manager,MERGED,2014-07-11 11:12:15.000000000,2014-07-16 19:35:12.000000000,2014-07-16 19:35:12.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8090}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-07-11 11:12:15.000000000', 'files': ['elements/hadoop-cloudera/pre-install.d/10-add-mirror', 'diskimage-create/README.rst', 'elements/hadoop-cloudera/README.rst', 'elements/hadoop-cloudera/element-deps', 'diskimage-create/diskimage-create.sh', 'elements/hadoop-cloudera/install.d/50-install-cloudera', 'elements/hadoop-cloudera/post-install.d/70-turn-services-off'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/76ae53ad42a2b69355131aba67077ebd05788f29', 'message': 'Building Cloudera hadoop images with Cloudera Manager\n\n* Add element hadoop-cloudera to install Cloudera hadoop packages\n* Edit diskimage-create script to build Cloudera images\n\nPartial implements blueprint cdh-plugin\n\nChange-Id: I0368eb12a6c06c8fc900c0f9cca94758437de1df\n'}]",0,106331,76ae53ad42a2b69355131aba67077ebd05788f29,22,8,1,7732,,,0,"Building Cloudera hadoop images with Cloudera Manager

* Add element hadoop-cloudera to install Cloudera hadoop packages
* Edit diskimage-create script to build Cloudera images

Partial implements blueprint cdh-plugin

Change-Id: I0368eb12a6c06c8fc900c0f9cca94758437de1df
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/31/106331/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/hadoop-cloudera/pre-install.d/10-add-mirror', 'diskimage-create/README.rst', 'elements/hadoop-cloudera/README.rst', 'elements/hadoop-cloudera/element-deps', 'diskimage-create/diskimage-create.sh', 'elements/hadoop-cloudera/install.d/50-install-cloudera', 'elements/hadoop-cloudera/post-install.d/70-turn-services-off']",7,76ae53ad42a2b69355131aba67077ebd05788f29,bp/cdh-plugin,#!/bin/bash set -eux for i in cloudera-scm-agent \ cloudera-scm-server \ cloudera-scm-server-db \ hadoop-hdfs-datanode \ hadoop-hdfs-namenode \ hadoop-hdfs-secondarynamenode \ hadoop-mapreduce-historyserver \ hadoop-yarn-nodemanager \ hadoop-yarn-resourcemanager \ oozie \ postgresql do if [ $(lsb_release -is) = 'Ubuntu' ]; then update-rc.d -f $i remove else chkconfig $i off fi done if [ $(lsb_release -is) = 'CentOS' ]; then chkconfig iptables off chkconfig ip6tables off fi ,,122,6
openstack%2Ftempest~master~Icf57589a8dcd914a45aff9072de4b669c359b392,openstack/tempest,master,Icf57589a8dcd914a45aff9072de4b669c359b392,Add compute feature attach_volume,ABANDONED,2014-07-11 19:14:26.000000000,2014-07-16 19:33:26.000000000,,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-11 19:14:26.000000000', 'files': ['tempest/api/compute/servers/test_delete_server.py', 'etc/tempest.conf.sample', 'tempest/api/compute/v3/servers/test_server_rescue_negative.py', 'tempest/api/volume/test_volumes_negative.py', 'tempest/api/compute/v3/test_live_block_migration.py', 'tempest/api/volume/test_volumes_actions.py', 'tempest/api/compute/v3/servers/test_attach_volume.py', 'tempest/api/compute/volumes/test_attach_volume.py', 'tempest/api/compute/v3/servers/test_delete_server.py', 'tempest/config.py', 'tempest/api/compute/test_live_block_migration.py', 'tempest/api/compute/servers/test_server_rescue_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/02df242a4d9ff23c501e931e71999035c6056c7b', 'message': 'Add compute feature attach_volume\n\nAllow support for specifying if volume attachment is supported.\nDefault behavior will match existing behavior (assumes it IS\nsupported).\n\nThe api.volume.test_volumes_actions test class was modified to\nnot create a test instance in the setUp call. This is to prevent\nneedless instance creation if a test is skipped, thus speeding\nup testing.\n\nChange-Id: Icf57589a8dcd914a45aff9072de4b669c359b392\n'}]",0,106472,02df242a4d9ff23c501e931e71999035c6056c7b,11,6,1,3099,,,0,"Add compute feature attach_volume

Allow support for specifying if volume attachment is supported.
Default behavior will match existing behavior (assumes it IS
supported).

The api.volume.test_volumes_actions test class was modified to
not create a test instance in the setUp call. This is to prevent
needless instance creation if a test is skipped, thus speeding
up testing.

Change-Id: Icf57589a8dcd914a45aff9072de4b669c359b392
",git fetch https://review.opendev.org/openstack/tempest refs/changes/72/106472/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_delete_server.py', 'etc/tempest.conf.sample', 'tempest/api/compute/v3/servers/test_server_rescue_negative.py', 'tempest/api/volume/test_volumes_negative.py', 'tempest/api/compute/v3/test_live_block_migration.py', 'tempest/api/volume/test_volumes_actions.py', 'tempest/api/compute/v3/servers/test_attach_volume.py', 'tempest/api/compute/volumes/test_attach_volume.py', 'tempest/api/compute/v3/servers/test_delete_server.py', 'tempest/config.py', 'tempest/api/compute/test_live_block_migration.py', 'tempest/api/compute/servers/test_server_rescue_negative.py']",12,02df242a4d9ff23c501e931e71999035c6056c7b,attach_volume," @testtools.skipUnless(CONF.compute_feature_enabled.attach_volume, 'Volume attachment is not available.') @testtools.skipUnless(CONF.compute_feature_enabled.attach_volume, 'Volume attachment is not available.')",,68,19
openstack%2Fswift~master~I643d7083a2a310fc3d24eab48c565f3798cff25f,openstack/swift,master,I643d7083a2a310fc3d24eab48c565f3798cff25f,clean up saio env. after runnning func tests,MERGED,2014-07-11 15:21:47.000000000,2014-07-16 19:20:15.000000000,2014-07-16 19:20:15.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8542}, {'_account_id': 9625}]","[{'number': 1, 'created': '2014-07-11 15:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/08d745fccf737354555af91bbbf468dfca7419b2', 'message': 'clean up saio env. after runnning func tests\n\nAdded call to delete container in teardown_package().\nTests are leaving objects and containers in saio environment\nafter finishing running the tests.\n\nCurrently, delete_containers() is called in the setUp of each test\nclass, which cleans up the containers of the previous test,\nbut leaves the containers of the last test in the saio environment.\n\nChange-Id: I643d7083a2a310fc3d24eab48c565f3798cff25f\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 2, 'created': '2014-07-11 18:25:58.000000000', 'files': ['test/functional/__init__.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e5d90a9cc3f784d23a4248a50a99287af6b99cc3', 'message': 'clean up saio env. after runnning func tests\n\nAdded call to delete container in teardown_package().\nTests are leaving objects and containers in saio environment\nafter finishing running the tests.\n\nCurrently, delete_containers() is called in the setUp of each test\nclass, which cleans up the containers of the previous test,\nbut leaves the containers of the last test in the saio environment.\n\nChange-Id: I643d7083a2a310fc3d24eab48c565f3798cff25f\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}]",4,106398,e5d90a9cc3f784d23a4248a50a99287af6b99cc3,21,10,2,9625,,,0,"clean up saio env. after runnning func tests

Added call to delete container in teardown_package().
Tests are leaving objects and containers in saio environment
after finishing running the tests.

Currently, delete_containers() is called in the setUp of each test
class, which cleans up the containers of the previous test,
but leaves the containers of the last test in the saio environment.

Change-Id: I643d7083a2a310fc3d24eab48c565f3798cff25f
Signed-off-by: Thiago da Silva <thiago@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/98/106398/2 && git format-patch -1 --stdout FETCH_HEAD,['test/functional/__init__.py'],1,08d745fccf737354555af91bbbf468dfca7419b2,cleanup_after_functest,"from test.functional.swift_test_client import Account, Connection, \ ResponseError # clean up containers and objects left behind after running tests global config conn = Connection(config) conn.authenticate() account = Account(conn, config.get('account', config['username'])) account.delete_containers() ","from test.functional.swift_test_client import Connection, ResponseError",9,1
openstack%2Fapi-site~master~If086475ab8d8d201fd72df8dffc598ec8ecb0a85,openstack/api-site,master,If086475ab8d8d201fd72df8dffc598ec8ecb0a85,Adds additional explanation for how to halt container sync with Object Storage API,MERGED,2014-07-14 22:40:45.000000000,2014-07-16 19:13:15.000000000,2014-07-16 19:13:15.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-07-14 22:40:45.000000000', 'files': ['api-ref/src/wadls/object-api/src/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/bccc21e20101950c8e834e804ed1bde740d2ce41', 'message': 'Adds additional explanation for how to halt container sync with Object Storage API\n\nChange-Id: If086475ab8d8d201fd72df8dffc598ec8ecb0a85\nCloses-bug: 1341813\n'}]",0,106887,bccc21e20101950c8e834e804ed1bde740d2ce41,10,3,1,964,,,0,"Adds additional explanation for how to halt container sync with Object Storage API

Change-Id: If086475ab8d8d201fd72df8dffc598ec8ecb0a85
Closes-bug: 1341813
",git fetch https://review.opendev.org/openstack/api-site refs/changes/87/106887/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/object-api/src/common.ent'],1,bccc21e20101950c8e834e804ed1bde740d2ce41,bug/1341813," <para>Sets the secret key for container synchronization. If you remove the secret key, synchronization is halted.</para> <para>Sets the destination for container synchronization. Used with the secret key indicated in the <code>X-Container-Sync-Key</code> header. If you want to stop a container from synchronizing, send a blank value for the <code>X-Container-Sync-Key</code> header.</para>", <para>Sets the secret key for container synchronization.</para> <para>Sets the destination for container synchronization.</para>,7,2
openstack%2Fneutron-specs~master~I0761c0a2f70d53c7be204ef76d7256902f900caa,openstack/neutron-specs,master,I0761c0a2f70d53c7be204ef76d7256902f900caa,Move title length check after name check,MERGED,2014-07-11 05:14:32.000000000,2014-07-16 19:11:15.000000000,2014-07-16 19:11:15.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 5948}, {'_account_id': 7787}]","[{'number': 1, 'created': '2014-07-11 05:14:32.000000000', 'files': ['tests/test_titles.py'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c645491454a2aca5e6928af7556327c03476683c', 'message': ""Move title length check after name check\n\nDon't check the number of titles in the spec until\nafter the individual sections are checked for. This\nmakes it easier to find which section is missing\nby having an assertIn failure for the name instead\nof an assertEqual failure on the length.\n\nChange-Id: I0761c0a2f70d53c7be204ef76d7256902f900caa\n""}]",2,106270,c645491454a2aca5e6928af7556327c03476683c,14,6,1,7787,,,0,"Move title length check after name check

Don't check the number of titles in the spec until
after the individual sections are checked for. This
makes it easier to find which section is missing
by having an assertIn failure for the name instead
of an assertEqual failure on the length.

Change-Id: I0761c0a2f70d53c7be204ef76d7256902f900caa
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/70/106270/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_titles.py'],1,c645491454a2aca5e6928af7556327c03476683c,utcheck," self.assertEqual(7, len(titles)) "," self.assertEqual(7, len(titles)) ",2,2
openstack%2Fneutron-specs~master~I5fdb15bd780c2ce7262c68a230f49d7335a463fd,openstack/neutron-specs,master,I5fdb15bd780c2ce7262c68a230f49d7335a463fd,Describes design of router service plugin for Cisco devices.,MERGED,2014-04-29 15:27:50.000000000,2014-07-16 19:09:11.000000000,2014-07-16 19:09:11.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 333}, {'_account_id': 704}, {'_account_id': 2031}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 9375}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-04-29 15:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/cc400b42491517dccdd3c7ca77256c75a1a2a72f', 'message': 'Specification for review\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 2, 'created': '2014-04-29 15:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/23e3c1ed3cbd32f906ecb16a9bd9dd99b4b442b7', 'message': 'Specification for review\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 3, 'created': '2014-04-30 08:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8538b8a225b1150f1e55af4a1023916295834bbd', 'message': 'Describes design of new router service plugin\n\n- Introduces routertype attribute to Neutron routers.\n- Instantiates router in a device matching the routertype of the router.\n- Routers that cannot be instantiated are backlogged until suitable\n  device to host the router is available.\n- The plugin can also create traditional Neutron network namespace routers.\n  A routertype is used for such routers.\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 4, 'created': '2014-04-30 09:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2ff8a8073c5d7e085b10679ddab6a31c2fe370eb', 'message': 'Describes design of new router service plugin\n\n- Introduces routertype attribute to Neutron routers.\n- Instantiates router in a device matching the routertype of the router.\n- Routers that cannot be instantiated are backlogged until suitable\n  device to host the router is available.\n- The plugin can also create traditional Neutron network namespace routers.\n  A routertype is used for such routers.\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 5, 'created': '2014-04-30 09:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e7a9ec4edb612d6ab1c4a07d3ab660d7d35da9d2', 'message': 'Describes design of new router service plugin\n\n- Introduces routertype attribute to Neutron routers.\n- Instantiates router in a device matching the routertype of the router.\n- Routers that cannot be instantiated are backlogged until suitable\n  device to host the router is available.\n- The plugin can also create traditional Neutron network namespace routers.\n  A routertype is used for such routers.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 6, 'created': '2014-04-30 10:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d879487eadfb43a5b96b569d34c742fb62ac2166', 'message': 'Describes design of new router service plugin\n\n- Introduces routertype attribute to Neutron routers.\n- Instantiates router in a device matching the routertype of the router.\n- Routers that cannot be instantiated are backlogged until suitable\n  device to host the router is available.\n- The plugin can also create traditional Neutron network namespace routers.\n  A routertype is used for such routers.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 7, 'created': '2014-06-12 08:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b71de0fc26f386ff8adc725bfcaf12595f148ab6', 'message': 'Describes design of router service plugin for Cisco devices.\n\n- Instantiates Neutron router in a Cisco CSR1kv device.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 8, 'created': '2014-06-12 08:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/860c25be181a5721198cc4c259f3d7b47e6a6f1a', 'message': 'Describes design of router service plugin for Cisco devices.\n\n- Instantiates Neutron router in a Cisco CSR1kv device.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 9, 'created': '2014-06-13 08:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a5f26a6752d641a62b2465dd5deb9dedfc0c10a9', 'message': 'Describes design of router service plugin for Cisco devices.\n\n- Instantiates Neutron router in a Cisco CSR1kv device.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 10, 'created': '2014-06-13 08:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0e4b98303bdbbff6d199f68f4861bf085a5df048', 'message': 'Describes design of router service plugin for Cisco devices.\n\n- Instantiates Neutron router in a Cisco CSR1kv device.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 11, 'created': '2014-06-13 09:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d4e4ac2c5a9dcfc01fc4a755f495d487830b16d0', 'message': 'Describes design of router service plugin for Cisco devices.\n\n- Instantiates Neutron router in a Cisco CSR1kv device.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 12, 'created': '2014-07-06 22:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d76c2083f9702830e8f50ac41171f9262585d3d3', 'message': 'Describes design of router service plugin for Cisco devices.\n\n- Instantiates Neutron router in a Cisco CSR1kv device.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 13, 'created': '2014-07-06 22:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b30ad7973cf8c77ce421e3513c97ad8e979f23ba', 'message': 'Describes design of router service plugin for Cisco devices.\n\n- Instantiates Neutron router in a Cisco CSR1kv device.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 14, 'created': '2014-07-15 20:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/dca165770a32b4e2a598e4ed829204b7287bc2a5', 'message': 'Describes design of router service plugin for Cisco devices.\n\n- Instantiates Neutron router in a Cisco CSR1kv device.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}, {'number': 15, 'created': '2014-07-15 21:08:08.000000000', 'files': ['specs/juno/cisco-routing-service-vm.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7ab4365718f786ca96cac5b7042ebbca3e7c8b60', 'message': 'Describes design of router service plugin for Cisco devices.\n\n- Instantiates Neutron router in a Cisco CSR1kv device.\n\n  cisco-routing-service-vm\n\nChange-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd\n'}]",26,91071,7ab4365718f786ca96cac5b7042ebbca3e7c8b60,84,10,15,162,,,0,"Describes design of router service plugin for Cisco devices.

- Instantiates Neutron router in a Cisco CSR1kv device.

  cisco-routing-service-vm

Change-Id: I5fdb15bd780c2ce7262c68a230f49d7335a463fd
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/71/91071/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/cisco-routing-service-vm.rst'],1,cc400b42491517dccdd3c7ca77256c75a1a2a72f,bp/cisco-routing-service-vm,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================================= Neutron routing service implemented using Cisco VM (and physical devices) ========================================================================= https://blueprints.launchpad.net/neutron/+spec/cisco-routing-service-vm Problem description =================== There is need to support Neutron's routing service implemented in virtual machines (or hardware devices). This blueprint targets that use case. In particular it implements routing using the Cisco CSR1kv VM devices. It can also handle routing capable hardware devices. Though targeted for a variety of Cisco products, the design could also be useful to the larger community. Proposed change =============== - The implementation is done as a separate routing service plugin. - Introduction of ``routertype`` resource that can be CRUD. - Introduction of ``routertype_id`` attribute to Neutron routers. - Introduction of binding table to associate routertype with hosting device template (the latter is defined and implemented in BP/patch for https://blueprints.launchpad.net/neutron/+spec/device-manager-service-plugin) - Introduction of binding table to associate Neutron router with hosting device (that latter also defined and implemented in BP/patch: https://blueprints.launchpad.net/neutron/+spec/device-manager-service-plugin) - RPC Notifications and callbacks for interactions with Cisco configuration agent (the latter defined and implemented in BP/patch: https://blueprints.launchpad.net/neutron/+spec/cisco-config-agent) - Interactions with routertype-aware l3agent scheduler (the latter defined and implemented in BP/patch: https://blueprints.launchpad.net/neutron/+spec/device-manager-service-plugin) Alternatives ------------ This could have been done as part of refactoring the existing routing service plugin. However, this path was not taken in order to reduce impact as there is a broader discussion in the community about L3 router modularization, flavor framework etc. Data model impact ----------------- The basic l3 routing data models are extended via the regular Neutron extension mechanism. The base classes will not be modified. Two new DB tables: **routertypes** and **routerhostingdevicebindings** :: class RouterType(model_base.BASEV2, models_v2.HasId): """"""Represents Neutron router types. A router type is associated with a with hosting device template. The template is used when hosting device for the router type is created. Only 'id', 'name', 'description' are visible in non-admin context. """""" # name of router type, should preferably be unique name = sa.Column(sa.String(255), nullable=False) # description of this router type description = sa.Column(sa.String(255)) # template to use to create hosting devices for this router type template_id = sa.Column(sa.String(36), sa.ForeignKey('hostingdevicetemplates.id', ondelete='CASCADE')) template = orm.relationship(hd_models.HostingDeviceTemplate) # 'shared' is True if this routertype is available to all tenants shared = sa.Column(sa.Boolean, default=True, nullable=False) # The number of slots this router type consume in hosting device slot_need = sa.Column(sa.Integer, autoincrement=False) # module to be used as scheduler for router of this type scheduler = sa.Column(sa.String(255), nullable=False) # module to be used by configuration agent for router of this type cfg_agent_driver = sa.Column(sa.String(255), nullable=False) class RouterHostingDeviceBinding(model_base.BASEV2): """"""Represents binding between Neutron routers and their hosting devices."""""" router_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id', ondelete='CASCADE'), primary_key=True) router = orm.relationship(l3_db.Router) # 'router_type_id' is id of router type for this router router_type_id = sa.Column( sa.String(36), sa.ForeignKey('routertypes.id'), primary_key=True, nullable=False) router_type = orm.relationship(RouterType) # If 'auto_schedule' is True then router is automatically scheduled # if it lacks a hosting device or its hosting device fails. auto_schedule = sa.Column(sa.Boolean, default=True, nullable=False) share_hosting_device = sa.Column(sa.Boolean, default=True, nullable=False) # id of hosting device hosting this router, None/NULL if unscheduled. hosting_device_id = sa.Column(sa.String(36), sa.ForeignKey('hostingdevices.id', ondelete='SET NULL')) hosting_device = orm.relationship(hd_models.HostingDevice)"" REST API impact --------------- The basic l3 routing service REST API remains intact. A new attribute ``routertype_id`` is added to the Neutron router resource via an extension named ``routertype``. This extension introduces a new resource called ``routertype``. The **routertype_id** attribute: +------------------+---------+---------+---------+-------------+---------------+ | Attribute | Type | Access | Default | Validation/ | Description | | Name | | | Value | Conversion | | +==================+=========+=========+=========+=============+===============+ | routertype_id | string | RW | Set by | uuid | router type | | | (UUID) | all | option | | for router | +------------------+---------+---------+---------+-------------+---------------+ The **router type** resource: +------------------+---------+-----------+---------+------------+--------------+ | Attribute Name | Type | Access | Default |Validation/ |Description | | | | | Value |Conversion | | +==================+=========+===========+=========+============+==============+ | id | string | RO, all | generate| | | | | (UUID) | | | | | +------------------+---------+-----------+---------+------------+--------------+ | name | string | R all, | None |string | type name | | | | W admin | |or none | | +------------------+---------+-----------+---------+------------+--------------+ | description | string | R all, | None |string | | | | | W admin | |or none | | +------------------+---------+-----------+---------+------------+--------------+ | tenant_id | string | RO, admin | | uuid | tenant id | | | (UUID) | set in Cr | | | | +------------------+---------+-----------+---------+------------+--------------+ | shared | boolean | RO, all | True | boolean | True if | | | | | | | available to | | | | | | | all tenants | +------------------+---------+-----------+---------+------------+--------------+ | template_id | string | RO, admin | | uuid | hosting | | | (UUID) | set in Cr | | | device | | | | | | | template id | +------------------+---------+-----------+---------+------------+--------------+ | slot_need | integer | RW, admin | 0 | non-neg. | slots needed | | | | | | | by router | +------------------+---------+-----------+---------+------------+--------------+ | scheduler | string | RO, admin | |check if | driver for | | | | set in Cr | |loadable | router | | | | | | | scheduler | +------------------+---------+-----------+---------+------------+--------------+ | cfg_agent_driver | string | RO, admin | |check if | driver for | | | | set in Cr | |loadable | config agent | +------------------+---------+-----------+---------+------------+--------------+ A ``routertype`` can be CRUD by admin users. Only ``id``, ``name`` and ``description`` attributes are visible to non-admin users in SHOW and LIST operations. A routertype is by default shared so it is available to all tenants. The routertype has a binding to a hosting device template. Only devices based on that hosting device template come in question when a Neutron router of the routertype in question is to be instantiated. The slot_need specifies how many slots the Neutron router of this type consume in the hosting device. The slot metric is an abstract one holistically representing processing capacity of a hosting device. The routertype also includes the module to be used to schedule router of this type to the hosting devices. Finally, the routertype includes the name of the driver that should be used to apply configurations in the hosting devices. Security impact --------------- None. Notifications impact -------------------- None to existing. This l3 routing service plugin uses its own RPC for interactions with Cisco configuration agents. These agents are defined in https://blueprints.launchpad.net/neutron/+spec/cisco-config-agent. The l3 routing service plugin can also create regular Namespace-based Neutron routers and then communicates with L3 agents using the regular notification and callback RPC used by those agents. Other end user impact --------------------- The ``python-neutronclient`` will be extended to with commands to CRUD routertypes as ``cisco-routertype-<`` *operation* ``>``, where *operation* = ``[create, show, list update, delete]`` Users can choose to specify the ``routertype_id`` attribute when creating Neuron routers. Otherwise default value chosen by cloud provider is used. Other deployer impact --------------------- We believe this will have no impact on community L3 router service plugin, not in its current implemenation, nor when DVR is merged. The deployer will have to specify that the Cisco routing service plugin be used instead of the community one. A configuration agent must also be deployed. Developer impact ---------------- None. Implementation ============== The below figure shows the new router service plugin and the components it interacts with. The routertype boxes are objects in the database and are just to show that the router service plugin knows about a certain number of routertypes that users can request. The plugin to config agent RPC is analogous to the l3 agent RPC. I.e., plugin sends router-update/delete notifications to the config agent. The latter periodically does get_routers() callback to hte plugin to fetch latest router configurations for updated routers. The router information sent to the config agent includes information about the device that is hosting the Neutron router. :: .......................................... ............. .............. . Neutron . . Some . . Nova . . Server . . Server . . Compute . . . . . . . . . . . . +-------+ . . . . . . |Hosting| . . . . . +---->|Device | . . +----------------------------------+ . . . | . |Svc VM | . . | Router Service Plugin | . . . | . +-------+ . . | | . RPC . +------+ . | .............. . | +------+ | NOTIFIC. |Config|<---+ . | +------+| +------------------+ |<--------->|Agent | . Device specific . | +------+|| |Neutron -> Hosting| | CALLBACKS | |<---+ protocol (e.g., . | |Router||+ |Router Device | | . . +------+ . | Netconf, REST) . | |Type |+ | SCHEDULER | | . . . | . | +------+ +------------------+ | . . . | +-------+ . +----------------------------------+ . . . | |Hosting| . . . . +---->|Device | . . . . |HW unit| .......................................... ............. +-------+ Each new router that is created is associated to a routertype, either by specification in the request or by default value. Routers will only be instantiated in hosting devices matching the template_id in the routertype. If no suitable hosting device is available the router is backlogged for new attempts later. This router service plugin collaborates with a hosting device manager plugin. The latter manages the lifecycle of CSR1kv VMs (and other physical or virtual devices). It starts VMs and destroy VMs automatically with the objective that some number of service VMs should be available at all times for immediate usage. Hence, all of that happens outside the router service plugin. A routertype is defined in the router service plugin for CSR1kv VM devices. A router-to-hosting-device scheduler is then used to select a suitable CSR1kv device when a Neutron router of that type is to be instantiated. A routertype is also created for traditional namespace routers and for those this router service plugin makes use of a routertype-aware l3agent scheduler. This scheduler is able to use the different types of l3agent schedulers that exist. For completeness a figure also showing the device manager service plugin is shown below: :: .......................................... ............. . Neutron Server . . Some . . . . Server . . +----------------------------------+ . . . .............. . | Device Manager Service Plugin | . . . . Nova . . | | . RPC NOTIFICATIONS . Compute . . | +--------+ | . & CALLBACKS . . . . | +--------+| +-----------------+ |<--------------+ . . +-------+ . . | +--------+|| |Hosting -> Config| | . . | . . |Hosting| . . | | Hosting||| |Device Agent | | . . | . +---->|Device | . . | | Device ||+ | SCHEDULER | | . . | . | . |Svc VM | . . | |Template|+ +-----------------+ | . . V . | . +-------+ . . | +--------+ | . . +------+ . | .............. . +----------------------------------+ . . |Config|<---+ . . . |Agent | . Device specific . +----------------------------------+ . . | |<---+ protocol (e.g., . | Router Service Plugin | . . +------+ . | Netconf, REST) . | | . . | . | . | +------+ | . . | . | +-------+ . | +------+| +------------------+ | . . | . | |Hosting| . | +------+|| |Neutron -> Hosting| |<--------------+ . +---->|Device | . | |Router||+ |Router Device | | . RPC NOTIFICATIONS |HW unit| . | |Type |+ | SCHEDULER | | . & CALLBACKS . +-------+ . | +------+ +------------------+ | . . . . +----------------------------------+ . . . .......................................... ............. Assignee(s) ----------- Primary assignee: bob-melander Other contributors: hareesh-puthalath, skandasw Work Items ---------- Code for review can be submitted for review shortly. Dependencies ============ Devstack and Neutron client must be updated to support this plugin. Testing ======= Unit tests will be added for all new functionality. Functional and scenario tests for community L3 implementation will be useful also for this implementation. Documentation Impact ==================== Will require new documentation in Cisco sections. References ========== ",,323,0
openstack%2Fopenstack-manuals~master~Iea91eca0a46999cd48103d1eb8cf688710558eb4,openstack/openstack-manuals,master,Iea91eca0a46999cd48103d1eb8cf688710558eb4,Create the role heat_stack_owner when installing Heat,MERGED,2014-07-14 16:12:41.000000000,2014-07-16 19:07:07.000000000,2014-07-16 19:07:06.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-07-14 16:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a8667dc8dea2fbd7fe9477bb21d396c7a7990cba', 'message': 'Create the role heat_stack_owner when installing Heat\n\nChange-Id: Iea91eca0a46999cd48103d1eb8cf688710558eb4\nCloses-Bug: #1341652\n'}, {'number': 2, 'created': '2014-07-14 20:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d35f223d2f27e5ef9527e7df463d330ce3e5f35b', 'message': 'Create the role heat_stack_owner when installing Heat\n\nChange-Id: Iea91eca0a46999cd48103d1eb8cf688710558eb4\nCloses-Bug: #1341652\n'}, {'number': 3, 'created': '2014-07-15 07:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/16304c6e7e8b96a83e43ad5e3bfde4a3bc3fb14c', 'message': 'Create the role heat_stack_owner when installing Heat\n\nChange-Id: Iea91eca0a46999cd48103d1eb8cf688710558eb4\nCloses-Bug: #1341652\n'}, {'number': 4, 'created': '2014-07-15 07:38:06.000000000', 'files': ['doc/install-guide/section_heat-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/39df6660230aca5149ec1e7758e10d958c778957', 'message': 'Create the role heat_stack_owner when installing Heat\n\nChange-Id: Iea91eca0a46999cd48103d1eb8cf688710558eb4\nCloses-Bug: #1341652\n'}]",3,106802,39df6660230aca5149ec1e7758e10d958c778957,22,3,4,167,,,0,"Create the role heat_stack_owner when installing Heat

Change-Id: Iea91eca0a46999cd48103d1eb8cf688710558eb4
Closes-Bug: #1341652
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/02/106802/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_heat-install.xml'],1,a8667dc8dea2fbd7fe9477bb21d396c7a7990cba,bug_1341652," <para>Create the <literal>heat_stack_user</literal> and <literal>heat_stack_owner</literal> roles:</para> <para>By default, users created by Orchestration use the role <literal>heat_stack_user</literal>.</para> <screen><prompt>$</prompt> <userinput>keystone role-create --name heat_stack_owner</userinput></screen>"," <para>Create the <literal>heat_stack_user</literal> role:</para> <para>By default, users created by Orchestration use this role.</para>",3,2
openstack%2Fopenstack-manuals~master~I9bb9ac86587686a43cdd9aabd1d975cb7a7c320a,openstack/openstack-manuals,master,I9bb9ac86587686a43cdd9aabd1d975cb7a7c320a,User name fixes,MERGED,2014-07-15 19:38:06.000000000,2014-07-16 19:06:59.000000000,2014-07-16 19:06:58.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}]","[{'number': 1, 'created': '2014-07-15 19:38:06.000000000', 'files': ['doc/high-availability-guide/ha_aa_db/section_ha_aa_db_mysql_galera.xml', 'doc/common/section_cli_openrc.xml', 'doc/config-reference/block-storage/section_block-storage-overview.xml', 'doc/install-guide/section_launch-instance-neutron.xml', 'doc/image-guide/section_ubuntu-example.xml', 'doc/common/section_cli_nova_baremetal.xml', 'doc/admin-guide-cloud/ch_compute.xml', 'doc/install-guide/section_launch-instance-nova.xml', 'doc/glossary/glossary-terms.xml', 'doc/common/section_keystone_certificates-for-pki.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/305f9b9d260a55241c97338221bd524b0f1e6368', 'message': 'User name fixes\n\nIt\'s ""user name"". Also fix markup for them to use systemitem.\n\nChange-Id: I9bb9ac86587686a43cdd9aabd1d975cb7a7c320a\n'}]",0,107160,305f9b9d260a55241c97338221bd524b0f1e6368,8,3,1,6547,,,0,"User name fixes

It's ""user name"". Also fix markup for them to use systemitem.

Change-Id: I9bb9ac86587686a43cdd9aabd1d975cb7a7c320a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/60/107160/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/high-availability-guide/ha_aa_db/section_ha_aa_db_mysql_galera.xml', 'doc/common/section_cli_openrc.xml', 'doc/config-reference/block-storage/section_block-storage-overview.xml', 'doc/image-guide/section_ubuntu-example.xml', 'doc/install-guide/section_launch-instance-neutron.xml', 'doc/common/section_cli_nova_baremetal.xml', 'doc/admin-guide-cloud/ch_compute.xml', 'doc/install-guide/section_launch-instance-nova.xml', 'doc/glossary/glossary-terms.xml', 'doc/common/section_keystone_certificates-for-pki.xml']",10,305f9b9d260a55241c97338221bd524b0f1e6368,username, to set the user name and group keystone is going to run, to set the username and group keystone is going to run,15,15
openstack%2Fopenstack-doc-tools~master~I13e76c75a74667fa9bd3c779a6cf45d0281ed680,openstack/openstack-doc-tools,master,I13e76c75a74667fa9bd3c779a6cf45d0281ed680,Don't use oslo's _sanitize_default,MERGED,2014-07-13 20:51:49.000000000,2014-07-16 18:58:24.000000000,2014-07-16 18:58:23.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-07-13 20:51:49.000000000', 'files': ['autogenerate_config_docs/autohelp.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/3854794b3ac3177460c403c59c6c428a83b9e6e1', 'message': ""Don't use oslo's _sanitize_default\n\nThis method disappeared from oslo, so provide our own sanitizer. This is\nneeded for now but can be removed as soon as projects provide\nOpts.sample_default values.\n\nChange-Id: I13e76c75a74667fa9bd3c779a6cf45d0281ed680\nCloses-Bug: #1341250\n""}]",0,106654,3854794b3ac3177460c403c59c6c428a83b9e6e1,10,3,1,7923,,,0,"Don't use oslo's _sanitize_default

This method disappeared from oslo, so provide our own sanitizer. This is
needed for now but can be removed as soon as projects provide
Opts.sample_default values.

Change-Id: I13e76c75a74667fa9bd3c779a6cf45d0281ed680
Closes-Bug: #1341250
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/54/106654/1 && git format-patch -1 --stdout FETCH_HEAD,['autogenerate_config_docs/autohelp.py'],1,3854794b3ac3177460c403c59c6c428a83b9e6e1,sanitizer,"def _sanitize_default(name, default): if default == os.uname()[1]: return 'localhost' if name == 'bindir': return '/usr/local/bin' if name == 'my_ip': return '10.0.0.1' for pathelm in sys.path[1:]: if pathelm == '': continue if pathelm.endswith('/'): pathelm = pathelm[:-1] if default.startswith(pathelm): return default.replace(pathelm, '/usr/lib/python/site-packages') return default opt.default = _sanitize_default(opt.name, str(opt.default)) if (hasattr(option, 'sample_default') and option.sample_default is not None): default = str(option.sample_default) else: default = _sanitize_default(option.name, str(option.default))","import openstack.common.config.generator as generator venv = os.environ.get('VIRTUAL_ENV') if venv is not None and opt.default.startswith(venv): opt.default = opt.default.replace(venv, '/usr/local') # Compute the absolute path of the git repository (the relative path is # prepended to sys.path in autohelp.py) target_abspath = os.path.abspath(sys.path[0]) # This regex will be used to sanitize file paths and uris uri_re = re.compile(r'(^[^:]+://)?%s' % target_abspath) default = generator._sanitize_default(option.name, str(option.default)) # This should be moved to generator._sanitize_default # NOTE(gpocentek): The first element in the path is the current # project git repository path. It is not useful to test values # against it, and it causes trouble if it is the same as the python # module name. So we just drop it. for pathelm in sys.path[1:]: if pathelm == '': continue if pathelm.endswith('/'): pathelm = pathelm[:-1] if default.startswith(pathelm): default = default.replace(pathelm, '/usr/lib/python/site-packages') break if uri_re.search(default): default = default.replace(target_abspath, '/usr/lib/python/site-packages') default = generator._sanitize_default(optname, str(default))",28,31
openstack%2Fopenstack-manuals~master~I07a9d528f7a250ad00e7d728fb67c08230a5bf3c,openstack/openstack-manuals,master,I07a9d528f7a250ad00e7d728fb67c08230a5bf3c,Gives clearer definition of a Linux Bridge,MERGED,2014-07-14 16:17:36.000000000,2014-07-16 18:47:12.000000000,2014-07-16 18:47:11.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2733}, {'_account_id': 6547}, {'_account_id': 10068}, {'_account_id': 12211}]","[{'number': 1, 'created': '2014-07-14 16:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f971443c53c2200a19853fe0dcf9554bb678bafe', 'message': 'Gives clearer definition of a Linux Bridge.\n\nChange-Id: I07a9d528f7a250ad00e7d728fb67c08230a5bf3c\n'}, {'number': 2, 'created': '2014-07-14 16:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/768f50c90e00ebc82efc9488dc26b39dfb91dc7c', 'message': 'Gives clearer definition of a Linux Bridge.\nChange-Id: I07a9d528f7a250ad00e7d728fb67c08230a5bf3c\n'}, {'number': 3, 'created': '2014-07-15 10:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ca6a491ebcee8015879275152f773c37c0e2ca16', 'message': 'Gives clearer definition of a Linux Bridge\n\nChange-Id: I07a9d528f7a250ad00e7d728fb67c08230a5bf3c\nCloses-Bug: 106803\n'}, {'number': 4, 'created': '2014-07-16 09:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/613c48faa04930bda504809129a2ab2533b16445', 'message': ""Gives clearer definition of a Linux Bridge\n\nLinux bridge doesn't behave like a hub, it behaves like a switch.\n\nChange-Id: I07a9d528f7a250ad00e7d728fb67c08230a5bf3c\nCloses-Bug: 1342619\n""}, {'number': 5, 'created': '2014-07-16 13:35:51.000000000', 'files': ['doc/admin-guide-cloud/networking/section_networking-scenarios.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/40744ef53956f8c82ada68ad2a17385e98788ced', 'message': ""Gives clearer definition of a Linux Bridge\n\nLinux bridge doesn't behave like a hub, it behaves like a switch.\n\nChange-Id: I07a9d528f7a250ad00e7d728fb67c08230a5bf3c\nCloses-Bug: 1342619\n""}]",12,106803,40744ef53956f8c82ada68ad2a17385e98788ced,30,6,5,12056,,,0,"Gives clearer definition of a Linux Bridge

Linux bridge doesn't behave like a hub, it behaves like a switch.

Change-Id: I07a9d528f7a250ad00e7d728fb67c08230a5bf3c
Closes-Bug: 1342619
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/03/106803/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/networking/section_networking-scenarios.xml'],1,f971443c53c2200a19853fe0dcf9554bb678bafe,bug/1342619," <para>A <emphasis role=""italic"">Linux bridge</emphasis> behaves like a simple MAC learning switch: you can connect multiple (physical or virtual) network interfaces devices to a Linux bridge. The Linux bridge uses a MAC learning database to keep track of host locations on the LAN. For any ethernet frames that come in from one interface attached to the bridge, the host MAC address and port on which the frame was received is recorded in the MAC learning database. When the bridge needs to forward a frame, it will check the to see if the frames destination MAC address is recorded in the database. If so, the Linux bridge will forward the frame through only that port. If not, the frame is flooded from all network ports in the bridge, with the exception of the port where the frame was received.</para>"," <para>A <emphasis role=""italic"">Linux bridge</emphasis> behaves like a hub: you can connect multiple (physical or virtual) network interfaces devices to a Linux bridge. Any ethernet frames that come in from one interface attached to the bridge is transmitted to all of the other devices.</para>",9,4
openstack%2Fopenstack-manuals~master~I920e1621062c8b17fca43f106e2b995637f2f48a,openstack/openstack-manuals,master,I920e1621062c8b17fca43f106e2b995637f2f48a,Update for python-novaclient 2.18.1,MERGED,2014-07-16 09:24:30.000000000,2014-07-16 18:34:50.000000000,2014-07-16 18:34:49.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-07-16 09:24:30.000000000', 'files': ['doc/common/ch_cli_nova_commands.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/76f0c2d1183e820aee81848748d8b484f1f73a97', 'message': 'Update for python-novaclient 2.18.1\n\nRegenerate ch_cli_nova_commands.xml with\npython-novaclient 2.18.1 version release.\n\nChange-Id: I920e1621062c8b17fca43f106e2b995637f2f48a\n'}]",0,107269,76f0c2d1183e820aee81848748d8b484f1f73a97,8,3,1,167,,,0,"Update for python-novaclient 2.18.1

Regenerate ch_cli_nova_commands.xml with
python-novaclient 2.18.1 version release.

Change-Id: I920e1621062c8b17fca43f106e2b995637f2f48a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/69/107269/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/ch_cli_nova_commands.xml'],1,76f0c2d1183e820aee81848748d8b484f1f73a97,update_nova_client, <command>nova</command> version 2.18.1. <term><command>migration-list</command></term> <listitem> <para> Print a list of migrations. </para> </listitem> </varlistentry> <varlistentry> <term><command>host-evacuate</command></term> <listitem> <para> Evacuate all instances from failed host to specified one. </para> </listitem> </varlistentry> <varlistentry> <term><command>instance-action</command></term> <listitem> <para> Show an action. </para> </listitem> </varlistentry> <varlistentry> <term><command>instance-action-list</command></term> <listitem> <para> List actions on a server. </para> </listitem> </varlistentry> <varlistentry> <term><command>list-extensions</command></term> List all the os-api extensions that are available. <term><command>host-meta</command></term> <listitem> <para> Set or Delete metadata on all instances of a host. </para> </listitem> </varlistentry> <varlistentry> [--vlan-start &lt;vlan start&gt;] [--vpn &lt;vpn start&gt;] [--gateway GATEWAY] [--gateway-v6 GATEWAY_V6] [--bridge &lt;bridge&gt;] vlan id to be assigned to project </para> </listitem> </varlistentry> <varlistentry> <term><command>--vlan-start &lt;vlan start&gt;</command></term> <listitem> <para> First vlan ID to be assigned to project. Subsequent vlan IDs will be assigned incrementally, <command>nova</command> version 2.18.0. <term><command>host-evacuate</command></term> Evacuate all instances from failed host to specified one. </para> </listitem> </varlistentry> <varlistentry> <term><command>instance-action</command></term> <listitem> <para> Show an action. </para> </listitem> </varlistentry> <varlistentry> <term><command>instance-action-list</command></term> <listitem> <para> List actions on a server. </para> </listitem> </varlistentry> <varlistentry> <term><command>migration-list</command></term> <listitem> <para> Print a list of migrations. <varlistentry> <term><command>host-meta</command></term> <listitem> <para> Set or Delete metadata on all instances of a host. </para> </listitem> </varlistentry> <varlistentry> <term><command>list-extensions</command></term> <listitem> <para> List all the os-api extensions that are available. </para> </listitem> </varlistentry> [--vpn &lt;vpn start&gt;] [--gateway GATEWAY] [--gateway-v6 GATEWAY_V6] [--bridge &lt;bridge&gt;] vlan id,60,49
openstack%2Fdesignate~master~Ia9006dbf9d3d2f9d4037a428681c3cee929a8e36,openstack/designate,master,Ia9006dbf9d3d2f9d4037a428681c3cee929a8e36,Enable hacking check H104,MERGED,2014-07-16 17:22:39.000000000,2014-07-16 18:23:10.000000000,2014-07-16 18:23:10.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}]","[{'number': 1, 'created': '2014-07-16 17:22:39.000000000', 'files': ['designate/manage/__init__.py', 'designate/tests/test_quota/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/designate/commit/acf67623f17d4a9fd72e4e40be3789733eaf747d', 'message': 'Enable hacking check H104\n\n* [H104] Files with no code shouldn’t contain any license\n         header nor comments, and must be left completely empty.\n\nChange-Id: Ia9006dbf9d3d2f9d4037a428681c3cee929a8e36\n'}]",0,107444,acf67623f17d4a9fd72e4e40be3789733eaf747d,8,3,1,167,,,0,"Enable hacking check H104

* [H104] Files with no code shouldn’t contain any license
         header nor comments, and must be left completely empty.

Change-Id: Ia9006dbf9d3d2f9d4037a428681c3cee929a8e36
",git fetch https://review.opendev.org/openstack/designate refs/changes/44/107444/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/manage/__init__.py', 'designate/tests/test_quota/__init__.py', 'tox.ini']",3,acf67623f17d4a9fd72e4e40be3789733eaf747d,enable_h104,"ignore = H302,H306,H402,H404,H405,H904,E126,E128","# H104 file contains nothing more than commentsignore = H104,H302,H306,H402,H404,H405,H904,E126,E128",1,32
openstack%2Fpython-keystoneclient~master~I1faaae0373a7ae12ee528ab5c71741a2b1122d43,openstack/python-keystoneclient,master,I1faaae0373a7ae12ee528ab5c71741a2b1122d43,add deprecation warning for auth_token,MERGED,2014-07-15 21:39:32.000000000,2014-07-16 18:20:07.000000000,2014-07-16 18:20:07.000000000,"[{'_account_id': 3}, {'_account_id': 220}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 11045}, {'_account_id': 11387}, {'_account_id': 11717}]","[{'number': 1, 'created': '2014-07-15 21:39:32.000000000', 'files': ['keystoneclient/middleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/5c9b13d4c7222b71084a0b4fd836e1fdda0edaf7', 'message': 'add deprecation warning for auth_token\n\nChange-Id: I1faaae0373a7ae12ee528ab5c71741a2b1122d43\nCloses-Bug: 1342274\n'}]",3,107182,5c9b13d4c7222b71084a0b4fd836e1fdda0edaf7,14,8,1,4,,,0,"add deprecation warning for auth_token

Change-Id: I1faaae0373a7ae12ee528ab5c71741a2b1122d43
Closes-Bug: 1342274
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/82/107182/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/middleware/auth_token.py'],1,5c9b13d4c7222b71084a0b4fd836e1fdda0edaf7,bug/1342274, self.LOG.warning( 'This middleware module is deprecated as of v0.10.0 in favor of ' 'keystonemiddleware.auth_token - please update your WSGI pipeline ' 'to reference the new middleware package.'),,4,0
openstack%2Frally~master~Ia3540c5b396212c0f214d41e51797c584329a482,openstack/rally,master,Ia3540c5b396212c0f214d41e51797c584329a482,Handle keyboard interrupt in task run,MERGED,2014-07-16 12:53:20.000000000,2014-07-16 18:18:35.000000000,2014-07-16 18:18:35.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-07-16 12:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7713af954b7b640ae8aac583d886e26aec95a7a8', 'message': 'Handle keyboard interrupt in task run\n\nCurrently cancelling task does not handle keyboard\ninterrupts. This fix is to add the exception and\nabort the task.\n\nChange-Id: Ia3540c5b396212c0f214d41e51797c584329a482\nCloses-Bug:#1326051\n'}, {'number': 2, 'created': '2014-07-16 14:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3b91afee50cae3760bcda51d8860d4051e154896', 'message': 'Handle keyboard interrupt in task run\n\nCurrently cancelling task does not handle keyboard\ninterrupts. This fix is to add the exception and\nabort the task.\n\nChange-Id: Ia3540c5b396212c0f214d41e51797c584329a482\nCloses-Bug:#1326051\n'}, {'number': 3, 'created': '2014-07-16 15:19:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/62bb94c37f4345d1c1085144be4687be1700fca8', 'message': 'Handle keyboard interrupt in task run\n\nCurrently cancelling task does not handle keyboard\ninterrupts. This fix is to add the exception and\nabort the task.\n\nChange-Id: Ia3540c5b396212c0f214d41e51797c584329a482\nCloses-Bug:#1326051\n'}, {'number': 4, 'created': '2014-07-16 15:35:08.000000000', 'files': ['tests/cmd/commands/test_task.py', 'rally/cmd/commands/task.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/0e1c90363b8c84efc46ebd1e80a57cef52d85f63', 'message': 'Handle keyboard interrupt in task run\n\nCurrently cancelling task does not handle keyboard\ninterrupts. This fix is to add the exception and\nabort the task.\n\nChange-Id: Ia3540c5b396212c0f214d41e51797c584329a482\nCloses-Bug:#1326051\n'}]",4,107358,0e1c90363b8c84efc46ebd1e80a57cef52d85f63,18,3,4,11105,,,0,"Handle keyboard interrupt in task run

Currently cancelling task does not handle keyboard
interrupts. This fix is to add the exception and
abort the task.

Change-Id: Ia3540c5b396212c0f214d41e51797c584329a482
Closes-Bug:#1326051
",git fetch https://review.opendev.org/openstack/rally refs/changes/58/107358/4 && git format-patch -1 --stdout FETCH_HEAD,['rally/cmd/commands/task.py'],1,7713af954b7b640ae8aac583d886e26aec95a7a8,bug/1326051, except KeyboardInterrupt: api.abort_task(task['uuid']) raise,,3,0
openstack%2Fcongress~master~Ie264ff6799f84a21b199ea32a2ba9ae1ec851285,openstack/congress,master,Ie264ff6799f84a21b199ea32a2ba9ae1ec851285,Update congress README file,MERGED,2014-07-09 23:46:06.000000000,2014-07-16 18:17:56.000000000,2014-07-16 18:17:56.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-07-09 23:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/63e895efdadcb88e35ef0298c3c6d599cebb606b', 'message': 'Update congress README file\n\nChange-Id: Ie264ff6799f84a21b199ea32a2ba9ae1ec851285\n'}, {'number': 2, 'created': '2014-07-09 23:47:34.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/congress/commit/90f9c747bfad247b30dfe5971deb87958be8627f', 'message': 'Update congress README file\n\nChange-Id: Ie264ff6799f84a21b199ea32a2ba9ae1ec851285\n'}]",0,105919,90f9c747bfad247b30dfe5971deb87958be8627f,13,3,2,4395,,,0,"Update congress README file

Change-Id: Ie264ff6799f84a21b199ea32a2ba9ae1ec851285
",git fetch https://review.opendev.org/openstack/congress refs/changes/19/105919/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,63e895efdadcb88e35ef0298c3c6d599cebb606b,, ./bin/congress-server --config-file congress/etc/congress.sample.conf tox -epy27 or via ./run_test.sh, ./scripts/run_api_server ./scripts/run_tests ,2,3
openstack%2Fcongress~master~I25ab083d359a4bd85c93356e5261d31061a7e9aa,openstack/congress,master,I25ab083d359a4bd85c93356e5261d31061a7e9aa,Refactor congress eventlet server code,MERGED,2014-07-09 21:17:53.000000000,2014-07-16 18:13:03.000000000,2014-07-16 18:13:03.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 6923}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-07-09 21:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/7865a5cdd933b4fdf0c8616f49f72cec2ad12e6d', 'message': 'Refactor congress eventlet server code\n\nThis patch removes the current wsgi-server in place of the one that keystone\nuses which is basically identical to the one that was already in congress.\nThe only reason I switched it out for the keystone one is just so copying\nthe keystone integration out of keystone to congress would be easier.\nIn addition, this patch adds mutiworker support so can use multiple processes\nto run our api server (though currently we just default that to 1).\nThis patch also includes test cases for the eventlet server.\n\nChange-Id: I25ab083d359a4bd85c93356e5261d31061a7e9aa\nCloses-bug: 1339880\n'}, {'number': 2, 'created': '2014-07-10 23:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d3c59d1923723afbfcac45201bf5c9e1dc14eff0', 'message': 'Refactor congress eventlet server code\n\nThis patch removes the current wsgi-server in place of the one that keystone\nuses which is basically identical to the one that was already in congress.\nThe only reason I switched it out for the keystone one is just so copying\nthe keystone integration out of keystone to congress would be easier.\nIn addition, this patch adds mutiworker support so can use multiple processes\nto run our api server (though currently we just default that to 1).\nThis patch also includes test cases for the eventlet server.\n\nChange-Id: I25ab083d359a4bd85c93356e5261d31061a7e9aa\nCloses-bug: 1339880\n'}, {'number': 3, 'created': '2014-07-15 00:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d12036222e5e31ae68659cc189d815bc91c98654', 'message': 'Refactor congress eventlet server code\n\nThis patch removes the current wsgi-server in place of the one that keystone\nuses which is basically identical to the one that was already in congress.\nThe only reason I switched it out for the keystone one is just so copying\nthe keystone integration out of keystone to congress would be easier.\nIn addition, this patch adds mutiworker support so can use multiple processes\nto run our api server (though currently we just default that to 1).\nThis patch also includes test cases for the eventlet server.\n\nChange-Id: I25ab083d359a4bd85c93356e5261d31061a7e9aa\nCloses-bug: 1339880\n'}, {'number': 4, 'created': '2014-07-15 19:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/793c8bd0753b18079a250bbf084a12e6144eaafa', 'message': 'Refactor congress eventlet server code\n\nThis patch removes the current wsgi-server in place of the one that keystone\nuses which is basically identical to the one that was already in congress.\nThe only reason I switched it out for the keystone one is just so copying\nthe keystone integration out of keystone to congress would be easier.\nIn addition, this patch adds mutiworker support so can use multiple processes\nto run our api server (though currently we just default that to 1).\nThis patch also includes test cases for the eventlet server.\n\nChange-Id: I25ab083d359a4bd85c93356e5261d31061a7e9aa\nCloses-bug: 1339880\n'}, {'number': 5, 'created': '2014-07-15 19:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/68dcbc60bdcf7eeb1ff14388e1a934641fa6a769', 'message': 'Refactor congress eventlet server code\n\nThis patch removes the current wsgi-server in place of the one that keystone\nuses which is basically identical to the one that was already in congress.\nThe only reason I switched it out for the keystone one is just so copying\nthe keystone integration out of keystone to congress would be easier.\nIn addition, this patch adds mutiworker support so can use multiple processes\nto run our api server (though currently we just default that to 1).\nThis patch also includes test cases for the eventlet server.\n\nChange-Id: I25ab083d359a4bd85c93356e5261d31061a7e9aa\nCloses-bug: 1339880\n'}, {'number': 6, 'created': '2014-07-15 22:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/75d2083b7a18df15d374ce1379e111d59382fb9e', 'message': 'Refactor congress eventlet server code\n\nThis patch removes the current wsgi-server in place of the one that keystone\nuses which is basically identical to the one that was already in congress.\nThe only reason I switched it out for the keystone one is just so copying\nthe keystone integration out of keystone to congress would be easier.\nIn addition, this patch adds mutiworker support so can use multiple processes\nto run our api server (though currently we just default that to 1).\nThis patch also includes test cases for the eventlet server.\n\nChange-Id: I25ab083d359a4bd85c93356e5261d31061a7e9aa\nCloses-bug: 1339880\n'}, {'number': 7, 'created': '2014-07-15 22:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/9d404a5a6e8bbde0413ae2c754e9584d26ae830f', 'message': 'Refactor congress eventlet server code\n\nThis patch removes the current wsgi-server in place of the one that keystone\nuses which is basically identical to the one that was already in congress.\nThe only reason I switched it out for the keystone one is just so copying\nthe keystone integration out of keystone to congress would be easier.\nIn addition, this patch adds mutiworker support so can use multiple processes\nto run our api server (though currently we just default that to 1).\nThis patch also includes test cases for the eventlet server.\n\nChange-Id: I25ab083d359a4bd85c93356e5261d31061a7e9aa\nCloses-bug: 1339880\n'}, {'number': 8, 'created': '2014-07-16 00:14:02.000000000', 'files': ['congress/common/config.py', 'congress/api/wsgi.py', 'congress/server/congress_server.py', 'congress/tests/test_server.py', 'congress/tests/test_config.py', 'congress/common/eventlet_server.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/23304a92bf780fbc917301e8246b806031666812', 'message': 'Refactor congress eventlet server code\n\nThis patch removes the current wsgi-server in place of the one that keystone\nuses which is basically identical to the one that was already in congress.\nThe only reason I switched it out for the keystone one is just so copying\nthe keystone integration out of keystone to congress would be easier.\nIn addition, this patch adds mutiworker support so can use multiple processes\nto run our api server (though currently we just default that to 1).\nThis patch also includes test cases for the eventlet server.\n\nChange-Id: I25ab083d359a4bd85c93356e5261d31061a7e9aa\nCloses-bug: 1339880\n'}]",18,105882,23304a92bf780fbc917301e8246b806031666812,39,5,8,4395,,,0,"Refactor congress eventlet server code

This patch removes the current wsgi-server in place of the one that keystone
uses which is basically identical to the one that was already in congress.
The only reason I switched it out for the keystone one is just so copying
the keystone integration out of keystone to congress would be easier.
In addition, this patch adds mutiworker support so can use multiple processes
to run our api server (though currently we just default that to 1).
This patch also includes test cases for the eventlet server.

Change-Id: I25ab083d359a4bd85c93356e5261d31061a7e9aa
Closes-bug: 1339880
",git fetch https://review.opendev.org/openstack/congress refs/changes/82/105882/8 && git format-patch -1 --stdout FETCH_HEAD,"['congress/common/config.py', 'congress/api/wsgi.py', 'congress/server/congress_server.py', 'congress/tests/test_server.py', 'congress/tests/test_config.py', 'congress/common/eventlet_server.py']",6,7865a5cdd933b4fdf0c8616f49f72cec2ad12e6d,(detached,"# Copyright 2012 OpenStack Foundation # Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # Copyright 2010 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import errno import re import socket import ssl import sys import eventlet import eventlet.wsgi import greenlet from congress.openstack.common.gettextutils import _ from congress.openstack.common import log LOG = log.getLogger(__name__) class EventletFilteringLogger(log.WritableLogger): # NOTE(morganfainberg): This logger is designed to filter out specific # Tracebacks to limit the amount of data that eventlet can log. In the # case of broken sockets (EPIPE and ECONNRESET), we are seeing a huge # volume of data being written to the logs due to ~14 lines+ per traceback. # The traceback in these cases are, at best, useful for limited debugging # cases. def __init__(self, *args, **kwargs): super(EventletFilteringLogger, self).__init__(*args, **kwargs) self.regex = re.compile(r'errno (%d|%d)' % (errno.EPIPE, errno.ECONNRESET), re.IGNORECASE) def write(self, msg): m = self.regex.search(msg) if m: self.logger.log(log.logging.DEBUG, 'Error(%s) writing to socket.', m.group(1)) else: self.logger.log(self.level, msg.rstrip()) class Server(object): """"""Server class to manage multiple WSGI sockets and applications."""""" def __init__(self, application, host=None, port=None, threads=1000, keepalive=False, keepidle=None): self.application = application self.host = host or '0.0.0.0' self.port = port or 0 self.pool = eventlet.GreenPool(threads) self.socket_info = {} self.greenthread = None self.do_ssl = False self.cert_required = False self.keepalive = keepalive self.keepidle = keepidle self.socket = None def start(self, key=None, backlog=128): """"""Run a WSGI server with the given application."""""" if self.socket is None: self.listen(key=key, backlog=backlog) self.greenthread = self.pool.spawn(self._run, self.application, self.socket) def listen(self, key=None, backlog=128): """"""Create and start listening on socket. Call before forking worker processes. Raises Exception if this has already been called. """""" if self.socket is not None: raise Exception(_('Server can only listen once.')) LOG.info(_('Starting %(arg0)s on %(host)s:%(port)s'), {'arg0': sys.argv[0], 'host': self.host, 'port': self.port}) # TODO(dims): eventlet's green dns/socket module does not actually # support IPv6 in getaddrinfo(). We need to get around this in the # future or monitor upstream for a fix info = socket.getaddrinfo(self.host, self.port, socket.AF_UNSPEC, socket.SOCK_STREAM)[0] _socket = eventlet.listen(info[-1], family=info[0], backlog=backlog) if key: self.socket_info[key] = _socket.getsockname() # SSL is enabled if self.do_ssl: if self.cert_required: cert_reqs = ssl.CERT_REQUIRED else: cert_reqs = ssl.CERT_NONE sslsocket = eventlet.wrap_ssl(_socket, certfile=self.certfile, keyfile=self.keyfile, server_side=True, cert_reqs=cert_reqs, ca_certs=self.ca_certs) _socket = sslsocket # Optionally enable keepalive on the wsgi socket. if self.keepalive: _socket.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1) # This option isn't available in the OS X version of eventlet if hasattr(socket, 'TCP_KEEPIDLE') and self.keepidle is not None: _socket.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPIDLE, self.keepidle) self.socket = _socket def set_ssl(self, certfile, keyfile=None, ca_certs=None, cert_required=True): self.certfile = certfile self.keyfile = keyfile self.ca_certs = ca_certs self.cert_required = cert_required self.do_ssl = True def kill(self): if self.greenthread is not None: self.greenthread.kill() def stop(self): self.kill() def wait(self): """"""Wait until all servers have completed running."""""" try: self.pool.waitall() except KeyboardInterrupt: pass except greenlet.GreenletExit: pass def _run(self, application, socket): """"""Start a WSGI server in a new green thread."""""" logger = log.getLogger('eventlet.wsgi.server') try: eventlet.wsgi.server(socket, application, custom_pool=self.pool, log=EventletFilteringLogger(logger), debug=False) except greenlet.GreenletExit: # Wait until all servers have completed running pass except Exception: LOG.exception(_('Server error')) raise ",,341,134
openstack%2Ftempest~master~I15d2e8676bcfc338ff4fcad5b33cf0e666a28300,openstack/tempest,master,I15d2e8676bcfc338ff4fcad5b33cf0e666a28300,Format endpoint URLs for validation,ABANDONED,2014-06-08 04:52:51.000000000,2014-07-16 18:07:52.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1192}, {'_account_id': 5046}, {'_account_id': 5196}, {'_account_id': 7350}, {'_account_id': 7725}, {'_account_id': 8041}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10234}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-08 04:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2509f7e8f6710ab10da0ef466d1dc25fc7a34695', 'message': 'Format endpoint URLs for validation\n\nPreviously, endpoint URL were generated randomly before sending endpoint\nrequests to the Keystone server. Now that Keystone is validating input\non incoming requests, URLs have to match a regular expression in order\nto be considered valid. This change modifies the endpoint URL to be\ncompliant before sending the endpoint request.\n\nChange-Id: I15d2e8676bcfc338ff4fcad5b33cf0e666a28300\n'}, {'number': 2, 'created': '2014-06-30 22:02:03.000000000', 'files': ['tempest/common/utils/data_utils.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b257e955e70190c6a3340161afa5717fa43cf85f', 'message': 'Format endpoint URLs for validation\n\nPreviously, endpoint URL were generated randomly before sending endpoint\nrequests to the Keystone server. Now that Keystone is validating input\non incoming requests, URLs have to match a regular expression in order\nto be considered valid. This change modifies the endpoint URL to be\ncompliant before sending the endpoint request.\n\nChange-Id: I15d2e8676bcfc338ff4fcad5b33cf0e666a28300\n'}]",0,98621,b257e955e70190c6a3340161afa5717fa43cf85f,41,12,2,5046,,,0,"Format endpoint URLs for validation

Previously, endpoint URL were generated randomly before sending endpoint
requests to the Keystone server. Now that Keystone is validating input
on incoming requests, URLs have to match a regular expression in order
to be considered valid. This change modifies the endpoint URL to be
compliant before sending the endpoint request.

Change-Id: I15d2e8676bcfc338ff4fcad5b33cf0e666a28300
",git fetch https://review.opendev.org/openstack/tempest refs/changes/21/98621/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/identity/admin/v3/test_endpoints_negative.py', 'tempest/api/identity/admin/v3/test_endpoints.py']",2,2509f7e8f6710ab10da0ef466d1dc25fc7a34695,fix-endpoint-urls, url = 'https://' + url + '.com' url = 'https://' + url + '.com' url1 = 'https://' + url1 + '.com' url2 = 'https://' + url2 + '.com',,7,0
openstack%2Fnova~master~I074391eaa7cfd580b89d89c2dd587796112c4a98,openstack/nova,master,I074391eaa7cfd580b89d89c2dd587796112c4a98,Small grammar fix in libvirt/driver.py. fix all occurrences.,MERGED,2014-07-15 12:48:59.000000000,2014-07-16 18:03:27.000000000,2014-07-16 17:36:20.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1247}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 9586}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-15 12:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fed51ba1abb7791147ffeda4178745abd6116a45', 'message': 'Small grammar fix in libvirt/driver.py\n\nChange wording to be more descriptive/correct for greenthread.sleep()\n\nChange-Id: I074391eaa7cfd580b89d89c2dd587796112c4a98\n'}, {'number': 2, 'created': '2014-07-15 18:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ab9d4c671fe3e403a54daa58f32a4fe898328f2', 'message': ""Small grammar fix in libvirt/driver.py\n\nChange wording to be more descriptive/correct for greenthread.sleep()\nJoe's wording is an improvement.\nChange-Id: I074391eaa7cfd580b89d89c2dd587796112c4a98\n""}, {'number': 3, 'created': '2014-07-16 07:59:00.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5fc4461a97ff7cb98782ba63ac9c109e17003f9b', 'message': 'Small grammar fix in libvirt/driver.py. fix all occurrences.\n\nChange wording to be more descriptive/correct for greenthread.sleep()\nChange-Id: I074391eaa7cfd580b89d89c2dd587796112c4a98\n'}]",2,107036,5fc4461a97ff7cb98782ba63ac9c109e17003f9b,64,13,3,9586,,,0,"Small grammar fix in libvirt/driver.py. fix all occurrences.

Change wording to be more descriptive/correct for greenthread.sleep()
Change-Id: I074391eaa7cfd580b89d89c2dd587796112c4a98
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/107036/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,fed51ba1abb7791147ffeda4178745abd6116a45,, # NOTE(gtt116): give a chance to the other tasks., # NOTE(gtt116): give change to do other task.,1,1
openstack%2Fsahara~master~I53750cd9bf23df06678d555e5c1fecfcc98edca3,openstack/sahara,master,I53750cd9bf23df06678d555e5c1fecfcc98edca3,Renamed Pending to PENDING fixes bug 1329526,MERGED,2014-07-15 13:21:14.000000000,2014-07-16 17:47:19.000000000,2014-07-16 17:41:59.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-15 13:21:14.000000000', 'files': ['sahara/service/edp/api.py', 'doc/source/restapi/rest_api_v1.1_EDP.rst', 'sahara/tests/unit/conductor/test_resource.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a6aea22d74b0e8b5a827ae5f273a2f071734fcd3', 'message': 'Renamed Pending to PENDING\nfixes bug 1329526\n\nChange-Id: I53750cd9bf23df06678d555e5c1fecfcc98edca3\n'}]",0,107047,a6aea22d74b0e8b5a827ae5f273a2f071734fcd3,29,10,1,6437,,,0,"Renamed Pending to PENDING
fixes bug 1329526

Change-Id: I53750cd9bf23df06678d555e5c1fecfcc98edca3
",git fetch https://review.opendev.org/openstack/sahara refs/changes/47/107047/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/edp/api.py', 'doc/source/restapi/rest_api_v1.1_EDP.rst', 'sahara/tests/unit/conductor/test_resource.py']",3,a6aea22d74b0e8b5a827ae5f273a2f071734fcd3,bug/1329526," ""status"": ""PENDING"""," ""status"": ""Pending""",5,5
openstack%2Fcinder~stable%2Fhavana~I8ffdb849f41e8c28137ad8c0fa1f86c54b5e6fe9,openstack/cinder,stable/havana,I8ffdb849f41e8c28137ad8c0fa1f86c54b5e6fe9,vmware: Fixes create volume from image error,MERGED,2014-06-04 14:09:13.000000000,2014-07-16 17:44:50.000000000,2014-07-16 17:44:49.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 2243}, {'_account_id': 7239}, {'_account_id': 8247}, {'_account_id': 9171}, {'_account_id': 9533}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-04 14:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/76b76097c24f0d94066136d7740b35e20da7c226', 'message': 'vmware: Fixes create volume from image error\n\nWhile creating a volume with an image specified as the volume source,\nthe VMDK driver tries creating the volume backing file on each host\nin the inventory (one by one; until any attempt succeeds). However,\nif the attempted host is in a bad connection state, the volume\ncreation fails and results in the volume going into error state.\nEffectively, user cannot create a volume from image in such scenario.\nThis patch catches the VimFaultException during backing file\ncreation, so that driver picks the next available host for volume\ncreation.\n\nChange-Id: I8ffdb849f41e8c28137ad8c0fa1f86c54b5e6fe9\nCloses-Bug: #1326366\n'}, {'number': 2, 'created': '2014-06-06 08:42:59.000000000', 'files': ['cinder/volume/drivers/vmware/vmdk.py', 'cinder/tests/test_vmware_vmdk.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e019824f3fc016e488e7e87839a071318b1ca43', 'message': 'vmware: Fixes create volume from image error\n\nWhile creating a volume with an image specified as the volume source,\nthe VMDK driver tries creating the volume backing file on each host\nin the inventory (one by one; until any attempt succeeds). However,\nif the attempted host is in a bad connection state, the volume\ncreation fails and results in the volume going into error state.\nEffectively, user cannot create a volume from image in such scenario.\nThis patch catches the VimFaultException during backing file\ncreation, so that driver picks the next available host for volume\ncreation.\n\nChange-Id: I8ffdb849f41e8c28137ad8c0fa1f86c54b5e6fe9\nCloses-Bug: #1326366\n'}]",0,97796,8e019824f3fc016e488e7e87839a071318b1ca43,18,8,2,1633,,,0,"vmware: Fixes create volume from image error

While creating a volume with an image specified as the volume source,
the VMDK driver tries creating the volume backing file on each host
in the inventory (one by one; until any attempt succeeds). However,
if the attempted host is in a bad connection state, the volume
creation fails and results in the volume going into error state.
Effectively, user cannot create a volume from image in such scenario.
This patch catches the VimFaultException during backing file
creation, so that driver picks the next available host for volume
creation.

Change-Id: I8ffdb849f41e8c28137ad8c0fa1f86c54b5e6fe9
Closes-Bug: #1326366
",git fetch https://review.opendev.org/openstack/cinder refs/changes/96/97796/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/vmware/vmdk.py'],1,76b76097c24f0d94066136d7740b35e20da7c226,bug/1326366," except error_util.VimFaultException as ex: LOG.error(_(""Error creating backing file for "" ""volume: %(vol)s under host: %(host)s. "" ""More details: %(excep)s"") % {'vol': volume['name'], 'host': host.obj, 'excep': ex})",,6,0
openstack%2Fglance~master~Iea1fa94a7c8690c874859b1b1e9fd1cdf29fed21,openstack/glance,master,Iea1fa94a7c8690c874859b1b1e9fd1cdf29fed21,Add a `_retry_on_deadlock` decorator,MERGED,2014-07-14 13:22:13.000000000,2014-07-16 17:44:42.000000000,2014-07-16 17:44:41.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 8759}]","[{'number': 1, 'created': '2014-07-14 13:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/23929b8909f8f1f84e2b8fa8a52bc60cb89edf8d', 'message': ""Add a `_retry_on_deadlock` decorator\n\nThis patch adds a `_retry_on_deadlock` decorator from Nova. The aim is\nto retry db transactions that had failed because of race-conditions.\nAlthough this is not the best and most ideal fix - it'd be better to get\nrid of the race condition - the fix does adds a guard against unseen\nreace conditions for some of the functions in the database API.\n\nI'll contribute this patch to oslo.db but in the meantime, I'd prefer to\nlet it land in Glance and then clean it up once it's in `oslo.db`.\n\nChange-Id: Iea1fa94a7c8690c874859b1b1e9fd1cdf29fed21\nFixes-bug: #1339735\n""}, {'number': 2, 'created': '2014-07-16 07:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e656dc7acf76c5427b16109a776fd0835a02b256', 'message': ""Add a `_retry_on_deadlock` decorator\n\nThis patch adds a `_retry_on_deadlock` decorator from Nova. The aim is\nto retry db transactions that had failed because of race-conditions.\nAlthough this is not the best and most ideal fix - it'd be better to get\nrid of the race condition - the fix does adds a guard against unseen\nreace conditions for some of the functions in the database API.\n\nI'll contribute this patch to oslo.db but in the meantime, I'd prefer to\nlet it land in Glance and then clean it up once it's in `oslo.db`.\n\nChange-Id: Iea1fa94a7c8690c874859b1b1e9fd1cdf29fed21\nFixes-bug: #1339735\n""}, {'number': 3, 'created': '2014-07-16 12:14:58.000000000', 'files': ['glance/tests/unit/test_db.py', 'glance/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/149074976c0a33bd67a4bfcabb6d2e65dac1310d', 'message': ""Add a `_retry_on_deadlock` decorator\n\nThis patch adds a `_retry_on_deadlock` decorator from Nova. The aim is\nto retry db transactions that had failed because of race-conditions.\nAlthough this is not the best and most ideal fix - it'd be better to get\nrid of the race condition - the fix does adds a guard against unseen\nreace conditions for some of the functions in the database API.\n\nI'll contribute this patch to oslo.db but in the meantime, I'd prefer to\nlet it land in Glance and then clean it up once it's in `oslo.db`.\n\nChange-Id: Iea1fa94a7c8690c874859b1b1e9fd1cdf29fed21\nFixes-bug: #1339735\n""}]",9,106764,149074976c0a33bd67a4bfcabb6d2e65dac1310d,25,6,3,6159,,,0,"Add a `_retry_on_deadlock` decorator

This patch adds a `_retry_on_deadlock` decorator from Nova. The aim is
to retry db transactions that had failed because of race-conditions.
Although this is not the best and most ideal fix - it'd be better to get
rid of the race condition - the fix does adds a guard against unseen
reace conditions for some of the functions in the database API.

I'll contribute this patch to oslo.db but in the meantime, I'd prefer to
let it land in Glance and then clean it up once it's in `oslo.db`.

Change-Id: Iea1fa94a7c8690c874859b1b1e9fd1cdf29fed21
Fixes-bug: #1339735
",git fetch https://review.opendev.org/openstack/glance refs/changes/64/106764/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_db.py', 'glance/db/sqlalchemy/api.py']",2,23929b8909f8f1f84e2b8fa8a52bc60cb89edf8d,bug-1339735,"import functools import time def _retry_on_deadlock(f): """"""Decorator to retry a DB API call if Deadlock was received."""""" @functools.wraps(f) def wrapped(*args, **kwargs): while True: try: return f(*args, **kwargs) except db_exception.DBDeadlock: LOG.warn(_(""Deadlock detected when running "" ""'%(func_name)s': Retrying...""), dict(func_name=f.__name__)) # Retry! time.sleep(0.5) continue functools.update_wrapper(wrapped, f) return wrapped @_retry_on_deadlock",,43,0
openstack%2Fpython-glanceclient~master~Iea1ebc13979a61d7bed397fb79e2b2a85f00c400,openstack/python-glanceclient,master,Iea1ebc13979a61d7bed397fb79e2b2a85f00c400,Use a correctly formatted example location in help,MERGED,2014-07-16 14:57:17.000000000,2014-07-16 17:44:40.000000000,2014-07-16 17:44:39.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 9236}]","[{'number': 1, 'created': '2014-07-16 14:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/2535aec459b815f90b6a4fc12fe11b07aebc59e0', 'message': 'Use a correctly formatted example location in help\n\nChange-Id: Iea1ebc13979a61d7bed397fb79e2b2a85f00c400\nCloses-bug: 1342753\n'}, {'number': 2, 'created': '2014-07-16 15:05:53.000000000', 'files': ['glanceclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/f75a81000e1060d608c624ff8e3287e8c99a5123', 'message': 'Use a correctly formatted example location in help\n\nChange-Id: Iea1ebc13979a61d7bed397fb79e2b2a85f00c400\nCloses-bug: 1342753\n'}]",1,107416,f75a81000e1060d608c624ff8e3287e8c99a5123,11,3,2,455,,,0,"Use a correctly formatted example location in help

Change-Id: Iea1ebc13979a61d7bed397fb79e2b2a85f00c400
Closes-bug: 1342753
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/16/107416/2 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/v1/shell.py'],1,2535aec459b815f90b6a4fc12fe11b07aebc59e0,bug/1342753, 'specify \'swift+http://tenant%%3Aaccount:key@127.0.0.1:5000/' 'v2.0/container/obj\'. ' '(Note: \'%%3A\' is \':\' URL encoded.)')) 'specify \'swift+http://tenant%%3Aaccount:key@127.0.0.1:5000/' 'v2.0/container/obj\'. ' '(Note: \'%%3A\' is \':\' URL encoded.)')), 'specify \'swift://account:key@example.com/container/obj\'.')) 'specify \'swift://account:key@example.com/container/obj\'.')),6,2
openstack%2Fnova~master~If3310a1cb44952e8fe2efe0b3358783f729bc190,openstack/nova,master,If3310a1cb44952e8fe2efe0b3358783f729bc190,Correct exception for flavor extra spec create/update,MERGED,2014-01-12 11:07:04.000000000,2014-07-16 17:40:16.000000000,2014-07-16 17:40:14.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7494}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9275}, {'_account_id': 9578}, {'_account_id': 9645}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-01-12 11:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b81f69dcb1e7587d3822cf7bbde1da2e733decd', 'message': 'Correct exception for flavor extra spec create v2 API\n\nWhen create flavor extra spec failed, it will not raise\nMetadataLimitExceeded but two exceptions as following:\n1) DBDuplicateEntry\n2) FlavorNotFound\n\nThe create flavor extra spec API should catch the above two\nexceptions.\n\nChange-Id: If3310a1cb44952e8fe2efe0b3358783f729bc190\n'}, {'number': 2, 'created': '2014-01-15 06:26:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c1bba3e381be1f9c92f92bf1e90561eaeebb894', 'message': 'Correct exception for flavor extra spec create/update\n\nWhen create/update flavor extra spec failed for v2 api, it will not\nraise MetadataLimitExceeded for but two exceptions as following:\n1) FlavorExtraSpecUpdateCreateFailed\n2) FlavorNotFound\n\nWhen create/update flavor extra spec failed for v3 api, it will not\nraise DBDuplicateEntry but raise FlavorExtraSpecUpdateCreateFailed.\n\nThis patch updates the exception handling logic for create/update\nflavor extra spec.\n\nChange-Id: If3310a1cb44952e8fe2efe0b3358783f729bc190\n'}, {'number': 3, 'created': '2014-01-15 14:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a6e120e44f8eb453d3e7b76dc7de3c6b4e304b10', 'message': 'Correct exception for flavor extra spec create/update\n\nWhen create/update flavor extra spec failed for v2 api, it will not\nraise MetadataLimitExceeded for but two exceptions as following:\n1) FlavorIdExists\n2) FlavorNotFound\n\nWhen create/update flavor extra spec failed for v3 api, it will not\nraise DBDuplicateEntry but raise FlavorIdExists.\n\nThis patch updates the exception handling logic for create/update\nflavor extra spec.\n\nChange-Id: If3310a1cb44952e8fe2efe0b3358783f729bc190\n'}, {'number': 4, 'created': '2014-01-15 14:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27474a6ca4c51e151504ea9948d25717f8731ae9', 'message': 'Correct exception for flavor extra spec create/update\n\nWhen create/update flavor extra spec failed for v2 api, it will not\nraise MetadataLimitExceeded for but two exceptions as following:\n1) FlavorIdExists\n2) FlavorNotFound\n\nWhen create/update flavor extra spec failed for v3 api, it will not\nraise DBDuplicateEntry but raise FlavorIdExists.\n\nThis patch updates the exception handling logic for create/update\nflavor extra spec.\n\nChange-Id: If3310a1cb44952e8fe2efe0b3358783f729bc190\n'}, {'number': 5, 'created': '2014-02-23 02:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec41334188733ef26d7117979618a16d8c770ce0', 'message': 'Correct exception for flavor extra spec create/update\n\nWhen create/update flavor extra spec failed for v2 api, it will not\nraise MetadataLimitExceeded for but two exceptions as following:\n1) FlavorIdExists\n2) FlavorNotFound\n\nWhen create/update flavor extra spec failed for v3 api, it will not\nraise DBDuplicateEntry but raise FlavorExtraSpecUpdateCreateFailed.\n\nThis patch updates the exception handling logic for create/update\nflavor extra spec.\n\nChange-Id: If3310a1cb44952e8fe2efe0b3358783f729bc190\n'}, {'number': 6, 'created': '2014-02-23 05:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a5715827484a4485170321215b42cceeb0cdab2', 'message': 'Correct exception for flavor extra spec create/update\n\nWhen create/update flavor extra spec failed for v2 api, it will not\nraise MetadataLimitExceeded for but two exceptions as following:\n1) FlavorExtraSpecUpdateCreateFailed\n2) FlavorNotFound\n\nWhen create/update flavor extra spec failed for v3 api, it will not\nraise DBDuplicateEntry but raise FlavorExtraSpecUpdateCreateFailed.\n\nThis patch updates the exception handling logic for create/update\nflavor extra spec.\n\nChange-Id: If3310a1cb44952e8fe2efe0b3358783f729bc190\n'}, {'number': 7, 'created': '2014-03-14 03:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c2177d252f241f6578485d8d13f06899ebeccbb', 'message': 'Correct exception for flavor extra spec create/update\n\nWhen create/update flavor extra spec failed for v2 api, it will not\nraise MetadataLimitExceeded for but two exceptions as following:\n1) FlavorExtraSpecUpdateCreateFailed\n2) FlavorNotFound\n\nWhen create/update flavor extra spec failed for v3 api, it will not\nraise DBDuplicateEntry but raise FlavorExtraSpecUpdateCreateFailed.\n\nThis patch updates the exception handling logic for create/update\nflavor extra spec.\n\nChange-Id: If3310a1cb44952e8fe2efe0b3358783f729bc190\n'}, {'number': 8, 'created': '2014-05-25 03:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b197a0069bc2340aa6d706869e16f999cc11960', 'message': 'Correct exception for flavor extra spec create/update\n\nWhen create/update flavor extra spec failed for v2 api, it will not\nraise MetadataLimitExceeded for but two exceptions as following:\n1) FlavorExtraSpecUpdateCreateFailed\n2) FlavorNotFound\n\nWhen create/update flavor extra spec failed for v3 api, it will not\nraise DBDuplicateEntry but raise FlavorExtraSpecUpdateCreateFailed.\n\nThis patch updates the exception handling logic for create/update\nflavor extra spec.\n\nChange-Id: If3310a1cb44952e8fe2efe0b3358783f729bc190\n'}, {'number': 9, 'created': '2014-07-16 03:24:49.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/exception.py', 'nova/tests/api/openstack/compute/contrib/test_flavors_extra_specs.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors_extra_specs.py', 'nova/api/openstack/compute/contrib/flavorextraspecs.py', 'nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cdae1c4fec1ddfa7e5939e8e23ff916bf7c78dea', 'message': 'Correct exception for flavor extra spec create/update\n\nWhen create/update flavor extra spec failed for v2 api, it will not\nraise MetadataLimitExceeded for but two exceptions as following:\n1) FlavorExtraSpecUpdateCreateFailed\n2) FlavorNotFound\n\nWhen create/update flavor extra spec failed for v3 api, it will not\nraise DBDuplicateEntry but raise FlavorExtraSpecUpdateCreateFailed.\n\nThis patch updates the exception handling logic for create/update\nflavor extra spec.\n\nChange-Id: If3310a1cb44952e8fe2efe0b3358783f729bc190\n'}]",11,66187,cdae1c4fec1ddfa7e5939e8e23ff916bf7c78dea,129,17,9,7494,,,0,"Correct exception for flavor extra spec create/update

When create/update flavor extra spec failed for v2 api, it will not
raise MetadataLimitExceeded for but two exceptions as following:
1) FlavorExtraSpecUpdateCreateFailed
2) FlavorNotFound

When create/update flavor extra spec failed for v3 api, it will not
raise DBDuplicateEntry but raise FlavorExtraSpecUpdateCreateFailed.

This patch updates the exception handling logic for create/update
flavor extra spec.

Change-Id: If3310a1cb44952e8fe2efe0b3358783f729bc190
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/66187/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_flavors_extra_specs.py', 'nova/api/openstack/compute/contrib/flavorextraspecs.py']",2,6b81f69dcb1e7587d3822cf7bbde1da2e733decd,bug/extra-spec-exc,"from nova.openstack.common.db import exception as db_exc except db_exc.DBDuplicateEntry: msg = _(""Concurrent transaction has been committed, try again"") raise exc.HTTPConflict(explanation=msg) except exception.FlavorNotFound as e: raise exc.HTTPNotFound(explanation=e.format_message())", except exception.MetadataLimitExceeded as error: raise exc.HTTPBadRequest(explanation=error.format_message()),33,2
openstack%2Fnova~master~Ia31b33c9a1d347f15d3e0a67fa31ef6b25a7407a,openstack/nova,master,Ia31b33c9a1d347f15d3e0a67fa31ef6b25a7407a,shelve doesn't work on nova-cells environment,MERGED,2014-07-07 10:29:29.000000000,2014-07-16 17:27:42.000000000,2014-07-16 17:27:40.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-07 10:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18e3928860c7ede08cdd440b914da9434b83e947', 'message': ""shelve doesn't work on nova-cells environment\n\nThe compute_api shelve/unshelve methods expect an Instance object,\nbut cell is still passing the sqlalchemy form.\nSo adding shelve/unshelve to the list of methods that will receive an\nInstance object when using nova-cell.\n\nWhen shelving instance with nova-cell environment,\ninstance object needs to contain 'metadata' and 'info_cache'.\nSo fetching the same from databse and adding it to\ninstance object before calling shelve/unshelve methods.\n\nCloses-Bug: #1338451\nChange-Id: Ia31b33c9a1d347f15d3e0a67fa31ef6b25a7407a\n""}, {'number': 2, 'created': '2014-07-16 13:51:03.000000000', 'files': ['nova/tests/cells/test_cells_messaging.py', 'nova/cells/messaging.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9d4b49c542e2076c8a572d1e8c6d50e255efe087', 'message': ""shelve doesn't work on nova-cells environment\n\nThe compute_api shelve/unshelve methods expect an Instance object,\nbut cell is still passing the sqlalchemy form.\nSo adding shelve/unshelve to the list of methods that will receive an\nInstance object when using nova-cell.\n\nWhen shelving instance with nova-cell environment,\ninstance object needs to contain 'metadata' and 'info_cache'.\nSo fetching the same from databse and adding it to\ninstance object before calling shelve/unshelve methods.\n\nCloses-Bug: #1338451\nChange-Id: Ia31b33c9a1d347f15d3e0a67fa31ef6b25a7407a\n""}]",2,105112,9d4b49c542e2076c8a572d1e8c6d50e255efe087,25,11,2,8300,,,0,"shelve doesn't work on nova-cells environment

The compute_api shelve/unshelve methods expect an Instance object,
but cell is still passing the sqlalchemy form.
So adding shelve/unshelve to the list of methods that will receive an
Instance object when using nova-cell.

When shelving instance with nova-cell environment,
instance object needs to contain 'metadata' and 'info_cache'.
So fetching the same from databse and adding it to
instance object before calling shelve/unshelve methods.

Closes-Bug: #1338451
Change-Id: Ia31b33c9a1d347f15d3e0a67fa31ef6b25a7407a
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/105112/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/cells/test_cells_messaging.py', 'nova/cells/messaging.py']",2,18e3928860c7ede08cdd440b914da9434b83e947,lp/1338451," 'update_instance_metadata', 'shelve', 'unshelve'] expected_attrs = None # shelve and unshelve requires 'info_cache' and 'metadata', # because of this fetching same from database. if method in ['shelve', 'unshelve']: expected_attrs = ['metadata', 'info_cache'] inst_obj._from_db_object(message.ctxt, inst_obj, instance, expected_attrs=expected_attrs)"," 'update_instance_metadata'] inst_obj._from_db_object(message.ctxt, inst_obj, instance)",73,5
openstack%2Fnova~master~I74c28119c979e511cece6b839e25a40197b0e5d9,openstack/nova,master,I74c28119c979e511cece6b839e25a40197b0e5d9,libvirt: add migrateToURI2 method to fakelibvirt,MERGED,2014-07-16 11:51:29.000000000,2014-07-16 17:21:31.000000000,2014-07-16 16:46:58.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 11069}]","[{'number': 1, 'created': '2014-07-16 11:51:29.000000000', 'files': ['nova/tests/virt/libvirt/fakelibvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0c96d46e08af1419764fcbb9c2e3d8b0eed1005a', 'message': 'libvirt: add migrateToURI2 method to fakelibvirt\n\nWith the merge of\n\n  commit ea7da5152cdca7ba674e2137c3899909995e2287\n  Author: Solly Ross <sross@redhat.com>\n  Date:   Tue Feb 4 14:27:51 2014 -0500\n\n    Change listen address on libvirt live-migration\n\nthe libvirt driver uses migrateToURI2 instead of\nmigrateToURI. The fakelibvirt class did not define\nthis method so it was unable to be mocked out.\n\nChange-Id: I74c28119c979e511cece6b839e25a40197b0e5d9\nCloses-bug: 1342498\nSigned-off-by: Daniel P. Berrange <berrange@redhat.com>\n'}]",0,107329,0c96d46e08af1419764fcbb9c2e3d8b0eed1005a,18,9,1,1779,,,0,"libvirt: add migrateToURI2 method to fakelibvirt

With the merge of

  commit ea7da5152cdca7ba674e2137c3899909995e2287
  Author: Solly Ross <sross@redhat.com>
  Date:   Tue Feb 4 14:27:51 2014 -0500

    Change listen address on libvirt live-migration

the libvirt driver uses migrateToURI2 instead of
migrateToURI. The fakelibvirt class did not define
this method so it was unable to be mocked out.

Change-Id: I74c28119c979e511cece6b839e25a40197b0e5d9
Closes-bug: 1342498
Signed-off-by: Daniel P. Berrange <berrange@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/107329/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/fakelibvirt.py'],1,0c96d46e08af1419764fcbb9c2e3d8b0eed1005a,bug/1342498," def migrateToURI2(self, dconnuri, miguri, dxml, flags, dname, bandwidth): raise make_libvirtError( libvirtError, ""Migration always fails for fake libvirt!"", error_code=VIR_ERR_INTERNAL_ERROR, error_domain=VIR_FROM_QEMU) ",,7,0
openstack%2Fdesignate~master~I2c460b6074026bc95070ada4378e2f24d229510b,openstack/designate,master,I2c460b6074026bc95070ada4378e2f24d229510b,Fixed issue with elevated contexts modifying the original context,MERGED,2014-07-15 14:46:05.000000000,2014-07-16 17:14:39.000000000,2014-07-16 17:14:39.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-07-15 14:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c2f31082db24cefd56b0bbfbb67a592f6d106b02', 'message': 'Fixed issue with elevated contexts modifying the original context\n\nChange-Id: I2c460b6074026bc95070ada4378e2f24d229510b\n'}, {'number': 2, 'created': '2014-07-15 17:13:57.000000000', 'files': ['designate/tests/test_context.py', 'designate/context.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/71e8282abf81a8d83fbad5b8855d7a6d3fd3a403', 'message': 'Fixed issue with elevated contexts modifying the original context\n\nChange-Id: I2c460b6074026bc95070ada4378e2f24d229510b\n'}]",0,107070,71e8282abf81a8d83fbad5b8855d7a6d3fd3a403,14,4,2,8099,,,0,"Fixed issue with elevated contexts modifying the original context

Change-Id: I2c460b6074026bc95070ada4378e2f24d229510b
",git fetch https://review.opendev.org/openstack/designate refs/changes/70/107070/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/context.py'],1,c2f31082db24cefd56b0bbfbb67a592f6d106b02,fix-context-object,import copy return copy.deepcopy(d), return d,2,1
openstack%2Fnova~master~Iba305fb7f8236955ca732e467db9e424535be93d,openstack/nova,master,Iba305fb7f8236955ca732e467db9e424535be93d,add checksums to udp independent of /dev/vhost-net.,MERGED,2014-06-27 16:44:42.000000000,2014-07-16 17:05:31.000000000,2014-07-16 17:05:28.000000000,"[{'_account_id': 3}, {'_account_id': 1082}, {'_account_id': 1297}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-27 16:44:42.000000000', 'files': ['nova/network/linux_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0ca33df5660849ce305f9e9756007d95fcbbfa2b', 'message': 'add checksums to udp independent of /dev/vhost-net.\n\nIn newer kernel versions, the network devices added for lxc containers\ndo not get checksums added.  The result is the same as previously\noccurred when vhost-net became prevalent in kvm guests.\n\nSoftware that expects the checksums on packets will ignore them.  One example\nof such software is udhcpc in cirros.  Without this change, cirros containers\nin 3.13 kernels (Ubuntu 14.04) will fail to acquire an address via dhcp.\n\nCloses-Bug: #1335193\nChange-Id: Iba305fb7f8236955ca732e467db9e424535be93d\n'}]",0,103193,0ca33df5660849ce305f9e9756007d95fcbbfa2b,22,10,1,1082,,,0,"add checksums to udp independent of /dev/vhost-net.

In newer kernel versions, the network devices added for lxc containers
do not get checksums added.  The result is the same as previously
occurred when vhost-net became prevalent in kvm guests.

Software that expects the checksums on packets will ignore them.  One example
of such software is udhcpc in cirros.  Without this change, cirros containers
in 3.13 kernels (Ubuntu 14.04) will fail to acquire an address via dhcp.

Closes-Bug: #1335193
Change-Id: Iba305fb7f8236955ca732e467db9e424535be93d
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/103193/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/linux_net.py'],1,0ca33df5660849ce305f9e9756007d95fcbbfa2b,always-add-udp-checksums,, if not os.path.exists('/dev/vhost-net'): return,0,2
openstack%2Fheat~master~I4651687acac83312a974b446623f4dd8fd0b746e,openstack/heat,master,I4651687acac83312a974b446623f4dd8fd0b746e,Remove redundant method handle_get_attributes,MERGED,2014-07-14 11:05:44.000000000,2014-07-16 17:02:17.000000000,2014-07-16 17:02:17.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4715}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 7253}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-07-14 11:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/26f85a544434215f0a9400856db766dafa384e0d', 'message': 'Remove redundant method handle_get_attributes\n\nAll resources use _resolve_attribute method to resolve attribute\nschema. Base neutron class contains confused method\nhandle_get_attributes that should be deleted.\n\nChange-Id: I4651687acac83312a974b446623f4dd8fd0b746e\n'}, {'number': 2, 'created': '2014-07-15 08:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/095b284c400ea58fd8308612cfe19035663d28ca', 'message': 'Remove redundant method handle_get_attributes\n\nAll resources use _resolve_attribute method to resolve attribute\nschema. Base neutron class contains confused method\nhandle_get_attributes that should be deleted.\n\nChange-Id: I4651687acac83312a974b446623f4dd8fd0b746e\n'}, {'number': 3, 'created': '2014-07-15 12:35:07.000000000', 'files': ['heat/engine/resources/neutron/neutron.py', 'heat/tests/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/654d3360598fd884b4687cf6aebaeed606852067', 'message': 'Remove redundant method handle_get_attributes\n\nAll resources use _resolve_attribute method to resolve attribute\nschema. Base neutron class contains confused method\nhandle_get_attributes that should be deleted.\n\nChange-Id: I4651687acac83312a974b446623f4dd8fd0b746e\n'}]",15,106734,654d3360598fd884b4687cf6aebaeed606852067,43,11,3,6577,,,0,"Remove redundant method handle_get_attributes

All resources use _resolve_attribute method to resolve attribute
schema. Base neutron class contains confused method
handle_get_attributes that should be deleted.

Change-Id: I4651687acac83312a974b446623f4dd8fd0b746e
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/106734/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/neutron/neutron.py'],1,26f85a544434215f0a9400856db766dafa384e0d,106734, if name == 'show': return attributes if name in attributes.keys(): return attributes[name]," def handle_get_attributes(name, key, attributes): ''' Support method for responding to FnGetAtt ''' if key == 'show': return attributes if key in attributes.keys(): return attributes[key] raise exception.InvalidTemplateAttribute(resource=name, key=key) @staticmethod return self.handle_get_attributes(self.name, name, attributes)",5,14
openstack%2Fcinder~stable%2Ficehouse~I8758fb8ef3fccbba2a598240c42d625b997e2db6,openstack/cinder,stable/icehouse,I8758fb8ef3fccbba2a598240c42d625b997e2db6,Add cinder-manage cmd to update host column,MERGED,2014-06-29 15:59:15.000000000,2014-07-16 16:53:39.000000000,2014-07-16 16:53:38.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 8556}, {'_account_id': 8874}, {'_account_id': 9533}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-29 15:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b178ad1e0e2ffc2ecbec6596be592b790bfed386', 'message': ""Add cinder-manage cmd to update host column\n\nIf you deploy Cinder as per the default using the docs,\nyou can't later decide to add backends using the\nmulti-backend functionality. The reason is that multi-backend\nis implemented by appending a backend-name to the host entry.\n\nSo if you convert the config to multi-backend the hostname\nfor any volumes that you have created are no longer\nassociated with a valid volume-driver (ie you can no\nlonger perform operations including delete on these\nvolumes).\n\nIn addition, in the case of using a SAN attached backend if\none redeploys their cinder-volume service to another node\nthey'll have the same issue.\n\nThis patch adds a cinder-manage command that will go through\nvolumes that are located on a specified host and update\nthe host column on each of them.\n\nChange-Id: I8758fb8ef3fccbba2a598240c42d625b997e2db6\nCloses-Bug: 1320688\n(cherry picked from commit 2068164d0f155578d2f7a106afe464ef578032cb)\n""}, {'number': 2, 'created': '2014-07-05 14:33:04.000000000', 'files': ['bin/cinder-manage'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1d80539f99be8e8eccb5fd2b172406cbd4da30cb', 'message': ""Add cinder-manage cmd to update host column\n\nIf you deploy Cinder as per the default using the docs,\nyou can't later decide to add backends using the\nmulti-backend functionality. The reason is that multi-backend\nis implemented by appending a backend-name to the host entry.\n\nSo if you convert the config to multi-backend the hostname\nfor any volumes that you have created are no longer\nassociated with a valid volume-driver (ie you can no\nlonger perform operations including delete on these\nvolumes).\n\nIn addition, in the case of using a SAN attached backend if\none redeploys their cinder-volume service to another node\nthey'll have the same issue.\n\nThis patch adds a cinder-manage command that will go through\nvolumes that are located on a specified host and update\nthe host column on each of them.\n\nChange-Id: I8758fb8ef3fccbba2a598240c42d625b997e2db6\nCloses-Bug: 1320688\n(cherry picked from commit 2068164d0f155578d2f7a106afe464ef578032cb)\n""}]",0,103414,1d80539f99be8e8eccb5fd2b172406cbd4da30cb,33,9,2,2243,,,0,"Add cinder-manage cmd to update host column

If you deploy Cinder as per the default using the docs,
you can't later decide to add backends using the
multi-backend functionality. The reason is that multi-backend
is implemented by appending a backend-name to the host entry.

So if you convert the config to multi-backend the hostname
for any volumes that you have created are no longer
associated with a valid volume-driver (ie you can no
longer perform operations including delete on these
volumes).

In addition, in the case of using a SAN attached backend if
one redeploys their cinder-volume service to another node
they'll have the same issue.

This patch adds a cinder-manage command that will go through
volumes that are located on a specified host and update
the host column on each of them.

Change-Id: I8758fb8ef3fccbba2a598240c42d625b997e2db6
Closes-Bug: 1320688
(cherry picked from commit 2068164d0f155578d2f7a106afe464ef578032cb)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/14/103414/2 && git format-patch -1 --stdout FETCH_HEAD,['bin/cinder-manage'],1,b178ad1e0e2ffc2ecbec6596be592b790bfed386,bug/1320688," @args('--currenthost', required=True, help='Existing volume host name') @args('--newhost', required=True, help='New volume host name') def update_host(self, currenthost, newhost): """"""Modify the host name asscoiated with a volume. Particularly to recover from cases where one has moved their Cinder Volume node, or modfied their backend_name in a multi-backend config. """""" ctxt = context.get_admin_context() volumes = db.volume_get_all_by_host(ctxt, currenthost) for v in volumes: db.volume_update(ctxt, v['id'], {'host': newhost}) ",,16,0
openstack%2Fdesignate~master~I143882181e3346c4ebe1f0ad491c75a4db549fe4,openstack/designate,master,I143882181e3346c4ebe1f0ad491c75a4db549fe4,"Avoid logging ""Expected"" exceptions returned over RPC",MERGED,2014-07-15 22:32:19.000000000,2014-07-16 16:45:29.000000000,2014-07-16 16:45:28.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 12428}]","[{'number': 1, 'created': '2014-07-15 22:32:19.000000000', 'files': ['designate/exceptions.py', 'designate/rpc.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/2c9460505d07d0e46765a552b637e5a3296b667b', 'message': 'Avoid logging ""Expected"" exceptions returned over RPC\n\nWhen an expected exception, such as a NotFound or Duplicate is passed over\nRPC, we identify it via the `expected` attribute and raise oslo.messagings\nExpectedException. The internals of ExpectedException effectively save the\ncurrent exception details (type, trace, etc) inside the ExpectedException,\nwhen received on the client side, the ExpectedException is detected, and\nthe saved details are used to bubble the original exception back up. On\nboth sides of the RPC, logging is avoided when ExpectedException is used.\n\nChange-Id: I143882181e3346c4ebe1f0ad491c75a4db549fe4\nCloses-Bug: #1304152\n'}]",0,107195,2c9460505d07d0e46765a552b637e5a3296b667b,11,5,1,741,,,0,"Avoid logging ""Expected"" exceptions returned over RPC

When an expected exception, such as a NotFound or Duplicate is passed over
RPC, we identify it via the `expected` attribute and raise oslo.messagings
ExpectedException. The internals of ExpectedException effectively save the
current exception details (type, trace, etc) inside the ExpectedException,
when received on the client side, the ExpectedException is detected, and
the saved details are used to bubble the original exception back up. On
both sides of the RPC, logging is avoided when ExpectedException is used.

Change-Id: I143882181e3346c4ebe1f0ad491c75a4db549fe4
Closes-Bug: #1304152
",git fetch https://review.opendev.org/openstack/designate refs/changes/95/107195/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/exceptions.py', 'designate/rpc.py']",2,2c9460505d07d0e46765a552b637e5a3296b667b,,"from oslo.messaging import server as msg_server from oslo.messaging.rpc import dispatcher as rpc_dispatcherclass RPCDispatcher(rpc_dispatcher.RPCDispatcher): def _dispatch(self, ctxt, message): try: return super(RPCDispatcher, self)._dispatch(ctxt, message) except Exception as e: if getattr(e, 'expected', False): raise rpc_dispatcher.ExpectedException() else: raise dispatcher = RPCDispatcher(target, endpoints, serializer) return msg_server.MessageHandlingServer(TRANSPORT, dispatcher, 'eventlet')"," return messaging.get_rpc_server(TRANSPORT, target, endpoints, executor='eventlet', serializer=serializer)",17,5
openstack%2Fsahara~master~I3c3504fe705ee2d91414323217f7185a7a695e43,openstack/sahara,master,I3c3504fe705ee2d91414323217f7185a7a695e43,Update oslo-incubator lockutils module,MERGED,2014-07-11 03:37:45.000000000,2014-07-16 16:41:18.000000000,2014-07-16 14:21:33.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-11 03:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2dc1af961e9f80111846cb5d5f7e233684f62a92', 'message': ""Update oslo-incubator lockutils module\n\nChanges -\n * Don't import fcntl on Windows\n * pep8: fixed multiple violations\n * fixed typos found by RETF rules\n\nChange-Id: I3c3504fe705ee2d91414323217f7185a7a695e43\n""}, {'number': 2, 'created': '2014-07-11 05:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9f81691fc95f936123f2b2e438033a8d5689ab22', 'message': ""Update oslo-incubator lockutils module\n\nChanges -\n * Don't import fcntl on Windows\n * pep8: fixed multiple violations\n * fixed typos found by RETF rules\n\nChange-Id: I3c3504fe705ee2d91414323217f7185a7a695e43\n""}, {'number': 3, 'created': '2014-07-11 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/894cb12acbf958c6ab2c36feba8dffad1aa8826a', 'message': ""Update oslo-incubator lockutils module\n\nChanges -\n * Don't import fcntl on Windows\n * pep8: fixed multiple violations\n * fixed typos found by RETF rules\n\nChange-Id: I3c3504fe705ee2d91414323217f7185a7a695e43\n""}, {'number': 4, 'created': '2014-07-14 14:00:47.000000000', 'files': ['requirements.txt', 'etc/sahara/sahara.conf.sample', 'sahara/openstack/common/lockutils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/09c5a7ca0474ccb2ffa24989d2ec58e23841138c', 'message': ""Update oslo-incubator lockutils module\n\nChanges -\n * Don't import fcntl on Windows\n * pep8: fixed multiple violations\n * fixed typos found by RETF rules\n\nChange-Id: I3c3504fe705ee2d91414323217f7185a7a695e43\n""}]",0,106259,09c5a7ca0474ccb2ffa24989d2ec58e23841138c,40,10,4,7555,,,0,"Update oslo-incubator lockutils module

Changes -
 * Don't import fcntl on Windows
 * pep8: fixed multiple violations
 * fixed typos found by RETF rules

Change-Id: I3c3504fe705ee2d91414323217f7185a7a695e43
",git fetch https://review.opendev.org/openstack/sahara refs/changes/59/106259/4 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/lockutils.py'],1,2dc1af961e9f80111846cb5d5f7e233684f62a92,oslo-sync,"from sahara.openstack.common.gettextutils import _, _LE, _LI help='Enables or disables inter-process locks.'), help='Directory to use for lock files.')class _FileLock(object): def acquire(self): basedir = os.path.dirname(self.fname) if not os.path.exists(basedir): fileutils.ensure_tree(basedir) LOG.info(_LI('Created lock path: %s'), basedir) LOG.debug('Got file lock ""%s""', self.fname) return True raise threading.ThreadError(_(""Unable to acquire lock on"" "" `%(filename)s` due to"" "" %(exception)s"") % { 'filename': self.fname, 'exception': e, }) def __enter__(self): self.acquire() return self def release(self): LOG.debug('Released file lock ""%s""', self.fname) except IOError: LOG.exception(_LE(""Could not release the acquired lock `%s`""), def __exit__(self, exc_type, exc_val, exc_tb): self.release() def exists(self): return os.path.exists(self.fname) class _WindowsLock(_FileLock):class _FcntlLock(_FileLock):class _PosixLock(object): def __init__(self, name): # Hash the name because it's not valid to have POSIX semaphore # names with things like / in them. Then use base64 to encode # the digest() instead taking the hexdigest() because the # result is shorter and most systems can't have shm sempahore # names longer than 31 characters. h = hashlib.sha1() h.update(name.encode('ascii')) self.name = str((b'/' + base64.urlsafe_b64encode( h.digest())).decode('ascii')) def acquire(self, timeout=None): self.semaphore = posix_ipc.Semaphore(self.name, flags=posix_ipc.O_CREAT, initial_value=1) self.semaphore.acquire(timeout) return self def __enter__(self): self.acquire() return self def release(self): self.semaphore.release() self.semaphore.close() def __exit__(self, exc_type, exc_val, exc_tb): self.release() def exists(self): try: semaphore = posix_ipc.Semaphore(self.name) except posix_ipc.ExistentialError: return False else: semaphore.close() return True FileLock = _WindowsLock else: import base64 import hashlib import posix_ipc FileLock = _FcntlLockdef _get_lock_path(name, lock_file_prefix, lock_path=None): # NOTE(mikal): the lock name cannot contain directory # separators name = name.replace(os.sep, '_') if lock_file_prefix: sep = '' if lock_file_prefix.endswith('-') else '-' name = '%s%s%s' % (lock_file_prefix, sep, name) local_lock_path = lock_path or CONF.lock_path if not local_lock_path: # NOTE(bnemec): Create a fake lock path for posix locks so we don't # unnecessarily raise the RequiredOptError below. if InterProcessLock is not _PosixLock: raise cfg.RequiredOptError('lock_path') local_lock_path = 'posixlock:/' return os.path.join(local_lock_path, name) def external_lock(name, lock_file_prefix=None, lock_path=None): LOG.debug('Attempting to grab external lock ""%(lock)s""', {'lock': name}) lock_file_path = _get_lock_path(name, lock_file_prefix, lock_path) # NOTE(bnemec): If an explicit lock_path was passed to us then it # means the caller is relying on file-based locking behavior, so # we can't use posix locks for those calls. if lock_path: return FileLock(lock_file_path) return InterProcessLock(lock_file_path) def remove_external_lock_file(name, lock_file_prefix=None): """"""Remove an external lock file when it's not used anymore This will be helpful when we have a lot of lock files """""" with internal_lock(name): lock_file_path = _get_lock_path(name, lock_file_prefix) try: os.remove(lock_file_path) except OSError: LOG.info(_LI('Failed to remove file %(file)s'), {'file': lock_file_path}) def internal_lock(name): with _semaphores_lock: try: sem = _semaphores[name] except KeyError: sem = threading.Semaphore() _semaphores[name] = sem LOG.debug('Got semaphore ""%(lock)s""', {'lock': name}) return sem lock files on disk with a meaningful prefix. should work across multiple processes. This means that if two different workers both run a method decorated with @synchronized('mylock', external=True), only one of them will execute at a time. int_lock = internal_lock(name) with int_lock: if external and not CONF.disable_process_locking: ext_lock = external_lock(name, lock_file_prefix, lock_path) with ext_lock: yield ext_lock else: yield int_lock LOG.debug('Released semaphore ""%(lock)s""', {'lock': name}) LOG.debug('Got semaphore / lock ""%(function)s""', LOG.debug('Semaphore / lock released ""%(function)s""',","from sahara.openstack.common.gettextutils import _ # noqa from sahara.openstack.common import local help='Whether to disable inter-process locks'), help=('Directory to use for lock files.'))class _InterProcessLock(object): def __enter__(self): return self raise def __exit__(self, exc_type, exc_val, exc_tb): except IOError: LOG.exception(_(""Could not release the acquired lock `%s`""),class _WindowsLock(_InterProcessLock):class _PosixLock(_InterProcessLock):else: lock files on disk with a meaningful prefix. should work across multiple processes. This means that if two different workers both run a a method decorated with @synchronized('mylock', external=True), only one of them will execute at a time. :param lock_path: The lock_path keyword argument is used to specify a special location for external lock files to live. If nothing is set, then CONF.lock_path is used as a default. with _semaphores_lock: try: sem = _semaphores[name] except KeyError: sem = threading.Semaphore() _semaphores[name] = sem with sem: LOG.debug(_('Got semaphore ""%(lock)s""'), {'lock': name}) # NOTE(mikal): I know this looks odd if not hasattr(local.strong_store, 'locks_held'): local.strong_store.locks_held = [] local.strong_store.locks_held.append(name) try: if external and not CONF.disable_process_locking: LOG.debug(_('Attempting to grab file lock ""%(lock)s""'), {'lock': name}) # We need a copy of lock_path because it is non-local local_lock_path = lock_path or CONF.lock_path if not local_lock_path: raise cfg.RequiredOptError('lock_path') if not os.path.exists(local_lock_path): fileutils.ensure_tree(local_lock_path) LOG.info(_('Created lock path: %s'), local_lock_path) def add_prefix(name, prefix): if not prefix: return name sep = '' if prefix.endswith('-') else '-' return '%s%s%s' % (prefix, sep, name) # NOTE(mikal): the lock name cannot contain directory # separators lock_file_name = add_prefix(name.replace(os.sep, '_'), lock_file_prefix) lock_file_path = os.path.join(local_lock_path, lock_file_name) try: lock = InterProcessLock(lock_file_path) with lock as lock: LOG.debug(_('Got file lock ""%(lock)s"" at %(path)s'), {'lock': name, 'path': lock_file_path}) yield lock finally: LOG.debug(_('Released file lock ""%(lock)s"" at %(path)s'), {'lock': name, 'path': lock_file_path}) else: yield sem finally: local.strong_store.locks_held.remove(name) LOG.debug(_('Got semaphore / lock ""%(function)s""'), LOG.debug(_('Semaphore / lock released ""%(function)s""'),",155,79
openstack%2Frequirements~master~I7c0ca5c58f7b533d6fc93ec52f2dae11f69a3db1,openstack/requirements,master,I7c0ca5c58f7b533d6fc93ec52f2dae11f69a3db1,"Add dbus library, needed for the DRBD cinder driver integration.",ABANDONED,2014-06-10 11:39:04.000000000,2014-07-16 16:36:37.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 8871}, {'_account_id': 10677}]","[{'number': 1, 'created': '2014-06-10 11:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/73877ebbe48efbedce0f148a1a18f87ce32715a3', 'message': 'Add dbus library, needed for the DRBD cinder driver integration.\n\nDRBDmanage is a cluster-wide service to provide replicated storage\nwith a simple administration interface; its daemon listens on\nthe system dbus for commands.\n\nThe DRBD cinder volume driver needs to talk to the daemon, and so\nneeds the dbus library.\n\nThe library is available as python-dbus (deb), and dbus-python (rpm)\nin most distributions.\n\nChange-Id: I7c0ca5c58f7b533d6fc93ec52f2dae11f69a3db1\n'}, {'number': 2, 'created': '2014-07-01 05:51:04.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/92ce398a0f7f52ea690510d8372c7ba0a8e97482', 'message': 'Add dbus library, needed for the DRBD cinder driver integration.\n\nDRBDmanage is a cluster-wide service to provide replicated storage\nwith a simple administration interface; its daemon listens on\nthe system dbus for commands.\n\nThe DRBD cinder volume driver needs to talk to the daemon, and so\nneeds the dbus library.\n\nThe library is available as python-dbus (deb), and dbus-python (rpm)\nin most distributions.\n\nChange-Id: I7c0ca5c58f7b533d6fc93ec52f2dae11f69a3db1\n'}]",0,99013,92ce398a0f7f52ea690510d8372c7ba0a8e97482,10,4,2,10677,,,0,"Add dbus library, needed for the DRBD cinder driver integration.

DRBDmanage is a cluster-wide service to provide replicated storage
with a simple administration interface; its daemon listens on
the system dbus for commands.

The DRBD cinder volume driver needs to talk to the daemon, and so
needs the dbus library.

The library is available as python-dbus (deb), and dbus-python (rpm)
in most distributions.

Change-Id: I7c0ca5c58f7b533d6fc93ec52f2dae11f69a3db1
",git fetch https://review.opendev.org/openstack/requirements refs/changes/13/99013/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,73877ebbe48efbedce0f148a1a18f87ce32715a3,,"dbus-python>=0.83,<=1.2.0 # MIT License",,1,0
openstack%2Fsahara~master~I7d3fec1fafe548ad87973d33d052ea7cc79aeb59,openstack/sahara,master,I7d3fec1fafe548ad87973d33d052ea7cc79aeb59,Update oslo-incubator fileutils module,MERGED,2014-07-11 03:37:45.000000000,2014-07-16 16:25:24.000000000,2014-07-16 14:21:26.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7491}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-11 03:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7f4103694267575973583a3775a161d75863b6cc', 'message': 'Update oslo-incubator fileutils module\n\nChanges -\n * file_open: fixed docstring to refer to open() instead of file()\n\nChange-Id: I7d3fec1fafe548ad87973d33d052ea7cc79aeb59\n'}, {'number': 2, 'created': '2014-07-11 05:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/6785a0df2618ba2bb44d6deae5d5aad8bdc98856', 'message': 'Update oslo-incubator fileutils module\n\nChanges -\n * file_open: fixed docstring to refer to open() instead of file()\n\nChange-Id: I7d3fec1fafe548ad87973d33d052ea7cc79aeb59\n'}, {'number': 3, 'created': '2014-07-11 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/de97142a4dfe6d0095ca6c05f54a61b66d537762', 'message': 'Update oslo-incubator fileutils module\n\nChanges -\n * file_open: fixed docstring to refer to open() instead of file()\n\nChange-Id: I7d3fec1fafe548ad87973d33d052ea7cc79aeb59\n'}, {'number': 4, 'created': '2014-07-14 14:00:47.000000000', 'files': ['sahara/openstack/common/fileutils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7beb21dda0efaf9cc0d6b51697cdcd17ab091e3f', 'message': 'Update oslo-incubator fileutils module\n\nChanges -\n * file_open: fixed docstring to refer to open() instead of file()\n\nChange-Id: I7d3fec1fafe548ad87973d33d052ea7cc79aeb59\n'}]",0,106258,7beb21dda0efaf9cc0d6b51697cdcd17ab091e3f,52,11,4,7555,,,0,"Update oslo-incubator fileutils module

Changes -
 * file_open: fixed docstring to refer to open() instead of file()

Change-Id: I7d3fec1fafe548ad87973d33d052ea7cc79aeb59
",git fetch https://review.opendev.org/openstack/sahara refs/changes/58/106258/3 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/fileutils.py'],1,7f4103694267575973583a3775a161d75863b6cc,oslo-sync," LOG.debug(""Reloading cached file %s"" % filename) see built-in open() documentation for more details return open(*args, **kwargs)","from sahara.openstack.common.gettextutils import _ # noqa LOG.debug(_(""Reloading cached file %s"") % filename) see built-in file() documentation for more details return file(*args, **kwargs)",3,5
openstack%2Foslo-incubator~master~I4d9945ed9488d84276b1f76994f712ca8792a821,openstack/oslo-incubator,master,I4d9945ed9488d84276b1f76994f712ca8792a821,Add default log level for websocket,MERGED,2014-06-23 13:10:13.000000000,2014-07-16 16:21:20.000000000,2014-07-16 16:21:20.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 8851}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-06-23 13:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/55268250a8fd475c269dcb57948be9d3b1514d08', 'message': 'Add default log level for websocket\n\nAdded default log level as warning for websocket module.\n\nChange-Id: I4d9945ed9488d84276b1f76994f712ca8792a821\nblueprint: update-to-latest-websockify\n'}, {'number': 2, 'created': '2014-07-09 07:12:18.000000000', 'files': ['openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/ac92c06d3b2f9b7e891d6bea9708726c2d05f3ca', 'message': 'Add default log level for websocket\n\nAdded default log level as warning for websocket module.\n\nblueprint: update-to-latest-websockify\nChange-Id: I4d9945ed9488d84276b1f76994f712ca8792a821\n'}]",0,101908,ac92c06d3b2f9b7e891d6bea9708726c2d05f3ca,19,5,2,9303,,,0,"Add default log level for websocket

Added default log level as warning for websocket module.

blueprint: update-to-latest-websockify
Change-Id: I4d9945ed9488d84276b1f76994f712ca8792a821
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/08/101908/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/log.py'],1,55268250a8fd475c269dcb57948be9d3b1514d08,bp/update-to-latest-websockify," 'requests.packages.urllib3.connectionpool=WARN', 'websocket=WARN'", 'requests.packages.urllib3.connectionpool=WARN',2,1
openstack%2Foslo-incubator~master~If0f7e9cd0b610c4924791a04e14eb3055d14ff85,openstack/oslo-incubator,master,If0f7e9cd0b610c4924791a04e14eb3055d14ff85,Transfer class LazyPluggable from nova to oslo-incubator,ABANDONED,2014-07-16 15:47:45.000000000,2014-07-16 16:20:41.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-16 15:47:45.000000000', 'files': ['openstack/common/db/exception.py', 'openstack/common/importutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a82dc0e94450ee4faf4128f95f18d0c690cd9473', 'message': 'Transfer class LazyPluggable from nova to oslo-incubator\n\nNeed to transfer code of class LazyPluggable to oslo-incubator\nbecause this code copied in different projects. Also global attribute CONF\nis now transmitted in __init__ function.\nAlso was written test for this class.\n\nChange-Id: If0f7e9cd0b610c4924791a04e14eb3055d14ff85\n'}]",0,107425,a82dc0e94450ee4faf4128f95f18d0c690cd9473,3,1,1,10614,,,0,"Transfer class LazyPluggable from nova to oslo-incubator

Need to transfer code of class LazyPluggable to oslo-incubator
because this code copied in different projects. Also global attribute CONF
is now transmitted in __init__ function.
Also was written test for this class.

Change-Id: If0f7e9cd0b610c4924791a04e14eb3055d14ff85
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/25/107425/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/db/exception.py', 'openstack/common/importutils.py']",2,a82dc0e94450ee4faf4128f95f18d0c690cd9473,lazy_pluggable," function _get_backend. """"""","from openstack.common.db import exception function _get_backend.""""""",3,7
openstack%2Foslo-incubator~master~I57afcfdfafa2e572bac39071d14de45b0e1306cb,openstack/oslo-incubator,master,I57afcfdfafa2e572bac39071d14de45b0e1306cb,Transfer class LazyPluggable from nova to oslo-incubator,ABANDONED,2014-07-16 16:04:01.000000000,2014-07-16 16:20:02.000000000,,"[{'_account_id': 3}, {'_account_id': 6849}]","[{'number': 1, 'created': '2014-07-16 16:04:01.000000000', 'files': ['tests/unit/test_importutils.py', 'openstack/common/db/exception.py', 'openstack/common/importutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/93623a9606c35cfb308345c4c97d529567aa75d6', 'message': 'Transfer class LazyPluggable from nova to oslo-incubator\n\nNeed to transfer code of class LazyPluggable to oslo-incubator\nbecause this code copied in different projects. Also global attribute CONF\nis now transmitted in __init__ function.\nAlso was written test for this class.\n\nChange-Id: I57afcfdfafa2e572bac39071d14de45b0e1306cb\n'}]",0,107429,93623a9606c35cfb308345c4c97d529567aa75d6,3,2,1,10614,,,0,"Transfer class LazyPluggable from nova to oslo-incubator

Need to transfer code of class LazyPluggable to oslo-incubator
because this code copied in different projects. Also global attribute CONF
is now transmitted in __init__ function.
Also was written test for this class.

Change-Id: I57afcfdfafa2e572bac39071d14de45b0e1306cb
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/29/107429/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_importutils.py', 'openstack/common/db/exception.py', 'openstack/common/importutils.py']",3,93623a9606c35cfb308345c4c97d529567aa75d6,lazy2," """"""A pluggable backend loaded lazily based on some value. For example when we need to load backend, which depends on some option, we can register this option in config and load needed backend via function _get_backend. """""" def __init__(self, conf, pivot, config_group=None, **backends): :param conf: instance of config self._conf = conf raise PluginLoadError(msg) class PluginLoadError(Exception): pass","from openstack.common.db import exception """"""A pluggable backend loaded lazily based on some value."""""" def __init__(self, pivot, conf, config_group=None, **backends): :param conf: instance of config self._conf = conf raise exception.PluginLoadError(msg)",18,16
openstack%2Fzaqar~master~I57ebe853554199490adba8b2a091423f399b0565,openstack/zaqar,master,I57ebe853554199490adba8b2a091423f399b0565,feat(benchmarking) : Producer-Consumer scenario,MERGED,2014-06-09 20:15:44.000000000,2014-07-16 16:14:56.000000000,2014-07-16 16:14:56.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 6944}, {'_account_id': 7498}, {'_account_id': 8092}, {'_account_id': 10634}, {'_account_id': 10777}]","[{'number': 1, 'created': '2014-06-09 20:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c7c56b631ccd6e03e381c96ceb3a6029a0d888fa', 'message': 'feat(benchmarking) : Producer-Consumer scenario\n\nThis patch adds the ability to benchmark Marconi. The Conductor\nkicks off both the Consumer and Producer with the specified number\nof processes, workers and duration of the Benchmark.\n\nRunning the Benchmark is as simple as:\n    python conductor.py\n\nChange-Id: I57ebe853554199490adba8b2a091423f399b0565\n'}, {'number': 2, 'created': '2014-06-09 20:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/37d381ac990f2619179ba628663fb96adb0058db', 'message': 'feat(benchmarking) : Producer-Consumer scenario\n\nThis patch adds the ability to benchmark Marconi. The Conductor\nkicks off both the Consumer and Producer with the specified number\nof processes, workers and duration of the Benchmark.\n\nRunning the Benchmark is as simple as:\n    python conductor.py\nPartially Implements: blueprint basic-benchmarking\nChange-Id: I57ebe853554199490adba8b2a091423f399b0565\n'}, {'number': 3, 'created': '2014-06-09 23:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/686cbf2e1c930ce287de0220dd41476c820a83ea', 'message': 'feat(benchmarking) : Producer-Consumer scenario\n\nThis patch adds the ability to benchmark Marconi. The Conductor\nkicks off both the Consumer and Producer with the specified number\nof processes, workers and duration of the Benchmark.\n\nRunning the Benchmark is as simple as:\n    python conductor.py\nPartially Implements: blueprint basic-benchmarking\nChange-Id: I57ebe853554199490adba8b2a091423f399b0565\n'}, {'number': 4, 'created': '2014-06-11 17:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/89e468c32f95cfe2118874cc3a8a31d45314ff97', 'message': 'feat(benchmarking) : Producer-Consumer scenario\n\nThis patch adds the ability to benchmark Marconi. The Conductor\nkicks off both the Consumer and Producer with the specified number\nof processes, workers and duration of the Benchmark.\n\nRunning the Benchmark is as simple as:\n    python conductor.py\nPartially Implements: blueprint basic-benchmarking\nChange-Id: I57ebe853554199490adba8b2a091423f399b0565\n'}, {'number': 5, 'created': '2014-06-19 15:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b4d5ee01b37545ebe38226028ec0aeddcbdcfc3f', 'message': 'feat(benchmarking) : Producer-Consumer scenario\n\nThis patch adds the ability to benchmark Marconi. The benchmark tool\nis a console script, and can be triggered using\n\n$ marconi-bench\n\nThe Benchmark tool fires up both a Producer Process and a Consumer\nProcess, while accepting CLI parameters for the number of processes,\nnumber of workers and duration of test.\n\nThe Producer Process publishes messages to a given queue, while the\nConsumer consumes the messages by claiming and deleting them.\n\nSetup:\n\nBenchmark dependencies need to be pip installed:\n\n pip install -r bench-requirements.txt\n\nExport an environment variable called MESSAGES_PATH and set it to the\npath of messages.json in marconi/bench\n\nNote: This allows benchmarking with different set of messages rather\nthan those specified in messages.json\n\nUsage:\n\n$ marconi-bench --p {No. Processes} --w {No. Workers} --d {No. Seconds}\n\nOnce the values are entered, the benchmark begins!\n\nPartially Implements: blueprint basic-benchmarking\nChange-Id: I57ebe853554199490adba8b2a091423f399b0565\n'}, {'number': 6, 'created': '2014-06-19 15:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1da97968809314fe72c2402b33bbcfc19128326d', 'message': 'feat(benchmarking) : Producer-Consumer scenario\n\nThis patch adds the ability to benchmark Marconi. The benchmark tool\nis a console script, and can be triggered using\n\n$ marconi-bench\n\nThe Benchmark tool fires up both a Producer Process and a Consumer\nProcess, while accepting CLI parameters for the number of processes,\nnumber of workers and duration of test.\n\nThe Producer Process publishes messages to a given queue, while the\nConsumer consumes the messages by claiming and deleting them.\n\nSetup:\n\nBenchmark dependencies need to be pip installed:\n\n pip install -r bench-requirements.txt\n\nExport an environment variable called MESSAGES_PATH and set it to the\npath of messages.json in marconi/bench\n\nNote: This allows benchmarking with different set of messages rather\nthan those specified in messages.json\n\nUsage:\n\n$ marconi-bench --p {No. Processes} --w {No. Workers} --d {No. Seconds}\n\nOnce the values are entered, the benchmark begins!\n\nPartially Implements: blueprint basic-benchmarking\nChange-Id: I57ebe853554199490adba8b2a091423f399b0565\n'}, {'number': 7, 'created': '2014-06-23 18:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/28e55dcdc1ac45f22c47153a073c1436f13436f2', 'message': 'feat(benchmarking) : Producer-Consumer scenario\n\nThis patch adds the ability to benchmark Marconi. The benchmark tool\nis a console script, and can be triggered using\n\n$ marconi-bench\n\nThe Benchmark tool fires up both a Producer Process and a Consumer\nProcess, while accepting CLI parameters for the number of processes,\nnumber of workers and duration of test.\n\nThe Producer Process publishes messages to a given queue, while the\nConsumer consumes the messages by claiming and deleting them.\n\nSetup:\n\nBenchmark dependencies need to be pip installed:\n\n pip install -r bench-requirements.txt\n\nExport an environment variable called MESSAGES_PATH and set it to the\npath of messages.json in marconi/bench\n\nNote: This allows benchmarking with different set of messages rather\nthan those specified in messages.json\n\nUsage:\n\n$ marconi-bench --p {No. Processes} --w {No. Workers} --d {No. Seconds}\n\nPartially Implements: blueprint basic-benchmarking\nChange-Id: I57ebe853554199490adba8b2a091423f399b0565\n'}, {'number': 8, 'created': '2014-07-09 20:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/97097c1894ae444475e32d6f497ce9d604ff7434', 'message': 'feat(benchmarking) : Producer-Consumer scenario\n\nThis patch adds the ability to benchmark Marconi. The benchmark tool\nis a console script, and can be triggered using\n\n$ marconi-bench\n\nThe Benchmark tool fires up both a Producer Process and a Consumer\nProcess, while accepting CLI parameters for the number of processes,\nnumber of workers and duration of test.\n\nThe Producer Process publishes messages to a given queue, while the\nConsumer consumes the messages by claiming and deleting them.\n\nSetup:\n\nBenchmark dependencies need to be pip installed:\n\n pip install -r bench-requirements.txt\n\nExport an environment variable called MESSAGES_PATH and set it to the\npath of messages.json in marconi/bench\n\nNote: This allows benchmarking with different set of messages rather\nthan those specified in messages.json\n\nUsage:\n\n$ marconi-bench-pc --p {No. Processes} --w {No. Workers} --d {No. Seconds}\n\nExample:\n\n$ marconi-bench-pc --p 2 --w 2 --d 4\n\nPartially Implements: blueprint basic-benchmarking\nChange-Id: I57ebe853554199490adba8b2a091423f399b0565\n'}, {'number': 9, 'created': '2014-07-10 12:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/2074908e4da9d874928efbdf4c9c42a4c5d5873b', 'message': 'feat(benchmarking) : Producer-Consumer scenario\n\nThis patch adds the ability to benchmark Marconi. The benchmark tool\nis a console script, and can be triggered using\n\n$ marconi-bench-pc\n\nThe Benchmark tool fires up both a Producer Process and a Consumer\nProcess, while accepting CLI parameters for the number of processes,\nnumber of workers and duration of test.\n\nThe Producer Process publishes messages to a given queue, while the\nConsumer consumes the messages by claiming and deleting them.\n\nSetup:\n\nBenchmark dependencies need to be pip installed:\n\n pip install -r bench-requirements.txt\n\nExport an environment variable called MESSAGES_PATH and set it to the\npath of messages.json in marconi/bench\n\nNote: This allows benchmarking with different set of messages rather\nthan those specified in messages.json\n\nUsage:\n\n$ marconi-bench-pc --p {No. Processes} --w {No. Workers} --d {No. Seconds}\n\nExample:\n\n$ marconi-bench-pc --p 2 --w 2 --d 4\n\nPartially Implements: blueprint basic-benchmarking\nChange-Id: I57ebe853554199490adba8b2a091423f399b0565\n'}, {'number': 10, 'created': '2014-07-16 14:39:16.000000000', 'files': ['marconi/bench/README.rst', 'marconi/bench/consumer.py', 'marconi/bench/__init__.py', 'marconi/bench/conductor.py', 'bench-requirements.txt', 'marconi/bench/cli_config.py', 'marconi/bench/producer.py', 'marconi/bench/messages.json', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/4c950f99e44c209f920f759084d09d74ea899fc2', 'message': 'feat(benchmarking) : Producer-Consumer scenario\n\nThis patch adds the ability to benchmark Marconi. The benchmark tool\nis a console script, and can be triggered using\n\n$ marconi-bench-pc\n\nThe Benchmark tool fires up both a Producer Process and a Consumer\nProcess, while accepting CLI parameters for the number of processes,\nnumber of workers and duration of test.\n\nThe Producer Process publishes messages to a given queue, while the\nConsumer consumes the messages by claiming and deleting them.\n\nSetup:\n\nBenchmark dependencies need to be pip installed:\n\n pip install -r bench-requirements.txt\n\nExport an environment variable called MESSAGES_PATH and set it to the\npath of messages.json in marconi/bench\n\nNote: This allows benchmarking with different set of messages rather\nthan those specified in messages.json\n\nUsage:\n\n$ marconi-bench-pc -p {No. Processes} -w {No. Workers} -t {No. Seconds}\n\nExample:\n\n$ marconi-bench-pc -p 2 -w 2 -t 4\n\nPartially Implements: blueprint basic-benchmarking\nChange-Id: I57ebe853554199490adba8b2a091423f399b0565\n'}]",35,98875,4c950f99e44c209f920f759084d09d74ea899fc2,61,9,10,8092,,,0,"feat(benchmarking) : Producer-Consumer scenario

This patch adds the ability to benchmark Marconi. The benchmark tool
is a console script, and can be triggered using

$ marconi-bench-pc

The Benchmark tool fires up both a Producer Process and a Consumer
Process, while accepting CLI parameters for the number of processes,
number of workers and duration of test.

The Producer Process publishes messages to a given queue, while the
Consumer consumes the messages by claiming and deleting them.

Setup:

Benchmark dependencies need to be pip installed:

 pip install -r bench-requirements.txt

Export an environment variable called MESSAGES_PATH and set it to the
path of messages.json in marconi/bench

Note: This allows benchmarking with different set of messages rather
than those specified in messages.json

Usage:

$ marconi-bench-pc -p {No. Processes} -w {No. Workers} -t {No. Seconds}

Example:

$ marconi-bench-pc -p 2 -w 2 -t 4

Partially Implements: blueprint basic-benchmarking
Change-Id: I57ebe853554199490adba8b2a091423f399b0565
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/75/98875/8 && git format-patch -1 --stdout FETCH_HEAD,"['benchmark/conductor.py', 'benchmark/messages.json', 'benchmark/consumer.py', 'benchmark/producer.py']",4,c7c56b631ccd6e03e381c96ceb3a6029a0d888fa,bp/basic-benchmarking,"from __future__ import division import argparse from gevent import monkey as curious_george curious_george.patch_all(thread=False, select=False) import gevent import json import marktime import multiprocessing as mp import random import time from marconiclient.queues.v1 import client # TODO: Make configurable URL = 'http://localhost:8888' QUEUE_PREFIX = 'ogre-test-queue-' with open('messages.json') as f: message_pool = json.loads(f.read()) message_pool.sort(key=lambda msg: msg['weight']) def choose_message(): """"""Choose a message from our pool of possibilities."""""" # Assume message_pool is sorted by weight, ascending position = random.random() accumulator = 0.00 for each_message in message_pool: accumulator += each_message['weight'] if position < accumulator: return each_message['doc'] assert False def producer(stats, test_duration): """"""Producer worker."""""" cli = client.Client(URL) queue = cli.queue(QUEUE_PREFIX + '1') total_requests = 0 total_elapsed = 0 end = time.time() + test_duration while time.time() < end: marktime.start('post message') # TODO: Track/report errors try: queue.post(choose_message()) except Exception as ex: print(""Could not post a message : {0}"".format(ex)) else: total_elapsed += marktime.stop('post message').seconds total_requests += 1 stats.put({ 'total_requests': total_requests, 'total_elapsed': total_elapsed }) # TODO: make distributed across multiple machines # TODO: post across several queues (which workers to which queues? weight # them, so can have some busy queues, some not.) def load_generator(stats, num_workers, test_duration): # TODO: Have some way to get all of the workers to line up and start # at the same time (is this really useful?) gevent.joinall([ gevent.spawn(producer, stats, test_duration) for _ in range(num_workers) ]) def crunch(stats): total_requests = 0 total_latency = 0.0 while not stats.empty(): entry = stats.get_nowait() total_requests += entry['total_requests'] total_latency += entry['total_elapsed'] return total_requests, total_latency if __name__ == '__main__': parser = argparse.ArgumentParser() parser.add_argument('-p', type=int, default=1) parser.add_argument('-w', type=int, default=1) parser.add_argument('-d', type=int, default=5) args = parser.parse_args() num_procs = args.p num_workers = args.w test_duration = args.d # TODO: Multiple test runs, vary num workers and drain/delete # queues in between each run. Plot these on a graph, with # concurrency as the X axis. # # TODO: Correlate these numbers with the same from consumer workers, # and also queue length... stats = mp.Queue() args = (stats, num_workers, test_duration) procs = [ mp.Process(target=load_generator, args=args) for _ in range(num_procs) ] print('\nStarting Producer...') start = time.time() for each_proc in procs: each_proc.start() for each_proc in procs: each_proc.join() total_requests, total_latency = crunch(stats) duration = time.time() - start print('Duration: {0:.1f} sec'.format(duration)) print('Total Requests: {0}'.format(total_requests)) # TODO: Add one more stat: ""attempted req/sec"" so can # graph that on the x axis vs. achieved throughput and # latency. throughput = total_requests / duration print('Throughput: {0:.0f} req/sec'.format(throughput)) latency = 1000 * total_latency / total_requests print('Latency: {0:.1f} ms/req'.format(latency)) print('') # Blank line ",,364,0
openstack%2Fheat-translator~master~I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d,openstack/heat-translator,master,I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d,Added a module for intrinsic function.,MERGED,2014-06-25 08:25:21.000000000,2014-07-16 16:07:47.000000000,2014-07-16 16:07:47.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7193}, {'_account_id': 10068}, {'_account_id': 11355}]","[{'number': 1, 'created': '2014-06-25 08:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/a6a3836d4eb7da5315c504a1ee2355ef739ab678', 'message': 'Added a module for intrinsic function.\n\nCurenntly only handles get_ref_property specified in interface operation\ninput.\n\nChange-Id: I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d\nImplements: blueprint tosca-ref-property\n'}, {'number': 2, 'created': '2014-06-25 14:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/874fc751b4f72b48cf1617db94f420562b8491a8', 'message': 'Added a module for intrinsic function.\n\nCurenntly only handles get_ref_property specified in interface operation\ninput.\n\nChange-Id: I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d\nImplements: blueprint tosca-ref-property\n'}, {'number': 3, 'created': '2014-06-25 17:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/97b7e092ddeec6ca95a396f8635db7f006b67202', 'message': 'Added a module for intrinsic function.\n\nCurenntly only handles get_ref_property specified in interface operation\ninput.\n\nChange-Id: I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d\nImplements: blueprint tosca-ref-property\n'}, {'number': 4, 'created': '2014-06-25 20:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/c16506839bf613101d1b4539780cf6718f5c74a0', 'message': 'Added a module for intrinsic function.\n\nCurenntly only handles get_ref_property specified in interface operation\ninput.\n\nChange-Id: I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d\nImplements: blueprint tosca-ref-property\n'}, {'number': 5, 'created': '2014-06-25 21:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/994ff065c92793e8f0914f4ef605656a1997e37b', 'message': 'Added a module for intrinsic function.\n\nCurenntly only handles get_ref_property specified in interface operation\ninput.\n\nChange-Id: I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d\nImplements: blueprint tosca-ref-property\n'}, {'number': 6, 'created': '2014-07-03 07:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/48b9c5188d230d6401b62692bf3fb1e3cd1ef70b', 'message': 'Added a module for intrinsic function.\n\nCurenntly only handles get_ref_property specified in interface operation\ninput.\n\nRenamed ntype to node_type.\n\nChange-Id: I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d\nImplements: blueprint tosca-ref-property\n'}, {'number': 7, 'created': '2014-07-14 13:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/179af68a132899f666a7104258fac7fc6ffc2caa', 'message': 'Added a module for intrinsic function.\n\nCurenntly only handles get_ref_property specified in interface operation\ninput.\n\nRenamed ntype to node_type.\n\nChange-Id: I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d\nImplements: blueprint tosca-ref-property\n'}, {'number': 8, 'created': '2014-07-14 14:42:25.000000000', 'files': ['translator/toscalib/elements/interfaces.py', 'translator/toscalib/nodetemplate.py', '.gitignore', 'translator/toscalib/functions.py', 'translator/toscalib/tests/test_toscatpl.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/2f2e84123af6db910bb7abf9ed70d2733230930a', 'message': 'Added a module for intrinsic function.\n\nCurenntly only handles get_ref_property specified in interface operation\ninput.\n\nRenamed ntype to node_type.\n\nChange-Id: I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d\nImplements: blueprint tosca-ref-property\n'}]",1,102462,2f2e84123af6db910bb7abf9ed70d2733230930a,44,5,8,11355,,,0,"Added a module for intrinsic function.

Curenntly only handles get_ref_property specified in interface operation
input.

Renamed ntype to node_type.

Change-Id: I4d95b28faba9b55a5d16b9f16dbe36bd3bcd5b4d
Implements: blueprint tosca-ref-property
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/62/102462/1 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/elements/interfaces.py', 'translator/toscalib/nodetemplate.py', '.gitignore', 'translator/toscalib/functions.py', 'translator/toscalib/tests/test_toscatpl.py']",5,a6a3836d4eb7da5315c504a1ee2355ef739ab678,bp/tosca-ref-property,"from translator.toscalib.functions import GetRefProperty def test_interfaces(self): wordpress_node = [ node for node in self.tosca.nodetemplates if node.name == 'wordpress'][0] interfaces = wordpress_node.interfaces create = interfaces[0] self.assertEqual('tosca.interfaces.node.Lifecycle', create.type) self.assertEqual('create', create.name) self.assertEqual('wordpress_install.sh', create.implementation) self.assertIsNone(create.input) configure = interfaces[1] self.assertEqual('tosca.interfaces.node.Lifecycle', configure.type) self.assertEqual('configure', configure.name) self.assertEqual('wordpress_configure.sh', configure.implementation) self.assertEqual(4, len(configure.input)) wp_db_port = configure.input['wp_db_port'] self.assertTrue(isinstance(wp_db_port, GetRefProperty)) self.assertEqual('get_ref_property', wp_db_port.name) self.assertEqual(['database_endpoint', 'database_endpoint', 'port'], wp_db_port.args) self.assertDictContainsSubset({'get_input': 'db_port'}, wp_db_port.result())",,163,13
openstack%2Fsahara-image-elements~master~I0b534f37dcb589545070d3db670bf3d21471b67d,openstack/sahara-image-elements,master,I0b534f37dcb589545070d3db670bf3d21471b67d,Add support building images for Hadoop 2.4.0,MERGED,2014-07-07 10:07:57.000000000,2014-07-16 16:04:56.000000000,2014-07-15 10:42:11.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7604}, {'_account_id': 7710}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-07-07 10:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/97264d9390308a13ad3ccb25746255b1ae28689c', 'message': 'Add support building images for Hadoop 2.4.0\n\npartially implements blueprint add-vanilla-2-hadoop-2-4-0\n\nChange-Id: I0b534f37dcb589545070d3db670bf3d21471b67d\n'}, {'number': 2, 'created': '2014-07-08 09:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/b502c146d2b49b4a496c97e7519a0ff2f91a2f9c', 'message': 'Add support building images for Hadoop 2.4.0\n\npartially implements blueprint add-vanilla-2-hadoop-2-4-0\n\nChange-Id: I0b534f37dcb589545070d3db670bf3d21471b67d\n'}, {'number': 3, 'created': '2014-07-08 10:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/436969efc16b1a4f0b95e073996086e7edad0a01', 'message': 'Add support building images for Hadoop 2.4.0\n\npartially implements blueprint add-vanilla-2-hadoop-2-4-0\n\nChange-Id: I0b534f37dcb589545070d3db670bf3d21471b67d\n'}, {'number': 4, 'created': '2014-07-08 10:46:42.000000000', 'files': ['elements/oozie/install.d/50-setup-oozie', 'diskimage-create/diskimage-create.sh', 'elements/oozie/root.d/0-check'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/f1e5da6be693d0df6a0f07d10cb37c96c197ee58', 'message': 'Add support building images for Hadoop 2.4.0\n\npartially implements blueprint add-vanilla-2-hadoop-2-4-0\n\nChange-Id: I0b534f37dcb589545070d3db670bf3d21471b67d\n'}]",13,105107,f1e5da6be693d0df6a0f07d10cb37c96c197ee58,52,9,4,7710,,,0,"Add support building images for Hadoop 2.4.0

partially implements blueprint add-vanilla-2-hadoop-2-4-0

Change-Id: I0b534f37dcb589545070d3db670bf3d21471b67d
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/07/105107/3 && git format-patch -1 --stdout FETCH_HEAD,['diskimage-create/diskimage-create.sh'],1,97264d9390308a13ad3ccb25746255b1ae28689c,bp/add-vanilla-2-hadoop-2-4-0," export OOZIE_HADOOP_V2_3_DOWNLOAD_URL=${OOZIE_HADOOP_V2_3_DOWNLOAD_URL:-""http://sahara-files.mirantis.com/oozie-4.0.0-hadoop-2.3.0.tar.gz""} export OOZIE_HADOOP_V2_4_DOWNLOAD_URL=${OOZIE_HADOOP_V2_4_DOWNLOAD_URL:-""http://sahara-files.mirantis.com/oozie-4.0.0-hadoop-2.3.0.tar.gz""} export HADOOP_V2_3_NATIVE_LIBS_DOWNLOAD_URL=${HADOOP_V2_3_NATIVE_LIBS_DOWNLOAD_URL:-""http://sahara-files.mirantis.com/hadoop-2.3.0-native-libs.tar.gz""} export HADOOP_V2_4_NATIVE_LIBS_DOWNLOAD_URL=${HADOOP_V2_4_NATIVE_LIBS_DOWNLOAD_URL:-""http://sahara-files.mirantis.com/hadoop-2.3.0-native-libs.tar.gz""} if [ -z ""$HADOOP_VERSION"" -o ""$HADOOP_VERSION"" = ""2.3"" ]; then export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_3:-""2.3.0""} export ubuntu_image_name=${ubuntu_vanilla_hadoop_2_3_image_name:-""ubuntu_sahara_vanilla_hadoop_2_3_latest""} disk-image-create $ubuntu_elements_sequence -o $ubuntu_image_name mv $ubuntu_image_name.qcow2 ../ fi if [ -z ""$HADOOP_VERSION"" -o ""$HADOOP_VERSION"" = ""2.4"" ]; then export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_4:-""2.4.0""} export ubuntu_image_name=${ubuntu_vanilla_hadoop_2_4_image_name:-""ubuntu_sahara_vanilla_hadoop_2_4_latest""} if [ -z ""$HADOOP_VERSION"" -o ""$HADOOP_VERSION"" = ""2.3"" ]; then export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_3:-""2.3.0""} export fedora_image_name=${fedora_vanilla_hadoop_2_3_image_name:-""fedora_sahara_vanilla_hadoop_2_3_latest$suffix""} disk-image-create $fedora_elements_sequence -o $fedora_image_name mv $fedora_image_name.qcow2 ../ fi if [ -z ""$HADOOP_VERSION"" -o ""$HADOOP_VERSION"" = ""2.4"" ]; then export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_4:-""2.4.0""} export fedora_image_name=${fedora_vanilla_hadoop_2_4_image_name:-""fedora_sahara_vanilla_hadoop_2_4_latest$suffix""} if [ -z ""$HADOOP_VERSION"" -o ""$HADOOP_VERSION"" = ""2.3"" ]; then export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_3:-""2.3.0""} export centos_image_name=${centos_vanilla_hadoop_2_3_image_name:-""centos_sahara_vanilla_hadoop_2_3_latest$suffix""} disk-image-create $centos_elements_sequence -n -o $centos_image_name mv $centos_image_name.qcow2 ../ fi if [ -z ""$HADOOP_VERSION"" -o ""$HADOOP_VERSION"" = ""2.4"" ]; then export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2_4:-""2.4.0""} export centos_image_name=${centos_vanilla_hadoop_2_4_image_name:-""centos_sahara_vanilla_hadoop_2_4_latest$suffix""}"," export OOZIE_HADOOP_V2_DOWNLOAD_URL=${OOZIE_HADOOP_V2_DOWNLOAD_URL:-""http://sahara-files.mirantis.com/oozie-4.0.0-hadoop-2.3.0.tar.gz""} export HADOOP_V2_NATIVE_LIBS_DOWNLOAD_URL=${HADOOP_V2_NATIVE_LIBS_DOWNLOAD_URL:-""http://sahara-files.mirantis.com/hadoop-2.3.0-native-libs.tar.gz""} if [ -z ""$HADOOP_VERSION"" -o ""$HADOOP_VERSION"" = ""2"" ]; then export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2:-""2.3.0""} export ubuntu_image_name=${ubuntu_vanilla_hadoop_2_image_name:-""ubuntu_sahara_vanilla_hadoop_2_latest""} if [ -z ""$HADOOP_VERSION"" -o ""$HADOOP_VERSION"" = ""2"" ]; then export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2:-""2.3.0""} export fedora_image_name=${fedora_vanilla_hadoop_2_image_name:-""fedora_sahara_vanilla_hadoop_2_latest$suffix""} if [ -z ""$HADOOP_VERSION"" -o ""$HADOOP_VERSION"" = ""2"" ]; then export DIB_HADOOP_VERSION=${DIB_HADOOP_VERSION_2:-""2.3.0""} export centos_image_name=${centos_vanilla_hadoop_2_image_name:-""centos_sahara_vanilla_hadoop_2_latest$suffix""}",31,11
openstack%2Ffuel-main~master~I43201cd87968a3d75b44bd8697b02e2e49471954,openstack/fuel-main,master,I43201cd87968a3d75b44bd8697b02e2e49471954,Add MySQL 5.6 to specification,ABANDONED,2014-07-02 14:47:59.000000000,2014-07-16 15:54:06.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-07-02 14:47:59.000000000', 'files': ['requirements-rpm.txt', 'requirements-deb.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d4ac07930552484c7b4a68c05fa49259011a4aae', 'message': 'Add MySQL 5.6 to specification\n\nChange-Id: I43201cd87968a3d75b44bd8697b02e2e49471954\n'}]",0,104210,d4ac07930552484c7b4a68c05fa49259011a4aae,9,3,1,11090,,,0,"Add MySQL 5.6 to specification

Change-Id: I43201cd87968a3d75b44bd8697b02e2e49471954
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/10/104210/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-rpm.txt', 'requirements-deb.txt']",2,d4ac07930552484c7b4a68c05fa49259011a4aae,mysql-5.6,mysql-client-5.6 mysql-server-wsrep-5.6,mysql-client mysql-common mysql-server-wsrep,6,10
openstack%2Foslo-incubator~master~Ib0ca1941b3f8d6ff88ed6341653a0d3d423633b5,openstack/oslo-incubator,master,Ib0ca1941b3f8d6ff88ed6341653a0d3d423633b5,Transfer class LazyPluggable from nova to oslo-incubator,ABANDONED,2014-07-16 15:47:45.000000000,2014-07-16 15:51:00.000000000,,"[{'_account_id': 3}, {'_account_id': 10614}]","[{'number': 1, 'created': '2014-07-16 15:47:45.000000000', 'files': ['tests/unit/test_importutils.py', 'openstack/common/db/exception.py', 'openstack/common/importutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/e55251d9f88c43e7d040bb3f48f01b056117089e', 'message': 'Transfer class LazyPluggable from nova to oslo-incubator\n\nNeed to transfer code of class LazyPluggable to oslo-incubator\nbecause this code copied in different projects. Also global attribute CONF\nis now transmitted in __init__ function.\nAlso was written test for this class.\n\nChange-Id: Ib0ca1941b3f8d6ff88ed6341653a0d3d423633b5\n'}]",0,107424,e55251d9f88c43e7d040bb3f48f01b056117089e,4,2,1,10614,,,0,"Transfer class LazyPluggable from nova to oslo-incubator

Need to transfer code of class LazyPluggable to oslo-incubator
because this code copied in different projects. Also global attribute CONF
is now transmitted in __init__ function.
Also was written test for this class.

Change-Id: Ib0ca1941b3f8d6ff88ed6341653a0d3d423633b5
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/24/107424/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_importutils.py', 'openstack/common/db/exception.py', 'openstack/common/importutils.py']",3,e55251d9f88c43e7d040bb3f48f01b056117089e,lazy_pluggable," """"""A pluggable backend loaded lazily based on some value. For example when we need to load backend, which depends on some option, we can register this option in config and load needed backend via function _get_backend."""""" def __init__(self, conf, pivot, config_group=None, **backends): :param conf: instance of config self._conf = conf raise PluginLoadError(msg) class PluginLoadError(Exception): pass"," """"""A pluggable backend loaded lazily based on some value."""""" def __init__(self, pivot, conf, config_group=None, **backends): :param conf: instance of config self._conf = conf raise exception.PluginLoadError(msg)",17,11
openstack%2Fcookbook-openstack-network~master~Idc128c76f6b93ce52acc51bba9da08ccaa308ac3,openstack/cookbook-openstack-network,master,Idc128c76f6b93ce52acc51bba9da08ccaa308ac3,Allow veth_mtu to be configured in openvswitch agent,MERGED,2014-06-03 14:46:33.000000000,2014-07-16 15:47:46.000000000,2014-07-16 15:47:46.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2589}, {'_account_id': 7128}, {'_account_id': 8410}, {'_account_id': 9884}, {'_account_id': 9970}, {'_account_id': 12323}]","[{'number': 1, 'created': '2014-06-03 14:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/49c504124e0f36ba8944f05f5ccf445e71b4d37c', 'message': 'Allow veth_mtu to be configured in openvswitch agent\n\nWith openvswitch vlan, default of veth_mtu = 1500 is 4 bytes short and you end up\nwith either no traffic or abysmal network performance.  Need the 4 extra bytes for\nthe vlan id.\n\nChange-Id: Idc128c76f6b93ce52acc51bba9da08ccaa308ac3\nCloses-Bug: #1325754\n'}, {'number': 2, 'created': '2014-06-13 16:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/9b821046d132f3b5d51d146e5340b3cbc365828d', 'message': 'Allow veth_mtu to be configured in openvswitch agent\n\nWith openvswitch vlan, default of veth_mtu = 1500 is 4 bytes short and you end up\nwith either no traffic or abysmal network performance.  Need the 4 extra bytes for\nthe vlan id.\n\nChange-Id: Idc128c76f6b93ce52acc51bba9da08ccaa308ac3\nCloses-Bug: #1325754\n'}, {'number': 3, 'created': '2014-07-07 15:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/c2b7c18cfec289931d846bb17b82c9191a8b2a4e', 'message': 'Allow veth_mtu to be configured in openvswitch agent\n\nWith openvswitch vlan, default of veth_mtu = 1500 is 4 bytes short and you end up\nwith either no traffic or abysmal network performance.  Need the 4 extra bytes for\nthe vlan id.\n\nChange-Id: Idc128c76f6b93ce52acc51bba9da08ccaa308ac3\nCloses-Bug: #1325754\n'}, {'number': 4, 'created': '2014-07-08 14:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/b3b04f0796600134439efb704dbd62e69d92a97d', 'message': 'Allow veth_mtu to be configured in openvswitch agent\n\nWith openvswitch vlan, default of veth_mtu = 1500 is 4 bytes short and you end up\nwith either no traffic or abysmal network performance.  Need the 4 extra bytes for\nthe vlan id.\n\nChange-Id: Idc128c76f6b93ce52acc51bba9da08ccaa308ac3\nCloses-Bug: #1325754\n'}, {'number': 5, 'created': '2014-07-09 16:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/ff34133a9e2d68f37377834a45c26df021093c7f', 'message': 'Allow veth_mtu to be configured in openvswitch agent\n\nWith openvswitch vlan, default of veth_mtu = 1500 is 4 bytes short and you end up\nwith either no traffic or abysmal network performance.  Need the 4 extra bytes for\nthe vlan id.\n\nChange-Id: Idc128c76f6b93ce52acc51bba9da08ccaa308ac3\nCloses-Bug: #1325754\n'}, {'number': 6, 'created': '2014-07-15 15:09:30.000000000', 'files': ['spec/openvswitch_spec.rb', 'templates/default/plugins/openvswitch/ovs_neutron_plugin.ini.erb', 'attributes/default.rb', 'CHANGELOG.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/905ae152abd2d52c352c1df5888a41bb9694a0fc', 'message': 'Allow veth_mtu to be configured in openvswitch agent\n\nWith openvswitch vlan, default of veth_mtu = 1500 is 4 bytes short and you end up\nwith either no traffic or abysmal network performance.  Need the 4 extra bytes for\nthe vlan id.\n\nChange-Id: Idc128c76f6b93ce52acc51bba9da08ccaa308ac3\nCloses-Bug: #1325754\n'}]",0,97522,905ae152abd2d52c352c1df5888a41bb9694a0fc,66,8,6,7128,,,0,"Allow veth_mtu to be configured in openvswitch agent

With openvswitch vlan, default of veth_mtu = 1500 is 4 bytes short and you end up
with either no traffic or abysmal network performance.  Need the 4 extra bytes for
the vlan id.

Change-Id: Idc128c76f6b93ce52acc51bba9da08ccaa308ac3
Closes-Bug: #1325754
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/22/97522/6 && git format-patch -1 --stdout FETCH_HEAD,"['spec/openvswitch_spec.rb', 'templates/default/plugins/openvswitch/ovs_neutron_plugin.ini.erb', 'attributes/default.rb', 'CHANGELOG.md', 'metadata.rb']",5,49c504124e0f36ba8944f05f5ccf445e71b4d37c,bug-1325754-mtu,version '9.0.9',version '9.0.8',14,1
openstack%2Ffuel-main~master~I29a6ca7718a881677b45df291ddfd224f04c579b,openstack/fuel-main,master,I29a6ca7718a881677b45df291ddfd224f04c579b,Remove mirror yandex.ru from downloading ubuntu kernel,MERGED,2014-07-16 10:29:00.000000000,2014-07-16 15:47:15.000000000,2014-07-16 15:47:14.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 10474}]","[{'number': 1, 'created': '2014-07-16 10:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0481f77562852e6778298c83c7c13ee92659a7b8', 'message': 'Remove yandex.ru mirror from kernel. Move to new kernel 3.11.0-24 in installer\n\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b\n'}, {'number': 2, 'created': '2014-07-16 10:39:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c49a2193dc67f2172abc3870acabb14690096e55', 'message': 'Move to new kernel 3.11.0-24 in installer\n\nCloses-bug: #1311095\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b\n'}, {'number': 3, 'created': '2014-07-16 10:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/604a566033fcc9c7d1d62d466b41264fa6387ccf', 'message': 'Move to new kernel 3.11.0-24 in installer\n\nCloses-bug: #1311095\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b\n'}, {'number': 4, 'created': '2014-07-16 11:09:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1a2bbec1a5729ff0b2e159a4e745c16d1f3bfe0b', 'message': 'Remove mirror yandex.ru from downloading ubuntu kernel\n\nCloses-bug: #1311095\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b\n'}, {'number': 5, 'created': '2014-07-16 11:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/82c27879ef4c19d343c3d530b62eb0c3c6c2dbb6', 'message': 'Remove mirror yandex.ru from downloading ubuntu kernel\n\nCloses-bug: #1311095\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b\n'}, {'number': 6, 'created': '2014-07-16 13:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1c11f483874fbc2d64e9c6e6cc6ffecddbf59a95', 'message': 'Remove mirror yandex.ru from downloading ubuntu kernel\n\nCloses-bug: #1311095\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b\n'}, {'number': 7, 'created': '2014-07-16 13:00:55.000000000', 'files': ['mirror/ubuntu/boot.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/37b50682c58444d33bf5fbe17814591af2109e7e', 'message': 'Remove mirror yandex.ru from downloading ubuntu kernel\n\nCloses-bug: #1311095\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b\n'}]",6,107306,37b50682c58444d33bf5fbe17814591af2109e7e,43,8,7,8777,,,0,"Remove mirror yandex.ru from downloading ubuntu kernel

Closes-bug: #1311095
Change-Id: I29a6ca7718a881677b45df291ddfd224f04c579b
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/06/107306/2 && git format-patch -1 --stdout FETCH_HEAD,"['mirror/ubuntu/files/mkrepo.sh', 'mirror/ubuntu/boot.mk']",2,0481f77562852e6778298c83c7c13ee92659a7b8,new_kernel, wget -O $@ $(MIRROR_UBUNTU)/ubuntu/dists/precise-updates/main/installer-amd64/current/images/saucy-netboot/netboot.tar.gz, wget -O $@ http://mirror.yandex.ru/ubuntu/dists/precise-updates/main/installer-amd64/current/images/saucy-netboot/netboot.tar.gz,5,5
openstack%2Ffuel-main~stable%2F5.0~Icef47a0dfd5533112cca0c1d7b3760d011818e71,openstack/fuel-main,stable/5.0,Icef47a0dfd5533112cca0c1d7b3760d011818e71,Move to internal  osci repository (centos and ubuntu) for building mirrors,MERGED,2014-07-16 10:20:26.000000000,2014-07-16 15:32:30.000000000,2014-07-16 15:32:30.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-16 10:20:26.000000000', 'files': ['config.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/048a6b179b42ffd26955c162e42d14f5d4ddbd5c', 'message': 'Move to internal  osci repository (centos and ubuntu) for building mirrors\n\nAddres for new internal upstream repository is mirrors-local-msk.msk.mirantis.net\nCloses-bug: #1311095\nChange-Id: Icef47a0dfd5533112cca0c1d7b3760d011818e71\n(cherry picked from commit 9ebd199fb61c41744bbc91608d4490cadbc3cf5e)\n'}]",0,107298,048a6b179b42ffd26955c162e42d14f5d4ddbd5c,13,4,1,8777,,,0,"Move to internal  osci repository (centos and ubuntu) for building mirrors

Addres for new internal upstream repository is mirrors-local-msk.msk.mirantis.net
Closes-bug: #1311095
Change-Id: Icef47a0dfd5533112cca0c1d7b3760d011818e71
(cherry picked from commit 9ebd199fb61c41744bbc91608d4490cadbc3cf5e)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/98/107298/1 && git format-patch -1 --stdout FETCH_HEAD,['config.mk'],1,048a6b179b42ffd26955c162e42d14f5d4ddbd5c,,MIRROR_CENTOS?=http://mirrors-local-msk.msk.mirantis.net/centos/$(CENTOS_RELEASE)MIRROR_UBUNTU?=http://mirrors-local-msk.msk.mirantis.net/ubuntu/,MIRROR_CENTOS?=http://mirrors.msk.mirantis.net/centos/$(CENTOS_RELEASE)MIRROR_UBUNTU?=http://mirror.yandex.ru/ubuntu/,2,2
openstack%2Ffuel-main~stable%2F5.0~I29a6ca7718a881677b45df291ddfd224f04c579b,openstack/fuel-main,stable/5.0,I29a6ca7718a881677b45df291ddfd224f04c579b,Remove mirror yandex.ru from downloading ubuntu kernel,MERGED,2014-07-16 10:32:08.000000000,2014-07-16 15:32:09.000000000,2014-07-16 15:32:09.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-16 10:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/25116a2168a875994aedb6f08c876e380f310a3e', 'message': 'Remove yandex.ru mirror from kernel. Move to new kernel 3.11.0-24 in installer\n\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b\n'}, {'number': 2, 'created': '2014-07-16 10:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/933119301ca3eca18228d8e81bbe84ceb8d3d048', 'message': 'Remove yandex.ru mirror from kernel. Move to new kernel 3.11.0-24 in installer\n\nCloses-bug: #1342633\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b'}, {'number': 6, 'created': '2014-07-16 11:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3c9161e2e661d37d73045f834731bb00b922d385', 'message': 'Remove mirror yandex.ru from downloading ubuntu kernel\n\nCloses-bug: #1311095\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b\n'}, {'number': 7, 'created': '2014-07-16 13:01:40.000000000', 'files': ['mirror/ubuntu/boot.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5fde87037d6c589dbabab98e4c23ff8172b109b7', 'message': 'Remove mirror yandex.ru from downloading ubuntu kernel\n\nCloses-bug: #1311095\nChange-Id: I29a6ca7718a881677b45df291ddfd224f04c579b\n'}]",0,107307,5fde87037d6c589dbabab98e4c23ff8172b109b7,34,5,4,8777,,,0,"Remove mirror yandex.ru from downloading ubuntu kernel

Closes-bug: #1311095
Change-Id: I29a6ca7718a881677b45df291ddfd224f04c579b
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/07/107307/2 && git format-patch -1 --stdout FETCH_HEAD,"['mirror/ubuntu/files/mkrepo.sh', 'mirror/ubuntu/boot.mk']",2,25116a2168a875994aedb6f08c876e380f310a3e,, wget -O $@ $(MIRROR_UBUNTU)/ubuntu/dists/precise-updates/main/installer-amd64/current/images/saucy-netboot/netboot.tar.gz, wget -O $@ http://mirror.yandex.ru/ubuntu/dists/precise-updates/main/installer-amd64/current/images/saucy-netboot/netboot.tar.gz,5,5
openstack%2Fpython-keystoneclient~master~Ie67e93f2ed994c3702ac66e388cf216609dd44ff,openstack/python-keystoneclient,master,Ie67e93f2ed994c3702ac66e388cf216609dd44ff,Document authentication plugins,MERGED,2014-04-28 20:01:23.000000000,2014-07-16 15:30:39.000000000,2014-07-16 15:30:39.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7186}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/56ab3ea88f6dab1363091624d3b747a91319d978', 'message': 'Document authentication plugins\n\nExplain the plugins that are provided and some information on how to\nwrite new ones. This will obviously need to be expanded as more features\nare added.\n\nChange-Id: Ie67e93f2ed994c3702ac66e388cf216609dd44ff\n'}, {'number': 2, 'created': '2014-06-17 09:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/7bfda725d3090ff255176a2ed552fabafc24bea5', 'message': 'Document authentication plugins\n\nExplain the plugins that are provided and some information on how to\nwrite new ones. This will obviously need to be expanded as more features\nare added.\n\nChange-Id: Ie67e93f2ed994c3702ac66e388cf216609dd44ff\n'}, {'number': 3, 'created': '2014-07-02 12:19:32.000000000', 'files': ['doc/source/authentication-plugins.rst', 'doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/326d4fbbdb1d73abad2546dd98400a922fc8edf1', 'message': 'Document authentication plugins\n\nExplain the plugins that are provided and some information on how to\nwrite new ones. This will obviously need to be expanded as more features\nare added.\n\nChange-Id: Ie67e93f2ed994c3702ac66e388cf216609dd44ff\n'}]",24,84071,326d4fbbdb1d73abad2546dd98400a922fc8edf1,47,13,3,7191,,,0,"Document authentication plugins

Explain the plugins that are provided and some information on how to
write new ones. This will obviously need to be expanded as more features
are added.

Change-Id: Ie67e93f2ed994c3702ac66e388cf216609dd44ff
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/71/84071/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/authentication-plugins.rst', 'doc/source/index.rst']",2,56ab3ea88f6dab1363091624d3b747a91319d978,docs, authentication-plugins,,147,0
openstack%2Fglance~master~I7b5eab9df8569cf19421a372cc15c04b51b74ae0,openstack/glance,master,I7b5eab9df8569cf19421a372cc15c04b51b74ae0,Fix typo in swift store message,MERGED,2014-07-16 12:28:08.000000000,2014-07-16 15:30:31.000000000,2014-07-16 15:30:30.000000000,"[{'_account_id': 3}, {'_account_id': 455}]","[{'number': 1, 'created': '2014-07-16 12:28:08.000000000', 'files': ['glance/store/swift.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/c3596aef1ef2904c06eb01b02549541df51fbe65', 'message': 'Fix typo in swift store message\n\nThere was a missing space between words.\n\nChange-Id: I7b5eab9df8569cf19421a372cc15c04b51b74ae0\n'}]",0,107349,c3596aef1ef2904c06eb01b02549541df51fbe65,7,2,1,455,,,0,"Fix typo in swift store message

There was a missing space between words.

Change-Id: I7b5eab9df8569cf19421a372cc15c04b51b74ae0
",git fetch https://review.opendev.org/openstack/glance refs/changes/49/107349/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/store/swift.py'],1,c3596aef1ef2904c06eb01b02549541df51fbe65,typo," reason = _(""Badly formed Swift URI. Credentials not found for """," reason = _(""Badly formed Swift URI. Credentials not found for""",1,1
openstack%2Fhorizon~stable%2Ficehouse~Ifef6c4c1b2924b03df00f427cfe3e6a7f415e569,openstack/horizon,stable/icehouse,Ifef6c4c1b2924b03df00f427cfe3e6a7f415e569,adapt to python-novaclient-2.18.0,MERGED,2014-07-14 10:12:09.000000000,2014-07-16 15:30:28.000000000,2014-07-16 15:30:27.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 6610}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-07-14 10:12:09.000000000', 'files': ['openstack_dashboard/test/test_data/exceptions.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/937436f95c9311db9f907051e56a609040f572b0', 'message': 'adapt to python-novaclient-2.18.0\n\nNovaclient renamed HTTPNotImplemented to HttpNotImplemented\nand changed the attribute code to status in exceptions\n\nThis change should make the code work on newer and older versions.\n\nCloses-Bug: #1340596\n(cherry picked from commit 322004f8480e40af5e77ed843ff803005d5af27c)\n\nConflicts:\n\topenstack_dashboard/dashboards/project/instances/console.py\n\topenstack_dashboard/test/test_data/exceptions.py\n\nChange-Id: Ifef6c4c1b2924b03df00f427cfe3e6a7f415e569\n'}]",0,106724,937436f95c9311db9f907051e56a609040f572b0,30,7,1,4264,,,0,"adapt to python-novaclient-2.18.0

Novaclient renamed HTTPNotImplemented to HttpNotImplemented
and changed the attribute code to status in exceptions

This change should make the code work on newer and older versions.

Closes-Bug: #1340596
(cherry picked from commit 322004f8480e40af5e77ed843ff803005d5af27c)

Conflicts:
	openstack_dashboard/dashboards/project/instances/console.py
	openstack_dashboard/test/test_data/exceptions.py

Change-Id: Ifef6c4c1b2924b03df00f427cfe3e6a7f415e569
",git fetch https://review.opendev.org/openstack/horizon refs/changes/24/106724/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/test_data/exceptions.py'],1,937436f95c9311db9f907051e56a609040f572b0,novaclient_icehouse," if code is not None: if hasattr(self, 'http_status'): self.http_status = code else: self.code = code", self.code = code,5,1
openstack%2Fos-loganalyze~master~Ic653bad9a0f74fb5714ff7ccfc7da8d790dcff8b,openstack/os-loganalyze,master,Ic653bad9a0f74fb5714ff7ccfc7da8d790dcff8b,add support for source=swift,MERGED,2014-07-16 10:25:22.000000000,2014-07-16 15:27:46.000000000,2014-07-16 15:27:45.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-07-16 10:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/54f02f30a33ec3a10c96278e04f1720864afb76a', 'message': 'add support for source=swift\n\nWhile we are running both filesystem and swift in parallel, it\nwould be good to be able to bypass the filesystem to test the\ndifference between swift and volume performance.\n\nDo this with the addition of a source= cgi parameter. Currently\nsource=swift is the only thing that will change behavior. Internally\nwe default it to all.\n\nRefactoring of the cgi param parsing is done to make it cleaner\ncode and not copy/paste the cgi param parsing a 3rd time.\n\nChange-Id: Ic653bad9a0f74fb5714ff7ccfc7da8d790dcff8b\n'}, {'number': 2, 'created': '2014-07-16 14:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/48caa4151347e7af687748aeb445bcad6cb70ae1', 'message': 'add support for source=swift\n\nWhile we are running both filesystem and swift in parallel, it\nwould be good to be able to bypass the filesystem to test the\ndifference between swift and volume performance.\n\nDo this with the addition of a source= cgi parameter. Currently\nsource=swift is the only thing that will change behavior. Internally\nwe default it to all.\n\nRefactoring of the cgi param parsing is done to make it cleaner\ncode and not copy/paste the cgi param parsing a 3rd time.\n\nChange-Id: Ic653bad9a0f74fb5714ff7ccfc7da8d790dcff8b\n'}, {'number': 3, 'created': '2014-07-16 14:50:06.000000000', 'files': ['os_loganalyze/wsgi.py', 'os_loganalyze/generator.py', 'README.rst', 'os_loganalyze/util.py', 'os_loganalyze/tests/base.py', 'os_loganalyze/tests/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/6cfb3649173e230fbc9a96223d95763dbdecc1a4', 'message': 'add support for source=swift\n\nWhile we are running both filesystem and swift in parallel, it\nwould be good to be able to bypass the filesystem to test the\ndifference between swift and volume performance.\n\nDo this with the addition of a source= cgi parameter. Currently\nsource=swift is the only thing that will change behavior. Internally\nwe default it to all.\n\nRefactoring of the cgi param parsing is done to make it cleaner\ncode and not copy/paste the cgi param parsing a 3rd time.\n\nChange-Id: Ic653bad9a0f74fb5714ff7ccfc7da8d790dcff8b\n'}]",1,107301,6cfb3649173e230fbc9a96223d95763dbdecc1a4,17,3,3,2750,,,0,"add support for source=swift

While we are running both filesystem and swift in parallel, it
would be good to be able to bypass the filesystem to test the
difference between swift and volume performance.

Do this with the addition of a source= cgi parameter. Currently
source=swift is the only thing that will change behavior. Internally
we default it to all.

Refactoring of the cgi param parsing is done to make it cleaner
code and not copy/paste the cgi param parsing a 3rd time.

Change-Id: Ic653bad9a0f74fb5714ff7ccfc7da8d790dcff8b
",git fetch https://review.opendev.org/openstack/os-loganalyze refs/changes/01/107301/3 && git format-patch -1 --stdout FETCH_HEAD,"['os_loganalyze/wsgi.py', 'os_loganalyze/generator.py', 'README.rst', 'os_loganalyze/util.py', 'os_loganalyze/tests/base.py', 'os_loganalyze/tests/test_wsgi.py']",6,54f02f30a33ec3a10c96278e04f1720864afb76a,skipfs," def test_skip_file(self): # this should generate a TypeError because we're telling it to # skip the filesystem, but we don't have a working swift here. self.assertRaises( TypeError, self.get_generator('screen-c-api.txt.gz', source='swift')) ",,47,21
openstack%2Fbarbican-specs~master~Ie8f127fc41171cb901c9d535ba45f63ef0839aea,openstack/barbican-specs,master,Ie8f127fc41171cb901c9d535ba45f63ef0839aea,Adding Certificate chains to the Certificate container,MERGED,2014-06-17 20:52:44.000000000,2014-07-16 15:19:07.000000000,2014-07-16 15:19:07.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 9234}, {'_account_id': 10273}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-06-17 20:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/2c55c1e6bcd2507104d4e70ac79d9665813124cd', 'message': 'Adding Certificate chains to the Certificate container.\n\nAdding Certificate chains to the Certificate container.\n\nChange-Id: Ie8f127fc41171cb901c9d535ba45f63ef0839aea\nImplements: blueprint add-certificate-to-the-container-type\n'}, {'number': 2, 'created': '2014-07-15 18:26:41.000000000', 'files': ['specs/juno/add-certificate-to-the-container-type.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/53f24bac7bdaebdd0d9ea72b16d9e0f01b6a5ea3', 'message': 'Adding Certificate chains to the Certificate container\n\nAdding Certificate chains to the Certificate container\n\nChange-Id: Ie8f127fc41171cb901c9d535ba45f63ef0839aea\nImplements: blueprint add-certificate-to-the-container-type\n'}]",4,100677,53f24bac7bdaebdd0d9ea72b16d9e0f01b6a5ea3,24,9,2,7398,,,0,"Adding Certificate chains to the Certificate container

Adding Certificate chains to the Certificate container

Change-Id: Ie8f127fc41171cb901c9d535ba45f63ef0839aea
Implements: blueprint add-certificate-to-the-container-type
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/77/100677/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/add-certificate-to-container-type.rst'],1,2c55c1e6bcd2507104d4e70ac79d9665813124cd,bp/add-certificate-to-the-container-type," ""name"": ""intermediates"", ""secret_ref"":""http://localhost:9311/v1/b885a8320e4f48c69ddffb0364eeef36/secrets/21f2234a-f65c-11e3-8791-002564955ea1"" }, { ""name"": ""intermediates"", ""secret_ref"":""http://localhost:9311/v1/b885a8320e4f48c69ddffb0364eeef36/secrets/21f2234a-f65c-11e3-8791-002564955ea1"" }, {https://blueprints.launchpad.net/barbican/+spec/add-certificate-to-the-container-type ",https://blueprints.launchpad.net/barbican/+spec/add-certificate-to-the-container-type,9,1
openstack%2Fdesignate~master~I8af921f3c9470b03991b53e17735307686eaa03a,openstack/designate,master,I8af921f3c9470b03991b53e17735307686eaa03a,Imported Translations from Transifex,MERGED,2014-07-16 06:08:24.000000000,2014-07-16 15:16:45.000000000,2014-07-16 15:16:45.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-07-16 06:08:24.000000000', 'files': ['designate/locale/designate-log-info.pot'], 'web_link': 'https://opendev.org/openstack/designate/commit/ac5e8b2fc017f15537169b738e35270d4a756074', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8af921f3c9470b03991b53e17735307686eaa03a\n'}]",0,107237,ac5e8b2fc017f15537169b738e35270d4a756074,9,4,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I8af921f3c9470b03991b53e17735307686eaa03a
",git fetch https://review.opendev.org/openstack/designate refs/changes/37/107237/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/locale/designate-log-info.pot'],1,ac5e8b2fc017f15537169b738e35270d4a756074,transifex/translations,"""Project-Id-Version: designate 2014.2.dev223.g2593949\n""""POT-Creation-Date: 2014-07-16 06:08+0000\n""msgid ""count_report: Calling central's count_report."" msgstr """" #: designate/central/rpcapi.py:313#: designate/central/rpcapi.py:317#: designate/central/rpcapi.py:321#: designate/central/rpcapi.py:328#: designate/central/rpcapi.py:332#: designate/central/rpcapi.py:337#: designate/central/rpcapi.py:344#: designate/central/rpcapi.py:349#: designate/central/rpcapi.py:355#: designate/central/rpcapi.py:361#: designate/central/rpcapi.py:365#: designate/central/rpcapi.py:370#: designate/central/service.py:1372","""Project-Id-Version: designate 2014.2.dev216.g331ee19\n""""POT-Creation-Date: 2014-07-15 06:07+0000\n""#: designate/central/rpcapi.py:312#: designate/central/rpcapi.py:316#: designate/central/rpcapi.py:323#: designate/central/rpcapi.py:327#: designate/central/rpcapi.py:332#: designate/central/rpcapi.py:339#: designate/central/rpcapi.py:344#: designate/central/rpcapi.py:350#: designate/central/rpcapi.py:356#: designate/central/rpcapi.py:360#: designate/central/rpcapi.py:365#: designate/central/service.py:1352",18,14
openstack%2Fzaqar~master~I25581965b3deea201d33a7b53a284294c15290c7,openstack/zaqar,master,I25581965b3deea201d33a7b53a284294c15290c7,Adding dependencies for redis support in marconi,MERGED,2014-05-28 03:04:21.000000000,2014-07-16 15:16:27.000000000,2014-07-16 15:16:27.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 6944}, {'_account_id': 7498}, {'_account_id': 8092}]","[{'number': 1, 'created': '2014-05-28 03:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9e65630e314bdfed195ebd8d35c3962bd027e2fd', 'message': 'Adding dependencies for redis support in marconi.\n\nAdding the py-redis dependancy to marconi to support\nredis storage backends.\n\nChange-Id: I25581965b3deea201d33a7b53a284294c15290c7\nPartially-Implements: bp/redis-storage-driver\n'}, {'number': 2, 'created': '2014-05-30 09:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ab8b7752718030821b9cd44791f91a8d75dfbc8f', 'message': 'Adding dependencies for redis support in marconi\n\nAdding the py-redis dependancy to marconi to support\nredis storage backends\n\nChange-Id: I25581965b3deea201d33a7b53a284294c15290c7\nPartially-Implements: bp/redis-storage-driver\n'}, {'number': 3, 'created': '2014-05-30 10:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9f7ef6d27b6548b2b024dabce8a084a204575784', 'message': 'Adding dependencies for redis support in marconi\n\nAdding the py-redis dependancy to marconi to support\nredis storage backends\n\nChange-Id: I25581965b3deea201d33a7b53a284294c15290c7\nPartially-Implements: bp/redis-storage-driver\n'}, {'number': 4, 'created': '2014-07-02 01:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/3f9d73facbaf5d7c3aa9a713383795faba301e97', 'message': 'Adding dependencies for redis support in marconi\n\nAdding the py-redis dependancy to marconi to support\nredis storage backend\n\nChange-Id: I25581965b3deea201d33a7b53a284294c15290c7\nPartially-Implements: bp/redis-storage-driver\n'}, {'number': 5, 'created': '2014-07-16 01:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b89c2d2a7679e4074a17df85f3f01cd2a4a62caa', 'message': 'Adding dependencies for redis support in marconi\n\nAdding the py-redis dependancy to marconi to support\nredis storage backend\n\nChange-Id: I25581965b3deea201d33a7b53a284294c15290c7\nPartially-Implements: bp/redis-storage-driver\n'}, {'number': 6, 'created': '2014-07-16 01:43:41.000000000', 'files': ['test-requirements.txt', 'test-requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0293fa3b57a36c5d30b91ce3255ef193706c4a3f', 'message': 'Adding dependencies for redis support in marconi\n\nAdding the py-redis dependancy to marconi to support\nredis storage backend\n\nAdding the dependencies only to test-requirements-*.txt\nas database backend requirements will slowly be phased\nout of requirements-*.txt\n\nChange-Id: I25581965b3deea201d33a7b53a284294c15290c7\nPartially-Implements: bp/redis-storage-driver\n'}]",0,96017,0293fa3b57a36c5d30b91ce3255ef193706c4a3f,43,7,6,10812,,,0,"Adding dependencies for redis support in marconi

Adding the py-redis dependancy to marconi to support
redis storage backend

Adding the dependencies only to test-requirements-*.txt
as database backend requirements will slowly be phased
out of requirements-*.txt

Change-Id: I25581965b3deea201d33a7b53a284294c15290c7
Partially-Implements: bp/redis-storage-driver
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/17/96017/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9e65630e314bdfed195ebd8d35c3962bd027e2fd,bp/redis-storage-driver-dep,redis,,1,0
openstack%2Fmurano~master~I5819022918af6f240642d6751ab2d47b9be96e2b,openstack/murano,master,I5819022918af6f240642d6751ab2d47b9be96e2b,Add new requirements install in setup.sh script,MERGED,2014-07-15 12:13:23.000000000,2014-07-16 15:10:40.000000000,2014-07-16 15:10:40.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 8127}, {'_account_id': 8824}]","[{'number': 1, 'created': '2014-07-15 12:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/662b62d1c1f1fda657b30ea4d0e0ca8abcad355d', 'message': 'Add depended packages install\n\n* This changeset handle proper migrations, by installing required libs\n\nChange-Id: I5819022918af6f240642d6751ab2d47b9be96e2b\n'}, {'number': 2, 'created': '2014-07-15 16:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0379d69c242dee8388f1d6a5a8bce68e6bb0611e', 'message': 'Add depended packages install\n\n* This changeset handle proper db migrations, by installing required libs for postgresql\n\n\nChange-Id: I5819022918af6f240642d6751ab2d47b9be96e2b\n'}, {'number': 3, 'created': '2014-07-15 17:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/1961f9a69115265ee4b001f1098e8dab30c976d1', 'message': 'Add new requirements install in setup.sh script\n\n* This changeset handle proper db migrations, by installing required libs for postgresql\n\n\nChange-Id: I5819022918af6f240642d6751ab2d47b9be96e2b\n'}, {'number': 4, 'created': '2014-07-16 09:26:17.000000000', 'files': ['setup.sh', 'doc/source/install/prepare.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/ddadb8ce8231ec9b9d689e24f6aad348cfb169cb', 'message': 'Add new requirements install in setup.sh script\n\n* This changeset handle proper db migrations, by installing required libs for postgresql\n* Add required packages to /doc/source/install/prepare.rst document\n\nChange-Id: I5819022918af6f240642d6751ab2d47b9be96e2b\n'}]",1,107020,ddadb8ce8231ec9b9d689e24f6aad348cfb169cb,31,9,4,7613,,,0,"Add new requirements install in setup.sh script

* This changeset handle proper db migrations, by installing required libs for postgresql
* Add required packages to /doc/source/install/prepare.rst document

Change-Id: I5819022918af6f240642d6751ab2d47b9be96e2b
",git fetch https://review.opendev.org/openstack/murano refs/changes/20/107020/4 && git format-patch -1 --stdout FETCH_HEAD,['setup.sh'],1,662b62d1c1f1fda657b30ea4d0e0ca8abcad355d,setup-script/update,"debian_pkgs=""python-dev python-mysqldb libxml2-dev libxslt1-dev libffi-dev python-openssl mysql-client libpq-dev"" redhat_pkgs=""python-devel MySQL-python libxml2-devel libxslt-devel libffi-devel pyOpenSSL mysql postgresql-devel""","debian_pkgs=""python-dev python-mysqldb libxml2-dev libxslt1-dev libffi-dev python-openssl mysql-client "" redhat_pkgs=""python-devel MySQL-python libxml2-devel libxslt-devel libffi-devel pyOpenSSL mysql""",2,2
openstack%2Fmurano~master~I4816790e11f225c5dbb130747535094fdf06733e,openstack/murano,master,I4816790e11f225c5dbb130747535094fdf06733e,Fix DB migration script,MERGED,2014-07-02 14:40:17.000000000,2014-07-16 15:08:49.000000000,2014-07-16 15:08:48.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 10063}, {'_account_id': 11098}]","[{'number': 1, 'created': '2014-07-02 14:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/8ed3636c719a151aa14e52daa7481e2fe47f66e8', 'message': ""[WIP] Fix DB migration scripts\n\nProblem we had:\nIf the collation of the DB and table is utf8 and the columns we want to index are 512 chars,\nit is too big for the index since the max key length is 767 bytes.\nFollowing error message observed:\n(OperationalError) (1071, 'Specified key was too long; max key length is 767 bytes')\n\nFix:\nUse prefix indexes on MySQL (128 bytes)\n\nTBD:\n* Drop indexes in downgrade script\n* Add tests\n\nChange-Id: I4816790e11f225c5dbb130747535094fdf06733e\n""}, {'number': 2, 'created': '2014-07-03 23:04:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/088af53bc95a3bf110f8c0f9f567fded16cc8b8e', 'message': ""Fix DB migration scripts\n\nProblem we had:\nIf the collation of the DB and table is utf8 and the columns we want to\nindex are 512 chars, it is too big for the index since the max key length\nis 767 bytes.\n\nFollowing error message observed:\n(OperationalError) (1071, 'Specified key was too long; max key length is 767 bytes')\n\nFix:\nSpecify ascii_bin collation for indexed columns instead of UTF8 we're\nusing by default.\n\nChange-Id: I4816790e11f225c5dbb130747535094fdf06733e\n""}, {'number': 3, 'created': '2014-07-04 23:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/7dbed8a465f34022cfc958671bd4d8447a919a5c', 'message': ""Fix DB migration scripts\n\nProblem we had:\nIf the collation of the DB and table is utf8 and the columns we want to\nindex are 512 chars, it is too big for the index since the max key length\nis 767 bytes.\n\nFollowing error message observed:\n(OperationalError) (1071, 'Specified key was too long; max key length is 767 bytes')\n\nFix:\nReduce length of indexed columns. 128 chars should be probably enough.\n\nChange-Id: I4816790e11f225c5dbb130747535094fdf06733e\n""}, {'number': 4, 'created': '2014-07-05 11:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/2516c08c2dedb28e6a7924c0f1fea8a31ee58903', 'message': ""Fix DB migration scripts\n\nProblem we had:\nIf the collation of the DB and table is utf8 and the columns we want to\nindex are 512 chars, it is too big for the index since the max key length\nis 767 bytes.\n\nFollowing error message observed:\n(OperationalError) (1071, 'Specified key was too long; max key length is 767 bytes')\n\nFix:\nReduce length of indexed columns. 128 chars should be probably enough.\n\nChange-Id: I4816790e11f225c5dbb130747535094fdf06733e\n""}, {'number': 5, 'created': '2014-07-09 14:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/6fbf908f4447e301e9d16c897124ccf2bae1a81a', 'message': ""Fix DB migration scripts\n\nProblems we had:\n1. If the collation of the DB and table is utf8 and the columns we want to\n   index are 512 chars, it is too big for the index since the max key length\n   is 767 bytes. Following error message observed:\n   (OperationalError) (1071, 'Specified key was too long; max key length is 767 bytes')\n\n2. During migration to Alembic we missed the unique field for the\n   'fully_qualified_name' column of the table 'package'. This change\n   fixes that issue.\n\nFixes:\n1. Reduce length of indexed columns to fix problem. 128 chars should be probably enough\n2. Add uniqe paramater for column fully_qualified_name of table package\n\nAdditional changes:\n* Test that column is unique in DB migration tests (on real databases)\n* Introduced base for DB-related unit-tests. These tests use in-memory\n  instance of SQLite\n* Test that column is unique in DB-related unit-tests\n\nCloses-Bug: #1339201\nCloses-Bug: #1339728\nChange-Id: I4816790e11f225c5dbb130747535094fdf06733e\n""}, {'number': 6, 'created': '2014-07-10 12:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/26aa9334f2e12dd8dbf3e444c8b4ae97df8f481f', 'message': ""Fix DB migration script\n\nProblems we had:\n1. If the collation of the DB and table is utf8 and the columns we want to\n   index are 512 chars, it is too big for the index since the max key length\n   is 767 bytes. Following error message observed:\n   (OperationalError) (1071, 'Specified key was too long; max key length is 767 bytes')\n\n2. During migration to Alembic we missed the unique field for the\n   'fully_qualified_name' column of the table 'package'. This change\n   fixes that issue.\n\nFixes:\n1. Reduce length of indexed columns to fix problem. 128 chars should be probably enough\n2. Add uniqe paramater for column fully_qualified_name of table package\n\nAdditional changes:\n* Test that column is unique in DB migration tests (on real databases)\n* Introduced base for DB-related unit-tests. These tests use in-memory\n  instance of SQLite\n* Test that column is unique in DB-related unit-tests\n\nCloses-Bug: #1339201\nCloses-Bug: #1339728\nChange-Id: I4816790e11f225c5dbb130747535094fdf06733e\n""}, {'number': 7, 'created': '2014-07-12 13:16:04.000000000', 'files': ['murano/db/catalog/api.py', 'murano/db/migration/alembic_migrations/versions/001_inital_version.py', 'murano/tests/base.py', 'murano/db/api.py', 'murano/tests/db/migration/test_migrations.py', 'murano/tests/db/test_catalog.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/2174fc8a8496dd6cd9b154bc9bd5a8569695de13', 'message': ""Fix DB migration script\n\nProblems we had:\n1. If the collation of the DB and table is utf8 and the columns we want to\n   index are 512 chars, it is too big for the index since the max key length\n   is 767 bytes. Following error message observed:\n   (OperationalError) (1071, 'Specified key was too long; max key length is 767 bytes')\n\n2. During migration to Alembic we missed the unique field for the\n   'fully_qualified_name' column of the table 'package'. This change\n   fixes that issue.\n\nFixes:\n1. Reduce length of indexed columns to fix problem. 128 chars should be probably enough\n2. Add uniqe paramater for column fully_qualified_name of table package\n\nAdditional changes:\n* Test that column is unique in DB migration tests (on real databases)\n* Introduced base for DB-related unit-tests. These tests use in-memory\n  instance of SQLite\n* Test that column is unique in DB-related unit-tests\n\nCloses-Bug: #1339201\nCloses-Bug: #1339728\nChange-Id: I4816790e11f225c5dbb130747535094fdf06733e\n""}]",2,104205,2174fc8a8496dd6cd9b154bc9bd5a8569695de13,72,10,7,7600,,,0,"Fix DB migration script

Problems we had:
1. If the collation of the DB and table is utf8 and the columns we want to
   index are 512 chars, it is too big for the index since the max key length
   is 767 bytes. Following error message observed:
   (OperationalError) (1071, 'Specified key was too long; max key length is 767 bytes')

2. During migration to Alembic we missed the unique field for the
   'fully_qualified_name' column of the table 'package'. This change
   fixes that issue.

Fixes:
1. Reduce length of indexed columns to fix problem. 128 chars should be probably enough
2. Add uniqe paramater for column fully_qualified_name of table package

Additional changes:
* Test that column is unique in DB migration tests (on real databases)
* Introduced base for DB-related unit-tests. These tests use in-memory
  instance of SQLite
* Test that column is unique in DB-related unit-tests

Closes-Bug: #1339201
Closes-Bug: #1339728
Change-Id: I4816790e11f225c5dbb130747535094fdf06733e
",git fetch https://review.opendev.org/openstack/murano refs/changes/05/104205/1 && git format-patch -1 --stdout FETCH_HEAD,['murano/db/migration/alembic_migrations/versions/001_inital_version.py'],1,8ed3636c719a151aa14e52daa7481e2fe47f66e8,db," sa.Column('name', sa.String(length=80), nullable=False), op.create_index(op.f('ix_category_name'), 'category', ['name'], unique=True, ) nullable=False), op.create_index(op.f('ix_category_name'), 'package', ['fully_qualified_name'], unique=True, mysql_length={'fully_qualified_name': 128}) sa.Column('name', sa.String(length=512), nullable=False), op.create_index(op.f('ix_class_definition_name'), 'class_definition', ['name'], unique=True, mysql_length={'name': 128}) "," sa.Column('name', sa.String(length=80), nullable=False, index=True), nullable=False, index=True), sa.Column('name', sa.String(length=512), nullable=False, index=True),",21,3
openstack%2Ftripleo-image-elements~master~I882c94f142af3b27d99722bf2098324fe29a9e7e,openstack/tripleo-image-elements,master,I882c94f142af3b27d99722bf2098324fe29a9e7e,WIP: Enable haproxy_connect_any port access,ABANDONED,2014-07-16 14:57:38.000000000,2014-07-16 14:58:21.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-16 14:57:38.000000000', 'files': ['elements/haproxy/post-install.d/10-haproxy-selinux'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ce9b1e072951c76bfd561419a371b0e5d6888d5f', 'message': 'WIP: Enable haproxy_connect_any port access\n\nEnable a boolean to allow haproxy to proxy any port. If not set,\nSELinux, in enforcing mode, denies haproxy access and haproxy will\nfail to start.\n\nBug: 1339938\nChange-Id: I882c94f142af3b27d99722bf2098324fe29a9e7e\n'}]",0,107417,ce9b1e072951c76bfd561419a371b0e5d6888d5f,4,1,1,7471,,,0,"WIP: Enable haproxy_connect_any port access

Enable a boolean to allow haproxy to proxy any port. If not set,
SELinux, in enforcing mode, denies haproxy access and haproxy will
fail to start.

Bug: 1339938
Change-Id: I882c94f142af3b27d99722bf2098324fe29a9e7e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/17/107417/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/haproxy/post-install.d/10-haproxy-selinux'],1,ce9b1e072951c76bfd561419a371b0e5d6888d5f,bug/1339938,#!/bin/bash # Allow haproxy to proxy any port if SELinux is in enforcing mode if [[ -x /usr/sbin/semanage ]]; then setsebool -P haproxy_connect_any 1 fi ,,6,0
openstack%2Fopenstack-planet~master~Ibdfcf150af43e3a990b45ee40d19cb0c22536d7c,openstack/openstack-planet,master,Ibdfcf150af43e3a990b45ee40d19cb0c22536d7c,Added OlinData to Planet OpenStack,MERGED,2014-07-16 13:23:32.000000000,2014-07-16 14:47:30.000000000,2014-07-16 14:47:30.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-07-16 13:23:32.000000000', 'files': ['planet.ini', 'images/olindata.jpg'], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/04e22ac8a88d9d8a3c6ad9e303557dc1707f807b', 'message': 'Added OlinData to Planet OpenStack\n\nChange-Id: Ibdfcf150af43e3a990b45ee40d19cb0c22536d7c\n'}]",0,107377,04e22ac8a88d9d8a3c6ad9e303557dc1707f807b,8,3,1,12470,,,0,"Added OlinData to Planet OpenStack

Change-Id: Ibdfcf150af43e3a990b45ee40d19cb0c22536d7c
",git fetch https://review.opendev.org/openstack/openstack-planet refs/changes/77/107377/1 && git format-patch -1 --stdout FETCH_HEAD,"['planet.ini', 'images/olindata.jpg']",2,04e22ac8a88d9d8a3c6ad9e303557dc1707f807b,,,,7,0
openstack%2Fmurano-dashboard~master~I0d9cb1fe4fe1d0b991356e12ed62b101a3e2b0a8,openstack/murano-dashboard,master,I0d9cb1fe4fe1d0b991356e12ed62b101a3e2b0a8,Updated from global requirements,MERGED,2014-06-30 17:31:18.000000000,2014-07-16 14:43:27.000000000,2014-07-16 14:43:27.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7613}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 9536}]","[{'number': 1, 'created': '2014-06-30 17:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/afac50232b8e1757b9702e0d81023cb793b5bded', 'message': 'Update requirements file matching global requ and add argparse module\n\nChange-Id: I0d9cb1fe4fe1d0b991356e12ed62b101a3e2b0a8\n'}, {'number': 2, 'created': '2014-07-01 14:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/87aa5869c2d235ef94f34f7af63578e55d457c4f', 'message': 'Updated from global requirements\n\nChange-Id: I0d9cb1fe4fe1d0b991356e12ed62b101a3e2b0a8\n'}, {'number': 3, 'created': '2014-07-05 17:54:14.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f7b382e1d0f389dcf78c6f0be56bda7c1a7b4770', 'message': 'Updated from global requirements\n\nChange-Id: I0d9cb1fe4fe1d0b991356e12ed62b101a3e2b0a8\n'}]",1,103599,f7b382e1d0f389dcf78c6f0be56bda7c1a7b4770,72,8,3,9536,,,0,"Updated from global requirements

Change-Id: I0d9cb1fe4fe1d0b991356e12ed62b101a3e2b0a8
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/99/103599/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,afac50232b8e1757b9702e0d81023cb793b5bded,requ_update,"pbr>=0.6,!=0.7,<1.0six>=1.7.0argparse","pbr>=0.6,<1.0six>=1.5.2",3,2
openstack%2Fcinder-specs~master~Id0d9789a572f8addd72a5bdcd94d2eb2b24ba3d7,openstack/cinder-specs,master,Id0d9789a572f8addd72a5bdcd94d2eb2b24ba3d7,Proposal for incremental backup functionality,ABANDONED,2014-07-15 15:50:36.000000000,2014-07-16 14:41:11.000000000,,"[{'_account_id': 3}, {'_account_id': 11923}]","[{'number': 1, 'created': '2014-07-15 15:50:36.000000000', 'files': ['specs/juno/incremental-backup.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/d9950699e747c8ae849edcde7317b4bbad55122f', 'message': 'Proposal for incremental backup functionality\n\n    Change-Id: If60fdb2a7d5c783ab12a2b1f9a2d64decf8e428b\n\nChange-Id: Id0d9789a572f8addd72a5bdcd94d2eb2b24ba3d7\n'}]",0,107094,d9950699e747c8ae849edcde7317b4bbad55122f,5,2,1,11923,,,0,"Proposal for incremental backup functionality

    Change-Id: If60fdb2a7d5c783ab12a2b1f9a2d64decf8e428b

Change-Id: Id0d9789a572f8addd72a5bdcd94d2eb2b24ba3d7
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/94/107094/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/incremental-backup.rst'],1,d9950699e747c8ae849edcde7317b4bbad55122f,incremental-backup,"Proposal to implement incremental backup feature in Cinder This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode This specification proposes two new options to cinder-backup create api to support incremental backup and backup from a volume snapshot. ======================================== Support for incremental backup in Cinder ======================================== Launchpad Blueprint: https://blueprints.launchpad.net/cinder/+spec/incremental-backup Problem description: ==================== The current implementation of Cinder Backup functionality only supports full backup and restore of a given volume. There is no provision to backup changes only that happened since last backup. As the volumes grow bigger and over, all changes to volumes between backups stay relatively small, copying entire volumes during backups will be resource intensive and do not scale well for larger deployments. This specification discusses implementation of incremental backup feature in detail. Proposed change: ================ Cinder backup API, by default uses Swift as its backend. When a volume is backed up to Swift, Swift creates a manifest file that describes the contents of the backup volume. The manifest file contains header (metadata) and array of pointers to the volume backup files. Since Swift has an upper limit on the object size, Cinder backup API splits the volume data into individual chunks of Swift object size and uploads these individual chunks to Swift. Cinder volume backup manifest file includes these list of objects, their corresponding objects, the logical offset of each object within the volume and a message digest of each chunk to detect any unwarranted changes to objects. During restore operation, Cinder reconstructs the volume based on the manifest and individual chunks referenced in the manifest. To support incremental backup functionality, we introduce another object called shafile to the list of backup files. shafile file helps track changes to the volume since last backup. This new object holds SHA256s of the volume. A brief description of SHA-2 or SHA256 can be found at http://en.wikipedia.org/wiki/SHA-2. The backup manifest file will have a reference to this object. During a full backup operation, Cinder divides up the volume into fixed blocks of user configurable block size. It calculates SHA256 of each block and compiles a list of SHAs and uploads the shafile to the backup container. To keep the incremental backup implementation simple, an incremental operation is only performed with respect to a full backup. During incremental backup, cinder reads the shafile of the full backup. It creates a new shafile from the current volume data and compares the new shafile with full backup shafile to calculate the blocks that are changed since last full backup. We will use existing manifest mechanism to capture the delta. Since full backups do not contain any holes, offset+lengths of each chunk of the volume describe the full length of the volume logical address. However with incremental backup, this model is challenged and the offset/chunk of individual files become sparse. The absence of offset/length in a manifest represents the data that is not modified since last backup. One potential drawback of this approach is if changes to volume are fragmented, incremental backup may result in too many objects in Swift. However object stores like Swift are built to handle many small objects effectively. The new shafile is uploaded as part of the incremental backup. The manifest header identifies this backup as incremental backup and hence contains a reference to the full backup container. Following changes are made to the manifest header of the backup metadata['version'] = self.DRIVER_VERSION metadata['backup_id'] = backup['id'] metadata['volume_id'] = volume_id metadata['backup_name'] = backup['display_name'] metadata['backup_description'] = backup['display_description'] metadata['created_at'] = str(backup['created_at']) # Changes to metadata section of manifest metadata['shafile'] = <shafilename> # Path to shafile name. Or # can be hardcoded to ""shafile"" # in the container metadata['backup_type'] = ""incrementa/full"" # backup type metadata['full_container'] = <object path> # path of full backup Restore API is not expected to change, however restore implementation will be changed to handle incremental backup. To keep the restore from incremental backup simple and easy to test, the restore operation first performs restore of the full volume from the full backup copy and then apply incremental changes at offset and length as described in the incremental backup manifest. Snapshot based backups ====================== Since existing backup implementation copies the data directly from the volume, it requires the volume to be detached from the instance. For most cloud workloads this may be sufficient but other workloads that cannot tolerate prolonged downtimes, a snapshot based backup solution can be a viable alternative. Snapshot based backup will perform a point in time copy of the volume and backup the data from point in time copy. This approach does not require volume to be detached from the instance. Rest of the backup and restore functionality remain the same. As an alternative, snapshot based backup can be implemented by extending existing backup functionality to snapshot volumes. This approach can be lot more simpler than backup API taking snapshot of the volume and then managing the snapshots. Alternatives ============ Incremental backup offers two important benefits: 1. Use less storage when storing backup images 2. Use less network bandwidth and improve overall efficiency of backup process in terms of CPU and time utilization The first benefit can be achieved as a post processing of the backup images to remove duplication or by using dedupe enabled backup storage. However the second benefit cannot be achieved unless Cinder backup supports incremental backup. Data model impact ================= No percieved data model changes REST API impact =============== No new APIs are proposed. Instead existing backup API will be enhanced to accept additional option called ""--incr"" with <path to full backup container>"" as its argument. cinder backup-create <volumeid> --incr <full backup container> Performs incremental backup cinder backup-create <volumeid> --snapshot Optionally backup-create will backup a snapshot of the volume. Snapshot based backups can be performed while the volume is still attached to the instance. cinder backup-create <volumeid> --snapshot --incr <full backup container> Optionally backup-create will perform incremental backup from volume snapshot No anticipated changes to restore api Security impact =============== None Notifications impact ==================== None Other end user impact ===================== python-cinderclient will be modified to accept ""--incr"" option. It may include some validation code to validate if the full backup container path is valid Currenly backup functionality is not integrated with OpenStack dashboard. When it happens, the dashboard will provide an option for user to choose incremental backup Performance Impact ================== Except for calculating SHAs during full backup operation, there is no other performance impact on existing API. The performance penalty can be easily offset by the efficiency gained by incremental backup. Also new hardware support CPU instructions to calculate SHAs which alleviates some stress on the CPU cycles. Other deployer impact ===================== None Developer impact ================ None Implementation ============== Assignee(s) Primary assignee: muralibalcha(murali.balcha@triliodata.com) Other contributors: giribasava(giri.basava@triliodata.com) Work Items ========== 1. python-cinderclient That accepts ""--incr"" option and some validation code 2. cinder/api Which parses the ""--incr"" option 3. cinder/backup/api.py backup api signature is modified 4. cinder/backup/manager.py 5. cinder/backup/driver/swift.py Heavy lifting is done here. Both backup and restore apis will be modified. Dependencies ============ None Testing ======= Unit tests will be added for incremental backup. Testing will primarily focus on the following: 1. SHA file generation 2. Creating various changes to the original volume. These include 1. Changes to first block 2. Changes to last block 3. Changes to odd number of successive blocks 4. Changes to even number of successive blocks 5. Changes spread across multiple sections of the volume 3. Perform 1 incremental 4. Peform multiple incremental backups 5. Restore series of incremental backups and compare the contents 6. Perform full backup, then incremental, then full and then incremenal restore the volume from various backups. Documentation Impact ==================== Need to document new option in the block storage manual. ",,234,0
openstack%2Fcinder-specs~master~I1d798fe19078b2e27fac96971e040667bced3a73,openstack/cinder-specs,master,I1d798fe19078b2e27fac96971e040667bced3a73,Incorporated Xing's commments,ABANDONED,2014-07-15 11:36:03.000000000,2014-07-16 14:40:50.000000000,,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 11923}]","[{'number': 1, 'created': '2014-07-15 11:36:03.000000000', 'files': ['specs/juno/incremental-backup.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/3c8e1717e4d72ad6ca61098df80a0a54748c23e5', 'message': ""Incorporated Xing's commments\n\nChange-Id: I1d798fe19078b2e27fac96971e040667bced3a73\n""}]",0,107004,3c8e1717e4d72ad6ca61098df80a0a54748c23e5,7,4,1,11923,,,0,"Incorporated Xing's commments

Change-Id: I1d798fe19078b2e27fac96971e040667bced3a73
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/04/107004/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/incremental-backup.rst'],1,3c8e1717e4d72ad6ca61098df80a0a54748c23e5,incremental-backup,"This work is licensed under a Creative Commons Attribution 3.0 Unportedhttp://creativecommons.org/licenses/by/3.0/legalcode This specification proposes two new options to cinder-backup create api to support incremental backup and backup from a volume snapshot.only that happened since last backup. As the volumes grow bigger and over, all changes to volumes between backups stay relatively small, copyingCinder backup API, by default uses Swift as its backend. When a volume is backed up to Swift, Swift creates a manifest file that describes the contentsobject size, Cinder backup API splits the volume data into individual chunks of Swift object size and uploads these individual chunks to Swift. Cinder volume backup manifest file includes these list of objects, their corresponding objects, the logical offset of each object within the volume and a message digest of each chunk to detect any unwarranted changes to objects. During restore operation, Cinder reconstructs the volume based on the manifest and individual chunks referenced in the manifest. shafile to the list of backup files. shafile file helps track changes to the volume since last backup. This new object holds SHA256s of the volume. A brief description of SHA-2 or SHA256 can be found at http://en.wikipedia.org/wiki/SHA-2. The backup manifest file will have a reference to this object. During a full backup operation, Cinder divides up the volume into fixed blocks of user configurable block size. It calculates SHA256 of each block and compiles a list of SHAs and uploads the shafile to the backup container.full backups do not contain any holes, offset+lengths of each chunk of with incremental backup, this model is challenged and the offset/chunk of represents the data that is not modified since last backup. One potential drawback of this approach is if changes to volume are fragmented, incremental backup may result in too many objects in Swift. However object stores like Swift are built to handle many small objects effectively.contains a reference to the full backup container.changed to handle incremental backup. To keep the restore from incremental backup simple and easy to test, the restore operation first performs restoreAs an alternative, snapshot based backup can be implemented by extending existing backup functionality to snapshot volumes. This approach can be lot more simpler than backup API taking snapshot of the volume and then managing the snapshots. Incremental backup offers two important benefits:second benefit cannot be achieved unless Cinder backup supports incremental backup.No new APIs are proposed. Instead existing backup API will be enhanced tocinder backup-create <volumeid> --incr <full backup container>cinder backup-create <volumeid> --snapshot Optionally backup-create will backup a snapshot of the volume. Snapshot based backups can be performed while the volume is still attached to the instance. cinder backup-create <volumeid> --snapshot --incr <full backup container>Currenly backup functionality is not integrated with OpenStack dashboard. When it happens, the dashboard will provide an option for user to choose incremental backupoffset by the efficiency gained by incremental backup. Also new hardwaremuralibalcha(murali.balcha@triliodata.com)giribasava(giri.basava@triliodata.com) Heavy lifting is done here.Unit tests will be added for incremental backup. 5. Changes spread across multiple sections of the volume restore the volume from various backups.Need to document new option in the block storage manual.","This work is licensed under a Creative Commons Attribution 3.0 Unported http://creativecommons.org/licenses/by/3.0/legalcodeonly that happened since last backup. As the volumes grow bigger and over all changes to volume between backups stay relatively small, copyingCinder backup API, by default uses swift as its backend. When a volume is backed up to Swift, swift creates a manifest file that describes the contentsobject size, cinder backup api splits the volume data into individual chunks of swift object size and uploads these individual chunks to swift. Cinder volume backup manifest file includes these list of object, their corresponding size, the logical offset of each object within the volume and a message digest of each chunk to detect any unwarranted changes to objects. During restore operation, cinder reconstructs the volume based on the manifest and individual chunks referenced in the manifest. shafile to the list of backup files. This new object holds SHA256s of the volume. The backup manifest file will have a reference to this object. During a full backup operation, Cinder divides up the volume into fixed blocks of user configurable block size. It calculates SHA256 of each block and compiles a list of SHAs and uploads the shafile to the backup container.full backups do not contain any holes, offset+lengths of each chunk of with incremental backups, this model is chanllenged and the offset/chunk of represents the data is not modified since last backup. One potential drawback of this approach is if changes to volume are fragmented, incremental backups may result in too many objects in the swift. However object stores like swift are built to handle many small objects effectively.contains a reference to full backup container.changed to handle incremental backups. To keep the restore from incremental backups simple and easy to test, the restore operation first performs restoreIncremental backups offer two important benefits:second benefit cannot be achieved unless cinder backup supports incremental backups. Snapshot based backups can be implemented by extending existing backup functionality to snapshot volumes. This approach can be lot more simpler than backup api taking snapshot of the volume and then managing the snapshots.No new apis are proposed. Instead existing backup api will be enhanced tocinder backup-create <volumeid> —incr <full backup container>cinder backup-create <volumeid> —snapshot Optionally backup-create will backup a snapshot of the volume. cinder backup-create <volumeid> —snapshot —incr <full backup container>Currenly backup functionality is not integrated with openstack dashboard. When it happens, the dashboard will provide an option for user to choose increment backupsoffset by the efficiency gained by incremental backups. Also new hardwareMurali Balcha (murali.balcha@triliodata.com)Giri Basava (giri.basava@triliodata.com) Heavy lifted is done here. 5. Changes spread across multiple regions of the volume Restore the volume from various backups.Need to document new option",60,50
openstack%2Ftripleo-image-elements~master~I67540ef0bfe2b4fb5a382dce8bae22c570cb1a38,openstack/tripleo-image-elements,master,I67540ef0bfe2b4fb5a382dce8bae22c570cb1a38,Move python-netaddr install to network-utils,MERGED,2014-07-01 14:04:52.000000000,2014-07-16 14:39:17.000000000,2014-07-16 14:39:16.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 6969}, {'_account_id': 7144}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-07-01 14:04:52.000000000', 'files': ['elements/network-utils/install.d/70-network-utils', 'elements/boot-stack/install.d/01-boot-stack'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/41ac77538b294b1f4ecbc7fd32c06f8a51e59b05', 'message': 'Move python-netaddr install to network-utils\n\nMove pythonn-netaddr installation to the network-utils\nelement where it is used, so that the network-utils element\ncan be used independently of the boot-stack element.\n\nChange-Id: I67540ef0bfe2b4fb5a382dce8bae22c570cb1a38\n'}]",0,103898,41ac77538b294b1f4ecbc7fd32c06f8a51e59b05,15,5,1,1605,,,0,"Move python-netaddr install to network-utils

Move pythonn-netaddr installation to the network-utils
element where it is used, so that the network-utils element
can be used independently of the boot-stack element.

Change-Id: I67540ef0bfe2b4fb5a382dce8bae22c570cb1a38
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/98/103898/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/network-utils/install.d/70-network-utils', 'elements/boot-stack/install.d/01-boot-stack']",2,41ac77538b294b1f4ecbc7fd32c06f8a51e59b05,move-python-netaddr,install-packages git build-essential python-dev libssl-dev,install-packages git build-essential python-dev libssl-dev python-netaddr,2,2
openstack%2Fmanila~master~I03b452de2cd4fe34c648b2434dab1b9244b1b005,openstack/manila,master,I03b452de2cd4fe34c648b2434dab1b9244b1b005,Add share-server-delete API,MERGED,2014-07-01 14:45:52.000000000,2014-07-16 14:36:00.000000000,2014-07-16 14:35:59.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7173}, {'_account_id': 7534}, {'_account_id': 8851}, {'_account_id': 10796}]","[{'number': 1, 'created': '2014-07-01 14:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/5b395e5d0d21fd65f91f9335cd3156a67c339659', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 2, 'created': '2014-07-01 14:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2608db405dbe0c3444c5a0366760d12a243406c5', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 3, 'created': '2014-07-01 16:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/65dd92319a98337be2ddcd64c8f3002816e0ecf3', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 4, 'created': '2014-07-01 16:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ffcedcf74a5407baae57d67fa5ea53191b8de86f', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 5, 'created': '2014-07-01 17:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f60bc3228d245b87acb107fc8129edff367a739e', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 6, 'created': '2014-07-02 06:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3dbab577a078618d1ada019e29c58bdd61142001', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 7, 'created': '2014-07-02 08:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/85edbdc69160bc6fe9f378e7286bcd60db01043b', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 8, 'created': '2014-07-03 17:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d5c38dd2830d1f873af4576cfe116d4c4e7b057b', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 9, 'created': '2014-07-04 09:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/089f2f4d5b7ed1d4bb928b50f563ce715291a8a3', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 10, 'created': '2014-07-04 12:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a00eb44ca5524fbe23991345b42e02c59bbdea38', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 11, 'created': '2014-07-06 21:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/44fc7afce057d6627a4aedc715755365b4cccb7d', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 12, 'created': '2014-07-07 11:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/de762e2d4cc0517267b31ac8f507c8a8dbc504f0', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 13, 'created': '2014-07-07 11:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8318743a293b0f8bab16f16999c9730ac363cf9e', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 14, 'created': '2014-07-08 16:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/233a07b3313c2fa55e0cdd3f10d7e64e24f5acb7', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 15, 'created': '2014-07-10 08:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e3dbda7fa4ea9b556aec60a8c90d216224ffd86c', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 16, 'created': '2014-07-11 08:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/344f5658c2ebfd1ad2ea48459dbffbf352d1dac2', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 17, 'created': '2014-07-14 18:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e8ae29f45a42e4417dc0b9861604426b5289c3ea', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 18, 'created': '2014-07-15 12:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4021024864254c74bbcc510145a845dfaf917b26', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server\nautodeletion is disabled, which is default behaviour.\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}, {'number': 19, 'created': '2014-07-15 14:13:57.000000000', 'files': ['contrib/tempest/tempest/services/share/json/shares_client.py', 'manila/api/v1/share_servers.py', 'manila/tests/api/v1/test_share_servers.py', 'manila/tests/test_share_api.py', 'contrib/tempest/tempest/api/share/admin/test_share_servers_negative.py', 'manila/share/rpcapi.py', 'manila/tests/test_share_rpcapi.py', 'contrib/tempest/tempest/api/share/admin/test_share_servers.py', 'manila/db/api.py', 'etc/manila/policy.json', 'manila/share/api.py', 'manila/db/sqlalchemy/api.py', 'manila/share/manager.py', 'manila/tests/policy.json'], 'web_link': 'https://opendev.org/openstack/manila/commit/83e94d735e47b115ddc583e2fc8d30b38321002f', 'message': 'Add share-server-delete API\n\nThis API is useful when share-server autodeletion is disabled, which is default behaviour.\n\nChanges:\n- added new api method with deletion of share server\n- added db method, that takes list of shares by share server id\n- changed logic of share manager, that is related to concurrency issues\n- added unit and tempest tests to cover changes\n\nPartially-implements blueprint add-admin-api-delete-share-server\n\nChange-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005\n'}]",72,103911,83e94d735e47b115ddc583e2fc8d30b38321002f,109,8,19,8851,,,0,"Add share-server-delete API

This API is useful when share-server autodeletion is disabled, which is default behaviour.

Changes:
- added new api method with deletion of share server
- added db method, that takes list of shares by share server id
- changed logic of share manager, that is related to concurrency issues
- added unit and tempest tests to cover changes

Partially-implements blueprint add-admin-api-delete-share-server

Change-Id: I03b452de2cd4fe34c648b2434dab1b9244b1b005
",git fetch https://review.opendev.org/openstack/manila refs/changes/11/103911/13 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/tempest/tempest/services/share/json/shares_client.py', 'manila/api/v1/share_servers.py', 'manila/tests/api/v1/test_share_servers.py', 'manila/tests/test_share_api.py', 'contrib/tempest/tempest/api/share/admin/test_share_servers_negative.py', 'manila/share/rpcapi.py', 'manila/tests/test_share_rpcapi.py', 'contrib/tempest/tempest/api/share/admin/test_share_servers.py', 'manila/db/api.py', 'etc/manila/policy.json', 'manila/share/api.py', 'manila/db/sqlalchemy/api.py', 'manila/tests/policy.json']",13,5b395e5d0d21fd65f91f9335cd3156a67c339659,bp/add-admin-api-delete-share-server," ""share_server:delete"": [[""rule:admin_api""]],",,219,16
openstack%2Fsahara~master~Iebe6913d731b4cee105c11abf7007ec13f0f5787,openstack/sahara,master,Iebe6913d731b4cee105c11abf7007ec13f0f5787,Update oslo-incubator loopingcall module,MERGED,2014-07-11 03:37:45.000000000,2014-07-16 14:28:47.000000000,2014-07-16 14:28:46.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-11 03:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1dffa882c004356f88e7349a053c3f1dc8cc30d2', 'message': 'Update oslo-incubator loopingcall module\n\nChanges -\n * Changes calcuation of variable delay\n * Use timestamp in loopingcall\n * Log the function name of looping call\n\nChange-Id: Iebe6913d731b4cee105c11abf7007ec13f0f5787\n'}, {'number': 2, 'created': '2014-07-11 05:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1e74c6484f472de724df23f9bad97ab17520e06c', 'message': 'Update oslo-incubator loopingcall module\n\nChanges -\n * Changes calcuation of variable delay\n * Use timestamp in loopingcall\n * Log the function name of looping call\n\nChange-Id: Iebe6913d731b4cee105c11abf7007ec13f0f5787\n'}, {'number': 3, 'created': '2014-07-11 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ea994d5ae72afe5f5bbc8b8ef6ce251c63940436', 'message': 'Update oslo-incubator loopingcall module\n\nChanges -\n * Changes calcuation of variable delay\n * Use timestamp in loopingcall\n * Log the function name of looping call\n\nChange-Id: Iebe6913d731b4cee105c11abf7007ec13f0f5787\n'}, {'number': 4, 'created': '2014-07-14 14:00:47.000000000', 'files': ['sahara/openstack/common/loopingcall.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/b2995f828b2a7fa28cce963bf0e3ad09718aeffe', 'message': 'Update oslo-incubator loopingcall module\n\nChanges -\n * Changes calcuation of variable delay\n * Use timestamp in loopingcall\n * Log the function name of looping call\n\nChange-Id: Iebe6913d731b4cee105c11abf7007ec13f0f5787\n'}]",0,106262,b2995f828b2a7fa28cce963bf0e3ad09718aeffe,45,10,4,7555,,,0,"Update oslo-incubator loopingcall module

Changes -
 * Changes calcuation of variable delay
 * Use timestamp in loopingcall
 * Log the function name of looping call

Change-Id: Iebe6913d731b4cee105c11abf7007ec13f0f5787
",git fetch https://review.opendev.org/openstack/sahara refs/changes/62/106262/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/loopingcall.py'],1,1dffa882c004356f88e7349a053c3f1dc8cc30d2,oslo-sync,"import time# NOTE(zyluo): This lambda function was declared to avoid mocking collisions # with time.time() called in the standard logging module # during unittests. _ts = lambda: time.time() """"""Exception to break out and stop a LoopingCallBase. The poll-function passed to LoopingCallBase can raise this exception to this return-value will be returned by LoopingCallBase.wait() """""":param retvalue: Value that LoopingCallBase.wait() should return."""""" start = _ts() end = _ts() delay = end - start - interval if delay > 0: LOG.warn(_LW('task %(func_name)s run outlasted ' 'interval by %(delay).2f sec'), {'func_name': repr(self.f), 'delay': delay}) greenthread.sleep(-delay if delay < 0 else 0) LOG.debug('Dynamic looping call %(func_name)s sleeping ' 'for %(idle).02f seconds', {'func_name': repr(self.f), 'idle': idle})","from sahara.openstack.common import timeutils """"""Exception to break out and stop a LoopingCall. The poll-function passed to LoopingCall can raise this exception to this return-value will be returned by LoopingCall.wait() """""":param retvalue: Value that LoopingCall.wait() should return."""""" start = timeutils.utcnow() end = timeutils.utcnow() delay = interval - timeutils.delta_seconds(start, end) if delay <= 0: LOG.warn(_LW('task run outlasted interval by %s sec') % -delay) greenthread.sleep(delay if delay > 0 else 0)# TODO(mikal): this class name is deprecated in Havana and should be removed # in the I release LoopingCall = FixedIntervalLoopingCall LOG.debug('Dynamic looping call sleeping for %.02f ' 'seconds', idle)",21,19
openstack%2Foslo-incubator~master~I932d5b2148a57c5b59ab3f071e53c87ef43b6a6e,openstack/oslo-incubator,master,I932d5b2148a57c5b59ab3f071e53c87ef43b6a6e,Make logging_context_format_string optional in log.set_defaults,MERGED,2014-07-15 15:16:18.000000000,2014-07-16 14:22:40.000000000,2014-07-16 14:22:40.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-07-15 15:16:18.000000000', 'files': ['openstack/common/log.py', 'tests/unit/test_log.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/433fa0b10efe49a5ff05612d9aa2591f824c6ded', 'message': 'Make logging_context_format_string optional in log.set_defaults\n\nInstead of supporting setting logging_context_format_string to None,\nwhich will break things. Support not specifying\nlogging_context_format_string in log.set_defaults so projects can set\nthe default_log_level\n\nChange-Id: I932d5b2148a57c5b59ab3f071e53c87ef43b6a6e\n'}]",0,107082,433fa0b10efe49a5ff05612d9aa2591f824c6ded,8,3,1,1849,,,0,"Make logging_context_format_string optional in log.set_defaults

Instead of supporting setting logging_context_format_string to None,
which will break things. Support not specifying
logging_context_format_string in log.set_defaults so projects can set
the default_log_level

Change-Id: I932d5b2148a57c5b59ab3f071e53c87ef43b6a6e
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/82/107082/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/log.py', 'tests/unit/test_log.py']",2,433fa0b10efe49a5ff05612d9aa2591f824c6ded,log, log.set_defaults(default_log_levels=['foo=bar']) self.assertIsNotNone(self.conf.logging_context_format_string)," def test_default_to_none(self): log.set_defaults(logging_context_format_string=None) self.conf([]) self.assertIsNone(self.conf.logging_context_format_string) log.set_defaults(logging_context_format_string=None, default_log_levels=['foo=bar'])",11,14
openstack%2Fsahara~master~I1781661a93ce533cd2b609661b3c505ddc9cb730,openstack/sahara,master,I1781661a93ce533cd2b609661b3c505ddc9cb730,Update oslo-incubator context module,MERGED,2014-07-11 03:37:45.000000000,2014-07-16 14:21:46.000000000,2014-07-16 14:21:46.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7491}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-11 03:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/3fcd8ed627865a247a69241d5d9f113379445088', 'message': 'Update oslo-incubator context module\n\nChanges -\n * Add a RequestContext.from_dict method\n\nChange-Id: I1781661a93ce533cd2b609661b3c505ddc9cb730\n'}, {'number': 2, 'created': '2014-07-11 05:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/36e51781064886f83bb917f29a04eb4de4c5e453', 'message': 'Update oslo-incubator context module\n\nChanges -\n * Add a RequestContext.from_dict method\n\nChange-Id: I1781661a93ce533cd2b609661b3c505ddc9cb730\n'}, {'number': 3, 'created': '2014-07-11 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e9db257cc40554a7880a450b908fc082b00647cf', 'message': 'Update oslo-incubator context module\n\nChanges -\n * Add a RequestContext.from_dict method\n\nChange-Id: I1781661a93ce533cd2b609661b3c505ddc9cb730\n'}, {'number': 4, 'created': '2014-07-14 14:00:47.000000000', 'files': ['sahara/openstack/common/context.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/c2b64fb8f2f3e409423e0168754847821c97a6e6', 'message': 'Update oslo-incubator context module\n\nChanges -\n * Add a RequestContext.from_dict method\n\nChange-Id: I1781661a93ce533cd2b609661b3c505ddc9cb730\n'}]",0,106261,c2b64fb8f2f3e409423e0168754847821c97a6e6,40,11,4,7555,,,0,"Update oslo-incubator context module

Changes -
 * Add a RequestContext.from_dict method

Change-Id: I1781661a93ce533cd2b609661b3c505ddc9cb730
",git fetch https://review.opendev.org/openstack/sahara refs/changes/61/106261/4 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/context.py'],1,3fcd8ed627865a247a69241d5d9f113379445088,oslo-sync," @classmethod def from_dict(cls, ctx): return cls( auth_token=ctx.get(""auth_token""), user=ctx.get(""user""), tenant=ctx.get(""tenant""), domain=ctx.get(""domain""), user_domain=ctx.get(""user_domain""), project_domain=ctx.get(""project_domain""), is_admin=ctx.get(""is_admin"", False), read_only=ctx.get(""read_only"", False), show_deleted=ctx.get(""show_deleted"", False), request_id=ctx.get(""request_id""), instance_uuid=ctx.get(""instance_uuid"")) ",,15,0
openstack%2Fsahara~master~I74e54cd684bc2a363d358064890f1e13f9ab5acc,openstack/sahara,master,I74e54cd684bc2a363d358064890f1e13f9ab5acc,Update oslo-incubator config.generator module,MERGED,2014-07-11 03:37:45.000000000,2014-07-16 14:21:40.000000000,2014-07-16 14:21:39.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-07-11 03:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/76fc5c05fdc599405758420a5773d9cc70920c91', 'message': 'Update oslo-incubator config.generator module\n\nChanges -\n * generator: remove unused param, small clean up\n\nChange-Id: I74e54cd684bc2a363d358064890f1e13f9ab5acc\n'}, {'number': 2, 'created': '2014-07-11 05:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/bea5409bc19bf556a5e21ce7f72322daf1679ebb', 'message': 'Update oslo-incubator config.generator module\n\nChanges -\n * generator: remove unused param, small clean up\n\nChange-Id: I74e54cd684bc2a363d358064890f1e13f9ab5acc\n'}, {'number': 3, 'created': '2014-07-11 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7ae602e0554c9fdc64f4a6080c5fd797d560fe10', 'message': 'Update oslo-incubator config.generator module\n\nChanges -\n * generator: remove unused param, small clean up\n\nChange-Id: I74e54cd684bc2a363d358064890f1e13f9ab5acc\n'}, {'number': 4, 'created': '2014-07-14 14:00:47.000000000', 'files': ['sahara/openstack/common/config/generator.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/176fea9facff5d81781e610247c3fd3d6c93b7eb', 'message': 'Update oslo-incubator config.generator module\n\nChanges -\n * generator: remove unused param, small clean up\n\nChange-Id: I74e54cd684bc2a363d358064890f1e13f9ab5acc\n'}]",0,106260,176fea9facff5d81781e610247c3fd3d6c93b7eb,40,11,4,7555,,,0,"Update oslo-incubator config.generator module

Changes -
 * generator: remove unused param, small clean up

Change-Id: I74e54cd684bc2a363d358064890f1e13f9ab5acc
",git fetch https://review.opendev.org/openstack/sahara refs/changes/60/106260/4 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/config/generator.py'],1,76fc5c05fdc599405758420a5773d9cc70920c91,oslo-sync,"def raise_extension_exception(extmanager, ep, err): raise on_load_failure_callback=raise_extension_exception """"""Check if opt is in group.""""""def _guess_groups(opt): ret.setdefault(_guess_groups(opt), []).append(opt) hostname = socket.gethostname() fqdn = socket.getfqdn() elif value in (hostname, fqdn): if 'host' in name: return 'sahara' elif value.endswith(hostname): return value.replace(hostname, 'sahara') elif value.endswith(fqdn): return value.replace(fqdn, 'sahara')"," ""Check if opt is in group.""def _guess_groups(opt, mod_obj): ret.setdefault(_guess_groups(opt, obj), []).append(opt) elif value in (socket.gethostname(), socket.getfqdn()) and 'host' in name: return 'sahara' opt_type = None",17,6
openstack%2Fhorizon~master~Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f,openstack/horizon,master,Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f,Display flavor details in instance listing in a popover,MERGED,2014-05-05 13:16:31.000000000,2014-07-16 14:18:02.000000000,2014-07-16 14:18:01.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1941}, {'_account_id': 6763}, {'_account_id': 8648}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9531}, {'_account_id': 9622}, {'_account_id': 9659}, {'_account_id': 10247}, {'_account_id': 10295}]","[{'number': 1, 'created': '2014-05-05 13:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/59106acc12da6109b39367eae6da4411153274f9', 'message': 'display flavor details in instance listing in a popup\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 2, 'created': '2014-05-05 13:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/448084f1db67a1625648d10062e648feed0a9563', 'message': 'display flavor details in instance listing in a popup\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 3, 'created': '2014-06-04 16:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a849fbb99a50e0efacba11756c3201ba620ae592', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 4, 'created': '2014-06-04 16:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/080c5729d3df265ae5970706753b29bc089635ad', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 5, 'created': '2014-06-05 05:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/69eda112289ab8e0fbb8d65d351514c23e04999b', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 6, 'created': '2014-06-06 08:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b01de516b4e2d87c382a0b4e3df78baf7a595c84', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 7, 'created': '2014-06-06 09:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d7fbe2917d12483e159b89cdd5be25fc3bec6528', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 8, 'created': '2014-06-06 17:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/15919bac43ef0aac74569ea98c4479e9a5f7b4eb', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 9, 'created': '2014-06-10 18:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/55f79326c0a42052d2d7a00d6cb625dd7fe9f242', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 10, 'created': '2014-06-23 10:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/31aa5bdf471710bad45cafb3def44b3ea648fa1d', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 11, 'created': '2014-07-02 09:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c56607f15b4396e4b22e99fe3a2b614c0a9f214c', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 12, 'created': '2014-07-02 20:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6f83c47b36881bfa334f8166191cf0cf7e14d820', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 13, 'created': '2014-07-03 09:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bfa673a0633bc29f61a42f7d43608fcc69a9b4ab', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 14, 'created': '2014-07-10 13:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/47e70765eaeac131b3b8458e90c68c310d0ae1ef', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 15, 'created': '2014-07-10 14:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3b6ded2294bb9e21e7aad57bf4b21aae55087144', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 16, 'created': '2014-07-15 08:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6ef2bec2d4267b1eac015937469ec7eba6cedd96', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 17, 'created': '2014-07-15 09:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3c35ef118b13043cacd176c25e58073ddb8a56d5', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}, {'number': 18, 'created': '2014-07-16 09:33:41.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/templates/instances/_instance_flavor.html', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'openstack_dashboard/dashboards/admin/instances/tests.py', 'openstack_dashboard/dashboards/project/instances/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/233b4345c4fcef33177b8f6ffa2d799a70b9aee9', 'message': 'Display flavor details in instance listing in a popover\n\nThis patch moves the flavor details in the instance listing into\na popover to reduce the amount of displayed details in the listing.\n\nChange-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f\nCloses-Bug: #1314177\n'}]",17,92112,233b4345c4fcef33177b8f6ffa2d799a70b9aee9,105,12,18,167,,,0,"Display flavor details in instance listing in a popover

This patch moves the flavor details in the instance listing into
a popover to reduce the amount of displayed details in the listing.

Change-Id: Ibd8cd228bae41e0f2870a8a14b6ce21338d61a8f
Closes-Bug: #1314177
",git fetch https://review.opendev.org/openstack/horizon refs/changes/12/92112/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/tables.py'],1,59106acc12da6109b39367eae6da4411153274f9,1314177," return instance.full_flavor.name return _(""Not available"") def get_full_size(instance): if hasattr(instance, ""full_flavor""): size_string = _(""%(RAM)s RAM\n%(VCPU)s VCPU\n%(disk)s Disk"") vals = { 'RAM': sizeformat.mbformat(instance.full_flavor.ram), 'VCPU': instance.full_flavor.vcpus, 'disk': sizeformat.diskgbformat(instance.full_flavor.disk) } full_size = tables.Column(get_full_size, verbose_name=_(""Full size""), hidden=True)"," size_string = _(""%(name)s | %(RAM)s RAM | %(VCPU)s VCPU "" ""| %(disk)s Disk"") vals = {'name': instance.full_flavor.name, 'RAM': sizeformat.mbformat(instance.full_flavor.ram), 'VCPU': instance.full_flavor.vcpus, 'disk': sizeformat.diskgbformat(instance.full_flavor.disk)}",15,6
openstack%2Fceilometer~master~I8f2218edcdd23fbd42a160afc5cc8e0af8d73af7,openstack/ceilometer,master,I8f2218edcdd23fbd42a160afc5cc8e0af8d73af7,Improves pipeline transformer documentation,MERGED,2014-07-15 12:22:33.000000000,2014-07-16 14:17:59.000000000,2014-07-16 14:17:59.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 8052}, {'_account_id': 8871}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-07-15 12:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9f63247021525fe430b9405f967f9161f2faa03c', 'message': ""Improves pipeline transformer documentation\n\nAdds the Transformers section in the configuration documentation.\nDescribes each transformer's function, parameters and provides\nan example.\n\nChange-Id: I8f2218edcdd23fbd42a160afc5cc8e0af8d73af7\n""}, {'number': 2, 'created': '2014-07-16 09:34:24.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/609088b36702499ca32d96a43fe139ee3081ba74', 'message': ""Improves pipeline transformer documentation\n\nAdds the Transformers section in the configuration documentation.\nDescribes each transformer's function, parameters and provides\nan example.\n\nChange-Id: I8f2218edcdd23fbd42a160afc5cc8e0af8d73af7\n""}]",21,107023,609088b36702499ca32d96a43fe139ee3081ba74,27,6,2,8052,,,0,"Improves pipeline transformer documentation

Adds the Transformers section in the configuration documentation.
Describes each transformer's function, parameters and provides
an example.

Change-Id: I8f2218edcdd23fbd42a160afc5cc8e0af8d73af7
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/23/107023/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,9f63247021525fe430b9405f967f9161f2faa03c,improve-transformer-documentation,"as the names of the related extensions in setup.cfg. For a more detailed description, see the :ref:`transformers` section. The *publishers* section contains the list of publishers, where the samples data should be sent after the possible transformations. The names of the publishers should be the same as the related names of the plugins in setup.cfg. The default configuration can be found in `pipeline.yaml`_. .. _pipeline.yaml: https://git.openstack.org/cgit/openstack/ceilometer/tree/etc/ceilometer/pipeline.yaml .. _transformers: Transformers ************which depends on the implementation of the transformer. .. _rate_of_change_transformer: Rate of change transformer ++++++++++++++++++++++++++ In the case of the transformer that creates the *cpu_util* meter, the definition looks like the following::Scaling transformer +++++++++++++++++++ Transformer to apply a scaling conversion. It takes the volume of the meter and multiplies it with the given 'scale' expression. Also supports *map_from* and *map_to* like the :ref:`rate_of_change_transformer`. Sample configuration:: transformers: - name: ""unit_conversion"" parameters: target: name: ""cpu_util"" unit: ""%"" type: ""gauge"" scale: ""100.0 / (10**9 *(resource_metadata.cpu_number or 1))"" Aggregator transformer ++++++++++++++++++++++ A transformer that sums up the incoming samples until enough samples have come in or a timeout has been reached. Timeout can be specified with the *retention_time* parameter. If we want to flush the aggregation after a set number of samples have been aggregated, we can specify the *size* parameter. The volume of the created sample is the sum of the volumes of samples that came into the transformer. Samples can be aggregated by the attributes *project_id*, *user_id* and *resource_metadata*. To aggregate by the chosen attributes, specify them in the configuration and set which value of the attribute to take for the new sample (*first* to take the first sample's attribute, *last* to take the last sample's attribute, and *drop* to discard the attribute). To aggregate 60s worth of samples by resource_metadata and keep the resource_metadata of the latest received sample:: transformers: - name: ""aggregator"" parameters: retention_time: 60 resource_metadata: last To aggregate each 15 samples by user_id and resource_metadata and keep the user_id of the first received sample and drop the resource_metadata:: transformers: - name: ""aggregator"" parameters: size: 15 user_id: first resource_metadata: drop Accumulator transformer +++++++++++++++++++++++ This transformer simply caches the samples until enough samples have arrived and then flushes them all down the pipeline at once. :: transformers: - name: ""accumulator"" parameters: size: 15 ","as the names of the related extensions in setup.cfg.which depends on the implementation of the transformer. In case of the transformer, which creates the *cpu_util* meter, the definition looks like the following::The *publishers* section contains the list of publishers, where the samples data should be sent after the possible transformations. The names of the publishers should be the same as the related names of the plugins in setup.cfg. The default configuration can be found in `pipeline.yaml`_. .. _pipeline.yaml: https://git.openstack.org/cgit/openstack/ceilometer/tree/etc/ceilometer/pipeline.yaml",90,10
openstack%2Fhorizon~master~I2dd796dbfd8ca6083c4d0025905d404e66b36cc5,openstack/horizon,master,I2dd796dbfd8ca6083c4d0025905d404e66b36cc5,Move _datepicker.scss to a correct place,MERGED,2014-07-14 16:18:50.000000000,2014-07-16 14:17:56.000000000,2014-07-16 14:17:56.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8040}, {'_account_id': 8648}, {'_account_id': 8794}, {'_account_id': 9622}, {'_account_id': 9659}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-07-14 16:18:50.000000000', 'files': ['openstack_dashboard/static/bootstrap/scss/_datepicker.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5dcb710a79aeb0947135e2d9bbab2edb7b4b2d08', 'message': 'Move _datepicker.scss to a correct place\n\nThe place that is referenced by _horizon.scss.\nCloses-Bug: #1341655\n\nChange-Id: I2dd796dbfd8ca6083c4d0025905d404e66b36cc5\n'}]",0,106805,5dcb710a79aeb0947135e2d9bbab2edb7b4b2d08,23,10,1,8040,,,0,"Move _datepicker.scss to a correct place

The place that is referenced by _horizon.scss.
Closes-Bug: #1341655

Change-Id: I2dd796dbfd8ca6083c4d0025905d404e66b36cc5
",git fetch https://review.opendev.org/openstack/horizon refs/changes/05/106805/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/bootstrap/scss/_datepicker.scss'],1,5dcb710a79aeb0947135e2d9bbab2edb7b4b2d08,bug/1341655,,,0,0
openstack%2Fhorizon~master~Ic72a5b0a17c211f3949edc69732c1101c24590ec,openstack/horizon,master,Ic72a5b0a17c211f3949edc69732c1101c24590ec,Cleaned up dict.update(single elem dict) code,MERGED,2014-07-09 19:33:27.000000000,2014-07-16 14:17:53.000000000,2014-07-16 14:17:52.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 4978}, {'_account_id': 6610}, {'_account_id': 8090}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9659}, {'_account_id': 9981}, {'_account_id': 10295}, {'_account_id': 12071}]","[{'number': 1, 'created': '2014-07-09 19:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f44a3be755fe11fa67dfea1ee8776d71a069cf43', 'message': ""Cleaned up dict.update(single elem dict) code\n\nThere's several places in the code where this type of thing exists:\n    form_data.update({'vpnservice_id': vpnservice.id})\nbetter would be this:\n    form_data['vpnservice_id'] = vpnservice.id\nThis type of thing bothers me, so I'm going to clean it up.\n\nChange-Id: Ic72a5b0a17c211f3949edc69732c1101c24590ec\nCloses-Bug: 1339849\n""}, {'number': 2, 'created': '2014-07-09 19:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1b19684571e773bc96eafc882122461b1bb2e05d', 'message': 'Cleaned up dict.update(single elem dict) code\n\nThere\'s several places in the code where this type of thing exists:\n    form_data.update({\'vpnservice_id\': vpnservice.id})\nbetter would be this:\n    form_data[\'vpnservice_id\'] = vpnservice.id\nThis type of thing bothers me, so I\'m going to clean it up.\n\nAlso fixed the two cases of:\n    if <some_string>.find(<some_other_string>) != -1:\nwhich should clearly use the ""in"" operator instead.\n\nChange-Id: Ic72a5b0a17c211f3949edc69732c1101c24590ec\nCloses-Bug: 1339849\n'}, {'number': 3, 'created': '2014-07-14 15:06:11.000000000', 'files': ['horizon/forms/fields.py', 'horizon/base.py', 'openstack_dashboard/dashboards/project/loadbalancers/tests.py', 'horizon/utils/html.py', 'openstack_dashboard/dashboards/project/vpn/tests.py', 'openstack_dashboard/dashboards/project/vpn/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/28e5874eb713b3589cbe393bc9cefbf6041a6818', 'message': 'Cleaned up dict.update(single elem dict) code\n\nThere\'s several places in the code where this type of thing exists:\n    form_data.update({\'vpnservice_id\': vpnservice.id})\nbetter would be this:\n    form_data[\'vpnservice_id\'] = vpnservice.id\nThis type of thing bothers me, so I\'m going to clean it up.\n\nAlso fixed the two cases of:\n    if <some_string>.find(<some_other_string>) != -1:\nwhich should clearly use the ""in"" operator instead.\n\nChange-Id: Ic72a5b0a17c211f3949edc69732c1101c24590ec\nCloses-Bug: 1339849\n'}]",0,105851,28e5874eb713b3589cbe393bc9cefbf6041a6818,50,13,3,9659,,,0,"Cleaned up dict.update(single elem dict) code

There's several places in the code where this type of thing exists:
    form_data.update({'vpnservice_id': vpnservice.id})
better would be this:
    form_data['vpnservice_id'] = vpnservice.id
This type of thing bothers me, so I'm going to clean it up.

Also fixed the two cases of:
    if <some_string>.find(<some_other_string>) != -1:
which should clearly use the ""in"" operator instead.

Change-Id: Ic72a5b0a17c211f3949edc69732c1101c24590ec
Closes-Bug: 1339849
",git fetch https://review.opendev.org/openstack/horizon refs/changes/51/105851/3 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/forms/fields.py', 'openstack_dashboard/dashboards/project/loadbalancers/tests.py', 'horizon/utils/html.py', 'openstack_dashboard/dashboards/project/vpn/tests.py', 'openstack_dashboard/dashboards/project/vpn/workflows.py']",5,f44a3be755fe11fa67dfea1ee8776d71a069cf43,bug/1339849," context['lifetime'] = {'units': data['lifetime_units'], 'value': data['lifetime_value']} context['lifetime'] = {'units': data['lifetime_units'], 'value': data['lifetime_value']} context['dpd'] = {'action': data['dpd_action'], 'interval': data['dpd_interval'], 'timeout': data['dpd_timeout']}"," context.update({'lifetime': {'units': data['lifetime_units'], 'value': data['lifetime_value']}}) context.update({'lifetime': {'units': data['lifetime_units'], 'value': data['lifetime_value']}}) context.update({'dpd': {'action': data['dpd_action'], 'interval': data['dpd_interval'], 'timeout': data['dpd_timeout']}})",27,29
openstack%2Foslo.vmware~master~I634b84da8bf32fab6152af3c84ed1bb8c52251af,openstack/oslo.vmware,master,I634b84da8bf32fab6152af3c84ed1bb8c52251af,Add support for using extensions,MERGED,2014-06-18 13:55:49.000000000,2014-07-16 14:13:14.000000000,2014-07-16 14:13:14.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5638}, {'_account_id': 8871}, {'_account_id': 9171}, {'_account_id': 9172}]","[{'number': 1, 'created': '2014-06-18 13:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/767efe6943d2126f085ed4b908f02e3b69d40d60', 'message': 'Add support for using extensions\n\nThis patch registers an extension in vCenter. This enables a third\nparty, for example OpenStack, to mark that it is responsible for a\nresource.\n\nIf an administrator tries to update the VM via vCenter then they will\nget the following message:\n\n""Solution OpenStack manages the selected virtual machine. You should\nnot modify the virtual machine directly. Use the management console of\nthe solution to make changes. Do you want to proceed?""\n\nThe following API\'s have been added:\n - find_extension - checks if a specific extension exists\n - create_extension - creates a new extension\n\nChange-Id: I634b84da8bf32fab6152af3c84ed1bb8c52251af\n'}, {'number': 2, 'created': '2014-07-03 10:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/0f7394178534192e9c923323e8134628b734a4ee', 'message': 'Add support for using extensions\n\nThis patch registers an extension in vCenter. This enables a third\nparty, for example OpenStack, to mark that it is responsible for a\nresource.\n\nIf an administrator tries to update the VM via vCenter then they will\nget the following message:\n\n""Solution OpenStack manages the selected virtual machine. You should\nnot modify the virtual machine directly. Use the management console of\nthe solution to make changes. Do you want to proceed?""\n\nThe following API\'s have been added:\n - find_extension - checks if a specific extension exists\n - create_extension - creates a new extension\n\nChange-Id: I634b84da8bf32fab6152af3c84ed1bb8c52251af\n'}, {'number': 3, 'created': '2014-07-08 11:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/1932e9b6150fb86447ead1f77cd83a9813ede72f', 'message': 'Add support for using extensions\n\nThis patch registers an extension in vCenter. This enables a third\nparty, for example OpenStack, to mark that it is responsible for a\nresource.\n\nIf an administrator tries to update the VM via vCenter then they will\nget the following message:\n\n""Solution OpenStack manages the selected virtual machine. You should\nnot modify the virtual machine directly. Use the management console of\nthe solution to make changes. Do you want to proceed?""\n\nThe following API\'s have been added:\n - find_extension - checks if a specific extension exists\n - register_extension - registers a new extension\n\nChange-Id: I634b84da8bf32fab6152af3c84ed1bb8c52251af\n'}, {'number': 4, 'created': '2014-07-10 13:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/ac05b2a58df5434e06e9fc235a6150e385aa7c1a', 'message': 'Add support for using extensions\n\nThis patch registers an extension in vCenter. This enables a third\nparty, for example OpenStack, to mark that it is responsible for a\nresource.\n\nIf an administrator tries to update the VM via vCenter then they will\nget the following message:\n\n""Solution OpenStack manages the selected virtual machine. You should\nnot modify the virtual machine directly. Use the management console of\nthe solution to make changes. Do you want to proceed?""\n\nThe following API\'s have been added:\n - find_extension - checks if a specific extension exists\n - register_extension - registers a new extension\n\nChange-Id: I634b84da8bf32fab6152af3c84ed1bb8c52251af\n'}, {'number': 5, 'created': '2014-07-10 15:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/1bb7622a33dce7a896cb8318d6c441229c7cf7b2', 'message': 'Add support for using extensions\n\nThis patch registers an extension in vCenter. This enables a third\nparty, for example OpenStack, to mark that it is responsible for a\nresource.\n\nIf an administrator tries to update the VM via vCenter then they will\nget the following message:\n\n""Solution OpenStack manages the selected virtual machine. You should\nnot modify the virtual machine directly. Use the management console of\nthe solution to make changes. Do you want to proceed?""\n\nThe following API\'s have been added:\n - find_extension - checks if a specific extension exists\n - register_extension - registers a new extension\n\nNote that the onus is on the caller to validate that the extension exists.\nIf not they should handle the exception returned ffrom the backend.\n\nThe pseudo code should be as follows:\n\n    if not find_extension(key):\n        register_extension(...)\n\nChange-Id: I634b84da8bf32fab6152af3c84ed1bb8c52251af\n'}, {'number': 6, 'created': '2014-07-10 17:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/36bc4e142e7e6a6d0a087a94c63a8a80256b19fc', 'message': 'Add support for using extensions\n\nThis patch registers an extension in vCenter. This enables a third\nparty, for example OpenStack, to mark that it is responsible for a\nresource.\n\nIf an administrator tries to update the VM via vCenter then they will\nget the following message:\n\n""Solution OpenStack manages the selected virtual machine. You should\nnot modify the virtual machine directly. Use the management console of\nthe solution to make changes. Do you want to proceed?""\n\nThe following API\'s have been added:\n - find_extension - checks if a specific extension exists\n - register_extension - registers a new extension\n\nNote that the onus is on the caller to validate that the extension exists.\nIf not they should handle the exception returned from the backend.\n\nThe pseudo code should be as follows:\n\n    if not find_extension(key):\n        register_extension(...)\n\nChange-Id: I634b84da8bf32fab6152af3c84ed1bb8c52251af\n'}, {'number': 7, 'created': '2014-07-14 12:13:23.000000000', 'files': ['tests/test_vim_util.py', 'oslo/vmware/vim_util.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/5efab684c6a7b82a26bf286e5ac824e2f0d4d990', 'message': 'Add support for using extensions\n\nThis patch registers an extension in vCenter. This enables a third\nparty, for example OpenStack, to mark that it is responsible for a\nresource.\n\nIf an administrator tries to update the VM via vCenter then they will\nget the following message:\n\n""Solution OpenStack manages the selected virtual machine. You should\nnot modify the virtual machine directly. Use the management console of\nthe solution to make changes. Do you want to proceed?""\n\nThe following API\'s have been added:\n - find_extension - checks if a specific extension exists\n - register_extension - registers a new extension\n\nNote that the onus is on the caller to validate that the extension exists.\nIf not they should handle the exception returned from the backend.\n\nThe pseudo code should be as follows:\n\n    if not find_extension(key):\n        register_extension(...)\n\nChange-Id: I634b84da8bf32fab6152af3c84ed1bb8c52251af\n'}]",28,100911,5efab684c6a7b82a26bf286e5ac824e2f0d4d990,57,6,7,1653,,,0,"Add support for using extensions

This patch registers an extension in vCenter. This enables a third
party, for example OpenStack, to mark that it is responsible for a
resource.

If an administrator tries to update the VM via vCenter then they will
get the following message:

""Solution OpenStack manages the selected virtual machine. You should
not modify the virtual machine directly. Use the management console of
the solution to make changes. Do you want to proceed?""

The following API's have been added:
 - find_extension - checks if a specific extension exists
 - register_extension - registers a new extension

Note that the onus is on the caller to validate that the extension exists.
If not they should handle the exception returned from the backend.

The pseudo code should be as follows:

    if not find_extension(key):
        register_extension(...)

Change-Id: I634b84da8bf32fab6152af3c84ed1bb8c52251af
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/11/100911/5 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_vim_util.py', 'oslo/vmware/vim_util.py']",2,767efe6943d2126f085ed4b908f02e3b69d40d60,extension,"from oslo.vmware.openstack.common import timeutils def find_extension(vim, key): """"""Looks for an existing extension."""""" service_content = vim.get_service_content() extension_manager = service_content.extensionManager return vim.client.service.FindExtension(extension_manager, key) def create_extension(vim, key, type): """"""Create a new key and type."""""" service_content = vim.get_service_content() extension_manager = service_content.extensionManager client_factory = vim.client.factory os_ext = client_factory.create('ns0:Extension') os_ext.key = key entity_info = client_factory.create('ns0:ExtManagedEntityInfo') entity_info.type = type os_ext.managedEntityInfo = [entity_info] os_ext.version = '1' desc = client_factory.create('ns0:Description') desc.label = 'OpenStack' desc.summary = 'OpenStack services' os_ext.description = desc os_ext.lastHeartbeatTime = timeutils.strtime() vim.client.service.RegisterExtension(extension_manager, os_ext)",,38,0
openstack%2Fceilometer~master~I42567cf9187bb70665abfa335a8dcdefcc05c9fe,openstack/ceilometer,master,I42567cf9187bb70665abfa335a8dcdefcc05c9fe,Fix call to meter-list in measurements doc,MERGED,2014-07-11 14:27:28.000000000,2014-07-16 14:13:05.000000000,2014-07-16 14:13:04.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 8871}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-07-11 14:27:28.000000000', 'files': ['doc/source/measurements.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/15b3394a5412afc792fe6a2885b45440400cff93', 'message': 'Fix call to meter-list in measurements doc\n\n-s is not an accepted argument.\n\nChange-Id: I42567cf9187bb70665abfa335a8dcdefcc05c9fe\nCloses-Bug: 1340775\n'}]",1,106385,15b3394a5412afc792fe6a2885b45440400cff93,39,6,1,11564,,,0,"Fix call to meter-list in measurements doc

-s is not an accepted argument.

Change-Id: I42567cf9187bb70665abfa335a8dcdefcc05c9fe
Closes-Bug: 1340775
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/85/106385/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/measurements.rst'],1,15b3394a5412afc792fe6a2885b45440400cff93,bug/1340775, $ ceilometer meter-list, $ ceilometer meter-list -s openstack,1,1
openstack%2Ffuel-library~master~I271c6d7db4cf8fe4c9dfc7599954cb0ec8813293,openstack/fuel-library,master,I271c6d7db4cf8fe4c9dfc7599954cb0ec8813293,Refactoring of rabbitmq OCF script,MERGED,2014-07-14 20:50:42.000000000,2014-07-16 14:06:32.000000000,2014-07-16 14:06:32.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-14 20:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0447f5cf13c6cc33743e1ce1cf5780bd987658d7', 'message': 'WIP:some fixes to rabbitmq OCF script\n\nChange-Id: I271c6d7db4cf8fe4c9dfc7599954cb0ec8813293\n'}, {'number': 2, 'created': '2014-07-15 18:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/25b6f1df5679a12aae41ed897e83cdff0fab53df', 'message': 'WIP:some fixes to rabbitmq OCF script\n\nChange-Id: I271c6d7db4cf8fe4c9dfc7599954cb0ec8813293\n'}, {'number': 3, 'created': '2014-07-15 20:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f858d11c805756ede1db8ac4ca99cd85c0bfdaf0', 'message': 'Refactoring of rabbitmq OCF script\n\n1) Store attributes in CIB instead of files\n2) Do not use ocf_run if command may fail\n3) Eliminate master_score race condition:\nset master_score to 1000 for the older nodes\nand do not forget to update their uptime value\n4) fix messed interleave/ordered settings\n5) set failure-timeout to 60 seconds to recover\nfrom RabbitMQ master node failure\n6) for slave nodes only run beam and\nstart rabbitmq only if there is master promoted\n7) stop RMQ app on slaves in case of master demotion\n8) clean up other nodes master attribute in case\nof promotion\n9) fix exit codes for failed services start and cluster\njoining\n10) get running nodes into running_nodes variable\n11) apply timeout command to cluster_status function\n\nChange-Id: I271c6d7db4cf8fe4c9dfc7599954cb0ec8813293\n'}, {'number': 4, 'created': '2014-07-15 20:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/544c3a3c690c8d4665f819528e3bbb80dfcece47', 'message': 'Refactoring of rabbitmq OCF script\n\n1) Store attributes in CIB instead of files\n2) Do not use ocf_run if command may fail\n3) Eliminate master_score race condition:\nset master_score to 1000 for the older nodes\nand do not forget to update their uptime value\n4) fix messed interleave/ordered settings\n5) set failure-timeout to 60 seconds to recover\nfrom RabbitMQ master node failure\n6) for slave nodes only run beam and\nstart rabbitmq only if there is master promoted\n7) stop RMQ app on slaves in case of master demotion\n8) clean up other nodes master attribute in case\nof promotion\n9) fix exit codes for failed services start and cluster\njoining\n10) get running nodes into running_nodes variable\n11) apply timeout command to cluster_status function\n\nCloses-bug: #1339080\nCloses-bug: #1336777\n\nChange-Id: I271c6d7db4cf8fe4c9dfc7599954cb0ec8813293\n'}, {'number': 5, 'created': '2014-07-15 22:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b90320423e8eeae74268a6d8249d89bc1120953e', 'message': 'Refactoring of rabbitmq OCF script\n\n1) Store attributes in CIB instead of files\n2) Do not use ocf_run if command may fail\n3) Eliminate master_score race condition:\nset master_score to 1000 for the older nodes\nand do not forget to update their uptime value\n4) fix messed interleave/ordered settings\n5) set failure-timeout to 60 seconds to recover\nfrom RabbitMQ master node failure\n6) for slave nodes only run beam and\nstart rabbitmq only if there is master promoted\n7) stop RMQ app on slaves in case of master demotion\n8) clean up other nodes master attribute in case\nof promotion\n9) fix exit codes for failed services start and cluster\njoining\n10) get running nodes into running_nodes variable\n11) apply timeout command to cluster_status function\n\nCloses-bug: #1339080\nCloses-bug: #1336777\n\nChange-Id: I271c6d7db4cf8fe4c9dfc7599954cb0ec8813293\n'}, {'number': 6, 'created': '2014-07-16 07:35:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/54ffca28b4857ade1eb95fb43ebf82a9502d2baa', 'message': 'Refactoring of rabbitmq OCF script\n\n1) Store attributes in CIB instead of files\n2) Do not use ocf_run if command may fail\n3) Eliminate master_score race condition:\nset master_score to 1000 for the older nodes\nand do not forget to update their uptime value\n4) fix messed interleave/ordered settings\n5) set failure-timeout to 60 seconds to recover\nfrom RabbitMQ master node failure\n6) for slave nodes only run beam and\nstart rabbitmq only if there is master promoted\n7) stop RMQ app on slaves in case of master demotion\n8) clean up other nodes master attribute in case\nof promotion\n9) fix exit codes for failed services start and cluster\njoining\n10) get running nodes into running_nodes variable\n11) apply timeout command to cluster_status function\n\nCloses-bug: #1339080\nCloses-bug: #1336777\n\nChange-Id: I271c6d7db4cf8fe4c9dfc7599954cb0ec8813293\n'}, {'number': 7, 'created': '2014-07-16 07:58:20.000000000', 'files': ['deployment/puppet/nova/manifests/rabbitmq.pp', 'deployment/puppet/nova/files/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/33a9794bdf59aefb815137632b039c011095cfa3', 'message': 'Refactoring of rabbitmq OCF script\n\n1) Store attributes in CIB instead of files\n2) Do not use ocf_run if command may fail\n3) Eliminate master_score race condition:\nset master_score to 1000 for the older nodes\nand do not forget to update their uptime value\n4) fix messed interleave/ordered settings\n5) set failure-timeout to 60 seconds to recover\nfrom RabbitMQ master node failure\n6) for slave nodes only run beam and\nstart rabbitmq only if there is master promoted\n7) stop RMQ app on slaves in case of master demotion\n8) clean up other nodes master attribute in case\nof promotion\n9) fix exit codes for failed services start and cluster\njoining\n10) get running nodes into running_nodes variable\n11) apply timeout command to cluster_status function\n\nCloses-bug: #1339080\nCloses-bug: #1336777\n\nChange-Id: I271c6d7db4cf8fe4c9dfc7599954cb0ec8813293\n'}]",4,106865,33a9794bdf59aefb815137632b039c011095cfa3,60,4,7,8786,,,0,"Refactoring of rabbitmq OCF script

1) Store attributes in CIB instead of files
2) Do not use ocf_run if command may fail
3) Eliminate master_score race condition:
set master_score to 1000 for the older nodes
and do not forget to update their uptime value
4) fix messed interleave/ordered settings
5) set failure-timeout to 60 seconds to recover
from RabbitMQ master node failure
6) for slave nodes only run beam and
start rabbitmq only if there is master promoted
7) stop RMQ app on slaves in case of master demotion
8) clean up other nodes master attribute in case
of promotion
9) fix exit codes for failed services start and cluster
joining
10) get running nodes into running_nodes variable
11) apply timeout command to cluster_status function

Closes-bug: #1339080
Closes-bug: #1336777

Change-Id: I271c6d7db4cf8fe4c9dfc7599954cb0ec8813293
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/65/106865/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nova/files/ocf/rabbitmq'],1,0447f5cf13c6cc33743e1ce1cf5780bd987658d7,master," stime=$( crm_attribute -N `hostname` -l reboot --name 'rabbit-start-time' --query 2>/dev/null | awk '{print $3}' | awk -F ""="" '{print $2}') if [[ $rc -eq 0 ]] ; then ocf_log info ""srv_uptime(): updating master score with diff between $(now) and ${stime}"" ocf_log info ""srv_uptime(): updating master score with 0"" ocf_log err ""${LH} RMQ-server app can't be stopped during Mnesia cleaning. beam will be killed."" ocf_log err ""${LH} RMQ-server can't be started while many tries. beam will be killed."" ocf_log info ""${LH} checking if rabbit app is running"" ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" nodelist=`crm_node -p -l | grep -v lost | awk '{print $2}' | grep -v ""^$""` ocf_log info ""${LH} rabbit app is running. looking for master on $node"" ocf_log info ""${LH} fetched master attribute for $node. attr value is ${is_master}"" if [[ ""x${is_master}"" == ""xtrue"" ]] ocf_log info ""${LH} rabbit app is running. master is $node"" ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" ocf_log info ""${LH} preparing to update master score for node"" score=$(srv_uptime) master_score $score ocf_log info ""${LH} updated master score for node to $score"" ocf_log info ""${LH} get_monitor function ready to return ${rc}"" if [[ ${OCF_RESKEY_CRM_meta_notify_type} == 'pre' ]] ; then # PRE- anything notify section case ""$OCF_RESKEY_CRM_meta_notify_operation"" in promote) ocf_log info ""${LH} pre-promote begin."" my_host ""$OCF_RESKEY_CRM_meta_notify_promote_uname"" rc=$? if [[ $rc == $OCF_SUCCESS ]] ; then nodelist=`crm_node -l | awk '{print $2}' | grep -v ""^$""` for i in $nodelist do crm_attribute -N $i -l reboot --name 'rabbit-master' --delete done ocf_log info ""${LH} post-promote end."" fi ;; *) ;; esac fi ocf_log info ""${LH} get_monitor returns ${rc}"" rc=$? if [ $rc -eq $OCF_RUNNING_MASTER ] then return $OCF_SUCCESS else return $OCF_ERR_GENERIC fi"," stime=`crm_attribute -N `hostname` -l reboot --name 'rabbit-start-time' --query 2>/dev/null | awk '{print $3}' | awk -F ""="" '{print $2}'` if [[ $rc == 0 ]] ; then ocf_log err ""${LH} RMQ-server app can't stopped while Mnesia cleaning. beam will be killed emergency."" ocf_log err ""${LH} RMQ-server can't started while many tries. beam will be killed emergency."" local master_for_queues=""master_for_queues-$OCF_RESOURCE_INSTANCE"" ocf_run crm_attribute -N $(crm_node -n) -n ${master_for_queues} -l reboot -v 0 ocf_log info ""checking if rabbit app is running"" ocf_log info ""rabbit app is running. checking if we are the part of healthy cluster"" nodelist=`crm_node -l | awk '{print $2}' | grep -v ""^$""` ocf_log info ""rabbit app is running. looking for master on $node"" if [[ ${is_master} == ""true"" ]] ocf_log info ""rabbit app is running. master is $node"" ocf_log info ""rabbit app is running and is member of healthy cluster"" ocf_run crm_attribute -N $(crm_node -n) -n ${master_for_queues} -l reboot -v 0 master_score $(srv_uptime) score=$( ${OCF_RESKEY_ctl} list_queues pid 2>/dev/null | grep -c ""$RABBITMQ_NODENAME"" ) if [[ $? == 0 ]] ; then ocf_run crm_attribute -N $(crm_node -n) -n ${master_for_queues} -l reboot -v $score fi # if [[ ${OCF_RESKEY_CRM_meta_notify_type} == 'pre' ]] ; then # # PRE- anything notify section # case ""$OCF_RESKEY_CRM_meta_notify_operation"" in # *) ;; # esac # el",49,28
openstack%2Ffuel-library~master~I4171e941321f60f91ab32647646333abe73af87f,openstack/fuel-library,master,I4171e941321f60f91ab32647646333abe73af87f,Set CentOS to use MySQL-client 5.6,MERGED,2014-07-14 22:13:03.000000000,2014-07-16 14:06:12.000000000,2014-07-16 14:06:11.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6926}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-07-14 22:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/736a844632f76f3d757e0dafed6da1a13f18789c', 'message': 'Set CentOS to use MySQL-client 5.6\n\nChange-Id: I4171e941321f60f91ab32647646333abe73af87f\nRelated-bug: #1341480\n'}, {'number': 2, 'created': '2014-07-14 22:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b1399d7251d5371b4517b25429e397ccce8dc965', 'message': 'Set CentOS to use MySQL-client 5.6\n\nChange-Id: I4171e941321f60f91ab32647646333abe73af87f\nRelated-bug: #1341480\n'}, {'number': 3, 'created': '2014-07-14 23:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3077550c0d7e522b572dc916ad2219a1df5ab633', 'message': 'Set CentOS to use MySQL-client 5.6\n\nChange-Id: I4171e941321f60f91ab32647646333abe73af87f\nRelated-bug: #1341480\n'}, {'number': 4, 'created': '2014-07-14 23:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9c36ef2da9cd4e9a8278069c210470524a2deed9', 'message': 'Set CentOS to use MySQL-client 5.6\n\nChange-Id: I4171e941321f60f91ab32647646333abe73af87f\nRelated-bug: #1341480\n'}, {'number': 5, 'created': '2014-07-15 00:52:50.000000000', 'files': ['deployment/puppet/galera/manifests/init.pp', 'deployment/puppet/galera/manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/78fb3aeeee9d02a38bf4f10a44b350d957819271', 'message': 'Set CentOS to use MySQL-client 5.6\n\nChange-Id: I4171e941321f60f91ab32647646333abe73af87f\nRelated-bug: #1341480\n'}]",1,106883,78fb3aeeee9d02a38bf4f10a44b350d957819271,47,10,5,8786,,,0,"Set CentOS to use MySQL-client 5.6

Change-Id: I4171e941321f60f91ab32647646333abe73af87f
Related-bug: #1341480
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/83/106883/5 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/galera/manifests/init.pp'],1,736a844632f76f3d757e0dafed6da1a13f18789c,106883," name => ""MySQL-client-wsrep"",",,1,0
openstack%2Fdevstack~master~Iece6d53e71054476d31adad5db793fdaecce547a,openstack/devstack,master,Iece6d53e71054476d31adad5db793fdaecce547a,The VG_DEV should be set before delete the loop device.,ABANDONED,2014-07-02 13:29:50.000000000,2014-07-16 13:45:34.000000000,,"[{'_account_id': 3}, {'_account_id': 9009}, {'_account_id': 10385}, {'_account_id': 10500}]","[{'number': 1, 'created': '2014-07-02 13:29:50.000000000', 'files': ['lib/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3d8b6a9e3499d9ca1ce948e03dd4040214347f23', 'message': 'The VG_DEV should be set before delete the loop device.\n\nChange-Id: Iece6d53e71054476d31adad5db793fdaecce547a\nCloses-Bug: #1336779\n'}]",0,104193,3d8b6a9e3499d9ca1ce948e03dd4040214347f23,13,4,1,10500,,,0,"The VG_DEV should be set before delete the loop device.

Change-Id: Iece6d53e71054476d31adad5db793fdaecce547a
Closes-Bug: #1336779
",git fetch https://review.opendev.org/openstack/devstack refs/changes/93/104193/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder'],1,3d8b6a9e3499d9ca1ce948e03dd4040214347f23,, VG_DEV=$(sudo losetup -j $DATA_DIR/${vg}-backing-file | awk -F':' '/backing-file/ { print $1}'), VG_DEV=$(sudo losetup -j $DATA_DIR/${vg}-backing-file | awk -F':' '/backing-file/ { print $1}'),1,1
openstack%2Foslo-incubator~master~I30a61978f7897a7c6b747bb8f71ada2909140f8c,openstack/oslo-incubator,master,I30a61978f7897a7c6b747bb8f71ada2909140f8c,test lazzy_pluggable,ABANDONED,2014-07-14 12:33:17.000000000,2014-07-16 13:21:51.000000000,,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 10068}, {'_account_id': 10614}]","[{'number': 1, 'created': '2014-07-14 12:33:17.000000000', 'files': ['tests/unit/test_importutils.py', 'openstack/common/db/exception.py', 'openstack/common/importutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a0e6219ccd0d511e874576d122564abc0c5aa4cf', 'message': 'test lazzy_pluggable\n\nChange-Id: I30a61978f7897a7c6b747bb8f71ada2909140f8c\n'}]",0,106748,a0e6219ccd0d511e874576d122564abc0c5aa4cf,6,4,1,10614,,,0,"test lazzy_pluggable

Change-Id: I30a61978f7897a7c6b747bb8f71ada2909140f8c
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/48/106748/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_importutils.py', 'openstack/common/db/exception.py', 'openstack/common/importutils.py']",3,a0e6219ccd0d511e874576d122564abc0c5aa4cf,lazzy_pluggable,"from openstack.common.db import exception class LazyPluggable(object): """"""A pluggable backend loaded lazily based on some value."""""" def __init__(self, pivot, conf, config_group=None, **backends): """""" :param pivot: name of option in config, which responsible for the selection of backend in runtime :param conf: instance of config :param config_group: group of config, None if not exist :param backends: supported backends """""" self.__backends = backends self.__pivot = pivot self.__backend = None self.__config_group = config_group self.__conf = conf def __get_backend(self): if not self.__backend: if self.__config_group is None: backend_name = self.__conf[self.__pivot] else: backend_name = self.__conf[self.__config_group][self.__pivot] if backend_name not in self.__backends: msg = ('Invalid backend: %s') % backend_name raise exception.PluginLoadError(msg) backend = self.__backends[backend_name] if isinstance(backend, tuple): name = backend[0] fromlist = backend[1] else: name = backend fromlist = backend self.__backend = __import__(name, None, None, fromlist) return self.__backend def __getattr__(self, key): backend = self.__get_backend() return getattr(backend, key)",,64,0
openstack%2Fdiskimage-builder~master~Ib0ca7fc4dc1003516e21bfcf881a8a3510934d8b,openstack/diskimage-builder,master,Ib0ca7fc4dc1003516e21bfcf881a8a3510934d8b,WIP:Don't match editor backup files in environment,ABANDONED,2014-07-08 16:31:02.000000000,2014-07-16 13:14:06.000000000,,"[{'_account_id': 3}, {'_account_id': 215}]","[{'number': 1, 'created': '2014-07-08 16:31:02.000000000', 'files': ['elements/dib-run-parts/bin/dib-run-parts'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/cf669ded25d16c50f1ffec08bb3474f61c8a02d7', 'message': 'WIP:Don\'t match editor backup files in environment\n\nRetesting this patch with extra debug info to find what went wrong\n\nThe current glob match for environment files can source editor backup\nfiles (foo.bash~) which will override the real changes you have made.\n\nOther parts matche use the regex to avoid matching such files, so do\nthe same for environment file matching.  Note this has to match "".""\nunlike the other regex, as most env files are ""foo.bash""\n\nChange-Id: Ib0ca7fc4dc1003516e21bfcf881a8a3510934d8b\n'}]",1,105513,cf669ded25d16c50f1ffec08bb3474f61c8a02d7,6,2,1,1926,,,0,"WIP:Don't match editor backup files in environment

Retesting this patch with extra debug info to find what went wrong

The current glob match for environment files can source editor backup
files (foo.bash~) which will override the real changes you have made.

Other parts matche use the regex to avoid matching such files, so do
the same for environment file matching.  Note this has to match "".""
unlike the other regex, as most env files are ""foo.bash""

Change-Id: Ib0ca7fc4dc1003516e21bfcf881a8a3510934d8b
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/13/105513/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/dib-run-parts/bin/dib-run-parts'],1,cf669ded25d16c50f1ffec08bb3474f61c8a02d7,revert_environment_d_fix,"set -uexfind $ENVIRONMENT_D_DIR env_files=$(find $ENVIRONMENT_D_DIR \ -maxdepth 1 -xtype f -printf '%f\n' | \ grep -E ""^[0-9A-Za-z_\.-]+$"") for env_file in $env_files ; do source $ENVIRONMENT_D_DIR/$env_fileenv ",set -ue for env_file in $ENVIRONMENT_D_DIR/* ; do source $env_file,10,3
openstack%2Ftripleo-incubator~master~I61a2c0c6121de09f68132e3cb9bf259b64bfb6ed,openstack/tripleo-incubator,master,I61a2c0c6121de09f68132e3cb9bf259b64bfb6ed,Protect from a unset TRIPLEO_OS_FAMILY.,MERGED,2014-07-11 11:50:44.000000000,2014-07-16 13:13:24.000000000,2014-07-16 13:13:23.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6348}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-07-11 11:50:44.000000000', 'files': ['scripts/create-nodes'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/5c95c68c4238aa6a56cdc4e5fde8f4bbc8efb1da', 'message': 'Protect from a unset TRIPLEO_OS_FAMILY.\n\nChange-Id: I61a2c0c6121de09f68132e3cb9bf259b64bfb6ed\n'}]",0,106343,5c95c68c4238aa6a56cdc4e5fde8f4bbc8efb1da,19,5,1,1926,,,0,"Protect from a unset TRIPLEO_OS_FAMILY.

Change-Id: I61a2c0c6121de09f68132e3cb9bf259b64bfb6ed
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/43/106343/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/create-nodes'],1,5c95c68c4238aa6a56cdc4e5fde8f4bbc8efb1da,te-fixes,"if [ ""${TRIPLEO_OS_FAMILY:-}"" = ""debian"" ]; then","if [ ""$TRIPLEO_OS_FAMILY"" = ""debian"" ]; then",1,1
openstack%2Fnova-specs~master~Ie6268882eaf302a7b020cec3e510ffcc3166d728,openstack/nova-specs,master,Ie6268882eaf302a7b020cec3e510ffcc3166d728,Update from global requirements,ABANDONED,2014-06-28 16:41:20.000000000,2014-07-16 13:11:26.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 10901}]","[{'number': 1, 'created': '2014-06-28 16:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fcd77d9c97be54f7c63097cbb0785f8e65cde888', 'message': 'Update pbr version\n\nChange-Id: Ie6268882eaf302a7b020cec3e510ffcc3166d728\n'}, {'number': 2, 'created': '2014-07-02 12:06:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/890796ab932dc2f5396dd755e44316ae5b1a1b28', 'message': 'Update from global requirements\n\n* Update the pbr version\nChange-Id: Ie6268882eaf302a7b020cec3e510ffcc3166d728\n'}]",1,103348,890796ab932dc2f5396dd755e44316ae5b1a1b28,14,4,2,9536,,,0,"Update from global requirements

* Update the pbr version
Change-Id: Ie6268882eaf302a7b020cec3e510ffcc3166d728
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/48/103348/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,fcd77d9c97be54f7c63097cbb0785f8e65cde888,pbv_version_update,"pbr>=0.6,!=0.7,<1.0","pbr>=0.6,<1.0",1,1
openstack%2Frelease-tools~master~I4011ec477534f920092cc323a26e75ff26a90051,openstack/release-tools,master,I4011ec477534f920092cc323a26e75ff26a90051,Use /usr/bin/env python instead of /usr/bin/python,MERGED,2014-07-13 16:56:52.000000000,2014-07-16 13:01:25.000000000,2014-07-16 13:01:25.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-07-13 16:56:52.000000000', 'files': ['consolidate_release_page.py', 'ms2version.py', 'upload_release.py', 'create_milestones.py', 'wait_for_tarball.py', 'process_bugs.py'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/8cbd60937d59ccdbe7ebfcc26e34f2798f0eaf2c', 'message': ""Use /usr/bin/env python instead of /usr/bin/python\n\nThe usage of /usr/bin/env ensures that the first interpreter\nfound in the environment's $PATH variable is used. This should\nbe preferred.\n\nChange-Id: I4011ec477534f920092cc323a26e75ff26a90051\n""}]",0,106639,8cbd60937d59ccdbe7ebfcc26e34f2798f0eaf2c,15,3,1,167,,,0,"Use /usr/bin/env python instead of /usr/bin/python

The usage of /usr/bin/env ensures that the first interpreter
found in the environment's $PATH variable is used. This should
be preferred.

Change-Id: I4011ec477534f920092cc323a26e75ff26a90051
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/39/106639/1 && git format-patch -1 --stdout FETCH_HEAD,"['consolidate_release_page.py', 'ms2version.py', 'upload_release.py', 'create_milestones.py', 'wait_for_tarball.py', 'process_bugs.py']",6,8cbd60937d59ccdbe7ebfcc26e34f2798f0eaf2c,use_env_python,#!/usr/bin/env python,#!/usr/bin/python,6,6
openstack%2Fhorizon~master~I8257cc50911904169c27e0687d40bcfe49e332c4,openstack/horizon,master,I8257cc50911904169c27e0687d40bcfe49e332c4,Add heading property to BasePage class,MERGED,2014-06-17 11:06:45.000000000,2014-07-16 12:58:56.000000000,2014-07-16 12:58:56.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8871}, {'_account_id': 9552}, {'_account_id': 10068}, {'_account_id': 10295}, {'_account_id': 11473}]","[{'number': 1, 'created': '2014-06-17 11:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/438fc8da2bf1b75cec3ef3bab28a71e0493f78b8', 'message': 'Add heading property to BasePage class\n\nEvery page should have heading that corresponds to menu item that was\npicked.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I8257cc50911904169c27e0687d40bcfe49e332c4\n'}, {'number': 2, 'created': '2014-06-26 14:37:03.000000000', 'files': ['openstack_dashboard/test/integration_tests/pages/basepage.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/13fdbe2067a648692203e446da031117375b97bb', 'message': 'Add heading property to BasePage class\n\nEvery page should have heading that corresponds to menu item that was\npicked.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I8257cc50911904169c27e0687d40bcfe49e332c4\n'}]",2,100493,13fdbe2067a648692203e446da031117375b97bb,28,10,2,11473,,,0,"Add heading property to BasePage class

Every page should have heading that corresponds to menu item that was
picked.

Partially implements blueprint: selenium-integration-testing

Change-Id: I8257cc50911904169c27e0687d40bcfe49e332c4
",git fetch https://review.opendev.org/openstack/horizon refs/changes/93/100493/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/pages/basepage.py'],1,438fc8da2bf1b75cec3ef3bab28a71e0493f78b8,bp/selenium-integration-testing," _heading_locator = (by.By.CSS_SELECTOR, ""div.page-header > h2"") @property def heading(self): return self.get_element(*self._heading_locator) ",,7,0
openstack%2Fironic~master~Ia585d27153b7cbc85ce5b5402948689fb969df1d,openstack/ironic,master,Ia585d27153b7cbc85ce5b5402948689fb969df1d,Add shared functions for hardware discovery,ABANDONED,2014-07-15 11:48:54.000000000,2014-07-16 12:52:08.000000000,,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-07-15 11:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/466d51a1a86b39de4fcf61acf18ee4c52db18726', 'message': 'Add shared functions for hardware discovery\n\nNew module ironic.common.discovery is introduced with functions:\n- store_inventory: store hardware inventory in a given Node\n- find_node: find Node object, given full hardware inventory\n\nChange-Id: Ia585d27153b7cbc85ce5b5402948689fb969df1d\nImplements: blueprint generic-hardware-discovery\n'}, {'number': 2, 'created': '2014-07-15 12:36:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c6c47584c72039f4d19afda9519dae5474387341', 'message': 'Add shared functions for hardware discovery\n\nNew module ironic.common.discovery is introduced with functions:\n- store_inventory: store hardware inventory in a given Node\n- find_node: find Node object, given full hardware inventory\n\nChange-Id: Ia585d27153b7cbc85ce5b5402948689fb969df1d\nImplements: blueprint generic-hardware-discovery\n'}, {'number': 3, 'created': '2014-07-15 15:28:40.000000000', 'files': ['ironic/common/discovery.py', 'ironic/tests/test_discovery.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0aaf4966a663df9ad6e5e75dbf8d11efa49925d7', 'message': 'Add shared functions for hardware discovery\n\nNew module ironic.common.discovery is introduced with functions:\n- store_inventory: store hardware inventory in a given Node\n- find_node: find Node object, given full hardware inventory\n\nChange-Id: Ia585d27153b7cbc85ce5b5402948689fb969df1d\nImplements: blueprint generic-hardware-discovery\n'}]",0,107010,0aaf4966a663df9ad6e5e75dbf8d11efa49925d7,18,3,3,10239,,,0,"Add shared functions for hardware discovery

New module ironic.common.discovery is introduced with functions:
- store_inventory: store hardware inventory in a given Node
- find_node: find Node object, given full hardware inventory

Change-Id: Ia585d27153b7cbc85ce5b5402948689fb969df1d
Implements: blueprint generic-hardware-discovery
",git fetch https://review.opendev.org/openstack/ironic refs/changes/10/107010/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/discovery.py', 'ironic/tests/test_discovery.py']",2,466d51a1a86b39de4fcf61acf18ee4c52db18726,bp/generic-hardware-discovery,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Test on shared hardware discovery code."""""" from ironic.tests.db import base class TestStoreInventory(base.DbTestCase): pass class TestFindNode(base.DbTestCase): pass ",,78,0
openstack%2Fopenstack-doc-tools~master~Ia4e8cbe0bece7d2f567d3064f97b4731057f5046,openstack/openstack-doc-tools,master,Ia4e8cbe0bece7d2f567d3064f97b4731057f5046,Bump hacking to version 0.9.2,MERGED,2014-07-16 12:11:11.000000000,2014-07-16 12:38:28.000000000,2014-07-16 12:38:28.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-07-16 12:11:11.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/6b609001b3c91f3d56a29b03a52d980e64b8ecde', 'message': 'Bump hacking to version 0.9.2\n\nChange-Id: Ia4e8cbe0bece7d2f567d3064f97b4731057f5046\n'}]",0,107337,6b609001b3c91f3d56a29b03a52d980e64b8ecde,10,4,1,167,,,0,"Bump hacking to version 0.9.2

Change-Id: Ia4e8cbe0bece7d2f567d3064f97b4731057f5046
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/37/107337/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,6b609001b3c91f3d56a29b03a52d980e64b8ecde,bump_hacking,"hacking>=0.9.2,<0.10","hacking>=0.9.1,<0.10",1,1
openstack%2Fgrenade~master~I7b4a5ae37189081abb567910155b5422b3e0f0d7,openstack/grenade,master,I7b4a5ae37189081abb567910155b5422b3e0f0d7,Test: enable verbosity in tempest,ABANDONED,2014-06-16 17:14:36.000000000,2014-07-16 12:38:27.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2014-06-16 17:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/4647027454c2becaebce15a7cbb81cef15afd870', 'message': 'Test: enable verbosity in tempest\n\nDo not merge this patch.\nIt aims to debug another patch and see why javelin2 fails to create\nresources.\n\nChange-Id: I7b4a5ae37189081abb567910155b5422b3e0f0d7\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 2, 'created': '2014-06-17 12:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/dc0e48a39d80d8f0580c0e03a034db385d8f62cf', 'message': 'Test: enable verbosity in tempest\n\nDo not merge this patch.\nIt aims to debug another patch and see why javelin2 fails to create\nresources.\n\nChange-Id: I7b4a5ae37189081abb567910155b5422b3e0f0d7\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 3, 'created': '2014-06-18 08:15:22.000000000', 'files': ['grenade.sh', 'setup-javelin'], 'web_link': 'https://opendev.org/openstack/grenade/commit/73f4c4962dd2909119dba271088553f0ab17bf57', 'message': 'Test: enable verbosity in tempest\n\nDo not merge this patch.\nIt aims to debug another patch and see why javelin2 fails to create\nresources.\n\nChange-Id: I7b4a5ae37189081abb567910155b5422b3e0f0d7\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}]",0,100302,73f4c4962dd2909119dba271088553f0ab17bf57,11,2,3,3153,,,0,"Test: enable verbosity in tempest

Do not merge this patch.
It aims to debug another patch and see why javelin2 fails to create
resources.

Change-Id: I7b4a5ae37189081abb567910155b5422b3e0f0d7
Signed-off-by: Emilien Macchi <emilien.macchi@enovance.com>
",git fetch https://review.opendev.org/openstack/grenade refs/changes/02/100302/1 && git format-patch -1 --stdout FETCH_HEAD,['grenade.sh'],1,4647027454c2becaebce15a7cbb81cef15afd870,javelin2, # FIXME(EmilienM): debug only iniset /etc/tempest/tempest.conf DEFAULT verbose True ,,3,0
openstack%2Fsahara~master~I79503e4c33959ae43d5f2a4daf0d383f1aecd1b4,openstack/sahara,master,I79503e4c33959ae43d5f2a4daf0d383f1aecd1b4,"Revert ""Fix use of novaclient.exceptions.NotFound""",MERGED,2014-07-16 09:44:01.000000000,2014-07-16 12:19:42.000000000,2014-07-16 12:19:41.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7745}]","[{'number': 1, 'created': '2014-07-16 09:44:01.000000000', 'files': ['sahara/tests/unit/service/test_instances.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a93820e5fad3d583e1b6f681ba9f54cbab254ec3', 'message': 'Revert ""Fix use of novaclient.exceptions.NotFound""\n\nIt was fixed in nova client now, so, we need to revert this fix too.\nhttps://github.com/openstack/python-novaclient/releases/tag/2.18.1\n\nhttps://github.com/openstack/python-novaclient/compare/2.18.0...2.18.1\n\nThis reverts commit 29026c88a1a0528ca9a73a941cb9d49015d83342.\n\nChange-Id: I79503e4c33959ae43d5f2a4daf0d383f1aecd1b4\n'}]",0,107282,a93820e5fad3d583e1b6f681ba9f54cbab254ec3,11,6,1,6786,,,0,"Revert ""Fix use of novaclient.exceptions.NotFound""

It was fixed in nova client now, so, we need to revert this fix too.
https://github.com/openstack/python-novaclient/releases/tag/2.18.1

https://github.com/openstack/python-novaclient/compare/2.18.0...2.18.1

This reverts commit 29026c88a1a0528ca9a73a941cb9d49015d83342.

Change-Id: I79503e4c33959ae43d5f2a4daf0d383f1aecd1b4
",git fetch https://review.opendev.org/openstack/sahara refs/changes/82/107282/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/unit/service/test_instances.py'],1,a93820e5fad3d583e1b6f681ba9f54cbab254ec3,, return nova_exceptions.NotFound(code=404), return nova_exceptions.NotFound(),1,1
openstack%2Fhorizon~master~Id0b1432a8a254283d8d03ec03da7cb4c3e30347b,openstack/horizon,master,Id0b1432a8a254283d8d03ec03da7cb4c3e30347b,Fix typo in select methods definition,MERGED,2014-07-16 09:42:21.000000000,2014-07-16 12:03:50.000000000,2014-07-16 12:03:50.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-07-16 09:42:21.000000000', 'files': ['openstack_dashboard/test/integration_tests/pages/pageobject.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f04b82421aeed9bbbf73c4decb793b059b2bdfb4', 'message': 'Fix typo in select methods definition\n\nConstructor of Support.Select object expects webelement, just one\nargument is necessary, therefore the asterisk is redundant.\n\nIt seems like this method was refactored and was originaly used with\nlocator.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: Id0b1432a8a254283d8d03ec03da7cb4c3e30347b\n'}]",0,107281,f04b82421aeed9bbbf73c4decb793b059b2bdfb4,8,3,1,11473,,,0,"Fix typo in select methods definition

Constructor of Support.Select object expects webelement, just one
argument is necessary, therefore the asterisk is redundant.

It seems like this method was refactored and was originaly used with
locator.

Partially implements blueprint: selenium-integration-testing

Change-Id: Id0b1432a8a254283d8d03ec03da7cb4c3e30347b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/81/107281/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/pages/pageobject.py'],1,f04b82421aeed9bbbf73c4decb793b059b2bdfb4,bp/selenium-integration-testing," def select_dropdown(self, value, element): select = Support.Select(element) def select_dropdown_by_value(self, value, element): select = Support.Select(element)"," def select_dropdown(self, value, *element): select = Support.Select(*element) def select_dropdown_by_value(self, value, *element): select = Support.Select(*element)",4,4
openstack%2Fnova-specs~master~Id8c1f14c5694787413c7fcd7585541f5b089dc31,openstack/nova-specs,master,Id8c1f14c5694787413c7fcd7585541f5b089dc31,EC2: Volume type support,ABANDONED,2014-05-09 10:12:44.000000000,2014-07-16 11:52:59.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 5441}, {'_account_id': 5538}, {'_account_id': 10070}]","[{'number': 1, 'created': '2014-05-09 10:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ef4e095400a2043ebfa10d4d4af5bc3d2fa60379', 'message': 'EC2: Volume type support\n\nExpose volume type in the EC2 API\n\nChange-Id: Id8c1f14c5694787413c7fcd7585541f5b089dc31\n'}, {'number': 2, 'created': '2014-05-09 10:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d7093b1ce64207d55afeef0b6762727f04e75a14', 'message': 'EC2: Volume type support\n\nExpose volume type in the EC2 API\n\nChange-Id: Id8c1f14c5694787413c7fcd7585541f5b089dc31\n'}, {'number': 3, 'created': '2014-05-09 10:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/73c3456fb756aaef926a3e4cf762d97c27734c8d', 'message': 'EC2: Volume type support\n\nExpose volume type in the EC2 API\n\nChange-Id: Id8c1f14c5694787413c7fcd7585541f5b089dc31\n'}, {'number': 4, 'created': '2014-05-09 12:48:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4e7feba46b4b2e45efb8931dcd976b8f5f793127', 'message': 'EC2: Volume type support\n\nExpose volume type in the EC2 API\n\nChange-Id: Id8c1f14c5694787413c7fcd7585541f5b089dc31\n'}, {'number': 5, 'created': '2014-06-25 13:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fa87bfdf754d6e168e7895ec6232b656e0b28375', 'message': 'EC2: Volume type support\n\nExpose volume type in the EC2 API\n\nChange-Id: Id8c1f14c5694787413c7fcd7585541f5b089dc31\n'}, {'number': 6, 'created': '2014-07-03 04:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/46c82a92413fc32c10fd51e2e3cb749f06b351d8', 'message': 'EC2: Volume type support\n\nExpose volume type in the EC2 API\n\nChange-Id: Id8c1f14c5694787413c7fcd7585541f5b089dc31\n'}, {'number': 7, 'created': '2014-07-08 05:13:20.000000000', 'files': ['specs/juno/ec2-volume-type.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c267fc543be313eee50de69aad6e5322ee244586', 'message': 'EC2: Volume type support\n\nExpose volume type in the EC2 API\n\nBlueprint: ec2-volume-type\n\nChange-Id: Id8c1f14c5694787413c7fcd7585541f5b089dc31\n'}]",8,93016,c267fc543be313eee50de69aad6e5322ee244586,35,7,7,5538,,,0,"EC2: Volume type support

Expose volume type in the EC2 API

Blueprint: ec2-volume-type

Change-Id: Id8c1f14c5694787413c7fcd7585541f5b089dc31
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/16/93016/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/ec2-volume-type.rst'],1,ef4e095400a2043ebfa10d4d4af5bc3d2fa60379,bp/ec2-volume-type,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================== Volume type in EC2 API ====================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/ec2-volume-type The concept of volume type is not exposed via the OpenStack's EC2 API. This blueprint is to address that, and make the EC2 API consistent with AWS's. Problem description =================== Volumes created by OpenStack's EC2 API does not have 'volumeType' attribute. AWS provides two volumes types currently -- 'standard' and 'io1', where 'standard' is for normal volumes without any guarantees, and 'io1' volumes to which we can attach a value for guaranteed IOPS. We should allow a way for deployers to configure the backend such that these volume types are exposed, if the backend supports it. If the deployer has only the 'standard' volume types, he should be able to expose only that, and then the code should raise error if the user requests for a volume of unsupported volume type. Proposed change =============== The proposal is to leverage Cinder's ""volume type extra-specs"" feature. The cloud admin will need to create scoped key-value pairs for the Cinder volume type they want to expose as EC2's volume type. For example, if they want to expose volume type 'slow-lvm' registered with Cinder as 'standard' volume type in the EC2 API, he will need to create an extra-spec ""EC2:type"" => ""standard"" for 'slow-lvm' volume type. If no volume type is created at the backend, or if these extra specs are not attached to them, EC2 will just shoot a request to Cinder to create a volume with no volume type, and will expose this volume in EC2 API as a 'standard' volume. In the code, a new method to fetch volume types and extra specs will be implemented, which will fetch this detail only once. The association of Cinder and EC2's volume type will be kept in memory, and be referred whenever needed while creating or listing of volumes via the EC2 API. For the guaranteed IOPS volume type, current proposal is to just pass the IOPS value as the metadata to the volume. In future, we need to make sure that this volume IOPS value can be consumed by the backend, if the backend supports it. Alternatives ------------ An alternative way to do it is by creating and setting config options. The current method is preferred as it is more extensible in case Amazon comes up with new volume types and we need to incorporate them. Currently, potentially, the deployer can make an association for the 'io1' volume type, but he will not be able to consume the IOPS value provided by the user. An alternative to this is, till the support for guaranteed-IOPS volumes is complete, we, in the code, just disable creating of volumes with this type (by raising an exception). Data model impact ----------------- No data model impact. REST API impact --------------- No change in the OpenStack ReST API. However behavior of a few EC2 API is going to change as described below: * DescribeVolumes * The volume elements of 'volumeSet' element will now contain a new attribute 'volumeType', with 'standard' as the default value for it. This value cannot be anything apart from 'standard' or 'io1', as of today. * CreateVolume * Parameter 'volumeType' passed in the request is not going to be ignored any more. * New error response codes: * UnknownVolumeType: when specified volume type is not one of 'standard' or 'io1' * VolumeTypeNotAvailableInZone: when the specified volume type is not supported by the backend, as configured by the deployer. Security impact --------------- Can't see any. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ The very first call to DescribeVolumes or CreateVolume (whichever is called first) will be slower, as internally, it will be making an additional call to Cinder to get the volume type details. Apart from this, no other performance impact. Other deployer impact --------------------- As specified above, deployer will need to specify extra specs for volume types mandatorily ONLY IF he wants to expose both volume types. If they want to only expose the 'standard' type, everything will work just fine without any fine-tuning from deployer. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: rushiagr (Rushi Agrawal) Work Items ---------- * Expose volume type in EC2 API. (Single work item) Dependencies ============ None Testing ======= In future, Tempest tests will need to be added, to test if this functionality work perfectly fine. Also, we should make sure that this code change works when existing volumes are created (upgrade tests). Shouldn't be a lot of code I am guessing. Documentation Impact ==================== EC2 API document will be impacted due to this change. We will now need to highlight that volume type will be exposed via the API. References ========== * CreateVolume from EC2 docs: http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-CreateVolume.html * DescribeVolumes from EC2 docs: http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeVolumes.html ",,165,0
openstack%2Fnova-specs~master~Ibbc62fb9866b33d046ff2fe13588b4d02db3d250,openstack/nova-specs,master,Ibbc62fb9866b33d046ff2fe13588b4d02db3d250,Add periodic task heartbeat file,ABANDONED,2014-06-25 14:16:43.000000000,2014-07-16 11:52:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 8688}, {'_account_id': 9060}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-06-25 14:16:43.000000000', 'files': ['specs/juno/periodic-heartbeat.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f1ae5b6e69bd801372330f61f1df5beffe660bce', 'message': ""Add periodic task heartbeat file\n\nAt present it's difficult to verify that all Nova services are\nresponsive, rather than merely running. Touch a heartbeat file, the\nfreshness of which can easily be monitored by EG an Icinga check.\n\nChange-Id: Ibbc62fb9866b33d046ff2fe13588b4d02db3d250\n""}]",5,102540,f1ae5b6e69bd801372330f61f1df5beffe660bce,15,7,1,8688,,,0,"Add periodic task heartbeat file

At present it's difficult to verify that all Nova services are
responsive, rather than merely running. Touch a heartbeat file, the
freshness of which can easily be monitored by EG an Icinga check.

Change-Id: Ibbc62fb9866b33d046ff2fe13588b4d02db3d250
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/40/102540/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/periodic-heartbeat.rst'],1,f1ae5b6e69bd801372330f61f1df5beffe660bce,periodic-heartbeat,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================== Periodic heartbeat ================== https://blueprints.launchpad.net/nova/+spec/periodic-heartbeat At present it's difficult to verify that all Nova services are responsive, rather than merely running. Touch a heartbeat file, the freshness of which can easily be monitored by EG an Icinga check. Problem description =================== As a service operator, I would like to ensure Nova services have not hung. It is naturally easy to check the responsiveness of the API service, but there is no simple way to check the other services. Proposed change =============== This spec proposes an additional periodic task as part of nova/manager.py which will run as part of the Nova API, scheduler, conductor and compute services. This task will touch a file in a well-known location, the freshness of which can easily be monitored by EG an Icinga check. Alternatives ------------ We could open up a REST API on the other services. That seems a heavyweight solution to the simple requirements posed by this spec. If more extensive service status requirements are introduced, this alternative may be more proportionate. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ Very low to none. Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: alexisl Other contributors: None Work Items ---------- * Add periodic task Dependencies ============ None. Testing ======= This is a simple change, so unit tests should be sufficient. Documentation Impact ==================== A note should be made about this behaviour so that operators may take advantage of it. References ========== None. ",,118,0
openstack%2Fnova-specs~master~I6442137549804f0632a28199d25df403ebf18e0d,openstack/nova-specs,master,I6442137549804f0632a28199d25df403ebf18e0d,VMware nova-Storage optimization for clusters with multiple datastores,ABANDONED,2014-06-09 07:31:11.000000000,2014-07-16 11:52:06.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5638}, {'_account_id': 7239}, {'_account_id': 7400}, {'_account_id': 7575}, {'_account_id': 8027}, {'_account_id': 8759}, {'_account_id': 9172}, {'_account_id': 11791}]","[{'number': 1, 'created': '2014-06-09 07:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a3d27350f5a3b4d57fcb7a2fd1cb557d945992e8', 'message': 'VMware nova-Storage optimization for clusters with multiple datastores\n\nThis blueprint allows images to launch faster and saves disk space by\ncreating linked clones of instances using the base disk already present in\nthe image cache of other datastore of the ESX cluster.\nVMware ESX cluster can have multiple datastores that are shared across all the\nhosts of the cluster. Its much more efficient to have a single copy of the\nimage in only one datastore of the cluster and create linked clones using\nthis image.\n\nChange-Id: I6442137549804f0632a28199d25df403ebf18e0d\n'}, {'number': 2, 'created': '2014-06-09 08:41:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/341476edcf5db53d9c12f651c72840855b9f6c72', 'message': 'VMware nova-Storage optimization for clusters with multiple datastores\n\nThis blueprint allows images to launch faster and saves disk space by\ncreating linked clones of instances using the base disk already present in\nthe image cache of other datastore of the ESX cluster.\nVMware ESX cluster can have multiple datastores that are shared across all the\nhosts of the cluster. Its much more efficient to have a single copy of the\nimage in only one datastore of the cluster and create linked clones using\nthis image.\n\nChange-Id: I6442137549804f0632a28199d25df403ebf18e0d\n'}, {'number': 3, 'created': '2014-06-09 09:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3d9ce4ccbc8c39571b76740d6d61095b32a14ba4', 'message': 'VMware nova-Storage optimization for clusters with multiple datastores\n\nThis blueprint storage-optimization-for-multi-datastore-clusters allows\nimages to launch faster and saves disk space by creating linked clones\nof instances using the base disk already present in the image cache of\nother datastore of the ESX cluster.\nVMware ESX cluster can have multiple datastores that are shared across all the\nhosts of the cluster. Its much more efficient to have a single copy of the\nimage in only one datastore of the cluster and create linked clones using\nthis image.\n\nChange-Id: I6442137549804f0632a28199d25df403ebf18e0d\n'}, {'number': 4, 'created': '2014-06-09 11:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/db22b9fce7cb859c0cf9d4c6146f54306e694f57', 'message': 'VMware nova-Storage optimization for clusters with multiple datastores\n\nThis blueprint storage-optimization-for-multi-datastore-clusters allows\nimages to launch faster and saves disk space by creating linked clones\nof instances using the base disk already present in the image cache of\nother datastore of the ESX cluster.\nVMware ESX cluster can have multiple datastores that are shared across all the\nhosts of the cluster. Its much more efficient to have a single copy of the\nimage in only one datastore of the cluster and create linked clones using\nthis image.\n\nChange-Id: I6442137549804f0632a28199d25df403ebf18e0d\n'}, {'number': 5, 'created': '2014-06-12 09:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/09f1b324c3da6854f16c4a73be1236ba19e29082', 'message': 'VMware nova-Storage optimization for clusters with multiple datastores\n\nThis blueprint storage-optimization-for-multi-datastore-clusters allows\nimages to launch faster and saves disk space by creating linked clones\nof instances using the base disk already present in the image cache of\nother datastore of the ESX cluster.\nVMware ESX cluster can have multiple datastores that are shared across all the\nhosts of the cluster. Its much more efficient to have a single copy of the\nimage in only one datastore of the cluster and create linked clones using\nthis image.\n\nChange-Id: I6442137549804f0632a28199d25df403ebf18e0d\n'}, {'number': 6, 'created': '2014-06-27 10:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0ad8332a7f7f822b438221c85ea6b99b25dd8f61', 'message': 'VMware nova-Storage optimization for clusters with multiple datastores\n\nThis blueprint storage-optimization-for-multi-datastore-clusters allows\nimages to launch faster and saves disk space by creating linked clones\nof instances using the base disk already present in the image cache of\nother datastore of the ESX cluster.\nVMware ESX cluster can have multiple datastores that are shared across all the\nhosts of the cluster. Its much more efficient to have a single copy of the\nimage in only one datastore of the cluster and create linked clones using\nthis image.\n\nChange-Id: I6442137549804f0632a28199d25df403ebf18e0d\n'}, {'number': 7, 'created': '2014-06-27 10:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1c3ec456ba195a1cb9a9d468ebd0d3d9c923f013', 'message': 'VMware nova-Storage optimization for clusters with multiple datastores\n\nThis blueprint storage-optimization-for-multi-datastore-clusters allows\nimages to launch faster and saves disk space by creating linked clones\nof instances using the base disk already present in the image cache of\nother datastore of the ESX cluster.\nVMware ESX cluster can have multiple datastores that are shared across all the\nhosts of the cluster. Its much more efficient to have a single copy of the\nimage in only one datastore of the cluster and create linked clones using\nthis image.\n\nChange-Id: I6442137549804f0632a28199d25df403ebf18e0d\n'}, {'number': 8, 'created': '2014-07-01 09:04:43.000000000', 'files': ['specs/juno/storage-optimization-for-multi-datastore-clusters.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/57ff913e23f5c591ec92eae29fae18e36f30ec3e', 'message': 'VMware nova-Storage optimization for clusters with multiple datastores\n\nThis blueprint storage-optimization-for-multi-datastore-clusters allows\nimages to launch faster and saves disk space by creating linked clones\nof instances using the base disk already present in the image cache of\nother datastore of the ESX cluster.\nVMware ESX cluster can have multiple datastores that are shared across all the\nhosts of the cluster. Its much more efficient to have a single copy of the\nimage in only one datastore of the cluster and create linked clones using\nthis image.\n\nblueprint: storage-optimization-for-multi-datastore-clusters\nChange-Id: I6442137549804f0632a28199d25df403ebf18e0d\n'}]",28,98704,57ff913e23f5c591ec92eae29fae18e36f30ec3e,46,14,8,7239,,,0,"VMware nova-Storage optimization for clusters with multiple datastores

This blueprint storage-optimization-for-multi-datastore-clusters allows
images to launch faster and saves disk space by creating linked clones
of instances using the base disk already present in the image cache of
other datastore of the ESX cluster.
VMware ESX cluster can have multiple datastores that are shared across all the
hosts of the cluster. Its much more efficient to have a single copy of the
image in only one datastore of the cluster and create linked clones using
this image.

blueprint: storage-optimization-for-multi-datastore-clusters
Change-Id: I6442137549804f0632a28199d25df403ebf18e0d
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/04/98704/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/storage-optimization-for-multi-datastore-clusters.rst'],1,a3d27350f5a3b4d57fcb7a2fd1cb557d945992e8,bp/storage-optimization-for-multi-datastore-clusters,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================== VMware nova – Storage optimization for clusters with multiple datastores ============================================================== https://blueprints.launchpad.net/nova/+spec/storage-optimization-for-multi-datastore-clusters This blueprint allows images to launch faster and saves disk space by creating linked clones of instances using the base disk already present in the image cache of other datastore of the ESX cluster. VMware ESX cluster can have multiple datastores that are shared across all the hosts of the cluster. Its much more efficient to have a single copy of the image in only one datastore of the cluster and create linked clones using this image. Problem description =================== ESX clusters can have multiple shared datastores configured. A datastore is a logical container that stores the virtual machine files. This includes both the disk (vmdk), configuration (vmx) files and snapshot files. A datastore can be created from different types of physical storage like local direct attached storage, iSCSI, FC SAN and NFS. The physical storage is presented to all host in the cluster and therefore the datastore is accessible from all the hosts of the cluster. Each cluster will typically have its own set of datastores and this is the recommended configuration. This configuration enable the live migration of VMs across all hosts of the cluster. When using the VMware ESX hypervisor nova driver for such clusters with multiple shared datastores the image can get cached in each datastore. Additionally a disk of size equal to the flavor of the instance is also created in the cache. Instance are created as linked clones to this flavor sized disks. This approach has the following problems: * Every time a new datastore is selected by the driver for deployment, a new cache is created on the datastore and the image is copied. * A copy of the image expanded to the size of the flavor is created for each instance deployed with a different flavor This approach leads to loss of actual storage space for creating instances. In the existing design, when an instance creation is done, the following occur * Step 1. The driver determines the best datastore to place the instance. It does this by selecting the datastore with maximum free space. * Step 2. The existence of the image is checked in the cache (directory named _vmware_base) on the clusters datastore * Step 3. If the image is not available in the cache, then (i) the image is downloaded from glance into nova-compute (the VM where the compute service runs) (ii) Then the image is transferred from the nova-compute to the datastore by vCenter * Step 4.Instance is spawned using the cached image by first creating a disk of the size of the specified in the flavor (if it doesnt exist). Then creating a linked clone using the flavor sized disk as the base disk. The problems exist in Step 1 and Step 2 since the the driver is not utilizing the cache in other datastores. Proposed change =============== * 1. The drivers datastore selection can be modified to select the datastore that has the image already cached and if has enough space for the new instance (as per Step 4 above) * 2. If the datastore where the image is cached does not have enough space for the new instance, then create a linked clone in a different datastore but still using the cached image as the base disk Alternatives ------------ Another alternative is to schedule instances to the clusters that have the image already cached. This will work fine until the cluster has capacity. To use this alternative, the following changes will be required (1) the VMware nova driver will have to publish the list of images in its cache. (2) A new scheduler filter will then select the nova-compute (cluster) that already has the image in its cache. If there are no clusters that have the image then it would return all clusters (existing behaviour). This will be addressed a separate blueprint (will be submitting this). Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Given that in a private cloud there will be different set of standard images, and the number of datastores per cluster is generaly more than 1, enhancing the datastore selection logic and creating linked clones across datastores will significantly improve user experience, reduce instance creation times since multiple caches are not created and improve storage utilization. Other deployer impact --------------------- None Developer impact ---------------- * The similar approach can be used by other nova drivers that support nodes with multiple logical storage where cache is maintained per logical storage. * This change only impacts the VMware nova driver. Other drivers will not be impacted due to this change. Implementation ============== Assignee(s) ----------- Primary assignee: aiswarya-sundaran Other contributors: kiran-kumar-vaddi Work Items ---------- * Modify the code the selects the datastore to spawn an instance to also use the cache as a criteria * Modify the instance creation code to be able to point to a different datastore for the instance base disk Dependencies ============ None Testing ======= The unit tests will be modified to test the branches introduced by the above work items Documentation Impact ==================== None References ========== None ",,177,0
openstack%2Fnova-specs~master~I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d,openstack/nova-specs,master,I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d,Support function of USB-redirection,ABANDONED,2014-04-23 13:31:05.000000000,2014-07-16 11:51:54.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 8290}, {'_account_id': 9847}, {'_account_id': 10510}]","[{'number': 1, 'created': '2014-04-23 13:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5909a6d3136e51be1e244c5a546d618d49001ef8', 'message': 'Support function of USB-redirection\n\nThere are requirements for USB-redirection function like redirect a USB printer from TC(Think client) to cloud by some kind of protocols like spice, then user can use printer device in cloud environment\n\nblueprint usb-redirection\n\nChange-Id: I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d\n'}, {'number': 2, 'created': '2014-04-24 16:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a1c083b3608b461def792c483b90751b97b3831d', 'message': 'Support function of USB-redirection\n\nThere are requirements for USB-redirection function like redirect a USB printer from TC(Think client) to cloud by some kind of protocols like spice,\nthen user can use printer device in cloud environment\n\nblueprint usb-redirection\n\nChange-Id: I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d\n'}, {'number': 3, 'created': '2014-04-24 16:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6299347232b214c93f82785140ec84bd20d96b86', 'message': 'Support function of USB-redirection\n\nThere are requirements for USB-redirection function like redirect a USB printer from TC(Think client) to cloud by some kind of protocols like spice,\nthen user can use printer device in cloud environment\n\nblueprint usb-redirection\n\nChange-Id: I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d\n'}, {'number': 4, 'created': '2014-04-28 13:27:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2a4d191522a40056e82c2de7d99f562fc18d6895', 'message': 'Support function of USB-redirection\n\nThere are requirements for USB-redirection function like redirect a USB printer from TC(Think client) to cloud by some kind of protocols like spice,\nthen user can use printer device in cloud environment\n\nblueprint usb-redirection\n\nChange-Id: I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d\n'}, {'number': 5, 'created': '2014-04-28 13:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/dcd64fa06098880432aed680f0599abee8a4f62f', 'message': 'Support function of USB-redirection\n\nThere are requirements for USB-redirection function like redirect a USB printer from TC(Think client) to cloud by some kind of protocols like spice,\nthen user can use printer device in cloud environment\n\nblueprint usb-redirection\n\nChange-Id: I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d\n'}, {'number': 6, 'created': '2014-05-04 13:35:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/12ff570645ae052daeaec261e0413927c9dbb634', 'message': 'Support function of USB-redirection\n\nThere are requirements for USB-redirection function like redirect a USB printer from TC(Think client) to cloud by some kind of protocols like spice,\nthen user can use printer device in cloud environment\n\nblueprint usb-redirection\n\nChange-Id: I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d\n'}, {'number': 7, 'created': '2014-05-04 14:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5895af213b2a9ac5b82c77b3ae96367997473f1a', 'message': 'Support function of USB-redirection\n\nThere are requirements for USB-redirection function like redirect a USB printer from TC(Think client) to cloud by some kind of protocols like spice,\nthen user can use printer device in cloud environment\n\nblueprint usb-redirection\n\nChange-Id: I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d\n'}, {'number': 8, 'created': '2014-06-17 14:45:20.000000000', 'files': ['specs/juno/usb-redirection.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0120a57f37a303933e6c71ec2a46cc8384908c22', 'message': 'Support function of USB-redirection\n\nThere are requirements for USB-redirection function like redirect a USB printer from TC(Think client) to cloud by some kind of protocols like spice,\nthen user can use printer device in cloud environment\n\nblueprint usb-redirection\n\nChange-Id: I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d\n'}]",23,89834,0120a57f37a303933e6c71ec2a46cc8384908c22,44,8,8,10510,,,0,"Support function of USB-redirection

There are requirements for USB-redirection function like redirect a USB printer from TC(Think client) to cloud by some kind of protocols like spice,
then user can use printer device in cloud environment

blueprint usb-redirection

Change-Id: I20f9e3e127b3a2f5d98ad69fd278ef657c3bd47d
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/34/89834/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/usb-redirection.rst'],1,5909a6d3136e51be1e244c5a546d618d49001ef8,bp/usb-redirection,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================== Support function of USB-redirection =================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/usb-redirection We provide VDI(Virtual Desktop)solution for customers, our customers have strong requirements for using USB devices. The typical use cases and our solutions are described as below: Customers want to use local USB printers or USB scanners with TC(Thin-Client), because remote desktop protocol like ICA have already supported USB-redirection, so customers only need to attach USB device to TC, the protocol can map USB device to VM. Problem description =================== Use cases: A end user wants to print some documents in cloud environments, him perform the following steps: 1. Create a VM with virtual USB-redirection devices. 2. Use TC with spice client to connect to VM, insert USB printer to TC, select printer to redirect to VM in GUI of spice client. 3. User can see printer in VM and use printer to print documents. A end user wants to take a video chat with friends in cloud environments, him perform the following steps: 1. Create a VM with virtual USB-redirection devices. 2. Use TC with spice client to connect to VM, insert USB camera to TC, select camera to redirect to VM in GUI of spice client. 3. User can see camera in VM and take video chat with friends. Proposed change =============== 1. Add function of create USB-redirection device in libvirt driver. 2. Support specify USB-redirection device in flavor and create VM with this kind of flavor. Alternatives ------------ None Data model impact ----------------- 1. Add USB-redirection device data object in libvirt driver, the libvirt xml may like: <redirdev bus='usb' type='spicevmc'> <alias name='redir0'/> </redirdev> 2. Use key-value to specify USB-redirection device in flavor, the schema may like: {""usb_redirection_devices"":{[""bus"": usb, ""type"": ""spicevmc""]}} REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <Jing Yuan> Work Items ---------- Step 1: Add object of USB-redirection device in libvirt driver. Step 2: Create VM with flvor which contains USB-redirection device. Dependencies ============ None Testing ======= None Documentation Impact ==================== It is necessary to add doc for how to use this new function. References ========== None ",,154,0
openstack%2Fnova-specs~master~I7a8abc3803b780b5fad759e1dfd23482a004f61d,openstack/nova-specs,master,I7a8abc3803b780b5fad759e1dfd23482a004f61d,Add separated policy rule for each v3 api,ABANDONED,2014-05-06 09:41:13.000000000,2014-07-16 11:49:09.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 9847}]","[{'number': 1, 'created': '2014-05-06 09:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fd87cce63fe08f58a8ef805a36e03ec63fcf9333', 'message': 'Add separated policy rule for each v3 api\n\nThis bp is propose to add separated policy rule for each v3 api.\nThat will provide finer granularity to permission control and\nconsistent way to configure policy rule\n\nPart of blueprint separated-policy-rule-v3-api\n\nChange-Id: I7a8abc3803b780b5fad759e1dfd23482a004f61d\n'}, {'number': 2, 'created': '2014-05-06 09:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a20c3e29d5b94bbcfe8ab6944e6c3b86a13bfe9a', 'message': 'Add separated policy rule for each v3 api\n\nThis bp is propose to add separated policy rule for each v3 api.\nThat will provide finer granularity to permission control and\nconsistent way to configure policy rule\n\nPart of blueprint separated-policy-rule-v3-api\n\nChange-Id: I7a8abc3803b780b5fad759e1dfd23482a004f61d\n'}, {'number': 3, 'created': '2014-05-28 06:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7a9f0686339dce2a663c7818476a7ce6a60b7d35', 'message': 'Add separated policy rule for each v3 api\n\nThis bp is propose to add separated policy rule for each v3 api.\nThat will provide finer granularity to permission control and\nconsistent way to configure policy rule\n\nPart of blueprint separated-policy-rule-v3-api\n\nChange-Id: I7a8abc3803b780b5fad759e1dfd23482a004f61d\n'}, {'number': 4, 'created': '2014-06-23 02:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4f413b964d4aa53daefb513ad31620169caab0b9', 'message': 'Add separated policy rule for each v3 api\n\nThis bp is propose to add separated policy rule for each v3 api.\nThat will provide finer granularity to permission control and\nconsistent way to configure policy rule\n\nPart of blueprint separated-policy-rule-v3-api\n\nChange-Id: I7a8abc3803b780b5fad759e1dfd23482a004f61d\n'}, {'number': 5, 'created': '2014-07-01 12:33:52.000000000', 'files': ['specs/juno/separated-policy-rule-v3-api.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a9292d34de111262cecb62b391b7480fc04b1cd2', 'message': 'Add separated policy rule for each v3 api\n\nThis bp is propose to add separated policy rule for each v3 api.\nThat will provide finer granularity to permission control and\nconsistent way to configure policy rule\n\nPart of blueprint separated-policy-rule-v3-api\n\nChange-Id: I7a8abc3803b780b5fad759e1dfd23482a004f61d\n'}]",22,92326,a9292d34de111262cecb62b391b7480fc04b1cd2,41,7,5,5754,,,0,"Add separated policy rule for each v3 api

This bp is propose to add separated policy rule for each v3 api.
That will provide finer granularity to permission control and
consistent way to configure policy rule

Part of blueprint separated-policy-rule-v3-api

Change-Id: I7a8abc3803b780b5fad759e1dfd23482a004f61d
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/26/92326/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/separated-policy-rule-v3-api.rst'],1,fd87cce63fe08f58a8ef805a36e03ec63fcf9333,bp/is,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Add separated policy rule for each v3 api ========================================== https://blueprints.launchpad.net/nova/+spec/separated-policy-rule-v3-api There are different way to add policy rule for an API in the v3 extension. In some extensions, there is use one policy rule for the API in that extension. In other extensions, there maybe provide policy rule for each API in that extension. So this BP want to add policy rule for each v3 API, then we can get finer granularity to permission control and consistent way to configure policy rule for API. Problem description =================== 1. It didn't have finer granularity permission control in v3 API, This problem is same with this bp https://blueprints.launchpad.net/nova/+spec/aggregate-api-policy that want to resolve. 2. Hard to configure a policy rule for cloud operator. There isn't any document to mention that how to write an policy rule for each API. But there are some extensions only have one rule for all the API, and some extension is not. Cloud operator need check the source code to know How to write poliry rule for a specific API. Proposed change =============== Add policy rule for each API in v3 API. Then it get finer granularity permission control. And Cloud Operator is easy to know how to write a policy rule. Because all the policy rule follow the pattern: compute_extension:v3:[extension_name]:[action_name] Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- Deployer get finer granularity permission control of API and consistent way to write policy rule. Developer impact ---------------- When developer add new extension, developer should provide policy rule for each API, not share an policy rule for the API in that extension. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: Alex Xu <xuhj@linux.vnet.ibm.com> Other contributors: Ji Chen <jcjichen@cn.ibm.com> Work Items ---------- https://etherpad.openstack.org/p/separated_policy_rule Dependencies ============ https://blueprints.launchpad.net/nova/+spec/extension-level-policy-as-default-v3-api Testing ======= None Documentation Impact ==================== For deployer, they can set policy rule for each API. References ========== ",,131,0
openstack%2Fnova-specs~master~I9c90246b3bb5419efa04b6b66ef1c026b556891d,openstack/nova-specs,master,I9c90246b3bb5419efa04b6b66ef1c026b556891d,vmware: enables mutliple backend drivers,ABANDONED,2014-06-27 08:28:02.000000000,2014-07-16 11:47:33.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 3016}, {'_account_id': 4393}, {'_account_id': 6498}, {'_account_id': 7400}, {'_account_id': 9172}, {'_account_id': 10487}]","[{'number': 1, 'created': '2014-06-27 08:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/cc5192cf3f35b19983e92f2bbb7b613f6b498860', 'message': 'enables mutiple backend driver\n\nIt enables the mutiple backend drivers for\nnova-compute to imporve the node usage,\nscalability of nova-compute and to enable\none nova-compute per hypervisor\n\nChange-Id: I9c90246b3bb5419efa04b6b66ef1c026b556891d\n'}, {'number': 2, 'created': '2014-06-27 08:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/777ce10ee09d766393884d9cee05a9bf8782cdc5', 'message': 'enables mutiple backend driver\n\nIt enables the mutiple backend drivers for\nnova-compute to imporve the node usage,\nscalability of nova-compute and to enable\none nova-compute per hypervisor\n\nChange-Id: I9c90246b3bb5419efa04b6b66ef1c026b556891d\n'}, {'number': 3, 'created': '2014-06-27 08:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/303126477ae085d56787cee44671a222d0fed459', 'message': 'enables mutiple backend driver\n\nIt enables the mutiple backend drivers for\nnova-compute to imporve the node usage,\nscalability of nova-compute and to enable\none nova-compute per hypervisor\n\nChange-Id: I9c90246b3bb5419efa04b6b66ef1c026b556891d\n'}, {'number': 4, 'created': '2014-06-27 09:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/59c5fd47db759ac6adc5f517d3a6b66772a22c64', 'message': 'enables mutiple backend driver\n\nIt enables the mutiple backend drivers for\nnova-compute to imporve the node usage,\nscalability of nova-compute and to enable\none nova-compute per hypervisor\n\nChange-Id: I9c90246b3bb5419efa04b6b66ef1c026b556891d\n'}, {'number': 5, 'created': '2014-06-27 09:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6365a67bd502b88df6b95633f1a5bda484094e19', 'message': 'enables mutiple backend driver\n\nIt enables the mutiple backend drivers for\nnova-compute to imporve the node usage,\nscalability of nova-compute and to enable\none nova-compute per hypervisor\n\nChange-Id: I9c90246b3bb5419efa04b6b66ef1c026b556891d\n'}, {'number': 6, 'created': '2014-06-27 10:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4ff8cba1e9acd99c954493acf114ea1e668de4db', 'message': 'enables mutliple backend driver\n\nIt enables the multiple backend drivers for\nnova-compute to imporve the node usage,\nscalability of nova-compute and to enable\none nova-compute per hypervisor\n\nChange-Id: I9c90246b3bb5419efa04b6b66ef1c026b556891d\n'}, {'number': 7, 'created': '2014-07-01 10:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2a7248152b5da97db1bf05c37e1dce48a512db0c', 'message': 'enables mutliple backend drivers\n\nIt enables the multiple backend drivers for\nnova-compute to improve the node usage,\nscalability of nova-compute and to enable\none nova-compute per hypervisor\n\nChange-Id: I9c90246b3bb5419efa04b6b66ef1c026b556891d\n'}, {'number': 8, 'created': '2014-07-02 17:46:16.000000000', 'files': ['specs/juno/nova-compute-multi-backend-support.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/bd4f47265cf27e5e79d4b6965f9724301865120b', 'message': 'vmware: enables mutliple backend drivers\n\nIt enables the multiple backend drivers for\nnova-compute to improve the node usage,\nscalability of nova-compute and to enable\none nova-compute per hypervisor\n\nChange-Id: I9c90246b3bb5419efa04b6b66ef1c026b556891d\n'}]",18,103054,bd4f47265cf27e5e79d4b6965f9724301865120b,37,9,8,10487,,,0,"vmware: enables mutliple backend drivers

It enables the multiple backend drivers for
nova-compute to improve the node usage,
scalability of nova-compute and to enable
one nova-compute per hypervisor

Change-Id: I9c90246b3bb5419efa04b6b66ef1c026b556891d
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/54/103054/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/nova-compute-multi-backend-support.rst'],1,cc5192cf3f35b19983e92f2bbb7b613f6b498860,bp/multi-backend,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Nova-compute multi-backend support ========================================== https://blueprints.launchpad.net/nova/+spec/multi-back-ends-for-nova-compute This blue print enables to run multiple nova-compute process from a given Node where nova-compute is installed. And is similar to Cinder feature https://wiki.openstack.org/wiki/Cinder-multi-backend Problem description =================== Following are the issues exist with nova-compute: 1. node is under utilized: Nova-compute is designed to configure with only one type of nova compute driver like kvm, vmware, citrix,etc. And for hypervisors like kvm, nova-compute is installed on the hypervisor node itself and here CPU, memory will be shared load will be high as hypervisor is running on the nova-compute. But for the vmware hypervisors, nova-compute is installed on the separate node and its called proxy for nova-compute. So the load on the proxy-compute node will be comparatively lesser and it will be more efficient if nova-compute node is allowed to configure multiple compute proxy driver similar to the cinder-volume multi-backend architecture. 2. Scalability is big challenge: By enabling the multiple back-end drivers, it helps to improve the scale-ability of the given nova-compute as it can handle more number of instance action across multiple backend drivers. 3. One nova compute per hyervisor: It helps to model one nova-compute per hypervisor as decided in juno release onwards. Proposed change =============== Cinder already solved the same issue by means of multi-backend and same can be leveraged for nova-compute to launch one nova-compute process per backend driver as detailed below: Update the nova.conf such that all common configuration will go in the [DEFAULT] section and for each backend drirver, create one section as below: [DEAFULT] .... #back_ends will have comma separated set of compute drivers section #Each compute driver could be same or different back_ends = vcdriver1, vcdriver2, xen1 [vcdriver1] ... [vcdriver2] ... [xen1] ... With these configuration in place, when nova-compute starts, it will spawn 3 nova-compute one for each of the configured driver. NOTE: This helps to launch different hypervisor drivers from the same node similar to cinder. Functionality vise there is no change and its only the service launching process change to address the drawbacks mentioned above. Alternatives ------------ For example, Consider the exemple of vmware VC driver. one nova-compute was supporting as many clusters in the given vcenter. Assume that admin wants to use a vcenter with 30 clusters, then in icehouse, only one nova-compute is sufficient to handle all clusters But in juno design summit, it was decided that, there should be only one vmware cluster per nova-compute. so to support 30 clusters, admin needs to follow one of the work-around given below: 1. Run 30 nova-compute nodes(servers) and each node for one cluster. Usually admin runs nova-compute on high-end servers, and it is an under utilization of server as only one nova-compute runs per server. 2. In a given high-end node, run 30 compute-node process and each process with independent copy of nova.conf. Here admin needs to run nova-compute from the command line, as there can be only upstart service named 'nova-compute' per node. In both the case, admin needs to maintain the same nova.conf parameters in all 30 nodes except the vmware->cluser_name parameter. This is more of error prone and for updating any of a given parameter is cumbersome, as it needs to be Updated across 30 node's nova.conf. . Data model impact ----------------- No change REST API impact --------------- No change Security impact --------------- No change Notifications impact -------------------- No change Other end user impact --------------------- No change Performance Impact ------------------ As each backend will be exposed as separate nova-compute process as existing today, there won't be no performance impact. Other deplorer impact --------------------- Only change is nova.conf as mentioned in the ""proposed change"" page. Developer impact ---------------- No Change. Implementation ============== Assignee(s) ----------- Primary assignee: kanagaraj-manickam Other contributors: None Work Items ---------- 1. Nova compute module update to launch one nova-compute per driver 2. Enable drivers to retrieve the driver parameters from respective section of nova.conf. 3. Update the queue name. a. Current format: compute.<nova-compute-node-host-name>. b. New format: computee.<nova-compute-node-host-name>.<backend-name> 4. Make sure that scheduler is able to identify the nova-computes launched in the multi backend modes and status updates are happening properly. 5. Make sure that ""nova-manage service list"" command provides the correct details as configured in the multi backend mode. Dependencies ============ * It will refer the existing functionality of cinder-volume Testing ======= Here unit testing of all compute.py, and its counter part nova.service module, compute manager modules should be updated with new test cases for the updated codes.Make sure existing tests successfully passed Documentation Impact ==================== As mentioned the ""proposed change"" section, the nova.conf will be updated. References ========== cinder multi-backed: https://wiki.openstack.org/wiki/Cinder-multi-backend ",,192,0
openstack%2Fnova-specs~master~I2029e1b0c152a91c711fea8f04bb293be8e6bbd7,openstack/nova-specs,master,I2029e1b0c152a91c711fea8f04bb293be8e6bbd7,Introduce support for a synchronous slave,ABANDONED,2014-05-13 15:16:08.000000000,2014-07-16 11:47:10.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2889}, {'_account_id': 4912}, {'_account_id': 6849}]","[{'number': 1, 'created': '2014-05-13 15:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2119731ec56d039e90d4c4bcccd4e961aa2ee131', 'message': ""Introduce support for a synchronous slave\n\nWe were able to introduce support for offloading reads to a slave\nconnection in Icehouse. However the slaving model was left up to\nthe deployer. Because we assumed that a deployer could use an async\nslave we weren't able to fully segregate reads. This spec aims\nto solve this problem.\n\nChange-Id: I2029e1b0c152a91c711fea8f04bb293be8e6bbd7\n""}, {'number': 2, 'created': '2014-05-14 18:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a670dd108d7c805befc6808a54c10e35872ead77', 'message': ""Introduce support for a synchronous slave\n\nWe were able to introduce support for offloading reads to a slave\nconnection in Icehouse. However the slaving model was left up to\nthe deployer. Because we assumed that a deployer could use an async\nslave we weren't able to fully segregate reads. This spec aims\nto solve this problem.\n\nChange-Id: I2029e1b0c152a91c711fea8f04bb293be8e6bbd7\n""}, {'number': 3, 'created': '2014-05-14 19:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9fd36d3b7fead75e8358278057240690afca24db', 'message': ""Introduce support for a synchronous slave\n\nWe were able to introduce support for offloading reads to a slave\nconnection in Icehouse. However the slaving model was left up to\nthe deployer. Because we assumed that a deployer could use an async\nslave we weren't able to fully segregate reads. This spec aims\nto solve this problem.\n\nChange-Id: I2029e1b0c152a91c711fea8f04bb293be8e6bbd7\n""}, {'number': 4, 'created': '2014-05-14 20:05:37.000000000', 'files': ['specs/juno/synchronous-read-support.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a7d4eea2ff39db7bccb46a428710a0002bf885eb', 'message': ""Introduce support for a synchronous slave\n\nWe were able to introduce support for offloading reads to a slave\nconnection in Icehouse. However the slaving model was left up to\nthe deployer. Because we assumed that a deployer could use an async\nslave we weren't able to fully segregate reads. This spec aims\nto solve this problem.\n\nChange-Id: I2029e1b0c152a91c711fea8f04bb293be8e6bbd7\n""}]",4,93466,a7d4eea2ff39db7bccb46a428710a0002bf885eb,26,8,4,4912,,,0,"Introduce support for a synchronous slave

We were able to introduce support for offloading reads to a slave
connection in Icehouse. However the slaving model was left up to
the deployer. Because we assumed that a deployer could use an async
slave we weren't able to fully segregate reads. This spec aims
to solve this problem.

Change-Id: I2029e1b0c152a91c711fea8f04bb293be8e6bbd7
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/66/93466/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/synchronous-read-support.rst'],1,2119731ec56d039e90d4c4bcccd4e961aa2ee131,juno/synchronous-read-support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Provide a capability to send synchronous reads to a different DB cluster ========================================== https://blueprints.launchpad.net/nova/+spec/synchronous-read-support We want to be able to scale the DB layer of Nova further and to do this we want to let deployers isolate their workloads to different classes of hardware. By seperating out writes, reads affected by causality and reads not affected by causality we can optimize for those workloads. Problem description =================== Support for offloading some reads to replication slaves was added in the Icehouse release. This was nice, but was unusable from the perspective of workflows that are sensitive to a non-causal replication slave. For example, if you call an API that writes to the DB then call a different API that should take into consideration the data that was just written, there is a chance that the asynchronous slaves hasn't written that out to it's version of the database. This has the potential to break the workflow. Proposed change =============== I want to add an additional db connection that is intended for a synchronous replication slave or slave cluster. If a deployer chooses to specify this connection in Nova's configuration all reads will go here unless explicitly sent to the asynchronous connection. Alternatives ------------ There is a sharding model in Nova, cells, which was designed specifically to deal with issues of scale. Because of it's bolt-on nature it is sometimes unattractive to deployers. It could be argued that we need to handle the DB scaling problem in Nova itself rather than scaling the DB as a seperate problem. It could be argued that time would be better spent working on cells or another form of handling application level sharding of the data problem. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Adding any synchronous db slaves will affect performance in the following ways: The Round Trip Time of any write is a function of the slowest node that is part of the relationship. The takeway is that you must make sure your hardware that hosts these is equal to the performance that you expect across the board. Other deployer impact --------------------- We will add a new configuration parameter: sync_slave_connection also will begin the deprecation process for slave_connection in favor of async_slave_connection If a deployment provides a valid sync_slave_connection all reads that are not explicitly sent to the async_slave_connection will be sent there. Deployments should understand the implications of adding a synchronous db slave into their infrastructure. It would also be important to tune all three sql connections for their particular workload so that the benefits may be fully enjoyed. Also, it should be noted that a synchronous cluster is going to multiply your number of required writes for each transaction. Specifically take writes and times that by the number of synchronous nodes in the cluster. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <geekinutah> Other contributors: <launchpad-id or None> Work Items ---------- -Add another connection to the db session code -Add logic to determine if a query is a write or a read and conditionally send a read down to the synchronous session. -Start the process of deprecating the slave_conection configuration option in favor of async_slave_conection. Dependencies ============ None Testing ======= We will want to add an additional database instance into some testing environments to make sure interactions are smooth. Documentation Impact ==================== We will need to upgrade the operations guide to reflect the ability to send reads to a seperate database cluster. References ========== None ",,158,0
openstack%2Fnova-specs~master~Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2,openstack/nova-specs,master,Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2,Propose: Adding generic image transfer layer to nova.virt,ABANDONED,2014-04-10 13:03:13.000000000,2014-07-16 11:41:52.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5638}, {'_account_id': 6549}, {'_account_id': 6873}, {'_account_id': 8759}]","[{'number': 1, 'created': '2014-04-10 13:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5ae3442318d0e03634ece824fa7444f1e37958f6', 'message': 'Propose: Adding image multiple location support\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparent dispatch image consuming request to relevant\nhandler plug-ins which working for different storage backend with\nappropriate approach.\n\nRelated to blueprint image-multiple-location\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2014-04-10 13:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5c9ec941da45965d532ed749bdc25284c52bfa65', 'message': 'Propose: Adding image multiple location support\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparent dispatch image consuming request to relevant\nhandler plug-ins which working for different storage backend with\nappropriate approach.\n\nRelated to blueprint image-multiple-location\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 3, 'created': '2014-04-11 15:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/29d2af3e812c64c2223ea063a884bb4a8550451d', 'message': 'Propose: Adding image multiple location support\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparent dispatch image consuming request to relevant\nhandler plug-ins which working for different storage backend with\nappropriate approach.\n\nRelated to blueprint image-multiple-location\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 4, 'created': '2014-04-14 13:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/21b5a80be1b3e5b769a812438a10cfbbd6b1d854', 'message': 'Propose: Adding image multiple location support\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparent dispatch image consuming request to relevant\nhandler plug-ins which working for different storage backend with\nappropriate approach.\n\nRelated to blueprint image-multiple-location\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 5, 'created': '2014-04-14 13:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d59718522cdcb4534989ed89ca572ba29ee9770e', 'message': 'Propose: Adding image multiple location support\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparent dispatch image consuming request to relevant\nhandler plug-ins which working for different storage backend with\nappropriate approach.\n\nRelated to blueprint image-multiple-location\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 6, 'created': '2014-04-14 13:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9d098935d464d8701010db5d1393bc8898487bf9', 'message': 'Propose: Adding image multiple location support\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparently dispatch image consuming request, e.g. download,\nupload, to relevant handler plug-ins which working for different storage\nbackend with appropriate approach.\n\nRelated to blueprint image-multiple-location\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 7, 'created': '2014-04-14 13:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/01e84ee7ec305a346635a5008f2ed5159ed7377a', 'message': 'Propose: Adding image multiple location support\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparently dispatch image consuming request, e.g. download,\nupload, to relevant handler plug-ins which working for different storage\nbackend with appropriate approach.\n\nRelated to blueprint image-multiple-location\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 8, 'created': '2014-04-29 04:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b1bda15a03fd6c3c5c1d9a0a1540e684a848dc53', 'message': 'Propose: Adding image multiple location support\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparently dispatch image consuming request, e.g. download,\nupload, to relevant handler plug-ins which working for different storage\nbackend with appropriate approach.\n\nRelated to blueprint image-multiple-location\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 9, 'created': '2014-05-05 08:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ad2ccf9db495d975559f7d99cbe768d15d137fae', 'message': 'Propose: Adding generic image transfer layer to nova.virt\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparently dispatch image consuming request, e.g. download,\nupload, to relevant handler plug-ins which working for different storage\nbackend with appropriate approach.\n\nRelated to blueprint virt-image-transfer-layer\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 10, 'created': '2014-05-10 02:41:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7a4cd98d571778166498486d6bbd6db30c0c5345', 'message': 'Propose: Adding generic image transfer layer to nova.virt\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparently dispatch image consuming request, e.g. download,\nupload, to relevant handler plug-ins which working for different storage\nbackend with appropriate approach.\n\nRelated to blueprint virt-image-transfer-layer\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 11, 'created': '2014-06-25 11:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/68405de212a711eb7c129b4c3fd4ecdd42589192', 'message': 'Propose: Adding generic image transfer layer to nova.virt\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparently dispatch image consuming request, e.g. download,\nupload, to relevant handler plug-ins which working for different storage\nbackend with appropriate approach.\n\nRelated to blueprint virt-image-transfer-layer\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 12, 'created': '2014-06-26 07:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/29e9aa5e8b4c9eb286d8d83bb858633feff02809', 'message': 'Propose: Adding generic image transfer layer to nova.virt\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparently dispatch image consuming request, e.g. download,\nupload, to relevant handler plug-ins which working for different storage\nbackend with appropriate approach.\n\nRelated to blueprint virt-image-transfer-layer\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 13, 'created': '2014-07-04 09:26:53.000000000', 'files': ['specs/juno/virt-image-transfer-layer.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/02cc3548f8c91c77ad0e4c18ca624bbe94c4921b', 'message': 'Propose: Adding generic image transfer layer to nova.virt\n\nTake advantage of the Glance image multiple location feature, adding a\nlayer to transparently dispatch image consuming request, e.g. download,\nupload, to relevant handler plug-ins which working for different storage\nbackend with appropriate approach.\n\nRelated to blueprint virt-image-transfer-layer\n\nChange-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}]",73,86583,02cc3548f8c91c77ad0e4c18ca624bbe94c4921b,81,10,13,6549,,,0,"Propose: Adding generic image transfer layer to nova.virt

Take advantage of the Glance image multiple location feature, adding a
layer to transparently dispatch image consuming request, e.g. download,
upload, to relevant handler plug-ins which working for different storage
backend with appropriate approach.

Related to blueprint virt-image-transfer-layer

Change-Id: Ifd1c0b6c31325ec7e1b838d8010fc0f2454988a2
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/83/86583/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/image-multiple-location.rst'],1,5ae3442318d0e03634ece824fa7444f1e37958f6,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Adding image multiple location support ========================================== https://blueprints.launchpad.net/nova/+spec/image-multiple-location Take advantage of the Glance image multiple location feature, adding a layer to transparent dispatch image consuming request to relevant handler plug-ins which working for different storage backend with appropriate approach. Problem description =================== Currently Nova driver is always consuming image from single backend storage which Glance API internal selected or exposed by direct-url mechanism. This approach is imperfect: 1. If one image backend storage failure, Nova doesn't know to consume image from another locations. 2. Nova is consuming Glance APIs to fetch and push images while spawning and snapshotting virtual machines, it requires Nova to invoke the upload and download Glance operations which means that the bits will go through the network with HTTP request. But for different image backend storage, it will be great if Nova be able to evaluate the backend model where images location is communicated and using storage particular technology to handle images, this would significantly reduce the data transfer (up-bound and down-bound) overhead and increase Glance efficiency. 3. Nova doesn't allow to appoint image backend storage selection order. For example deployer might like try to consuming image from Ceph first then to VMware storage for particular rack, compute nodes, availability zone. Proposed change =============== Adding a generic image handler framework, it lives in the virt folder and can be consumed by every driver. The framework triggers a handler based on the location of a Glance image or not for generic handlers that do not require a location to be triggered. Each driver implements its own flavour of the interface (fetch, push, move, delete) with optimized storage accessing technology particularly which required by image handler framework. Each hypervisor driver can have several image handlers (see References). Fundamental implementation steps: 1. To change Glance image service/api to expose get_locations() as a public interface. 2. Adding nova.virt.images.ImageHandle base class to the Nova common image layer which has fetch, push, move and delete interfaces. 3. Implementing nova.virt.images.DefaultImageHandler class which inherits above base class. It uses download and upload approach (HTTP GET and POST) to fetch and push image bits as Nova current default handling behaviour. 4. To implement load_image_handlers() entry function, it will be called when particular hypervisor driver initialization and loads deployer configured image handlers plug-ins. 5. Implementing nova.virt.images.handle_image() function, evaluate the schema where images location is communicated and using applicable handler to handle that image. 6. To change nova.virt.images.fetch_to_raw() function to leverage image handler framework. 7. Changing like nova.virt.libvirt.ImageCacheManager to leverage image handler framework as well. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- The change of this blueprint will have no any impact, it doesn't need any input from end user, but the follow up image handler probably will do some. (see References) Performance Impact ------------------ There's no any impact but the performance optimization is the main value of follow up blueprints which based on this image handler framework. (see References) Other deployer impact --------------------- Deployer has no any impact, but follow steps will be needed for follow up handler: - Enabling image handlers by Nova settings as deployer needed order. This change will add a download handler which is the default one for Nova, and it can be used as a fall-back for follow up handler (see References). [DEFAULT] image_handlers=download - Glance should be configured to have 'how_multiple_locations' and/or 'show_image_direct_url' set to True. [DEFAULT] show_multiple_locations = True show_image_direct_url = True Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: Zhi Yan Liu (lzy-dev) Work Items ---------- The implementation is not complicated so one patch is enough (see References). Dependencies ============ - This blueprint requires use-glance-v2-api changes to be merged. blueprint: https://blueprints.launchpad.net/nova/+spec/use-glance-v2-api reviews: https://review.openstack.org/#/c/74844/ https://review.openstack.org/#/c/75434/ https://review.openstack.org/#/c/80747/ https://review.openstack.org/#/c/82558/ - This blueprint needs standardize-nova-image changes to be merged blueprint: https://blueprints.launchpad.net/nova/+spec/standardize-nova-image Testing ======= None Documentation Impact ==================== The new configuration variable 'image_handlers' in the 'DEFAULT' section needs to be documented. References ========== - The idea for Ceph storage: https://blueprints.launchpad.net/nova/+spec/rbd-clone-image-handler - The idea for VMware storage: https://blueprints.launchpad.net/nova/+spec/vmware-clone-image-handler - The change of this blueprint is reverted due to problems with glance v2 API: https://review.openstack.org/33409 ",,187,0
openstack%2Fnova-specs~master~I1812022c748b1232c3ca763c4e3611fd0af738ea,openstack/nova-specs,master,I1812022c748b1232c3ca763c4e3611fd0af738ea,proposed blueprint for pci extra info provisioning,ABANDONED,2014-04-15 09:04:58.000000000,2014-07-16 11:39:07.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 4458}, {'_account_id': 6685}, {'_account_id': 6772}, {'_account_id': 7543}]","[{'number': 1, 'created': '2014-04-15 09:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a07eecc69d2b819d0be6cd82c65d5fbd3ce4a814', 'message': 'proposed blueprint for PCI extra information support\n\nfacility to provisioning PCI device information, and provide a interface to\nother module which depend on PCI passthrough.\n\nblueprint pci-extra-info\n\nChange-Id: I1812022c748b1232c3ca763c4e3611fd0af738ea\n'}, {'number': 2, 'created': '2014-04-15 09:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9761d259858b98fb4111002bcaf534138bf2ac46', 'message': 'proposed blueprint for PCI extra information support\n\nfacility to provisioning PCI device information, and provide a interface to\nother module which depend on PCI passthrough.\n\nblueprint pci-extra-info\n\nChange-Id: I1812022c748b1232c3ca763c4e3611fd0af738ea\n'}, {'number': 3, 'created': '2014-04-16 09:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/03d0c07431cb02904d7d4a15ab7015493b5ac109', 'message': 'proposed blueprint for PCI extra information support\n\nfacility to provisioning PCI device information, and provide a interface to\nother module which depend on PCI passthrough.\n\nblueprint pci-extra-info\n\nChange-Id: I1812022c748b1232c3ca763c4e3611fd0af738ea\n'}, {'number': 4, 'created': '2014-04-23 08:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ebcdebfde667a17a382e124d9f62b256aac73978', 'message': 'proposed blueprint for PCI extra information support\n\nfacility to provisioning PCI device information, and provide a interface to\nother module which depend on PCI passthrough.\n\nblueprint pci-extra-info\n\nChange-Id: I1812022c748b1232c3ca763c4e3611fd0af738ea\n'}, {'number': 5, 'created': '2014-05-06 07:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6780486cea1a31a09a5b122cbddf3f7f0ab3da3a', 'message': 'proposed blueprint for PCI extra information support\n\nfacility to provisioning PCI device information, and provide a interface to\nother module which depend on PCI passthrough.\n\nblueprint pci-extra-info-provisioning\n\nChange-Id: I1812022c748b1232c3ca763c4e3611fd0af738ea\n'}, {'number': 6, 'created': '2014-05-06 09:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/39cfb56b356cecc32d7f878b6f89bda72d607594', 'message': 'proposed blueprint for PCI extra infomation provisioning\n\nfacility which provisioning PCI device extra information to\nNova besides the vendor_id/product_id.\n\nblueprint pci-extra-info-provisioning\n\nChange-Id: I1812022c748b1232c3ca763c4e3611fd0af738ea\n'}, {'number': 7, 'created': '2014-05-06 09:06:44.000000000', 'files': ['specs/juno/pci-extra-info.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/194007694f0ab2e5433a3d1257505bce52b7c325', 'message': 'proposed blueprint for pci extra info provisioning\n\nfacility which provisioning PCI device extra information to\nNova besides the vendor_id/product_id.\n\nblueprint pci-extra-info-provisioning\n\nChange-Id: I1812022c748b1232c3ca763c4e3611fd0af738ea\n'}]",48,87500,194007694f0ab2e5433a3d1257505bce52b7c325,45,8,7,7543,,,0,"proposed blueprint for pci extra info provisioning

facility which provisioning PCI device extra information to
Nova besides the vendor_id/product_id.

blueprint pci-extra-info-provisioning

Change-Id: I1812022c748b1232c3ca763c4e3611fd0af738ea
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/00/87500/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/pci-extra-info.rst'],1,a07eecc69d2b819d0be6cd82c65d5fbd3ce4a814,pci-extra-info-provisioning,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================================== PCI passthrough Extra information of PCI device =============================================== https://blueprints.launchpad.net/nova/+spec/pci-extra-info for deploying and use Nova PCI passthrough, there is need a facility to provisioning PCI device information to Nova, and provide a interface to other module which depend on PCI passthrough. Problem description =================== in current PCI passthrough there is lack of a method to provisioning the PCI device related information to cloud and use it to select correct PCI device to use: * for SRIOV support, there is need a physical network name attach to PCI device. * for PCI acceleration/encryption/decryption card, there is need to attach PCI devices's capability to the pci device, i.e, is it support md5, DES, 3DES, AES, RSA, SHA-x, IDEA, RC4,5,6...? other module like SRIOV need to access PCI passthrough facility, allocating pci devices, access pci devices allocted for SRIOV. Proposed change =============== 1. pci information(extended the white-list) to support extra information tag Add a new configuration item on compute node which provide pci device's additional information as needed. 2. pci utils support extra property pci/utils module support a simple match expression, then the white list could flexible select devices and provide extra information for pci device. 3. pci stats support extra property pci stats should report pci device pools based on both pci property and extra information. 4. pci alias/whitlist enhancement alias could be extend to support extra information. 5. provide interface to module based on PCI passthrough for module need to allocation PCI device, this module should fill a PCI request structure at API stage, and save the request to instance system meta data. ``create_pci_request(system_metadata, request_spec, flavor_name,count=1, prefix=''):`` request_spec: for example: ``{""vendor_id"":""8086"", ""phy_network"":""phyvlan1""}`` flavor_name: a unique name, typical it's alias name count: how many pci devices needed. return: the UUID of created pci reqeust. for module need to access the pci device allocted to a specific pci reqeust, the module should save the UUID of it's own request ID, and fech the pci device use this UUID after allocation finished. ``def get_instance_pci_devs_by_spec(inst, specs):`` inst: which inst the pci device belong ot specs: pci specs the pci device should be match, for example ``{'request_id': 'the id saved befor'}`` Alternatives ------------ What other ways could we do this thing? Why aren't we using those? This doesn't have to be a full literature review, but it should demonstrate that thought has been put into why the proposed solution is an appropriate one. Data model impact ----------------- None REST API impact --------------- Each API method which is either added or changed should have the following * Specification for the method * A description of what the method does suitable for use in user documentation * Method type (POST/PUT/GET/DELETE) * Normal http response code(s) * Expected error http response code(s) * A description for each possible error code should be included describing semantic errors which can cause it such as inconsistent parameters supplied to the method, or when an instance is not in an appropriate state for the request to succeed. Errors caused by syntactic problems covered by the JSON schema defintion do not need to be included. * URL for the resource * Parameters which can be passed via the url * JSON schema definition for the body data if allowed * JSON schema definition for the response data if any * Example use case including typical API samples for both data supplied by the caller and the response * Discuss any policy changes, and discuss what things a deployer needs to think about when defining their policy. Example JSON schema definitions can be found in the Nova tree http://git.openstack.org/cgit/openstack/nova/tree/nova/api/openstack/compute/schemas/v3 Note that the schema should be defined as restrictively as possible. Parameters which are required should be marked as such and only under exceptional circumstances should additional parameters which are not defined in the schema be permitted (eg additionaProperties should be False). Reuse of existing predefined parameter types such as regexps for passwords and user defined names is highly encouraged. Security impact --------------- TODO * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. Notifications impact -------------------- Please specify any changes to notifications. Be that an extra notification, changes to an existing notification, or removing a notification. Other end user impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-novaclient? What does the user interface there look like? Performance Impact ------------------ None Other deployer impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * If this change is a new binary, how would it be deployed? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: yongli.he@intel.com Other contributors: None Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in nova, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Nova (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Testing ======= the pci passthrough now need run OS on bearmetal compute node, not a VM based test environment, there is needed to providing 3rd test platform for PCI passthrough testing. Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== SRIOV meeting: https://wiki.openstack.org/wiki/Meetings/Passthrough SRIOV use case: https://docs.google.com/document/d/1zgMaXqrCnad01-jQH7Mkmf6amlghw9RMScGLBrKslmw/edit# SRIOV support bp(which depend on this bp): https://blueprints.launchpad.net/nova/+spec/pci-passthrough-sriov ",,259,0
openstack%2Fnova-specs~master~Ie4b83bbdca3617b8d3910803e422895f90acc69e,openstack/nova-specs,master,Ie4b83bbdca3617b8d3910803e422895f90acc69e,Propose: Implement percentage-based RAM Weigher,ABANDONED,2014-07-08 10:12:54.000000000,2014-07-16 11:38:53.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 91}, {'_account_id': 782}]","[{'number': 1, 'created': '2014-07-08 10:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7b363b1d104d5305b01c1039d6cea750eb866ebe', 'message': 'Propose: Implement percentage-based RAM Weigher\n\nContinuation of the bp normalize-scheduler-weights. This blueprint is\ntargeted on the adaptation of the RAMWeigher to be able to use\npercentages (i.e. relative values) for scheduling.\n\nChange-Id: Ie4b83bbdca3617b8d3910803e422895f90acc69e\nImplements: blueprint ram-as-percentage\n'}, {'number': 2, 'created': '2014-07-10 07:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9a0f528fe83710e20a9e4e9142ca8c4ede90f09b', 'message': 'Propose: Implement percentage-based RAM Weigher\n\nContinuation of the bp normalize-scheduler-weights. This blueprint is\ntargeted on the adaptation of the RAMWeigher to be able to use\npercentages (i.e. relative values) for scheduling.\n\nChange-Id: Ie4b83bbdca3617b8d3910803e422895f90acc69e\nImplements: blueprint ram-as-percentage\n'}, {'number': 3, 'created': '2014-07-10 08:22:34.000000000', 'files': ['specs/juno/ram-as-percentage.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5efc2362b35388b1af2acf0827b5cb740df35b5f', 'message': 'Propose: Implement percentage-based RAM Weigher\n\nContinuation of the bp normalize-scheduler-weights. This blueprint is\ntargeted on the adaptation of the RAMWeigher to be able to use\npercentages (i.e. relative values) for scheduling.\n\nChange-Id: Ie4b83bbdca3617b8d3910803e422895f90acc69e\nImplements: blueprint ram-as-percentage\n'}]",6,105410,5efc2362b35388b1af2acf0827b5cb740df35b5f,14,4,3,91,,,0,"Propose: Implement percentage-based RAM Weigher

Continuation of the bp normalize-scheduler-weights. This blueprint is
targeted on the adaptation of the RAMWeigher to be able to use
percentages (i.e. relative values) for scheduling.

Change-Id: Ie4b83bbdca3617b8d3910803e422895f90acc69e
Implements: blueprint ram-as-percentage
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/10/105410/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/ram-as-percentage.rst'],1,7b363b1d104d5305b01c1039d6cea750eb866ebe,bp/normalize-scheduler-weights,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================== Implement percentage-based RAM Weigher ======================================== https://blueprints.launchpad.net/nova/+spec/ram-as-percentage This blueprint is just a continuation of a blueprint already approved for Havana that missed feature freeze: https://blueprints.launchpad.net/nova/+spec/normalize-scheduler-weights Nova's scheduler used the raw values returned by each of the weighers to compute the final weight of a compute host or cell. This made difficult for operators to setup and use multipliers to stablish the relative importance between weighers since they weren't able to know the maximim weight for an object in advance, as it was a variable value. Moreover, in order to make a weigher prevail among others in some cases it was needed to artificially inflate either the weigher's returned value or the weigher's multiplier. The blueprint that was already implemented introduced weight normalization. This mechanism maps all the values returned from a weigher between 0 and 1, thus they have an even relative influence in the final weight for a host. Therefore, an operator knows a-priori that a host with a weight of 1 is the winner of that weighing process, and a host with 0 is the loser, making easier to setup multipliers in order to stablish the relative importance between weighers. Problem description =================== With weight normalization in place the RAM weigher can be improved, so that it support relative values instead of the absolute ones. Proposed change =============== The 'nova.scheduler.weights.ram.RAMWeigher' will be adapted to use relative values (i.e. percentage based). A new flag will be introduced to select this behaviour, thus it will remain compatible with its current status (i.e. use absolute values). Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- A new configuration option will be included for the 'RAMWeigher': 'ram_weight_percentage=False' so as to use the percentage of free RAM available instead of the usage of the absolute values. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: aloga Other contributors: None Work Items ---------- - Modify RamWeigher so that percentages can be used instead of absolute values (new flag 'ram_weight_percentage'). - Update both the developer documentation and the Cloud Admin Guide. Dependencies ============ This blueprint is a continuation of the following (already implemented): https://blueprints.launchpad.net/nova/+spec/normalize-scheduler-weights Testing ======= There is no need for new tempest tests. Documentation Impact ==================== A new configuration option 'ram_weight_percentage' will be introduced, so that the RAM weighing will take into account the percentage of free ram instead of the absolute values. These configuration changes will be noted in the Release Notes and the Cloud Admin Guide will be updated along with this blueprint. References ========== None. ",,138,0
openstack%2Fnova-specs~master~Id7ff0e0c2a2d83178f448e12c399d01a5e9b2716,openstack/nova-specs,master,Id7ff0e0c2a2d83178f448e12c399d01a5e9b2716,Propose associate least recently used fixed IP address,ABANDONED,2014-06-26 01:13:12.000000000,2014-07-16 11:38:51.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-06-26 01:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b560aa4c2ed3cbf96192fe22352a4320f1f9f7ee', 'message': 'Propose associate least recently used fixed IP address\n\nThis blueprint would associate the least recently used fixed IP address\ninstead of the first available one.\n\nRelated to blueprint associate-lru-fixed-ip-address\n\nChange-Id: Id7ff0e0c2a2d83178f448e12c399d01a5e9b2716\n'}, {'number': 2, 'created': '2014-06-26 01:19:06.000000000', 'files': ['specs/juno/associate-lru-fixed-ip-address.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2055d0702b09df6070cd7d8f94af071d9120e8e6', 'message': 'Propose associate least recently used fixed IP address\n\nThis blueprint would associate the least recently used fixed IP address\ninstead of the first available one.\n\nRelated to blueprint associate-lru-fixed-ip-address\n\nChange-Id: Id7ff0e0c2a2d83178f448e12c399d01a5e9b2716\n'}]",0,102688,2055d0702b09df6070cd7d8f94af071d9120e8e6,12,3,2,4690,,,0,"Propose associate least recently used fixed IP address

This blueprint would associate the least recently used fixed IP address
instead of the first available one.

Related to blueprint associate-lru-fixed-ip-address

Change-Id: Id7ff0e0c2a2d83178f448e12c399d01a5e9b2716
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/88/102688/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/associate-lru-fixed-ip-address.rst'],1,b560aa4c2ed3cbf96192fe22352a4320f1f9f7ee,bp/associate-lru-fixed-ip-address,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================== Associate least recently used fixed IP address ============================================== https://blueprints.launchpad.net/nova/+spec/associate-lru-fixed-ip-address In this blueprint, we propose to enhance the fixed IP associate DB API functions by having them return the least recently used IP address instead of the lowest address, which is likely the most recently used address. Problem description =================== End users creating servers have an optimal experience when they can get their applications serving in the cloud as immediately as possible. This includes networking infrastructure having routes already populated and services such as DNS resolving as expected, right away. Problems can arise if an end user receives a fixed IP address that was very recently released by a different user, which is likely in a busy and dynamic cloud environment that assigns IP addresses on a first-available basis. The IP address associated with the new user's server may have had reverse DNS set to point elsewhere or the old user may have had a custom hostname configured, requiring DNS to be updated before the new server can serve traffic. The problem can be made less likely if IP addresses were to be associated on a least recently used basis, instead. Proposed change =============== We propose a change to the fixed_ip_associate, fixed_ip_associate_pool, and floating_ip_fixed_ip_associate functions to add a call e.g.: fixed_ip_ref = model_query(context, models.FixedIp, session=session, read_deleted=""no"").\ filter(network_or_none).\ filter_by(reserved=False).\ filter_by(instance_uuid=None).\ filter_by(host=None).\ + order_by('updated_at').\ with_lockmode('update').\ first() order_by('updated_at') to pick the least recently used fixed IP address and return it, instead of the first available, in nova/db/sqlalchemy/api.py Alternatives ------------ Another approach would be a configurable policy for associating fixed IP addresses with policies like 'least recently used' and 'first available.' This would be a more significant change and involves adding yet another configuration flag. It is hoped that the least recently used policy is an overall improvement for users creating servers. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Calls of the fixed_ip_associate, fixed_ip_associate_pool, and floating_ip_fixed_ip_associate functions will be more costly as the filtered rows will be ordered by 'updated_at' before returning the first item. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: melwitt Other contributors: None Work Items ---------- * Add an order_by('updated_at') call to the query of the FixedIp model, right before the with_lockmode('update') call, in the fixed_ip_associate, fixed_ip_associate_pool, and floating_ip_fixed_ip_associate functions in nova/db/sqlalchemy/api.py Dependencies ============ None Testing ======= This change can be tested by adding unit tests to nova/tests/db/test_db_api.py which verify that the fixed_ip_associate, fixed_ip_associate_pool, and floating_ip_fixed_ip_associate functions return the least recently used/updated IP address in the fake DB. Documentation Impact ==================== None References ========== None ",,145,0
openstack%2Fdiskimage-builder~master~Idc37f037e6416e3cf00f054f8d40926cac0818be,openstack/diskimage-builder,master,Idc37f037e6416e3cf00f054f8d40926cac0818be,Don't try to install if packages is empty,ABANDONED,2014-07-15 20:46:34.000000000,2014-07-16 11:37:29.000000000,,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-07-15 20:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/90dcf2663fd28eff4048d40023573161955b869d', 'message': ""Don't try to install if packages is empty\n\nAfter running through pkg-map we could have no packages to install,\nif so, don't attempt to run a malformed command.\n\nChange-Id: Idc37f037e6416e3cf00f054f8d40926cac0818be\n""}, {'number': 2, 'created': '2014-07-16 11:36:04.000000000', 'files': ['elements/yum/bin/install-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ea2a9ad24ce20589381f07bd0c3b58d0bbe80eff', 'message': ""Don't try to install if packages is empty\n\nAfter running through pkg-map we could have no packages to install,\nif so, don't attempt to run a malformed command.\n\nChange-Id: Idc37f037e6416e3cf00f054f8d40926cac0818be\n""}]",1,107171,ea2a9ad24ce20589381f07bd0c3b58d0bbe80eff,10,3,2,8532,,,0,"Don't try to install if packages is empty

After running through pkg-map we could have no packages to install,
if so, don't attempt to run a malformed command.

Change-Id: Idc37f037e6416e3cf00f054f8d40926cac0818be
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/71/107171/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/yum/bin/install-packages'],1,90dcf2663fd28eff4048d40023573161955b869d,yum-install-packages-blank," if [ -z ""${PKGS}"" ]; then echo 'No packages need to be installed' else yum -y $ACTION $EXTRA_ARGS $PKGS fi ", yum -y $ACTION $EXTRA_ARGS $PKGS,6,1
openstack%2Fnova-specs~master~I9c30f2cc15357301f033a2d10c2f9da464e8247b,openstack/nova-specs,master,I9c30f2cc15357301f033a2d10c2f9da464e8247b,support multiple image backends for libvirt driver,ABANDONED,2014-05-03 12:49:47.000000000,2014-07-16 11:35:37.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 6062}, {'_account_id': 10069}]","[{'number': 1, 'created': '2014-05-03 12:49:47.000000000', 'files': ['specs/juno/libvirt-multiple-image-backends.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9636ea87c7a39e50bca237b9c26c1f476c9a7744', 'message': 'support multiple image backends for libvirt driver\n\nCurrently, the cloud administrator can not choose ephemeral storage backend\ndevice (e.g. SSD or non-SSD) and driver (e.g. qcow2 or ceph) for per flavor.\nThe lack of these features restrict the price strategy for different\nperformance and functional requirements. So we should add support to\nconfigure multiple libvirt image backends, and then in the flavor\nindicate which backend should be used for per instance.\n\nRelated to blueprint libvirt-multiple-image-backends\n\nChange-Id: I9c30f2cc15357301f033a2d10c2f9da464e8247b\n'}]",21,91957,9636ea87c7a39e50bca237b9c26c1f476c9a7744,20,6,1,10069,,,0,"support multiple image backends for libvirt driver

Currently, the cloud administrator can not choose ephemeral storage backend
device (e.g. SSD or non-SSD) and driver (e.g. qcow2 or ceph) for per flavor.
The lack of these features restrict the price strategy for different
performance and functional requirements. So we should add support to
configure multiple libvirt image backends, and then in the flavor
indicate which backend should be used for per instance.

Related to blueprint libvirt-multiple-image-backends

Change-Id: I9c30f2cc15357301f033a2d10c2f9da464e8247b
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/57/91957/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/libvirt-multiple-image-backends.rst'],1,9636ea87c7a39e50bca237b9c26c1f476c9a7744,bp/libvirt-multiple-image-backends,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================================================== support multiple image backends for libvirt driver =============================================================== https://blueprints.launchpad.net/nova/+spec/libvirt-multiple-image-backends Currently, the cloud administrator can not choose ephemeral storage backend device (e.g. SSD or non-SSD) and driver (e.g. qcow2 or ceph) for per flavor. The lack of these features restrict the price strategy for different performance and functional requirements. So we should add support to configure multiple libvirt image backends, and then in the flavor indicate which backend should be used for per instance. Problem description =================== 1. The administrator have no ability to create flavor with ephemeral storage assigned on SSD as some Amazon EC2 instance types (e.g. m3.large). 2. The administrator have no ability to choose among different libvirt image types for instance disks. To strive for high performance, local disk (e.g. raw/qcow2) may be better. To strive for live migration or single storage backend for glance, nova and cinder, choosing ceph is more reasonable. 3. The administrator have no ability about more fine grained configuration for ephemeral storage backend, i.e. separately set which backend to be used for root disk, ephemeral disk and swap disk. For example, there is the case where the administrator wants some flavours with root disk and swap disk on SSD, and other flavors with only swap disk on SSD. Proposed change =============== 1. The <libvirt_image_type> in nova.conf would need to allow a list of image backend names + types, and we use existing config parameters: raw/qcow2-<instances_path>, lvm-<libvirt_images_volume_group>, rbd-<libvirt_images_rbd_pool>. these parameters need to be extended to allow a list of values, instead of a single value. For example, if we want to do a choice of local qcow2 and two rbd pools, one of which is fast ssd backend, we should configure: libvirt_image_type=default:qcow2, fast:qcow2, shared:rbd, sharedfast:rbd instance_path=default:/var/nova/images/hdd, fast:/var/nova/imges/ssd libvirt_images_rbd_pool=shared:main,sharedfast:mainssd The names 'default', 'fast', 'shared', 'sharedfast' are set by deployer freely, and would be used to tag ephemeral storage backend in the flavour. 2. In periodic task about update_available_resource, resource tracker retrieve the detail info of each ephemeral storage back-ends. These info include backend name, free size, used size and total size. 3. Modify the disk_filter, and then based on ephemeral storage backend type and available size, nova-scheduler choose compute node reasonably. 4. Modify the imagebackend, and then based on ephemeral storage backend type, create_image for root disk, ephemeral disk and swap disk, which involves four image type: raw, qcow2, lvm and rbd. Alternatives ------------ none Data model impact ----------------- Add a table compute_node_storage_resource, its fields contain: compute_node_id, backend_name, total_size, free_size, used_size disk_available_least. REST API impact --------------- none Security impact --------------- none Notifications impact -------------------- none Other end user impact --------------------- None Performance Impact ------------------ Modify a scheduler filter (i.e. disk filter) and a periodic task (i.e. update_available_resource), but not add any new scheduler filters and periodic tasks. So there are little impact on nova. Other deployer impact --------------------- The <libvirt_image_type> in nova.conf allow a list of image backend names + types, and we use existing config parameters: raw/qcow2-<instances_path>, lvm-<libvirt_images_volume_group>, rbd-<libvirt_images_rbd_pool> but these parameters have been extended to allow a list of values, instead of a single value. For example, if we want to do a choice of local qcow2 and two rbd pools, one of which is fast ssd backend, we should configure: libvirt_image_type=default:qcow2, fast:qcow2, shared:rbd, sharedfast:rbd instance_path=default:/var/nova/images/hdd, fast:/var/nova/imges/ssd libvirt_images_rbd_pool=shared:main,sharedfast:mainssd The names 'default', 'fast', 'shared', 'sharedfast' are set by deployer freely, and would be used to tag ephemeral storage backend in the flavour. Developer impact ---------------- none Implementation ============== Assignee(s) ----------- Primary assignee: Zhou Yu <vitas.yuzhou@huawei.com> Work Items ---------- 1. In periodic task about update_available_resource, resource tracker retrieve the detail info of each ephemeral storage back-ends. These info include backend name, free size, used size and total size. 2. Modify the disk_filter, and then based on ephemeral storage backend type and available size, nova-scheduler choose compute node reasonably. 3. Modify the imagebackend, and then based on ephemeral storage backend type, create_image for root disk, ephemeral disk and swap disk, which involves four image type: raw, qcow2, lvm and rbd. Dependencies ============ none Testing ======= none Documentation Impact ==================== 1. In the installation and configuration guide, we need to add content about how to configure the parameters of libvirt multiple image backends. 2. In the admin guide, we need to add content about how to specify ephemeral storage backend in flavor. References ========== https://www.mail-archive.com/openstack-dev%40lists.openstack.org/msg22152.html",,181,0
openstack%2Fnova-specs~master~Ia2abf97d9d42ad37ac237d0457471e0533ff1945,openstack/nova-specs,master,Ia2abf97d9d42ad37ac237d0457471e0533ff1945,HyperV nova driver enhancement to create highly available instances,ABANDONED,2014-07-07 09:00:16.000000000,2014-07-16 11:35:02.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 3185}, {'_account_id': 7239}]","[{'number': 1, 'created': '2014-07-07 09:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8cc0373bc72b773209304b23b913f44774c1df41', 'message': ""HyperV nova driver enhancement to create highly available instances\n\nThis blueprint creating-hyperv-ha-instances allows creating of highly\navailable instances in a HyperV hosts that are in a failover cluster.\nHighly available virtual machines are defined by the the document\nhttp://technet.microsoft.com/en-us/library/cc967323.aspx as\n'Highly available virtual machines, also known as HAVMs, can easily be\nmigrated to a different virtual machine host in a failover cluster to provide\ncontinuing service when their current host needs maintenance. If their current\nhost fails, the HAVMs automatically migrate to a different host in the cluster\nthrough a process known as failover.'\n\nChange-Id: Ia2abf97d9d42ad37ac237d0457471e0533ff1945\nblueprint: creating-hyperv-ha-instances\n""}, {'number': 2, 'created': '2014-07-07 09:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/828f7ac5d3dc94ac6214eba3a9ed9cad5dcb3f23', 'message': ""HyperV nova driver enhancement to create highly available instances\n\nThis blueprint creating-hyperv-ha-instances allows creating of highly\navailable instances in a HyperV hosts that are in a failover cluster.\nHighly available virtual machines are defined by the the document\nhttp://technet.microsoft.com/en-us/library/cc967323.aspx as\n'Highly available virtual machines, also known as HAVMs, can easily be\nmigrated to a different virtual machine host in a failover cluster to provide\ncontinuing service when their current host needs maintenance. If their current\nhost fails, the HAVMs automatically migrate to a different host in the cluster\nthrough a process known as failover.'\n\nChange-Id: Ia2abf97d9d42ad37ac237d0457471e0533ff1945\nblueprint: creating-hyperv-ha-instances\n""}, {'number': 3, 'created': '2014-07-07 09:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e8fa3a783d4a9088d2486e7c56472adefc5ca6ae', 'message': ""HyperV nova driver enhancement to create highly available instances\n\nThis blueprint creating-hyperv-ha-instances allows creating of highly\navailable instances in a HyperV hosts that are in a failover cluster.\nHighly available virtual machines are defined by the the document\nhttp://technet.microsoft.com/en-us/library/cc967323.aspx as\n'Highly available virtual machines, also known as HAVMs, can easily be\nmigrated to a different virtual machine host in a failover cluster to provide\ncontinuing service when their current host needs maintenance. If their current\nhost fails, the HAVMs automatically migrate to a different host in the cluster\nthrough a process known as failover.'\n\nChange-Id: Ia2abf97d9d42ad37ac237d0457471e0533ff1945\nblueprint: creating-hyperv-ha-instances\n""}, {'number': 4, 'created': '2014-07-08 11:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/da261093d8d15ff339538a771b3a42735ef292e4', 'message': ""HyperV nova driver enhancement to create highly available instances\n\nThis blueprint creating-hyperv-ha-instances allows creating of highly\navailable instances in a HyperV hosts that are in a failover cluster.\nHighly available virtual machines are defined by the the document\nhttp://technet.microsoft.com/en-us/library/cc967323.aspx as\n'Highly available virtual machines, also known as HAVMs, can easily be\nmigrated to a different virtual machine host in a failover cluster to provide\ncontinuing service when their current host needs maintenance. If their current\nhost fails, the HAVMs automatically migrate to a different host in the cluster\nthrough a process known as failover.'\n\nChange-Id: Ia2abf97d9d42ad37ac237d0457471e0533ff1945\nblueprint: creating-hyperv-ha-instances\n""}, {'number': 5, 'created': '2014-07-08 12:15:36.000000000', 'files': ['specs/juno/creating-hyperv-ha-instances.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fa6c7555fc7b5c3754503e6f04eebc78e27965d7', 'message': ""HyperV nova driver enhancement to create highly available instances\n\nThis blueprint creating-hyperv-ha-instances allows creating of highly\navailable instances in a HyperV hosts that are in a failover cluster.\nHighly available virtual machines are defined by the the document\nhttp://technet.microsoft.com/en-us/library/cc967323.aspx as\n'Highly available virtual machines, also known as HAVMs, can easily be\nmigrated to a different virtual machine host in a failover cluster to provide\ncontinuing service when their current host needs maintenance. If their current\nhost fails, the HAVMs automatically migrate to a different host in the cluster\nthrough a process known as failover.'\n\nChange-Id: Ia2abf97d9d42ad37ac237d0457471e0533ff1945\nblueprint: creating-hyperv-ha-instances\n""}]",27,105094,fa6c7555fc7b5c3754503e6f04eebc78e27965d7,27,5,5,7239,,,0,"HyperV nova driver enhancement to create highly available instances

This blueprint creating-hyperv-ha-instances allows creating of highly
available instances in a HyperV hosts that are in a failover cluster.
Highly available virtual machines are defined by the the document
http://technet.microsoft.com/en-us/library/cc967323.aspx as
'Highly available virtual machines, also known as HAVMs, can easily be
migrated to a different virtual machine host in a failover cluster to provide
continuing service when their current host needs maintenance. If their current
host fails, the HAVMs automatically migrate to a different host in the cluster
through a process known as failover.'

Change-Id: Ia2abf97d9d42ad37ac237d0457471e0533ff1945
blueprint: creating-hyperv-ha-instances
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/94/105094/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/creating-hyperv-ha-instances.rst'],1,8cc0373bc72b773209304b23b913f44774c1df41,bp/creating-hyperv-ha-instances,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================================================== HyperV nova driver enhancement to create highly available instances =================================================================== https://blueprints.launchpad.net/nova/+spec/creating-hyperv-ha-instances This blueprint creating-hyperv-ha-instances allows creating of highly available instances in a HyperV hosts that are in a failover cluster. Highly available virtual machines are defined by the the document http://technet.microsoft.com/en-us/library/cc967323.aspx as 'Highly available virtual machines, also known as HAVMs, can easily be migrated to a different virtual machine host in a failover cluster to provide continuing service when their current host needs maintenance. If their current host fails, the HAVMs automatically migrate to a different host in the cluster through a process known as failover.' Problem description =================== Existing HyperV nova driver does not provide the benefits available on HyperV hosts configured in a failover cluster and therefore when a host in the cluster fails the instance is not available to the user. Proposed change =============== Add support to configure high availability for an instance in the HyperV nova driver. This is done by modifying the instance creation steps in the following way * 1. Create instances on shared storage * 2. Configure the instance as highly available Also, the image cache should also be created on the shared storage A new boolean config option failover_clustering will be added. When the option is set to true, the proposed changes take effect. Alternatives for implementation of the proposed change * 1. Using the config option approach the existing driver behaviour can be modified without adding a new driver deriving from the existing driver. However with this approach, the implementation will have conditional switch since WMI calls to get cluster data are done using a different namespace and classes. * 2. Create a new driver that derives from the existing driver. Only override the methods that require changes. It is proposed to using alternative 1 described above since the changes are limited to spawn method. Alternatives ------------ * 1. A single driver manages all the hosts in the cluster. The problem with this is the server hosting the nova-compute should always be available. To make this work the nova-compute service must be made a clustered service. * 2. The nova-compute runs in a VM that is hosted in a host in the cluster. This VM is configured as a highly available VM. The drawback of this approach is that the remote WMI are slow and therefore will impact the performance of the driver. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Instance deployments will have additional WMI calls done to detect the shared storage. However since the image cache is on the shared storage, the number of downloads from glance is reduced. Earlier each host has its own cache and therefore needed to download its own copy. Other deployer impact --------------------- None Developer impact ---------------- * This change only impacts the HyperV nova driver. Other drivers will not be impacted due to this change. Implementation ============== Assignee(s) ----------- Primary assignee: kiran-kumar-vaddi Other contributors: Work Items ---------- * Modify the code the selects the location to spawn an instance to select only shared storage (Cluster Shared Volumes) * Enable HA on the instance before starting the instance * The image cache must be on shared storage Dependencies ============ None Testing ======= The unit tests will be modified to test the branches introduced by the above work items Documentation Impact ==================== A new boolean config option failover_clustering will be added. When the option is set to true, the instances are configured as highly available instances. References ========== http://technet.microsoft.com/en-us/library/cc967323.aspx ",,151,0
openstack%2Fnova-specs~master~I3f574c194b1e4d6cb2eb7f99f84cdbc200f94c4b,openstack/nova-specs,master,I3f574c194b1e4d6cb2eb7f99f84cdbc200f94c4b,Initial step towards instance-level snapshots,ABANDONED,2014-06-19 19:20:36.000000000,2014-07-16 11:34:24.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 5441}, {'_account_id': 9060}, {'_account_id': 9236}]","[{'number': 1, 'created': '2014-06-19 19:20:36.000000000', 'files': ['specs/juno/instance-level-snapshots.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/cdc9899128792d0b9f37cf57ae4cc605b71fb17e', 'message': 'Initial step towards instance-level snapshots\n\nThis feature aims to implement an initial step towards achieving\nper-instance transaction snapshots of all attached volumes.\n\nChange-Id: I3f574c194b1e4d6cb2eb7f99f84cdbc200f94c4b\n'}]",4,101295,cdc9899128792d0b9f37cf57ae4cc605b71fb17e,14,7,1,9236,,,0,"Initial step towards instance-level snapshots

This feature aims to implement an initial step towards achieving
per-instance transaction snapshots of all attached volumes.

Change-Id: I3f574c194b1e4d6cb2eb7f99f84cdbc200f94c4b
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/95/101295/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/instance-level-snapshots.rst'],1,cdc9899128792d0b9f37cf57ae4cc605b71fb17e,instance-level-snapshots,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Instance-Level Snapshots ========================================== https://blueprints.launchpad.net/nova/+spec/instance-level-snapshots Moving towards the ability to take a transactional snapshot of all volumes attached to an instance. Problem description =================== This blueprint covers adding support for taking a transactional snapshot of all volumes attached to an instance. I/O on the guest is quiesced to achieve filesystem consistency for each snapshot in the set. This gives the user the ability to capture the entire disk state of an instance with a single operation. The result can be stored in Glance and used later as a starting point for instantiating a new instance or provide a known point for rolling back an existing instance. This will require recent changes in libvirt and the pending artifact implementation in Glance. As these changes will likely not be available in Juno, this blueprint covers the initial changes that can be made without needing these requirements. There are currently four ways in Nova to create a snapshot of one, some, or all of the volumes attached to a particular instance. But none of these options allow a user to create volume snapshots after I/O is quiesced as a single transaction. Existing Behaviour ------------------ These are four ways of creating a snapshot in Nova: 1. `create_image` - takes a snapshot of the root volume and may take snapshots of the attached volumes depending on the volume type of the root volume. I/O is not quiesced. 2. `create_backup` - takes a snapshot of the root volume with options to specify how often to repeat and how many previous snapshots to keep around. I/O is not quiesced. 3. `volume_snapshot_create` - takes a snapshot of a single cinder volume. I/O is not quiesced. 4. `os-assisted-snapshot` - takes a snapshot of a single cinder volume. The volume is first quiesced before the snapshot is initiated. Proposed change =============== Although libvirt has recently acquired the ability to quiese an instance as a first-class operation, this version must be present in the gate in order to make use this feature in Nova. Additionally, the artifact implementation for Glance is still under development. So here I propose that we make as much progress towards the end goal as possible without relying on these dependencies for Juno. As a first step, I propose to modify `create_image` to behave consistently regardless of the type of root volume. In its current state, this call will create volume snapshots only if the root volume is persistent. I would like this behaviour to be applied to ephemeral root volumes as well. So the result would be a snapshot of the root volume (either in glance or cinder) and volume snapshots of all attached cinder volumes. Alternatives ------------ In general, I think the `create_image` API call is perhaps being misused in this context. Instead, we could remove the volume-iteration logic so that `create_image` becomes simply a function that creates a glance image from an instance's root volume. The extended capability of a transactional snapshot of all volumes could be implemented in a new API call. Data model impact ----------------- None REST API impact --------------- For this initial piece, no changes required. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- Working with the resulting snapshots is not the most intuitive thing, and given the snapshot naming scheme, working with numerous snapshots of a single instance can be difficult to manage. However, the proposed change here does not worsen that experience. And hopefully in next iteratations this can be improved. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: jbernard Work Items ---------- The proposed change should be nicely contained in the api layer and only requires modifying the snapshot logic to not discriminate based on root volume type. Dependencies ============ None Testing ======= Similar to the proposed change, the tests will be updated to expect the same behaviour from `create_image` regardless of root volume type. So all attached cinder volumes will be snapshotted as a result of the call to `create_image`. Otherwise, the feature is not working as expected. Documentation Impact ==================== Update `create_image` behaviour when the root volume is ephemeral. References ========== Mailing list discussion: * http://lists.openstack.org/pipermail/openstack-dev/2014-January/025382.html Summit discussion: * https://etherpad.openstack.org/p/juno-nova-multi-volume-snapshots ",,169,0
openstack%2Fnova-specs~master~I5b866be6ba3103e8c2603d1ab6d5fe8a5f2f03e8,openstack/nova-specs,master,I5b866be6ba3103e8c2603d1ab6d5fe8a5f2f03e8,EMC: ScaleIO Data Client (SDC) Libvirt Driver,ABANDONED,2014-06-12 10:07:05.000000000,2014-07-16 11:33:15.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 6491}, {'_account_id': 10068}, {'_account_id': 10389}]","[{'number': 1, 'created': '2014-06-12 10:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9ffc188e1c1a962d94e3b8782865131ba006d521', 'message': 'EMC: ScaleIO Data Client (SDC) Libvirt Driver\n\nThis blueprint proposes to add a libvirt driver for the support of SDC\n(ScaleIO Data Client) connected volumes. The addition of SDC support to\nlibvirt will be leveraged by Nova to attach/detach volumes provided by\nproducts such as EMC ScaleIO and ECS (Elastic Cloud Storage).\n\nChange-Id: I5b866be6ba3103e8c2603d1ab6d5fe8a5f2f03e8\n'}, {'number': 2, 'created': '2014-06-12 11:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5773aa816b2e6ac31ff24589f6e24932e8ef8886', 'message': 'EMC: ScaleIO Data Client (SDC) Libvirt Driver\n\nThis blueprint proposes to add a libvirt driver for the support of SDC\n(ScaleIO Data Client) connected volumes. The addition of SDC support to\nlibvirt will be leveraged by Nova to attach/detach volumes provided by\nproducts such as EMC ScaleIO and ECS (Elastic Cloud Storage).\n\nAddressed comments made by Daniel Berrange\n\nChange-Id: I5b866be6ba3103e8c2603d1ab6d5fe8a5f2f03e8\n'}, {'number': 3, 'created': '2014-07-11 13:11:11.000000000', 'files': ['specs/juno/emc-sdc-libvirt-driver.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3038adcd1aaa10c878adfd201c5090f5a20585f3', 'message': 'EMC: ScaleIO Data Client (SDC) Libvirt Driver\n\nThis blueprint proposes to add a libvirt driver for the support of SDC\n(ScaleIO Data Client) connected volumes. The addition of SDC support to\nlibvirt will be leveraged by Nova to attach/detach volumes provided by\nproducts such as EMC ScaleIO and ECS (Elastic Cloud Storage).\n\nblueprint emc-sdc-libvirt-driver\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: I5b866be6ba3103e8c2603d1ab6d5fe8a5f2f03e8\n'}]",20,99615,3038adcd1aaa10c878adfd201c5090f5a20585f3,23,6,3,10389,,,0,"EMC: ScaleIO Data Client (SDC) Libvirt Driver

This blueprint proposes to add a libvirt driver for the support of SDC
(ScaleIO Data Client) connected volumes. The addition of SDC support to
libvirt will be leveraged by Nova to attach/detach volumes provided by
products such as EMC ScaleIO and ECS (Elastic Cloud Storage).

blueprint emc-sdc-libvirt-driver

CCLA SCHEDULE B SUBMISSION

Change-Id: I5b866be6ba3103e8c2603d1ab6d5fe8a5f2f03e8
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/15/99615/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/emc-sdc-libvirt-driver.rst'],1,9ffc188e1c1a962d94e3b8782865131ba006d521,bp/proposes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== EMC: ScaleIO Data Client (SDC) Libvirt Driver ========================================== https://blueprints.launchpad.net/nova/+spec/emc-sdc-libvirt-driver This blueprint proposes to add a libvirt driver for the support of SDC (ScaleIO Data Client) connected volumes. The addition of SDC support to libvirt will be leveraged by Nova to attach/detach volumes provided by products such as EMC ScaleIO and ECS (Elastic Cloud Storage). Problem description =================== This blueprint is being submitted for the EMC ECS (Elastic Cloud Storage) hyper scale storage infrastructure system. ECS is an appliance that provides block, object, and HDFS capabilities natively and combines commodity infrastructure with resilient data services. The EMC ECS appliance will support block volume services through the ScaleIO block API. In order to support mounting such block volumes to Nova instances, a libvirt driver for for ScaleIO block protocol is needed. This blueprint proposes to add such a driver to nova. Proposed change =============== A libvirt driver for the ScaleIO protocol used by EMC ECS will be added to the nova/virt/libvirt directory. A section will be added to the list of libvirt volume drivers in the file nova/virt/libvirt/volume.py. This will direct volumes of 'volume_driver' type 'scaleio' to the correct driver. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- End users will be able to create block volumes from EMC ECS and use them in OpenStack. This change is accompanied by a cinder driver for EMC ECS (a separate cinder blueprint). Performance Impact ------------------ None. Other deployer impact --------------------- The ScaleIO SDC component must be installed on the OpenStack compute node. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: anil-degwekar Other contributors: None Work Items ---------- * ScaleIO Libvirt driver -- this is already developed * An entry in the volume.py file * a filter for scaleio in nova/rootwrap Dependencies ============ * Cinder blueprint for EMC ECS driver https://blueprints.launchpad.net/cinder/+spec/emc-ecs-driver Testing ======= The cinder driver will be tested using the cinder acceptance tests. Those tests will cover this driver as well. A 3rd party CI testing system will be used and its results submitted. Documentation Impact ==================== None. References ========== Product Links: EMC ECS: http://www.emc.com/storage/ecs-appliance/index.htm EMC ScaleIO: http://www.emc.com/storage/scaleio/index.htm ",,141,0
openstack%2Fnova-specs~master~I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650,openstack/nova-specs,master,I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650,Implement policy should be enforced at REST API layer,ABANDONED,2014-05-04 11:28:34.000000000,2014-07-16 11:33:07.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 964}, {'_account_id': 1501}, {'_account_id': 1849}, {'_account_id': 5174}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 5586}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7641}, {'_account_id': 9847}]","[{'number': 1, 'created': '2014-05-04 11:28:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/febf8f8548d5f782101fa81bea3db29dfe3bd454', 'message': 'Blueprint for implementing policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v3 API. And provide consistent policy\nrule for v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 2, 'created': '2014-05-04 11:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6eddb5865c2e3d40cb0d6fbd1d606eaf7913ff01', 'message': 'Blueprint for implementing policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v3 API. And provide consistent policy\nrule for v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 3, 'created': '2014-05-06 07:18:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a7d75a0580f0ccd64b94aa0f143ea506b4c63be1', 'message': 'Blueprint for implementing policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v3 API. And provide consistent policy\nrule for v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 4, 'created': '2014-05-07 22:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d272ebfa65f6eac3a314d41d39a44d1af2810635', 'message': 'Blueprint for implementing policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v3 API. And provide consistent policy\nrule for v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 5, 'created': '2014-05-07 22:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/886b7aef3d14b0a9d4180035c3c70ae9939a779e', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v3 API. And provide consistent policy\nrule for v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 6, 'created': '2014-05-28 03:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/65789a897b5dbf5a44734b5f917815cbf809a403', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v3 API. And provide consistent policy\nrule for v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 7, 'created': '2014-06-11 05:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4f78d0ee9b6d80295640ccd1aac92e394dba6651', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v3 API. And provide consistent policy\nrule for v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 8, 'created': '2014-06-13 11:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a1824f7b4efb311aee855f8235fb37171d3b4e7b', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v2.1/v3 API. And provide consistent\npolicy rule for v2.1/v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 9, 'created': '2014-06-17 03:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/64504d455094658ad9b05d24e7f0567680018df2', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v2.1/v3 API. And provide consistent\npolicy rule for v2.1/v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 10, 'created': '2014-06-20 14:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6e2e0ebf0940b937a9c32a916094cce1d2971140', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v2.1/v3 API. And provide consistent\npolicy rule for v2.1/v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 11, 'created': '2014-06-20 15:29:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/85bac0650d1606d9b9a5d8c426ebfe2d6edf92c5', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v2.1/v3 API. And provide consistent\npolicy rule for v2.1/v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 12, 'created': '2014-06-25 01:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/be53560c9e8fb99a2d31c76bc9a03c49188d3c92', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v2.1/v3 API. And provide consistent\npolicy rule for v2.1/v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 13, 'created': '2014-06-25 02:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4c2f2782dcb89902f858c5fc8440c0601c521389', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v2.1/v3 API. And provide consistent\npolicy rule for v2.1/v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 14, 'created': '2014-06-27 01:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b9ab7f90d3b71138c2d7aab515dafa12cc3dafe9', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v2.1/v3 API. And provide consistent\npolicy rule for v2.1/v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}, {'number': 15, 'created': '2014-06-27 06:21:20.000000000', 'files': ['specs/juno/nova-api-policy.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a41add03491e67ab0dfb9197d09c4385aac3496e', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be enforced\nat REST API layer for ec2, v2 and v2.1/v3 API. And provide consistent\npolicy rule for v2.1/v3 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650\n'}]",104,92005,a41add03491e67ab0dfb9197d09c4385aac3496e,111,14,15,5754,,,0,"Implement policy should be enforced at REST API layer

This is proposed blueprint for implementing policy should be enforced
at REST API layer for ec2, v2 and v2.1/v3 API. And provide consistent
policy rule for v2.1/v3 API.

Part of blueprint v3-api-policy

Change-Id: I7aa0d7d40aa305ffcfddb99c3d7dbab05ab16650
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/05/92005/14 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/nova-api-policy.rst'],1,febf8f8548d5f782101fa81bea3db29dfe3bd454,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Policy should be enforced at API layer where possible ========================================== https://blueprints.launchpad.net/nova/+spec/v3-api-policy Currently the permission checking spread in different level of nova code. There are cases for one api have multiple policy rule both in nova rest api layer and nova compute api layer. Also some cases for hard code permission checking in db layer. That make api policy hard to use in nova. This BP want to enforce all policy at nova rest API layer, and remove all the extra permission checking in nova compute API layer or db layer. And provide consistent policy rule for all the v3 api. This BP is already discussed at Icehouse summit: https://etherpad.openstack.org/p/icehouse-summit-nova-v3-api Problem description =================== A detailed description of the problem: * Permission checking spread in different level of nova code Example: * API layer: https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/contrib/admin_actions.py#L53 * Compute API layer: https://github.com/openstack/nova/blob/master/nova/compute/api.py#L2521 * DB layer: https://github.com/openstack/nova/blob/master/nova/db/sqlalchemy/api.py#L445 * Duplicated policy checking for same API Example: * For server's pause action: * API layer: ""compute_extension:admin_actions:pause"": ""rule:admin_or_owner"" * Compute API layer: ""compute:pause"": """" * Hard code policy check at db layer Example: https://github.com/openstack/nova/blob/master/nova/db/sqlalchemy/api.py#L445 This means it won't have any effect after you modify the policy at REST API layer, it always enforce as admin at db layer. * Different granularity for policy rule In some extension, each api exported from that extension have separated policy rule: https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/contrib/admin_actions.py Also In some extension, all the exported from that extension only have one extension level policy rule: https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/contrib/agents.py * There isn't any distinguish between core and extension for v3 api For v3 api, all api's policy rule is started by ""compute_extension:v3"", there isn't ant distinguish between core and extension api. Proposed change =============== * Remove policy check from compute API layer * For v3 api, there will be only one policy rule for the API. * https://review.openstack.org/#/c/65071/5/nova/api/openstack/compute/plugins/v3/shelve.py * For ec2 and v2 api, we just want to keep all the thing same. So just move the compute API layer into rest api layer, there will be two policy check in v2 rest api layer: * https://review.openstack.org/#/c/65071/5/nova/api/openstack/compute/contrib/shelve.py * Remove hard-code permission check from db layer * Example: https://review.openstack.org/#/c/73490/ * For v3 API, we remove all the hard-code permission check from DB layer. And we should ensure we have policy check at REST API layer. * For v2 API, we remove all the hard-code permission check from DB layer. And with UpgradeImapct flags that notify deployer to update their development configuration. * Add separated policy rule for each v3 api * https://review.openstack.org/#/c/67749/4/nova/api/openstack/compute/plugins/v3/agents.py * Correct the policy rule name specification for v3 api * Core API rule scope: ""compute:v3:[core_api]:[action]"" * Extension api rule scope: ""compute_extension:v3:[core_api]:[action]"" * Enable extension level policy rule as default of action level policy rule After we provide separated policy rule for each v3 API, there will be a lot of policy rules. For ease the burden of deployer, we enable extension level policy rule as default of action level rule, the action level policy rule can override extension level policy. Example: * Extension level policy rule ""compute_extension:admin_actions"": ""rule:admin_api"", * Action level policy rules ""compute_extension:admin_actions:pause"": ""rule:admin_or_owner"", ""compute_extension:admin_actions:unpause"": ""rule:admin_or_owner"", The extension level policy rule is ""rule:admin_api"", that rule will apply to all the actions that haven't specific rule in the policy config file. If deployer want to specifiy different rule than extension level rule for actions pause and unpause, deployer only need add action level rules for pause and unpause in policy config file. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- This BP will clear up the permission check in compute API layer and DB layer. So we should ensure there isn't any API loss the permission checks before we delete those. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- * Correct the policy rule name specification for v3 API Core API rule scope: ""compute:v3:[core_api]:[action]"" Extension api rule scope: ""compute_extension:v3:[core_api]:[action]"" * Split policy rule for each action in v3 API * Compute API layer policy checks(compute:[action]) removed in v3 API * Remove db layer permission checks both in v2 and v3 API Deployer need ensure there are permission checks in API policy. Developer impact ---------------- When developer add new REST API for nova * The permission checks only enforce at REST API layer by policy. * Each API should have separated policy rule. Implementation ============== Assignee(s) ----------- Primary assignee: Alex Xu <xuhj@linux.vnet.ibm.com> Other contributors: Ivan Zhu <bozhu@linux.vnet.ibm.com> Ji Chen <jichenjc@cn.ibm.com> Shuangtai Tian <shuangtai.tian@intel.com> Work Items ---------- https://etherpad.openstack.org/p/apipolicycheck Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== https://etherpad.openstack.org/p/icehouse-summit-nova-v3-api ",,198,0
openstack%2Fheat~master~I8ea301610c20b4c65328cae7c6d35fcc9626a562,openstack/heat,master,I8ea301610c20b4c65328cae7c6d35fcc9626a562,Revert updates to NetworkInterfaces and SubnetId,ABANDONED,2014-07-10 08:18:07.000000000,2014-07-16 11:32:11.000000000,,"[{'_account_id': 3}, {'_account_id': 6498}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-07-10 08:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c9d5d7880b7b07a71701a61338f3e8f133afcc26', 'message': 'Revert updates to NetworkInterfaces and SubnetId\n\nRevert ""Make sure NetworkInterfaces and SubnetId updatable"".\n\nThis reverts commit 0ddd9e0d9f6298500b8f0d7c2c847b7c254de2b0.\n\nReason is that AWS supports updates to NetworkInterfaces and SubnetId\nproperties only in UpdateReplace manner [1].\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html\n\nConflicts:\n\theat/engine/resources/instance.py\n\theat/tests/test_instance.py\n\nChange-Id: I8ea301610c20b4c65328cae7c6d35fcc9626a562\nCloses-Bug: #1340065\n'}, {'number': 2, 'created': '2014-07-13 14:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9651a1830df7693ba37a3bd5a01ef26c1ae0d7fc', 'message': 'Revert updates to NetworkInterfaces and SubnetId\n\nRevert ""Make sure NetworkInterfaces and SubnetId updatable"".\n\nThis reverts commit 0ddd9e0d9f6298500b8f0d7c2c847b7c254de2b0.\n\nReason is that AWS supports updates to NetworkInterfaces and SubnetId\nproperties only in UpdateReplace manner [1].\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html\n\nConflicts:\n\theat/engine/resources/instance.py\n\theat/tests/test_instance.py\n\nChange-Id: I8ea301610c20b4c65328cae7c6d35fcc9626a562\nCloses-Bug: #1340065\n'}, {'number': 3, 'created': '2014-07-15 08:51:39.000000000', 'files': ['heat/tests/test_instance.py', 'heat/engine/resources/instance.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/dbe46e9022b81882161a6bd6585facb024cc20b7', 'message': 'Revert updates to NetworkInterfaces and SubnetId\n\nRevert ""Make sure NetworkInterfaces and SubnetId updatable"".\n\nThis reverts commit 0ddd9e0d9f6298500b8f0d7c2c847b7c254de2b0.\n\nReason is that AWS supports updates to NetworkInterfaces and SubnetId\nproperties only in UpdateReplace manner [1].\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html\n\nConflicts:\n\theat/engine/resources/instance.py\n\theat/tests/test_instance.py\n\nChange-Id: I8ea301610c20b4c65328cae7c6d35fcc9626a562\nCloses-Bug: #1340065\n'}]",0,105992,dbe46e9022b81882161a6bd6585facb024cc20b7,15,4,3,9542,,,0,"Revert updates to NetworkInterfaces and SubnetId

Revert ""Make sure NetworkInterfaces and SubnetId updatable"".

This reverts commit 0ddd9e0d9f6298500b8f0d7c2c847b7c254de2b0.

Reason is that AWS supports updates to NetworkInterfaces and SubnetId
properties only in UpdateReplace manner [1].

[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html

Conflicts:
	heat/engine/resources/instance.py
	heat/tests/test_instance.py

Change-Id: I8ea301610c20b4c65328cae7c6d35fcc9626a562
Closes-Bug: #1340065
",git fetch https://review.opendev.org/openstack/heat refs/changes/92/105992/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_instance.py', 'heat/engine/resources/instance.py']",2,c9d5d7880b7b07a71701a61338f3e8f133afcc26,bug/1340096," _('Network interfaces to associate with instance.') _('Subnet ID to launch instance in.') checker.start() return checker def check_update_complete(self, checker): return checker.step() if checker is not None else True","import copy _('Network interfaces to associate with instance.'), update_allowed=True _('Subnet ID to launch instance in.'), update_allowed=True def _remove_matched_ifaces(self, old_network_ifaces, new_network_ifaces): # find matches and remove them from old and new ifaces old_network_ifaces_copy = copy.deepcopy(old_network_ifaces) for iface in old_network_ifaces_copy: if iface in new_network_ifaces: new_network_ifaces.remove(iface) old_network_ifaces.remove(iface) checkers = [] checkers.append(checker) if self.NETWORK_INTERFACES in prop_diff: new_network_ifaces = prop_diff.get(self.NETWORK_INTERFACES) old_network_ifaces = self.properties.get(self.NETWORK_INTERFACES) subnet_id = ( prop_diff.get(self.SUBNET_ID) or self.properties.get(self.SUBNET_ID)) security_groups = self._get_security_groups() if not server: server = self.nova().servers.get(self.resource_id) # if there is entrys in old_network_ifaces and new_network_ifaces, # remove the same entrys from old and new ifaces if old_network_ifaces and new_network_ifaces: # there are four situations: # 1.old includes new, such as: old = 2,3, new = 2 # 2.new includes old, such as: old = 2,3, new = 1,2,3 # 3.has overlaps, such as: old = 2,3, new = 1,2 # 4.different, such as: old = 2,3, new = 1,4 # detach unmatched ones in old, attach unmatched ones in new self._remove_matched_ifaces(old_network_ifaces, new_network_ifaces) if old_network_ifaces: old_nics = self._build_nics(old_network_ifaces) for nic in old_nics: checker = scheduler.TaskRunner( server.interface_detach, nic['port-id']) checkers.append(checker) if new_network_ifaces: new_nics = self._build_nics(new_network_ifaces) for nic in new_nics: checker = scheduler.TaskRunner( server.interface_attach, nic['port-id'], None, None) checkers.append(checker) # if the interfaces not come from property 'NetworkInterfaces', # the situation is somewhat complex, so to detach the old ifaces, # and then attach the new ones. else: interfaces = server.interface_list() for iface in interfaces: checker = scheduler.TaskRunner(server.interface_detach, iface.port_id) checkers.append(checker) nics = self._build_nics(new_network_ifaces, security_groups=security_groups, subnet_id=subnet_id) # 'SubnetId' property is empty(or None) and # 'NetworkInterfaces' property is empty(or None), # _build_nics() will return nics = None,we should attach # first free port, according to similar behavior during # instance creation if not nics: checker = scheduler.TaskRunner(server.interface_attach, None, None, None) checkers.append(checker) else: for nic in nics: checker = scheduler.TaskRunner( server.interface_attach, nic['port-id'], None, None) checkers.append(checker) if checkers: checkers[0].start() return checkers def check_update_complete(self, checkers): '''Push all checkers to completion in list order.''' for checker in checkers: if not checker.started(): checker.start() if not checker.step(): return False return True",6,353
openstack%2Fnova-specs~master~I599b1a86011f1df058d9e9c0b4611343d46cf420,openstack/nova-specs,master,I599b1a86011f1df058d9e9c0b4611343d46cf420,new spect for blueprint solving ssh-key issues on localhost resize,ABANDONED,2014-07-08 14:21:00.000000000,2014-07-16 11:28:27.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 6962}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-07-08 14:21:00.000000000', 'files': ['specs/juno/no-migration-resize.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c6fe5ca439453e5e1ce07a01573f5a9f8c6cfed6', 'message': 'new spect for blueprint solving ssh-key issues on localhost resize\n\nChange-Id: I599b1a86011f1df058d9e9c0b4611343d46cf420\n'}]",3,105466,c6fe5ca439453e5e1ce07a01573f5a9f8c6cfed6,9,6,1,12317,,,0,"new spect for blueprint solving ssh-key issues on localhost resize

Change-Id: I599b1a86011f1df058d9e9c0b4611343d46cf420
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/66/105466/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/no-migration-resize.rst'],1,c6fe5ca439453e5e1ce07a01573f5a9f8c6cfed6,bp/solving,"allow instance resize without migration ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ https://blueprints.launchpad.net/nova/+spec/no-migration-resize Allow resize of instance disk without instance host migration Problem Description ^^^^^^^^^^^^^^^^^^^^^ following bug https://bugs.launchpad.net/nova/+bug/1323578, the current allow_resize_to_same_host=True only adds the localhost to the pool of computes used to migrate during resize. Proposed change ^^^^^^^^^^^^^^^^^^^^^ I am not sure the current allow_resize_to_same_host usage is clear to the user **Alternative** 1. if we do not change allow_resize_to_same_host to only allow resize to the localhost I think we should create a new option to configure resize without migration. 2. if we see a need in adding localhost to the hosts pool on resize, than I would also suggest that we add optional argument of manual host selection for resize. (--host or --target) **Data model Impact** None **REST API impact** depends on the solution selected **Security Impact** None **Notification impact** depending on solution selected **Other end user impact** depending on solution selected **Other deployer impact** depending on solution selected ** Developer impact** depending on solution selected Implementation ^^^^^^^^^^^^^^^ **Assignee(s)** None **Work Items** depending on solution selected Dependencies ^^^^^^^^^^^^^^^ None Testing ^^^^^^^^ depending on solution selected Documentation Impact ^^^^^^^^^^^^^^^^^^^^^ depending on solution selected References ^^^^^^^^^^^^ https://bugs.launchpad.net/nova/+bug/1323578 ",,86,0
openstack%2Fnova-specs~master~I34dec5ae73514389dd439cf20b9124ea0e4a875e,openstack/nova-specs,master,I34dec5ae73514389dd439cf20b9124ea0e4a875e,Create a scheduler that functions based on policies defined by admin.,ABANDONED,2014-06-03 13:49:23.000000000,2014-07-16 11:26:40.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 91}, {'_account_id': 136}, {'_account_id': 1849}, {'_account_id': 2468}, {'_account_id': 7166}, {'_account_id': 8690}]","[{'number': 1, 'created': '2014-06-03 13:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c84a48c129e74b3fe3b2df4798b853fcc73a6268', 'message': 'Create a scheduler that functions based on policies defined by admin.\n\nThis blueprint proposes a new scheduler that allows admin to apply different\npolicies to different part of the infrastructures or different projects while\nperforming scheduling. Admin can define scheduling rules for each client,\neach aggreggate, each availabiloity-zone or the whole infrastructure\nseparatedly. Admin can also modify these rules in real time without restarting\nthe scheduler.\n\nChange-Id: I34dec5ae73514389dd439cf20b9124ea0e4a875e\nImplements: blueprint policy-based-scheduler\n'}, {'number': 2, 'created': '2014-06-03 14:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8b77f183ee934179fe8434eeb86affef95a2f5a5', 'message': 'Create a scheduler that functions based on policies defined by admin.\n\nThis blueprint proposes a new scheduler that allows admin to apply different\npolicies to different part of the infrastructures or different projects while\nperforming scheduling. Admin can define scheduling rules for each client,\neach aggreggate, each availabiloity-zone or the whole infrastructure\nseparatedly. Admin can also modify these rules in real time without restarting\nthe scheduler.\n\nChange-Id: I34dec5ae73514389dd439cf20b9124ea0e4a875e\nImplements: blueprint policy-based-scheduler\n'}, {'number': 3, 'created': '2014-06-10 15:41:56.000000000', 'files': ['specs/juno/policy-based-scheduing-engine.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6ad05e35ada7ae8f0570e5c11adb9d12426a9750', 'message': 'Create a scheduler that functions based on policies defined by admin.\n\nThis blueprint proposes a new scheduler that allows admin to apply different\npolicies to different part of the infrastructures or different projects while\nperforming scheduling. Admin can define scheduling rules for each client,\neach aggreggate, each availabiloity-zone or the whole infrastructure\nseparatedly. Admin can also modify these rules in real time without restarting\nthe scheduler.\n\nChange-Id: I34dec5ae73514389dd439cf20b9124ea0e4a875e\nImplements: blueprint policy-based-scheduler\n'}]",45,97503,6ad05e35ada7ae8f0570e5c11adb9d12426a9750,20,8,3,8690,,,0,"Create a scheduler that functions based on policies defined by admin.

This blueprint proposes a new scheduler that allows admin to apply different
policies to different part of the infrastructures or different projects while
performing scheduling. Admin can define scheduling rules for each client,
each aggreggate, each availabiloity-zone or the whole infrastructure
separatedly. Admin can also modify these rules in real time without restarting
the scheduler.

Change-Id: I34dec5ae73514389dd439cf20b9124ea0e4a875e
Implements: blueprint policy-based-scheduler
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/03/97503/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/policy-based-scheduing-engine.rst'],1,c84a48c129e74b3fe3b2df4798b853fcc73a6268,bp/proposes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== PBSM - A Scheduling engine using policy ========================================== https://blueprints.launchpad.net/nova/+spec/policy-based-scheduler This blueprint proposes a new scheduler that allows admin to apply different policies to different parts of the infrastructures or different clients while performing scheduling. Admin can define scheduling rules for each client, each aggreggate, each availabiloity-zone or the whole infrastructure separatedly. Admin can also modify these rules in real time without restarting the scheduler. Problem description =================== Current Filter_Scheduler uses Filters and Weighers to help choose the best suited host for any requested VM. However, FilterScheduler has several limits that make it unable to make the best use of its Filter and Weigher catalog and provide business-level services to clients. Among others: * Static policy: admin cannot change the placement policy in runtime without restarting nova-scheduler. Most of Filters and Weighers use parameters from configuration and thus also require restarting nova-scheduler. * Lack of client context: the same filters and weighers are applied with the same parameters regardless of clients. In this situation, it is difficult to provide different qualities of services to clients who sign different contracts. * Global setup only: the same filters and weighers are applied to all hosts. Even though Openstack defines aggregates for regrouping a set of hosts with similar characteristics, it still does not allow admin to define different policies for these aggregates (eventhough some Filters allow per-aggregate parameters). For instance, admin cannot call different Filters/Weighers on different aggregates). The following usecases are unfeasible with FilterScheduler: * Transparency to clients: A company signs a contract with gold service class. With this contract its VMs will be hosted in the aggregate where all high-quality hosts are regrouped, regardless of flavors its users choose. * Runtime modification: Admin can select any set of filters and weighers from the catalog available in Openstack to execute without restarting nova- scheduler. * Local policy vs Global policy: Admin wants to define a Consolidation policy in one aggregate to regroup all VMs into a minimal number of hosts, and a global Load Balancing policy to share the workload in the remaining aggregates. Proposed change =============== Our idea is to separate the scheduling logic (""how do you want to provision the VMs?"") from the application target (""on which part of the resources that you want to apply the scheduling logic?""). This separation allows admin to specify how he wants to provision the resources in each and any context: per client, per aggregate, or per situation. Let's take the first scenario as example. With FilterScheduler, admin has to set up a dedicated flavor associated with this aggregate (via metadata) and let the client select this flavor. However, the client has to know about this flavor, and if he changes the contract, he has to modify all his applications to select the new flavor. The Policy-Based Scheduler will provide clients with transparency: the client just selects any flavor, and the system will automatically put his VMs into suitable aggregates as defined by the rules. Thus no special flavor is needed, and client does not need to modify his appplication at all. Another client will have another set of rules corresponding his context. He may process the same step as the previous one (selecting the same image, the same flavor, etc) but the deployment of his VMs will depend on his context alone. With the transparency provided by Policy-Based Scheduler, admin can use an analytic system to monitor and analyse the client's usage and behaviour and apply suitable rules for the client to better suit his need without reactions from the client's part. The architecture of this scheduler is illustrated as follows: +--------------------------------+ | | | Nova-scheduler | | | | +-----------------------+ | | | | | | | Policy-Based Scheduler| | | | | | | +----------+------------+ | | | | +--------------+-----------------+ | | v +-----------------------+ +----------------+ | | | | | Policy-Based | | Policy | | Scheduling Module +------->| Repository | | | | | +----------+------------+ +----------------+ | | | v +----------------+ | | | Policy plugins | | | +----------------+ * All the policy rules will be stored in Policy Repository. The Repository can be a file, a database or a policy system. The Rule is of format: Target - Effect - Condition (""Under this Condition, apply this Effect to this Target""). Condition can be time, overload situation, etcc. Effect can be Load Balancing, Oversubsription, Service_class, etc. Target can be a tenant, an aggregate, an availability-zone, the entire infra, etc. * The Policy-Based Scheduling Module (PBSM) is the main engine of this architecture. It get the rules from the Policy Repository apply the rules via Policy plugins - the implementation of the rule effect. Plugins can apply Filters or Weighers to the hosts. * Policy-Based Scheduler (PBS) is located inside Nova-scheduler and relays the call from Nova-scheduler to PBSM. PBS will inherit from FilterScheduler with little modification to reduce the impact to the system and benefits from all the development in Nova (especially the work from Instance-group [2]). It also covers all the functionalities of FilterScheduler. If admin does not put any rule into Policy Repository, PBS will function in exactly the same way as FilterScheduler. Admin can configure the filters and weighers that with current FilterScheduler. Thus migration from FilterScheduler to PBS will be natural and does not require any re-configuration from admin. A prototype of this architecture was presented in Demo Session in OpenStack Juno Summit [1]. Alternatives ------------ A alternative is to build PBS from scratch. However, with the works in progress in nova (especially instance-group [2]), it is more convenient to keep it inherit from FilterScheduler. Data model impact ----------------- None REST API impact --------------- The PBS and its modules will not make changes to REST API. In the future, if a policy management system such as Congress [3] as Policy Repository's backend, we can use its REST API to add/modify/delete rules. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ The execution time (making scheduling decision) depends on number of compute nodes and number of policy rules. If admin does not make any rule, it will function exactly the same as FilterScheduler, thus having the same performance. Other deployer impact --------------------- To fully exploit PBS, some configuration is needed: * Make Policy-Based Scheduler the scheduling engine in nova.conf * Precify the Policy Repository backend. The default is a file in /etc/nova/. * (Optional) Put rules in Policy Repository. If a policy management system such as Congress is used as the Repository's backend, this can be done via the system's REST API. At the very least, PBS does not require any other configuration than what admin does with FilterScheduler, except making it the scheduling engine in nova.conf. In this case (no rule is set), PBS will function exactly the same as FilterScheduler. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: toan-tran Work Items ---------- The main part of the architecture will be implemented first: * Policy-based Scheduler * Polci-based Scheduling Module * Policy Repository: file backend The first version of the architecture will use simple file as a Policy Repository's backend. Others will be proposed in separated blueprints. The Policy plugins will be implemented in separated patches of the same blueprint. Dependencies ============ None Testing ======= None other than unittests. Documentation Impact ==================== Documents will be provided on how to write policy rules. References ========== [1] http://openstacksummitmay2014atlanta.sched.org/event/ b4313b37de4645079e3d5506b1d725df [2] https://blueprints.launchpad.net/nova/+spec/instance-group-api-extension [3] https://wiki.openstack.org/wiki/Congress ",,268,0
openstack%2Fnova-specs~master~Ia44a9814f27bbed8af5e229e896cc6b315ca012d,openstack/nova-specs,master,Ia44a9814f27bbed8af5e229e896cc6b315ca012d,Blueprint to enable tls mode for spice/vnc console,ABANDONED,2014-06-18 21:20:18.000000000,2014-07-16 11:25:27.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 7455}]","[{'number': 1, 'created': '2014-06-18 21:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f083babcaca6b425b10dc43bfe0c86caf8155735', 'message': 'In this blueprint, we aim to connect to spice/vnc console\nof the vm using SSL wrapped socket, if enabled in the configuration.\n\nPart of blueprint console-tls-mode\n\nChange-Id: Ia44a9814f27bbed8af5e229e896cc6b315ca012d\n'}, {'number': 2, 'created': '2014-06-18 21:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6a7e69a223c458d4f4f2d806cec9127330849dac', 'message': 'Blueprint to enable tls mode for spice/vnc console\n\nIn this blueprint, we aim to connect to spice/vnc console\nof the vm using SSL wrapped socket, if enabled in the configuration.\n\nPart of blueprint console-tls-mode\n\nChange-Id: Ia44a9814f27bbed8af5e229e896cc6b315ca012d\n'}, {'number': 3, 'created': '2014-06-18 21:55:47.000000000', 'files': ['specs/juno/console-tls-mode.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/254c2b56ce7bf2c28e6ae61a94c940e3c54afaa9', 'message': 'Blueprint to enable tls mode for spice/vnc console\n\nIn this blueprint, we aim to connect to spice/vnc console\nof the vm using SSL wrapped socket, if enabled in the configuration.\n\nPart of blueprint console-tls-mode\n\nChange-Id: Ia44a9814f27bbed8af5e229e896cc6b315ca012d\n'}]",2,101026,254c2b56ce7bf2c28e6ae61a94c940e3c54afaa9,17,4,3,7455,,,0,"Blueprint to enable tls mode for spice/vnc console

In this blueprint, we aim to connect to spice/vnc console
of the vm using SSL wrapped socket, if enabled in the configuration.

Part of blueprint console-tls-mode

Change-Id: Ia44a9814f27bbed8af5e229e896cc6b315ca012d
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/26/101026/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/console-tls-mode.rst'],1,f083babcaca6b425b10dc43bfe0c86caf8155735,bp/to,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================================== Enable tls mode for console access in openstack =============================================== https://blueprints.launchpad.net/nova/+spec/console-tls-mode In this blueprint, we aim to connect to spice/vnc console of the vm using SSL wrapped socket, if enabled in the configuration. Problem Description =================== Both spice and vnc have tls mode configuration available in qemu.conf. If it is turned on, additional tls port is opened up for spice/vnc which accepts SSL connection. Currently openstack provides a way to connect to the spice/vnc console of vm using nova-spicehtml5proxy or nova-novncproxy. These proxies connect to the console using non-SSL socket. There should be a configuration option provided in nova.conf called console_tls_mode. If it is turned on, then the proxy will attempt to connect to the spice/vnc tls port using SSL. This will help provide authentication and encrypt all connections from proxy to the console. Proposed change =============== * Introduce console_tls_mode parameter in nova.conf. * Today, when users request spice/vnc console url, nova-consoleauth stores mapping of token -> console info which includes port at which spice/vnc server is listening. Change: normal port or tlsPort will be stored in the mapping based on what console_tls_mode is configured in nova.conf. * Currently, when users connect to the console url via novncproxy or nova-spicehtml5proxy, nova-consoleauth will validate console port of vm, which user is trying to connect by calling validate_console_port rpcapi. It calls validate_console_port in nova compute manager. Change: nova compute manager will validate normal port or tlsPort based on what console_tls_mode is set in the configuration. * Currently, nova websocketproxy uses non-SSL socket to connect to spice/vnc server. Change: nova websocketproxy will use SSL wrapped socket to connect to spice/vnc server based on what console_tls_mode is configured. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- * Mapping corresponding to the token stored in consoleauth will contain tlsPort or normal port based on what console_tls_mode is configured. * If console_tls_mode is configured, nova websocket proxy will connect to spice/vnc server using ssl wrapped socket. This will provide authentication and encrypted communication between proxy and compute node. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- * If console_tls_mode is configured, deployer will have to ensure ssl certificates are generated and configured in hypervisor driver configuration file. * Also, ensure that tls mode is turned on so that spice/vnc server listens on secure tls port. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: meghal Other contributors: None Work Items ---------- Defined above in Proposed Change section. Dependencies ============ None Testing ======= Existing tempest tests will have to be enhanced. Documentation Impact ==================== New console_tls_mode will have to be documented. References ========== None ",,144,0
openstack%2Fnova-specs~master~Ifdce68ef859e9cd2936f8678c9c49d8066d67704,openstack/nova-specs,master,Ifdce68ef859e9cd2936f8678c9c49d8066d67704,LVM: Support a volume-group on shared storage,ABANDONED,2014-06-03 19:21:41.000000000,2014-07-16 11:25:01.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 9176}, {'_account_id': 10115}]","[{'number': 1, 'created': '2014-06-03 19:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2d0e263a120ec498ca2156edca8b2783a9ea7426', 'message': 'LVM: Support a volume-gorup on shared storage\n\nCurrent LVM cinder driver only supports iSCSI topology and a guest instance\non nova compute is connected to a cinder volume(logical volume) on a\nvolume-group via iSCSI target.\n\nThis proposal adds a feature to connect cinder volume to an instance directly\nusing LVM on a shared storage volume.\n\nAs a result, an instance which uses cinder volume can directly issue I/O to\nvolumes via FC and this provides better I/O performance to a instance.\n\nIn this feature, both cinder and nova pieces are necessary, and blueprint\nfor cinder piece was already approved.\n\nChange-Id: Ifdce68ef859e9cd2936f8678c9c49d8066d67704\nImplements: blueprint lvm-driver-for-shared-storage\n'}, {'number': 2, 'created': '2014-06-05 16:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f792cec120ce4e6ff92660d680fea3c0ebc799ad', 'message': 'LVM: Support a volume-group on shared storage\n\nCurrent LVM cinder driver only supports iSCSI topology and a guest instance\non nova compute is connected to a cinder volume(logical volume) on a\nvolume-group via iSCSI target.\n\nThis proposal adds a feature to connect cinder volume to an instance directly\nusing LVM on a shared storage volume.\n\nAs a result, an instance which uses cinder volume can directly issue I/O to\nvolumes via FC and this provides better I/O performance to a instance.\n\nIn this feature, both cinder and nova pieces are necessary, and blueprint\nfor cinder piece was already approved.\n\nChange-Id: Ifdce68ef859e9cd2936f8678c9c49d8066d67704\nImplements: blueprint lvm-driver-for-shared-storage\n'}, {'number': 3, 'created': '2014-06-16 22:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/036ebc5ffaa7f4f92cc5cb2538bd6fb8d6dc1b39', 'message': 'LVM: Support a volume-group on shared storage\n\nCurrent LVM cinder driver only supports iSCSI topology and a guest instance\non nova compute is connected to a cinder volume(logical volume) on a\nvolume-group via iSCSI target.\n\nThis proposal adds a feature to connect cinder volume to an instance directly\nusing LVM on a shared storage volume.\n\nAs a result, an instance which uses cinder volume can directly issue I/O to\nvolumes via FC and this provides better I/O performance to a instance.\n\nIn this feature, both cinder and nova pieces are necessary, and blueprint\nfor cinder piece was already approved.\n\nChange-Id: Ifdce68ef859e9cd2936f8678c9c49d8066d67704\nImplements: blueprint lvm-driver-for-shared-storage\n'}, {'number': 4, 'created': '2014-06-30 20:40:26.000000000', 'files': ['specs/juno/lvm-driver-for-shared-storage.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1086f2d00b92d05c92ed9e3eb5187d6c79fbdde7', 'message': 'LVM: Support a volume-group on shared storage\n\nCurrent LVM cinder driver only supports iSCSI topology and a guest instance\non nova compute is connected to a cinder volume(logical volume) on a\nvolume-group via iSCSI target.\n\nThis proposal adds a feature to connect cinder volume to an instance directly\nusing LVM on a shared storage volume.\n\nAs a result, an instance which uses cinder volume can directly issue I/O to\nvolumes via FC and this provides better I/O performance to a instance.\n\nIn this feature, both cinder and nova pieces are necessary, and blueprint\nfor cinder piece was already approved.\n\nChange-Id: Ifdce68ef859e9cd2936f8678c9c49d8066d67704\nImplements: blueprint lvm-driver-for-shared-storage\n'}]",18,97602,1086f2d00b92d05c92ed9e3eb5187d6c79fbdde7,41,10,4,10115,,,0,"LVM: Support a volume-group on shared storage

Current LVM cinder driver only supports iSCSI topology and a guest instance
on nova compute is connected to a cinder volume(logical volume) on a
volume-group via iSCSI target.

This proposal adds a feature to connect cinder volume to an instance directly
using LVM on a shared storage volume.

As a result, an instance which uses cinder volume can directly issue I/O to
volumes via FC and this provides better I/O performance to a instance.

In this feature, both cinder and nova pieces are necessary, and blueprint
for cinder piece was already approved.

Change-Id: Ifdce68ef859e9cd2936f8678c9c49d8066d67704
Implements: blueprint lvm-driver-for-shared-storage
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/02/97602/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/lvm-driver-for-shared-storage.rst'],1,2d0e263a120ec498ca2156edca8b2783a9ea7426,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Support LVM on a shared storage volume ========================================== https://blueprints.launchpad.net/nova/+spec/lvm-driver-for-shared-storage Current LVM cinder driver only supports iSCSI topology and a guest instance on nova compute is connected to a cinder volume(logical volume) on a volume-group via iSCSI target. This proposal add a feature to connect cinder volume to an instance directly using LVM on a shared storage volume. As a result, an instance which uses cinder volume can directly issue I/O to volumes via FC and this provides better I/O performance to a instance. In this feature, both cinder and nova pieces are necessary, and blueprint for cinder piece was already approved. https://blueprints.launchpad.net/cinder/+spec/lvm-driver-for-shared-storage Problem description =================== Here is a use case for this proposal. Conventionally, operations to an enterprise storage such as volume creation, deletion, snapshot, etc are only permitted system administrator and they handle these operations after carefully examining. In OpenStack cloud environment, workloads of storages have been increasing and it is difficult to manage the workloads because every user have a permission to execute storage operations via cinder. In order to use expensive storage more efficient, I think it is better to reduce hardware based storage workload by offloading the workload to software based volume operation on a case by case. If we have two drivers in regards to a storage, we can provide volumes both way as the situation demands. For example, - As for ""Standard"" type storage, use proposed software based LVM cinder driver. - As for ""High performance"" type storage, use hardware based cinder driver. (Ex. Higher charge than ""Standard"" volume) For more detail of this proposal such as benefits, use-cases, please refer URLs in section ""Reference"". Proposed change =============== Introduce LibvirtSharedLvmDriver class to virt.libvirt.volume and add the class to list of volume_drivers to handle in case of ""lvm"". In this class, connect_volume() and disconnect_volume() will be implemented to handle LVM on a shared storage volume. - connect_volume() When a storage volume is shared to multiple nodes, volume activation to created logical volume is necessary before attaching a created volume to instance. After volume creation at cinder node, only cinder node knows the volume and other compute nodes do not know about the created volume. Therefore, volume activation using ""lvchange -ay"" is required at a compute node. After volume activation, access device path /dev/VG1/LV1 is created at compute node. Libvirt and qemu can handle device path and attach a volume using this. - disconnect_volume() After detaching a cinder volume, the compute node does not have to access a cinder volume. Therefore, volume deactivation using ""lvchange -an"" is required at a compute node. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: mitsuhiro-tanino Work Items ---------- None. Dependencies ============ This feature depends on following cinder blueprint. https://blueprints.launchpad.net/cinder/+spec/lvm-driver-for-shared-storage Testing ======= Unit tests will be added in nova. Documentation Impact ==================== Cinder driver documentation will be added. There is no impact to nova documentation. References ========== Blueprints: https://blueprints.launchpad.net/nova/+spec/lvm-driver-for-shared-storage https://blueprints.launchpad.net/cinder/+spec/lvm-driver-for-shared-storage Wiki: https://wiki.openstack.org/wiki/Cinder/NewLVMbasedDriverForSharedStorageInCinder openstack-dev discussion: [openstack-dev] [Cinder] Support LVM on a shared LU ",,170,0
openstack%2Fcinder~master~Iab32a3fe230a11692a8cad274304214247d6c2c6,openstack/cinder,master,Iab32a3fe230a11692a8cad274304214247d6c2c6,Cinder-api service throws error on SIGHUP signal,MERGED,2014-07-11 13:53:47.000000000,2014-07-16 11:23:24.000000000,2014-07-16 11:23:24.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2759}, {'_account_id': 7198}, {'_account_id': 10485}]","[{'number': 1, 'created': '2014-07-11 13:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4c87274be69c1f56593373b66093a4f0e2be59a3', 'message': ""Cinder-api service throws error on SIGHUP signal\n\nAdded reset method in WSGIService class.\n\nAfter adding reset method when SIGHUP signal is sent to\nwsgi service parent process,then it sends SIGHUP signal\nto all of its child processes. Each child process handles\nSIGHUP signal by first stopping the service and then calls\nservice start method again. When it stops the service, it\nkills the eventlet thread, which internally closes the wsgi\nserver socket object. This server socket object is now not\nusable again and it throws following error, while restarting\nthe service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nCloses-Bug: #1337796\n\nChange-Id: Iab32a3fe230a11692a8cad274304214247d6c2c6\n""}, {'number': 2, 'created': '2014-07-11 15:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/40e9d48456ba29b18845c2d0b27a7ded79c4753c', 'message': ""Cinder-api service throws error on SIGHUP signal\n\nAdded reset method in WSGIService class.\n\nAfter adding reset method when SIGHUP signal is sent to\nwsgi service parent process,then it sends SIGHUP signal\nto all of its child processes. Each child process handles\nSIGHUP signal by first stopping the service and then calls\nservice start method again. When it stops the service, it\nkills the eventlet thread, which internally closes the wsgi\nserver socket object. This server socket object is now not\nusable again and it throws following error, while restarting\nthe service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nCloses-Bug: #1337796\n\nChange-Id: Iab32a3fe230a11692a8cad274304214247d6c2c6\n""}, {'number': 3, 'created': '2014-07-14 09:29:39.000000000', 'files': ['cinder/service.py', 'cinder/wsgi.py', 'cinder/tests/test_service.py', 'cinder/tests/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4caca0dfae45dd6c61ddc1b4a2233d2ce1a11685', 'message': ""Cinder-api service throws error on SIGHUP signal\n\nAdded reset method in WSGIService class.\n\nAfter adding reset method when SIGHUP signal is sent to\nwsgi service parent process,then it sends SIGHUP signal\nto all of its child processes. Each child process handles\nSIGHUP signal by first stopping the service and then calls\nservice start method again. When it stops the service, it\nkills the eventlet thread, which internally closes the wsgi\nserver socket object. This server socket object is now not\nusable again and it throws following error, while restarting\nthe service:\n\nerror: [Errno 9] Bad file descriptor\n\nTo resolve 'Bad file descriptor' error, creating duplicate\nsocket object, every time service starts.\n\nCloses-Bug: #1337796\n\nChange-Id: Iab32a3fe230a11692a8cad274304214247d6c2c6\n""}]",6,106377,4caca0dfae45dd6c61ddc1b4a2233d2ce1a11685,22,6,3,10485,,,0,"Cinder-api service throws error on SIGHUP signal

Added reset method in WSGIService class.

After adding reset method when SIGHUP signal is sent to
wsgi service parent process,then it sends SIGHUP signal
to all of its child processes. Each child process handles
SIGHUP signal by first stopping the service and then calls
service start method again. When it stops the service, it
kills the eventlet thread, which internally closes the wsgi
server socket object. This server socket object is now not
usable again and it throws following error, while restarting
the service:

error: [Errno 9] Bad file descriptor

To resolve 'Bad file descriptor' error, creating duplicate
socket object, every time service starts.

Closes-Bug: #1337796

Change-Id: Iab32a3fe230a11692a8cad274304214247d6c2c6
",git fetch https://review.opendev.org/openstack/cinder refs/changes/77/106377/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/service.py', 'cinder/wsgi.py', 'cinder/tests/test_service.py', 'cinder/tests/test_wsgi.py']",4,4c87274be69c1f56593373b66093a4f0e2be59a3,bug/1337796," server = cinder.wsgi.Server(""test_app"", None, host=""127.0.0.1"", port=0) server = cinder.wsgi.Server(""test_app"", hello_world, host=""127.0.0.1"", port=0) server = cinder.wsgi.Server(""test_app"", hello_world, host=""127.0.0.1"", port=0) def test_reset_pool_size_to_default(self): server = cinder.wsgi.Server(""test_resize"", None, host=""127.0.0.1"") server.start() # Stopping the server, which in turn sets pool size to 0 server.stop() self.assertEqual(server._pool.size, 0) # Resetting pool size to default server.reset() server.start() self.assertEqual(server._pool.size, 1000) "," server = cinder.wsgi.Server(""test_app"", None) self.assertEqual(0, server.port) server = cinder.wsgi.Server(""test_app"", hello_world) server = cinder.wsgi.Server(""test_app"", hello_world)",120,81
openstack%2Fnova-specs~master~I18030a9c0400807731b880b6fdbf12b13b26c7be,openstack/nova-specs,master,I18030a9c0400807731b880b6fdbf12b13b26c7be,make nova hypervisor to list available resources for scheduling,ABANDONED,2014-07-03 01:14:31.000000000,2014-07-16 11:23:18.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-07-03 01:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a419d5f7d107bd09d9ae8af97b2b9efd60b98424', 'message': 'make nova hypervisor to list available resources for scheduling\n\nThis will make nova hypervisor-* to return the current available\nresources for scheduling on the host.\n\nChange-Id: I18030a9c0400807731b880b6fdbf12b13b26c7be\n'}, {'number': 2, 'created': '2014-07-03 01:48:16.000000000', 'files': ['specs/juno/extends-nova-hypervisor.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5052a603ba6ed39a917b21e891fc04b3436ada06', 'message': 'make nova hypervisor to list available resources for scheduling\n\nThis will make nova hypervisor-* to return the current available\nresources for scheduling on the host.\n\nChange-Id: I18030a9c0400807731b880b6fdbf12b13b26c7be\n'}]",2,104402,5052a603ba6ed39a917b21e891fc04b3436ada06,12,3,2,8915,,,0,"make nova hypervisor to list available resources for scheduling

This will make nova hypervisor-* to return the current available
resources for scheduling on the host.

Change-Id: I18030a9c0400807731b880b6fdbf12b13b26c7be
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/02/104402/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/extends-nova-hypervisor.rst'],1,a419d5f7d107bd09d9ae8af97b2b9efd60b98424,nova-hypervisor,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Spec - make nova hypervisor to list available resources for scheduling ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/extends-nova-hypervisor Currently, there is no easy way to check the current available resources on a given hypervisor. This work augments 'nova hypervisor-*' with available resources for scheduling. Problem description =================== Currently, there is no easy way to check the current available resources on a given hypervisor. If we only monitor the actual resource usage, there might be cases where real usage is < 75% but the scheduler sees no more capacity available to scheduling vm's. For example, we have a 10G RAM on a hypervisor. By running ‘proc’ on the compute node, we see the actual RAM usage is only 3G. With these data point, we cannot say the available RAM is 7G. By checking nova.compute_nodes table, the current free RAM is -3G. Assuming ram_allocation_ratio is 1.5, the correct available RAM seen by scheduler is 2G. The correct calculation is as follows: Physical RAM: 10G Free RAM: -3G Actual used RAM: 3G ram_allocation_ratio: 1.5 Available RAM seen by scheduler: 10*1.5-(10-(-3)) = 2 We need an easy way to get the current available resources on a given hypervisor for both alerting and planning purposes. We should capture the total capacity as the scheduler would see it. This should take into consideration the overcommit ratios too. Proposed change =============== We patch '/os-hypervisors' to also return available resources for scheduling, as well as the overcommit ratio. All the available resources calculations are in the same way as scheduler. ram : https://github.com/openstack/nova/blob/master/nova/scheduler/filters/ram_filter.py core : https://github.com/openstack/nova/blob/master/nova/scheduler/filters/core_filter.py disk : https://github.com/openstack/nova/blob/master/nova/scheduler/filters/disk_filter.py Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- * No new extension needed, the existing hypervisor REST API will be updated to return the resources available for scheduling, as well as the overcommit ratios * URL: existed hypervisors extension as: * /v2/{tenant_id}/os-hypervisors/{id} JSON response body:: {""hypervisor"": { ""vcpus_used"": 4, ""hypervisor_type"": ""QEMU"", ""local_gb_used"": 80, ""host_ip"": ""172.25.110.34"", ""hypervisor_hostname"": ""otccloud06"", ""memory_mb_used"": 8704, ""memory_mb"": 23638, ""current_workload"": 0, ""vcpus"": 16, ""cpu_info"": {""vendor"": ""Intel} ""running_vms"": 2, ""free_disk_gb"": 439, ""hypervisor_version"": 1000000, ""disk_available_least"": 408, ""local_gb"": 519, ""free_ram_mb"": 14934, ""id"": 1, ""cpu_allocation_ratio"": 16.0, ""disk_allocation_ratio"": 1.0, ""ram_allocation_ratio"": 1.5, ""available_disk_gb"": 439, ""available_ram_mb"": 26753, ""available_vcpus"": 252} } The new fields are: 'cpu_allocation_ratio' 'disk_allocation_ratio' 'ram_allocation_ratio' 'available_disk_gb' 'available_ram_mb' 'available_vcpus' Security impact --------------- No Notifications impact -------------------- No Other end user impact --------------------- Yes, this will impact the python-novaclient. novaclient should show the new fields on the 'nova hypervisor' command. Performance Impact ------------------ No Other deployer impact --------------------- No Developer impact ---------------- No Implementation ============== Assignee(s) ----------- Primary assignee: weidu@yahoo-inc.com Work Items ---------- * Changes to V2 API * Changes to novaclient Dependencies ============ No Testing ======= Both unit and Tempest tests will be created to ensure the correct implementation. Documentation Impact ==================== Document the change to the REST API. References ========== No ",,178,0
openstack%2Fheat~master~I4f31c2cd64b94564ff53d944cae36bff472491d4,openstack/heat,master,I4f31c2cd64b94564ff53d944cae36bff472491d4,Add missing DeprecationWarning category to warning,MERGED,2014-07-15 10:42:27.000000000,2014-07-16 11:23:16.000000000,2014-07-16 11:23:15.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7385}, {'_account_id': 8246}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-15 10:42:27.000000000', 'files': ['heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/56165fcb12a278747e9b5da11fbe98dc37cf76a7', 'message': 'Add missing DeprecationWarning category to warning\n\nThis is a deprecation warning but it lacks the category specifier\nfor DeprecationWarning.\n\nChange-Id: I4f31c2cd64b94564ff53d944cae36bff472491d4\n'}]",0,106990,56165fcb12a278747e9b5da11fbe98dc37cf76a7,30,8,1,4328,,,0,"Add missing DeprecationWarning category to warning

This is a deprecation warning but it lacks the category specifier
for DeprecationWarning.

Change-Id: I4f31c2cd64b94564ff53d944cae36bff472491d4
",git fetch https://review.opendev.org/openstack/heat refs/changes/90/106990/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/service.py'],1,56165fcb12a278747e9b5da11fbe98dc37cf76a7,deprecation_warning," 'release.', DeprecationWarning)", 'release.'),1,1
openstack%2Fnova-specs~master~I89d3f784e73a166d91dd29515955f8b4c76bbac3,openstack/nova-specs,master,I89d3f784e73a166d91dd29515955f8b4c76bbac3,Only allow admins to delete VMs from down compute nodes,ABANDONED,2014-06-02 21:38:01.000000000,2014-07-16 11:22:19.000000000,,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 1297}, {'_account_id': 1298}, {'_account_id': 1501}, {'_account_id': 1849}, {'_account_id': 5441}, {'_account_id': 10165}, {'_account_id': 11801}]","[{'number': 1, 'created': '2014-06-02 21:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/05e3cee49ff48888700a7501316bd8db8d5ab53c', 'message': 'Only allow admins to delete VMs from down compute nodes\n\nOnly allow admins to do local deletes to avoid the possibility of\nmultiple VMs using the same IP.\n\nChange-Id: I89d3f784e73a166d91dd29515955f8b4c76bbac3\n'}, {'number': 2, 'created': '2014-06-03 17:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c52e6005d4ab43fb82810e0e5a76e88d2d22829c', 'message': 'Only allow admins to delete VMs from down compute nodes\n\nOnly allow admins to do local deletes to avoid the possibility of\nmultiple VMs using the same IP.\n\nChange 1: Fix RST syntax errors\n\nChange-Id: I89d3f784e73a166d91dd29515955f8b4c76bbac3\n'}, {'number': 3, 'created': '2014-06-03 19:38:59.000000000', 'files': ['specs/juno/only-allow-admins-to-do-local-delete.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a8db1f240d5c57eff21d6668442c24ee32020951', 'message': 'Only allow admins to delete VMs from down compute nodes\n\nOnly allow admins to do local deletes to avoid the possibility of\nmultiple VMs using the same IP.\n\nChange 1: Fix RST syntax errors\n\nChange 2: Fix a couple of typos\n\nChange-Id: I89d3f784e73a166d91dd29515955f8b4c76bbac3\n'}]",1,97350,a8db1f240d5c57eff21d6668442c24ee32020951,31,9,3,1298,,,0,"Only allow admins to delete VMs from down compute nodes

Only allow admins to do local deletes to avoid the possibility of
multiple VMs using the same IP.

Change 1: Fix RST syntax errors

Change 2: Fix a couple of typos

Change-Id: I89d3f784e73a166d91dd29515955f8b4c76bbac3
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/50/97350/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/only-allow-admins-to-do-local-delete.rst'],1,05e3cee49ff48888700a7501316bd8db8d5ab53c,97350,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Only allow admins to delete VMs from down compute nodes ========================================== https://blueprints.launchpad.net/nova/+spec/only-allow-admins-to-do-local-delete Currently any user is allowed to do a local delete (delete a VM from a compute node which is currently down). This is useful functionality but we've seen first hand that there is a potential issue. We locally patch the code to restrict local deletes to only admins. Since we find this change extremely useful, it may be of benefit to the community. Problem description =================== Consider the following scenario. * A compute node goes down for some unknown cause. All of the VMs currently running on it are unavailable to users. * The users do 'nova delete' on their VMs. The local delete processing cleans up things and releases the IPs from those VMs back into the pool. * New VMs are started which may reuse some or all of those IPs. * Through the valiant efforts of the operations team, the compute node is brough back and all of the VMs hosted on it are restarted. * We now have multiple VMs with the same IP. Proposed change =============== The local delete functionality is still extremely important to have in order to clean up VMs from down compute nodes. Our proposal (and what we do with a local patch) is to only allow admins to use it since they're the ones who know if the compute node has a chance of coming back or not. The exact chance would be to modify nova/compute/api.py before _local_delete is called to check if the current user is an admin. If so, go ahead and do the local delete as before. If the user is not an admin, then clear the current task state and raise an error stating that the delete can't happen because the compute node is down, so please contact your local administrator. Note that as part of raising the error, a call to QUOTAS.rollback will happen to make sure that the delete quota change does not go through. Alternatives ------------ We could leave it as it is, but as we've seen, this can be a dangerious situation. We could provide a config setting to retain the old behavior for folks who want to go ahead and let their users keep the ability to do local deletes. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- A new error message will be generated to tell a non-admin user that they aren't being allowed to delete their VM because the compute node is down and that they should contact their administrator. Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- As mentioned above, a new config setting could be added to keep the old behavior for folks who like living on the edge. If this config setting is added, I strongly recommend that the default setting be to use the new more restrictive (and safer) behavior. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: krt Other contributors: None Work Items ---------- * Modify nova/compute/api.py * Modify/write unit tests (if possible) Dependencies ============ * None Testing ======= * To prevent from breaking any existing local delete tests, we'll need to make sure that the user being used is an admin, or we that the config setting is set to use the old behavior. * If possible, a new test for non-admin user doing local delete will be written and check that the expected error is returned. Documentation Impact ==================== We may need to add a note to nova delete that it may be rejected by non-admin users if the compute node is down. References ========== None ",,153,0
openstack%2Fnova-specs~master~I36624233b5d436aedcb289848e6fd5e535efa1c7,openstack/nova-specs,master,I36624233b5d436aedcb289848e6fd5e535efa1c7,Action type aware scheduling.,ABANDONED,2014-06-01 14:20:51.000000000,2014-07-16 11:21:58.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 9275}, {'_account_id': 10068}, {'_account_id': 11636}]","[{'number': 1, 'created': '2014-06-01 14:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ded7af068b5ed44a0ef295fa982c22cf63b48892', 'message': 'Action type aware scheduling.\n\nBlueprint proposes to add ""action_type"" key to ""filter_properties""\nso that filters and weighers could be aware of currently processed\naction (scheduling / rescheduling / migration / resize / live-migration\n/ evacuation / unshelving).\n\nChange-Id: I36624233b5d436aedcb289848e6fd5e535efa1c7\n'}, {'number': 2, 'created': '2014-06-01 15:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f914258c2bbc049bb83706cc73240d8515fd083d', 'message': 'Action type aware scheduling.\n\nBlueprint proposes to add ""action_type"" key to ""filter_properties""\nso that filters and weighers could be aware of currently processed\naction (scheduling / rescheduling / migration / resize / live-migration\n/ evacuation / unshelving).\n\nChange-Id: I36624233b5d436aedcb289848e6fd5e535efa1c7\n'}, {'number': 3, 'created': '2014-07-08 13:02:51.000000000', 'files': ['specs/juno/action-type-aware-scheduling.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/708590b955bf9433a0e2c9f71a88ee350817a252', 'message': 'Action type aware scheduling.\n\nBlueprint proposes to add ""action_type"" key to ""filter_properties""\nso that filters and weighers could be aware of currently processed\naction (scheduling / rescheduling / migration / resize / live-migration\n/ evacuation / unshelving).\n\nChange-Id: I36624233b5d436aedcb289848e6fd5e535efa1c7\n'}]",10,97103,708590b955bf9433a0e2c9f71a88ee350817a252,27,8,3,11636,,,0,"Action type aware scheduling.

Blueprint proposes to add ""action_type"" key to ""filter_properties""
so that filters and weighers could be aware of currently processed
action (scheduling / rescheduling / migration / resize / live-migration
/ evacuation / unshelving).

Change-Id: I36624233b5d436aedcb289848e6fd5e535efa1c7
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/03/97103/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/action-type-aware-scheduling.rst'],1,ded7af068b5ed44a0ef295fa982c22cf63b48892,bp/proposes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================================= Action type aware scheduling ============================================================================= https://blueprints.launchpad.net/nova/+spec/action-type-aware-scheduling Currently in ``FilterScheduler`` there is no variable indicating which action triggered the request that is currently processed. The behavior of filters and weighers may be different depending on the fact if currently processed request is scheduling/rescheduling/migration/resize/live-migration/evacuation/unshelving. What this blueprint proposes is to add a new variable which would keep an action type. It should be accessible from custom scheduler filters and weighers. This could be accomplished using ``filter_properties`` dictionary - a new key like ``'action_type'`` can be added there. Problem description =================== Right now it's difficult to check which action triggered scheduling in FilterScheduler, you need to use ``task_state`` from ``filter_properites`` and some other properties to distinguish between them: * if ``task_state`` is ``""scheduling""`` you need to use ``retry`` parameter to distinguish between scheduling and rescheduling. * if ``task_state`` is ``""resize_prep""`` you need to check if old and new VM flavor is the same to distinguish between migration and resize. * if ``task_state`` is ``""migrating""`` then it's live migration (this one is really confusing). * if ``task_state`` is ``""unshelving""`` then this request was triggered by unshelving action. * another action to distinguish is evacuation, as once blueprint *find-host-and-evacuate-instance* will be implemented, evacuation will also be able to trigger scheduling. Therefore if your custom filter needs this information to properly schedule a VM, you need to use complicated if-else statement. It would be much easier if there was a flag in ``filter_properties`` that indicates action type. With this feature you will be able to schedule your VMs according to action that triggered scheduling. For example (if this blueprint will be implemented: https://blueprints.launchpad.net/nova/+spec/find-host-and-evacuate-instance) you would be able to keep multiple compute nodes for emergency evacuation purpose and place VMs on them only when scheduling was triggered by evacuation. Or you can keep a host for rescheduling only to be sure that if other hosts fail booting a VM, then it will always start on this one fail-proof host. Also when migrating a VM you can filter out hosts that have a set of capabilities incompatible with running VM (now such migration fails without obvious reason, and user need to dig out error message from nova-compute logs). Proposed change =============== We intend to change: * ``compute/api.py`` file where ``filter_properties`` for migrate and resize are created; * ``conductor/manager.py`` file for create and unshelve actions; * ``conductor/tasks/live_migrate`` for live migration action; In these files we will insert ``action_type`` element into ``filter_properties``. It will be set to the corresponding action. Probably best type for this is ``nova.compute.instance_actions`` enum and we want to add missing live migration action to it. Alternatives ------------ Another way of doing this is to modify ``FilterScheduler`` and add this flag in ``schedule_run_instance`` using aforementioned if-else statement. This is an improper way of developing this feature because in the future there can be an action type that is indistinguishable from others using only the current set of ``filter_properties``. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Solution we propose is adding only one assignment to methods where scheduling requests are created. This should have no impact on performance. Other deployer impact --------------------- If deployer is using his custom filters he will have more information to decide on which node a particular VM should be launched. Additional flag in ``filter_properties`` won't affect any already developed filters or ``FilterScheduler`` extensions. Developer impact ---------------- Developers will have more flexibility in defining rules in stock filters. Implementation ============== Assignee(s) ----------- Primary assignee: mateusz-blaszkowski-8 Other contributors: michal-dulko-f Work Items ---------- * Insert ``action_type`` to ``filter_properties`` in proper places. * Add unit tests for all scheduling actions checking if ``action_type`` element is present in ``filter_properties``. Dependencies ============ None Testing ======= As this feature at the start will be used only if user will modify filters or ``FilterScheduler`` on his own it doesn't need any new integration tests. Unit tests will be sufficient. Documentation Impact ==================== None References ========== None ",,184,0
openstack%2Fnova-specs~master~Ie95cb7a67d0d0de5a257a4f4cdb1a5779529ae90,openstack/nova-specs,master,Ie95cb7a67d0d0de5a257a4f4cdb1a5779529ae90,Fail resize operations that attempt to reduce disk size,ABANDONED,2014-06-18 16:33:09.000000000,2014-07-16 11:21:13.000000000,,"[{'_account_id': 3}, {'_account_id': 1501}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 6062}, {'_account_id': 8021}, {'_account_id': 9060}]","[{'number': 1, 'created': '2014-06-18 16:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1d4d465b30de5f7aeedfaf823f14522df8208a1d', 'message': 'Make resize opertaions that attempt to reduce disk size an error\n\nCurrent hypervisors have a range of checks against reduction in disk size for\nresize operations, ranging from checking root and ephemeral to not checking at\nall. Blocking any resize operation to a flavor with less disk capacity will\nprovide a better and more consistent user experience.\n\nChange-Id: Ie95cb7a67d0d0de5a257a4f4cdb1a5779529ae90\n'}, {'number': 2, 'created': '2014-06-18 17:38:22.000000000', 'files': ['specs/juno/no-downward-resize.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ad7148c83c30e02b594bd7a5a18adf2250e0b124', 'message': 'Fail resize operations that attempt to reduce disk size\n\nCurrent hypervisors have a range of checks against reduction in disk size for\nresize operations, ranging from checking root and ephemeral to not checking at\nall. Blocking any resize operation to a flavor with less disk capacity will\nprovide a better and more consistent user experience.\n\nChange-Id: Ie95cb7a67d0d0de5a257a4f4cdb1a5779529ae90\n'}]",6,100953,ad7148c83c30e02b594bd7a5a18adf2250e0b124,16,7,2,1501,,,0,"Fail resize operations that attempt to reduce disk size

Current hypervisors have a range of checks against reduction in disk size for
resize operations, ranging from checking root and ephemeral to not checking at
all. Blocking any resize operation to a flavor with less disk capacity will
provide a better and more consistent user experience.

Change-Id: Ie95cb7a67d0d0de5a257a4f4cdb1a5779529ae90
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/53/100953/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/no-downward-resize.rst'],1,1d4d465b30de5f7aeedfaf823f14522df8208a1d,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================== Don't allow resize to smaller disks =================================== https://blueprints.launchpad.net/nova/+spec/no-downward-resize Current hypervisors have a range of checks against reduction in disk size for resize operations, ranging from checking root and ephemeral to not checking at all. Blocking any resize operation to a flavor with less disk capacity will provide a better and more consistent user experience. Problem description =================== Hypervisor checks on resize to a smaller disc are currently inconsistent: Baremetal: No support for resize Hyperv: Checks and fails root disk only Libvirt: Checks and fails for root and ephemeral Vmware: Currently no checks, patch submitted to check and fail root disk Xen: Allows root disk resize, but fails ephemeral disk Because these checks are only implemented at the driver failures cannot be easily detected by the user (the instance remains active). Even where implemented resize operations will not work if the source disk already contains more data that the new flavor allows. This gives an inconsistent user experience. Proposed change =============== Consensus on the mailing list was that resize operations where the root or ephemeral disk capacity is reduced should be treated as an error and blocked at the API layer. The new check will be implemented as an API extension, which if loaded will return an error if either of the root or ephemeral disks in the target flavor are smaller than the current sizes used by the instance. Alternatives ------------ As the current behavior is either that checks exist (but are buried in the system), or is inconsistent (the operation may fail under some conditions) an alternative implantation would be to considered this as enhanced validation in the API rather than a change in behavior, and so add the check to the existing API code rather than as an extension. However that would prevent users from being able to detect if the new check was being enforced, and prevent operators who do have a hypervisor that partially implements the resize from continuing to do so. Data model impact ----------------- None REST API impact --------------- Adds a new API extension: Name = ""NoResizeDown"" Alias = ""os-no-resize-down"" Loading this extension will modify the behavior of the resize operation so that if the root disk size or ephemeral disk size are less than the current sizes used by the instance it will return 400 Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- Users will get an error result for operations that would have previously been accepted (but may not have been successful) Performance Impact ------------------ None Other deployer impact --------------------- Deployers will need to decide whether to load this new extension or not, taking into account the capabilities of their hypervisor. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Phil Day Work Items ---------- Will be implemented as a single change Dependencies ============ None Testing ======= Tempest will not be affected as it currently only includes a resize upwards (resize to a smaller flavor would have failed silently on libvirt). The new additional validation check can be adequate covered by unit tests. Documentation Impact ==================== The new APi extension will need to be documented. References ========== The issue and approach was discussed on openstack-dev: http://lists.openstack.org/pipermail/openstack-dev/2014-June/037609.html ",,152,0
openstack%2Fnova-specs~master~Ie274f64f151dc9824cbe8e83a2737d660e4bacd6,openstack/nova-specs,master,Ie274f64f151dc9824cbe8e83a2737d660e4bacd6,make nova host-describe to return available resources seen by scheduler,ABANDONED,2014-06-26 05:40:28.000000000,2014-07-16 11:20:58.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 6062}, {'_account_id': 7166}]","[{'number': 1, 'created': '2014-06-26 05:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b1b058567f4bff3423a24560d7503c40acb86761', 'message': 'nova-api extension to list available resources seen by scheduler\n\nCurrently, there is no easy way to check the current available resources on a\ngiven cluster. This work provides a nova client extension, and a corresponding\nnova api implementaion. Through this nova client command, admin users can\neasily get the current resource availability data, which is same as those\nseen by scheduler.\n\nChange-Id: Ie274f64f151dc9824cbe8e83a2737d660e4bacd6\n'}, {'number': 2, 'created': '2014-06-26 21:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0c23ed6b090260a3d4cb45febf061fa0bad519e7', 'message': ""make nova host-describe to return available resources seen by scheduler\n\nCurrently, there is no easy way to check the current available resources on a given hypervisor. This work extends 'nova host-describe' to also return available resources, which is same as those seen by scheduler.\n\nChange-Id: Ie274f64f151dc9824cbe8e83a2737d660e4bacd6\n""}, {'number': 3, 'created': '2014-06-26 21:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a5f36a19621869f96bea0d4cc0806d3f94f4010b', 'message': ""make nova host-describe to return available resources seen by scheduler\n\nCurrently, there is no easy way to check the current available \nresources on a given hypervisor. This work extends 'nova host-describe' to also return available resources, which is same as those seen \nby scheduler.\n\nChange-Id: Ie274f64f151dc9824cbe8e83a2737d660e4bacd6\n""}, {'number': 4, 'created': '2014-06-26 21:41:57.000000000', 'files': ['specs/juno/nova-api-extension-to-list-available-resources.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/00836099bf025fad79fc5feb8f096eeaa645c7b9', 'message': ""make nova host-describe to return available resources seen by scheduler\n\nCurrently, there is no easy way to check the current available \nresources on a given hypervisor. This work extends 'nova host-describe'\nto also return available resources, which is same as those seen \nby scheduler.\n\nChange-Id: Ie274f64f151dc9824cbe8e83a2737d660e4bacd6\n""}]",3,102727,00836099bf025fad79fc5feb8f096eeaa645c7b9,15,4,4,8915,,,0,"make nova host-describe to return available resources seen by scheduler

Currently, there is no easy way to check the current available 
resources on a given hypervisor. This work extends 'nova host-describe'
to also return available resources, which is same as those seen 
by scheduler.

Change-Id: Ie274f64f151dc9824cbe8e83a2737d660e4bacd6
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/27/102727/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/nova-api-extension-to-list-available-resources.rst'],1,b1b058567f4bff3423a24560d7503c40acb86761,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Spec - nova-api extension to list available resources seen by scheduler ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/nova-api-extension-to-list-available-resources Currently, there is no easy way to check the current available resources on a given cluster. This work provides a nova client extension, and a corresponding nova api implementaion. Through this nova client command, admin users can easily get the current resource availability data, which is same as those seen by scheduler. Problem description =================== Currently, there is no easy way to check the current available resources on a given cluster. If we only monitor the actual resource usage, there might be cases where real usage is < 75% but the scheduler sees no more capacity available to scheduling vm's. For example, we have a 10G RAM on a hypervisor. By running ‘proc’ on the compute node, we see the actual RAM usage is only 3G. With these data point, we cannot say the available RAM is 7G. By checking nova.compute_nodes table, the current free RAM is -3G. Assuming ram_allocation_ratio is 1.5, the correct available RAM seen by scheduler is 2G. The correct calculation is as follows: Physical RAM: 10G Free RAM: -3G Actual used RAM: 3G ram_allocation_ratio: 1.5 Available RAM seen by scheduler: 10*1.5-(10-(-3)) = 2 We need an easy way to get the current available resources on a given cluster for both alerting and planning purposes. We should capture the total cluster capacity as the scheduler would see it. This should take into consideration the overcommit ratios too. Proposed change =============== We implement a nova api extension 'os-available-resources'. An admin user can invoke it through novaclient extension like 'nova available-resources'. All the available resources calculations are in the same way as scheduler. ram : https://github.com/openstack/nova/blob/master/nova/scheduler/filters/ram_filter.py core : https://github.com/openstack/nova/blob/master/nova/scheduler/filters/core_filter.py disk : https://github.com/openstack/nova/blob/master/nova/scheduler/filters/disk_filter.py Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- * New v2 API extension: * Name: AvailableResources * Alias: os-available-resources * Description : List current available resources for a cluster * Method type : GET * Normal http response code : 200 * Expected error http response code(s) * serviceUnavailable (503) * forbidden (403) * URL for the resource : v2/{tenant_id}/os-available-resources * Parameters which can be passed via the url : None * JSON schema definition for the response data : response := {'available_resources': nodes} nodes := [node] node := {key : value} key := 'hypervisor_hostname' | 'vcpus' | 'vcpus_used' | 'cpu_allocation_ratio' | 'available_vcpus' | 'memory_mb' | 'free_ram_mb' | 'ram_allocation_ratio' | 'available_ram_mb' | 'local_gb' | 'free_disk_gb' | 'disk_allocation_ratio' | 'available_disk_gb * Example : request : GET /v2/{tenant_id}/os-available-resources response : RESP: [200] {'date': 'Thu, 26 Jun 2014 00:04:47 GMT', 'content-length': '371', 'content-type': 'application/json', 'x-compute-request-id': 'req-2daaca17-4008-48d5-b277-60c21659de01'} RESP BODY: {""available_resources"": [{""available_disk_gb"": 479.0, ""available_ram_mb"": 30849.0, ""vcpus_used"": 2, ""cpu_allocation_ratio"": 16.0, ""available_vcpus"": 254.0, ""hypervisor_hostname"": ""hostname.domain.com"", ""memory_mb"": 23638, ""vcpus"": 16, ""disk_allocation_ratio"": 1.0, ""free_disk_gb"": 479, ""local_gb"": 519, ""free_ram_mb"": 19030, ""ram_allocation_ratio"": 1.5}]} Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- There is also a novaclient extension to invoke this new api, which is 'nova available-resource'. Performance Impact ------------------ None -- This new API is not introducing any new DB joins that would affect performance. Other deployer impact --------------------- None ---------------- Implementation ============== Assignee(s) ----------- weidu@yahoo-inc.com Work Items ---------- 1. nova api extension implementation 2. novaclient extension implementation Dependencies ============ None Testing ======= Both unit and Tempest tests need to be created to ensure that the returned data is accurate for clusters. Documentation Impact ==================== Document the API extension (see ""REST API impact"" section for details). References ========== None ",,190,0
openstack%2Fnova-specs~master~Ifce7283dd0ff432b44332d4cc8003dc91936ff71,openstack/nova-specs,master,Ifce7283dd0ff432b44332d4cc8003dc91936ff71,Standardize Client Parameters,ABANDONED,2014-06-10 05:51:49.000000000,2014-07-16 11:20:29.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 10070}]","[{'number': 1, 'created': '2014-06-10 05:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0c19b1b70731c92433ed424a4a4a100fdff1d94a', 'message': 'Standardize Client Parameters\n\nThis spec represents one of the goals of the Session work happening\nwithin the clients, to standardize the security and authentication\nparameters (and code).\n\nThere is ongoing work in the client to define the correct names and\nmethods of loading the same parameters for multiple clients. To make\nsure that that work is accepted I would like to make sure that the\nservers are onboard with the direction. Whilst this is for nova if\naccepted the same pattern will be deployed to the other services as\nwell.\n\nChange-Id: Ifce7283dd0ff432b44332d4cc8003dc91936ff71\n'}, {'number': 2, 'created': '2014-06-10 07:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/74d0486a3732c11307eddb17552836d397afa1eb', 'message': 'Standardize Client Parameters\n\nThis spec represents one of the goals of the Session work happening\nwithin the clients, to standardize the security and authentication\nparameters (and code).\n\nThere is ongoing work in the client to define the correct names and\nmethods of loading the same parameters for multiple clients. To make\nsure that that work is accepted I would like to make sure that the\nservers are onboard with the direction. Whilst this is for nova if\naccepted the same pattern will be deployed to the other services as\nwell.\n\nChange-Id: Ifce7283dd0ff432b44332d4cc8003dc91936ff71\n'}, {'number': 3, 'created': '2014-06-10 08:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/86b63d880cf878fbd2cfdf92a5aeaad2aa424dca', 'message': 'Standardize Client Parameters\n\nThis spec represents one of the goals of the Session work happening\nwithin the clients, to standardize the security and authentication\nparameters (and code).\n\nThere is ongoing work in the client to define the correct names and\nmethods of loading the same parameters for multiple clients. To make\nsure that that work is accepted I would like to make sure that the\nservers are onboard with the direction. Whilst this is for nova if\naccepted the same pattern will be deployed to the other services as\nwell.\n\nChange-Id: Ifce7283dd0ff432b44332d4cc8003dc91936ff71\n'}, {'number': 4, 'created': '2014-06-10 19:59:00.000000000', 'files': ['specs/juno/standardize-client-params.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4c0c42ec5005eda5f2137d1a8caa943a1da8f3f0', 'message': 'Standardize Client Parameters\n\nThis spec represents one of the goals of the Session work happening\nwithin the clients, to standardize the security and authentication\nparameters (and code).\n\nThere is ongoing work in the client to define the correct names and\nmethods of loading the same parameters for multiple clients. To make\nsure that that work is accepted I would like to make sure that the\nservers are onboard with the direction. Whilst this is for nova if\naccepted the same pattern will be deployed to the other services as\nwell.\n\nChange-Id: Ifce7283dd0ff432b44332d4cc8003dc91936ff71\n'}]",3,98955,4c0c42ec5005eda5f2137d1a8caa943a1da8f3f0,19,4,4,7191,,,0,"Standardize Client Parameters

This spec represents one of the goals of the Session work happening
within the clients, to standardize the security and authentication
parameters (and code).

There is ongoing work in the client to define the correct names and
methods of loading the same parameters for multiple clients. To make
sure that that work is accepted I would like to make sure that the
servers are onboard with the direction. Whilst this is for nova if
accepted the same pattern will be deployed to the other services as
well.

Change-Id: Ifce7283dd0ff432b44332d4cc8003dc91936ff71
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/55/98955/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/standardize-client-params.rst'],1,0c19b1b70731c92433ed424a4a4a100fdff1d94a,client-params,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================= Standardize Client Parameters ============================= https://blueprints.launchpad.net/nova/+spec/standardize-client-params Every time nova (or any other service) wishes to talk to another service we end up in the position of having to support that client's every option in the config file. This is a burden on developers and can lead to missing security options as they are added or differences in parameter handling. Problem description =================== The lack of consistency in the clients has led to the config options describing server to server communications being handled on an as needed basis. This has led to inconsistencies such as being able to set CA certificates for most services, but not for glance. It also means that valuable deployment options such as HTTP timeouts and client certificates cannot be configured from nova. Further as we move to Keystone V3 authentication and other additional authentication mechanisms the number of possible authentication options available for every client becomes endless. There needs to be one standard way of loading security and authentication options regardless of the server such that Nova (and others) are not having to manually keep track of these configuration options. Proposed change =============== The clients are in the process of having the security and authorization components standardized. To use a client you: 1. Construct an authentication plugin which has a username and password or any other form of authentication (e.g. oauth, kerberos) options. 2. Construct a session object containing options such as certificates and connection parameters (e.g. http timeout), and the authentication plugin. 3. Construct a client with the session object. The first two steps above will become standard for all clients and as such keystoneclient is defining a standard set of helper mechanisms to allow them to be loaded from any OSLO config file. Current the Cinder options look like:: [DEFAULT] # Info to match when looking for cinder in the service # catalog. Format is: separated values of the form: # <service_type>:<service_name>:<endpoint_type> (string value) #cinder_catalog_info=volume:cinder:publicURL # Override service catalog lookup with template for cinder # endpoint e.g. http://localhost:8776/v1/%(project_id)s # (string value) #cinder_endpoint_template=<None> # Region name of this node (string value) #os_region_name=<None> # Location of ca certificates file to use for cinder client # requests. (string value) #cinder_ca_certificates_file=<None> # Number of cinderclient retries on failed http calls (integer # value) #cinder_http_retries=3 # Allow to perform insecure SSL requests to cinder (boolean # value) #cinder_api_insecure=false # Allow attach between instance and volume in different # availability zones. (boolean value) #cinder_cross_az_attach=true Neutron:: [DEFAULT] # URL for connecting to neutron (string value) #neutron_url=http://127.0.0.1:9696 # Timeout value for connecting to neutron in seconds (integer # value) #neutron_url_timeout=30 # Username for connecting to neutron in admin context (string # value) #neutron_admin_username=<None> # Password for connecting to neutron in admin context (string # value) #neutron_admin_password=<None> # Tenant id for connecting to neutron in admin context (string # value) #neutron_admin_tenant_id=<None> # Tenant name for connecting to neutron in admin context. This # option is mutually exclusive with neutron_admin_tenant_id. # Note that with Keystone V3 tenant names are only unique # within a domain. (string value) #neutron_admin_tenant_name=<None> # Region name for connecting to neutron in admin context # (string value) #neutron_region_name=<None> # Authorization URL for connecting to neutron in admin context # (string value) #neutron_admin_auth_url=http://localhost:5000/v2.0 # If set, ignore any SSL validation issues (boolean value) #neutron_api_insecure=false # Authorization strategy for connecting to neutron in admin # context (string value) #neutron_auth_strategy=keystone # Name of Integration Bridge used by Open vSwitch (string # value) #neutron_ovs_bridge=br-int # Number of seconds before querying neutron for extensions # (integer value) #neutron_extension_sync_interval=600 # Location of CA certificates file to use for neutron client # requests. (string value) #neutron_ca_certificates_file=<None> and Glance:: [DEFAULT] # Default glance hostname or IP address (string value) #glance_host=$my_ip # Default glance port (integer value) #glance_port=9292 # Default protocol to use when connecting to glance. Set to # https for SSL. (string value) #glance_protocol=http # A list of the glance api servers available to nova. Prefix # with https:// for ssl-based glance api servers. # ([hostname|ip]:port) (list value) #glance_api_servers=$glance_host:$glance_port # Allow to perform insecure SSL (https) requests to glance # (boolean value) #glance_api_insecure=false # Number of retries when downloading an image from glance # (integer value) #glance_num_retries=0 Many of these options such as `neutron_extension_sync_interval` or `cinder_catalog_info` are specific to the clients and will remain. However some such as `*_ca_certificates` (Note: Glance doesn't have one) `*_api_insecure` are common and will be loaded by the helper functions. To facilitate this the proposal is to group related client functions into their own ini section rather than prefix them in the DEFAULT section. An example would be:: [neutron] certfile = '/path/to/client.crt' keyfile = '/path/to/key.key' cafile = '/path/to/ca.crt' insecure = False timeout = 300 auth_name = v2password auth_url = 'http://keystone:5000/v2.0/ user_name = 'user' password = 'pass' tenant_name = 'tenn' Note: the use of `[neutron]` is purely an example, what the sections are called is left undefined for now. Using these options then looks something like:: from keystoneclient.auth import conf from keystoneclient import session from neutronclient.v2_0 import client option_group = 'neutron' sess = session.Session.load_from_conf_options(CONF, option_group) sess.auth = conf.plugin_from_conf(CONF, option_group) client = client.Client(session=sess) In the case where authentication is not needed (using the user's authentication) the auth plugin would be provided by auth_token middleware or constructible from those headers. For simplicity it would be good to move the other non-standard options into this same ini group, however that is left open for now. Alternatives ------------ Essentially the alternative is to go on manually supporting the options for the individual clients. This leads to shortcomings such as the current inability to use client certificates to do inter-service communication and the inability to set glance CA certificates from configuration. With the standardization happening in the clients already Nova could maintain it's own config loading scheme however for consistency across the projects it would be better to just have one defined scheme. It also means that as new options are added Nova would automatically gain the ability to use these options if set in config. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- This proposal will give deployers more control over the security settings of the clients and allow continuing improvements in security without each option being additionally supported by nova. It will go most of the way to allowing SSL everywhere deployments and allow a new range of authentication mechanisms to be used for server interaction. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- Configuration changes are well defined above. The exact names of these are currently still in review in keystoneclient. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: jamielennox Other contributors: Work Items ---------- The majority of work to implement this will not be done in nova. * Finalize the config and authentication loading in keystoneclient * Convert cinderclient, neturonclient and glanceclient to use the session object. * Change nova to instantiate client objects with the session. Dependencies ============ This proposal will requires ongoing work across at least 3 different client projects. The intention of raising this spec now is to make sure that the end goal is agreed upon by the servers rather than going and implementing the client side only to find that Nova and others are unwilling to change. There is still time to affect things like option names in keystoneclient. Testing ======= As applicable changes to configuration should be mirrored in devstack and gate testing as well as updating any affected unit tests. As we are changing the default configuration options the continual passing of gate tests will be good indication that the changes are working. Documentation Impact ==================== The configuration options for the client related options are going to need to be changed and the old ones deprecated. References ========== * Session objects: http://www.jamielennox.net/blog/2014/02/24/client-session-objects/ * cinderclient use session object: https://review.openstack.org/#/c/95986/ * Create a session object from a config file: https://review.openstack.org/#/c/95015/ * Create an auth plugin from a config file: https://review.openstack.org/#/c/79542/ ",,331,0
openstack%2Fnova-specs~master~I19ef76c2c5aa127fa33f5a163bcdca46d6475f24,openstack/nova-specs,master,I19ef76c2c5aa127fa33f5a163bcdca46d6475f24,Support pci passthrough device hotplug,ABANDONED,2014-04-22 14:34:41.000000000,2014-07-16 11:20:03.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 6772}, {'_account_id': 9847}]","[{'number': 1, 'created': '2014-04-22 14:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a49bd3bf35732749225602b38f6ce04d51d111f4', 'message': 'Support pci passthrough device hotplug\n\nAdd the ability to hotplug and hotunplug a pci passthrough device\nto an instance.\n\nblueprint pci-hotplug\n\nChange-Id: I19ef76c2c5aa127fa33f5a163bcdca46d6475f24\n'}, {'number': 2, 'created': '2014-04-22 14:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/596e915993a63c5096f7a8f2fe0385da2c13e469', 'message': 'Support pci passthrough device hotplug\n\nAdd the ability to hotplug and hotunplug a pci passthrough device\nto an instance.\n\nblueprint pci-hotplug\n\nChange-Id: I19ef76c2c5aa127fa33f5a163bcdca46d6475f24\n'}, {'number': 3, 'created': '2014-04-23 05:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8d36f166b56b76f055df16bde992e37593c33b36', 'message': 'Support pci passthrough device hotplug\n\nAdd the ability to hotplug and hotunplug a pci passthrough device\nto an instance.\n\nblueprint pci-hotplug\n\nChange-Id: I19ef76c2c5aa127fa33f5a163bcdca46d6475f24\n'}, {'number': 4, 'created': '2014-04-23 05:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a73491dbcc43f4de1cf1b346310764f9d27be2ee', 'message': 'Support pci passthrough device hotplug\n\nAdd the ability to hotplug and hotunplug a pci passthrough device\nto an instance.\n\nblueprint pci-hotplug\n\nChange-Id: I19ef76c2c5aa127fa33f5a163bcdca46d6475f24\n'}, {'number': 5, 'created': '2014-04-23 05:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c4b1cc74307fc4182563a236dd088a91b9e394f3', 'message': 'Support pci passthrough device hotplug\n\nAdd the ability to hotplug and hotunplug a pci passthrough device\nto an instance.\n\nblueprint pci-hotplug\n\nChange-Id: I19ef76c2c5aa127fa33f5a163bcdca46d6475f24\n'}, {'number': 6, 'created': '2014-04-25 15:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/86b57af3c437525269deb56c644e7d2ab05dc29e', 'message': 'Support pci passthrough device hotplug\n\nAdd the ability to hotplug and hotunplug a pci passthrough device\nto an instance.\n\nblueprint pci-hotplug\n\nChange-Id: I19ef76c2c5aa127fa33f5a163bcdca46d6475f24\n'}, {'number': 7, 'created': '2014-05-05 02:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/541d38671bd05ae3fa4b73f1e1245f4173ee1211', 'message': 'Support pci passthrough device hotplug\n\nAdd the ability to hotplug and hotunplug a pci passthrough device\nto an instance.\n\nblueprint pci-hotplug\n\nChange-Id: I19ef76c2c5aa127fa33f5a163bcdca46d6475f24\n'}, {'number': 8, 'created': '2014-05-11 03:56:39.000000000', 'files': ['specs/juno/pci-hotplug-juno.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ea6e036d99e82a3ac1ce0490874f32145ad1530a', 'message': 'Support pci passthrough device hotplug\n\nAdd the ability to hotplug and hotunplug a pci passthrough device\nto an instance.\n\nblueprint pci-hotplug\n\nChange-Id: I19ef76c2c5aa127fa33f5a163bcdca46d6475f24\n'}]",22,89592,ea6e036d99e82a3ac1ce0490874f32145ad1530a,38,10,8,9847,,,0,"Support pci passthrough device hotplug

Add the ability to hotplug and hotunplug a pci passthrough device
to an instance.

blueprint pci-hotplug

Change-Id: I19ef76c2c5aa127fa33f5a163bcdca46d6475f24
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/92/89592/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/pci-hotplug-juno.rst'],1,a49bd3bf35732749225602b38f6ce04d51d111f4,bp/pci-hotplug,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== PCI passthrough hotplug ========================================== https://blueprints.launchpad.net/nova/+spec/pci-hotplug Currently, openstack only support pci passthrough statically before the instance is booted. This blueprint is aim to provide the ability to allow user to hotplug the pci passthrough device when the instance is running. Problem description =================== * An instance called ""green"", ""green"" has one or more passthrough pci device. Someday, one pci device becomes into failed. User can unplug the passthrough pci device and plug a normal one. * An instance called ""blue"", ""blue"" has a passthrough pci device(nic). Someday, we found one nic is not enough. We need more nics for more network throughout. User can plug another passthrough pci device(nic). Or maybe, we found two nics is a waste for the instance. The instance doesn't has so large network throughout, we can unplug one passthrough pci device(nic). Proposed change =============== * api to hot plug/unplug pci passthrough devices for an instance * api to query attached pci passthrough devices for an instance Alternatives ------------ None Data model impact ----------------- Need to add a new column in table ""pci_devices"" called ""inner_address"" to store the device address in the instance. Need to add a new column in table ""pci_devices"" called ""attachment_id"" to store an id to identify a pci attachment of the instance. REST API impact --------------- * API for hotplug a pci device V2 API specification: POST: v2/{tenant_id}/servers/{server_id}/os-pci_attachments V3 API specification: POST: v3/servers/{server_id}/os-pci_attachments JSON Request: { ""pciAttachment"": { ""pci_passthrough:alias"":""a1:2"" } } JSON Response: { ""pci_devices"": [ { ""attachment_id"":""a26887c6-c47b-4654-abb5-dfadf7d3f803"", ""serverId"": ""4d8c3732-a248-40ed-bebc-539a6ffd25c0"", ""dev_id"":""pci_0000_02_00_0"", ""address"":""0000:02:00.0"", ""inner_address"":""0000:03:00.0"", ""vendor_id"":""8086"", ""product_id"":""10c9"" }, { ""attachment_id"":""a26887c6-c47b-4654-abb5-dfadf7d3f704"", ""serverId"": ""4d8c3732-a248-40ed-bebc-539a6ffd25c0"", ""dev_id"":""pci_0000_02_00_1"", ""address"":""0000:02:00.1"", ""inner_address"":""0000:03:01.0"", ""vendor_id"":""8086"", ""product_id"":""10c9"" } ] } * API for hotunplug a pci device V2 API specification: DELETE: v2/{tenant_id}/servers/{server_id}/os-pci_attachments/{attachment_id} V3 API specification: DELETE: v3/servers/{server_id}/os-pci_attachments/{attachment_id} HTTP response codes: v2: Normal HTTP Response Code: 200 on success v3: Normal HTTP Response Code: 202 on success * API for query plugged pci devices of an instance V2 API specification: GET: v2/{tenant_id}/servers/{server_id}/os-pci_attachments V3 API specification: GET: v3/servers/{server_id}/os-pci_attachments JSON Response: { ""pciAttachment"": [ { ""attachment_id"":""a26887c6-c47b-4654-abb5-dfadf7d3f803"", ""serverId"": ""4d8c3732-a248-40ed-bebc-539a6ffd25c0"", ""dev_id"":""pci_0000_02_00_0"", ""address"":""0000:02:00.0"", ""inner_address"":""0000:03:00.0"", ""vendor_id"":""8086"", ""product_id"":""10c9"" }, { ""attachment_id"":""a26887c6-c47b-4654-abb5-dfadf7d3f803"", ""serverId"": ""4d8c3732-a248-40ed-bebc-539a6ffd25c0"", ""dev_id"":""pci_0000_02_00_1"", ""address"":""0000:02:00.1"", ""inner_address"":""0000:03:01.0"", ""vendor_id"":""8086"", ""product_id"":""10c9"" } ] } Security impact --------------- None Notifications impact -------------------- Add notification for the operation of plug/unplug pci passthrough device. Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: boh.ricky Work Items ---------- * query instance's pci passthrough device * hotplug pci passthrough device to an instance * hotunplug pci passthrough device to an instance Dependencies ============ * https://blueprints.launchpad.net/nova/+spec/pci-passthrough-base * https://wiki.openstack.org/wiki/Pci_passthrough Testing ======= Need to add tempest for the feature. Documentation Impact ==================== Need to document the APIs. References ========== None ",,186,0
openstack%2Fnova-specs~master~I2551fa5d0824e8dc5225a499f8aca3b7c33ce21a,openstack/nova-specs,master,I2551fa5d0824e8dc5225a499f8aca3b7c33ce21a,Blueprint for Monitoring IP Availability in Openstack Deployment,ABANDONED,2014-05-20 03:20:06.000000000,2014-07-16 11:19:22.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 6062}, {'_account_id': 7232}, {'_account_id': 9060}, {'_account_id': 10068}, {'_account_id': 10263}]","[{'number': 1, 'created': '2014-05-20 03:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f02ccb5de088d3df0bca1e7ee9a62d0ce9626b1c', 'message': 'Blueprint for Monitoring IP Availability in Openstack Deployment\n\nChange-Id: I2551fa5d0824e8dc5225a499f8aca3b7c33ce21a\n'}, {'number': 2, 'created': '2014-05-23 02:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1a5919dab7253acfba66c3b0d7c1287b7e6d99be', 'message': 'Blueprint for Monitoring IP Availability in Openstack Deployment\n\nChange-Id: I2551fa5d0824e8dc5225a499f8aca3b7c33ce21a\n'}, {'number': 3, 'created': '2014-05-31 02:49:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c3b086cd749d0da65254e187d3fd359761ea972f', 'message': 'Blueprint for Monitoring IP Availability in Openstack Deployment\n\nChange-Id: I2551fa5d0824e8dc5225a499f8aca3b7c33ce21a\n'}, {'number': 4, 'created': '2014-05-31 03:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/59b5efc1d97aaafd0ef22f3bdf950909ea7653d2', 'message': 'Blueprint for Monitoring IP Availability in Openstack Deployment\n\nChange-Id: I2551fa5d0824e8dc5225a499f8aca3b7c33ce21a\n'}, {'number': 5, 'created': '2014-06-02 21:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1364b0798e89de0327196ae22b375f782849b5d4', 'message': 'Blueprint for Monitoring IP Availability in Openstack Deployment\n\nChange-Id: I2551fa5d0824e8dc5225a499f8aca3b7c33ce21a\n'}, {'number': 6, 'created': '2014-06-02 22:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4ca9bf1c4497866fa2bcf81ff1cc5498ef32e114', 'message': 'Blueprint for Monitoring IP Availability in Openstack Deployment\n\nChange-Id: I2551fa5d0824e8dc5225a499f8aca3b7c33ce21a\n'}, {'number': 7, 'created': '2014-06-25 00:55:00.000000000', 'files': ['specs/juno/monitoring-ip-availability.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fc2d903998b05247ac9bc81530cc570f714b2657', 'message': 'Blueprint for Monitoring IP Availability in Openstack Deployment\n\nChange-Id: I2551fa5d0824e8dc5225a499f8aca3b7c33ce21a\n'}]",20,94299,fc2d903998b05247ac9bc81530cc570f714b2657,44,10,7,10263,,,0,"Blueprint for Monitoring IP Availability in Openstack Deployment

Change-Id: I2551fa5d0824e8dc5225a499f8aca3b7c33ce21a
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/99/94299/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/monitoring-ip-availability.rst'],1,f02ccb5de088d3df0bca1e7ee9a62d0ce9626b1c,bp/for,"================================================ List all the available IP present in all subnets ================================================ https://blueprints.launchpad.net/nova/+spec/monitoring-ip-availability Problem description =================== In an Openstack deployment monitoring usage of resource like compute, storage, network is critical. Having a way to keep track of these resources can be important so that proper actions can be taken in case a threshold is reached in resource consumption of these resources. This feature can be used to monitor IP availability in all the available subnets. Proposed change =============== A new command nova fixed-ip-list will be introduced with the parameter ‘available’ to display the list of available IP’s present in all the subnets. This can be a useful utility to monitor IP availability. 1. The change will consist of modification at the nova-api layer and the nova client side. 2. At the DB layer and the SQLAlchemy a new API will be added to list available IP’s. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- API for specifying available fixed ips. V2 API specification: POST: v2/{tenant_id}/os-fixed-ips/action Request parameters: * tenant_id: The ID for the tenant or account in a multi-tenancy cloud. * action : available Sample v2 request: POST: v2/1b4a75e0c54049518438ee3e514e1844/os-fixed-ips/available Where 1b4a75e0c54049518438ee3e514e1844 : tenant-id HTTP response codes: Normal HTTP Response Code: 200 on success Validation: ‘action’ must be ‘available’ Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- The parameter will be optional, so no other code needs to be changed. Implementation ============== Assignee(s) ----------- Primary assignee: Vilobh Meshram (vilobhmm@yahoo-inc.com) Work Items ---------- * Add an API to get the list of available IP’s for all subnets. * At the SQLAlchemy layer add an API to get the list of available IP’s for all subnets. * Changes at the nova-api layer to handle the request to list IP and invoke DB layer API. * Nova client changes to parse the command line options and invoke Nova API. Dependencies ============ None Testing ======= Tempest test to be added to verify available IP list. Documentation Impact ==================== Changes to be made to the Nova API documentation to include the new command fixed-ip-list and additional parameter ‘available' that can be passed in. References ========== None ",,122,0
openstack%2Fsecurity-doc~master~I0d40f5e25a8ef3c93bd86e90fefd0a1e6c55eb11,openstack/security-doc,master,I0d40f5e25a8ef3c93bd86e90fefd0a1e6c55eb11,Remove extra 'Code' in ch_dashboard,MERGED,2014-07-16 09:27:56.000000000,2014-07-16 11:16:18.000000000,2014-07-16 11:16:18.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2807}]","[{'number': 1, 'created': '2014-07-16 09:27:56.000000000', 'files': ['security-guide/ch_dashboard.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/f3f89b2859c9baae9a0415bf7dab5ef8d20c12a9', 'message': ""Remove extra 'Code' in ch_dashboard\n\nChange-Id: I0d40f5e25a8ef3c93bd86e90fefd0a1e6c55eb11\nCloses-Bug: #1342378\n""}]",0,107270,f3f89b2859c9baae9a0415bf7dab5ef8d20c12a9,8,3,1,6547,,,0,"Remove extra 'Code' in ch_dashboard

Change-Id: I0d40f5e25a8ef3c93bd86e90fefd0a1e6c55eb11
Closes-Bug: #1342378
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/70/107270/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_dashboard.xml'],1,f3f89b2859c9baae9a0415bf7dab5ef8d20c12a9,bug/1342378, <programlisting>CSRF_COOKIE_SECURE = True, <programlisting>Code CSRF_COOKIE_SECURE = True,1,1
openstack%2Fneutron~master~I882a9ec08ad47b195a0604b1bcb36a65b283faeb,openstack/neutron,master,I882a9ec08ad47b195a0604b1bcb36a65b283faeb,Set up brocadeport up to models,ABANDONED,2014-07-03 07:25:56.000000000,2014-07-16 11:15:15.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 9008}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-07-03 07:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8fa67f0400add4c30d4964688afe6cbde0be8669', 'message': 'Set up brocadeport up to models\n\nIn models for brocadeport for columns admin_state_up and network_id\nhave nullable=False, but it was skipped in migrations. Also vlan_id\nhave type Sring(10) instead of String(36) and there is a missing\nforeign key on network_id column.\n\nChange-Id: I882a9ec08ad47b195a0604b1bcb36a65b283faeb\nPartial-Bug: #1337185\n'}, {'number': 2, 'created': '2014-07-03 07:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ffee75cc54458f3c79f72d14876ee67c410022b7', 'message': 'Set up brocadeport up to models\n\nIn models for brocadeport for columns admin_state_up and network_id\nhave nullable=False, but it was skipped in migrations. Also vlan_id\nhave type Sring(10) instead of String(36) and there is a missing\nforeign key on network_id column.\n\nPartial-Bug: #1337185\n\nChange-Id: I882a9ec08ad47b195a0604b1bcb36a65b283faeb\n'}, {'number': 3, 'created': '2014-07-08 10:21:43.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/242c6433a3cd_set_up_brocadeport_to_models.py', 'neutron/db/migration/alembic_migrations/versions/HEAD'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a61660a5885249241526415c5842fa2a16a5067f', 'message': 'Set up brocadeport up to models\n\nIn models for brocadeport for columns admin_state_up and network_id\nhave nullable=False, but it was skipped in migrations. Also vlan_id\nhave type Sring(10) instead of String(36).\n\nPartial-Bug: #1337185\n\nChange-Id: I882a9ec08ad47b195a0604b1bcb36a65b283faeb\n'}]",0,104465,a61660a5885249241526415c5842fa2a16a5067f,52,19,3,7249,,,0,"Set up brocadeport up to models

In models for brocadeport for columns admin_state_up and network_id
have nullable=False, but it was skipped in migrations. Also vlan_id
have type Sring(10) instead of String(36).

Partial-Bug: #1337185

Change-Id: I882a9ec08ad47b195a0604b1bcb36a65b283faeb
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/104465/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/242c6433a3cd_set_up_brocadeport_to_models.py', 'neutron/db/migration/alembic_migrations/versions/HEAD']",2,8fa67f0400add4c30d4964688afe6cbde0be8669,bug/1337185,242c6433a3cd,2db5203cb7a9,63,1
openstack%2Fnova-specs~master~Ic9fe64da5c0a4c605ca9aae03de05520a62b880d,openstack/nova-specs,master,Ic9fe64da5c0a4c605ca9aae03de05520a62b880d,libvirt/linux_net refactor to work on FreeBSD,ABANDONED,2014-05-24 07:08:46.000000000,2014-07-16 11:14:38.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 6509}]","[{'number': 1, 'created': '2014-05-24 07:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b05b348ae59ca7f9c44a003fb2aecae5c3ee8cb8', 'message': 'libvirt/linux_net refactor to work on FreeBSD\n\nA proposal to implement freebsd_net and refactor libvirt.vif\nmodule not use use only linux_net, but allow to choose\nwhat network driver to use.\n\nChange-Id: Ic9fe64da5c0a4c605ca9aae03de05520a62b880d\n'}, {'number': 2, 'created': '2014-05-24 07:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1c34b5feb7c921b0645f0cc97ab08867c908ebbe', 'message': 'libvirt/linux_net refactor to work on FreeBSD\n\nA proposal to implement freebsd_net and refactor libvirt.vif\nmodule not use use only linux_net, but allow to choose\nwhat network driver to use.\n\nChange-Id: Ic9fe64da5c0a4c605ca9aae03de05520a62b880d\n'}, {'number': 3, 'created': '2014-06-30 16:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/753004f2bf4acee4a41dd4c7445a9fc5ef754aaf', 'message': 'libvirt/linux_net refactor to work on FreeBSD\n\nA proposal to implement freebsd_net and refactor libvirt.vif\nmodule not use use only linux_net, but allow to choose\nwhat network driver to use.\n\nChange-Id: Ic9fe64da5c0a4c605ca9aae03de05520a62b880d\n'}, {'number': 4, 'created': '2014-06-30 16:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f0dc86d2a17afc9aaca35b23f71b9818b5048106', 'message': 'libvirt/linux_net refactor to work on FreeBSD\n\nA proposal to implement freebsd_net and refactor libvirt.vif\nmodule not use use only linux_net, but allow to choose\nwhat network driver to use.\n\nChange-Id: Ic9fe64da5c0a4c605ca9aae03de05520a62b880d\n'}, {'number': 5, 'created': '2014-07-11 11:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/bd16040575c5caf15dd78e4b261ae06caaa88c19', 'message': 'libvirt/linux_net refactor to work on FreeBSD\n\nA proposal to implement freebsd_net and refactor libvirt.vif\nmodule not use use only linux_net, but allow to choose\nwhat network driver to use.\n\nChange-Id: Ic9fe64da5c0a4c605ca9aae03de05520a62b880d\n'}, {'number': 6, 'created': '2014-07-11 11:38:27.000000000', 'files': ['specs/juno/libvirt-linux-net-refactor-for-freebsd.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3dcc3fb07941b40d85461ca336e4b2f6fc396ac5', 'message': 'libvirt/linux_net refactor to work on FreeBSD\n\nA proposal to implement freebsd_net and refactor libvirt.vif\nmodule not use use only linux_net, but allow to choose\nwhat network driver to use.\n\nChange-Id: Ic9fe64da5c0a4c605ca9aae03de05520a62b880d\n'}]",11,95328,3dcc3fb07941b40d85461ca336e4b2f6fc396ac5,31,4,6,6509,,,0,"libvirt/linux_net refactor to work on FreeBSD

A proposal to implement freebsd_net and refactor libvirt.vif
module not use use only linux_net, but allow to choose
what network driver to use.

Change-Id: Ic9fe64da5c0a4c605ca9aae03de05520a62b880d
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/28/95328/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/libvirt-linux-net-refactor-for-freebsd.rst'],1,b05b348ae59ca7f9c44a003fb2aecae5c3ee8cb8,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================================ Refactor libvirt/linux_net integration to be portable to FreeBSD ================================================================ https://blueprints.launchpad.net/nova/+spec/libvirt-linux-net-refactor-for-freebsd The ultimate goal is to get Openstack working on FreeBSD host using the libvirt driver. Libvirt on FreeBSD supports Qemu and Bhyve. Independently of which driver will be used, it is still required to bring in the networking support for nova's libvirt driver. Problem description =================== Currently nova.virt.libvirt.vif imports and uses nova.network.linux_net directly. It is not flexible enough if we target non-Linux systems as a host, so it should be configurable which network driver will be used. Proposed change =============== The proposed appoach would be: - implement nova.network.freebsd_net with a minimal required feature set for libvirt.vif - refactor libvirt.vif to allow configure network driver to use instead of hardcoding 'linux_net' Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- It will require to attention from developers changing linux_net and libvirt.vif interfaces. Implementation ============== Assignee(s) ----------- Primary assignee: novel Work Items ---------- - Make nova test suite pass on FreeBSD - Implement freebsd_net with the essential features for libvirt.vif - Refactor libvirt.vif to allow pluging either linux_net, freebsd_net and potentially other drivers Dependencies ============ None Testing ======= Once the feature is complete, it would be useful to add gate tests on FreeBSD. Documentation Impact ==================== Need to document new options for controlling which network driver will be used by libvirt.vif. References ========== Blueprint created based on discussion of this change: https://review.openstack.org/#/c/85119/ ",,122,0
openstack%2Fnova-specs~master~I9e84e2086a3543ba36148cbec2b1dd7da7acb005,openstack/nova-specs,master,I9e84e2086a3543ba36148cbec2b1dd7da7acb005,Propose Compute Image Precaching Capability,ABANDONED,2014-04-07 19:25:03.000000000,2014-07-16 11:11:40.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1501}, {'_account_id': 1849}, {'_account_id': 2835}, {'_account_id': 4393}, {'_account_id': 4573}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6699}, {'_account_id': 8021}, {'_account_id': 8430}, {'_account_id': 9060}]","[{'number': 1, 'created': '2014-04-07 19:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ff2769c2b874fff7b9e65eb7dd541ba48060d3df', 'message': 'Spec for bp/compute-image-cache\n\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 2, 'created': '2014-04-07 19:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d6c46c6c2f2ec5850a39c09dc48e47adfe61ebb2', 'message': 'Spec for bp/compute-image-cache\n\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 3, 'created': '2014-04-10 16:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/122ccecc1382cb3073435e7608f7b79406c396b0', 'message': 'Spec for bp/compute-image-cache\n\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 4, 'created': '2014-04-14 16:07:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c316b3b6eb168b611097ffa5bbd87d209d2f554a', 'message': 'Propose Compute Image Precaching Capability (WORKINPROGRESS)\n\nSpec for bp/compute-image-cache.  Currently in progress while\nadmin API is added.  Other documentation is mostly in place\nfor review.\n\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 5, 'created': '2014-04-14 16:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e71e0a016a492ab06141d5bcccb532e8cd76d861', 'message': 'Propose Compute Image Precaching Capability (WORKINPROGRESS)\n\nSpec for bp/compute-image-cache.  Currently in progress while\nadmin API is added.  Other documentation is mostly in place\nfor review.\n\nblueprint compute-image-cache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 6, 'created': '2014-04-16 19:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ee289d886785d210becd5c72cc6a09d10dbdf6a9', 'message': 'Propose Compute Image Precaching Capability\n\nSpec for bp/compute-image-cache.\nadmin API added as part of latest review.\n\nblueprint compute-image-cache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 7, 'created': '2014-04-21 18:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/93cf81bb39eea8eda68e2f3913c93330c3f5f96d', 'message': 'Propose Compute Image Precaching Capability\n\nSpec for bp/compute-image-cache.\nadmin API added as part of latest review.\n\nblueprint compute-image-cache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 8, 'created': '2014-04-22 22:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e99e08df0700eb597e838d38814c0b92f2d441a4', 'message': 'Propose Compute Image Precaching Capability\n\nSpec for bp/compute-image-cache.\nadmin API added as part of latest review.\n\nblueprint compute-image-cache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 9, 'created': '2014-04-23 20:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/517a62b5f69f0af5fb7b861d732c6df9097fc66f', 'message': 'Propose Compute Image Precaching Capability\n\nSpec for bp/compute-image-cache.\nadmin API added as part of latest review.\n\nblueprint compute-image-cache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 10, 'created': '2014-05-07 20:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/87b2ae23891e6e9f1b05238b9301777925291cf5', 'message': 'Propose Compute Image Precaching Capability\n\nblueprint compute-image-cache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 11, 'created': '2014-05-22 00:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4357109aa586554fcaddb6768afca898268861a4', 'message': 'Propose Compute Image Precaching Capability\n\nblueprint compute-image-cache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 12, 'created': '2014-05-22 18:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/08c9d8217cf79769eb117b1a540fce5bdda34787', 'message': 'Propose Compute Image Precaching Capability\n\nblueprint compute-image-cache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 13, 'created': '2014-05-28 01:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/db3536c23b69312f771ff05954e0d6ece0e20043', 'message': 'Propose Compute Image Precaching Capability\n\nblueprint compute-image-precache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 14, 'created': '2014-06-05 21:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/bf22ceaa6e737ff8d534777c8ca559342d016d32', 'message': 'Propose Compute Image Precaching Capability\n\nblueprint compute-image-precache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 15, 'created': '2014-06-13 19:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2bc6c428401cf5f56c8804f8a7790b43e27f6264', 'message': 'Propose Compute Image Precaching Capability\n\nblueprint compute-image-precache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 16, 'created': '2014-07-02 17:41:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8f113481dfb7d6d89c0f134d5bf546feaa8593d8', 'message': 'Propose Compute Image Precaching Capability\n\nblueprint compute-image-precache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}, {'number': 17, 'created': '2014-07-08 22:16:34.000000000', 'files': ['specs/juno/compute-image-precache.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/977ee1e82dd091f9eb4329a18962466c6545ef83', 'message': 'Propose Compute Image Precaching Capability\n\nblueprint compute-image-precache\nChange-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005\n'}]",202,85792,977ee1e82dd091f9eb4329a18962466c6545ef83,143,15,17,8430,,,0,"Propose Compute Image Precaching Capability

blueprint compute-image-precache
Change-Id: I9e84e2086a3543ba36148cbec2b1dd7da7acb005
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/92/85792/17 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/compute-image-cache.rst'],1,ff2769c2b874fff7b9e65eb7dd541ba48060d3df,bp/compute-image-precache,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Compute Image Caching Capability ========================================== https://blueprints.launchpad.net/nova/+spec/compute-image-cache One of the most common operations in Openstack is to build servers. As part of builds, hosts need to download images. These images can be reasonably small (under 200MB) to very large (160GB). The size of the image can directly affect how long it takes to build a server. To improve the experience, prepopulating or caching images will allow servers to become active more quickly in the common cases. Also solving the problem where a captive customer has a special image which needs quick build times for scaling is desired. This document looks at building the necessary component infrastructure in the compute nodes to help solve these types of problems. Problem description =================== The basic problem being solved is faster build times at time of launch by eliminating download needs on hosts where possible. The two use cases being explored are: * Image caching of common images for public clouds. * Image caching of image(s) across a subset of fleet to allow fast build times for a subset of customers. In the common images case, the deployer picks the images which s/he wishes to cache and the end user sees the performance improvement based on launching within the selected set of hosts where the image is cached. In the subset case, the deployer works in conjunction with the user to pick image(s) which make sense to replicate across the fleet. Once an image(s) is picked it is then marked to recognized it special nature in meta-data. That information is then used to help propogate to the image to subest hosts. Proposed change =============== This blueprint focuses on changes needed at the compute to handle this solution. We are focusing on what is needed to change in compute from an RPC API perspective and any common infrastructure which other drivers may wish to share. We are currently keeping the proposed change to a bare minimum. The bare minimum being one request to cache an image on the host. def host_cache_image(ctxt, image_id, meta) ctxt - context permissions for the actions of the host to cache image_id - the glance uuid of the image that will be cached meta - meta information useful in downloading and caching image Alternatives ------------ Two alternatives were considered prior to the proposed solution above. Both solutions are currently in use in various forms in public clouds today. The first solution is to build VMs to cache the image and then delete the build using a targetted host mechanism. This is less than desireable for a couple of reasons. * The process requires a fair amount of book keeping and doesn't scale. * Hosts could be temporariliy fully utilized. As such launching a VM may not be an option even if caching is desired. The second option is to do this outside nova via script. This allows more flexibilty in download options and implementation. However, no common functions can be shared down the road between drivers. Also, the script would be prone to breaking do to changes in driver implementations along the way. For isntance, in the Xen implemetnation, cached images are recognized by the name ""Glance <uuid>"" if this ever changed, this would need to change in both the external script and nova. This breakdown is not preferred. Data model impact ----------------- There is no change to Data model from a compute perspective. REST API impact --------------- There is no change to the external API from a compute perspective. Security impact --------------- The download of images will follow normal security authentication procedures like a VM launch. As such there are NO new security impacts to the compute portion of the implementation. The image being downloaded must be accessible to the context provided in the rpc call. The accesibility can be because 1) the account created the image or 2) the account has access to the image via image-sharing/account approval. It will be up to the deployer to determine the best method to provide access so the image is downloable. * Does this change touch sensitive data such as tokens, keys, or user data? NO. * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? NO. * Does this change involve cryptography or hashing? NO. * Does this change require the use of sudo or any elevated privileges? NO. * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. NO. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. NO. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ The performance impact from a host perspective is the same as the time and network bandwidth it takes to launch a VM of the image type without caching on a host. We do not anticipate this changing what would be the impact of a single download. The feature overall does allow for downloads to run in parallel (even encourages it). This means there is a larger system implication. Deployers will need to recognize how many images and boxes they want to cache at a single time. This affects load on glance servers or other servers providing images. See https://review.openstack.org/#/c/85768/ of other service being affected. The performance could significantly speed up the problem of distributing images to many hosts and subsequent build times. Other deployer impact --------------------- None. Developer impact ---------------- The recommended way to implement the new API is to leverage the already existing download strategies to computes. Ideally if the code is already modularized then hook the API to the download and caching portions of the driver code. If the code is not modularized then look at ways that the hooking can still occur. For instance, in the xen driver, it may be necessary to create a stub VM to leverage pre-existing code which already performs both bittorrent and glance downloading. Implementation ============== See developer impact. This is largely the implementaiton of a single API at this point. Assignee(s) ----------- Primary assignee: christopher.lefelhoc@rackspace.com Other contributors: alaski Work Items ---------- - Create api and hooks for drivers - Create xenapi driver reference implementation Dependencies ============ The blueprint has a dependency on the following to call the new API: - https://blueprints.launchpad.net/nova/+spec/image-precacher Testing ======= - Unit Tests - TBD integration test(s) with image-precacher Documentation Impact ==================== Need to document new service and interactions with nova-compute. References ========== None ",,194,0
openstack%2Fnova-specs~master~Ib729572431d343ce240079e4af33f396a935e7ba,openstack/nova-specs,master,Ib729572431d343ce240079e4af33f396a935e7ba,Add username in the response of nova list command,ABANDONED,2014-05-01 22:53:14.000000000,2014-07-16 11:09:24.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1297}, {'_account_id': 1501}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4573}, {'_account_id': 6167}, {'_account_id': 8515}, {'_account_id': 9608}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-05-01 22:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ec07772bccb00884fedee0dae5fd134a93eaec24', 'message': ""Adding a new bluepring for Juno\nhttps://blueprints.launchpad.net/nova/+spec/add-username-in-nova-list-response\n\nChange-Id: Ib729572431d343ce240079e4af33f396a935e7ba\nDescription: Currently nova list command does not show which user the particular VM belong too. In enterprise deployments, knowing which user booted the VM could be very useful for the cluster administrator. This will save admin a lot of manual steps before knowing the owner of the VM. In this blueprint, we plan to add an additional column 'username' to 'nova list' output which will facilitate cluster maintenance for the administrator\n""}, {'number': 2, 'created': '2014-05-02 21:46:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/73b508148bf71547800a70654e945f1ee512cb42', 'message': ""Adding a new bluepring for Juno\nhttps://blueprints.launchpad.net/nova/+spec/add-username-in-nova-list-response\n\nChange-Id: Ib729572431d343ce240079e4af33f396a935e7ba\nDescription: Currently nova list command does not show which user the particular VM belong too. In enterprise deployments, knowing which user booted the VM could be very useful for the cluster administrator. This will save admin a lot of manual steps before knowing the owner of the VM. In this blueprint, we plan to add an additional column 'username' to 'nova list' output which will facilitate cluster maintenance for the administrator\n""}, {'number': 3, 'created': '2014-05-08 18:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/38926f9160f3924d3287aca4497711605a58b26e', 'message': ""Add username in the response of nova list command\n\nDescription: Currently nova list command does not show which user the\nparticular VM belong too. In enterprise deployments, knowing which user\nbooted the VM could be very useful for the cluster administrator.\nThis will save admin a lot of manual steps before knowing the owner of\nthe VM. In this blueprint, we plan to add an additional column\n'username' to 'nova list' output which will facilitate cluster\nmaintenance for the administrator\n\nhttps://blueprints.launchpad.net/nova/+spec/add-username-in-nova-list-response\n\nChange-Id: Ib729572431d343ce240079e4af33f396a935e7ba\n""}, {'number': 4, 'created': '2014-06-30 17:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a912399c36adba14d5165658628a50c0c15bff4a', 'message': ""Add username in the response of nova list command\n\nDescription: Currently nova list command does not show which user the\nparticular VM belong too. In enterprise deployments, knowing which user\nbooted the VM could be very useful for the cluster administrator.\nThis will save admin a lot of manual steps before knowing the owner of\nthe VM. In this blueprint, we plan to add an additional column\n'username' to 'nova list' output which will facilitate cluster\nmaintenance for the administrator\n\nhttps://blueprints.launchpad.net/nova/+spec/add-username-in-nova-list-response\n\nChange-Id: Ib729572431d343ce240079e4af33f396a935e7ba\n""}, {'number': 5, 'created': '2014-06-30 17:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/28f220caa6323b9073f83634dfa0d047c892f38d', 'message': ""Add username in the response of nova list command\n\nDescription: Currently nova list command does not show which user the\nparticular VM belong too. In enterprise deployments, knowing which user\nbooted the VM could be very useful for the cluster administrator.\nThis will save admin a lot of manual steps before knowing the owner of\nthe VM. In this blueprint, we plan to add an additional column\n'username' to 'nova list' output which will facilitate cluster\nmaintenance for the administrator\n\nhttps://blueprints.launchpad.net/nova/+spec/add-username-in-nova-list-response\n\nChange-Id: Ib729572431d343ce240079e4af33f396a935e7ba\n""}, {'number': 6, 'created': '2014-06-30 22:56:39.000000000', 'files': ['specs/juno/username-in-nova-list-for-admin-purpose.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a962033435fb520202e6c6e59629a8e9a0cfa630', 'message': ""Add username in the response of nova list command\n\nDescription: Currently nova list command does not show which user the\nparticular VM belong too. In enterprise deployments, knowing which user\nbooted the VM could be very useful for the cluster administrator.\nThis will save admin a lot of manual steps before knowing the owner of\nthe VM. In this blueprint, we plan to add an additional column\n'username' to 'nova list' output which will facilitate cluster\nmaintenance for the administrator\n\nhttps://blueprints.launchpad.net/nova/+spec/add-username-in-nova-list-response\n\nChange-Id: Ib729572431d343ce240079e4af33f396a935e7ba\n""}]",23,91697,a962033435fb520202e6c6e59629a8e9a0cfa630,56,11,6,8515,,,0,"Add username in the response of nova list command

Description: Currently nova list command does not show which user the
particular VM belong too. In enterprise deployments, knowing which user
booted the VM could be very useful for the cluster administrator.
This will save admin a lot of manual steps before knowing the owner of
the VM. In this blueprint, we plan to add an additional column
'username' to 'nova list' output which will facilitate cluster
maintenance for the administrator

https://blueprints.launchpad.net/nova/+spec/add-username-in-nova-list-response

Change-Id: Ib729572431d343ce240079e4af33f396a935e7ba
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/97/91697/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/username-in-nova-list-for-admin-purpose.rst'],1,ec07772bccb00884fedee0dae5fd134a93eaec24,bp/s,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Add username in nova list response for administration purposes ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/example Currently nova list command does not show which user the particular VM belong too. In enterprise deployments, knowing which user booted the VM could be very useful for the cluster administrator. This will save admin a lot of manual steps before knowing the user. For members of a project/tenant, it can be helpful to see which user the other VMs in a project belong to. Problem description =================== In the current implementation, nova list command does not show any information about the user that booted the VM. In an enterprise deployment, when an administrator receives a request from a user about his VM, he should have an easy way to get that information without manually looking at the database. Hence, it will be nice to have that information in the output of 'nova list' command. Proposed change =============== * Add an extension to nova api that will call keystone for user-list and insert username parameter in the response. * Modify novaclient shell.py to check if servers/detail response contains username attribute and if it does, include it in the displayed response table. Alternatives ------------ Data model impact ----------------- None REST API impact --------------- * GET /servers/detail response will contain additional parameter: username Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: spandhe Other contributors: None Work Items ---------- * Add an extension to nova api to fetch username information from keystone * Modify shell.py to display 'username' information, if received from the server. Dependencies ============ None Testing ======= * The username information is displayed in 'nova list' output if server response contains 'username' attribute Documentation Impact ==================== None References ========== None ",,108,0
openstack%2Fironic-specs~master~I7b701a87b3ed65996fe6e28ecb350d3aa64d73da,openstack/ironic-specs,master,I7b701a87b3ed65996fe6e28ecb350d3aa64d73da,Generic Hardware Discovery Bits,ABANDONED,2014-06-25 15:46:54.000000000,2014-07-16 11:03:41.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 6899}, {'_account_id': 7419}, {'_account_id': 7537}, {'_account_id': 7699}, {'_account_id': 8029}, {'_account_id': 8399}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 11297}]","[{'number': 1, 'created': '2014-06-25 15:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4243d8726d18cf403e8ef56c598de66e22953f1b', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 2, 'created': '2014-06-25 16:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/e72395825ccdaea8242d03d8a748dd9b8be047ac', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 3, 'created': '2014-06-26 13:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/dfd84c5a2af08d279a5343b716f781ab98f4be9c', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 4, 'created': '2014-06-26 14:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/115037946e1b3024946b877ff9ec81671e4f13b6', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 5, 'created': '2014-06-26 16:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4a2b10a9bdd2880760509244e8a54ae66e3d6c29', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 6, 'created': '2014-06-26 16:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/b74deea077e95acebf8e2e4c33fda614df683ff7', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 7, 'created': '2014-06-26 18:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/d3c2197af02ab4535745397b568be66363c9edde', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 8, 'created': '2014-06-27 11:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/0e186a885ab8f4bfd746027e44382aaf8ffe3fea', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 9, 'created': '2014-06-27 12:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/f3307f4795b79f67978edc45932fc12fa1cd1939', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 10, 'created': '2014-06-27 13:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/11ab5c019dd17806834c6d637c0d3a6a4fa5fff8', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 11, 'created': '2014-06-27 18:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/d51c2343175fdbf54fa7a5106145f19bd2c8835f', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 12, 'created': '2014-07-14 09:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/3ce3f8dfc81785885e4cc8528a748ffc5fd8d333', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 13, 'created': '2014-07-14 09:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/8bf94952ce54f5d0cc57050b537826e1dc50d257', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 14, 'created': '2014-07-14 14:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/36122c9d05f68b7b49f56da42e259709f7829cd1', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 15, 'created': '2014-07-15 12:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/185369336558b5c517a90a08f8484c123e67f24a', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}, {'number': 16, 'created': '2014-07-16 06:01:30.000000000', 'files': ['specs/juno/generic-hardware-discovery.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/06860ef78c1b932008cb8ab9691e5bede2f16081', 'message': ""Generic Hardware Discovery Bits\n\nThis specification tries to set some common ground for future work on\nhardware discovery, so that we don't end up with bunch of completely\nincompatible implementations of the same things.\n\nChange-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da\n""}]",85,102565,06860ef78c1b932008cb8ab9691e5bede2f16081,86,14,16,10239,,,0,"Generic Hardware Discovery Bits

This specification tries to set some common ground for future work on
hardware discovery, so that we don't end up with bunch of completely
incompatible implementations of the same things.

Change-Id: I7b701a87b3ed65996fe6e28ecb350d3aa64d73da
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/65/102565/16 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/generic-hardware-discovery.rst'],1,4243d8726d18cf403e8ef56c598de66e22953f1b,discover_properties,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Generic Hardware Discovery Bits ========================================== https://blueprints.launchpad.net/ironic/+spec/example TODO This specification tries to set some common ground for future work on hardware discovery, so that we don't end up with bunch of completely incompatible implementations of the same things. Problem description =================== Ironic will have to support auto-discovery of new nodes, as well as discovery of hardware specs of a server (either new or existing). Several approaches are expected to arrive for solving these, including, but not limited to, Ironic Python Agent. Use cases for hardware discovery may include: * Enrollment of new servers in data center * Keeping up-to-date information about node hardware within node metadata * Responding to basic hardware changes, e.g. new hard drive, added RAM etc Proposed change =============== NOTE: Some of these changes were shamelessly borrowed from IPA spec: https://review.openstack.org/#/c/98506/ * Write common code for storing hardware inventories in Node.extra field. Format is dicussed in `Data model impact` section. Any external agent, performing hardware discovery of new hardware (or when it does not know the ID) will issue request to a new endpoint `/nodes/autodiscovery` (see below). Any external agent, performing hardware specs update for the Node, which ID it knows, will just send `node-update` request, changing Node.extras. * Create new boolean field `Node.discovered` and make possible filtering by it in API. TODO: when to clear this field? On cleaning maintenance? On first deploy? * Create endpoint `/nodes/autodiscovery`. Ramdisk agent will post all known hardware specs to it. There can be two kinds of outcome: * Node is not known to Ironic. Ironic will create a new Node object with given specs and set `maintenance=True`, `discovered=True`. Result of call is new Node UUID. * Node is already known to Ironic. Hardware specs for this Node are updated with new data. Result is again Node UUID. * Write code, that allows conductor server to be used as ""catch-all"" PXE point for booting any unknown servers. TODO: need exact steps here TODO#2: should we mention iPXE and depend on it for generating configuration in runtime? TODO#3: list security considerations. It makes sense not to specify exact solution here, just give some directions. Alternatives ------------ * We can continue to enroll and update nodes manually. That may be hard or even impossible in a large data center. Data model impact ----------------- Changes which require modifications to the data model often have a wider impact on the system. The community often has strong opinions on how the data model should be evolved, from both a functional and performance perspective. It is therefore important to capture and gain agreement as early as possible on any proposed changes to the data model. Questions which need to be addressed by this section include: * What new data objects and/or database schema changes is this going to require? * What database migrations will accompany this change? * How will the initial set of new data objects be generated? For example, if you need to take into account existing instances, or modify other existing data, describe how that will work. REST API impact --------------- Each API method which is either added or changed should have the following * Specification for the method * A description of what the method does, suitable for use in user documentation. * Method type (POST/PUT/GET/DELETE/PATCH) * Normal http response code(s) * Expected error http response code(s) * A description for each possible error code should be included. Describe semantic errors which can cause it, such as inconsistent parameters supplied to the method, or when a resource is not in an appropriate state for the request to succeed. Errors caused by syntactic problems covered by the JSON schema defintion do not need to be included. * URL for the resource * Parameters which can be passed via the url, including data types * JSON schema definition for the body data if allowed * JSON schema definition for the response data if any * Example use case including typical API samples for both data supplied by the caller and the response * Discuss any policy changes, and discuss what things a deployer needs to think about when defining their policy. * Is a corresponding change in the client library and CLI necessary? Note that the schema should be defined as restrictively as possible. Parameters which are required should be marked as such and only under exceptional circumstances should additional parameters which are not defined in the schema be permitted. Use of free-form JSON dicts should only be permitted where necessary to allow divergence in the drivers. In such case, the drivers must expose the expected content of the JSON dict and an ability to validate it. Reuse of existing predefined parameter types is highly encouraged. Driver API impact ----------------- Changes which affect the driver API have a direct effect on all drivers, and often have a wider impact on the system. There are several things to consider in this section. * Is it a change to a ""core"" or ""common"" API? * Can all drivers support it initially, or is it specific to a particular vendor's hardware? * How will it be tested in the gate and in third-party CI systems? * If adding a new interface, explain the intended scope of the proposed interface, what functionality it enables, why it is needed, and whether it is supported by current drivers. * If adding or changing a method on an existing interface, the impact on existing drivers should be explored. * Will the new interface or method need to be invoked when the hash ring rebalances, for example to rebuild local state on a new conductor service? Nova driver impact ------------------ Chances are, if this change affects the REST or Driver APIs, it will also affect the Nova driver in some way. Questions which need to be addressed in this section include: * What is the impact on Nova? * If this change is enabling new functionality exposed via Nova, this section should cite the relevant components within other Nova drivers that alraedy implement this. * Ironic and Nova services must be upgradable independently. If the change affects existing functionality of the nova.virt.ironic driver, how will an upgrade be performed? How will it be tested? Security impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or credentials? * Does this change affect the accessibility of hardware managed by Ironic? * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Other end user impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-ironicclient? What does the user interface there look like? * Will this require changes in the Horizon panel, or any other OpenStack project? Scalability impact ------------------ Describe any potential scalability impact on the system, for example any increase in network, RPC, or database traffic, or whether the feature requires synchronization across multiple services. Examples of things to consider here include: * Additional network calls to internal or external services. * Additional disk or network traffic that will be required by the feature. * Any change in the number of physical nodes which can be managed by each conductor service. Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A periodic task might look like a small addition, but all periodic tasks run in a single thread so a periodic task that takes a long time to run will have an effect on the timing of other periodic tasks. * A small change in a utility function or a commonly used decorator can have a large impact on performance. * Calls which result in one or more database queries (whether in the api or conductor services) can have a profound impact on performance when called in critical sections of the code. * Will the change include any TaskManager locking, and if so what considerations are there on holding the lock? * How will the new code be affected if the hash ring rebalances while it is running? Other deployer impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example, a flag that other hardware drivers might want to implement as well)? Are the default values appropriate for production? Provide an explanation of why these defaults are reasonable. * Is this a change that takes immediate effect after it's merged, or is it something that has to be explicitly enabled? * If this change adds a new service that deployers will be requried to run, how would it be deployed? Describe the expected topology, for example, what network connectivity the new service would need, what service(s) it would interact with, how many should run relative to the size of the deployment, and so on. * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we were to change the directory that PXE boot files were stored in, how would we update existing boot files created before the change landed? Would we require deployers to manually move them? Is there a special case in the code, which would be removed after some deprecation period? Would we require operators to delete and recreate all instances in order to perform the upgrade? Developer impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other drivers would implement the feature is required. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in Ironic, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Ironic, document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? * Does this feature target specific hardware? If so, is it a common standard (eg IPMI) or a vendor-specific implementation (eg iLO)? Testing ======= Please discuss how the change will be tested. We especially want to know what tempest tests will be added. It is assumed that unit test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit tests are sufficient and we don't need to add more tempest tests would need to be included. Is this untestable in gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc)? Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to ",,390,0
openstack%2Fnova-specs~master~If79cdcdc31b570e2d1e16c5ed014242c961417b8,openstack/nova-specs,master,If79cdcdc31b570e2d1e16c5ed014242c961417b8,Add support for cinder scheduler hints,ABANDONED,2014-07-11 11:05:10.000000000,2014-07-16 11:03:09.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 6737}]","[{'number': 1, 'created': '2014-07-11 11:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2cde9f1f6be9fbda311e7f63e5382baf30900453', 'message': 'Add support for cinder scheduler hints\n\nWhen booting an instance with nova boot --block-device-mapping i.e.\nallowing Nova to autocreate storage for a new instance, there is\ncurrently no way for Nova to hint to the Cinder scheduler how it\nshould go about creating/placing this volumes. This blueprint\nproposes adding support for storing cinder scheduler hints in Nova\nflavor extra-specs and adding in support for those hints to be\npassed to Cinder when volumes are created.\n\nChange-Id: If79cdcdc31b570e2d1e16c5ed014242c961417b8\n'}, {'number': 2, 'created': '2014-07-14 15:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5915cfe6e7023804d3ec3138c52b63d77b98c0a7', 'message': 'Add support for cinder scheduler hints\n\nWhen booting an instance with nova boot --block-device i.e.\nasking Nova to auto-create storage for a new instance, there\nis currently no way for Nova to hint to the Cinder scheduler\nhow it should go about creating/placing this volumes. This\nspecification proposes adding support for storing cinder\nextra_specs in Nova flavors and passing them to Cinder when\nvolumes are created.\n\nChange-Id: If79cdcdc31b570e2d1e16c5ed014242c961417b8\n'}, {'number': 3, 'created': '2014-07-14 15:42:21.000000000', 'files': ['specs/juno/add-support-for-cinder-scheduler-hints.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/75ce0012edf24610862f2111e96a2dc6fd5d4190', 'message': 'Add support for cinder scheduler hints\n\nWhen booting an instance with nova boot --block-device i.e.\nasking Nova to auto-create storage for a new instance, there\nis currently no way for Nova to hint to the Cinder scheduler\nhow it should go about creating/placing this volumes. This\nspecification proposes adding support for storing cinder\nextra_specs in Nova flavors and passing them to Cinder when\nvolumes are created.\n\nChange-Id: If79cdcdc31b570e2d1e16c5ed014242c961417b8\n'}]",0,106330,75ce0012edf24610862f2111e96a2dc6fd5d4190,13,4,3,6737,,,0,"Add support for cinder scheduler hints

When booting an instance with nova boot --block-device i.e.
asking Nova to auto-create storage for a new instance, there
is currently no way for Nova to hint to the Cinder scheduler
how it should go about creating/placing this volumes. This
specification proposes adding support for storing cinder
extra_specs in Nova flavors and passing them to Cinder when
volumes are created.

Change-Id: If79cdcdc31b570e2d1e16c5ed014242c961417b8
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/30/106330/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/add-support-for-cinder-scheduler-hints.rst'],1,2cde9f1f6be9fbda311e7f63e5382baf30900453,specs/add-cinder-scheduler-support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================================================== Add support for providing cinder scheduler hints when creating volumes ====================================================================== https://blueprints.launchpad.net/nova/+spec/add-support-for-cinder-scheduler-hints When booting an instance with nova boot --block-device-mapping i.e. allowing Nova to autocreate storage for a new instance, there is currently no way for Nova to hint to the Cinder scheduler how it should go about creating/placing this volumes. This blueprint proposes adding support for storing cinder scheduler hints in Nova flavor extra-specs and adding in support for those hints to be passed to Cinder when volumes are created. Problem description =================== A detailed description of the problem: * For a new feature this might be use cases. Ensure you are clear about the actors in each use case: End User vs Deployer * For a major reworking of something existing it would describe the problems in that feature that are being addressed. Proposed change =============== Here is where you cover the change you propose to make in detail. How do you propose to solve this problem? If this is one part of a larger effort make it clear where this piece ends. In other words, what's the scope of this effort? Alternatives ------------ I am not aware of any alternatives to achieve this. The Nova cinderclient does currently support supplying an availability-zone to Cinder but this does not provide much granularity in terms of volume placement based on type/capacity/tiering or indeed any of the filters available through the cinder scheduler. Data model impact ----------------- Changes which require modifications to the data model often have a wider impact on the system. The community often has strong opinions on how the data model should be evolved, from both a functional and performance perspective. It is therefore important to capture and gain agreement as early as possible on any proposed changes to the data model. Questions which need to be addressed by this section include: * What new data objects and/or database schema changes is this going to require? * What database migrations will accompany this change. * How will the initial set of new data objects be generated, for example if you need to take into account existing instances, or modify other existing data describe how that will work. REST API impact --------------- Each API method which is either added or changed should have the following * Specification for the method * A description of what the method does suitable for use in user documentation * Method type (POST/PUT/GET/DELETE) * Normal http response code(s) * Expected error http response code(s) * A description for each possible error code should be included describing semantic errors which can cause it such as inconsistent parameters supplied to the method, or when an instance is not in an appropriate state for the request to succeed. Errors caused by syntactic problems covered by the JSON schema defintion do not need to be included. * URL for the resource * Parameters which can be passed via the url * JSON schema definition for the body data if allowed * JSON schema definition for the response data if any * Example use case including typical API samples for both data supplied by the caller and the response * Discuss any policy changes, and discuss what things a deployer needs to think about when defining their policy. Example JSON schema definitions can be found in the Nova tree http://git.openstack.org/cgit/openstack/nova/tree/nova/api/openstack/compute/schemas/v3 Note that the schema should be defined as restrictively as possible. Parameters which are required should be marked as such and only under exceptional circumstances should additional parameters which are not defined in the schema be permitted (eg additionaProperties should be False). Reuse of existing predefined parameter types such as regexps for passwords and user defined names is highly encouraged. Security impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Notifications impact -------------------- Please specify any changes to notifications. Be that an extra notification, changes to an existing notification, or removing a notification. Other end user impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-novaclient? What does the user interface there look like? Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A periodic task might look like a small addition but if it calls conductor or another service the load is multiplied by the number of nodes in the system. * Scheduler filters get called once per host for every instance being created, so any latency they introduce is linear with the size of the system. * A small change in a utility function or a commonly used decorator can have a large impacts on performance. * Calls which result in a database queries (whether direct or via conductor) can have a profound impact on performance when called in critical sections of the code. * Will the change include any locking, and if so what considerations are there on holding the lock? Other deployer impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * If this change is a new binary, how would it be deployed? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? Developer impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other hypervisors would implement the feature is required. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in nova, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Nova (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Testing ======= Please discuss how the change will be tested. We especially want to know what tempest tests will be added. It is assumed that unit test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit tests are sufficient and we don't need to add more tempest tests would need to be included. Is this untestable in gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc). Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to ",,302,0
openstack%2Fnova-specs~master~I71b79446ba9c052b7fd66eeb88944757728c79d0,openstack/nova-specs,master,I71b79446ba9c052b7fd66eeb88944757728c79d0,WIP: Change api-microversions-alt,ABANDONED,2014-07-03 02:22:38.000000000,2014-07-16 11:00:00.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8556}]","[{'number': 1, 'created': '2014-07-03 02:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/61c196b6605d2dfd792f25f42f810511718fc122', 'message': 'WIP: Change api-microversions-alt\n\nThis changes api-microversions-alt spec based on the discussions.\n\nChange-Id: I71b79446ba9c052b7fd66eeb88944757728c79d0\n'}, {'number': 2, 'created': '2014-07-03 02:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/31b740e54ac6aec544953cd03c3e5c037759bd84', 'message': 'WIP: Change api-microversions-alt\n\nThis changes api-microversions-alt spec based on the discussions.\n\nChange-Id: I71b79446ba9c052b7fd66eeb88944757728c79d0\n'}, {'number': 3, 'created': '2014-07-03 11:11:07.000000000', 'files': ['specs/juno/api-microversions-alt.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/eae1e82744c751f602513022750a13a4672ed708', 'message': 'WIP: Change api-microversions-alt\n\nThis changes api-microversions-alt spec based on the discussions.\n\nChange-Id: I71b79446ba9c052b7fd66eeb88944757728c79d0\n'}]",14,104418,eae1e82744c751f602513022750a13a4672ed708,21,7,3,6167,,,0,"WIP: Change api-microversions-alt

This changes api-microversions-alt spec based on the discussions.

Change-Id: I71b79446ba9c052b7fd66eeb88944757728c79d0
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/18/104418/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/api-microversions-alt.rst'],1,61c196b6605d2dfd792f25f42f810511718fc122,api-microversions,"the form X.Y.Z: - X: any backwards incompatible change (that includes removal of parameters) This X will bump by each incompatible change. However if the biggest X is experimental at the time we don't need to bump X. - Y: backs compatible changes This Y will bump by each compatible change. - Z: critical bug fixes on stable branches This Z will bump by each bug fix. So the versioning does not depend on the release boundary(Juno, etc.).don't feel are addequate to support. For instance if version 2.1 was the drop of the XML API, at some point in the future 2.1 would beIn the nova tree, there are two ways to implement different microversion functions. - The way 1: A decorator would be introduced to absorb the differences between microversions. (This way is already described on v2-on-v3-api) @translate_body(version=""2"", diff_v2) def show(...): """"""this method is for v3 and there are differences of response body. diff_v2 represents the differences""""""- The way 2: A decorator would be introduced to label routing functions version specification :: servers.py: @api.version(introduced=""2.0"") def show(...): .... @api.version(introduced=""3.0"") def show_v3(...) @api.version also supports experimental=True/False (default False). And vnd="""". It's a fatal error to combine either of those flags with the version flag. This will provide an in tree way of signaling when new methods come into play, as well as a selection for routing requests to different paths based on versions allowed. (Note: yes this is a *ton* of new work, but for long term tree sanity I think we need it). Basically, we need to implement microversion functions with the way 1 as possible to avoid copy&paste code and reduce meintenance cost. However sometimes we need the way 2 for avoiding spaghetti code if there are big differences between microversions. So we can choose either way by considering the balance for each API.","the form X.Y.Z though X.Y is acceptable, and assumes Z is 0. Z is reserved for critical bug fixes on stable branches.don't feel are addequate to support. For instance if version 2.001 was the drop of the XML API, at some point in the future 2.001 would beIn the nova tree a decorator would be introduced to label routing functions version specification @api.version(introduced=""2.0"", deprecated=""2.115"", removed=""2.300"") def index(...): @api.version(introduced=""2.300"") def index_2(...) @api.version also supports experimental=True/False (default False). And vnd="""". It's a fatal error to combine either of those flags with the version flag. This will provide an in tree way of signaling when new methods come into play, as well as a selection for routing requests to different paths based on versions allowed. (Note: yes this is a *ton* of new work, but for long term tree sanity I think we need it).",48,20
openstack%2Fnova-specs~master~I72cd4cfdbca6ac499468be82d48b5e9857936bb4,openstack/nova-specs,master,I72cd4cfdbca6ac499468be82d48b5e9857936bb4,Alternative take on API microversioning,ABANDONED,2014-06-20 20:31:17.000000000,2014-07-16 10:59:51.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 964}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8556}]","[{'number': 1, 'created': '2014-06-20 20:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/53eb1d92d609d4f32284437fc12be39d64e7f125', 'message': ""Alternative take on API microversioning\n\nThis is a different take on API microversioning that tries to be\na bit stricter on the design approach. It's done as an -alt in\na second patch so that it can be easily seen at the same time, and\ndebated independently.\n\nIt is far from complete, but seemed more useful to propose this\nway versus through gerrit comments.\n\nChange-Id: I72cd4cfdbca6ac499468be82d48b5e9857936bb4\n""}, {'number': 2, 'created': '2014-06-28 11:43:36.000000000', 'files': ['specs/juno/api-microversions-alt.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/110c50a8625de553ad782054b9d9bac44696a5fd', 'message': ""Alternative take on API microversioning\n\nThis is a different take on API microversioning that tries to be\na bit stricter on the design approach. It's done as an -alt in\na second patch so that it can be easily seen at the same time, and\ndebated independently.\n\nIt is far from complete, but seemed more useful to propose this\nway versus through gerrit comments.\n\nChange-Id: I72cd4cfdbca6ac499468be82d48b5e9857936bb4\n""}]",68,101648,110c50a8625de553ad782054b9d9bac44696a5fd,44,13,2,2750,,,0,"Alternative take on API microversioning

This is a different take on API microversioning that tries to be
a bit stricter on the design approach. It's done as an -alt in
a second patch so that it can be easily seen at the same time, and
debated independently.

It is far from complete, but seemed more useful to propose this
way versus through gerrit comments.

Change-Id: I72cd4cfdbca6ac499468be82d48b5e9857936bb4
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/48/101648/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/api-microversions-alt.rst'],1,53eb1d92d609d4f32284437fc12be39d64e7f125,api-microversions,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== API Microversions (Alternate Proposal) ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/api-microversions (This is in no way a complete spec covering this space, but it's trying to narrow in on a few things.) Problem description =================== As a community we are really good at evolving interfaces and code over time via incremental development. We've been less good at giant big bang drops of code. The Nova API has become sufficiently large, and constantly growing through new extensions, that it's not likely to be able to ever do a new major version of the API. At the same time the escape hatch that we've provided for allowing innovation in the API, through adding extensions, has grown to the point where we now have extensions to extensions, under the assumption that the extension list is a poor man's versioning mechanism. While true, this has let to pain and debt, and prevents us from making certain changes, like deprecating pieces of the API that are currently non sensible (or flat out broken). We must come up with a better way that serves the following needs: - Makes it possible to evolve the API in an incremental manner, which is our strength as a community - Provides backwards compatability for consumers - Provides cleanliness in the code to make it less likely that we'll do the wrong thing and break the world. A great interface is one that goes out of it's way to make it hard to use incorrectly. A good interface tries to be a great interface, but bends to the realties of the moment. Proposed change =============== We have 3 main concerns: - How will the end users use this, and how to we make it hard to use wrong - How will the code be internally structured, and how do we make it easy to see in code that you are about to break the world (not just from testing, but from code structure). - How will we test this in integration. And what limits does that impose. Type of versioning ------------------ The base proposal provides options, and a hybrid approach. I believe this is too complicated and confusing to get right. In complexity lie dragons, also giant sloths, equally dangerous, but slower to emerge. (For the purposes of the following discussion ""the API"" is all core and optional extensions in the upstream Nova tree.) Versioning of the API should be 1 monotonic counter. It should be in the form X.Y.Z though X.Y is acceptable, and assumes Z is 0. Z is reserved for critical bug fixes on stable branches. A version response would look as follows :: GET / { ""versions"": [ { ""id"": ""v2.0"", ""links"": [ { ""href"": ""http://localhost:8774/v2/"", ""rel"": ""self"" } ], ""status"": ""CURRENT"", ""updated"": ""2011-01-21T11:33:21Z"" ""version"": ""2.115"" ""min_version"": ""2.0"" }, ] } This specifies the min and max version that the server can understand. min_version will start at 2.0 representing the current 2.0 API. It may eventually be uplifted if there are support burdens we don't feel are addequate to support. For instance if version 2.001 was the drop of the XML API, at some point in the future 2.001 would be the minimum version provided. Client Interaction ------------------ A client specifies the version of the API they want via the following approach, a new header:: X-OS-Compute-Version: 2.114, experimental, vnd:rax This conceptually acts like the accept header, with some nuance. We introduce 3 concepts here, global API version, experimental flag, and vendor flags. Semantically: - if X-OS-Compute-Version is not provided, act as if min_version was sent. - if X-OS-Compute-Version is sent, respond with the API at that version. If that's outside of the range of versions supported, return 406 (or some other future determined appropriate error). - if X-OS-Compute-Version: latest (special keyword) return Max Version response. - if experimental is sent, return results with *all* experimental extensions enabled. - if vnd:VENDORNAMESPACE is sent, return results that include that out of tree vendor extensions. This means out of the box, with an old client, an OpenStack installation will return vanilla OpenStack responses at v2. The user or SDK will have to ask for something different. Experimental and vendor, by being virtue of out of tree, do not benefit from versioning. It's an all or nothing affair. There are less unique snowflakes in the world than people think, and we actually want these things back in tree. Nova Tree --------- In the nova tree a decorator would be introduced to label routing functions version specification :: servers.py: @api.version(introduced=""2.0"", deprecated=""2.115"", removed=""2.300"") def index(...): .... @api.version(introduced=""2.300"") def index_2(...) """"""A bigger badder index listing"""""" .... @api.version also supports experimental=True/False (default False). And vnd="""". It's a fatal error to combine either of those flags with the version flag. This will provide an in tree way of signaling when new methods come into play, as well as a selection for routing requests to different paths based on versions allowed. (Note: yes this is a *ton* of new work, but for long term tree sanity I think we need it). Alternatives ------------ See non-alt proposal Data model impact ----------------- None REST API impact --------------- Additional version information added to GET / even in the base case, it should be minimally disruptive. Otherwise the whole proposal is basically REST impact Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- SDK authors will need to start using the X-OS-Compute-Version header to get access to new features. The fact that new features will only be added in new versions will encourage them to do so. Performance Impact ------------------ None Other deployer impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * If this change is a new binary, how would it be deployed? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? Developer impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other hypervisors would implement the feature is required. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: cyeoh-0 Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in nova, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Nova (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Testing ======= Historically API stability in Nova was really only maintained because Tempest covered such a large portion of the API. That will not be realistic for all versions possible here. Nova unit tests will need to be enhanced to do most of the heavy lifting. When new tests are added to Tempest, they will specify the minimum version they function on (we are already starting down that path for novaclient testing). Tempest will run Nova tests twice during a run. At min_version (escentially specifying no OS-Compute-Version), and at at version detected by the setup tool (currently devstack) for the max version Nova supports in the branch in question. Scenario tests will occur at max version. Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Design summit session https://etherpad.openstack.org/p/juno-nova-v3-api * Recent discussions: https://wiki.openstack.org/wiki/Nova/ProposalForAPIMicroVersions ",,328,0
openstack%2Fnova-specs~master~I5442a5edafe8358c9ace64e8c260b6a7c89343b7,openstack/nova-specs,master,I5442a5edafe8358c9ace64e8c260b6a7c89343b7,vmware: Enable VCDriver with NFS glance source datastore,ABANDONED,2014-07-02 14:48:32.000000000,2014-07-16 10:56:58.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 7400}, {'_account_id': 9297}, {'_account_id': 10487}]","[{'number': 1, 'created': '2014-07-02 14:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a018a6768e37221b824197eea6e23757c2240689', 'message': 'Enable VmwareVCDriver with NFS glance source datastore\n\nIt enables the VmwareVCDriver to improve the image\ncopying process from glance to vmware_temp by\nexposing glace image file store as NFS share and\nmount it on the vCenter cluster as NFS datastore\n\nChange-Id: I5442a5edafe8358c9ace64e8c260b6a7c89343b7\n'}, {'number': 2, 'created': '2014-07-02 17:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9992bb886abe110fa3c917d7ef8eadc4d03330cb', 'message': 'vmware: Enable VCDriver with NFS glance source datastore\n\nIt enables the VmwareVCDriver to improve the image\ncopying process from glance to vmware_temp by\nexposing glace image file store as NFS share and\nmount it on the vCenter cluster as NFS datastore\n\nChange-Id: I5442a5edafe8358c9ace64e8c260b6a7c89343b7\n'}, {'number': 3, 'created': '2014-07-08 03:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ec20998f32ccf613d6bd88a21603433bc93af164', 'message': 'vmware: Enable VCDriver with NFS glance source datastore\n\nIt enables the VmwareVCDriver to improve the image\ncopying process from glance to vmware_temp by\nexposing glace image file store as NFS share and\nmount it on the vCenter cluster as NFS datastore\n\nChange-Id: I5442a5edafe8358c9ace64e8c260b6a7c89343b7\n'}, {'number': 4, 'created': '2014-07-15 05:49:24.000000000', 'files': ['specs/juno/nova-vmware-vcdriver-nfs-image-copy.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/dfe28f9a6cb93ad05ad2e411c387bbf4f25c9bc7', 'message': 'vmware: Enable VCDriver with NFS glance source datastore\n\nIt enables the VmwareVCDriver to improve the image\ncopying process from glance to vmware_temp by\nexposing glace image file store as NFS share and\nmount it on the vCenter cluster as NFS datastore\n\nChange-Id: I5442a5edafe8358c9ace64e8c260b6a7c89343b7\n'}]",6,104211,dfe28f9a6cb93ad05ad2e411c387bbf4f25c9bc7,19,7,4,10487,,,0,"vmware: Enable VCDriver with NFS glance source datastore

It enables the VmwareVCDriver to improve the image
copying process from glance to vmware_temp by
exposing glace image file store as NFS share and
mount it on the vCenter cluster as NFS datastore

Change-Id: I5442a5edafe8358c9ace64e8c260b6a7c89343b7
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/11/104211/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/nova-vmware-vcdriver-nfs-image-copy.rst'],1,a018a6768e37221b824197eea6e23757c2240689,bp/vmware-vc-driver-nfs-datastore-image-copy,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================================== Enable VmwareVCDriver with NFS glance image datastore ====================================================== https://blueprints.launchpad.net/nova/+spec /vmware-vc-driver-nfs-datastore-image-copy This blueprint enables VmwareVCDrvier to copy the image from the glance by using NFS imagestore configured in the glance. Problem description =================== while instance is boot from an image, the VmwareVCDriver copys the image from glance into vmware_temp folder, by using the glance REST API. This makes the image copy process to be slower and it consumes the nova-compute CPU and memory resource. This can be improved by using NFS image store on the glance as mentioned in below section. Proposed change =============== Assume that admin has made following setup: 1. Once Glance is installed with file system as image store, install and configure NFS on the image store 2. On the vCenter cluster, which is consumed as compute node, create the NFS datastore from the glance image store configured in above step and let the name be 'nfs_glance_datastore'. Then following are the changes in the nova: 1. In nova.conf, under [vmware] section, add a new config parameter named, ' nfs_glance_datastore' and set the value as 'nfs_glance_datastore' 2. update the driver code to copy the image from 'nfs_glance_datastore' to 'vmware_temp', if 'nfs_glance_datastore' is configured, otherwise use the existing logic to copy the image from glance Alternatives ------------ The existing logic is alternative to this blueprint Data model impact ----------------- No change REST API impact --------------- No change Security impact --------------- No change Notifications impact -------------------- No change Other end user impact --------------------- No change Performance Impact ------------------ As the image copy is happening between datastores, its very faster approach comparted to existing one. Other deployer impact --------------------- No change Developer impact ---------------- No Change. Implementation ============== Assignee(s) ----------- Primary assignee: kanagaraj-manickam Other contributors: johnson.raj@hp.com Work Items ---------- 1. Add new variable 'nfs_glance_datastore' to to nova.conf and set default to None. 2. Add a new utility method in vim_utils to copy the image file from 'nfs_glance_datastore' to 'vmware_temp' 3. update the image copying logic to use the above defined new method if 'nfs_glance_datastore' is configured, otherwise use existing logic Dependencies ============ There is no dependency. Testing ======= 1. provide required unit tests to test the image copy with and without nfs_glance_datastore in place 2. add required tempest test cases to test. 3. Vmware minesweeper to be updated with required NFS setup in place in both glance and vCenter. Documentation Impact ==================== As mentioned the ""proposed change"" section, the nova.conf will be updated. References ========== None ",,136,0
openstack%2Fnova~master~I6bb2af45d3e72bdc11470877fd2a993e9d0a4623,openstack/nova,master,I6bb2af45d3e72bdc11470877fd2a993e9d0a4623,Refactors VIF configuration logic,MERGED,2014-07-11 03:19:21.000000000,2014-07-16 10:55:59.000000000,2014-07-16 10:55:57.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-11 03:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e0842cd1efa8d21824dff290d5f10d88036acf8', 'message': 'Refactors VIF configuration logic\n\nThere are too many if/else checks when we choose the right function to\nconduct vif operations. We can do better by setting an alias of each\nvif type and getattr on the nessesary function obj.\n\nPlease enter the commit message for your changes. Lines starting\n\nChange-Id: I6bb2af45d3e72bdc11470877fd2a993e9d0a4623\n'}, {'number': 2, 'created': '2014-07-11 03:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7bbd3d0460dc77cbe76e0c26acdee67a1b0a8352', 'message': 'Refactors VIF configuration logic\n\nThere are too many if/else checks when we choose the right function to\nconduct vif operations. We can do better by setting an alias of each\nvif type and getattr on the nessesary function obj.\n\nChange-Id: I6bb2af45d3e72bdc11470877fd2a993e9d0a4623\n'}, {'number': 3, 'created': '2014-07-11 04:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/479162f26b8ca678218c57eb730fe822d6751744', 'message': 'Refactors VIF configuration logic\n\nThere are too many if/else checks when we choose the right function to\nconduct vif operations. We can do better by getattr on the nessesary\nfunction obj. The vif type needs normalization to remove periods.\n\nChange-Id: I6bb2af45d3e72bdc11470877fd2a993e9d0a4623\n'}, {'number': 4, 'created': '2014-07-11 05:16:19.000000000', 'files': ['nova/virt/libvirt/vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cb12cb12eba6e29d440c7ea05077c2ccde5294d5', 'message': 'Refactors VIF configuration logic\n\nThere are too many if/else checks when we choose the right function to\nconduct vif operations. We can do better by getattr on the nessesary\nfunction obj. The vif type needs normalization to remove periods.\n\nChange-Id: I6bb2af45d3e72bdc11470877fd2a993e9d0a4623\n'}]",0,106249,cb12cb12eba6e29d440c7ea05077c2ccde5294d5,28,9,4,1994,,,0,"Refactors VIF configuration logic

There are too many if/else checks when we choose the right function to
conduct vif operations. We can do better by getattr on the nessesary
function obj. The vif type needs normalization to remove periods.

Change-Id: I6bb2af45d3e72bdc11470877fd2a993e9d0a4623
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/106249/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/vif.py', 'nova/network/model.py']",2,5e0842cd1efa8d21824dff290d5f10d88036acf8,vif_refactor,"# Alias for the 'vif_type' field in VIF class VIF_TYPE_ALIAS = { VIF_TYPE_BRIDGE: 'bridge', VIF_TYPE_OVS: 'ovs', VIF_TYPE_802_QBG: '802qbg', VIF_TYPE_802_QBH: '802qbh', VIF_TYPE_IVS: 'ivs', VIF_TYPE_IOVISOR: 'iovisor', VIF_TYPE_MLNX_DIRECT: 'mlnx_direct', VIF_TYPE_MIDONET: 'midonet', } ",,24,75
openstack%2Foslo.rootwrap~master~I1ac4535ad176d78769c497fa037285bc610acadf,openstack/oslo.rootwrap,master,I1ac4535ad176d78769c497fa037285bc610acadf,Continue on failure of leaf filters of chaining filters,MERGED,2014-07-10 14:57:19.000000000,2014-07-16 10:55:54.000000000,2014-07-16 10:55:54.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 5638}, {'_account_id': 9176}]","[{'number': 1, 'created': '2014-07-10 14:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/dc5e6683ce915004a3de7995e4e8db4fc77dfc2c', 'message': 'Continue on failure of leaf filters of chaining filters\n\nCurrently wrapper.py has an implementation error in chaining filters, which\nis expecting match_filter() returns None when no leaf filter matches to\narguments, although it actually raises an exception.\n\nThis patch fixes this and adds an unit test for it.\n\nChange-Id: I1ac4535ad176d78769c497fa037285bc610acadf\n'}, {'number': 2, 'created': '2014-07-11 15:07:59.000000000', 'files': ['tests/test_rootwrap.py', 'oslo/rootwrap/wrapper.py'], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/fb8f8af47f106205c64713fcffe05ac5e9397157', 'message': 'Continue on failure of leaf filters of chaining filters\n\nCurrently wrapper.py has an implementation error in chaining filters, which\nis expecting match_filter() returns None when no leaf filter matches to\narguments, although it actually raises an exception.\n\nThis patch fixes this and adds an unit test for it.\n\nCloses-Bug: #1340792\nChange-Id: I1ac4535ad176d78769c497fa037285bc610acadf\n'}]",0,106071,fb8f8af47f106205c64713fcffe05ac5e9397157,15,4,2,9176,,,0,"Continue on failure of leaf filters of chaining filters

Currently wrapper.py has an implementation error in chaining filters, which
is expecting match_filter() returns None when no leaf filter matches to
arguments, although it actually raises an exception.

This patch fixes this and adds an unit test for it.

Closes-Bug: #1340792
Change-Id: I1ac4535ad176d78769c497fa037285bc610acadf
",git fetch https://review.opendev.org/openstack/oslo.rootwrap refs/changes/71/106071/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_rootwrap.py', 'oslo/rootwrap/wrapper.py']",2,dc5e6683ce915004a3de7995e4e8db4fc77dfc2c,," if not args: continue try: match_filter(leaf_filters, args, exec_dirs=exec_dirs) except (NoFilterMatched, FilterMatchNotExecutable):"," if (not args or not match_filter(leaf_filters, args, exec_dirs=exec_dirs)):",17,2
openstack%2Ffuel-library~master~I6c75d6027f617abe96122569686c9fb04497ca89,openstack/fuel-library,master,I6c75d6027f617abe96122569686c9fb04497ca89,Direct mount of puppet directory for puppet container,MERGED,2014-07-09 14:30:29.000000000,2014-07-16 10:52:33.000000000,2014-07-11 22:07:45.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-07-09 14:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b15377a4e610627e9d6b0e6a809f6d52654f63f9', 'message': 'Direct mount of puppet directory for puppet container\n\nRelies on https://review.openstack.org/105739\n\nChange-Id: I6c75d6027f617abe96122569686c9fb04497ca89\nCloses-Bug: #1339688\n'}, {'number': 2, 'created': '2014-07-10 11:05:00.000000000', 'files': ['deployment/puppet/docker/templates/dockerctl_config.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/064cd6983dd6826a73d805d99b31e31d395db1e2', 'message': 'Direct mount of puppet directory for puppet container\n\nRelies on https://review.openstack.org/105739\n\nChange-Id: I6c75d6027f617abe96122569686c9fb04497ca89\nCloses-Bug: #1339688\n'}]",0,105750,064cd6983dd6826a73d805d99b31e31d395db1e2,24,6,2,7195,,,0,"Direct mount of puppet directory for puppet container

Relies on https://review.openstack.org/105739

Change-Id: I6c75d6027f617abe96122569686c9fb04497ca89
Closes-Bug: #1339688
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/50/105750/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/docker/templates/dockerctl_config.erb'],1,b15377a4e610627e9d6b0e6a809f6d52654f63f9,dockerctl-direct-puppet,"HOST_VOL['puppet']=""-v /etc/puppet:/etc/puppet:ro""","HOST_VOL['puppet']=""-v /etc/puppet:/puppet:ro""",1,1
openstack%2Ffuel-main~master~I31470af079bc88ae4303dc511bfe2b1c1c9c2fed,openstack/fuel-main,master,I31470af079bc88ae4303dc511bfe2b1c1c9c2fed,Use direct mount for puppet docker container,MERGED,2014-07-09 13:45:51.000000000,2014-07-16 10:52:24.000000000,2014-07-11 18:41:58.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-07-09 13:45:51.000000000', 'files': ['docker/storage-puppet/Dockerfile'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8b658b11be66afea92acbe362064aa5ee41de22a', 'message': 'Use direct mount for puppet docker container\n\nRemoving workaround for mount of /etc/puppet\nto /puppet, then ln -s /puppet/{files} into\n/etc/puppet, because it breaks upgrade schema\nwhere /etc/puppet/$VER is added.\n\nChange-Id: I31470af079bc88ae4303dc511bfe2b1c1c9c2fed\nPartial-Bug: #1339688\n'}]",0,105739,8b658b11be66afea92acbe362064aa5ee41de22a,15,6,1,7195,,,0,"Use direct mount for puppet docker container

Removing workaround for mount of /etc/puppet
to /puppet, then ln -s /puppet/{files} into
/etc/puppet, because it breaks upgrade schema
where /etc/puppet/$VER is added.

Change-Id: I31470af079bc88ae4303dc511bfe2b1c1c9c2fed
Partial-Bug: #1339688
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/39/105739/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/storage-puppet/Dockerfile'],1,8b658b11be66afea92acbe362064aa5ee41de22a,puppetdirs,#run with -v /etc/puppet:/etc/puppetCMD /bin/echo storage/puppet I am a data-only container for Fuel,#run with -v /etc/puppet:/puppetRUN mkdir -p /etc/puppet/ /puppet CMD /bin/echo storage/puppet I am a data-only container for Fuel && ln -s /puppet/puppet.conf /puppet/modules /puppet/manifests /etc/puppet/,2,3
openstack%2Fceilometer~master~Ic859e9a477f03b680e1ac0db1498261a3dc24997,openstack/ceilometer,master,Ic859e9a477f03b680e1ac0db1498261a3dc24997,Improve a bit performance of Ceilometer,MERGED,2014-06-30 18:12:43.000000000,2014-07-16 10:51:56.000000000,2014-07-16 10:51:55.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 6172}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 8871}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-30 18:12:43.000000000', 'files': ['ceilometer/storage/hbase/utils.py', 'ceilometer/plugin.py', 'ceilometer/network/statistics/opencontrail/client.py', 'ceilometer/network/statistics/opendaylight/client.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/89b325c3e91ee5e571ac32024ecf47265760dce5', 'message': ""Improve a bit performance of Ceilometer\n\nwe shouldn't use <array>.extend([<generator>]) it's similiar to\n<array>.extend(<generator>) but slower\n\nChange-Id: Ic859e9a477f03b680e1ac0db1498261a3dc24997\n""}]",0,103610,89b325c3e91ee5e571ac32024ecf47265760dce5,49,9,1,6172,,,0,"Improve a bit performance of Ceilometer

we shouldn't use <array>.extend([<generator>]) it's similiar to
<array>.extend(<generator>) but slower

Change-Id: Ic859e9a477f03b680e1ac0db1498261a3dc24997
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/10/103610/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/hbase/utils.py', 'ceilometer/plugin.py', 'ceilometer/network/statistics/opencontrail/client.py', 'ceilometer/network/statistics/opendaylight/client.py']",4,89b325c3e91ee5e571ac32024ecf47265760dce5,imporve_notification_base," dump.extend('%s: %s\n' % (k, v) for k, v in six.iteritems(resp.headers))"," dump.extend(['%s: %s\n' % (k, v) for k, v in six.iteritems(resp.headers)])",9,9
openstack-attic%2Fobject-api~master~I7989829cd22f040c54b2878ab9c5d17a823eacd9,openstack-attic/object-api,master,I7989829cd22f040c54b2878ab9c5d17a823eacd9,Fix swift invocation,MERGED,2014-07-13 09:05:53.000000000,2014-07-16 10:46:41.000000000,2014-07-16 10:46:40.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2622}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-07-13 09:05:53.000000000', 'files': ['v1/section_object-api-tempurl.xml'], 'web_link': 'https://opendev.org/openstack-attic/object-api/commit/c8728fdd9838f7415dedb3c23bef8b679297f54f', 'message': 'Fix swift invocation\n\nswift -m adds X-Account-Meta to each parameter, fix the invocation.\n\nChange-Id: I7989829cd22f040c54b2878ab9c5d17a823eacd9\nCloses-Bug: #1325780\n'}]",0,106609,c8728fdd9838f7415dedb3c23bef8b679297f54f,11,4,1,6547,,,0,"Fix swift invocation

swift -m adds X-Account-Meta to each parameter, fix the invocation.

Change-Id: I7989829cd22f040c54b2878ab9c5d17a823eacd9
Closes-Bug: #1325780
",git fetch https://review.opendev.org/openstack-attic/object-api refs/changes/09/106609/1 && git format-patch -1 --stdout FETCH_HEAD,['v1/section_object-api-tempurl.xml'],1,c8728fdd9838f7415dedb3c23bef8b679297f54f,bug/1325780," <screen><prompt>$</prompt> <userinput>swift post -m ""Temp-URL-Key:<replaceable>MYKEY</replaceable>""</userinput></screen>"," <screen><prompt>$</prompt> <userinput>swift post -m ""X-Account-Meta-Temp-URL-Key: <replaceable>MYKEY</replaceable>""</userinput></screen>",1,1
openstack%2Fkeystone~master~I5727bc7ed967f81ab63b0d031b9a6d6da673da3a,openstack/keystone,master,I5727bc7ed967f81ab63b0d031b9a6d6da673da3a,render json examples with syntax highlighting,MERGED,2014-07-14 18:53:18.000000000,2014-07-16 10:43:40.000000000,2014-07-16 10:43:39.000000000,"[{'_account_id': 3}, {'_account_id': 220}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 8871}, {'_account_id': 8978}, {'_account_id': 11333}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-07-14 18:53:18.000000000', 'files': ['doc/source/event_notifications.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/04dc1cae95c5cb927063b8ceb8e4db0b2cc4ef31', 'message': 'render json examples with syntax highlighting\n\nChange-Id: I5727bc7ed967f81ab63b0d031b9a6d6da673da3a\n'}]",0,106840,04dc1cae95c5cb927063b8ceb8e4db0b2cc4ef31,23,8,1,4,,,0,"render json examples with syntax highlighting

Change-Id: I5727bc7ed967f81ab63b0d031b9a6d6da673da3a
",git fetch https://review.opendev.org/openstack/keystone refs/changes/40/106840/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/event_notifications.rst'],1,04dc1cae95c5cb927063b8ceb8e4db0b2cc4ef31,,resource completes successfully: .. code-block:: javascriptThis is an example of a notification sent for a newly created user: .. code-block:: javascript,resource completes successfully::This is an example of a notification sent for a newly created user::,6,2
openstack%2Fkeystone~master~I9815289444763450131fa9cd87f725bfc7a92aa6,openstack/keystone,master,I9815289444763450131fa9cd87f725bfc7a92aa6,Clean up the endpoint filtering configuration docs,MERGED,2014-07-11 19:25:46.000000000,2014-07-16 10:43:32.000000000,2014-07-16 10:43:31.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 11045}, {'_account_id': 11333}, {'_account_id': 11387}, {'_account_id': 11717}]","[{'number': 1, 'created': '2014-07-11 19:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5914953cbc355ed485f32a82cf702333aeb2a9fd', 'message': 'Clean up the endpoint filtering configuration docs\n\nThere were a few grammatical errors seen in the docs, this patch\nshould clean those up.\n\nChange-Id: I9815289444763450131fa9cd87f725bfc7a92aa6\n'}, {'number': 2, 'created': '2014-07-11 20:08:20.000000000', 'files': ['doc/source/extensions/endpoint_filter.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e7ac0ac806bf863ffa27eacf831c93b41ad6df85', 'message': 'Clean up the endpoint filtering configuration docs\n\nThere were a few grammatical errors seen in the docs, this patch\nshould clean those up.\n\nChange-Id: I9815289444763450131fa9cd87f725bfc7a92aa6\n'}]",2,106475,e7ac0ac806bf863ffa27eacf831c93b41ad6df85,22,8,2,6482,,,0,"Clean up the endpoint filtering configuration docs

There were a few grammatical errors seen in the docs, this patch
should clean those up.

Change-Id: I9815289444763450131fa9cd87f725bfc7a92aa6
",git fetch https://review.opendev.org/openstack/keystone refs/changes/75/106475/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/extensions/endpoint_filter.rst'],1,5914953cbc355ed485f32a82cf702333aeb2a9fd,update_EF_docs,"1. Add the endpoint filter extension catalog driver to the ``[catalog]`` section2. Add the ``endpoint_filter_extension`` filter to the ``api_v3`` pipeline in3. Create the endpoint filter extension tables if using the provided sql backend. For example::4. Optionally, change ``return_all_endpoints_if_no_filter`` the ``[endpoint_filter]`` section in ``keystone.conf`` to return an empty catalog if no associations are made. For example::",1. add the endpoint filter extension catalog driver to the ``[catalog]`` section2. add the ``endpoint_filter_extension`` filter to the ``api_v3`` pipeline in3. create the endpoint filter extension tables if using the provided sql backend. example::4. optional: change ``return_all_endpoints_if_no_filter`` the ``[endpoint_filter]`` section in ``keystone.conf`` to return an empty catalog if no associations are made. example::,5,6
openstack%2Frally~master~I10d5b38f9947e04736fbb58e8fac976f0c10daab,openstack/rally,master,I10d5b38f9947e04736fbb58e8fac976f0c10daab,fixed several pep8 issues,ABANDONED,2014-05-15 18:46:51.000000000,2014-07-16 10:36:26.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-05-15 18:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c12d95e960f133cfc09dff43016190844335dcbd', 'message': ""fixed pep8 issue E265\n\n  * E265 block comment should start with '# '\n\nChange-Id: I10d5b38f9947e04736fbb58e8fac976f0c10daab\n""}, {'number': 2, 'created': '2014-05-16 11:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8d771ff2e89fb94106d1d4605513519faf242192', 'message': ""fixed pep8 issue E265\n\n  * E265 block comment should start with '# '\n\nChange-Id: I10d5b38f9947e04736fbb58e8fac976f0c10daab\n""}, {'number': 3, 'created': '2014-05-17 08:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b8336169ac17e49ec81b6aadaeacdb494541981a', 'message': ""fixed pep8 issue E265\n\n  * E126 continuation line over-indented for hanging indent\n  * E127 continuation line over-indented for visual indent\n  * E128 continuation line under-indented for visual indent\n  * E131 continuation line unaligned for hanging indent\n  * E251 unexpected spaces around keyword / parameter equals\n  * E265 block comment should start with '# '\n\nChange-Id: I10d5b38f9947e04736fbb58e8fac976f0c10daab\n""}, {'number': 4, 'created': '2014-05-17 08:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ca3f8451358f00f1b710fa37c693376293fc111a', 'message': ""fixed several pep8 issue\n\n  * E126 continuation line over-indented for hanging indent\n  * E127 continuation line over-indented for visual indent\n  * E128 continuation line under-indented for visual indent\n  * E131 continuation line unaligned for hanging indent\n  * E251 unexpected spaces around keyword / parameter equals\n  * E265 block comment should start with '# '\n\nChange-Id: I10d5b38f9947e04736fbb58e8fac976f0c10daab\n""}, {'number': 5, 'created': '2014-05-17 08:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a8666dd29c18978b3effa0029a6f8e292f17ee04', 'message': ""fixed several pep8 issue\n\n  * E126 continuation line over-indented for hanging indent\n  * E127 continuation line over-indented for visual indent\n  * E128 continuation line under-indented for visual indent\n  * E131 continuation line unaligned for hanging indent\n  * E251 unexpected spaces around keyword / parameter equals\n  * E265 block comment should start with '# '\n\nChange-Id: I10d5b38f9947e04736fbb58e8fac976f0c10daab\n""}, {'number': 6, 'created': '2014-05-17 09:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f9fcf92e10f3516b21f3501df51f357064158664', 'message': ""fixed several pep8 issues\n\n  * E126 continuation line over-indented for hanging indent\n  * E127 continuation line over-indented for visual indent\n  * E128 continuation line under-indented for visual indent\n  * E131 continuation line unaligned for hanging indent\n  * E251 unexpected spaces around keyword / parameter equals\n  * E265 block comment should start with '# '\n\nChange-Id: I10d5b38f9947e04736fbb58e8fac976f0c10daab\n""}, {'number': 7, 'created': '2014-06-01 18:21:10.000000000', 'files': ['tests/benchmark/runners/test_base.py', 'tests/benchmark/context/test_users.py', 'tests/deploy/serverprovider/providers/test_openstack.py', 'rally/benchmark/runners/constant.py', 'tests/benchmark/test_engine.py', 'tests/benchmark/runners/test_periodic.py', 'tests/benchmark/context/test_secgroups.py', 'tests/deploy/serverprovider/providers/test_lxc.py', 'rally/benchmark/processing/charts/histogram.py', 'rally/benchmark/runners/base.py', 'tests/benchmark/scenarios/nova/test_utils.py', 'tests/deploy/engines/test_devstack.py', 'tests/cmd/commands/test_task.py', 'rally/benchmark/scenarios/glance/utils.py', 'rally/deploy/serverprovider/providers/virsh.py', 'tests/benchmark/context/test_roles.py', 'tests/fakes.py', 'tests/benchmark/scenarios/nova/test_servers.py', 'tests/benchmark/processing/test_plot.py', 'rally/db/sqlalchemy/api.py', 'rally/benchmark/processing/utils.py', 'tests/benchmark/scenarios/vm/test_vmtasks.py', 'rally/benchmark/scenarios/nova/utils.py', 'rally/benchmark/context/secgroup.py', 'rally/benchmark/scenarios/base.py', 'rally/db/sqlalchemy/models.py', 'tests/deploy/serverprovider/providers/test_virsh.py', 'rally/benchmark/scenarios/neutron/utils.py', 'tests/cmd/test_envutils.py', 'tests/benchmark/context/test_quotas.py', 'tests/benchmark/scenarios/quotas/test_utils.py', 'tests/benchmark/runners/test_constant.py', 'rally/verification/verifiers/tempest/config.py', 'rally/cmd/commands/task.py', 'tests/verification/verifiers/fakes.py', 'rally/benchmark/scenarios/utils.py', 'tox.ini', 'rally/benchmark/context/users.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/623e5465171a56bf14c7ceac5e2cb4f033e21109', 'message': ""fixed several pep8 issues\n\n  * E126 continuation line over-indented for hanging indent\n  * E127 continuation line over-indented for visual indent\n  * E128 continuation line under-indented for visual indent\n  * E131 continuation line unaligned for hanging indent\n  * E251 unexpected spaces around keyword / parameter equals\n  * E265 block comment should start with '# '\n\nChange-Id: I10d5b38f9947e04736fbb58e8fac976f0c10daab\n""}]",1,93781,623e5465171a56bf14c7ceac5e2cb4f033e21109,25,5,7,167,,,0,"fixed several pep8 issues

  * E126 continuation line over-indented for hanging indent
  * E127 continuation line over-indented for visual indent
  * E128 continuation line under-indented for visual indent
  * E131 continuation line unaligned for hanging indent
  * E251 unexpected spaces around keyword / parameter equals
  * E265 block comment should start with '# '

Change-Id: I10d5b38f9947e04736fbb58e8fac976f0c10daab
",git fetch https://review.opendev.org/openstack/rally refs/changes/81/93781/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/benchmark/context/test_quotas.py', 'rally/db/sqlalchemy/models.py', 'tests/benchmark/context/test_secgroups.py', 'rally/benchmark/scenarios/glance/utils.py', 'tests/deploy/serverprovider/providers/test_lxc.py', 'tests/benchmark/context/test_roles.py', 'tests/fakes.py', 'tools/patch_tox_venv.py']",8,c12d95e960f133cfc09dff43016190844335dcbd,pep8," # NOTE(dprince): For Tox we only run post_process (which patches files, etc)"," #NOTE(dprince): For Tox we only run post_process (which patches files, etc)",14,14
openstack%2Frally~master~I772bcfae418722371b7abcd525fcf913aef1e01e,openstack/rally,master,I772bcfae418722371b7abcd525fcf913aef1e01e,Add unit tests for processing utils,MERGED,2014-07-09 07:26:10.000000000,2014-07-16 10:34:51.000000000,2014-07-16 10:34:50.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6124}, {'_account_id': 6172}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-07-09 07:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/036575dc30e67f7c64a2b027c7d7a89a20a0e1f0', 'message': 'Add unit tests for processing utils\n\nAdded following unit tests\ntest_percentile_value_none\ntest_percentile_equal\n\nChange-Id: I772bcfae418722371b7abcd525fcf913aef1e01e\nImplements: blueprint improve-unit-test-coverage-rally\n'}, {'number': 2, 'created': '2014-07-10 09:33:58.000000000', 'files': ['tests/benchmark/processing/test_utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/57e92801041424ec5d2d424109762200f30fa796', 'message': 'Add unit tests for processing utils\n\nAdded following unit tests\ntest_percentile_value_none\ntest_percentile_equal\n\nChange-Id: I772bcfae418722371b7abcd525fcf913aef1e01e\nImplements: blueprint improve-unit-test-coverage-rally\n'}]",5,105664,57e92801041424ec5d2d424109762200f30fa796,16,5,2,11105,,,0,"Add unit tests for processing utils

Added following unit tests
test_percentile_value_none
test_percentile_equal

Change-Id: I772bcfae418722371b7abcd525fcf913aef1e01e
Implements: blueprint improve-unit-test-coverage-rally
",git fetch https://review.opendev.org/openstack/rally refs/changes/64/105664/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/benchmark/processing/test_utils.py'],1,036575dc30e67f7c64a2b027c7d7a89a20a0e1f0,bp/improve-unit-test-coverage-rally," def test_percentile_value_none(self): result = utils.percentile(None, 0.1) self.assertTrue(result is None) def test_percentile_equal(self): lst = range(1, 101) result = utils.percentile(lst, 1) self.assertTrue(result == 100) ",,9,0
openstack%2Frequirements~master~I560bf669ebe9f01a94790a069cfdbfd07cdf3d95,openstack/requirements,master,I560bf669ebe9f01a94790a069cfdbfd07cdf3d95,Add tox as global requirement,ABANDONED,2014-06-07 08:17:39.000000000,2014-07-16 10:32:02.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1812}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 6172}, {'_account_id': 6593}, {'_account_id': 6786}, {'_account_id': 7680}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-07 08:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/684993f2ed6050bdc3c156589f53d4ae795c8011', 'message': 'Add tox as global requirement\n\nChange-Id: I560bf669ebe9f01a94790a069cfdbfd07cdf3d95\nCloses-Bug: #1316751\n'}, {'number': 2, 'created': '2014-06-07 08:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/f127b462c040dc10c08743ba6e0b91d2a6a706b4', 'message': 'Add tox as global requirement\n\nChange-Id: I560bf669ebe9f01a94790a069cfdbfd07cdf3d95\nCloses-Bug: #1316751\n'}, {'number': 3, 'created': '2014-06-07 19:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a599fc5fd81bc7e5b6d5f7834ce5f43bf00b7e71', 'message': 'Add tox as global requirement\n\nAt the moment tox is missing on http://pypi.openstack.org/.\nWhen using pypi.openstack.org as PyPi mirror for stack.sh (Devstack)\nthe script will fail because the requirement tox<1.7.0 can\nnot be fullfilled.\n\nChange-Id: I560bf669ebe9f01a94790a069cfdbfd07cdf3d95\nCloses-Bug: #1316751\n'}, {'number': 4, 'created': '2014-06-07 19:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/7851854ea491a6cc0146b3097a823303df60da97', 'message': 'Add tox as global requirement\n\nAt the moment tox is missing on http://pypi.openstack.org/.\nWhen using pypi.openstack.org as PyPi mirror for stack.sh (Devstack)\nthe script will fail because the requirement tox<1.7.0 can\nnot be fulfilled.\n\nChange-Id: I560bf669ebe9f01a94790a069cfdbfd07cdf3d95\nCloses-Bug: #1316751\n'}, {'number': 5, 'created': '2014-06-07 22:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/16c12bffebd96682c749b22c117130bd6d5d7ba6', 'message': 'Add tox as global requirement\n\nAt the moment tox is missing on http://pypi.openstack.org/.\nWhen using pypi.openstack.org as PyPi mirror for stack.sh (Devstack)\nthe script will fail because the requirement tox<1.7.0 can\nnot be fulfilled.\n\nChange-Id: I560bf669ebe9f01a94790a069cfdbfd07cdf3d95\nCloses-Bug: #1316751\n'}, {'number': 6, 'created': '2014-06-11 17:00:50.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a7299baf5a45a3c4ff3562e5bc6fae474bfaa7ae', 'message': 'Add tox as global requirement\n\nAt the moment tox is missing on http://pypi.openstack.org/.\nWhen using pypi.openstack.org as PyPi mirror for stack.sh (Devstack)\nthe script will fail because the requirement tox<1.7.0 can\nnot be fulfilled.\n\nChange-Id: I560bf669ebe9f01a94790a069cfdbfd07cdf3d95\nCloses-Bug: #1316751\n'}]",1,98575,a7299baf5a45a3c4ff3562e5bc6fae474bfaa7ae,43,12,6,167,,,0,"Add tox as global requirement

At the moment tox is missing on http://pypi.openstack.org/.
When using pypi.openstack.org as PyPi mirror for stack.sh (Devstack)
the script will fail because the requirement tox<1.7.0 can
not be fulfilled.

Change-Id: I560bf669ebe9f01a94790a069cfdbfd07cdf3d95
Closes-Bug: #1316751
",git fetch https://review.opendev.org/openstack/requirements refs/changes/75/98575/6 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,684993f2ed6050bdc3c156589f53d4ae795c8011,1316751,tox<1.7.0,,1,0
openstack%2Fnova~master~I6438bcf47e06a401323ea708d5a44c69fa00e967,openstack/nova,master,I6438bcf47e06a401323ea708d5a44c69fa00e967,Fix nova/network direct use of object modules,MERGED,2014-05-20 15:27:54.000000000,2014-07-16 10:31:41.000000000,2014-07-16 05:17:04.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-20 15:27:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d35ff71eb46bf3fe839a4fe45bb7af4fbda8b73', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 2, 'created': '2014-05-20 17:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7220b36ae1279e6874bac6763aec984676db3c4', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 3, 'created': '2014-05-20 21:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f01ee98a2a7dab3fdc8cea166eb20920f1a7c140', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 4, 'created': '2014-05-20 22:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/05b81ef9a38867a8e8d19b0ffe2ed35c0524f32c', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 5, 'created': '2014-05-21 03:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1dbbad2822b90b00d55f04d96b15749cb38aac45', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 6, 'created': '2014-05-21 04:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68a492a4acf16143ba02865cee0a4cce45c6e828', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 7, 'created': '2014-05-21 06:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f2bcde60354b524008ac14e81cc8e4b2cde75eb', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 8, 'created': '2014-05-21 06:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4d96cb57a8bb08a8432e00ed552a655622c07e6', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 9, 'created': '2014-05-22 04:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/760e76955d8ccf6f19b71288863c9689d661b900', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 10, 'created': '2014-05-25 17:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6348812b7753b44485434a22ee0a799bae2025d8', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 11, 'created': '2014-05-28 15:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0785af0738feb870004f20e109edb2d22fd24376', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 12, 'created': '2014-05-29 16:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1b384cedb784cf67ef8dd2b7324c939362ee402', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 13, 'created': '2014-05-30 14:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f0f0d99ec27be3397ce972afd06dea4ab0c40a9', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 14, 'created': '2014-06-03 16:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec0f2dbc25504e1c12d5560a84c1e39134b803c3', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 15, 'created': '2014-06-17 17:08:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/642c73821a14a6efb989191787288b195da794aa', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 16, 'created': '2014-06-18 17:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13f8e4966ad6b4102a156799574f62c8d40ca6ee', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 17, 'created': '2014-06-24 07:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba93298880ea7b8b5706c1ee6eecf91988b9fc2c', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}, {'number': 18, 'created': '2014-06-28 21:48:50.000000000', 'files': ['nova/tests/fake_network.py', 'nova/network/api.py', 'nova/network/base_api.py', 'nova/tests/network/test_api.py', 'nova/network/nova_ipam_lib.py', 'nova/network/manager.py', 'nova/network/linux_net.py', 'nova/network/security_group/neutron_driver.py', 'nova/tests/network/test_manager.py', 'nova/tests/network/test_linux_net.py', 'nova/network/floating_ips.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/23a27e47b519a54f6d1c50190fc8c2ef13f79fdb', 'message': 'Fix nova/network direct use of object modules\n\nThis replaces all uses of nova.objects.<module>.<object> with\nnova.objects.<object> within nova/network and nova/tests/network.\n\nChange-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967\nPartial-Blueprint: object-subclassing\n'}]",0,94402,23a27e47b519a54f6d1c50190fc8c2ef13f79fdb,157,13,18,1030,,,0,"Fix nova/network direct use of object modules

This replaces all uses of nova.objects.<module>.<object> with
nova.objects.<object> within nova/network and nova/tests/network.

Change-Id: I6438bcf47e06a401323ea708d5a44c69fa00e967
Partial-Blueprint: object-subclassing
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/94402/18 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/api.py', 'nova/network/base_api.py', 'nova/network/nova_ipam_lib.py', 'nova/tests/network/test_api.py', 'nova/network/manager.py', 'nova/network/linux_net.py', 'nova/network/security_group/neutron_driver.py', 'nova/tests/network/test_manager.py', 'nova/tests/network/test_linux_net.py', 'nova/network/floating_ips.py']",10,8d35ff71eb46bf3fe839a4fe45bb7af4fbda8b73,bp/object-subclassing," floating_ips = objects.FloatingIPList.get_by_host(admin_context, self.host) fixed_ips = objects.FixedIPList.get_by_instance_uuid( floating_ips = objects.FloatingIPList.get_by_fixed_ip_id(context, fixed_id) floating_ip = objects.FloatingIP.allocate_address( floating_ip = objects.FloatingIP.get_by_address(context, address) floating_ip_ref = objects.FloatingIP.deallocate(context, address) floating_ip = objects.FloatingIP.get_by_address(context, floating_address) fixed_ip = objects.FixedIP.get_by_address(context, fixed_address) network = objects.Network.get_by_id(context.elevated(), fixed_ip.network_id) floating = objects.FloatingIP.associate(context, floating_address, fixed_address, self.host) objects.FloatingIP.disassociate(context, floating_address) floating_ip = objects.FloatingIP.get_by_address(context, address) fixed_ip = objects.FixedIP.get_by_id(context, floating_ip.fixed_ip_id) network = objects.Network.get_by_id(context.elevated(), fixed_ip.network_id) service = objects.Service.get_by_host_and_topic( floating = objects.FloatingIP.disassociate(context, address) return dict(objects.FloatingIP.get_by_id(context, id).iteritems()) pools = objects.FloatingIP.get_pool_names(context) floating_ip = objects.FloatingIP.get_by_address(context, address) floating_ip = objects.FloatingIP.get_by_address(context, address) domain_list = objects.DNSDomainList.get_all(context) objects.DNSDomain.register_for_zone(context, domain, av_zone) objects.DNSDomain.register_for_project(context, domain, project) objects.DNSDomain.delete_by_domain(context, domain)","from nova.objects import dns_domain as dns_domain_obj from nova.objects import fixed_ip as fixed_ip_obj from nova.objects import floating_ip as floating_ip_obj from nova.objects import network as network_obj from nova.objects import service as service_obj floating_ips = floating_ip_obj.FloatingIPList.get_by_host( admin_context, self.host) fixed_ips = fixed_ip_obj.FixedIPList.get_by_instance_uuid( floating_ips = floating_ip_obj.FloatingIPList.get_by_fixed_ip_id( context, fixed_id) floating_ip = floating_ip_obj.FloatingIP.allocate_address( floating_ip = floating_ip_obj.FloatingIP.get_by_address(context, address) floating_ip_ref = floating_ip_obj.FloatingIP.deallocate(context, address) floating_ip = floating_ip_obj.FloatingIP.get_by_address( context, floating_address) fixed_ip = fixed_ip_obj.FixedIP.get_by_address(context, fixed_address) network = network_obj.Network.get_by_id(context.elevated(), fixed_ip.network_id) floating = floating_ip_obj.FloatingIP.associate(context, floating_address, fixed_address, self.host) floating_ip_obj.FloatingIP.disassociate( context, floating_address) floating_ip = floating_ip_obj.FloatingIP.get_by_address(context, address) fixed_ip = fixed_ip_obj.FixedIP.get_by_id(context, floating_ip.fixed_ip_id) network = network_obj.Network.get_by_id(context.elevated(), fixed_ip.network_id) service = service_obj.Service.get_by_host_and_topic( floating = floating_ip_obj.FloatingIP.disassociate(context, address) return dict(floating_ip_obj.FloatingIP.get_by_id( context, id).iteritems()) pools = floating_ip_obj.FloatingIP.get_pool_names(context) floating_ip = floating_ip_obj.FloatingIP.get_by_address(context, address) floating_ip = floating_ip_obj.FloatingIP.get_by_address(context, address) domain_list = dns_domain_obj.DNSDomainList.get_all(context) dns_domain_obj.DNSDomain.register_for_zone(context, domain, av_zone) dns_domain_obj.DNSDomain.register_for_project(context, domain, project) dns_domain_obj.DNSDomain.delete_by_domain(context, domain)",169,209
openstack%2Fhorizon~master~I90866e9b9718bb5aabf36dc4df18d0a2572db993,openstack/horizon,master,I90866e9b9718bb5aabf36dc4df18d0a2572db993,Showing a more representive message when instance launching fails,ABANDONED,2014-07-09 13:16:51.000000000,2014-07-16 10:29:15.000000000,,"[{'_account_id': 3}, {'_account_id': 4978}, {'_account_id': 8090}, {'_account_id': 8866}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 10046}, {'_account_id': 10295}, {'_account_id': 11022}]","[{'number': 1, 'created': '2014-07-09 13:16:51.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8a49a485506cdbb120315a6fe2a691ce1183d59c', 'message': 'Showing a more representive message when instance launching fails\n\nWhen an instance launch fails due to the flavor disk or memory\nsize, user only gets a ""No valid host was found."" message. Instead\nof it, this patch will show a more representative message, which was\nalready on the code, but wrongly mapped from the exception.\n\nChange-Id: I90866e9b9718bb5aabf36dc4df18d0a2572db993\nCloses-bug: 1276696\n'}]",0,105734,8a49a485506cdbb120315a6fe2a691ce1183d59c,26,9,1,10046,,,0,"Showing a more representive message when instance launching fails

When an instance launch fails due to the flavor disk or memory
size, user only gets a ""No valid host was found."" message. Instead
of it, this patch will show a more representative message, which was
already on the code, but wrongly mapped from the exception.

Change-Id: I90866e9b9718bb5aabf36dc4df18d0a2572db993
Closes-bug: 1276696
",git fetch https://review.opendev.org/openstack/horizon refs/changes/34/105734/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/tables.py'],1,8a49a485506cdbb120315a6fe2a691ce1183d59c,bug/1276696," 'No valid host was found.': _(""There is not enough capacity for this "" ""flavor in the selected availability "" ""zone. Try again later or select a "" ""different availability zone."") } return fault_map.get(message.strip(), default_message)"," 'NoValidHost': _(""There is not enough capacity for this "" ""flavor in the selected availability zone. "" ""Try again later or select a different availability "" ""zone."") } return fault_map.get(message, default_message)",5,5
openstack%2Fnova-specs~master~I5089a204549433dbbb1b4e47972580bc46b8dcc1,openstack/nova-specs,master,I5089a204549433dbbb1b4e47972580bc46b8dcc1,Add nic state aware scheduling,ABANDONED,2014-04-16 14:18:42.000000000,2014-07-16 10:27:38.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 161}, {'_account_id': 216}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 6772}, {'_account_id': 6932}, {'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 9975}, {'_account_id': 10318}]","[{'number': 1, 'created': '2014-04-16 14:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/26cab15d73c333b8b5fe8b8d0d7c62cf6920bcc6', 'message': 'Add nic state aware scheduling\n\nbp nic-state-aware-scheduling\n\nChange-Id: I5089a204549433dbbb1b4e47972580bc46b8dcc1\n'}, {'number': 2, 'created': '2014-04-16 16:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7f058b9c6abffb891447ba307fc6d4bf2461cbdd', 'message': 'Add nic state aware scheduling\n\nbp nic-state-aware-scheduling\n\nChange-Id: I5089a204549433dbbb1b4e47972580bc46b8dcc1\n'}, {'number': 3, 'created': '2014-05-28 14:37:30.000000000', 'files': ['specs/juno/nic-state-aware-scheduling.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1a8b095f5b79304a195b7625765e76d317a51079', 'message': 'Add nic state aware scheduling\n\nbp nic-state-aware-scheduling\n\nChange-Id: I5089a204549433dbbb1b4e47972580bc46b8dcc1\n'}]",29,87978,1a8b095f5b79304a195b7625765e76d317a51079,56,14,3,9708,,,0,"Add nic state aware scheduling

bp nic-state-aware-scheduling

Change-Id: I5089a204549433dbbb1b4e47972580bc46b8dcc1
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/78/87978/3 && git format-patch -1 --stdout FETCH_HEAD,"['specs/juno/nic-state-aware-scheduling.rst', 'specs/juno/nic-state-aware-scheduling.png']",2,26cab15d73c333b8b5fe8b8d0d7c62cf6920bcc6,bp/nic-state-aware-scheduling,,,156,0
openstack%2Fnova-specs~master~I5284892e8b4ad47133df568c7dae563178a7dd3f,openstack/nova-specs,master,I5284892e8b4ad47133df568c7dae563178a7dd3f,Add support for physical CD-ROM when VM is running,ABANDONED,2014-04-15 13:23:03.000000000,2014-07-16 10:27:08.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 964}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 10070}]","[{'number': 1, 'created': '2014-04-15 13:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c2e78e33a9946d67d5300cdb5233b05046e8b934', 'message': ""Add support for physical CD-ROM when VM is running\n\nSometimes we need to attach/detach host's or PC's CD-ROM device to a running\ninstance when we want to access content directly without upload to glance.\n\nblueprint use-physical-cdrom\n\nChange-Id: I5284892e8b4ad47133df568c7dae563178a7dd3f\n""}, {'number': 2, 'created': '2014-04-25 13:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f590ec940c7f0837219eefe57e438f34d0941318', 'message': ""Add support for physical CD-ROM when VM is running\n\nSometimes we need to attach/detach host's or PC's CD-ROM device to a running\ninstance when we want to access content directly without upload to glance.\n\nblueprint use-physical-cdrom\n\nChange-Id: I5284892e8b4ad47133df568c7dae563178a7dd3f\n""}, {'number': 3, 'created': '2014-05-11 09:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/aec0e7cd73957772796e318b728688d49893d913', 'message': ""Add support for physical CD-ROM when VM is running\n\nSometimes we need to attach/detach host's or PC's CD-ROM device to a running\ninstance when we want to access content directly without upload to glance.\n\nblueprint use-physical-cdrom\n\nChange-Id: I5284892e8b4ad47133df568c7dae563178a7dd3f\n""}, {'number': 4, 'created': '2014-05-11 09:20:06.000000000', 'files': ['specs/juno/use-physical-cdrom.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/78defc48c0a83fa349406d4e36f983367ea3466a', 'message': ""Add support for physical CD-ROM when VM is running\n\nSometimes we need to attach/detach host's or PC's CD-ROM device to a running\ninstance when we want to access content directly without upload to glance.\n\nblueprint use-physical-cdrom\n\nChange-Id: I5284892e8b4ad47133df568c7dae563178a7dd3f\n""}]",10,87611,78defc48c0a83fa349406d4e36f983367ea3466a,31,7,4,10070,,,0,"Add support for physical CD-ROM when VM is running

Sometimes we need to attach/detach host's or PC's CD-ROM device to a running
instance when we want to access content directly without upload to glance.

blueprint use-physical-cdrom

Change-Id: I5284892e8b4ad47133df568c7dae563178a7dd3f
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/11/87611/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/use-physical-cdrom.rst'],1,c2e78e33a9946d67d5300cdb5233b05046e8b934,bp/use-physical-cdrom," .. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================== Add support for physical CD-ROM when VM is running ================================================== https://blueprints.launchpad.net/nova/+spec/use-physical-cdrom Sometimes we need to attach/detach host's or PC's CD-ROM device to a running instance when we want to access content directly without upload to glance. Problem description =================== Base on this feature, user needn't to convert CD-ROM disk to ISO file or copy the content of CD-ROM disk into the instance. The feature makes administrator's maintenance more convenient. Proposed change =============== Add CD-ROM service in compute node, add plug in dashboard as CD-ROM client. Thus the CD-ROM of the PC can be use as a host's device. Alternatives ------------ It also supports attach the PC's ISO file. Data model impact ----------------- None REST API impact --------------- The rest API look like this in v2: /v2/{project_id}/servers/{server_id}/action { ""attach_cdrom"":{ ""host_mode"":""false"" } } and look like this in v3: /v3/servers/{server_id}/action { ""attach_cdrom"":{ ""host_mode"":""false"" } } 'host_mode' is false stand use PC's CD-ROM, otherwise use host's CD-ROM. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <hs.chen@huawei.com> Work Items ---------- * Add attach CD-ROM API. * Add testcase of the attach CD-ROM API. Dependencies ============ None Testing ======= Unit tests and tempest tests will check ""attach cdrom"" function. Documentation Impact ==================== A description of this function will be added into Compute API V2 and V3 Reference. References ========== None",,131,0
openstack%2Fnova-specs~master~I7572e8f8feb8a5a8ca0fd66b76dace57459878e5,openstack/nova-specs,master,I7572e8f8feb8a5a8ca0fd66b76dace57459878e5,Nova v2 API should be able to return detailed quotas,ABANDONED,2014-06-13 14:46:45.000000000,2014-07-16 10:23:00.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 5292}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 8866}, {'_account_id': 8932}, {'_account_id': 11022}]","[{'number': 1, 'created': '2014-06-13 14:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/29d4b5243ec03e734f31d3b84c7255864035ecaa', 'message': ""Nova v2 API should be able to return detailed quotas\n\nCompute V2 API returns detailed information about quotas.\nBasically this is a documented part of the os-quota-sets API extension\nin V2 but isn't implemented in the V2 API. It's implemented in the V3\nAPI.\nThis change is adding the detail support for the V2 API so\nthis works:\n/v2/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}?\n\nChange-Id: I7572e8f8feb8a5a8ca0fd66b76dace57459878e5\n""}, {'number': 2, 'created': '2014-06-13 14:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d2936afcac160de13be9025dc5f62945099cb907', 'message': ""Nova v2 API should be able to return detailed quotas\n\nCompute V2 API returns detailed information about quotas.\nBasically this is a documented part of the os-quota-sets API extension\nin V2 but isn't implemented in the V2 API. It's implemented in the V3\nAPI.\nThis change is adding the detail support for the V2 API so\nthis works:\n/v2/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}?\n\nimplements: blueprint v2-api-detailed-quotas\nChange-Id: I7572e8f8feb8a5a8ca0fd66b76dace57459878e5\n""}, {'number': 3, 'created': '2014-06-15 04:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f0af19cec8caed84cdfa61940b014ee73f8af5fe', 'message': ""Nova v2 API should be able to return detailed quotas\n\nCompute V2 API returns detailed information about quotas.\nBasically this is a documented part of the os-quota-sets API extension\nin V2 but isn't implemented in the V2 API. It's implemented in the V3\nAPI.\nThis change is adding the detail support for the V2 API so\nthis works:\n/v2/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}?\n\nimplements: blueprint v2-api-detailed-quotas\nChange-Id: I7572e8f8feb8a5a8ca0fd66b76dace57459878e5\n""}, {'number': 4, 'created': '2014-06-16 14:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f6f7f3754746b9fa9786b4abf3f63b16fd3baba2', 'message': ""Nova v2 API should be able to return detailed quotas\n\nCompute V2 API returns detailed information about quotas.\nBasically this is a documented part of the os-quota-sets API extension\nin V2 but isn't implemented in the V2 API. It's implemented in the V3\nAPI.\nThis change is adding the detail support for the V2 API so\nthis works:\n/v2/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}?\n\nimplements: blueprint v2-api-detailed-quotas\nChange-Id: I7572e8f8feb8a5a8ca0fd66b76dace57459878e5\n""}, {'number': 5, 'created': '2014-06-17 11:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3972fc564f89aafee397b1b1cabddf60f25636b8', 'message': ""Nova v2 API should be able to return detailed quotas\n\nCompute V2 API returns detailed information about quotas.\nBasically this is a documented part of the os-quota-sets API extension\nin V2 but isn't implemented in the V2 API. It's implemented in the V3\nAPI.\nThis change is adding the detail support for the V2 API so\nthis works:\n/v2/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}?\n\nimplements: blueprint v2-api-detailed-quotas\nChange-Id: I7572e8f8feb8a5a8ca0fd66b76dace57459878e5\n""}, {'number': 6, 'created': '2014-06-18 17:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/80ad44c03a24ea76e6e5cb8651d8138888ea24ca', 'message': ""Nova v2 API should be able to return detailed quotas\n\nCompute V2 API returns detailed information about quotas.\nBasically this is a documented part of the os-quota-sets API extension\nin V2 but isn't implemented in the V2 API. It's implemented in the V3\nAPI.\nThis change is adding the detail support for the V2 API so\nthis works:\n/v2/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}?\n\nimplements: blueprint v2-api-detailed-quotas\nChange-Id: I7572e8f8feb8a5a8ca0fd66b76dace57459878e5\n""}, {'number': 7, 'created': '2014-06-18 20:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1c04e7fc197454935bc7fbbf71ed5c36013176f1', 'message': ""Nova v2 API should be able to return detailed quotas\n\nCompute V2 API returns detailed information about quotas.\nBasically this is a documented part of the os-quota-sets API extension\nin V2 but isn't implemented in the V2 API. It's implemented in the V3\nAPI.\nThis change is adding the detail support for the V2 API so\nthis works:\n/v2/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}?\n\nimplements: blueprint v2-api-detailed-quotas\nChange-Id: I7572e8f8feb8a5a8ca0fd66b76dace57459878e5\n""}, {'number': 8, 'created': '2014-06-18 20:33:43.000000000', 'files': ['specs/juno/v2-api-detailed-quotas.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ab4054410c5bdded8a5318344a44dd0ddf0b4eeb', 'message': ""Nova v2 API should be able to return detailed quotas\n\nCompute V2 API does not return detailed information about quotas.\nThere is no direct call to retrieve this information and there is no other\nway to get this information.\n\nBasically this is a documented part of the os-quota-sets API extension\nin V2 but isn't implemented in the V2 API. It's implemented in the V3\nAPI.\nThis change is adding the detail support for the V2 API so\nthis works:\n/v2/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}?\n\nimplements: blueprint v2-api-detailed-quotas\nChange-Id: I7572e8f8feb8a5a8ca0fd66b76dace57459878e5\n""}]",14,99949,ab4054410c5bdded8a5318344a44dd0ddf0b4eeb,50,9,8,8932,,,0,"Nova v2 API should be able to return detailed quotas

Compute V2 API does not return detailed information about quotas.
There is no direct call to retrieve this information and there is no other
way to get this information.

Basically this is a documented part of the os-quota-sets API extension
in V2 but isn't implemented in the V2 API. It's implemented in the V3
API.
This change is adding the detail support for the V2 API so
this works:
/v2/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}?

implements: blueprint v2-api-detailed-quotas
Change-Id: I7572e8f8feb8a5a8ca0fd66b76dace57459878e5
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/49/99949/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/v2-api-detailed-quotas.rst'],1,29d4b5243ec03e734f31d3b84c7255864035ecaa,bp/v2-api-detailed-quotas,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================================================== Nova v2 API should be able to return detailed quotas ===================================================== https://blueprints.launchpad.net/nova/+spec/v2-api-detailed-quotas Compute V2 API returns detailed information about quotas. Basically this is a documented part of the os-quota-sets API extension in V2 but isn't implemented in the V2 API. It's implemented in the V3 API. This change is adding the detail support for the V2 API so this works: /v2/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}? Problem description =================== Right now v2 API documentation shows that it is able to return detailed quota information. This feature is only implemented in v3 API and there is a need to keep consistency with the documentation. Proposed change =============== The idea is to implement this feature as described by the API Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- * Specification for the method * The method returns detailed quota information * GET method * Normal http response code(s) * 200 * Expected error http response code(s) * 404 is the expected error code. This can be due to wrong url. * /v3/?{tenant_id}?/os-quota-sets/?{tenant_id}?/detail/?{user_id}? * Parameters which can be passed via the url * user_id={user_id} * Expected reponse json:: { ""quota_set"": { ""cores"": { ""in_use"": 0, ""limit"": 20, ""reserved"": 0 }, ""fixed_ips"": { ""in_use"": 0, ""limit"": -1, ""reserved"": 0 }, ""floating_ips"": { ""in_use"": 0, ""limit"": 10, ""reserved"": 0 }, ""injected_files"": { ""in_use"": 0, ""limit"": 5, ""reserved"": 0 }, ""instances"": { ""in_use"": 0, ""limit"": 10, ""reserved"": 0 }, ""key_pairs"": { ""in_use"": 0, ""limit"": 100, ""reserved"": 0 }, ""metadata_items"": { ""in_use"": 0, ""limit"": 128, ""reserved"": 0 }, ""ram"": { ""in_use"": 0, ""limit"": 51200, ""reserved"": 0 }, ""security_groups"": { ""in_use"": 0, ""limit"": 10, ""reserved"": 0 }, ""injected_file_content_bytes"": { ""in_use"": 0, ""limit"": 10240, ""reserved"": 0 }, ""injected_file_path_bytes"": { ""in_use"": 0, ""limit"": 255, ""reserved"": 0 }, ""security_group_rules"": { ""in_use"": 0, ""limit"": 20, ""reserved"": 0 } } } * The policy change needed is to include the call ""compute_extension:quotas:detail"": ""rule:admin_api"" to the policy.json Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: tellesmvn Work Items ---------- * Implement the detail method that works just like show but returns detailed quota Dependencies ============ None Testing ======= Integration tests will be added using the tempest test for show method as a bases for this one. Since they work very much alike, the tests will not be very different. Documentation Impact ==================== None References ========== None ",,188,0
openstack%2Fnova-specs~master~I880a4b5d7a8adf8b3b29e0b5bce7383871d79a45,openstack/nova-specs,master,I880a4b5d7a8adf8b3b29e0b5bce7383871d79a45,Proposed blueprint to add extra specs to flavor calls.,ABANDONED,2014-05-26 05:41:28.000000000,2014-07-16 10:22:26.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 7532}]","[{'number': 1, 'created': '2014-05-26 05:41:28.000000000', 'files': ['specs/juno/add-extra-specs-to-flavor-calls.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9a2a6b4365959a4e5769017edbe46f4216e6130f', 'message': 'Proposed blueprint to add extra specs to flavor calls.\n\nThis blueprint would add extra specs information to the response\nof the flavor show and list calls.\n\nChange-Id: I880a4b5d7a8adf8b3b29e0b5bce7383871d79a45\n'}]",0,95408,9a2a6b4365959a4e5769017edbe46f4216e6130f,14,5,1,7532,,,0,"Proposed blueprint to add extra specs to flavor calls.

This blueprint would add extra specs information to the response
of the flavor show and list calls.

Change-Id: I880a4b5d7a8adf8b3b29e0b5bce7383871d79a45
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/08/95408/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/add-extra-specs-to-flavor-calls.rst'],1,9a2a6b4365959a4e5769017edbe46f4216e6130f,bp/to,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================== Add extra specs info to flavor list and show calls ================================================== https://blueprints.launchpad.net/nova/+spec/add-extra-specs-to-flavor-list In this blueprint we aim to add the extra specs information to the flavor list and show call responses. Problem description =================== When we make a flavor show or flavor list call, currently the response does not include the extra specs information. We need to make an additional call to get the extra specs corresponding to that flavor. Proposed change =============== In order to get both the flavor information as well as the extra specs associated with the flavor in one API call, I propose that we include the extra specs information in the response of the flavor list and show calls itself. This will avoid an extra call to get all the information about a flavor. The current db call to get flavor information already makes the call to get the extra specs associated with the flavor. So the only change that is required here is to add the extra specs to the response template. Hence, there will be no change in the db calls and performance or response time. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- API requests for the flavor list and show call will not change. There will be a change in the API responses: Flavor show call - V3 API specification: Request: GET: v3/flavors/{flavor_id} Response:: { ""flavor"": { ""id"": ""1"", ""links"": [ { ""href"": ""http://openstack.example.com/v3/flavors/1"", ""rel"": ""self"" }, { ""href"": ""http://openstack.example.com/flavors/1"", ""rel"": ""bookmark"" } ], ""extra_specs"": {""key1"": ""value1"", ""key2"": ""value2""}, ""name"": ""small"", ""ram"": 512, ""disk"": 10, ""swap"": 0, ""vcpus"": 1 } } Flavor list call - V3 API specification: Request: GET: v3/flavors Response:: { ""flavors"": [ { ""id"": ""1"", ""name"": ""256 MB Server"", ""ram"": 256, ""disk"": 10, ""vcpus"": 1, ""links"": [ { ""href"": ""http://openstack.example.com/v3/1"", ""rel"": ""self"" }, { ""href"": ""http://openstack.example.com/flavors/1"", ""rel"": ""bookmark"" } ], ""extra_specs"": {""key1"": ""value1"", ""key2"": ""value2""}, }, { ""id"": ""2"", ""name"": ""512 MB Server"", ""ram"": 512, ""disk"": 20, ""vcpus"": 2, ""links"": [ { ""href"": ""http://openstack.example.com/v3/flavors/2"", ""rel"": ""self"" }, { ""href"": ""http://openstack.example.com/flavors/2"", ""rel"": ""bookmark"" } ], ""extra_specs"": {""key1"": ""value1"", ""key2"": ""value2""}, } ] } Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- The response of the API needs to change in the documentation. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: aditirav Work Items ---------- * Changes to be made to the API responses of the flavor list and show calls. * Changes to the python nova client to not make an additional call to get extra specs associated with the flavor. Dependencies ============ None Testing ======= Tempest tests to be added to check if the flavor list and show calls have the extra specs information included in the response. Documentation Impact ==================== Changes to be made to the flavor API documentation to include the extra specs information in the response of show and list calls. References ========== None ",,202,0
openstack%2Foslo-incubator~master~I855d5f2001ac721249217d9fbd782c64af9db874,openstack/oslo-incubator,master,I855d5f2001ac721249217d9fbd782c64af9db874,Fix deletion of cached file for policy enforcer,MERGED,2014-07-11 16:50:11.000000000,2014-07-16 10:22:07.000000000,2014-07-16 10:22:06.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-07-11 16:50:11.000000000', 'files': ['openstack/common/fileutils.py', 'openstack/common/policy.py', 'tests/unit/test_policy.py', 'tests/unit/test_fileutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2b966f94de7367b5d0915d8e301b9b0e78d8c831', 'message': ""Fix deletion of cached file for policy enforcer\n\nPolicy ENFORCER's method 'clear' does not really\ndelete cached file as written in its docstring.\n\nThis commit adds 'delete_cached_file' to fileutils\nand makes 'clear' method of ENFORCER use it.\n\nChange-Id: I855d5f2001ac721249217d9fbd782c64af9db874\nCloses-Bug: #1340843\n""}]",0,106433,2b966f94de7367b5d0915d8e301b9b0e78d8c831,12,4,1,8851,,,0,"Fix deletion of cached file for policy enforcer

Policy ENFORCER's method 'clear' does not really
delete cached file as written in its docstring.

This commit adds 'delete_cached_file' to fileutils
and makes 'clear' method of ENFORCER use it.

Change-Id: I855d5f2001ac721249217d9fbd782c64af9db874
Closes-Bug: #1340843
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/33/106433/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/fileutils.py', 'openstack/common/policy.py', 'tests/unit/test_policy.py', 'tests/unit/test_fileutils.py']",4,2b966f94de7367b5d0915d8e301b9b0e78d8c831,delete_cached_file," def test_delete_cached_file(self): filename = '/this/is/a/fake/deletion/of/cached/file' fileutils._FILE_CACHE = { filename: {""data"": 1123, ""mtime"": 1} } self.assertIn(filename, fileutils._FILE_CACHE) fileutils.delete_cached_file(filename) self.assertNotIn(filename, fileutils._FILE_CACHE) def test_delete_cached_file_not_exist(self): # We expect that if cached file does not exist no Exception raised. filename = '/this/is/a/fake/deletion/attempt/of/not/cached/file' self.assertNotIn(filename, fileutils._FILE_CACHE) fileutils.delete_cached_file(filename) self.assertNotIn(filename, fileutils._FILE_CACHE) ",,36,2
openstack%2Fnova-specs~master~I26fda89e3a3a6eed15fc13daf8a49111e13c30e2,openstack/nova-specs,master,I26fda89e3a3a6eed15fc13daf8a49111e13c30e2,Blueprint for the implementation of Nested Quota Driver API,ABANDONED,2014-06-24 07:58:42.000000000,2014-07-16 10:21:27.000000000,,"[{'_account_id': 3}, {'_account_id': 136}, {'_account_id': 1849}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-06-24 07:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/21a7b4154fd3dff3066fe53fa8473bf0adc7dec7', 'message': 'nova api commit\n\nChange-Id: I26fda89e3a3a6eed15fc13daf8a49111e13c30e2\n'}, {'number': 2, 'created': '2014-06-24 09:45:54.000000000', 'files': ['specs/juno/nested-quota-driver-api.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8052b0b4dbf9e95468b4d33be985108cc1bd292a', 'message': 'Blueprint for the implementation of Nested Quota Driver API\n\nNested Quota Driver API helps in the enforcement of\nquotas in hierarchical projects\n\nChange-Id: I26fda89e3a3a6eed15fc13daf8a49111e13c30e2\n'}]",0,102142,8052b0b4dbf9e95468b4d33be985108cc1bd292a,10,4,2,11057,,,0,"Blueprint for the implementation of Nested Quota Driver API

Nested Quota Driver API helps in the enforcement of
quotas in hierarchical projects

Change-Id: I26fda89e3a3a6eed15fc13daf8a49111e13c30e2
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/42/102142/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/nested-quota-driver-api.rst'],1,21a7b4154fd3dff3066fe53fa8473bf0adc7dec7,bp/for,"This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================= nested-quota-driver-api ======================= https://blueprints.launchpad.net/nova/+spec/nested-quota-driver-api Nested quota driver for Nested Quota Management will enable OpenStack projects to enforce quota in nested projects.The current openstack nova implementation can support only one level of hierarchy,ie projects and users.The nested projects is having a hierarchical structure, where each project contains projects and users inside it ,except those at the leaf nodes,which contain only users. Problem description =================== Use Case 1 : Consider the use case of a special effects company named Industrial Light And Magic(ILM). The parent project ILM ,will be having different projects like ANIMATION,ACTION and FICTION,to deal with different types of films.So, under FICTION there will be projects like MATRIX,AVATAR etc ,under ACTION there will be MI,SKYFALL etc and ANIMATION will be having projects like SHREK,TINTIN etc.Consider the hierarchy ILM->FICTION->MATRIX.Suppose, George is having admin role in ILM,John is having admin role in FICTION and Peter is having admin role in MATRIX.Through role inheritance,George and John will be having the same role in their child projects. Suppose the free instance cores in ILM and FICTION are 500 and 100,respectively.And MATRIX, which has a total allocation of 50 cores,needs an additional 150 cores.If the user is George ,FICTION will take 50 cores from ILM ,and a total of 150 cores will be given to MATRIX.But John cannot provide 150 cores to MATRIX, as he doesn't have any role in ILM and FICTION is having only 100 free cores with it. Suppose after some time, MATRIX doesn't require 75 cores and it needs to be allocated back to the parent project.If John is doing the deletion,the 75 cores will add to the free quota of FICTION and if George is doing the deletion,75 cores will add to the free quota of ILM. For efficient utilization of resources,it is ensured that more free quota is available at the higher levels,so that maximum number of projects can make use of it. Proposed change =============== Quota Allocation: When the user tries to do an allocation in a project,all the hierarchy up to the topmost parent where the user is having a role is found out.The free quota is accumulated by traversing up the order, till the sufficient amount of quota is found and the allocation will be done top down the order. Quota Deletion: If the quota is deleted,then that quota will add to the free quota of the top most project where the user who is deleting is having the same role. Project Deletion: A project can be deleted if it doesn't have allocation in the child project.The quota of the deleted project ,will add to the free quota of the top most project where the user is having the same role. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ If the sufficient free quota is not available with the immediate parent,it has to be taken from the projects further up in the order ,which requires more database operations Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Sajeesh Other contributors: vishy shwicke raildo tellesnobrega morganfainberg Work Items ---------- 1.The current dbquotadriver should be extended for nested projects 2.When the immediate parent is not having sufficient quota for the child ,there should be an iterative mechanism to go up the hierarchy till sufficient quota is found. 3.While deletion of quota and projects,the free quota should add to the topmost parent project,where the user who is deleting is having the same rule. Dependencies ============ Depends on keystone to get the hierarchy of projects,and the users and their corresponding roles in those projects Testing ======= Integration and unit tests should be added.It should be verified that ,whether the quota is properly allocated from the parent and if sufficient quota is not available with the immediate parent,it is taken from higher levels.Also,it should be verfied that ,when there is a deletion of quota or project,the free quota is getting added to the top most project,where the user is having the same role. Documentation Impact ==================== None References ========== https://wiki.openstack.org/wiki/HierarchicalMultitenancy ",,113,0
openstack%2Fnova-specs~master~I0ef1e073afaabd66416937a028bd1611b244b79d,openstack/nova-specs,master,I0ef1e073afaabd66416937a028bd1611b244b79d,VMware nova driver - datastore image cache update improvements,ABANDONED,2014-04-02 08:30:44.000000000,2014-07-16 10:20:54.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 7239}, {'_account_id': 7400}, {'_account_id': 7575}, {'_account_id': 8759}, {'_account_id': 9555}]","[{'number': 1, 'created': '2014-04-02 08:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/61bb1f5cb9b3560e90ecb274d00271a30d657a8c', 'message': 'VMware nova driver - datastore image cache update improvements\n\nIf an image is available in the cache of one cluster, then copy of\nimage from glance to nova (proxy VM) can be completely avoided by using\nvCenter APIs to copy the cached image from one datastore to another\ndatastore.\n\nChange-Id: I0ef1e073afaabd66416937a028bd1611b244b79d\n'}, {'number': 2, 'created': '2014-04-02 09:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/41b57e947d767422bc94a16165ec1e56dfed1c55', 'message': 'VMware nova driver - datastore image cache update improvements\n\nIf an image is available in the cache of one cluster, then copy of\nimage from glance to nova (proxy VM) can be completely avoided by using\nvCenter APIs to copy the cached image from one datastore to another\ndatastore.\n\nChange-Id: I0ef1e073afaabd66416937a028bd1611b244b79d\n'}, {'number': 3, 'created': '2014-04-10 16:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/50564057619000143ab97d84f7c343fb033a550d', 'message': 'VMware nova driver - datastore image cache update improvements\n\nIf an image is available in the cache of one cluster, then copy of\nimage from glance to nova (proxy VM) can be completely avoided by using\nvCenter APIs to copy the cached image from one datastore to another\ndatastore.\n\nChange-Id: I0ef1e073afaabd66416937a028bd1611b244b79d\n'}, {'number': 4, 'created': '2014-04-15 06:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3f588f8a9fb6a92968cbfb90eb4649a98de5cb4c', 'message': 'VMware nova driver - datastore image cache update improvements\n\nIf an image is available in the cache of one cluster, then copy of\nimage from glance to nova (proxy VM) can be completely avoided by using\nvCenter APIs to copy the cached image from one datastore to another\ndatastore.\n\nChange-Id: I0ef1e073afaabd66416937a028bd1611b244b79d\n'}, {'number': 5, 'created': '2014-04-28 11:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/81605d76c73f24011e1f7f5acabd5ac35db08900', 'message': 'VMware nova driver - datastore image cache update improvements\n\nIf an image is available in the cache of one cluster, then copy of\nimage from glance to nova (proxy VM) can be completely avoided by using\nvCenter APIs to copy the cached image from one datastore to another\ndatastore.\n\nChange-Id: I0ef1e073afaabd66416937a028bd1611b244b79d\n'}, {'number': 6, 'created': '2014-06-08 15:03:03.000000000', 'files': ['specs/juno/datastore-image-cache-update-improvements.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/12f4c7b360e5741a2a677f5922a00d4ececd8d29', 'message': 'VMware nova driver - datastore image cache update improvements\n\nIf an image is available in the cache of one cluster, then copy of\nimage from glance to nova (proxy VM) can be completely avoided by using\nvCenter APIs to copy the cached image from one datastore to another\ndatastore.\n\nChange-Id: I0ef1e073afaabd66416937a028bd1611b244b79d\n'}]",73,84662,12f4c7b360e5741a2a677f5922a00d4ececd8d29,55,10,6,7239,,,0,"VMware nova driver - datastore image cache update improvements

If an image is available in the cache of one cluster, then copy of
image from glance to nova (proxy VM) can be completely avoided by using
vCenter APIs to copy the cached image from one datastore to another
datastore.

Change-Id: I0ef1e073afaabd66416937a028bd1611b244b79d
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/62/84662/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/datastore-image-cache-update-improvements.rst'],1,61bb1f5cb9b3560e90ecb274d00271a30d657a8c,bp/vmware-image-cache,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== VMware nova driver - datastore image cache update improvements ========================================== https://blueprints.launchpad.net/nova/+spec/datastore-image-cache-update-improvements If an image is available in the cache of one cluster, then copy of image from glance to nova (proxy VM) and from proxy to the datastore can be completely avoided by using vCenter APIs to copy the cached image from one datastore to another datastore of the cluster. Problem description =================== VMware nova driver - datastore image cache update improvements In the existing design, when an instance creation is done, the following occur *1. The existence of the image is checked in the cache (directory named _base_dir) on the cluster's datastore *2. If the image is not available in the cache, then the image is downloaded from glance into nova (proxy VM) when the compute service runs, and then from the compute service to the datastore by vCenter *3. Instance is spawned using the cached image Step 2 is a CPU intensive and time and bandwidth consuming task. The existing optimization being done throttle the number of images transferred and removed unnecessary queues. This is applicable for the first time the image is transferred to a datastore cache. In case the same image is deployed into another cluster that exists on the same vCenter the process is repeated. This would mean that the same image is getting transferred multiple times between glance and nova for each cluster present in vCenter. Proposed change =============== Proposal: If an image is available in the cache of one cluster, then copy of image from glance to nova (proxy VM) can be completely avoided by using vCenter APIs to copy the cached image from one datastore to another datastore. By using vCenter the progress of the task can be tracked as well. This approach works for clusters within the same vCenter. With this approach the modified steps would be *1. The existence of the image is checked in the cache (_base directory) on ALL the cluster's datastores using vCenter APIs *2. If the image is not available in ANY CLUSTERS the cache, then the image is downloaded from glance into nova (proxy VM) when the compute service runs, and then from the compute service to the datastore by vCenter *3. If the image is available in the cache of any cluster, then the image is copied to the other clusters cache using the vCenter API. This is very much efficient than the two hop transfer. *4. Instance is spawned using the cached image Given that in a private cloud there will be different set of standard images, and the number of clusters in vCenter can be between 12 to 64, enhancing the model used to update the image cache in the datastore will significantly improve user experience, reduce instance creation times, reduce CPU load on the compute proxy and reduce traffic on the network Alternatives ------------ Another alternative is to schedule instances to the clusters that have the image already cached. This will work fine until the cluster has capacity. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ * A map of the image ids present in the cache (_base_dir) must be maintained to reduce the checking of images existence in the datastore in every spawn Other deployer impact --------------------- None Developer impact ---------------- * The similar approach can be used by other nova drivers that support clusters and cache images ona per cluster basis. Implementation ============== Assignee(s) ----------- Primary assignee: kiran-kumar-vaddi Other contributors: None Work Items ---------- * Build the map of image cache ids on start of the compute service * Update the map of the image cache ids when new image is uploaded * During spawn, If image is already present in the cache then use the new code to copy the image from one datastore to another * During spawn, If image is _not_ already present in the cache then use existing code. Dependencies ============ None Testing ======= Unit tests are sufficient since the actual copy is done by the vCenter API The unit tests will test the branches introduced Documentation Impact ==================== None References ========== None ",,160,0
openstack%2Fnova-specs~master~If4ed37d81b74d4ab41cc05d89d12fe3578005dbc,openstack/nova-specs,master,If4ed37d81b74d4ab41cc05d89d12fe3578005dbc,Address slow queries,ABANDONED,2014-06-03 14:40:41.000000000,2014-07-16 10:20:29.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 1501}, {'_account_id': 1528}, {'_account_id': 1849}, {'_account_id': 6062}, {'_account_id': 8688}]","[{'number': 1, 'created': '2014-06-03 14:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5149ddc0efe093196477ba9264433b5988cfbb8f', 'message': 'Address slow queries\n\nChange-Id: If4ed37d81b74d4ab41cc05d89d12fe3578005dbc\n'}, {'number': 2, 'created': '2014-06-03 14:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5e6d261ed336bc02dcc050cb404dfa9bd8206ba0', 'message': 'Address slow queries\n\nAnalysis of the MySQL slow query log has revealed some queries which are not using indexes. This causes a scalability issue when combined with soft delete.\n\nAdvances blueprint: nova-juno-slow-queries\n\nChange-Id: If4ed37d81b74d4ab41cc05d89d12fe3578005dbc\n'}, {'number': 3, 'created': '2014-06-03 14:47:18.000000000', 'files': ['specs/juno/slow-queries.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/008e2babe683d84f8e0c58549dba68f7a5f3bd8c', 'message': 'Address slow queries\n\nAnalysis of the MySQL slow query log has revealed some queries which are not\nusing indexes. This causes a scalability issue when combined with soft\ndelete.\n\nAdvances blueprint: nova-juno-slow-queries\n\nChange-Id: If4ed37d81b74d4ab41cc05d89d12fe3578005dbc\n'}]",17,97520,008e2babe683d84f8e0c58549dba68f7a5f3bd8c,21,8,3,8688,,,0,"Address slow queries

Analysis of the MySQL slow query log has revealed some queries which are not
using indexes. This causes a scalability issue when combined with soft
delete.

Advances blueprint: nova-juno-slow-queries

Change-Id: If4ed37d81b74d4ab41cc05d89d12fe3578005dbc
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/20/97520/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/slow-queries.rst'],1,5149ddc0efe093196477ba9264433b5988cfbb8f,bp/nova-juno-slow-queries,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================== Optimise slow queries ===================== https://blueprints.launchpad.net/nova/+spec/nova-juno-slow-queries Problem description =================== Analysis of the MySQL slow query log has revealed some queries which are not using indexes. This causes a scalability issue when combined with soft delete. Proposed change =============== This specification proposes a number of changes to table indexes to alleviate these symptoms. The volume_usage_cache table is missing an index on (volume_id):: Count: 9848 Time=3.71s (36526s) SELECT ... FROM volume_usage_cache WHERE volume_usage_cache.volume_id = 'S' LIMIT N The reservations table is missing an index on (deleted, expire):: Count: 612 Time=7.51s (4596s) UPDATE reservations SET updated_at=updated_at, deleted_at='S', deleted=id WHERE reservations.deleted = N AND reservations.expire < 'S' Count: 612 Time=7.22s (4420s) SELECT ... FROM reservations INNER JOIN quota_usages ON quota_usages.id = reservations.usage_id WHERE reservations.deleted = N AND reservations.expire < 'S' Table instances has several indexes which include 'deleted':: host, deleted uuid, deleted host, node, deleted host, deleted, cleaned As 'deleted' is often a very powerful way to reduce the result, it should go first. Further, the (host, deleted) index is unnecessary, as the more-specific indexes can provide that:: deleted, uuid deleted, host, node deleted, host, cleaned An additional index should be added to cover (deleted, project_id, user_id):: Count: 1236 Time=2.70s (3342s) SELECT count(i.id), sum(instances.vcpus), sum(i.memory_mb) FROM instances i WHERE i.deleted = N AND i.project_id = 'S' AND i.user_id = 'S' LIMIT N Finally, an index should be added to cover (deleted, vm_state, created_at, project_id). These queries are somewhat complex but very similar, the interesting part of each is the subselect:: Count: 2417 Time=2.96s (7160s) SELECT ... FROM (SELECT ... FROM instances WHERE i.deleted = N AND i.vm_state != 'S' AND i.project_id = 'S' ORDER BY i.created_at DESC, i.created_at DESC, i.created_at DESC, i.id DESC LIMIT N) AS a LEFT OUTER JOIN security_group_instance_association AS sgia ON sgia.instance_uuid = a.instances_uuid AND a.instances_deleted = N LEFT OUTER JOIN security_groups AS sg ON sg.id = sgia.security_group_id AND sgia.deleted = N AND sg.deleted = N LEFT OUTER JOIN instance_info_caches AS iic ON iic.instance_uuid = a.instances_uuid ORDER BY a.instances_created_at DESC, a.instances_created_at DESC, a.instances_created_at DESC, a.instances_id DESC Count: 399 Time=3.02s (1206s) SELECT ... FROM (SELECT ... FROM instances WHERE i.deleted = N AND i.vm_state != 'S' AND i.project_id = 'S' ORDER BY i.created_at DESC, i.created_at DESC, i.created_at DESC, i.id DESC LIMIT N) AS a LEFT OUTER JOIN instance_info_caches AS iic ON iic.instance_uuid = a.instances_uuid LEFT OUTER JOIN security_group_instance_association AS sgia ON sgia.instance_uuid = a.instances_uuid AND a.instances_deleted = N LEFT OUTER JOIN security_groups AS sg ON sg.id = sgia.security_group_id AND sgia.deleted = N AND sg.deleted = N ORDER BY a.instances_created_at DESC, a.instances_created_at DESC, a.instances_created_at DESC, a.instances_id DESC Count: 52 Time=5.38s (279s) SELECT ... FROM (SELECT ... FROM instances WHERE i.deleted = N AND i.vm_state != 'S' AND (i.created_at < 'S' OR i.created_at = 'S' AND i.created_at < 'S' OR i.created_at = 'S' AND i.created_at = 'S' AND i.id < N) ORDER BY i.created_at DESC, i.created_at DESC, i.created_at DESC, i.id DESC LIMIT N) AS a LEFT OUTER JOIN security_group_instance_association AS sgia ON sgia.instance_uuid = a.instances_uuid AND a.instances_deleted = N LEFT OUTER JOIN security_groups AS sg ON sg.id = sgia.security_group_id AND sgia.deleted = N AND sg.deleted = N LEFT OUTER JOIN instance_info_caches AS iic ON iic.instance_uuid = a.instances_uuid ORDER BY a.instances_created_at DESC, a.instances_created_at DESC, a.instances_created_at DESC, a.instances_id DESC Count: 15 Time=3.05s (45s) SELECT ... FROM (SELECT ... FROM instances WHERE i.deleted = N AND i.vm_state != 'S' ORDER BY i.created_at DESC, i.created_at DESC, i.created_at DESC, i.id DESC LIMIT N) AS a LEFT OUTER JOIN security_group_instance_association AS sgia ON sgia.instance_uuid = a.instances_uuid AND a.instances_deleted = N LEFT OUTER JOIN security_groups AS sg ON sg.id = sgia.security_group_id AND sgia.deleted = N AND sg.deleted = N LEFT OUTER JOIN instance_info_caches AS iic ON iic.instance_uuid = a.instances_uuid ORDER BY a.instances_created_at DESC, a.instances_created_at DESC, a.instances_created_at DESC, a.instances_id DESC Alternatives ------------ The scalability issue can be mitigated through automatically clearing down soft-deleted rows. However performance will always be improved through correct use of indexes. Data model impact ----------------- At least one migration is proposed by this change. It is open for discussion how many migrations the proposed changes are split over. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ Database performance should be improved. A modest amount of additional storage will be required to hold the additional indexes. Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: alexisl Other contributors: None Work Items ---------- * Add volume_usage_cache (volume_id) * Add reservations (deleted, expire) * Delete instances indexes:: host, deleted uuid, deleted host, node, deleted host, deleted, cleaned * Add instances indexes:: deleted, uuid deleted, host, node deleted, host, cleaned deleted, project_id, user_id deleted, vm_state, created_at, project_id Dependencies ============ None. Testing ======= I'd expect this to be adequately tested by whatever performance testing is already in place. Documentation Impact ==================== None. References ========== None. ",,260,0
openstack%2Ffuel-main~master~Icef47a0dfd5533112cca0c1d7b3760d011818e71,openstack/fuel-main,master,Icef47a0dfd5533112cca0c1d7b3760d011818e71,Move to internal  osci repository (centos and ubuntu) for building mirrors,MERGED,2014-05-26 14:22:58.000000000,2014-07-16 10:20:26.000000000,2014-06-27 13:23:41.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8789}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 9977}, {'_account_id': 10474}]","[{'number': 1, 'created': '2014-05-26 14:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f2cd636938f5a820ab2cdb15cb532062b17ebc9b', 'message': 'Move to internal  osci repository (centos and ubuntu) for building mirrors\n\nAddres for new internal upstream repository is mirrors-local-msk.msk.mirantis.net\n\nChange-Id: Icef47a0dfd5533112cca0c1d7b3760d011818e71\n'}, {'number': 2, 'created': '2014-06-04 12:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9018c490b11f42e25dbb6d27cbd9ab3fee722e9c', 'message': 'Move to internal  osci repository (centos and ubuntu) for building mirrors\n\nAddres for new internal upstream repository is mirrors-local-msk.msk.mirantis.net\n\nChange-Id: Icef47a0dfd5533112cca0c1d7b3760d011818e71\n'}, {'number': 3, 'created': '2014-06-04 13:00:39.000000000', 'files': ['config.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9ebd199fb61c41744bbc91608d4490cadbc3cf5e', 'message': 'Move to internal  osci repository (centos and ubuntu) for building mirrors\n\nAddres for new internal upstream repository is mirrors-local-msk.msk.mirantis.net\nCloses-bug: #1311095\nChange-Id: Icef47a0dfd5533112cca0c1d7b3760d011818e71\n'}]",1,95531,9ebd199fb61c41744bbc91608d4490cadbc3cf5e,30,8,3,8777,,,0,"Move to internal  osci repository (centos and ubuntu) for building mirrors

Addres for new internal upstream repository is mirrors-local-msk.msk.mirantis.net
Closes-bug: #1311095
Change-Id: Icef47a0dfd5533112cca0c1d7b3760d011818e71
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/31/95531/2 && git format-patch -1 --stdout FETCH_HEAD,['config.mk'],1,f2cd636938f5a820ab2cdb15cb532062b17ebc9b,(detached,MIRROR_CENTOS?=mirrors-local-msk.msk.mirantis.net/centos/$(CENTOS_RELEASE)MIRROR_UBUNTU?=mirrors-local-msk.msk.mirantis.net/ubuntu/,MIRROR_CENTOS?=http://mirrors.msk.mirantis.net/centos/$(CENTOS_RELEASE)MIRROR_UBUNTU?=http://mirror.yandex.ru/ubuntu/,2,2
openstack%2Fnova-specs~master~Id8f85219343b32306a7ee8e12e58d5994f72dbff,openstack/nova-specs,master,Id8f85219343b32306a7ee8e12e58d5994f72dbff,Add transport support to iscsi,ABANDONED,2014-04-10 15:52:19.000000000,2014-07-16 10:19:45.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 67}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4523}, {'_account_id': 6575}, {'_account_id': 6598}, {'_account_id': 6699}, {'_account_id': 12088}]","[{'number': 1, 'created': '2014-04-10 15:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7133a4a89f7978627887966bd1edc175079c5853', 'message': 'Add transport support to iscsi\n\nblueprint add-transport-support-to-iscsi\n\nChange-Id: Id8f85219343b32306a7ee8e12e58d5994f72dbff\n'}, {'number': 2, 'created': '2014-04-10 16:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8dc06933943727076fabca938ba189f5c44ab3bc', 'message': 'Add transport support to iscsi\n\nblueprint add-transport-support-to-iscsi\n\nChange-Id: Id8f85219343b32306a7ee8e12e58d5994f72dbff\n'}, {'number': 3, 'created': '2014-04-28 12:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/bb05c1b3c0b78ddcdf9fb5729f40b06c1279e58c', 'message': 'Add transport support to iscsi\n\nblueprint add-transport-support-to-iscsi\n\nChange-Id: Id8f85219343b32306a7ee8e12e58d5994f72dbff\n'}, {'number': 4, 'created': '2014-04-30 08:52:56.000000000', 'files': ['specs/juno/add-transport-support-to-iscsi.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a6142f0fb555c7af241deee1193c13a87d822fa6', 'message': 'Add transport support to iscsi\n\nblueprint add-transport-support-to-iscsi\n\nChange-Id: Id8f85219343b32306a7ee8e12e58d5994f72dbff\n'}]",21,86637,a6142f0fb555c7af241deee1193c13a87d822fa6,46,11,4,6575,,,0,"Add transport support to iscsi

blueprint add-transport-support-to-iscsi

Change-Id: Id8f85219343b32306a7ee8e12e58d5994f72dbff
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/37/86637/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/add-transport-support-to-iscsi.rst'],1,7133a4a89f7978627887966bd1edc175079c5853,bp/add-transport-support-to-iscsi,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Add transport support to iscsi ========================================== https://blueprints.launchpad.net/nova/+spec/add-transport-support-to-iscsi Refactor ISCSIDriver to support other iSCSI transports besides TCP which will allow minimal changes to support iSER. Problem description =================== Currently, Vendors who have their iSCSI driver, and want to add RDMA transport cannot leverage their existing plug-in driver which inherit from iSCSI And must modify their driver or create an additional plug-in driver which inherit from iSER, and copy the exact same code. Proposed change =============== On the initiator side the only difference between TCP and RDMA is in the interface flag (--interface=[iface]) e.g. ""iscsiadm -m discoverydb -t st -p ip:port -I iser --discover"" The required changes are: * Add a parameter called ""default_rdma"" (default to false) to enable rdma. The operation that ""default_rdma"" would mean try RDMA and if it fails fall back to TCP, to simplify operations. * The existing ISER code will be removed. Alternatives ------------ Currently, there's an ISER subclass in iscsi for Cinder (starting Havana) I think that the right/better approach is as suggested by this blueprint. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ iSER (iSCSI over RDMA) allow 5x faster bandwidth compared to using iSCSI TCP. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Assignee: shlomis <shlomis@mellanox.com> Work Items ---------- * Remove iser from 'libvirt_volume_drivers' here: ./nova/virt/libvirt/driver.py * Remove iser code and opts. Add 'default_rdma' and implementation here: ./nova/virt/libvirt/volume.py Dependencies ============ Cinder blueprint: https://blueprints.launchpad.net/cinder/+spec/add-transport-support-to-iscsi Testing ======= The same as for iSCSI TCP Documentation Impact ==================== The new configuration parameter 'default_rdma' should be documented References ========== None ",,122,0
openstack%2Fnova-specs~master~I0e18646d8b14e1d26145094adeba758ade7e7938,openstack/nova-specs,master,I0e18646d8b14e1d26145094adeba758ade7e7938,Adds lock-free quota management spec,ABANDONED,2014-06-02 18:22:59.000000000,2014-07-16 10:18:58.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 1849}, {'_account_id': 6849}]","[{'number': 1, 'created': '2014-06-02 18:22:59.000000000', 'files': ['specs/juno/lock-free-quota-management.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/dce7470bf5f34162f8f57a5a3f9a63e2a4258b21', 'message': 'Adds lock-free quota management spec\n\nLock-free quota management implementation\n\nBlueprint lock-free-quota-management\n\nChange-Id: I0e18646d8b14e1d26145094adeba758ade7e7938\n'}]",6,97310,dce7470bf5f34162f8f57a5a3f9a63e2a4258b21,17,5,1,7,,,0,"Adds lock-free quota management spec

Lock-free quota management implementation

Blueprint lock-free-quota-management

Change-Id: I0e18646d8b14e1d26145094adeba758ade7e7938
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/10/97310/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/lock-free-quota-management.rst'],1,dce7470bf5f34162f8f57a5a3f9a63e2a4258b21,bp/lock-free-quota-management,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================ A lock-free quota implementation ================================ https://blueprints.launchpad.net/nova/+spec/lock-free-quota-management Implement a lock-free quota management algorithm that removes the use of the SELECT FOR UPDATE in the database API. Problem description =================== When launching a single instance in Nova, more than 120 database queries may be made against the Nova, Neutron, Glance and/or Cinder databases. Of these queries, a significant portion of them involve quota management tasks -- checking for existing quotas, checking for existing project and user usage records, claiming the resources used in a reservation, and either committing or rolling back those reservations once the launch sequence succeeds or fails. The `SELECT FOR UPDATE` SQL construct is used in Nova in a couple places, to ensure that no two concurrent threads attempt to update the same rows in the database. When a thread selects records with `SELECT FOR UPDATE`, the thread is announcing that it intends to modify the records it is reading from the table -- this is called a write-intent lock. If another thread wants to update the same set of records, it will issue a `SELECT FOR UPDATE` call, and this call will wait until the first thread has completed the transaction and either issued a `COMMIT` or a `ROLLBACK`. In the case of traditional RDBMS systems like PostgreSQL or MySQL, calls to `SELECT FOR UPDATE` are, by nature, a detriment to scalability, since only a single thread may hold the write-intent lock on the same rows in the table at any given time. All other threads must wait while the single writer thread finishes what it is doing. In the case of Nova, the use of `SELECT FOR UPDATE` is predominantly in two areas: quota management and assignment of free IP addresses in nova-network's IPAM layer. In addition to `SELECT FOR UPDATE`'s inherent scalability issues, a popular replication variant of MySQL, called MySQL Galera, does not support the write-intent locks that `SELECT FOR UPDATE` requires. What this means, in practice, for deployers of Nova with MySQL Galera, is that occasionally the MySQL client will return a deadlock error when two threads simultaneously attempt to change the same set of rows. A deadlock in the traditional sense of the term does not actually occur, but Galera raises the error code for an InnoDB lock wait timeout (deadlock has occurred) when something called a certification failure happens. A certification failure happens when two threads writing to two different nodes in a Galera cluster attempt to `UPDATE` the same set of rows in the same table during the same time interval. Instead of causing MySQL to contain inconsistent data (two nodes having a different idea of the underlying data), Galera simply causes both threads to fail and thus issue a `ROLLBACK` of the containing transaction. This is different behavior from standard MySQL, in which a similar situation would cause just one of the threads to `ROLLBACK` after receiving a lock wait timeout error, and the other thread's `UPDATE` would succeed. The reason that this ""deadlock"" is not actually a deadlock in the Galera case is that the entire process happens without any actual waits or timeout loops. Each conflicting thread is simply sent an error and that thread issues a `ROLLBACK` of the current SQL transaction. Since MySQL Galera is, by far, the most popular high-availability database deployment option currently in the operator ecosystem, some changes are required in the quota management code to replace the use of `SELECT FOR UPDATE` with a lock-free implementation that suffers neither scalability problems nor the Galera-specific quasi-deadlock problems. Proposed change =============== The proposed solution is to borrow a page from obstruction-free and lock-free algorithm design and use a ""compare and swap"" method that allows the thread that intends to change the quota usage records for a user or project to issue a standard `SELECT` statement for those records, and when that thread goes to update those records, it first checks that the state of records is what the thread previously knew to exist. The `UPDATE` statement will include a `WHERE` condition that will ensure that the rows are *only* updated in the table IFF the current row values are what the thread thought they were when previously reading the rows with the `SELECT` statement. The thread will check the number of rows affected by the `UPDATE` statement. If the number of rows affected is 0, then a randomized exponential backoff loop will be hit and the process of reading and then `UPDATE` ing with the `WHERE` condition will repeat until a pre-defined number of tries has been attempted. This algoritm is lock-free, in that no record locks of any kind are taken at any point in the quota management transactions. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ We will work with the Rally developer team to identify some pre and post benchmarks that should demonstrate better concurrency with this lock-free implementation under standard MySQL and PostgreSQL deployments. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== We will implement the lock-free algorithm entirely in the quota_reserve(), quota_rollback() and quota_commit() DB API methods. The use of `with_lockmode('update')` shall be removed from the query object construction in the `_get_project_user_quota_usages()` method in `nova.db.sqlalchemy.api`. Within `quota_reserve()`, `quota_commit()` and `quota_rollback()`, we will change the algorithm from this *simplified* pseudo-code for `quota_reserve()`: .. code:: start_transaction: usage_records = get_and_lock_usage_records() reservations = [] for resource, amoount in requested_resource_changes: reservation = reservation_record_create(resource, amount) reservations.append(reservation) commit_transaction return reservations to this: .. code:: start_transaction: current_usage_records = get_usage_records() for resource, amoount in requested_resource_changes: while num_attempts < max_attempts: if usage_records_update(resource, amount, current_usage_records): break num_attempts++ current_usage_records = get_usage_records() commit_transaction return requested_resource_changes where the `usage_records_update()` method would look like this, again, in pseudo-code: .. code:: def usage_records_update(resource, amount, current_records): sql = ""UPDATE quota_usage SET used = used + amount WHERE resource = $resource AND used = $current_records.used"" execute_sql() return num_affected_rows() > 0 Assignee(s) ----------- Primary assignee: jaypipes Other assignees: AlexFrolov pkholkin Work Items ---------- TODO Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== None ",,215,0
openstack%2Fos-loganalyze~master~I3e4dfe15dbdac6e3e681c1e0766447c2106db238,openstack/os-loganalyze,master,I3e4dfe15dbdac6e3e681c1e0766447c2106db238,Go back to stderr rather than warnings module,MERGED,2014-07-16 09:29:37.000000000,2014-07-16 10:16:34.000000000,2014-07-16 10:16:34.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2014-07-16 09:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/687b945fbf64704ce4b7f8dac585ade649fa6557', 'message': 'Go back to stderr rather than warnings module\n\nAlso add extra debug information\n\nChange-Id: I3e4dfe15dbdac6e3e681c1e0766447c2106db238\n'}, {'number': 2, 'created': '2014-07-16 10:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/bc7681ed096ca1f2375c711bb6db0bbf95c50f1b', 'message': 'Go back to stderr rather than warnings module\n\nAlso add extra debug information\n\nChange-Id: I3e4dfe15dbdac6e3e681c1e0766447c2106db238\n'}, {'number': 3, 'created': '2014-07-16 10:02:44.000000000', 'files': ['os_loganalyze/generator.py'], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/14aad35b6581358cbb89898064fe63cfb0005424', 'message': 'Go back to stderr rather than warnings module\n\nAlso add extra debug information\n\nChange-Id: I3e4dfe15dbdac6e3e681c1e0766447c2106db238\n'}]",4,107272,14aad35b6581358cbb89898064fe63cfb0005424,15,3,3,7069,,,0,"Go back to stderr rather than warnings module

Also add extra debug information

Change-Id: I3e4dfe15dbdac6e3e681c1e0766447c2106db238
",git fetch https://review.opendev.org/openstack/os-loganalyze refs/changes/72/107272/1 && git format-patch -1 --stdout FETCH_HEAD,['os_loganalyze/generator.py'],1,687b945fbf64704ce4b7f8dac585ade649fa6557,fix_swift_fetch_path,"import sys sys.stderr.write('Not configured to use swift..') sys.stderr.write('logname: ') sys.stderr.write(logname) sys.stderr.write(""Error fetching from swift"") sys.stderr.write('logname: ') sys.stderr.write(logname) traceback.print_exc()","import warnings warnings.warn('Not configured to use swift..') warnings.warn(""Error fetching from swift"") warnings.warn(traceback.format_exc())",8,4
openstack%2Fhorizon~master~If0191f56b7242a422198b7fed40ca342669dd211,openstack/horizon,master,If0191f56b7242a422198b7fed40ca342669dd211,Remove Cinder traces from test output (add missing mock),MERGED,2014-07-15 15:58:19.000000000,2014-07-16 10:14:49.000000000,2014-07-16 10:14:48.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 6825}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-07-15 15:58:19.000000000', 'files': ['openstack_dashboard/dashboards/project/volumes/volumes/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/47cfb2aac1d4a14f10f0fee23b048d9fa3a9ad0e', 'message': 'Remove Cinder traces from test output (add missing mock)\n\nChange-Id: If0191f56b7242a422198b7fed40ca342669dd211\nCloses-Bug: #1340146\n'}]",0,107098,47cfb2aac1d4a14f10f0fee23b048d9fa3a9ad0e,13,6,1,4978,,,0,"Remove Cinder traces from test output (add missing mock)

Change-Id: If0191f56b7242a422198b7fed40ca342669dd211
Closes-Bug: #1340146
",git fetch https://review.opendev.org/openstack/horizon refs/changes/98/107098/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/volumes/volumes/tests.py'],1,47cfb2aac1d4a14f10f0fee23b048d9fa3a9ad0e,bug/1340146," @test.create_stubs({cinder: ('volume_list', 'volume_snapshot_list', 'volume_backup_supported'), cinder.volume_backup_supported(IsA(http.HttpRequest))\ .MultipleTimes().AndReturn(False)"," @test.create_stubs({cinder: ('volume_list', 'volume_snapshot_list'),",4,1
openstack%2Fnova-specs~master~I656f7b79ad22583c19bd044b81e69143ee8d3304,openstack/nova-specs,master,I656f7b79ad22583c19bd044b81e69143ee8d3304,API: Live Resize,ABANDONED,2014-05-23 02:13:16.000000000,2014-07-16 10:12:24.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5754}, {'_account_id': 7543}, {'_account_id': 8021}, {'_account_id': 9060}, {'_account_id': 11303}]","[{'number': 1, 'created': '2014-05-23 02:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/357cc9f15ae2ad7929c2baeb403cae7e2501a428', 'message': ""API: Live Resize\n\n'Cold-resize' had been implemented previously.\nBut instance needs to be rebooted during the period.\n\nSo this plan aims to add 'live-resize' function into Nova.\nThis is useful and convenient for users.\n\nChange-Id: I656f7b79ad22583c19bd044b81e69143ee8d3304\nImplements: blueprint hot-resize\n""}, {'number': 2, 'created': '2014-05-23 02:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6f30c9159a5990279ed903e251652b4a4094c68c', 'message': ""API: Live Resize\n\n'Cold-resize' had been implemented previously.\nBut instance needs to be rebooted during the period.\n\nSo this plan aims to add 'live-resize' function into Nova.\nThis is useful and convenient for users.\n\nChange-Id: I656f7b79ad22583c19bd044b81e69143ee8d3304\nImplements: blueprint hot-resize\n""}, {'number': 3, 'created': '2014-05-23 02:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/486db148e26824993ab56e0e735cbf040ab3fd99', 'message': ""API: Live Resize\n\n'Cold-resize' had been implemented previously.\nBut instance needs to be rebooted during the period.\n\nSo this plan aims to add 'live-resize' function into Nova.\nThis is useful and convenient for users.\n\nChange-Id: I656f7b79ad22583c19bd044b81e69143ee8d3304\nImplements: blueprint hot-resize\n""}, {'number': 4, 'created': '2014-05-26 08:01:00.000000000', 'files': ['specs/juno/hot-resize.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/124a5b652590707a09a496b2aa19a2863f96bf4c', 'message': ""API: Live Resize\n\n'Cold-resize' had been implemented previously.\nBut instance needs to be rebooted during the period.\n\nSo this plan aims to add 'live-resize' function into Nova.\nThis is useful and convenient for users.\n\nChange-Id: I656f7b79ad22583c19bd044b81e69143ee8d3304\nImplements: blueprint hot-resize\n""}]",30,95054,124a5b652590707a09a496b2aa19a2863f96bf4c,38,9,4,8021,,,0,"API: Live Resize

'Cold-resize' had been implemented previously.
But instance needs to be rebooted during the period.

So this plan aims to add 'live-resize' function into Nova.
This is useful and convenient for users.

Change-Id: I656f7b79ad22583c19bd044b81e69143ee8d3304
Implements: blueprint hot-resize
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/54/95054/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/hot-resize.rst'],1,357cc9f15ae2ad7929c2baeb403cae7e2501a428,bp/hot-resize,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== API: Live Resize ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/hot-resize 'Cold-resize' had been implemented previously. But instance needs to be rebooted during the period. So this plan aims to add 'live-resize'(or 'hot-resize'?) function into Nova. This is useful and convenient for users. Cpu hot-add feature has been supported by qemu(since version 1.6.2) and libvirt(since version 1.2). VMware can support cpu-hot-add/remove, mem-hot-add/remove. It will be implemented if this function merged. Problem description =================== There is no current API that can resize servers online. The original resize API is equal to cold-resize, or offline resize. That's not convenient for end users. The use cases that are driving this API extension are derived from a user's experience. Proposed change =============== 0. Only images contain 'QEMU Guest Agent'(qga) could support this function in libvirt. It uses 'hw_qemu_guest_agent' tag in image's metadata to indicate(Implemented in Havana [1]). Image without qga in libvirt will be raised 'NotSupportedException' for ""live-resize"". 1. Add a new key-value pair in image's metadata like {'max_vcpus_limit': <int>}. This value will be effective in spawn/rebuild/rescue/resize/live-resize. 2. Add a new extension API ""live-resize"" which the owner and admin can use it. The API can specify whether execute ""live_migration"" when original host doesn't have enough resources to hotplug or not. See details in the API part. 3. Add a new 'LIVE_RESIZING' to task states. It means the request is sent to compute node to execute. 4. Add a new ""live-resize"" ComputeTaskAPI & related logic in nova-conductor to decide whether need/how to select a new target host. 5. Add new ""check_live_resize_supported"" & ""live-resize"" APIs in base virt driver. The former one allows each hypervisor can check its supported for live-resizing by comparing the requested flavor with the old one. And the latter one will implement specific execution for live-resizing. The default of the two APIs is to raise 'NotImplementedError' in virt driver. 6. Add a new field called 'max_vcpus_limit' in 'Instance.system_metadata' (or Instance?) table in DB to record max vCPUs of instances. It aims to ensure max vCPUs number correct even if the image's metadata was modified. If image does not have the 'max_vcpus_limit' tag in its metadata, the value of 'max_vcpus_limit' will be 0('NO LIMIT'). Besides, all instances upgraded from lower version, this value will also be equals to 0. 7. Change one element in the config-xml of instance in libvirt driver from ""<vcpu>X</vcpu>"" style to ""<vcpu current='X'>'Y'</vcpu>"" if 'max_vcpus_limit' is specified in image's metadata. Here, the 'X' will be the value of flavor's 'vcpus', and the 'Y' will be equal to 'max_vcpus_limit' we added in the step1. 8. The API 'DescribeInstance' needs to add one key-pair property into the response body like <'max_vcpus_limit':4> to show the max vcpus limit of this instance which can be obtained from DB instances table. (Now only vcpus live-resize will be implemented in libvirt driver) Alternatives ------------ 1. Support image without QEMU guest agent(qga) In the above design, only the image installed qga can support this feature in libvirt. Actually, if image doesn't contain gqa, after ""live-resize"" action in libvirt, the user can execute some commands manually in the instance to activate the new plugged resources(choose vcpus to explain): 'echo 1 > /sys/devices/system/cpu/cpuX/online' * The 'X' means which vCPU you want to activate. * The range of 'X' is from 0 to (amount of vCPUs - 1). * For example, the 'cpu0' means your instance only has one vCPU. * The count of the executions relies on the vCPUs number your instance has. The reason why this proposal isn't chosen is the manual operations is not friendly enough to end-users. * If normal images need to be supported, the API response ought to give two different answers to end-users based on your image attribute, like 'Your operation took effort.' or 'Your operation is applied, but you need to execute some commands in your instance...'. * Moreover, if one instance plugged new 4 vCPUs, end-user needs to execute the command four times. So this is not a good idea IMO. 2. Don't touch 'DescribeInstance' Why I add a new param in response body of 'DescribeInstance' is I want to provide a mechanism for user to check max_vcpus_limit of instances. * If not, the only way to get this info is to check it in DB, and that's not a convenient and acceptable way for normal users. * Image's metadata could be changed therefore it can't be the evidence. * Moreover, I don't think it's necessary to add a new API for describing the max vcpus limit of instances. Therefore, I modified the response body of 'DescribeInstance'. 3. The 'disk-over-commit' in live_migration The 'disk-over-commit' means whether allow disk overcommit in live_migration. The default value of it is 'False', and I'm also preferred to use 'False'. And I don't think it's clear to expose this param in the 'live-resize' because this param doesn't suit all conditions (only effective for one condition). But I paste it here to see other reviewers' opinion. 4. The behaviour of 'resize' API In the above design, we want to keep the consistency between ""resize"" & ""live-resize"". * If images without 'max_vcpus_limit', the instances will be handled as usual, no restriction in ""resize"", but no ""live-resize"" available. * If images include 'max_vcpus_limit', the instance will have a restriction that new flavor's item can't be greater than the limitation(like vcpus), both in ""resize"" & ""live-resize"". * But the 'max_vcpus_limit' of instance can't be modified after initialization. It's not convenient. So, should we need to remove the 'max_vcpus_limit' restriction in ""resize""? * If item value(like 'vcpus') of new flavor in ""resize"" is greater than the 'max_vcpus_limit' in DB, we change the DB value to this new value, instead raising an exception. * The advantage is we'll have a method to change the 'max_vcpus_limit' in DB. * The disadvantage is it'll brings difference between ""resize"" & ""live-resize"". Because ""live_resize"" needs to follow the restriction. Therefore, I'm still preferred to the original design. Data model impact ----------------- Table 'instance_system_metadata'(or Instances?) needs to add one filed: +-----------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-----------------+--------------+------+-----+---------+----------------+ | max_vcpus_limit | int(11) | YES | | NULL | | +-----------------+--------------+------+-----+---------+----------------+ * This value is initialled in the procession of instance creation, and can't be modified afterwards. * The value of 'max_vcpus_limit' will be equal to the 'max_vcpus_limit' in image's metadata. * But if image doesn't have the tag, the value of it will be 0('No Limit'). The related DB modification will also be merged into /nova/db/sqlalchemy/migrate_repo/versions/. REST API impact --------------- 1. Add one API ""live_resize"" The rest API look like this in v2:: /v2/{project_id}/servers/{server_id}/action { 'live_resize':{ 'flavor_id':2, 'allow_live_migration':True } } and in v3 it is like:: /v3/servers/{server_id}/action { 'live_resize':{ 'flavor_id':2, 'allow_live_migration':True } } * The <int> 'flavor_id' means the new flavor you want to change to. No default value. * The <boolean> 'allow_live_migration' means whether execute ""live_migration"" if instance's original host doesn't have enough resources. The default value should be 'False'. The response body of it is like:: { 'task_states':'LIVE_RESIZING'(/'MIGRATING') } * The 'task_states' will be 'LIVE_RESIZING'/'MIGRATING'. * The 'LIVE_RESIZING' means the request is sent to compute node to execute the real-logic. * The 'MIGRATING' means the original host doesn't have enough resources; we need to ""live_migrate"" instance to another suitable host and execute ""live-resize"" later if 'allow_live_migration' equals to 'True'. The status code will be 202 when the request has succeeded. If the request fails, corresponding exception will be raised. The related states/information will be roll back. * The state of instance will always be ACTIVE during the procession. * If flavor or instance doesn't exist, the request will fail. * If 'max_vcpus_limit' of the instance is smaller than the request flavor's vcpus, one new exception like 'VCPUsLimitExceeded' will be raised. * If instance's original host doesn't have enough resources to ""live-resize"" and 'allow_live_migration' equals to 'False' in request body, then the request will fail and 'ComputeResourcesUnavailable' exception will be raised. * The task_state will be roll backed if fails happened during the verification. (validation in API/host selection in conductor/supported check in compute) 2. Modify API ""DescribeInstance"" Add one optional key-pair property into the response body to show the 'max_vcpus_limit' of this instance. This value will not be None or '': { 'server':{ ... 'max_vcpus_limit':4, ... } } * The 'max_vcpus_limit' can be captured from 'max_vcpus_limit' in DB 'instance_system_metadata' table. 3. Change in ""CreateInstances"" If tag 'max_vcpus_limit' includes in image's metadata, its value will be recorded in DB 'instance_system_metadata' table for instance. If not, the value of 'max_vcpus_limit' in DB will be 0. It means 'No Limit'. 4. Change in ""resize"" Now we add 'max_vcpus_limit' for every instance, so we need to restrict all related APIs to obey the same rule. * If images without 'max_vcpus_limit', ""resize"" action will be handled as usual. * If images includes 'max_vcpus_limit', ""resize"" action will have a new restriction that new flavor's item can't be greater than the limitation(like 'max_vcpus_limit') in DB. Or a new exception will be raised. Security impact --------------- None Notifications impact -------------------- Needs to add two new types of notification: 1. live_resize.start 2. live_resize.end Other end user impact --------------------- This function will be added into python-novaclient when the work finish. Performance Impact ------------------ None Other deployer impact --------------------- * The 'max_vcpus_limit' of all instances upgraded from lower version will be 0. They'll be treated as the instances without 'max_vcpus_limit' specified. * The images contain 'QEMU Guest Agent'(qga) are required by this function in libvirt. * A new key-value pair in image's metadata like {'max_vcpus_limit': <int>} is required. Developer impact ---------------- Now only cpu-hot-add will be implemented in libvirt driver. Memory & disk functions will be added when QEMU supports them. Later, the VMware Driver support will be added if this function merged [2]. Implementation ============== Assignee(s) ----------- Assignee: wingwj <wingwj@gmail.com> Work Items ---------- 1. Code this function in v2/v3 1.1 DB modification 1.2 API ""live-resize"" Implementation in v2/v3 1.3 Related APIs(create/resize/..) modification 2. Finish tempest tests 3. Code this function in python-novaclient Dependencies ============ Now only vcpus live-resize will be implemented in libvirt driver firstly 1. QEMU >= 1.5.0 2. libvirt >= 1.1.0 Testing ======= Unit tests and tempest tests will verify this function. UTs for API/DB/libvirt driver will be examined separately. In integrated tests and tempest, it will be tested together. Documentation Impact ==================== A description of this function will be added into Compute API V2 and V3 Reference. Moreover, a ""live-resize"" support matrix of GuestOSs under each hypervisor is planed to add into the Reference. References ========== A ""live-resize"" support matrix of GuestOSs under each hypervisor is planed to add into a new wiki page in wiki.openstack.org.(Under Construction) * [1] https://blueprints.launchpad.net/nova/+spec/qemu-guest-agent-support * [2] http://kb.vmware.com/selfservice/microsites/search.do? language=en_US&cmd=displayKC&externalId=2020993",,399,0
openstack%2Frally~master~I65b2e398826a5883d033eb8b5214dd41ceea3063,openstack/rally,master,I65b2e398826a5883d033eb8b5214dd41ceea3063,Add unit tests for vm benchmark scenarios,MERGED,2014-07-10 17:05:07.000000000,2014-07-16 10:12:11.000000000,2014-07-16 10:12:10.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9545}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-07-10 17:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/768dde247129b13f2add698f9bae5537c828f09e', 'message': 'Add unit tests for vm benchmark scenarios\n\nAdded following tests\n\ntest__boot_server_with_sec_group\ntest__boot_server_with_sec_group\ntest__boot_server_with_similar_sec_group\n\nChange-Id: I65b2e398826a5883d033eb8b5214dd41ceea3063\nImplements: blueprint improve-unit-test-coverage-rally\n'}, {'number': 2, 'created': '2014-07-15 10:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cb1a9f683eebd44bf99e98503e3a5575221034fc', 'message': 'Add unit tests for vm benchmark scenarios\n\nAdded following tests\n\ntest__boot_server_with_sec_group\ntest__boot_server_with_sec_group\ntest__boot_server_with_similar_sec_group\n\nCreated mock_actions to remove repeated\nassert_called_once_with calls\n\nChange-Id: I65b2e398826a5883d033eb8b5214dd41ceea3063\nImplements: blueprint improve-unit-test-coverage-rally\n'}, {'number': 3, 'created': '2014-07-15 15:34:22.000000000', 'files': ['tests/benchmark/scenarios/nova/test_utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/1ca4ac91ae4b5ab5ced8a100bf640705856bcbf9', 'message': 'Add unit tests for vm benchmark scenarios\n\nAdded following tests\n\ntest__boot_server_with_sec_group\ntest__boot_server_with_sec_group\ntest__boot_server_with_similar_sec_group\n\nCreated method to remove repeated\nassert_called_once_with calls\n\nChange-Id: I65b2e398826a5883d033eb8b5214dd41ceea3063\nImplements: blueprint improve-unit-test-coverage-rally\n'}]",7,106109,1ca4ac91ae4b5ab5ced8a100bf640705856bcbf9,19,6,3,11105,,,0,"Add unit tests for vm benchmark scenarios

Added following tests

test__boot_server_with_sec_group
test__boot_server_with_sec_group
test__boot_server_with_similar_sec_group

Created method to remove repeated
assert_called_once_with calls

Change-Id: I65b2e398826a5883d033eb8b5214dd41ceea3063
Implements: blueprint improve-unit-test-coverage-rally
",git fetch https://review.opendev.org/openstack/rally refs/changes/09/106109/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/benchmark/scenarios/nova/test_utils.py'],1,768dde247129b13f2add698f9bae5537c828f09e,bp/improve-unit-test-coverage-rally," @mock.patch(NOVA_UTILS + '.NovaScenario.clients') def test__boot_server_with_ssh(self, mock_clients): mock_clients(""nova"").servers.create.return_value = self.server nova_scenario = utils.NovaScenario(context={""allow_ssh"": ""test""}) return_server = nova_scenario._boot_server('server_name', 'image_id', 'flavor_id') self.wait_for.mock.assert_called_once_with( self.server, update_resource=self.gfm(), is_ready=self.res_is.mock(), check_interval=CONF.benchmark.nova_server_boot_poll_interval, timeout=CONF.benchmark.nova_server_boot_timeout ) self.res_is.mock.assert_has_calls(mock.call('ACTIVE')) self.assertEqual(self.wait_for.mock(), return_server) self._test_atomic_action_timer(nova_scenario.atomic_actions(), 'nova.boot_server') @mock.patch(NOVA_UTILS + '.NovaScenario.clients') def test__boot_server_with_sec_group(self, mock_clients): mock_clients(""nova"").servers.create.return_value = self.server nova_scenario = utils.NovaScenario(context={""allow_ssh"": ""new""}) return_server = nova_scenario._boot_server( 'server_name', 'image_id', 'flavor_id', security_groups=['test1']) self.wait_for.mock.assert_called_once_with( self.server, update_resource=self.gfm(), is_ready=self.res_is.mock(), check_interval=CONF.benchmark.nova_server_boot_poll_interval, timeout=CONF.benchmark.nova_server_boot_timeout ) self.res_is.mock.assert_has_calls(mock.call('ACTIVE')) self.assertEqual(self.wait_for.mock(), return_server) self._test_atomic_action_timer(nova_scenario.atomic_actions(), 'nova.boot_server') @mock.patch(NOVA_UTILS + '.NovaScenario.clients') def test__boot_server_with_similar_sec_group(self, mock_clients): mock_clients(""nova"").servers.create.return_value = self.server nova_scenario = utils.NovaScenario(context={""allow_ssh"": ""test1""}) return_server = nova_scenario._boot_server( 'server_name', 'image_id', 'flavor_id', security_groups=['test1']) self.wait_for.mock.assert_called_once_with( self.server, update_resource=self.gfm(), is_ready=self.res_is.mock(), check_interval=CONF.benchmark.nova_server_boot_poll_interval, timeout=CONF.benchmark.nova_server_boot_timeout ) self.res_is.mock.assert_has_calls(mock.call('ACTIVE')) self.assertEqual(self.wait_for.mock(), return_server) self._test_atomic_action_timer(nova_scenario.atomic_actions(), 'nova.boot_server') ",,56,0
openstack%2Fgovernance~master~I9613b4e08d246818a892a92261accfac7815f045,openstack/governance,master,I9613b4e08d246818a892a92261accfac7815f045,Propose scores for DefCore capabilities,MERGED,2014-06-17 23:49:30.000000000,2014-07-16 10:09:36.000000000,2014-07-16 10:09:35.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 67}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2889}]","[{'number': 1, 'created': '2014-06-17 23:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/e6bb0d3650550a3e629a4c943a78206636e68cda', 'message': 'Propose scores for DefCore capabilities\n\nThis is the set of changes to the original DefCore capabilities scores.\n\nChange-Id: I9613b4e08d246818a892a92261accfac7815f045\n'}, {'number': 2, 'created': '2014-06-20 19:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/e562241dd166ea1e6b5017fe28b7196268d11549', 'message': 'Propose scores for DefCore capabilities\n\nThis is the set of changes to the original DefCore capabilities scores.\n\nChange-Id: I9613b4e08d246818a892a92261accfac7815f045\n'}, {'number': 3, 'created': '2014-06-24 12:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/29e38ca0eba9d97c61f7eeac307d0314470aef07', 'message': 'Propose scores for DefCore capabilities\n\nThis is the set of changes to the original DefCore capabilities scores.\n\nChange-Id: I9613b4e08d246818a892a92261accfac7815f045\n'}, {'number': 4, 'created': '2014-07-08 20:09:42.000000000', 'files': ['resolutions/20140617-defcore-capabilities-scoring.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/7aeee9d9eb88ea5f8a9b6af99b2da7769a06f89d', 'message': 'Propose scores for DefCore capabilities\n\nThis is the set of changes to the original DefCore capabilities scores.\n\nChange-Id: I9613b4e08d246818a892a92261accfac7815f045\n'}]",20,100722,7aeee9d9eb88ea5f8a9b6af99b2da7769a06f89d,51,11,4,2472,,,0,"Propose scores for DefCore capabilities

This is the set of changes to the original DefCore capabilities scores.

Change-Id: I9613b4e08d246818a892a92261accfac7815f045
",git fetch https://review.opendev.org/openstack/governance refs/changes/22/100722/2 && git format-patch -1 --stdout FETCH_HEAD,['resolutions/20140617-defcore-capabilities-scoring.rst'],1,e6bb0d3650550a3e629a4c943a78206636e68cda,defcore-capabilities-scoring, 8 compute-flavors 1 1 1 10 compute-auth 0 1 1 18 compute-floating-ips 1 1 1 20 compute-security-groups 0 1 1 22 objectstore-container-quota 1 1 1 23 compute-virtual-interfaces 1 1 0 40 compute-multiple-create 1 0 0 60 compute-admin-aggregates 1 1 1 61 objectstore-quotas 1 1 1 68 compute-admin-flavors 1 1 1 71 compute-admin-fixed-ips 1 1 1,".. note:: The table below reproduces that section of the spreadsheet as it stands on 2014-06-17, based on ``defcore.csv``. A follow-up changeset will modify this resolution to reflect the scores of the TC (separate patches will make it easier to discuss the changes from the original values). 8 compute-flavors 0.5 1 1 10 compute-auth 0.5 1 1 18 compute-floating-ips 0.5 1 1 20 compute-security-groups 0.5 1 1 22 objectstore-container-quota 0.5 1 1 23 compute-virtual-interfaces 0.5 1 0 40 compute-multiple-create 0.5 0 0 60 compute-admin-aggregates 0.5 1 1 61 objectstore-quotas 0.5 1 1 68 compute-admin-flavors 0.5 1 1 71 compute-admin-fixed-ips 0.5 1 1",11,19
openstack%2Fgovernance~master~I96b59e0e051c6b193a627d0093d3db6b27c10366,openstack/governance,master,I96b59e0e051c6b193a627d0093d3db6b27c10366,Current version of DefCore capability scoring,MERGED,2014-06-17 23:49:30.000000000,2014-07-16 10:09:30.000000000,2014-07-16 10:09:30.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 2889}]","[{'number': 1, 'created': '2014-06-17 23:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/5285b1c1c8ddd48c729e38dc8f9ceedb0760ae16', 'message': 'Current version of DefCore capability scoring\n\nThis is the version of the scoring spreadsheet as it appears now. The\nnext changeset includes the proposed changes.\n\nChange-Id: I96b59e0e051c6b193a627d0093d3db6b27c10366\n'}, {'number': 2, 'created': '2014-06-20 19:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/54608aeaae7c2bc3e3ff9842c4b853b8c6fd2173', 'message': 'Current version of DefCore capability scoring\n\nThis is the version of the scoring spreadsheet as it appears now. The\nnext changeset includes the proposed changes.\n\nChange-Id: I96b59e0e051c6b193a627d0093d3db6b27c10366\n'}, {'number': 3, 'created': '2014-06-24 12:58:55.000000000', 'files': ['resolutions/20140617-defcore-capabilities-scoring.rst', 'resolutions/20140617-defcore-capabilities-scoring/extract.py', 'resolutions/20140617-defcore-capabilities-scoring/defcore.csv'], 'web_link': 'https://opendev.org/openstack/governance/commit/878fe2f5ea0066aaec048d4ec0159b65aec33f3b', 'message': 'Current version of DefCore capability scoring\n\nThis is the version of the scoring spreadsheet as it appears now. The\nnext changeset includes the proposed changes.\n\nChange-Id: I96b59e0e051c6b193a627d0093d3db6b27c10366\n'}]",7,100721,878fe2f5ea0066aaec048d4ec0159b65aec33f3b,36,9,3,2472,,,0,"Current version of DefCore capability scoring

This is the version of the scoring spreadsheet as it appears now. The
next changeset includes the proposed changes.

Change-Id: I96b59e0e051c6b193a627d0093d3db6b27c10366
",git fetch https://review.opendev.org/openstack/governance refs/changes/21/100721/2 && git format-patch -1 --stdout FETCH_HEAD,"['resolutions/20140617-defcore-capabilities-scoring.rst', 'resolutions/20140617-defcore-capabilities-scoring/extract.py', 'resolutions/20140617-defcore-capabilities-scoring/defcore.csv']",3,5285b1c1c8ddd48c729e38dc8f9ceedb0760ae16,defcore-capabilities-scoring,",,Criteria Weight,8.33,8.33,8.33,8.33,8.33,8.33,8.33,8.33,8.33,8.33,8.33,8.33,0,, ,,,Shows Proven Usage,,,Aligns with Technical Direction,,,Plays Well with Others,,,Takes a System View,,,,, Candidate Capabilities,Count,Score,Widely Deployed,Used By Tools,Used By Clients,TC Future Direction,Complete,Stable,Discoverable,Doc'd,Core in Last Rel.,Foundational,Atomic,Proximity,Non-Admin,Description,xref compute-servers,73,100,1,1,1,1,1,1,1,1,1,1,1,1,1,Basic Nova functions (launch instances), volume,30,100,1,1,1,1,1,1,1,1,1,1,1,1,1,, compute-volume,16,100,1,1,1,1,1,1,1,1,1,1,1,1,1,Attach/Detach functionality only, compute-quotas,2,100,1,1,1,1,1,1,1,1,1,1,1,1,1,, compute-flavors,15,96,1,1,1,0.5,1,1,1,1,1,1,1,1,1,, images-v1,19,92,1,1,1,1,1,1,1,1,0,1,1,1,1,, compute-auth,14,92,1,1,1,0.5,1,1,1,0.5,1,1,1,1,1,, images-v2,5,92,1,1,1,1,1,1,1,1,0,1,1,1,1,, objectstore-object,17,83,0.5,1,1,1,1,1,0.5,1,0,1,1,1,1,, compute-keypairs,17,83,1,1,1,1,1,1,1,1,1,0,1,0,1,Injects keys into VMs, compute-servers-metadata,16,83,1,1,1,1,1,1,1,1,1,1,0,0,1,Tagging, objectstore-container,5,83,0.5,1,1,1,1,1,0.5,1,0,1,1,1,1,, volume-snapshots,2,83,1,1,1,1,1,1,1,1,1,0,0,1,1,, compute-images,37,79,0.5,1,1,0,1,1,1,1,1,0,1,1,1,, compute-floating-ips,14,79,1,1,1,0.5,1,1,1,1,0,0,1,1,1,, compute-instance-actions,4,79,1,1,1,1,1,1,1,0.5,0,1,1,0,1,, compute-security-groups,27,71,1,1,1,0.5,1,1,0,1,0,0,1,1,1,, compute-image-metadata,12,67,1,0,0,0,1,1,1,1,1,0,1,1,1,allows users add arbitrary keys and values on create, objectstore-container-quota,3,67,1,0,0,0.5,1,1,0.5,1,1,1,1,0,1,, compute-virtual-interfaces,2,67,0.5,1,1,0.5,1,0,1,1,0,1,1,0,1,There are COMPETITING VERSIONS that cause Interop pain, objectstore-container-acl,11,62,1,0,0,0,1,1,0.5,1,1,1,1,0,1,, objectstore-acct-services,8,62,1,0,0,0,1,1,0.5,1,1,1,1,0,1,, objectstore-container-staticweb,2,62,1,0,0,0,1,1,0.5,1,1,1,1,0,1,, <identity-non-admin-roles>,?,58,1,0,0,1,1,0,1,1,0,1,1,0,1,Used w/ middleware (LDAP or AD), compute-usage,6,58,0,1,0,0,1,1,1,1,0,0,1,1,1,Used by Dashboard, compute-limits,2,58,1,1,0,1,1,1,1,1,0,0,0,0,1,Works with rate limiting, networks-extensions,1,58,0,0,0,1,1,1,1,1,0,1,1,0,1,, networks-l2,14,50,0,0,0,1,0,0,1,1,0,1,1,1,1,, compute-ext-disk-config,4,50,1,0,1,0,1,0,1,1,0,0,1,0,1,controls how the disk is partitioned when you manage a server,https://github.com/openstack/tempest/blob/master/tempest/api/compute/servers/test_disk_config.py networks-l3,3,50,0,0,0,1,0,0,1,1,0,1,1,1,1,, compute-live-migration,3,42,0,0,0,1,0,0,1,1,0,1,1,0,1,, compute-servers-personality,3,42,1,0,0,0,1,1,1,1,0,0,0,0,1,, networks-floating-ips,1,37,0,0,0,1,0,0,1,1,0,0.5,1,0,1,,http://docs.openstack.org/admin-guide-cloud/content/l3_workflow.html networks-security-groups,5,33,0,0,0,1,0,0,1,1,0,0,0,1,1,, networks-lbaas,12,25,0,0,0,1,0,0,1,1,0,0,0,0,1,,http://docs.openstack.org/admin-guide-cloud/content/fwaas_workflow.html orch-stacks,20,21,0,0,0,0,0,0,0.5,1,0,1,0,0,1,, compute-multiple-create,7,21,0,0,0,0.5,0,0,1,0,0,0,0,1,1,, networks-vpn,3,17,0,0,0,1,0,0,1,0,0,0,0,0,1,, compute-attach-interface,1,17,0,0,0,0,0,0,1,0,0,0,1,0,1,used to attach NIC to running VM, networks-quotas,1,17,0,0,0,1,0,0,1,0,0,0,0,0,1,, compute-auth-v3,1,8,0,0,0,1,0,0,0,0,0,0,0,0,1,, compute-volume-proxy,?,0,,,,0,,,,,0,,,,,Maps to the old os-volume extensions, compute-volume-ebs,?,0,,,,0,,,,,0,,,,,, compute-console-log,1,-17,0,0,0,1,0,0,0,0,0,0,1,0,-1,, identity-admin-v3-roles,5,-25,0,0,0,1,0,0,0,0,0,1,1,0,-1,, identity-admin-v3-endpoints,3,-25,0,0,0,1,0,0,0,0,0,1,1,0,-1,, identity-admin-v3-credentials,2,-25,0,0,0,1,0,0,0,0,0,1,1,0,-1,, identity-admin-v3-domains,2,-25,0,0,0,1,0,0,0,0,0,1,1,0,-1,, identity-admin-v3-policies,2,-25,0,0,0,1,0,0,0,0,0,1,1,0,-1,, identity-admin-v3-users,2,-25,0,0,0,1,0,0,0,0,0,1,1,0,-1,, identity-admin-v3-services,1,-25,0,0,0,1,0,0,0,0,0,1,1,0,-1,, identity-admin-v3-tokens,1,-25,0,0,0,1,0,0,0,0,0,1,1,0,-1,, identity-admin-v3-projects,15,-33,0,0,0,1,0,0,0,0,0,1,1,1,-1,, volume-multi-backend,2,-42,0,0,0,1,1,1,0,1,0,0,1,0,-1,, identity-admin-users,31,-54,1,0,0,0,1,1,1,0.5,0,0,1,1,-1,, identity-admin-roles,23,-58,0,0,0,1,1,1,1,1,0,1,1,0,-1,, compute-admin-aggregates,18,-62,1,0.5,0.5,0.5,1,1,0,1,0,0,1,1,-1,,https://blueprints.launchpad.net/nova/+spec/host-aggregates objectstore-quotas,4,-67,1,0,0,0.5,1,1,0.5,1,1,1,1,0,-1,, compute-admin-servers-pause,3,-67,1,1,0,1,1,1,1,0,0,0,1,1,-1,admin only, compute-admin-servers-suspend,3,-67,1,1,0,1,1,1,1,0,0,0,1,1,-1,admin only, identity-admin-tenants,20,-71,1,1,1,0,1,0,1,0.5,0,1,1,1,-1,, compute-admin-avail-zone,4,-83,1,1,1,0,1,1,1,1,1,1,1,0,-1,, identity-admin-services,2,-87,1,1,1,1,1,1,1,0.5,0,1,1,1,-1,, volume-extra-specs,13,-92,1,1,1,1,1,1,0,1,1,1,1,1,-1,, compute-admin-flavors,24,-96,1,1,1,0.5,1,1,1,1,1,1,1,1,-1,related to compute flavors, compute-admin-server,11,-96,1,1,1,1,1,1,1,1,1,0.5,1,1,-1,, compute-admin-services,9,-96,1,1,1,1,1,1,1,1,1,0.5,1,1,-1,, compute-admin-fixed-ips,8,-96,1,1,1,0.5,1,1,1,1,1,1,1,1,-1,, compute-admin-quota,9,-100,1,1,1,1,1,1,1,1,1,1,1,1,-1,, compute-admin-hypervisor,8,-100,1,1,1,1,1,1,1,1,1,1,1,1,-1,, compute-admin-hosts,7,-100,1,1,1,1,1,1,1,1,1,1,1,1,-1,, ,,,59.42%,48.55%,44.20%,71.13%,68.12%,62.32%,72.46%,71.74%,35.21%,64.49%,84.06%,50.72%,18.84%,,",,211,0
openstack%2Ftooz~master~I61a853751bd6e459b0d78cd526e098c7f4a48081,openstack/tooz,master,I61a853751bd6e459b0d78cd526e098c7f4a48081,Upgrade hacking requirement,MERGED,2014-07-16 08:58:33.000000000,2014-07-16 10:04:47.000000000,2014-07-16 10:04:47.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-07-16 08:58:33.000000000', 'files': ['tooz/tests/test_coordination.py', 'test-requirements.txt', 'tooz/coordination.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tooz/commit/90b977ee5eb101aa39d5d15f32ff266e12bbb237', 'message': 'Upgrade hacking requirement\n\nChange-Id: I61a853751bd6e459b0d78cd526e098c7f4a48081\n'}]",0,107262,90b977ee5eb101aa39d5d15f32ff266e12bbb237,7,2,1,1669,,,0,"Upgrade hacking requirement

Change-Id: I61a853751bd6e459b0d78cd526e098c7f4a48081
",git fetch https://review.opendev.org/openstack/tooz refs/changes/62/107262/1 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/tests/test_coordination.py', 'test-requirements.txt', 'tooz/coordination.py', 'tox.ini']",4,90b977ee5eb101aa39d5d15f32ff266e12bbb237,,"deps = hacking>=0.9.2,<0.10ignore = H405","# Install bounded pep8/pyflakes first, then let flake8 install deps = pep8==1.4.5 pyflakes==0.7.2 flake8==2.0 hacking>=0.8.0,<0.9",7,10
openstack%2Fnova-specs~master~I1c4224161566fdb3fc13048057c2b4726c8c83f0,openstack/nova-specs,master,I1c4224161566fdb3fc13048057c2b4726c8c83f0,Enable online extend of in-use Cinder volumes,ABANDONED,2014-05-29 13:04:27.000000000,2014-07-16 10:03:39.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4954}]","[{'number': 1, 'created': '2014-05-29 13:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ada61ad29f4b9ad0b56cdf1070b0f48b95e2660b', 'message': 'Enable online extend of in-use Cinder volumes\n\nOnline volume extend allows volumes that are attached to instances (in-use)\nto be extended without first detaching them. This spec defines a Nova\nextension that is required by Cinder to issue an online volume extend,\nspecifically this requires iSCSI rescan and the ability to return the size of\nthe volume block device from the compute host that the instance is running on.\n\nChange-Id: I1c4224161566fdb3fc13048057c2b4726c8c83f0\n'}, {'number': 2, 'created': '2014-05-29 13:16:18.000000000', 'files': ['specs/juno/online-volume-extend-extension.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/045ec0ecdf51e9d43b99a16af7ea323d12fe672a', 'message': 'Enable online extend of in-use Cinder volumes\n\nOnline volume extend allows volumes that are attached to instances (in-use)\nto be extended without first detaching them. This spec defines a Nova\nextension that is required by Cinder to issue an online volume extend,\nspecifically this requires iSCSI rescan and the ability to return the size of\nthe volume block device from the compute host that the instance is running on.\n\nChange-Id: I1c4224161566fdb3fc13048057c2b4726c8c83f0\n'}]",7,96455,045ec0ecdf51e9d43b99a16af7ea323d12fe672a,20,5,2,4954,,,0,"Enable online extend of in-use Cinder volumes

Online volume extend allows volumes that are attached to instances (in-use)
to be extended without first detaching them. This spec defines a Nova
extension that is required by Cinder to issue an online volume extend,
specifically this requires iSCSI rescan and the ability to return the size of
the volume block device from the compute host that the instance is running on.

Change-Id: I1c4224161566fdb3fc13048057c2b4726c8c83f0
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/55/96455/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/online-volume-extend-extension.rst'],1,ada61ad29f4b9ad0b56cdf1070b0f48b95e2660b,online_cinder_extend,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================= Enable online extend of in-use Cinder volumes ============================================= https://blueprints.launchpad.net/nova/+spec/online-volume-extend-extension Online volume extend allows volumes that are attached to instances (in-use) to be extended without first detaching them. This spec defines a Nova extension that is required by Cinder to issue an online volume extend, specifically this requires iSCSI rescan and the ability to return the size of the volume block device from the compute host that the instance is running on. Problem description =================== Currently Cinder volumes must be detached from instances before they can be extended. In cases where services are using the volume (e.g., a Trove instance running MySQL), these services must be stopped, causing downtime for the user. For Cinder to extend in-use volumes, it needs the compute host that the instance is running on to be able to issue an iSCSI rescan and return the size of the volume block device so Cinder can poll until the block device is actually the new size. Online extend also requires support from the underlying hypervisor and volume backend. Proposed change =============== To support Cinder online extend this spec proposes a corresponding Nova extension to run the following on the underlying compute host (via the virt driver): * Rescan iSCSI. This will allow the underlying compute host to see the new size of the volume block device after it has been extended by Cinder. * Get volume block device size. This will allow Cinder to poll until the underlying block device is actually the new size on the compute host before Cinder completes the online extend. This initial proposal only covers the minimum required components for some hypervisors, specifically those that do not require any additional hooks to expose the updated size of the volume block device inside instances. Additional work would be required to support this extension for other virt drivers (see additional comments in Developer impact). The Cinder portion of the online extend feature is proposed in [1]_. Alternatives ------------ The main alternative is simply to detach the volume for extend, which is already supported, and requires services using the volume to be offline. Data model impact ----------------- None REST API impact --------------- Add os-online_extend_volume extension with the following API calls: PUT v2/{tenant_id}/servers/{server_id}/os-online_extend_volume * Issues an iSCSI rescan on the compute host with the instance and volume * Normal http response code: 202 * Expected error http response code: 404: Instance not found * JSON schema definition for the body data:: { ""volume_id"": ""string"" } * JSON schema definition for the response data: None * Example use case: Request: PUT v2/fa83baf8315542229f39af36aa643206/servers/822b2c1b-e4c4-4b12-\ b28e-35ca7f036edb/os-online_extend_volume Body:: { ""volume_id"": ""e5f556d2-3cfe-4ef1-9ddd-6ddb07d9b9b4"", } Response: HTTP 202/Accepted * Policy changes: Requires admin API access or it must be explicitly enabled by an admin in policy.json GET v2/{tenant_id}/servers/{server_id}/os-online_extend_volume/{volume_id} * Get the block device size of a server's volume on its compute host * Normal http response code: 200 * Expected error http response code: 404: Instance not found * JSON schema definition for the body data: None * JSON schema definition for the response data:: { ""blockdev"": { ""volume_id"": ""string"", ""bytes"": integer } } * Example use case: Request: GET v2/fa83baf8315542229f39af36aa643206/servers/822b2c1b-e4c4-4b12-\ b28e-35ca7f036edb/os-online_extend_volume/e5f556d2-3cfe-4ef1-9ddd-\ 6ddb07d9b9b4 Response: HTTP 200/OK :: { ""blockdev"":{ ""volume_id"": ""e5f556d2-3cfe-4ef1-9ddd-6ddb07d9b9b4"", ""bytes"": 4294967296 } } * Policy changes: Requires admin API access or it must be explicitly enabled by an admin in policy.json Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- These Nova operations are included in novaclient for Cinder, however, users will simply perform an online extend via Cinder if a deployer has it enabled. Performance Impact ------------------ Both of the calls in this extension require calls to the underlying compute host. Rescan is non-blocking and getting block device size is blocking. However, these calls should only be made when a user has issued an online extend from Cinder. Other deployer impact --------------------- The online extend extension is disabled by default for users and therefore it must be explicitly enabled in Cinder and Nova by a deployer if they have the required hypervisor and volume backend support. Developer impact ---------------- In addition to backend volume support, other virt drivers may support this extension as-is if they do not require any additional mechanisms to notify running instances of updated block device sizes. Libvirt versions that support block resize would likely need an additional call to notify the running instance of the new volume block device size. Implementation ============== Assignee(s) ----------- Primary assignee: paulvmarshall Work Items ---------- Add online extend extension with two API calls: rescan and get block device size. Add rescan to compute manager, compute rpc api, and the virt driver interface. Add get block device size to compute manager, compute rpc api, and the virt driver interface. Add unit tests for both rescan and get block device size. Add rescan and get block device size calls to novaclient. Dependencies ============ The initial implementation requires backend volume support as well as hypervisors that do not require additional mechanisms to expose updated block device sizes to instances, such as OpenVZ: https://github.com/stackforge/openvz-nova-driver Testing ======= The initial implementation of this extension is disabled by default and requires special hypervisor and volume backend support (e.g., OpenVZ and HP LH SAN), therefore, it will only be tested by unit tests and non-gate 3rd party tests. Documentation Impact ==================== None. Documentation will be included for Cinder. References ========== .. [1] https://blueprints.launchpad.net/cinder/+spec/inuse-extend-volume-extension ",,229,0
openstack%2Fnova-specs~master~I211e439407055e0f9bd1e8d564b216ad003c85e7,openstack/nova-specs,master,I211e439407055e0f9bd1e8d564b216ad003c85e7,Expose user and project in metadata services,ABANDONED,2014-04-17 19:55:58.000000000,2014-07-16 10:00:18.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1501}, {'_account_id': 1849}, {'_account_id': 4571}, {'_account_id': 4573}, {'_account_id': 6062}, {'_account_id': 7191}, {'_account_id': 9500}]","[{'number': 1, 'created': '2014-04-17 19:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3cda84ad93d747922b0fc26dcba5e7ab5926a763', 'message': 'Proposed nova-specs for user-project-metadata\n\nPart of blueprint user-project-metadata\n\nChange-Id: I211e439407055e0f9bd1e8d564b216ad003c85e7\n'}, {'number': 2, 'created': '2014-04-18 18:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b99717081dd2d81baf732e598ca6741c567351fa', 'message': 'Proposed nova-specs for user-project-metadata\n\nPart of blueprint user-project-metadata\n\nChange-Id: I211e439407055e0f9bd1e8d564b216ad003c85e7\n'}, {'number': 3, 'created': '2014-04-21 20:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b8f4639d004ae70933cebe836cb2191cf6de62f4', 'message': 'Proposed nova-specs for user-project-metadata\n\nPart of blueprint user-project-metadata\n\nChange-Id: I211e439407055e0f9bd1e8d564b216ad003c85e7\n'}, {'number': 4, 'created': '2014-04-24 23:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6de50ee00a3a3a2830c5e469b7f5e4f02b31917e', 'message': 'Expose user,project,domain in metadata services\n\nProposal to add new metadata fields to the existing nova metadata\nservices that are related to the individual user who has requested\ncreation of that compute resource (this could be a user or heat or\nother service acting on-behalf of some user).\n\nPart of blueprint user-project-metadata\n\nChange-Id: I211e439407055e0f9bd1e8d564b216ad003c85e7\n'}, {'number': 5, 'created': '2014-05-23 01:14:49.000000000', 'files': ['specs/juno/user-project-metadata.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/00c3bf9e2267bec0248a409e5f830f9f27c9be2c', 'message': 'Expose user and project in metadata services\n\nProposal to add new metadata fields to the existing nova metadata\nservices that are related to the individual user who has requested\ncreation of that compute resource (this could be a user or heat or\nother service acting on-behalf of some user).\n\nPart of blueprint user-project-metadata\n\nChange-Id: I211e439407055e0f9bd1e8d564b216ad003c85e7\n'}]",40,88419,00c3bf9e2267bec0248a409e5f830f9f27c9be2c,58,9,5,1297,,,0,"Expose user and project in metadata services

Proposal to add new metadata fields to the existing nova metadata
services that are related to the individual user who has requested
creation of that compute resource (this could be a user or heat or
other service acting on-behalf of some user).

Part of blueprint user-project-metadata

Change-Id: I211e439407055e0f9bd1e8d564b216ad003c85e7
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/19/88419/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/user-project-metadata.rst'],1,3cda84ad93d747922b0fc26dcba5e7ab5926a763,bp/user-project-metadata,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================================== User and project exposed via the openstack metadata & config drive service ========================================================================== **BP:** https://blueprints.launchpad.net/nova/+spec/user-project-metadata **Prior review:** https://review.openstack.org/#/c/72018/ Problem description =================== It is useful to expose the following tuple (user uuid, user name, tenant name, tenant uuid) of information to the instance to allow for the instance upon being booted to configure itself for the user or tenant that created the vm. A use-case that `yahoo`_ has that requires this: * On-boot pre-populate the users ssh-keys (by calling out to a remote service to get said public keys) so that said user can login immediatly without having to submit cloud-init user-data to perform the same actions (a hassle to users as the manual user-data method is not required when a service exists that can provide the ssh-keys in the first place). Another use-case that another company has that requires this: * Installing system tools on boot that should only be on available for tenant uuid X and not for another tenant uuid Y. Supplying these tuples to metadata allows for cloud-init (or other metadata/userdata consuming scripts) to perform different actions on-behalf of the user or tenant. .. _yahoo: http://www.yahoo.com/ Proposed change =============== When populating the extra metadata that is provided to the config drive and to the ec2 and openstack metadata service provide the user_id, project_id, user_name, project_name as extra data that will be provided for the instance to consume as instance metadata. New fields will be added to the `ec2 metadata`_: * owner/ * project-id * project-name * user-id * user-name New fields will be added to the openstack `metadata`_ and to the openstack `config drive`_ (a new metadata version should be created to match this new data fields):: { ""uuid"":""d8e02d56-2648-49a3-bf97-6be8f1204f38"", ... ""owner"":{ ""project_id"": ""4bdce62d-18b0-470e-9f10-f6d37d5b0714"", ""project_name"": ""harlowja"", ""user_id"": ""eb4b83cd-35f3-4896-b35d-88cc67d08c31"", ""user_name"": ""harlowja"" }, ... } .. _ec2 metadata: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AESDG-chapter-instancedata.html .. _metadata: http://docs.openstack.org/admin-guide-cloud/content/section_metadata-service.html .. _config drive: http://docs.openstack.org/user-guide/content/config-drive.html Alternatives ------------ 1. User has to submit same data manually by providing it as user-data (and cloud-init then has to know to look at user-data locations for this information). Data model impact ----------------- None REST API impact --------------- * The existing openstack metadata version (which also appears on the config drive as a folder representation) should be incremented and the new data will be added to this API version, the current version being ``2013-10-17.`` * **Open question**: should the ec2 version be incremented (these fields are not provided in any existing ec2 metadata response)? If so what ec2 version should this data belong in? Security impact --------------- * Provides instance owner their own project uuid and user id (and associated names making it easier for an attacker to provision VMs from inside an instance by calling out to nova). Of course the instance would not have access to the users password or keystone credentials so the risk should be minimial (although the risk is more than it was when this information was not available in the first place). Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None, existing query for data from nova-compute to populate config-drive or ec2/openstack metadata will be expanded to include new fields (which should exist in the avaiable ``context`` anyway). Other deployer impact --------------------- * No new config options * Will take effect on config-drive and metadata service/s immediately. * The change will be backwards compatible (since the change is additive) so continuous deployments should see no negative affects. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: harlowja Work Items ---------- * Add extraction of needed data at location where metadata and config drive extra metadata is initialized. * Provide new information as increment openstack & ec2 metadata version. * Incorporate change in config-drive as new folder/version where this data is provided and adjust openstack code so that ``latest`` points to this new version (instead of the prior version). Dependencies ============ None Testing ======= Seeing that there appears to be zero metadata tests (?) in tempest it would be great if this change could start adding at least a few tests to tempest that post-boot call into the metadata service (with tempest calling on behalf of the vm) and verifying that the metadata returned contains the newly added information. Documentation Impact ==================== * Adjustment of documentation about config-drive provided files. * Adjustment of documentation about ec2 and openstack metadata provided apis. References ========== None ",,182,0
openstack%2Fnova-specs~master~Ibe479d405f8f3bf395bca357ed7373ad459eb750,openstack/nova-specs,master,Ibe479d405f8f3bf395bca357ed7373ad459eb750,Refactor virt driver capabilities to support inheretence,ABANDONED,2014-04-22 13:51:00.000000000,2014-07-16 09:59:47.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 964}, {'_account_id': 1501}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5441}]","[{'number': 1, 'created': '2014-04-22 13:51:00.000000000', 'files': ['specs/juno/refactor-virt-capabilities.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a3aa819e987ccb4f702633567795668d25de98d7', 'message': 'Refactor virt driver capabilities to support inheretence\n\nCurrently the capabilities dict in the generic virt driver is\nover-written by each driver as required (or left unchanged).\n\nhis is problematic when new capabilities are added with what should\nbe a common default for most drivers, esp for an external driver class\nsuch as Ironic.  This BP proposes a simple refactor to provide\ninheritance for the capabilities dict.\n\nAlthough a simple change to implement it has an effect on all\ndriver development going forwards and hence seems worth of capturing\nas a blueprint.\n\nChange-Id: Ibe479d405f8f3bf395bca357ed7373ad459eb750\n'}]",9,89574,a3aa819e987ccb4f702633567795668d25de98d7,15,8,1,1501,,,0,"Refactor virt driver capabilities to support inheretence

Currently the capabilities dict in the generic virt driver is
over-written by each driver as required (or left unchanged).

his is problematic when new capabilities are added with what should
be a common default for most drivers, esp for an external driver class
such as Ironic.  This BP proposes a simple refactor to provide
inheritance for the capabilities dict.

Although a simple change to implement it has an effect on all
driver development going forwards and hence seems worth of capturing
as a blueprint.

Change-Id: Ibe479d405f8f3bf395bca357ed7373ad459eb750
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/74/89574/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/refactor-virt-capabilities.rst'],1,a3aa819e987ccb4f702633567795668d25de98d7,bp/proposes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================= Refactor Virt Driver Capabilities ================================= https://blueprints.launchpad.net/nova/+spec/refactor-virt-capabilities Refactor the capabilites exposed by virt drivers to support basic inheritance. Problem description =================== The virt driver provides a capabilities dict which allows the compute manager to determine the support for optional features such as ""has_imagecache"" and ""supports_recreate"". Currently this is a dict which each hypervisor driver either leaves intact of replaces completly, which means that whan a new capability is introduced, with a default value in the generic driver which maps to the existing functionality all drivers that have any specific capability settings need to be updated. Since Ironic includes a hypervisor driver which sits outside Nova the problem is extended to one that spans projects. Proposed change =============== The proposed solution is to refactor the code slightly so that capabilities only need to be defined in a hypervisor specific driver if they differ from the default. The change could be as simple as something like the following in the generic driver init method: capabilites.update(driver_specific_capabilites) Alternatives ------------ The alternatives are to either continue redefining all capabilities in any driver that needs to change one or mor values, or to make sure that any code that reads a capaibility provides the required deafult value if the capability is not defined. Data model impact ----------------- None, the change is restricted to the initialisation of the virt driver. REST API impact --------------- None, the change is restricted to the initialisation of the virt driver. Security impact --------------- None, the change is restricted to the initialisation of the virt driver. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Developers adding a new capability to the virt driver will only have to declare the capability in the generic driver and any driver that supports the non-default setting. The default setting of any new capabilty should always match the existing functionality. Implementation ============== Assignee(s) ----------- Primary assignee: philip-day Work Items ---------- * Refactor virt driver initialisation Dependencies ============ None Testing ======= The net effect of the change will be that each driver still exposes the same set of capabilities. The basic mechanism will be covered by unit tests. Existing Hypervisor specific CI tests will highlight any functional changes introduced by accident. Documentation Impact ==================== None References ========== None ",,142,0
openstack%2Ffuel-library~master~I28c0c7c6ff8c23dd9a9e4e911373ab4c443f1827,openstack/fuel-library,master,I28c0c7c6ff8c23dd9a9e4e911373ab4c443f1827,Fix glance meters for ceilometer,ABANDONED,2014-07-01 09:55:40.000000000,2014-07-16 09:58:04.000000000,,"[{'_account_id': 3}, {'_account_id': 7732}, {'_account_id': 8782}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-01 09:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b7e93534117cc9cf51c263d9929b036359254c1a', 'message': 'Fix glance meters for ceilometer\n\nChange-Id: I28c0c7c6ff8c23dd9a9e4e911373ab4c443f1827\nCloses-bug: #1335891\n'}, {'number': 2, 'created': '2014-07-03 15:53:17.000000000', 'files': ['deployment/puppet/glance/manifests/notify/rabbitmq.pp', 'deployment/puppet/ceilometer/manifests/init.pp', 'deployment/puppet/glance/spec/classes/glance_notify_rabbitmq_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8db7c34cedcd33ac9b27f8bab175f68ad7e72e16', 'message': 'Fix glance meters for ceilometer\n\nChange-Id: I28c0c7c6ff8c23dd9a9e4e911373ab4c443f1827\nCloses-bug: #1335891\n'}]",0,103827,8db7c34cedcd33ac9b27f8bab175f68ad7e72e16,20,5,2,7732,,,0,"Fix glance meters for ceilometer

Change-Id: I28c0c7c6ff8c23dd9a9e4e911373ab4c443f1827
Closes-bug: #1335891
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/27/103827/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/glance/manifests/notify/rabbitmq.pp', 'deployment/puppet/ceilometer/manifests/init.pp', 'deployment/puppet/glance/spec/classes/glance_notify_rabbitmq_spec.rb']",3,b7e93534117cc9cf51c263d9929b036359254c1a,master, it { should contain_glance_api_config('DEFAULT/rabbit_notification_exchange').with_value('openstack') }, it { should contain_glance_api_config('DEFAULT/rabbit_notification_exchange').with_value('glance') },6,5
openstack%2Fhorizon~master~I10ebc668f99ed3f502be07cb82759052a29654a1,openstack/horizon,master,I10ebc668f99ed3f502be07cb82759052a29654a1,Update 'Create Volume' button with ajax,MERGED,2014-06-06 12:27:37.000000000,2014-07-16 09:56:43.000000000,2014-07-16 09:56:43.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8090}, {'_account_id': 8871}, {'_account_id': 9622}, {'_account_id': 10112}, {'_account_id': 10442}, {'_account_id': 11546}]","[{'number': 1, 'created': '2014-06-06 12:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b74deaedf9afd8019b594fc2eb35c02d73e788c6', 'message': ""Update 'Create Volume' button with ajax\n\nThis patch set makes button 'Create Volume (Quota Exceeded)'\nbe replaced with enabled button 'Create Volume' after\ndeleting a volume.\n\nCloses-Bug: #1326589\n\nChange-Id: I10ebc668f99ed3f502be07cb82759052a29654a1\n""}, {'number': 2, 'created': '2014-06-06 12:33:19.000000000', 'files': ['openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'horizon/static/horizon/js/horizon.tables.js', 'openstack_dashboard/dashboards/project/volumes/volumes/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b2f4f3a3e2d750b0cce80f30a72f8f1db5916b02', 'message': ""Update 'Create Volume' button with ajax\n\nThis patch set makes button 'Create Volume (Quota Exceeded)'\nbe replaced with enabled button 'Create Volume' after\ndeleting a volume.\n\nCloses-Bug: #1326589\n\nChange-Id: I10ebc668f99ed3f502be07cb82759052a29654a1\n""}]",0,98395,b2f4f3a3e2d750b0cce80f30a72f8f1db5916b02,25,10,2,6914,,,0,"Update 'Create Volume' button with ajax

This patch set makes button 'Create Volume (Quota Exceeded)'
be replaced with enabled button 'Create Volume' after
deleting a volume.

Closes-Bug: #1326589

Change-Id: I10ebc668f99ed3f502be07cb82759052a29654a1
",git fetch https://review.opendev.org/openstack/horizon refs/changes/95/98395/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'horizon/static/horizon/js/horizon.tables.js', 'openstack_dashboard/dashboards/project/volumes/volumes/tables.py']",3,b74deaedf9afd8019b594fc2eb35c02d73e788c6,bug/1326589,"from django.http import HttpResponse # noqa ajax = True def __init__(self, attrs=None, **kwargs): kwargs['preempt'] = True super(CreateVolume, self).__init__(attrs, **kwargs) def single(self, table, request, object_id=None): self.allowed(request, None) return HttpResponse(self.render()) ",,13,2
openstack%2Foslo.vmware~master~I033f8371637a726b1d188eae0af16ceff946c9f7,openstack/oslo.vmware,master,I033f8371637a726b1d188eae0af16ceff946c9f7,Fix docstrings of constructors,MERGED,2014-07-11 14:36:48.000000000,2014-07-16 09:51:35.000000000,2014-07-16 09:51:35.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 8759}, {'_account_id': 9171}]","[{'number': 1, 'created': '2014-07-11 14:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/04dcbfad552ac648931aa6a524ae239df9c30777', 'message': ""Fix docstring of BlockingQueue.__init__()\n\nThe second argument is 'max_transfer_size', not '_max_transfer_size'.\n\nChange-Id: I033f8371637a726b1d188eae0af16ceff946c9f7\n""}, {'number': 2, 'created': '2014-07-11 14:42:03.000000000', 'files': ['oslo/vmware/image_transfer.py', 'oslo/vmware/rw_handles.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/7db48b335112163a8981425e9bea3face8ad9f31', 'message': 'Fix docstrings of constructors\n\nThe docstrings of the constructors for FileHandle and BlockingQueue are\nfixed.\n\nChange-Id: I033f8371637a726b1d188eae0af16ceff946c9f7\n'}]",0,106386,7db48b335112163a8981425e9bea3face8ad9f31,12,4,2,9172,,,0,"Fix docstrings of constructors

The docstrings of the constructors for FileHandle and BlockingQueue are
fixed.

Change-Id: I033f8371637a726b1d188eae0af16ceff946c9f7
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/86/106386/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/vmware/image_transfer.py'],1,04dcbfad552ac648931aa6a524ae239df9c30777,fix-docstring, :param max_transfer_size: maximum amount of data that can be, :param _max_transfer_size: maximum amount of data that can be,1,1
openstack%2Fhorizon~master~I39d21317570f4c3b58aa9e303bdbf23116a962c5,openstack/horizon,master,I39d21317570f4c3b58aa9e303bdbf23116a962c5,Imported Translations from Transifex,MERGED,2014-07-16 06:02:59.000000000,2014-07-16 09:51:22.000000000,2014-07-16 09:51:21.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-07-16 06:02:59.000000000', 'files': ['horizon/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/92675414a403725526066eb7bc5a62c7230460e8', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d21317570f4c3b58aa9e303bdbf23116a962c5\n'}]",0,107235,92675414a403725526066eb7bc5a62c7230460e8,9,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I39d21317570f4c3b58aa9e303bdbf23116a962c5
",git fetch https://review.opendev.org/openstack/horizon refs/changes/35/107235/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",18,92675414a403725526066eb7bc5a62c7230460e8,transifex/translations,"""POT-Creation-Date: 2014-07-15 07:11-0500\n"" ""PO-Revision-Date: 2014-07-15 11:04+0000\n""#: dashboards/project/data_processing/nodegroup_templates/tables.py:72 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:6 #: dashboards/project/data_processing/utils/workflow_helpers.py:106#: dashboards/project/databases/tables.py:232#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:10 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:40#: dashboards/project/databases/templates/databases/_resize_volume.html:25#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:14 #: dashboards/project/databases/templates/databases/_detail_overview.html:22#: dashboards/project/databases/templates/databases/_detail_overview.html:24#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:8#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:167 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:293#: dashboards/project/databases/tables.py:202#: dashboards/project/databases/tables.py:176 #: dashboards/project/databases/templates/databases/_detail_overview.html:38#: dashboards/project/databases/tables.py:185 #: dashboards/project/databases/tables.py:240#: dashboards/project/dashboard.py:69#: dashboards/project/databases/tables.py:178#: dashboards/project/databases/views.py:146#: dashboards/project/data_processing/nodegroup_templates/tables.py:55#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/nodegroup_templates.html:3#: dashboards/project/databases/tables.py:235#: dashboards/project/data_processing/nodegroup_templates/tables.py:75 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:6 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:18#: dashboards/project/data_processing/nodegroup_templates/panel.py:22 #: dashboards/project/data_processing/nodegroup_templates/tables.py:83 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/nodegroup_templates.html:6 msgid ""Node Group Templates"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tables.py:27 msgid ""Create Template"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tables.py:35 msgid ""Configure Template"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tables.py:44 msgid ""Copy Template"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tables.py:51 #: dashboards/project/data_processing/nodegroup_templates/tables.py:54 #: dashboards/project/database_backups/tables.py:76 #: dashboards/project/databases/tables.py:62 #: dashboards/project/databases/tables.py:78 #: dashboards/project/firewalls/tables.py:50 #: dashboards/project/firewalls/tables.py:65 #: dashboards/project/firewalls/tables.py:80 #: dashboards/project/loadbalancers/tables.py:70 #: dashboards/project/loadbalancers/tables.py:84 #: dashboards/project/loadbalancers/tables.py:98 #: dashboards/project/loadbalancers/tables.py:107 #: dashboards/project/stacks/tables.py:49 dashboards/project/vpn/tables.py:63 #: dashboards/project/vpn/tables.py:77 dashboards/project/vpn/tables.py:91 #: dashboards/project/vpn/tables.py:105 msgid ""Delete"" msgstr ""Delete"" #: dashboards/project/data_processing/nodegroup_templates/tables.py:56 msgid ""Template"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tables.py:57 msgid ""Templates"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tables.py:77 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:20 #: dashboards/project/data_processing/utils/workflow_helpers.py:165 msgid ""Hadoop Version"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tables.py:79 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:24 msgid ""Node Processes"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tabs.py:29 msgid ""General Info"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tabs.py:41 #: dashboards/project/data_processing/nodegroup_templates/tabs.py:64 msgid ""Unable to fetch node group template."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tabs.py:47 msgid ""Unable to fetch flavor for template."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tabs.py:52 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html:2 msgid ""Service Configurations"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/views.py:48 msgid ""Unable to fetch node group template list."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/views.py:103 msgid ""Unable to fetch template object."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:4 msgid ""This Node Group Template will be created for:"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:8 msgid ""Hadoop version"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:12 msgid """" ""The Node Group Template object should specify processes that will be "" ""launched on each instance. Also an OpenStack flavor is required to boot VMs."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:15 msgid """" ""Data Processing provides different storage location options. You may choose "" ""Ephemeral Drive or a Cinder Volume to be attached to instances."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:18 msgid """" ""When processes are selected, you may set <b>node</b> scoped Hadoop "" ""configurations on corresponding tabs."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_create_general_help.html:3 msgid ""Select a plugin and Hadoop version for a new Node group template."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:3 msgid ""Template Overview"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:34 msgid ""HDFS placement"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:36 msgid ""Cinder volumes"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:37 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:54 msgid ""Volumes per node"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:39 msgid ""Volumes size"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:42 msgid ""Ephemeral drive"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/configure.html:3 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/configure.html:6 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/create.html:3 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/create.html:6 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:166 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:292 msgid ""Create Node Group Template"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/details.html:3 msgid ""Nodegroup Template Details"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/details.html:6 msgid ""Node Group Template Details"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/copy.py:29 #, python-format msgid ""Node Group Template copy %s created"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/copy.py:77 msgid ""Unable to fetch plugin details."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:38 msgid ""Template Name"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:44 msgid ""OpenStack Flavor"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:47 msgid ""Storage location"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:48 msgid ""Storage"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:61 msgid ""Volumes size (GB)"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:90 msgid ""Unable to generate process choices."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:98 msgid ""Floating IP pool"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:103 msgid ""Processes"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:105 msgid ""Processes to be launched in node group"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:130 #: dashboards/project/instances/utils.py:31 msgid ""Unable to retrieve instance flavors."" msgstr ""Unable to retrieve instance flavors."" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:142 msgid ""Configure Node Group Template"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:168 #, python-format msgid ""Created Node Group Template %s"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:273 msgid ""Select plugin and hadoop version"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:294 #: dashboards/project/images/templates/images/images/_detail_overview.html:25 #: dashboards/project/instances/templates/instances/_detail_overview.html:18 #: dashboards/project/instances/templates/instances/_detail_overview.html:36 #: dashboards/project/stacks/tables.py:91 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:22 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:36 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:39 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:29 msgid ""Created"" msgstr ""Created"" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:295 msgid ""Could not create"" msgstr """" #: dashboards/project/data_processing/utils/workflow_helpers.py:111 msgid ""Node group cluster"" msgstr """" #: dashboards/project/data_processing/utils/workflow_helpers.py:116 msgid ""Count"" msgstr """" #: dashboards/project/data_processing/utils/workflow_helpers.py:157 msgid ""Plugin Name"" msgstr """" #: dashboards/project/databases/tables.py:246#: dashboards/project/databases/tables.py:148 #: dashboards/project/databases/tables.py:154#: dashboards/project/databases/tables.py:233#: dashboards/project/databases/forms.py:28 #: dashboards/project/volumes/volumes/forms.py:497 msgid ""Current Size (GB)"" msgstr """" #: dashboards/project/databases/forms.py:32 #: dashboards/project/volumes/volumes/forms.py:501 msgid ""New Size (GB)"" msgstr """" #: dashboards/project/databases/forms.py:39 msgid ""New size for volume must be greater than current size."" msgstr """" #: dashboards/project/databases/forms.py:50 #, python-format msgid ""Resizing volume \""%s\"""" msgstr """" #: dashboards/project/databases/forms.py:53 #, python-format msgid ""Unable to resize volume. %s"" msgstr """" #: dashboards/project/databases/tables.py:191#: dashboards/project/databases/tables.py:221#: dashboards/project/databases/tables.py:116 msgid ""Resize Volume"" msgstr """" #: dashboards/project/databases/tables.py:144#: dashboards/project/databases/tables.py:162#: dashboards/project/databases/tables.py:175 #: dashboards/project/databases/tables.py:217#: dashboards/project/databases/tables.py:181 #: dashboards/project/databases/templates/databases/_detail_overview.html:27#: dashboards/project/databases/tables.py:203#: dashboards/project/databases/tables.py:208#: dashboards/project/databases/tables.py:237#: dashboards/project/databases/views.py:47#: dashboards/project/databases/views.py:63#: dashboards/project/databases/views.py:84#: dashboards/project/databases/views.py:119#: dashboards/project/databases/templates/databases/_detail_overview.html:19 #: dashboards/project/images/templates/images/images/_detail_overview.html:41 #: dashboards/project/instances/templates/instances/_detail_overview.html:43 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:31 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:34 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:24 msgid ""Specs"" msgstr ""Specs"" #: dashboards/project/databases/templates/databases/_detail_overview.html:34#: dashboards/project/databases/templates/databases/_detail_overview.html:40#: dashboards/project/databases/templates/databases/_detail_overview.html:42#: dashboards/project/databases/templates/databases/_resize_volume.html:9 #: dashboards/project/databases/templates/databases/_resize_volume.html:24 #: dashboards/project/databases/templates/databases/resize_volume.html:3 #: dashboards/project/databases/templates/databases/resize_volume.html:6 msgid ""Resize Database Volume"" msgstr """" #: dashboards/project/databases/templates/databases/_resize_volume.html:18 msgid ""Specify the new volume size for the database instance."" msgstr """" #: dashboards/project/databases/templates/databases/_resize_volume.html:19 msgid """" ""<strong>Please note:</strong> The new value must be greater than the "" ""existing volume size."" msgstr """" ","""POT-Creation-Date: 2014-07-14 18:58-0500\n"" ""PO-Revision-Date: 2014-07-14 23:28+0000\n""#: dashboards/project/databases/tables.py:215#: dashboards/project/databases/templates/databases/_detail_overview.html:15#: dashboards/project/databases/tables.py:185#: dashboards/project/databases/tables.py:161 #: dashboards/project/databases/templates/databases/_detail_overview.html:29#: dashboards/project/databases/tables.py:170 #: dashboards/project/databases/tables.py:223#: dashboards/project/dashboard.py:68#: dashboards/project/databases/tables.py:163#: dashboards/project/databases/tables.py:218#: dashboards/project/databases/tables.py:229#: dashboards/project/database_backups/tables.py:76 #: dashboards/project/databases/tables.py:62 #: dashboards/project/databases/tables.py:78 #: dashboards/project/firewalls/tables.py:50 #: dashboards/project/firewalls/tables.py:65 #: dashboards/project/firewalls/tables.py:80 #: dashboards/project/loadbalancers/tables.py:70 #: dashboards/project/loadbalancers/tables.py:84 #: dashboards/project/loadbalancers/tables.py:98 #: dashboards/project/loadbalancers/tables.py:107 #: dashboards/project/stacks/tables.py:49 dashboards/project/vpn/tables.py:63 #: dashboards/project/vpn/tables.py:77 dashboards/project/vpn/tables.py:91 #: dashboards/project/vpn/tables.py:105 msgid ""Delete"" msgstr ""Delete"" #: dashboards/project/databases/tables.py:133 #: dashboards/project/databases/tables.py:139#: dashboards/project/databases/tables.py:216#: dashboards/project/databases/tables.py:176 #: dashboards/project/databases/tables.py:187#: dashboards/project/databases/tables.py:129#: dashboards/project/databases/tables.py:147#: dashboards/project/databases/tables.py:160 #: dashboards/project/databases/tables.py:200#: dashboards/project/databases/tables.py:166 #: dashboards/project/databases/templates/databases/_detail_overview.html:18#: dashboards/project/databases/tables.py:186#: dashboards/project/databases/tables.py:191#: dashboards/project/databases/tables.py:220#: dashboards/project/databases/views.py:44#: dashboards/project/databases/views.py:60#: dashboards/project/databases/views.py:81#: dashboards/project/databases/views.py:116#: dashboards/project/databases/templates/databases/_detail_overview.html:25#: dashboards/project/databases/templates/databases/_detail_overview.html:31#: dashboards/project/databases/templates/databases/_detail_overview.html:33#: dashboards/project/images/templates/images/images/_detail_overview.html:25 #: dashboards/project/instances/templates/instances/_detail_overview.html:18 #: dashboards/project/instances/templates/instances/_detail_overview.html:36 #: dashboards/project/stacks/tables.py:91 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:22 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:36 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:39 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:29 msgid ""Created"" msgstr ""Created"" #: dashboards/project/images/templates/images/images/_detail_overview.html:41 #: dashboards/project/instances/templates/instances/_detail_overview.html:43 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:31 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:34 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:24 msgid ""Specs"" msgstr ""Specs"" #: dashboards/project/instances/utils.py:31 msgid ""Unable to retrieve instance flavors."" msgstr ""Unable to retrieve instance flavors."" #: dashboards/project/volumes/volumes/forms.py:497 msgid ""Current Size (GB)"" msgstr """" #: dashboards/project/volumes/volumes/forms.py:501 msgid ""New Size (GB)"" msgstr """" ",5947,1391
openstack%2Fceilometer~master~I21f78698431ef9da9ddf5771a0594e5ab7f755a5,openstack/ceilometer,master,I21f78698431ef9da9ddf5771a0594e5ab7f755a5,Add keystone control exchange,MERGED,2014-06-29 17:18:15.000000000,2014-07-16 09:51:14.000000000,2014-07-16 09:51:13.000000000,"[{'_account_id': 3}, {'_account_id': 595}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 4715}, {'_account_id': 6172}, {'_account_id': 6537}, {'_account_id': 7478}, {'_account_id': 9562}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-06-29 17:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ac012f8dd4a442b127fcec9317f5b069e01cee70', 'message': 'WIP Add keystone exchange & notification plugins\n\nChange-Id: I21f78698431ef9da9ddf5771a0594e5ab7f755a5\nTODO: find some interesting notifications to collect them\n'}, {'number': 2, 'created': '2014-07-11 16:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/122ba8b13faf06472f13af1d962abf54b8d2f736', 'message': 'Add keystone exchange & notification plugins\n\nThis patch adds\n1) Notification exchange for keystone\n2) Abbility to profile keystone\n\nIn future we are going to add as well keystone\naudit notification pluging\n\nChange-Id: I21f78698431ef9da9ddf5771a0594e5ab7f755a5\n'}, {'number': 3, 'created': '2014-07-11 16:02:29.000000000', 'files': ['ceilometer/identity/__init__.py', 'ceilometer/profiler/notifications.py', 'ceilometer/identity/notifications.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/52b2779e1bae060d8dcf0edfc9307859d6cf4e93', 'message': 'Add keystone control exchange\n\nThis patch adds\n1) Notification exchange for keystone\n2) Abbility to profile keystone\n\nIn future we are going to add as well keystone\naudit notification pluging\n\nChange-Id: I21f78698431ef9da9ddf5771a0594e5ab7f755a5\n'}]",2,103420,52b2779e1bae060d8dcf0edfc9307859d6cf4e93,23,14,3,6172,,,0,"Add keystone control exchange

This patch adds
1) Notification exchange for keystone
2) Abbility to profile keystone

In future we are going to add as well keystone
audit notification pluging

Change-Id: I21f78698431ef9da9ddf5771a0594e5ab7f755a5
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/20/103420/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/identity/__init__.py', 'ceilometer/identity/notifications.py']",2,ac012f8dd4a442b127fcec9317f5b069e01cee70,add_keystone_exchange,"# Copyright 2014 Mirantis Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo.config import cfg OPTS = [ cfg.StrOpt('keystone_control_exchange', default='keystone', help=""Exchange name for Keystone notifications.""), ] cfg.CONF.register_opts(OPTS) ",,26,0
openstack%2Ftempest~master~I97903b1ea7faa02c5880c091a166e386295de0da,openstack/tempest,master,I97903b1ea7faa02c5880c091a166e386295de0da,Fix availability zone client in compute admin test,MERGED,2014-06-23 05:01:34.000000000,2014-07-16 09:51:06.000000000,2014-07-16 09:51:05.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 7139}, {'_account_id': 7428}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 05:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aaaafa40a4886ce44847ef908a7519bdcca55dea', 'message': 'Fix availability zone client in compute admin test\n\nIn /tempest/api/compute/admin/test_availability_zone.py file,\nV3 test class use the V2 Availability Zone client.\n\nThis patch correct the client for V2 and V3 by instantiating the\ncorrect one in base class.\n\nChange-Id: I97903b1ea7faa02c5880c091a166e386295de0da\n'}, {'number': 2, 'created': '2014-06-24 10:35:30.000000000', 'files': ['tempest/api/compute/base.py', 'tempest/api/compute/admin/test_availability_zone.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/315011163c94ebb2cb4886e1a192eaf039ab3782', 'message': 'Fix availability zone client in compute admin test\n\nIn /tempest/api/compute/admin/test_availability_zone.py file,\nV3 test class use the V2 Availability Zone client.\n\nThis patch correct the client for V2 and V3 by instantiating the\ncorrect one in base class.\n\nChange-Id: I97903b1ea7faa02c5880c091a166e386295de0da\n'}]",4,101798,315011163c94ebb2cb4886e1a192eaf039ab3782,74,10,2,8556,,,0,"Fix availability zone client in compute admin test

In /tempest/api/compute/admin/test_availability_zone.py file,
V3 test class use the V2 Availability Zone client.

This patch correct the client for V2 and V3 by instantiating the
correct one in base class.

Change-Id: I97903b1ea7faa02c5880c091a166e386295de0da
",git fetch https://review.opendev.org/openstack/tempest refs/changes/98/101798/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/base.py', 'tempest/api/compute/admin/test_availability_zone.py']",2,aaaafa40a4886ce44847ef908a7519bdcca55dea,availability_zone_client, cls.client = cls.availability_zone_admin_client, cls.client = cls.os_adm.availability_zone_client,10,2
openstack%2Fironic-specs~master~Ib37e6a86650698bc763281ddafbab65bf80d2bdc,openstack/ironic-specs,master,Ib37e6a86650698bc763281ddafbab65bf80d2bdc,Add support for retry on NodeLocked exceptions,MERGED,2014-07-01 20:45:58.000000000,2014-07-16 09:49:55.000000000,2014-07-16 09:49:55.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 11076}]","[{'number': 1, 'created': '2014-07-01 20:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/9333b55f50f325a1b4a2f93e91ce28434c21159e', 'message': 'Add support retry on NodeLocked exceptions.\n\nAn attempt to help mitigate the problem errors due to a node being\nlocked by multiple threads.\n\nChange-Id: Ib37e6a86650698bc763281ddafbab65bf80d2bdc\n'}, {'number': 2, 'created': '2014-07-01 20:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/239449e73e64ffb0d9291d7a3dcb844875a8d6dd', 'message': 'Add support for retry on NodeLocked exceptions\n\nAn attempt to help mitigate the problem errors due to a node being\nlocked by multiple threads.\n\nChange-Id: Ib37e6a86650698bc763281ddafbab65bf80d2bdc\n'}, {'number': 3, 'created': '2014-07-01 20:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/39808f63cb9123789d940d37ee73cba04b6a3bf7', 'message': 'Add support for retry on NodeLocked exceptions\n\nAn attempt to help mitigate the problem errors due to a node being\nlocked by multiple threads.\n\nChange-Id: Ib37e6a86650698bc763281ddafbab65bf80d2bdc\n'}, {'number': 4, 'created': '2014-07-01 20:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c435a90bccd748ba00ce84f1e3a0316ba5c6dec4', 'message': 'Add support for retry on NodeLocked exceptions\n\nAn attempt to help mitigate the problem errors due to a node being\nlocked by multiple threads.\n\nChange-Id: Ib37e6a86650698bc763281ddafbab65bf80d2bdc\n'}, {'number': 5, 'created': '2014-07-09 18:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/ef579a154d9f80ae1d5bcdc9cd5159214f32410d', 'message': 'Add support for retry on NodeLocked exceptions\n\nAn attempt to help mitigate the problem errors due to a node being\nlocked by multiple threads.\n\nChange-Id: Ib37e6a86650698bc763281ddafbab65bf80d2bdc\n'}, {'number': 6, 'created': '2014-07-14 15:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/58e24fcf1880d7ad054bfa5c62b6f251bba5bbe6', 'message': 'Add support for retry on NodeLocked exceptions\n\nAn attempt to help mitigate the problem errors due to a node being\nlocked by multiple threads.\n\nChange-Id: Ib37e6a86650698bc763281ddafbab65bf80d2bdc\n'}, {'number': 7, 'created': '2014-07-14 19:21:41.000000000', 'files': ['specs/juno/add-nodelocked-retry.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/7fbd26ac061a506dfe81f1be6da781f3f318877b', 'message': 'Add support for retry on NodeLocked exceptions\n\nAn attempt to help mitigate the problem errors due to a node being\nlocked by multiple threads.\n\nChange-Id: Ib37e6a86650698bc763281ddafbab65bf80d2bdc\n'}]",21,103996,7fbd26ac061a506dfe81f1be6da781f3f318877b,43,7,7,3099,,,0,"Add support for retry on NodeLocked exceptions

An attempt to help mitigate the problem errors due to a node being
locked by multiple threads.

Change-Id: Ib37e6a86650698bc763281ddafbab65bf80d2bdc
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/96/103996/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/add-nodelocked-retry.rst'],1,9333b55f50f325a1b4a2f93e91ce28434c21159e,add-nodelocked-retry,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================== Add Support for Retry on NodeLocked Exceptions ============================================== https://blueprints.launchpad.net/ironic/+spec/add-nodelocked-retry Let's reduce the pain of clients being presented errors due to conflicts with locking a particular node (NodeLocked exceptions) by adding multiple attempts to lock the node on the client's behalf. As an added benefit, this would also help with tempest testing where this error is seen on occasion. Problem description =================== Ironic clients may sometimes experience a NodeLocked exception/error when making certain REST API calls. This is because the conductor(s) will grab a lock on a node before performing any action that may change that node's characteristics. Examples of where node locking occurs are: * Almost all of the REST API calls lock the node in question except for: change_node_maintenance_mode, driver_vendor_passthru, get_console_information and validate_driver_interfaces. * The conductor periodic task to synchronize power states. * The conductor periodic task to check deploy timeouts. The amount of time the node locks are held are typically not long. We could eliminate many of these errors by simply retrying the lock attempt. Admittedly, this would not *totally* eliminate the problem, but it would make it much less likely to occur for clients, and thus make for a much better experience. Proposed change =============== The TaskManager class is used to control when nodes are locked. The lock itself is implemented by the database backend. I propose we change the TaskManager.__init__() method to incorporate the retry logic, leaving the implementation of the lock itself (the database API layer) untouched. This lets us change the lock implementation later, if we choose, without having to migrate the retry logic. Alternatives ------------ A more permanent solution to this problem is being discussed in a spec that is defining an asynchronous REST API [1]: https://review.openstack.org/94923 It is unlikely that spec will be approved in Juno because of the work that it entails to change the APIs. This proposal is simple and can be implemented quickly. Data model impact ----------------- None REST API impact --------------- None Driver API impact ----------------- None Nova driver impact ------------------ None Security impact --------------- None Other end user impact --------------------- The only impact this will have on the user is the reduced amount of node lock errors from API requests. Scalability impact ------------------ This does have the possibility to negatively impact scalability. A spawned worker thread within the conductor could potentially take longer to process the work if a NodeLocked expection is thrown. This impact can be mitigated by increasing the number of workers in the pool (the workers_pool_size option). Performance Impact ------------------ This will add additional processing time to REST API calls that happen to encounter a node lock error. This is due to repeated calls to the database API layer to attempt to successfully lock the node. If the node is locked successfully on the first attempt, then performance is not impacted at all. Other deployer impact --------------------- We may want to control the retry logic with configuration variables for maximum retry attempts and time in between attempts (or values for doing exponential backoff). Hard coded values for retry attempts and time between attempts would create no deployer impact. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <dshrews> Work Items ---------- None Dependencies ============ The retrying [2] Python library would be of great use here, as it encasulates all of the logic we would want. Version 1.2.2 (the latest release as of this writing) would be the minimum version we would want since it contains an important bug fix related to retrying on certain exceptions. Testing ======= I don't see how to test this in tempest successfully (other than eliminating the current errors from tempest due to this problem), but I imagine we can add unit tests to verify it's working as we expect. Documentation Impact ==================== None References ========== [1] https://review.openstack.org/94923 [2] https://pypi.python.org/pypi/retrying ",,171,0
openstack%2Ffuel-web~master~I943209199ef536bec65163dfc15acc091dbaec0e,openstack/fuel-web,master,I943209199ef536bec65163dfc15acc091dbaec0e,Fixing enabled tests checkbox on Healthcheck tab,MERGED,2014-07-15 15:29:10.000000000,2014-07-16 09:45:11.000000000,2014-07-16 09:45:11.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-07-15 15:29:10.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/healthcheck_tab.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c4b13cd2acf2cf0ec7e5f6aed4858750cbc608a6', 'message': 'Fixing enabled tests checkbox on Healthcheck tab\n\nAdded check for selectAll disabled state on tests render\n\nChange-Id: I943209199ef536bec65163dfc15acc091dbaec0e\nCloses-bug: 1342174\n'}]",1,107087,c4b13cd2acf2cf0ec7e5f6aed4858750cbc608a6,12,6,1,9091,,,0,"Fixing enabled tests checkbox on Healthcheck tab

Added check for selectAll disabled state on tests render

Change-Id: I943209199ef536bec65163dfc15acc091dbaec0e
Closes-bug: 1342174
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/87/107087/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/cluster_page_tabs/healthcheck_tab.js'],1,c4b13cd2acf2cf0ec7e5f6aed4858750cbc608a6,bug/1342174," var commonDisabledState = this.tab.selectAllCheckbox.get('disabled'); this.selectAllCheckbox.set({disabled: commonDisabledState}); this.tests.invoke('set', {disabled: commonDisabledState});",,3,0
openstack%2Fnova-specs~master~I7d37b5382764d2dbeb5750422ef1fd8eaa8eb3ce,openstack/nova-specs,master,I7d37b5382764d2dbeb5750422ef1fd8eaa8eb3ce,"nova-specs for ""add-delete-on-termination-option""",ABANDONED,2014-04-23 09:15:40.000000000,2014-07-16 09:45:00.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1501}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 8646}, {'_account_id': 8846}]","[{'number': 1, 'created': '2014-04-23 09:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0c99d861271b470dca2cf47837c1d5c0914adc4f', 'message': 'nova-specs for ""add-support-for-cpu-hotadd""\n\nChange-Id: I7d37b5382764d2dbeb5750422ef1fd8eaa8eb3ce\nImplements: blueprint add-delete-on-termination-option\n'}, {'number': 2, 'created': '2014-04-23 09:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/31704e6213b3eb6b44aa4876c320e19da48e872f', 'message': 'nova-specs for ""add-delete-on-termination-option""\n\nChange-Id: I7d37b5382764d2dbeb5750422ef1fd8eaa8eb3ce\nImplements: blueprint add-delete-on-termination-option\n'}, {'number': 3, 'created': '2014-04-25 01:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8c2f79ca7af8d4d50cb3f712d57a5568231675a9', 'message': 'nova-specs for ""add-delete-on-termination-option""\n\nChange-Id: I7d37b5382764d2dbeb5750422ef1fd8eaa8eb3ce\nImplements: blueprint add-delete-on-termination-option\n'}, {'number': 4, 'created': '2014-05-05 08:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/82b59934b620f29dfcfb5d8ded90f301fa639359', 'message': 'nova-specs for ""add-delete-on-termination-option""\n\nChange-Id: I7d37b5382764d2dbeb5750422ef1fd8eaa8eb3ce\nImplements: blueprint add-delete-on-termination-option\n'}, {'number': 5, 'created': '2014-05-06 08:05:26.000000000', 'files': ['specs/juno/add-delete-on-termination-option.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4ba1986645b0e012206badc3b5d254c411e4cf89', 'message': 'nova-specs for ""add-delete-on-termination-option""\n\nChange-Id: I7d37b5382764d2dbeb5750422ef1fd8eaa8eb3ce\nImplements: blueprint add-delete-on-termination-option\n'}]",2,89777,4ba1986645b0e012206badc3b5d254c411e4cf89,30,8,5,8646,,,0,"nova-specs for ""add-delete-on-termination-option""

Change-Id: I7d37b5382764d2dbeb5750422ef1fd8eaa8eb3ce
Implements: blueprint add-delete-on-termination-option
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/77/89777/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/add-delete-on-termination-option.rst'],1,0c99d861271b470dca2cf47837c1d5c0914adc4f,bp/add-delete-on-termination-option,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================================================== add delete_on_termination option for attaching volume to an existing server =========================================================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/add-delete-on-termination-option Add delete_on_termination option when attaching volume for an exist server. Problem description =================== There is parameter known as delete_on_termination option for attaching volume when creating a new server, but no option when attaching a volume to an exist server. so the result will be different when deleting the server. Attach a volume when creating a new server, the API contains 'block_device_mapping', such as: ""block_device_mapping"": [ {""volume_id"": ""<VOLUME_ID>"", ""device_name"": ""/dev/vdc"", ""delete_on_termination"": ""true""}] There is no option 'delete_on_termination' when attaching a volume to an exsit server, the POST data likes: {""volumeAttachment"":{""volumeId"":""<VOLUME_ID>"", ""device"":""/dev/sdb""}} Proposed change =============== Add the same option 'delete_on_termination' when attaching a volume to an exsit server, the POST data likes: {""volumeAttachment"":{""volumeId"":""<VOLUME_ID>"", ""device"":""/dev/sdb"" ""delete_on_termination"": ""true""}} Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- API for attaching a volume to an exist instance: Scenarios: Case 1: If delete_on_termination is true, the volume will be delete when delete the instance. Case 2: If delete_on_termination is false, the volume will not be delete when delete the instance. (Default behavior) V2 API specification: POST: v3/{tenant_id}/servers/{server_id}/os-volume_attachments V3 API specification: POST: v3/servers/{server_id}/os-volume_attachments Request parameters: * server_id: The UUID for the server of interest to you. * volumeId: ID of the volume to attach. * device: Name of the device such as, /dev/vdb. Use ""auto"" for auto-assign (if supported). * delete_on_termination(Optional): Whether to remove the volume when the server is terminated(default: False). * volumeAttachment: A dictionary representation of a volume attachment. JSON request: { ""volumeAttachment"": { ""volumeId"": ""a26887c6-c47b-4654-abb5-dfadf7d3f803"", ""device"": ""/dev/vdd"", ""delete_on_termination"": True } } JSON response: { ""volumeAttachment"": { ""device"": ""/dev/vdd"", ""id"": ""a26887c6-c47b-4654-abb5-dfadf7d3f803"", ""serverId"": ""0c92f3f6-c253-4c9b-bd43-e880a8d2eb0a"", ""volumeId"": ""a26887c6-c47b-4654-abb5-dfadf7d3f803"", ""delete_on_termination"": True } } Sample v2 request: POST: v2/{tenant_id}/servers/{server_id}/os-volume_attachments -d '{ ""volumeAttachment"": { ""volumeId"": ""a26887c6-c47b-4654-abb5-dfadf7d3f803"", ""device"": ""/dev/vdd"", ""delete_on_termination"": True } }' Sample v3 request: POST: v3/servers/{server_id}/os-volume_attachments -d '{ ""volumeAttachment"": { ""volumeId"": ""a26887c6-c47b-4654-abb5-dfadf7d3f803"", ""device"": ""/dev/vdd"", ""delete_on_termination"": True } }' JSON schema definition:: attach = { 'type': 'object', 'properties': { 'attach': { 'type': 'object', 'properties': { 'volume_id': {'type': 'string', 'format': 'uuid'}, 'device': { 'type': 'string', # NOTE: The validation pattern from match_device() in # nova/block_device.py. 'pattern': '(^/dev/x{0,1}[a-z]{0,1}d{0,1})([a-z]+)[0-9]*$' }, 'disk_bus': { 'type': 'string' }, 'device_type': { 'type': 'string', }, 'delete_on_termination': { 'type': 'boolean', }, }, 'required': ['volume_id'], 'additionalProperties': False, }, }, 'required': ['attach'], 'additionalProperties': False, } HTTP response codes: v2: Normal HTTP Response Code: 202 on success v3: Normal HTTP Response Code: 200 on success Validation: 'delete_on_termination' must be boolean. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- If developers attach a volume to an exist server. they must define 'delete_on_termination' option to determine whether or not delete the volume when deleting server. Implementation ============== Assignee(s) ----------- Primary assignee: idopra Work Items ---------- * add option 'delete_on_termination' when attaching a volume to an exsit server. * users whether or not delete the volume based on 'delete_on_termination' option. Dependencies ============ None. Testing ======= add unit test to check the option valid. Documentation Impact ==================== Changes to be made to the attach volume API documentation to include the additional parameter 'delete_on_termination' that can be passed in. References ========== None. ",,253,0
